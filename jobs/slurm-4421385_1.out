model : table13slim
N : 1
flips : False
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.3
schedule_freq : 10
seed : 1
n_epochs : 30
batch_size : 64
non_wrapped : False
chunked : False
dense : True
parameter_correction : True
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-29 15:59:47

Channel scaling factor: 13.5

The number of parameters is: 279504

The number of individual parameters is:

108
432
108
108
162
52488
162
162
324
157464
324
324
64
62208
64
64
4096
64
640
10
64
64

nonzero elements in E: 13975198
elements in E: 13975200
fraction nonzero: 0.9999998568893469
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.43; acc: 0.11
Batch: 20; loss: 2.32; acc: 0.09
Batch: 40; loss: 2.36; acc: 0.12
Batch: 60; loss: 2.27; acc: 0.19
Batch: 80; loss: 2.15; acc: 0.23
Batch: 100; loss: 2.25; acc: 0.25
Batch: 120; loss: 2.23; acc: 0.17
Batch: 140; loss: 2.04; acc: 0.42
Batch: 160; loss: 2.13; acc: 0.19
Batch: 180; loss: 2.16; acc: 0.27
Batch: 200; loss: 2.14; acc: 0.19
Batch: 220; loss: 2.21; acc: 0.27
Batch: 240; loss: 2.07; acc: 0.28
Batch: 260; loss: 2.14; acc: 0.23
Batch: 280; loss: 2.03; acc: 0.31
Batch: 300; loss: 2.23; acc: 0.22
Batch: 320; loss: 2.0; acc: 0.31
Batch: 340; loss: 2.03; acc: 0.36
Batch: 360; loss: 2.1; acc: 0.27
Batch: 380; loss: 2.02; acc: 0.33
Batch: 400; loss: 2.08; acc: 0.27
Batch: 420; loss: 2.09; acc: 0.28
Batch: 440; loss: 2.0; acc: 0.33
Batch: 460; loss: 2.12; acc: 0.33
Batch: 480; loss: 2.06; acc: 0.41
Batch: 500; loss: 2.06; acc: 0.41
Batch: 520; loss: 2.04; acc: 0.31
Batch: 540; loss: 2.13; acc: 0.23
Batch: 560; loss: 2.13; acc: 0.19
Batch: 580; loss: 2.02; acc: 0.34
Batch: 600; loss: 2.03; acc: 0.31
Batch: 620; loss: 2.03; acc: 0.28
Batch: 640; loss: 2.09; acc: 0.25
Batch: 660; loss: 2.1; acc: 0.27
Batch: 680; loss: 2.1; acc: 0.25
Batch: 700; loss: 2.09; acc: 0.2
Batch: 720; loss: 2.04; acc: 0.36
Batch: 740; loss: 2.05; acc: 0.31
Batch: 760; loss: 2.04; acc: 0.3
Batch: 780; loss: 1.98; acc: 0.38
Train Epoch over. train_loss: 2.11; train_accuracy: 0.27 

2.832168320310302e-05
3.98350675823167e-06
Batch: 0; loss: 1.93; acc: 0.34
Batch: 20; loss: 2.25; acc: 0.2
Batch: 40; loss: 1.98; acc: 0.31
Batch: 60; loss: 1.99; acc: 0.36
Batch: 80; loss: 2.01; acc: 0.3
Batch: 100; loss: 1.99; acc: 0.44
Batch: 120; loss: 2.01; acc: 0.38
Batch: 140; loss: 2.07; acc: 0.3
Val Epoch over. val_loss: 2.0431954116578313; val_accuracy: 0.3059315286624204 

The current subspace-distance is: 3.98350675823167e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.05; acc: 0.25
Batch: 20; loss: 1.98; acc: 0.28
Batch: 40; loss: 1.96; acc: 0.39
Batch: 60; loss: 2.16; acc: 0.2
Batch: 80; loss: 2.0; acc: 0.27
Batch: 100; loss: 2.05; acc: 0.27
Batch: 120; loss: 2.12; acc: 0.27
Batch: 140; loss: 1.97; acc: 0.36
Batch: 160; loss: 2.08; acc: 0.22
Batch: 180; loss: 2.0; acc: 0.36
Batch: 200; loss: 2.06; acc: 0.3
Batch: 220; loss: 2.02; acc: 0.3
Batch: 240; loss: 1.96; acc: 0.45
Batch: 260; loss: 2.1; acc: 0.22
Batch: 280; loss: 2.0; acc: 0.3
Batch: 300; loss: 2.07; acc: 0.23
Batch: 320; loss: 1.89; acc: 0.41
Batch: 340; loss: 2.05; acc: 0.36
Batch: 360; loss: 2.01; acc: 0.39
Batch: 380; loss: 1.92; acc: 0.33
Batch: 400; loss: 2.06; acc: 0.3
Batch: 420; loss: 1.98; acc: 0.44
Batch: 440; loss: 2.03; acc: 0.31
Batch: 460; loss: 2.0; acc: 0.36
Batch: 480; loss: 2.15; acc: 0.25
Batch: 500; loss: 1.98; acc: 0.36
Batch: 520; loss: 2.1; acc: 0.28
Batch: 540; loss: 2.11; acc: 0.2
Batch: 560; loss: 1.92; acc: 0.47
Batch: 580; loss: 2.07; acc: 0.23
Batch: 600; loss: 1.93; acc: 0.39
Batch: 620; loss: 1.96; acc: 0.45
Batch: 640; loss: 2.13; acc: 0.3
Batch: 660; loss: 1.98; acc: 0.33
Batch: 680; loss: 1.96; acc: 0.39
Batch: 700; loss: 2.05; acc: 0.34
Batch: 720; loss: 1.96; acc: 0.34
Batch: 740; loss: 1.98; acc: 0.44
Batch: 760; loss: 1.9; acc: 0.5
Batch: 780; loss: 1.99; acc: 0.33
Train Epoch over. train_loss: 2.02; train_accuracy: 0.33 

2.8701944756903686e-05
5.5019158935465384e-06
Batch: 0; loss: 1.9; acc: 0.45
Batch: 20; loss: 2.13; acc: 0.22
Batch: 40; loss: 1.89; acc: 0.41
Batch: 60; loss: 1.85; acc: 0.44
Batch: 80; loss: 1.93; acc: 0.44
Batch: 100; loss: 1.97; acc: 0.38
Batch: 120; loss: 1.94; acc: 0.41
Batch: 140; loss: 1.98; acc: 0.34
Val Epoch over. val_loss: 1.969659962471883; val_accuracy: 0.36176353503184716 

The current subspace-distance is: 5.5019158935465384e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.0; acc: 0.39
Batch: 20; loss: 1.94; acc: 0.39
Batch: 40; loss: 2.09; acc: 0.27
Batch: 60; loss: 1.99; acc: 0.36
Batch: 80; loss: 1.95; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.48
Batch: 120; loss: 1.97; acc: 0.34
Batch: 140; loss: 1.99; acc: 0.38
Batch: 160; loss: 1.92; acc: 0.41
Batch: 180; loss: 2.0; acc: 0.31
Batch: 200; loss: 2.03; acc: 0.3
Batch: 220; loss: 2.2; acc: 0.2
Batch: 240; loss: 1.9; acc: 0.45
Batch: 260; loss: 1.94; acc: 0.41
Batch: 280; loss: 1.97; acc: 0.36
Batch: 300; loss: 2.0; acc: 0.39
Batch: 320; loss: 2.05; acc: 0.31
Batch: 340; loss: 2.07; acc: 0.33
Batch: 360; loss: 2.02; acc: 0.38
Batch: 380; loss: 2.0; acc: 0.34
Batch: 400; loss: 2.02; acc: 0.3
Batch: 420; loss: 1.94; acc: 0.36
Batch: 440; loss: 1.94; acc: 0.47
Batch: 460; loss: 1.97; acc: 0.36
Batch: 480; loss: 2.05; acc: 0.36
Batch: 500; loss: 2.02; acc: 0.3
Batch: 520; loss: 2.07; acc: 0.36
Batch: 540; loss: 1.94; acc: 0.45
Batch: 560; loss: 1.94; acc: 0.34
Batch: 580; loss: 1.96; acc: 0.39
Batch: 600; loss: 2.01; acc: 0.38
Batch: 620; loss: 2.01; acc: 0.34
Batch: 640; loss: 2.03; acc: 0.36
Batch: 660; loss: 2.13; acc: 0.25
Batch: 680; loss: 1.97; acc: 0.33
Batch: 700; loss: 1.98; acc: 0.38
Batch: 720; loss: 2.05; acc: 0.34
Batch: 740; loss: 2.05; acc: 0.25
Batch: 760; loss: 1.96; acc: 0.39
Batch: 780; loss: 1.99; acc: 0.33
Train Epoch over. train_loss: 2.0; train_accuracy: 0.35 

2.9929637094028294e-05
5.098372184875188e-06
Batch: 0; loss: 1.9; acc: 0.42
Batch: 20; loss: 2.17; acc: 0.22
Batch: 40; loss: 1.87; acc: 0.45
Batch: 60; loss: 1.85; acc: 0.48
Batch: 80; loss: 1.93; acc: 0.41
Batch: 100; loss: 1.98; acc: 0.36
Batch: 120; loss: 1.95; acc: 0.38
Batch: 140; loss: 1.95; acc: 0.36
Val Epoch over. val_loss: 1.9636334499735741; val_accuracy: 0.38007563694267515 

The current subspace-distance is: 5.098372184875188e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.92; acc: 0.31
Batch: 20; loss: 2.02; acc: 0.23
Batch: 40; loss: 1.97; acc: 0.36
Batch: 60; loss: 1.95; acc: 0.36
Batch: 80; loss: 1.99; acc: 0.3
Batch: 100; loss: 2.11; acc: 0.3
Batch: 120; loss: 2.08; acc: 0.28
Batch: 140; loss: 1.98; acc: 0.34
Batch: 160; loss: 2.01; acc: 0.28
Batch: 180; loss: 2.02; acc: 0.38
Batch: 200; loss: 1.99; acc: 0.41
Batch: 220; loss: 2.03; acc: 0.39
Batch: 240; loss: 2.01; acc: 0.38
Batch: 260; loss: 2.04; acc: 0.31
Batch: 280; loss: 2.09; acc: 0.25
Batch: 300; loss: 1.92; acc: 0.36
Batch: 320; loss: 1.98; acc: 0.34
Batch: 340; loss: 2.08; acc: 0.28
Batch: 360; loss: 1.98; acc: 0.31
Batch: 380; loss: 1.98; acc: 0.39
Batch: 400; loss: 1.91; acc: 0.41
Batch: 420; loss: 2.02; acc: 0.47
Batch: 440; loss: 2.05; acc: 0.3
Batch: 460; loss: 1.93; acc: 0.34
Batch: 480; loss: 2.07; acc: 0.3
Batch: 500; loss: 1.89; acc: 0.42
Batch: 520; loss: 1.92; acc: 0.47
Batch: 540; loss: 2.0; acc: 0.39
Batch: 560; loss: 1.88; acc: 0.47
Batch: 580; loss: 2.01; acc: 0.36
Batch: 600; loss: 1.96; acc: 0.36
Batch: 620; loss: 2.03; acc: 0.38
Batch: 640; loss: 1.92; acc: 0.41
Batch: 660; loss: 2.06; acc: 0.23
Batch: 680; loss: 2.02; acc: 0.39
Batch: 700; loss: 1.96; acc: 0.39
Batch: 720; loss: 2.03; acc: 0.34
Batch: 740; loss: 1.9; acc: 0.41
Batch: 760; loss: 1.92; acc: 0.45
Batch: 780; loss: 2.02; acc: 0.33
Train Epoch over. train_loss: 1.99; train_accuracy: 0.35 

2.896999467338901e-05
4.345173692854587e-06
Batch: 0; loss: 1.92; acc: 0.41
Batch: 20; loss: 2.17; acc: 0.23
Batch: 40; loss: 1.92; acc: 0.41
Batch: 60; loss: 1.84; acc: 0.5
Batch: 80; loss: 1.95; acc: 0.36
Batch: 100; loss: 1.99; acc: 0.34
Batch: 120; loss: 1.95; acc: 0.39
Batch: 140; loss: 1.97; acc: 0.42
Val Epoch over. val_loss: 1.973347731456635; val_accuracy: 0.3796775477707006 

The current subspace-distance is: 4.345173692854587e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.0; acc: 0.36
Batch: 20; loss: 1.91; acc: 0.41
Batch: 40; loss: 2.04; acc: 0.31
Batch: 60; loss: 2.02; acc: 0.34
Batch: 80; loss: 1.92; acc: 0.33
Batch: 100; loss: 2.04; acc: 0.33
Batch: 120; loss: 1.94; acc: 0.45
Batch: 140; loss: 1.99; acc: 0.31
Batch: 160; loss: 1.95; acc: 0.36
Batch: 180; loss: 2.02; acc: 0.34
Batch: 200; loss: 1.96; acc: 0.38
Batch: 220; loss: 2.02; acc: 0.31
Batch: 240; loss: 2.02; acc: 0.39
Batch: 260; loss: 2.11; acc: 0.28
Batch: 280; loss: 1.9; acc: 0.42
Batch: 300; loss: 1.94; acc: 0.34
Batch: 320; loss: 1.98; acc: 0.31
Batch: 340; loss: 2.09; acc: 0.19
Batch: 360; loss: 1.9; acc: 0.41
Batch: 380; loss: 2.02; acc: 0.42
Batch: 400; loss: 2.04; acc: 0.31
Batch: 420; loss: 2.01; acc: 0.34
Batch: 440; loss: 2.1; acc: 0.27
Batch: 460; loss: 2.05; acc: 0.28
Batch: 480; loss: 2.04; acc: 0.31
Batch: 500; loss: 1.89; acc: 0.48
Batch: 520; loss: 1.97; acc: 0.34
Batch: 540; loss: 1.93; acc: 0.39
Batch: 560; loss: 1.99; acc: 0.31
Batch: 580; loss: 1.93; acc: 0.42
Batch: 600; loss: 1.97; acc: 0.39
Batch: 620; loss: 1.91; acc: 0.41
Batch: 640; loss: 2.01; acc: 0.36
Batch: 660; loss: 2.09; acc: 0.27
Batch: 680; loss: 2.07; acc: 0.28
Batch: 700; loss: 1.99; acc: 0.38
Batch: 720; loss: 2.03; acc: 0.28
Batch: 740; loss: 2.02; acc: 0.33
Batch: 760; loss: 1.95; acc: 0.39
Batch: 780; loss: 1.94; acc: 0.44
Train Epoch over. train_loss: 1.98; train_accuracy: 0.36 

2.9794957299600355e-05
4.9253299039264675e-06
Batch: 0; loss: 1.88; acc: 0.48
Batch: 20; loss: 2.1; acc: 0.31
Batch: 40; loss: 1.88; acc: 0.45
Batch: 60; loss: 1.82; acc: 0.52
Batch: 80; loss: 1.87; acc: 0.45
Batch: 100; loss: 1.95; acc: 0.41
Batch: 120; loss: 1.94; acc: 0.39
Batch: 140; loss: 1.95; acc: 0.41
Val Epoch over. val_loss: 1.9502300289785786; val_accuracy: 0.38883359872611467 

The current subspace-distance is: 4.9253299039264675e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.84; acc: 0.48
Batch: 20; loss: 1.89; acc: 0.36
Batch: 40; loss: 1.94; acc: 0.45
Batch: 60; loss: 2.02; acc: 0.41
Batch: 80; loss: 1.91; acc: 0.41
Batch: 100; loss: 2.01; acc: 0.38
Batch: 120; loss: 1.86; acc: 0.42
Batch: 140; loss: 1.98; acc: 0.33
Batch: 160; loss: 1.94; acc: 0.39
Batch: 180; loss: 1.99; acc: 0.44
Batch: 200; loss: 1.93; acc: 0.34
Batch: 220; loss: 1.89; acc: 0.5
Batch: 240; loss: 1.95; acc: 0.34
Batch: 260; loss: 1.91; acc: 0.39
Batch: 280; loss: 1.91; acc: 0.36
Batch: 300; loss: 1.91; acc: 0.42
Batch: 320; loss: 1.96; acc: 0.42
Batch: 340; loss: 1.96; acc: 0.39
Batch: 360; loss: 1.95; acc: 0.3
Batch: 380; loss: 1.92; acc: 0.39
Batch: 400; loss: 2.0; acc: 0.27
Batch: 420; loss: 1.94; acc: 0.44
Batch: 440; loss: 2.11; acc: 0.28
Batch: 460; loss: 1.89; acc: 0.44
Batch: 480; loss: 1.99; acc: 0.33
Batch: 500; loss: 1.92; acc: 0.42
Batch: 520; loss: 2.02; acc: 0.3
Batch: 540; loss: 1.86; acc: 0.5
Batch: 560; loss: 1.88; acc: 0.39
Batch: 580; loss: 1.95; acc: 0.36
Batch: 600; loss: 2.04; acc: 0.34
Batch: 620; loss: 1.89; acc: 0.39
Batch: 640; loss: 1.86; acc: 0.44
Batch: 660; loss: 2.01; acc: 0.22
Batch: 680; loss: 2.0; acc: 0.3
Batch: 700; loss: 1.92; acc: 0.31
Batch: 720; loss: 1.85; acc: 0.42
Batch: 740; loss: 2.1; acc: 0.27
Batch: 760; loss: 1.93; acc: 0.41
Batch: 780; loss: 1.97; acc: 0.31
Train Epoch over. train_loss: 1.96; train_accuracy: 0.36 

3.0675346351927146e-05
5.782952030131128e-06
Batch: 0; loss: 1.87; acc: 0.41
Batch: 20; loss: 2.07; acc: 0.33
Batch: 40; loss: 1.86; acc: 0.52
Batch: 60; loss: 1.83; acc: 0.44
Batch: 80; loss: 1.84; acc: 0.41
Batch: 100; loss: 1.97; acc: 0.41
Batch: 120; loss: 1.95; acc: 0.34
Batch: 140; loss: 1.92; acc: 0.39
Val Epoch over. val_loss: 1.9312193818912384; val_accuracy: 0.3883359872611465 

The current subspace-distance is: 5.782952030131128e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.95; acc: 0.41
Batch: 20; loss: 1.88; acc: 0.34
Batch: 40; loss: 1.94; acc: 0.44
Batch: 60; loss: 1.92; acc: 0.39
Batch: 80; loss: 2.06; acc: 0.28
Batch: 100; loss: 2.04; acc: 0.25
Batch: 120; loss: 1.95; acc: 0.27
Batch: 140; loss: 2.03; acc: 0.34
Batch: 160; loss: 1.93; acc: 0.41
Batch: 180; loss: 1.89; acc: 0.5
Batch: 200; loss: 2.0; acc: 0.36
Batch: 220; loss: 1.94; acc: 0.34
Batch: 240; loss: 1.98; acc: 0.33
Batch: 260; loss: 1.84; acc: 0.45
Batch: 280; loss: 1.96; acc: 0.34
Batch: 300; loss: 2.0; acc: 0.34
Batch: 320; loss: 1.98; acc: 0.34
Batch: 340; loss: 2.01; acc: 0.3
Batch: 360; loss: 1.96; acc: 0.41
Batch: 380; loss: 1.89; acc: 0.39
Batch: 400; loss: 1.92; acc: 0.38
Batch: 420; loss: 1.95; acc: 0.34
Batch: 440; loss: 1.87; acc: 0.56
Batch: 460; loss: 1.96; acc: 0.34
Batch: 480; loss: 1.92; acc: 0.44
Batch: 500; loss: 1.78; acc: 0.48
Batch: 520; loss: 1.94; acc: 0.38
Batch: 540; loss: 1.97; acc: 0.34
Batch: 560; loss: 1.86; acc: 0.48
Batch: 580; loss: 1.94; acc: 0.39
Batch: 600; loss: 2.03; acc: 0.31
Batch: 620; loss: 1.89; acc: 0.36
Batch: 640; loss: 2.05; acc: 0.31
Batch: 660; loss: 1.89; acc: 0.42
Batch: 680; loss: 1.95; acc: 0.42
Batch: 700; loss: 1.9; acc: 0.3
Batch: 720; loss: 2.0; acc: 0.33
Batch: 740; loss: 1.98; acc: 0.34
Batch: 760; loss: 2.01; acc: 0.31
Batch: 780; loss: 2.0; acc: 0.3
Train Epoch over. train_loss: 1.95; train_accuracy: 0.36 

2.988898086186964e-05
6.003579073876608e-06
Batch: 0; loss: 1.87; acc: 0.36
Batch: 20; loss: 2.06; acc: 0.31
Batch: 40; loss: 1.85; acc: 0.56
Batch: 60; loss: 1.85; acc: 0.45
Batch: 80; loss: 1.86; acc: 0.36
Batch: 100; loss: 1.97; acc: 0.39
Batch: 120; loss: 1.96; acc: 0.39
Batch: 140; loss: 1.96; acc: 0.36
Val Epoch over. val_loss: 1.9416866598615221; val_accuracy: 0.37420382165605093 

The current subspace-distance is: 6.003579073876608e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.98; acc: 0.34
Batch: 20; loss: 1.82; acc: 0.47
Batch: 40; loss: 1.91; acc: 0.44
Batch: 60; loss: 2.06; acc: 0.34
Batch: 80; loss: 1.98; acc: 0.36
Batch: 100; loss: 1.96; acc: 0.34
Batch: 120; loss: 1.9; acc: 0.41
Batch: 140; loss: 1.96; acc: 0.34
Batch: 160; loss: 1.81; acc: 0.47
Batch: 180; loss: 1.92; acc: 0.36
Batch: 200; loss: 2.0; acc: 0.28
Batch: 220; loss: 1.93; acc: 0.44
Batch: 240; loss: 1.9; acc: 0.38
Batch: 260; loss: 1.87; acc: 0.45
Batch: 280; loss: 2.05; acc: 0.31
Batch: 300; loss: 1.9; acc: 0.34
Batch: 320; loss: 2.03; acc: 0.34
Batch: 340; loss: 2.02; acc: 0.25
Batch: 360; loss: 2.02; acc: 0.3
Batch: 380; loss: 2.03; acc: 0.38
Batch: 400; loss: 2.03; acc: 0.38
Batch: 420; loss: 1.89; acc: 0.39
Batch: 440; loss: 1.97; acc: 0.36
Batch: 460; loss: 1.95; acc: 0.33
Batch: 480; loss: 2.0; acc: 0.31
Batch: 500; loss: 2.02; acc: 0.38
Batch: 520; loss: 1.94; acc: 0.41
Batch: 540; loss: 2.05; acc: 0.3
Batch: 560; loss: 1.89; acc: 0.41
Batch: 580; loss: 1.98; acc: 0.41
Batch: 600; loss: 1.97; acc: 0.39
Batch: 620; loss: 2.03; acc: 0.31
Batch: 640; loss: 2.02; acc: 0.28
Batch: 660; loss: 2.09; acc: 0.27
Batch: 680; loss: 1.91; acc: 0.42
Batch: 700; loss: 1.92; acc: 0.42
Batch: 720; loss: 2.05; acc: 0.3
Batch: 740; loss: 2.01; acc: 0.25
Batch: 760; loss: 1.89; acc: 0.41
Batch: 780; loss: 1.94; acc: 0.39
Train Epoch over. train_loss: 1.95; train_accuracy: 0.37 

3.056991408811882e-05
5.373161911848001e-06
Batch: 0; loss: 1.86; acc: 0.39
Batch: 20; loss: 2.05; acc: 0.34
Batch: 40; loss: 1.85; acc: 0.53
Batch: 60; loss: 1.84; acc: 0.45
Batch: 80; loss: 1.85; acc: 0.42
Batch: 100; loss: 1.97; acc: 0.34
Batch: 120; loss: 1.96; acc: 0.39
Batch: 140; loss: 1.92; acc: 0.39
Val Epoch over. val_loss: 1.9281126822635626; val_accuracy: 0.3818670382165605 

The current subspace-distance is: 5.373161911848001e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.03; acc: 0.25
Batch: 20; loss: 1.94; acc: 0.38
Batch: 40; loss: 2.1; acc: 0.25
Batch: 60; loss: 1.86; acc: 0.45
Batch: 80; loss: 2.1; acc: 0.33
Batch: 100; loss: 1.88; acc: 0.41
Batch: 120; loss: 1.92; acc: 0.41
Batch: 140; loss: 1.98; acc: 0.31
Batch: 160; loss: 1.94; acc: 0.31
Batch: 180; loss: 2.01; acc: 0.3
Batch: 200; loss: 2.06; acc: 0.31
Batch: 220; loss: 1.97; acc: 0.33
Batch: 240; loss: 2.0; acc: 0.25
Batch: 260; loss: 1.97; acc: 0.31
Batch: 280; loss: 2.01; acc: 0.39
Batch: 300; loss: 1.96; acc: 0.34
Batch: 320; loss: 1.87; acc: 0.41
Batch: 340; loss: 1.95; acc: 0.33
Batch: 360; loss: 1.99; acc: 0.36
Batch: 380; loss: 1.98; acc: 0.34
Batch: 400; loss: 1.96; acc: 0.38
Batch: 420; loss: 1.9; acc: 0.47
Batch: 440; loss: 2.03; acc: 0.36
Batch: 460; loss: 1.94; acc: 0.38
Batch: 480; loss: 1.87; acc: 0.38
Batch: 500; loss: 2.0; acc: 0.27
Batch: 520; loss: 1.95; acc: 0.33
Batch: 540; loss: 1.86; acc: 0.5
Batch: 560; loss: 1.92; acc: 0.41
Batch: 580; loss: 1.94; acc: 0.36
Batch: 600; loss: 1.89; acc: 0.41
Batch: 620; loss: 1.92; acc: 0.45
Batch: 640; loss: 2.01; acc: 0.34
Batch: 660; loss: 1.95; acc: 0.36
Batch: 680; loss: 1.93; acc: 0.34
Batch: 700; loss: 1.95; acc: 0.38
Batch: 720; loss: 1.95; acc: 0.34
Batch: 740; loss: 1.97; acc: 0.38
Batch: 760; loss: 2.01; acc: 0.3
Batch: 780; loss: 1.96; acc: 0.39
Train Epoch over. train_loss: 1.94; train_accuracy: 0.37 

3.085282151005231e-05
6.081837000238011e-06
Batch: 0; loss: 1.83; acc: 0.44
Batch: 20; loss: 2.11; acc: 0.23
Batch: 40; loss: 1.84; acc: 0.5
Batch: 60; loss: 1.84; acc: 0.42
Batch: 80; loss: 1.81; acc: 0.42
Batch: 100; loss: 1.94; acc: 0.39
Batch: 120; loss: 1.93; acc: 0.34
Batch: 140; loss: 1.86; acc: 0.45
Val Epoch over. val_loss: 1.9083153988905013; val_accuracy: 0.3896297770700637 

The current subspace-distance is: 6.081837000238011e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.88; acc: 0.44
Batch: 20; loss: 2.03; acc: 0.34
Batch: 40; loss: 1.95; acc: 0.39
Batch: 60; loss: 2.03; acc: 0.34
Batch: 80; loss: 2.06; acc: 0.25
Batch: 100; loss: 1.84; acc: 0.45
Batch: 120; loss: 1.89; acc: 0.34
Batch: 140; loss: 2.0; acc: 0.39
Batch: 160; loss: 1.98; acc: 0.25
Batch: 180; loss: 1.89; acc: 0.36
Batch: 200; loss: 1.93; acc: 0.33
Batch: 220; loss: 1.98; acc: 0.3
Batch: 240; loss: 1.76; acc: 0.45
Batch: 260; loss: 1.93; acc: 0.42
Batch: 280; loss: 1.97; acc: 0.42
Batch: 300; loss: 1.92; acc: 0.33
Batch: 320; loss: 1.91; acc: 0.36
Batch: 340; loss: 1.91; acc: 0.36
Batch: 360; loss: 1.78; acc: 0.47
Batch: 380; loss: 2.05; acc: 0.31
Batch: 400; loss: 1.91; acc: 0.36
Batch: 420; loss: 1.96; acc: 0.3
Batch: 440; loss: 1.87; acc: 0.45
Batch: 460; loss: 1.89; acc: 0.47
Batch: 480; loss: 1.91; acc: 0.38
Batch: 500; loss: 1.95; acc: 0.31
Batch: 520; loss: 2.0; acc: 0.27
Batch: 540; loss: 1.92; acc: 0.38
Batch: 560; loss: 1.88; acc: 0.53
Batch: 580; loss: 1.88; acc: 0.47
Batch: 600; loss: 2.03; acc: 0.34
Batch: 620; loss: 1.96; acc: 0.31
Batch: 640; loss: 1.85; acc: 0.42
Batch: 660; loss: 1.84; acc: 0.38
Batch: 680; loss: 1.96; acc: 0.3
Batch: 700; loss: 1.97; acc: 0.36
Batch: 720; loss: 1.91; acc: 0.44
Batch: 740; loss: 1.92; acc: 0.41
Batch: 760; loss: 1.92; acc: 0.42
Batch: 780; loss: 1.88; acc: 0.44
Train Epoch over. train_loss: 1.93; train_accuracy: 0.38 

3.160322376061231e-05
5.434116701508174e-06
Batch: 0; loss: 1.83; acc: 0.44
Batch: 20; loss: 2.13; acc: 0.2
Batch: 40; loss: 1.8; acc: 0.53
Batch: 60; loss: 1.83; acc: 0.44
Batch: 80; loss: 1.8; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.36
Batch: 120; loss: 1.91; acc: 0.33
Batch: 140; loss: 1.78; acc: 0.55
Val Epoch over. val_loss: 1.8927587065727087; val_accuracy: 0.3890326433121019 

The current subspace-distance is: 5.434116701508174e-06 

Epoch 11 start
The current lr is: 0.3
Batch: 0; loss: 1.88; acc: 0.42
Batch: 20; loss: 1.99; acc: 0.3
Batch: 40; loss: 1.82; acc: 0.41
Batch: 60; loss: 1.96; acc: 0.31
Batch: 80; loss: 1.96; acc: 0.33
Batch: 100; loss: 1.89; acc: 0.44
Batch: 120; loss: 1.83; acc: 0.36
Batch: 140; loss: 1.81; acc: 0.45
Batch: 160; loss: 1.96; acc: 0.33
Batch: 180; loss: 1.9; acc: 0.41
Batch: 200; loss: 2.04; acc: 0.25
Batch: 220; loss: 1.96; acc: 0.33
Batch: 240; loss: 1.85; acc: 0.36
Batch: 260; loss: 1.92; acc: 0.33
Batch: 280; loss: 1.96; acc: 0.41
Batch: 300; loss: 1.86; acc: 0.44
Batch: 320; loss: 1.88; acc: 0.36
Batch: 340; loss: 1.95; acc: 0.36
Batch: 360; loss: 1.95; acc: 0.38
Batch: 380; loss: 1.92; acc: 0.41
Batch: 400; loss: 1.94; acc: 0.3
Batch: 420; loss: 1.96; acc: 0.28
Batch: 440; loss: 1.89; acc: 0.38
Batch: 460; loss: 1.95; acc: 0.38
Batch: 480; loss: 1.85; acc: 0.45
Batch: 500; loss: 1.84; acc: 0.44
Batch: 520; loss: 1.99; acc: 0.27
Batch: 540; loss: 1.92; acc: 0.36
Batch: 560; loss: 1.89; acc: 0.41
Batch: 580; loss: 1.91; acc: 0.34
Batch: 600; loss: 1.95; acc: 0.39
Batch: 620; loss: 1.9; acc: 0.38
Batch: 640; loss: 1.93; acc: 0.34
Batch: 660; loss: 1.88; acc: 0.5
Batch: 680; loss: 1.84; acc: 0.42
Batch: 700; loss: 1.99; acc: 0.33
Batch: 720; loss: 1.88; acc: 0.38
Batch: 740; loss: 1.96; acc: 0.31
Batch: 760; loss: 1.86; acc: 0.41
Batch: 780; loss: 1.93; acc: 0.31
Train Epoch over. train_loss: 1.92; train_accuracy: 0.37 

3.101090987911448e-05
6.920159194123698e-06
Batch: 0; loss: 1.84; acc: 0.41
Batch: 20; loss: 2.1; acc: 0.33
Batch: 40; loss: 1.79; acc: 0.48
Batch: 60; loss: 1.82; acc: 0.47
Batch: 80; loss: 1.81; acc: 0.48
Batch: 100; loss: 1.91; acc: 0.33
Batch: 120; loss: 1.91; acc: 0.38
Batch: 140; loss: 1.78; acc: 0.58
Val Epoch over. val_loss: 1.8903103459412884; val_accuracy: 0.4023686305732484 

The current subspace-distance is: 6.920159194123698e-06 

Epoch 12 start
The current lr is: 0.3
Batch: 0; loss: 1.83; acc: 0.47
Batch: 20; loss: 1.97; acc: 0.28
Batch: 40; loss: 2.05; acc: 0.2
Batch: 60; loss: 1.82; acc: 0.45
Batch: 80; loss: 1.83; acc: 0.41
Batch: 100; loss: 2.0; acc: 0.31
Batch: 120; loss: 2.06; acc: 0.28
Batch: 140; loss: 1.89; acc: 0.34
Batch: 160; loss: 2.07; acc: 0.28
Batch: 180; loss: 1.96; acc: 0.33
Batch: 200; loss: 1.98; acc: 0.36
Batch: 220; loss: 1.84; acc: 0.5
Batch: 240; loss: 1.89; acc: 0.36
Batch: 260; loss: 1.88; acc: 0.34
Batch: 280; loss: 1.89; acc: 0.38
Batch: 300; loss: 1.82; acc: 0.53
Batch: 320; loss: 1.83; acc: 0.45
Batch: 340; loss: 1.97; acc: 0.33
Batch: 360; loss: 1.82; acc: 0.45
Batch: 380; loss: 1.93; acc: 0.45
Batch: 400; loss: 1.83; acc: 0.45
Batch: 420; loss: 2.0; acc: 0.33
Batch: 440; loss: 2.0; acc: 0.28
Batch: 460; loss: 1.93; acc: 0.33
Batch: 480; loss: 1.85; acc: 0.39
Batch: 500; loss: 1.87; acc: 0.44
Batch: 520; loss: 1.8; acc: 0.39
Batch: 540; loss: 1.88; acc: 0.41
Batch: 560; loss: 1.82; acc: 0.48
Batch: 580; loss: 2.08; acc: 0.28
Batch: 600; loss: 1.95; acc: 0.36
Batch: 620; loss: 1.85; acc: 0.39
Batch: 640; loss: 1.99; acc: 0.34
Batch: 660; loss: 1.93; acc: 0.38
Batch: 680; loss: 1.82; acc: 0.45
Batch: 700; loss: 1.83; acc: 0.45
Batch: 720; loss: 2.0; acc: 0.31
Batch: 740; loss: 1.89; acc: 0.36
Batch: 760; loss: 2.06; acc: 0.25
Batch: 780; loss: 2.12; acc: 0.27
Train Epoch over. train_loss: 1.91; train_accuracy: 0.38 

3.168144030496478e-05
7.909602572908625e-06
Batch: 0; loss: 1.82; acc: 0.5
Batch: 20; loss: 2.09; acc: 0.34
Batch: 40; loss: 1.76; acc: 0.58
Batch: 60; loss: 1.79; acc: 0.5
Batch: 80; loss: 1.8; acc: 0.47
Batch: 100; loss: 1.87; acc: 0.36
Batch: 120; loss: 1.89; acc: 0.45
Batch: 140; loss: 1.75; acc: 0.56
Val Epoch over. val_loss: 1.8752487115799241; val_accuracy: 0.4075437898089172 

The current subspace-distance is: 7.909602572908625e-06 

Epoch 13 start
The current lr is: 0.3
Batch: 0; loss: 1.92; acc: 0.31
Batch: 20; loss: 1.84; acc: 0.5
Batch: 40; loss: 1.88; acc: 0.44
Batch: 60; loss: 1.85; acc: 0.42
Batch: 80; loss: 1.83; acc: 0.38
Batch: 100; loss: 1.91; acc: 0.45
Batch: 120; loss: 1.91; acc: 0.39
Batch: 140; loss: 2.0; acc: 0.31
Batch: 160; loss: 1.93; acc: 0.39
Batch: 180; loss: 1.84; acc: 0.42
Batch: 200; loss: 1.93; acc: 0.36
Batch: 220; loss: 1.79; acc: 0.45
Batch: 240; loss: 1.91; acc: 0.47
Batch: 260; loss: 1.87; acc: 0.39
Batch: 280; loss: 1.95; acc: 0.38
Batch: 300; loss: 1.88; acc: 0.38
Batch: 320; loss: 1.98; acc: 0.27
Batch: 340; loss: 2.0; acc: 0.33
Batch: 360; loss: 1.79; acc: 0.48
Batch: 380; loss: 1.93; acc: 0.36
Batch: 400; loss: 1.93; acc: 0.34
Batch: 420; loss: 1.93; acc: 0.34
Batch: 440; loss: 1.87; acc: 0.36
Batch: 460; loss: 1.89; acc: 0.42
Batch: 480; loss: 1.88; acc: 0.39
Batch: 500; loss: 1.81; acc: 0.44
Batch: 520; loss: 1.84; acc: 0.56
Batch: 540; loss: 1.91; acc: 0.39
Batch: 560; loss: 1.81; acc: 0.52
Batch: 580; loss: 1.75; acc: 0.48
Batch: 600; loss: 1.79; acc: 0.55
Batch: 620; loss: 1.85; acc: 0.42
Batch: 640; loss: 1.99; acc: 0.25
Batch: 660; loss: 2.02; acc: 0.34
Batch: 680; loss: 1.94; acc: 0.38
Batch: 700; loss: 1.97; acc: 0.3
Batch: 720; loss: 1.84; acc: 0.38
Batch: 740; loss: 1.93; acc: 0.36
Batch: 760; loss: 1.86; acc: 0.45
Batch: 780; loss: 1.84; acc: 0.41
Train Epoch over. train_loss: 1.9; train_accuracy: 0.38 

3.226747867302038e-05
6.36969070910709e-06
Batch: 0; loss: 1.81; acc: 0.44
Batch: 20; loss: 2.05; acc: 0.27
Batch: 40; loss: 1.73; acc: 0.59
Batch: 60; loss: 1.8; acc: 0.47
Batch: 80; loss: 1.75; acc: 0.48
Batch: 100; loss: 1.82; acc: 0.39
Batch: 120; loss: 1.9; acc: 0.45
Batch: 140; loss: 1.76; acc: 0.58
Val Epoch over. val_loss: 1.8647659758853306; val_accuracy: 0.4029657643312102 

The current subspace-distance is: 6.36969070910709e-06 

Epoch 14 start
The current lr is: 0.3
Batch: 0; loss: 1.86; acc: 0.31
Batch: 20; loss: 1.89; acc: 0.38
Batch: 40; loss: 1.88; acc: 0.38
Batch: 60; loss: 1.9; acc: 0.38
Batch: 80; loss: 1.87; acc: 0.47
Batch: 100; loss: 1.97; acc: 0.33
Batch: 120; loss: 1.88; acc: 0.38
Batch: 140; loss: 1.84; acc: 0.42
Batch: 160; loss: 1.84; acc: 0.45
Batch: 180; loss: 1.81; acc: 0.47
Batch: 200; loss: 1.96; acc: 0.31
Batch: 220; loss: 1.94; acc: 0.39
Batch: 240; loss: 1.91; acc: 0.39
Batch: 260; loss: 1.99; acc: 0.25
Batch: 280; loss: 1.99; acc: 0.31
Batch: 300; loss: 1.78; acc: 0.55
Batch: 320; loss: 1.79; acc: 0.41
Batch: 340; loss: 1.89; acc: 0.36
Batch: 360; loss: 1.9; acc: 0.36
Batch: 380; loss: 2.01; acc: 0.31
Batch: 400; loss: 1.91; acc: 0.36
Batch: 420; loss: 1.82; acc: 0.47
Batch: 440; loss: 1.88; acc: 0.44
Batch: 460; loss: 1.79; acc: 0.42
Batch: 480; loss: 1.84; acc: 0.36
Batch: 500; loss: 1.97; acc: 0.39
Batch: 520; loss: 1.85; acc: 0.38
Batch: 540; loss: 1.99; acc: 0.23
Batch: 560; loss: 1.91; acc: 0.31
Batch: 580; loss: 1.96; acc: 0.34
Batch: 600; loss: 1.9; acc: 0.33
Batch: 620; loss: 1.98; acc: 0.45
Batch: 640; loss: 2.06; acc: 0.33
Batch: 660; loss: 1.9; acc: 0.34
Batch: 680; loss: 1.82; acc: 0.45
Batch: 700; loss: 1.9; acc: 0.34
Batch: 720; loss: 2.0; acc: 0.2
Batch: 740; loss: 1.92; acc: 0.38
Batch: 760; loss: 1.86; acc: 0.44
Batch: 780; loss: 1.78; acc: 0.47
Train Epoch over. train_loss: 1.9; train_accuracy: 0.38 

3.2589399779681116e-05
6.91802597430069e-06
Batch: 0; loss: 1.78; acc: 0.47
Batch: 20; loss: 2.07; acc: 0.3
Batch: 40; loss: 1.72; acc: 0.61
Batch: 60; loss: 1.79; acc: 0.48
Batch: 80; loss: 1.75; acc: 0.45
Batch: 100; loss: 1.79; acc: 0.48
Batch: 120; loss: 1.89; acc: 0.42
Batch: 140; loss: 1.74; acc: 0.56
Val Epoch over. val_loss: 1.8571208419313856; val_accuracy: 0.4104299363057325 

The current subspace-distance is: 6.91802597430069e-06 

Epoch 15 start
The current lr is: 0.3
Batch: 0; loss: 1.87; acc: 0.41
Batch: 20; loss: 1.85; acc: 0.47
Batch: 40; loss: 1.92; acc: 0.39
Batch: 60; loss: 1.94; acc: 0.34
Batch: 80; loss: 1.89; acc: 0.41
Batch: 100; loss: 1.96; acc: 0.31
Batch: 120; loss: 2.02; acc: 0.33
Batch: 140; loss: 1.92; acc: 0.39
Batch: 160; loss: 1.83; acc: 0.44
Batch: 180; loss: 1.9; acc: 0.41
Batch: 200; loss: 1.96; acc: 0.36
Batch: 220; loss: 2.01; acc: 0.34
Batch: 240; loss: 1.94; acc: 0.33
Batch: 260; loss: 1.81; acc: 0.47
Batch: 280; loss: 2.11; acc: 0.25
Batch: 300; loss: 1.91; acc: 0.34
Batch: 320; loss: 1.86; acc: 0.45
Batch: 340; loss: 1.92; acc: 0.34
Batch: 360; loss: 1.85; acc: 0.41
Batch: 380; loss: 1.88; acc: 0.39
Batch: 400; loss: 1.85; acc: 0.36
Batch: 420; loss: 1.91; acc: 0.34
Batch: 440; loss: 1.86; acc: 0.42
Batch: 460; loss: 1.88; acc: 0.39
Batch: 480; loss: 1.8; acc: 0.45
Batch: 500; loss: 1.76; acc: 0.48
Batch: 520; loss: 1.97; acc: 0.31
Batch: 540; loss: 1.82; acc: 0.47
Batch: 560; loss: 1.84; acc: 0.41
Batch: 580; loss: 1.71; acc: 0.59
Batch: 600; loss: 1.87; acc: 0.41
Batch: 620; loss: 1.99; acc: 0.41
Batch: 640; loss: 1.93; acc: 0.34
Batch: 660; loss: 1.88; acc: 0.33
Batch: 680; loss: 2.02; acc: 0.3
Batch: 700; loss: 1.99; acc: 0.38
Batch: 720; loss: 1.92; acc: 0.34
Batch: 740; loss: 1.82; acc: 0.39
Batch: 760; loss: 1.92; acc: 0.31
Batch: 780; loss: 1.89; acc: 0.38
Train Epoch over. train_loss: 1.89; train_accuracy: 0.38 

3.248933717259206e-05
7.393288797175046e-06
Batch: 0; loss: 1.8; acc: 0.39
Batch: 20; loss: 2.06; acc: 0.3
Batch: 40; loss: 1.73; acc: 0.58
Batch: 60; loss: 1.8; acc: 0.45
Batch: 80; loss: 1.76; acc: 0.48
Batch: 100; loss: 1.8; acc: 0.47
Batch: 120; loss: 1.9; acc: 0.42
Batch: 140; loss: 1.76; acc: 0.55
Val Epoch over. val_loss: 1.8643208400459046; val_accuracy: 0.40216958598726116 

The current subspace-distance is: 7.393288797175046e-06 

Epoch 16 start
The current lr is: 0.3
Batch: 0; loss: 1.77; acc: 0.44
Batch: 20; loss: 1.89; acc: 0.39
Batch: 40; loss: 1.93; acc: 0.39
Batch: 60; loss: 1.88; acc: 0.34
Batch: 80; loss: 1.84; acc: 0.45
Batch: 100; loss: 1.77; acc: 0.42
Batch: 120; loss: 1.93; acc: 0.38
Batch: 140; loss: 1.84; acc: 0.44
Batch: 160; loss: 1.88; acc: 0.45
Batch: 180; loss: 1.85; acc: 0.44
Batch: 200; loss: 1.77; acc: 0.42
Batch: 220; loss: 1.89; acc: 0.38
Batch: 240; loss: 1.98; acc: 0.31
Batch: 260; loss: 1.9; acc: 0.39
Batch: 280; loss: 1.87; acc: 0.34
Batch: 300; loss: 1.84; acc: 0.39
Batch: 320; loss: 1.87; acc: 0.42
Batch: 340; loss: 1.95; acc: 0.3
Batch: 360; loss: 2.0; acc: 0.33
Batch: 380; loss: 1.87; acc: 0.41
Batch: 400; loss: 1.8; acc: 0.45
Batch: 420; loss: 1.93; acc: 0.47
Batch: 440; loss: 1.91; acc: 0.34
Batch: 460; loss: 2.06; acc: 0.28
Batch: 480; loss: 1.88; acc: 0.31
Batch: 500; loss: 1.79; acc: 0.48
Batch: 520; loss: 1.82; acc: 0.39
Batch: 540; loss: 1.95; acc: 0.36
Batch: 560; loss: 1.86; acc: 0.39
Batch: 580; loss: 1.84; acc: 0.42
Batch: 600; loss: 1.93; acc: 0.44
Batch: 620; loss: 1.98; acc: 0.41
Batch: 640; loss: 1.85; acc: 0.41
Batch: 660; loss: 1.92; acc: 0.39
Batch: 680; loss: 1.86; acc: 0.39
Batch: 700; loss: 1.93; acc: 0.27
Batch: 720; loss: 1.93; acc: 0.39
Batch: 740; loss: 1.81; acc: 0.44
Batch: 760; loss: 1.93; acc: 0.36
Batch: 780; loss: 2.02; acc: 0.34
Train Epoch over. train_loss: 1.89; train_accuracy: 0.38 

3.296429349575192e-05
7.5950747486785986e-06
Batch: 0; loss: 1.8; acc: 0.42
Batch: 20; loss: 2.05; acc: 0.3
Batch: 40; loss: 1.71; acc: 0.52
Batch: 60; loss: 1.78; acc: 0.48
Batch: 80; loss: 1.75; acc: 0.44
Batch: 100; loss: 1.79; acc: 0.42
Batch: 120; loss: 1.88; acc: 0.42
Batch: 140; loss: 1.74; acc: 0.56
Val Epoch over. val_loss: 1.8533984559356786; val_accuracy: 0.41033041401273884 

The current subspace-distance is: 7.5950747486785986e-06 

Epoch 17 start
The current lr is: 0.3
Batch: 0; loss: 1.93; acc: 0.33
Batch: 20; loss: 1.86; acc: 0.5
Batch: 40; loss: 2.0; acc: 0.22
Batch: 60; loss: 2.0; acc: 0.34
Batch: 80; loss: 1.81; acc: 0.39
Batch: 100; loss: 1.86; acc: 0.38
Batch: 120; loss: 1.82; acc: 0.48
Batch: 140; loss: 1.87; acc: 0.39
Batch: 160; loss: 1.87; acc: 0.42
Batch: 180; loss: 1.82; acc: 0.48
Batch: 200; loss: 1.88; acc: 0.44
Batch: 220; loss: 1.83; acc: 0.47
Batch: 240; loss: 1.84; acc: 0.44
Batch: 260; loss: 1.83; acc: 0.38
Batch: 280; loss: 1.87; acc: 0.27
Batch: 300; loss: 1.86; acc: 0.39
Batch: 320; loss: 1.86; acc: 0.41
Batch: 340; loss: 1.95; acc: 0.33
Batch: 360; loss: 2.01; acc: 0.27
Batch: 380; loss: 1.86; acc: 0.41
Batch: 400; loss: 1.9; acc: 0.38
Batch: 420; loss: 1.99; acc: 0.23
Batch: 440; loss: 1.84; acc: 0.42
Batch: 460; loss: 1.8; acc: 0.48
Batch: 480; loss: 1.93; acc: 0.3
Batch: 500; loss: 1.88; acc: 0.45
Batch: 520; loss: 1.85; acc: 0.48
Batch: 540; loss: 1.91; acc: 0.34
Batch: 560; loss: 1.87; acc: 0.41
Batch: 580; loss: 1.94; acc: 0.33
Batch: 600; loss: 1.81; acc: 0.41
Batch: 620; loss: 1.86; acc: 0.38
Batch: 640; loss: 1.82; acc: 0.47
Batch: 660; loss: 2.0; acc: 0.28
Batch: 680; loss: 1.87; acc: 0.5
Batch: 700; loss: 1.86; acc: 0.41
Batch: 720; loss: 1.88; acc: 0.31
Batch: 740; loss: 1.78; acc: 0.48
Batch: 760; loss: 1.76; acc: 0.48
Batch: 780; loss: 1.84; acc: 0.34
Train Epoch over. train_loss: 1.88; train_accuracy: 0.38 

3.310960528324358e-05
8.833725587464869e-06
Batch: 0; loss: 1.81; acc: 0.41
Batch: 20; loss: 2.05; acc: 0.33
Batch: 40; loss: 1.72; acc: 0.48
Batch: 60; loss: 1.78; acc: 0.47
Batch: 80; loss: 1.75; acc: 0.47
Batch: 100; loss: 1.8; acc: 0.42
Batch: 120; loss: 1.88; acc: 0.44
Batch: 140; loss: 1.75; acc: 0.52
Val Epoch over. val_loss: 1.8548244761813217; val_accuracy: 0.4055533439490446 

The current subspace-distance is: 8.833725587464869e-06 

Epoch 18 start
The current lr is: 0.3
Batch: 0; loss: 1.85; acc: 0.36
Batch: 20; loss: 1.99; acc: 0.34
Batch: 40; loss: 1.83; acc: 0.36
Batch: 60; loss: 1.83; acc: 0.47
Batch: 80; loss: 1.89; acc: 0.33
Batch: 100; loss: 1.87; acc: 0.41
Batch: 120; loss: 1.93; acc: 0.3
Batch: 140; loss: 1.9; acc: 0.33
Batch: 160; loss: 1.81; acc: 0.48
Batch: 180; loss: 1.91; acc: 0.41
Batch: 200; loss: 1.93; acc: 0.42
Batch: 220; loss: 1.94; acc: 0.34
Batch: 240; loss: 1.89; acc: 0.34
Batch: 260; loss: 1.84; acc: 0.41
Batch: 280; loss: 1.95; acc: 0.27
Batch: 300; loss: 1.79; acc: 0.45
Batch: 320; loss: 1.87; acc: 0.38
Batch: 340; loss: 1.85; acc: 0.39
Batch: 360; loss: 1.97; acc: 0.3
Batch: 380; loss: 1.9; acc: 0.36
Batch: 400; loss: 1.85; acc: 0.45
Batch: 420; loss: 1.98; acc: 0.3
Batch: 440; loss: 1.82; acc: 0.5
Batch: 460; loss: 1.98; acc: 0.31
Batch: 480; loss: 1.87; acc: 0.34
Batch: 500; loss: 1.74; acc: 0.45
Batch: 520; loss: 2.04; acc: 0.28
Batch: 540; loss: 1.85; acc: 0.34
Batch: 560; loss: 1.92; acc: 0.36
Batch: 580; loss: 1.94; acc: 0.33
Batch: 600; loss: 1.83; acc: 0.36
Batch: 620; loss: 1.84; acc: 0.41
Batch: 640; loss: 1.77; acc: 0.55
Batch: 660; loss: 1.85; acc: 0.44
Batch: 680; loss: 1.85; acc: 0.39
Batch: 700; loss: 1.8; acc: 0.53
Batch: 720; loss: 1.9; acc: 0.44
Batch: 740; loss: 1.88; acc: 0.36
Batch: 760; loss: 1.85; acc: 0.41
Batch: 780; loss: 1.94; acc: 0.41
Train Epoch over. train_loss: 1.88; train_accuracy: 0.38 

3.261332312831655e-05
7.879370969021693e-06
Batch: 0; loss: 1.82; acc: 0.41
Batch: 20; loss: 2.05; acc: 0.3
Batch: 40; loss: 1.72; acc: 0.48
Batch: 60; loss: 1.78; acc: 0.45
Batch: 80; loss: 1.74; acc: 0.48
Batch: 100; loss: 1.8; acc: 0.41
Batch: 120; loss: 1.87; acc: 0.47
Batch: 140; loss: 1.76; acc: 0.52
Val Epoch over. val_loss: 1.8472696633855248; val_accuracy: 0.40545382165605093 

The current subspace-distance is: 7.879370969021693e-06 

Epoch 19 start
The current lr is: 0.3
Batch: 0; loss: 1.84; acc: 0.36
Batch: 20; loss: 1.95; acc: 0.33
Batch: 40; loss: 1.88; acc: 0.41
Batch: 60; loss: 1.86; acc: 0.45
Batch: 80; loss: 1.94; acc: 0.33
Batch: 100; loss: 2.02; acc: 0.27
Batch: 120; loss: 1.88; acc: 0.31
Batch: 140; loss: 1.91; acc: 0.38
Batch: 160; loss: 1.94; acc: 0.38
Batch: 180; loss: 1.99; acc: 0.39
Batch: 200; loss: 1.89; acc: 0.31
Batch: 220; loss: 1.82; acc: 0.36
Batch: 240; loss: 1.98; acc: 0.3
Batch: 260; loss: 1.92; acc: 0.34
Batch: 280; loss: 1.92; acc: 0.39
Batch: 300; loss: 1.89; acc: 0.38
Batch: 320; loss: 1.83; acc: 0.45
Batch: 340; loss: 1.9; acc: 0.36
Batch: 360; loss: 1.86; acc: 0.44
Batch: 380; loss: 1.78; acc: 0.45
Batch: 400; loss: 1.82; acc: 0.41
Batch: 420; loss: 1.95; acc: 0.3
Batch: 440; loss: 1.88; acc: 0.36
Batch: 460; loss: 1.8; acc: 0.39
Batch: 480; loss: 1.93; acc: 0.36
Batch: 500; loss: 1.75; acc: 0.52
Batch: 520; loss: 1.95; acc: 0.31
Batch: 540; loss: 1.78; acc: 0.5
Batch: 560; loss: 1.84; acc: 0.45
Batch: 580; loss: 1.78; acc: 0.44
Batch: 600; loss: 1.87; acc: 0.41
Batch: 620; loss: 1.78; acc: 0.45
Batch: 640; loss: 1.9; acc: 0.45
Batch: 660; loss: 1.88; acc: 0.38
Batch: 680; loss: 1.82; acc: 0.42
Batch: 700; loss: 1.86; acc: 0.38
Batch: 720; loss: 1.92; acc: 0.31
Batch: 740; loss: 1.91; acc: 0.34
Batch: 760; loss: 1.9; acc: 0.34
Batch: 780; loss: 1.91; acc: 0.33
Train Epoch over. train_loss: 1.88; train_accuracy: 0.38 

3.343931894050911e-05
8.866227290127426e-06
Batch: 0; loss: 1.81; acc: 0.36
Batch: 20; loss: 2.05; acc: 0.31
Batch: 40; loss: 1.71; acc: 0.52
Batch: 60; loss: 1.78; acc: 0.42
Batch: 80; loss: 1.74; acc: 0.5
Batch: 100; loss: 1.79; acc: 0.39
Batch: 120; loss: 1.87; acc: 0.42
Batch: 140; loss: 1.76; acc: 0.48
Val Epoch over. val_loss: 1.8463460108277145; val_accuracy: 0.4124203821656051 

The current subspace-distance is: 8.866227290127426e-06 

Epoch 20 start
The current lr is: 0.3
Batch: 0; loss: 1.86; acc: 0.42
Batch: 20; loss: 1.78; acc: 0.44
Batch: 40; loss: 1.95; acc: 0.3
Batch: 60; loss: 1.87; acc: 0.34
Batch: 80; loss: 1.91; acc: 0.27
Batch: 100; loss: 2.06; acc: 0.25
Batch: 120; loss: 1.84; acc: 0.38
Batch: 140; loss: 1.93; acc: 0.34
Batch: 160; loss: 1.95; acc: 0.31
Batch: 180; loss: 1.89; acc: 0.31
Batch: 200; loss: 1.98; acc: 0.3
Batch: 220; loss: 1.83; acc: 0.48
Batch: 240; loss: 1.95; acc: 0.33
Batch: 260; loss: 1.86; acc: 0.44
Batch: 280; loss: 1.93; acc: 0.33
Batch: 300; loss: 1.91; acc: 0.33
Batch: 320; loss: 1.97; acc: 0.34
Batch: 340; loss: 1.81; acc: 0.44
Batch: 360; loss: 1.7; acc: 0.48
Batch: 380; loss: 1.81; acc: 0.41
Batch: 400; loss: 1.94; acc: 0.34
Batch: 420; loss: 1.79; acc: 0.44
Batch: 440; loss: 1.95; acc: 0.3
Batch: 460; loss: 1.93; acc: 0.44
Batch: 480; loss: 1.88; acc: 0.39
Batch: 500; loss: 1.9; acc: 0.33
Batch: 520; loss: 1.78; acc: 0.41
Batch: 540; loss: 1.81; acc: 0.42
Batch: 560; loss: 1.92; acc: 0.42
Batch: 580; loss: 1.95; acc: 0.39
Batch: 600; loss: 1.84; acc: 0.38
Batch: 620; loss: 1.89; acc: 0.41
Batch: 640; loss: 1.86; acc: 0.44
Batch: 660; loss: 1.81; acc: 0.39
Batch: 680; loss: 1.77; acc: 0.41
Batch: 700; loss: 1.85; acc: 0.38
Batch: 720; loss: 1.99; acc: 0.3
Batch: 740; loss: 1.83; acc: 0.45
Batch: 760; loss: 1.87; acc: 0.34
Batch: 780; loss: 1.8; acc: 0.42
Train Epoch over. train_loss: 1.88; train_accuracy: 0.39 

3.4549975680420175e-05
7.953231033752672e-06
Batch: 0; loss: 1.79; acc: 0.34
Batch: 20; loss: 2.04; acc: 0.27
Batch: 40; loss: 1.7; acc: 0.48
Batch: 60; loss: 1.76; acc: 0.44
Batch: 80; loss: 1.73; acc: 0.47
Batch: 100; loss: 1.76; acc: 0.44
Batch: 120; loss: 1.85; acc: 0.45
Batch: 140; loss: 1.75; acc: 0.48
Val Epoch over. val_loss: 1.8301791339922862; val_accuracy: 0.41023089171974525 

The current subspace-distance is: 7.953231033752672e-06 

Epoch 21 start
The current lr is: 0.09
Batch: 0; loss: 1.79; acc: 0.45
Batch: 20; loss: 1.88; acc: 0.47
Batch: 40; loss: 1.97; acc: 0.31
Batch: 60; loss: 1.91; acc: 0.44
Batch: 80; loss: 1.79; acc: 0.44
Batch: 100; loss: 1.81; acc: 0.38
Batch: 120; loss: 1.89; acc: 0.33
Batch: 140; loss: 2.1; acc: 0.33
Batch: 160; loss: 1.93; acc: 0.28
Batch: 180; loss: 1.92; acc: 0.3
Batch: 200; loss: 1.92; acc: 0.34
Batch: 220; loss: 1.95; acc: 0.39
Batch: 240; loss: 1.8; acc: 0.38
Batch: 260; loss: 1.86; acc: 0.33
Batch: 280; loss: 1.91; acc: 0.3
Batch: 300; loss: 1.86; acc: 0.39
Batch: 320; loss: 1.76; acc: 0.52
Batch: 340; loss: 1.8; acc: 0.42
Batch: 360; loss: 1.82; acc: 0.39
Batch: 380; loss: 1.87; acc: 0.44
Batch: 400; loss: 1.87; acc: 0.33
Batch: 420; loss: 1.83; acc: 0.34
Batch: 440; loss: 1.94; acc: 0.33
Batch: 460; loss: 1.91; acc: 0.38
Batch: 480; loss: 1.79; acc: 0.5
Batch: 500; loss: 1.79; acc: 0.42
Batch: 520; loss: 1.83; acc: 0.44
Batch: 540; loss: 1.9; acc: 0.39
Batch: 560; loss: 1.87; acc: 0.34
Batch: 580; loss: 2.09; acc: 0.27
Batch: 600; loss: 1.95; acc: 0.34
Batch: 620; loss: 1.84; acc: 0.38
Batch: 640; loss: 1.84; acc: 0.5
Batch: 660; loss: 1.96; acc: 0.31
Batch: 680; loss: 1.82; acc: 0.39
Batch: 700; loss: 1.91; acc: 0.42
Batch: 720; loss: 1.77; acc: 0.47
Batch: 740; loss: 1.8; acc: 0.39
Batch: 760; loss: 1.79; acc: 0.41
Batch: 780; loss: 1.83; acc: 0.38
Train Epoch over. train_loss: 1.87; train_accuracy: 0.39 

3.356362140038982e-05
9.148595381702762e-06
Batch: 0; loss: 1.8; acc: 0.34
Batch: 20; loss: 2.05; acc: 0.3
Batch: 40; loss: 1.71; acc: 0.53
Batch: 60; loss: 1.78; acc: 0.44
Batch: 80; loss: 1.72; acc: 0.52
Batch: 100; loss: 1.77; acc: 0.48
Batch: 120; loss: 1.86; acc: 0.48
Batch: 140; loss: 1.77; acc: 0.5
Val Epoch over. val_loss: 1.8350079742966183; val_accuracy: 0.42326831210191085 

The current subspace-distance is: 9.148595381702762e-06 

Epoch 22 start
The current lr is: 0.09
Batch: 0; loss: 1.85; acc: 0.39
Batch: 20; loss: 1.79; acc: 0.5
Batch: 40; loss: 1.81; acc: 0.45
Batch: 60; loss: 1.88; acc: 0.41
Batch: 80; loss: 1.91; acc: 0.33
Batch: 100; loss: 1.86; acc: 0.44
Batch: 120; loss: 1.82; acc: 0.48
Batch: 140; loss: 1.7; acc: 0.5
Batch: 160; loss: 1.71; acc: 0.52
Batch: 180; loss: 1.79; acc: 0.41
Batch: 200; loss: 1.8; acc: 0.45
Batch: 220; loss: 1.93; acc: 0.31
Batch: 240; loss: 1.79; acc: 0.44
Batch: 260; loss: 1.84; acc: 0.36
Batch: 280; loss: 2.12; acc: 0.19
Batch: 300; loss: 1.84; acc: 0.41
Batch: 320; loss: 1.85; acc: 0.44
Batch: 340; loss: 1.93; acc: 0.38
Batch: 360; loss: 1.9; acc: 0.44
Batch: 380; loss: 1.79; acc: 0.5
Batch: 400; loss: 1.79; acc: 0.41
Batch: 420; loss: 1.85; acc: 0.34
Batch: 440; loss: 2.06; acc: 0.3
Batch: 460; loss: 1.93; acc: 0.33
Batch: 480; loss: 1.81; acc: 0.44
Batch: 500; loss: 1.76; acc: 0.52
Batch: 520; loss: 1.92; acc: 0.3
Batch: 540; loss: 1.88; acc: 0.38
Batch: 560; loss: 1.88; acc: 0.31
Batch: 580; loss: 1.95; acc: 0.27
Batch: 600; loss: 1.7; acc: 0.48
Batch: 620; loss: 1.86; acc: 0.38
Batch: 640; loss: 1.8; acc: 0.47
Batch: 660; loss: 1.83; acc: 0.41
Batch: 680; loss: 1.95; acc: 0.3
Batch: 700; loss: 1.86; acc: 0.38
Batch: 720; loss: 1.79; acc: 0.45
Batch: 740; loss: 1.75; acc: 0.45
Batch: 760; loss: 1.98; acc: 0.33
Batch: 780; loss: 1.83; acc: 0.45
Train Epoch over. train_loss: 1.87; train_accuracy: 0.39 

3.337920134072192e-05
8.733850336284377e-06
Batch: 0; loss: 1.79; acc: 0.39
Batch: 20; loss: 2.05; acc: 0.3
Batch: 40; loss: 1.7; acc: 0.52
Batch: 60; loss: 1.76; acc: 0.42
Batch: 80; loss: 1.73; acc: 0.5
Batch: 100; loss: 1.76; acc: 0.48
Batch: 120; loss: 1.84; acc: 0.45
Batch: 140; loss: 1.76; acc: 0.58
Val Epoch over. val_loss: 1.8305484010915087; val_accuracy: 0.42356687898089174 

The current subspace-distance is: 8.733850336284377e-06 

Epoch 23 start
The current lr is: 0.09
Batch: 0; loss: 1.88; acc: 0.27
Batch: 20; loss: 1.76; acc: 0.47
Batch: 40; loss: 1.92; acc: 0.38
Batch: 60; loss: 1.87; acc: 0.33
Batch: 80; loss: 1.94; acc: 0.36
Batch: 100; loss: 1.82; acc: 0.47
Batch: 120; loss: 1.77; acc: 0.38
Batch: 140; loss: 1.9; acc: 0.38
Batch: 160; loss: 1.94; acc: 0.31
Batch: 180; loss: 1.83; acc: 0.45
Batch: 200; loss: 1.87; acc: 0.36
Batch: 220; loss: 1.86; acc: 0.48
Batch: 240; loss: 1.88; acc: 0.33
Batch: 260; loss: 1.91; acc: 0.36
Batch: 280; loss: 1.91; acc: 0.39
Batch: 300; loss: 1.84; acc: 0.47
Batch: 320; loss: 1.87; acc: 0.38
Batch: 340; loss: 1.96; acc: 0.31
Batch: 360; loss: 1.88; acc: 0.36
Batch: 380; loss: 2.02; acc: 0.31
Batch: 400; loss: 1.97; acc: 0.34
Batch: 420; loss: 1.92; acc: 0.34
Batch: 440; loss: 1.83; acc: 0.41
Batch: 460; loss: 1.88; acc: 0.39
Batch: 480; loss: 1.89; acc: 0.36
Batch: 500; loss: 1.85; acc: 0.41
Batch: 520; loss: 1.87; acc: 0.38
Batch: 540; loss: 2.0; acc: 0.28
Batch: 560; loss: 1.94; acc: 0.27
Batch: 580; loss: 1.93; acc: 0.3
Batch: 600; loss: 1.85; acc: 0.42
Batch: 620; loss: 2.09; acc: 0.25
Batch: 640; loss: 1.85; acc: 0.39
Batch: 660; loss: 1.94; acc: 0.31
Batch: 680; loss: 1.94; acc: 0.31
Batch: 700; loss: 1.8; acc: 0.42
Batch: 720; loss: 2.04; acc: 0.25
Batch: 740; loss: 1.94; acc: 0.42
Batch: 760; loss: 2.04; acc: 0.3
Batch: 780; loss: 1.87; acc: 0.38
Train Epoch over. train_loss: 1.87; train_accuracy: 0.39 

3.353899228386581e-05
8.147731023200322e-06
Batch: 0; loss: 1.8; acc: 0.39
Batch: 20; loss: 2.06; acc: 0.31
Batch: 40; loss: 1.71; acc: 0.52
Batch: 60; loss: 1.78; acc: 0.42
Batch: 80; loss: 1.73; acc: 0.48
Batch: 100; loss: 1.78; acc: 0.47
Batch: 120; loss: 1.85; acc: 0.47
Batch: 140; loss: 1.78; acc: 0.5
Val Epoch over. val_loss: 1.838224937202065; val_accuracy: 0.4252587579617834 

The current subspace-distance is: 8.147731023200322e-06 

Epoch 24 start
The current lr is: 0.09
Batch: 0; loss: 1.93; acc: 0.31
Batch: 20; loss: 1.85; acc: 0.34
Batch: 40; loss: 1.96; acc: 0.25
Batch: 60; loss: 1.85; acc: 0.36
Batch: 80; loss: 1.87; acc: 0.39
Batch: 100; loss: 1.87; acc: 0.36
Batch: 120; loss: 1.84; acc: 0.44
Batch: 140; loss: 1.81; acc: 0.41
Batch: 160; loss: 1.84; acc: 0.44
Batch: 180; loss: 1.91; acc: 0.34
Batch: 200; loss: 1.93; acc: 0.34
Batch: 220; loss: 1.9; acc: 0.36
Batch: 240; loss: 1.86; acc: 0.44
Batch: 260; loss: 1.84; acc: 0.41
Batch: 280; loss: 1.81; acc: 0.5
Batch: 300; loss: 2.0; acc: 0.23
Batch: 320; loss: 1.82; acc: 0.44
Batch: 340; loss: 1.98; acc: 0.39
Batch: 360; loss: 1.81; acc: 0.39
Batch: 380; loss: 2.0; acc: 0.33
Batch: 400; loss: 1.99; acc: 0.34
Batch: 420; loss: 1.81; acc: 0.45
Batch: 440; loss: 1.88; acc: 0.47
Batch: 460; loss: 2.02; acc: 0.31
Batch: 480; loss: 1.75; acc: 0.45
Batch: 500; loss: 1.85; acc: 0.38
Batch: 520; loss: 1.9; acc: 0.36
Batch: 540; loss: 1.8; acc: 0.52
Batch: 560; loss: 1.87; acc: 0.27
Batch: 580; loss: 1.87; acc: 0.38
Batch: 600; loss: 1.98; acc: 0.38
Batch: 620; loss: 1.82; acc: 0.34
Batch: 640; loss: 1.81; acc: 0.48
Batch: 660; loss: 1.92; acc: 0.39
Batch: 680; loss: 1.98; acc: 0.3
Batch: 700; loss: 1.95; acc: 0.3
Batch: 720; loss: 1.82; acc: 0.38
Batch: 740; loss: 1.85; acc: 0.38
Batch: 760; loss: 2.01; acc: 0.28
Batch: 780; loss: 1.84; acc: 0.41
Train Epoch over. train_loss: 1.87; train_accuracy: 0.39 

3.335010842420161e-05
7.489094969059806e-06
Batch: 0; loss: 1.79; acc: 0.42
Batch: 20; loss: 2.05; acc: 0.31
Batch: 40; loss: 1.69; acc: 0.5
Batch: 60; loss: 1.77; acc: 0.41
Batch: 80; loss: 1.71; acc: 0.48
Batch: 100; loss: 1.76; acc: 0.47
Batch: 120; loss: 1.84; acc: 0.47
Batch: 140; loss: 1.76; acc: 0.52
Val Epoch over. val_loss: 1.823197444533087; val_accuracy: 0.42615445859872614 

The current subspace-distance is: 7.489094969059806e-06 

Epoch 25 start
The current lr is: 0.09
Batch: 0; loss: 1.83; acc: 0.41
Batch: 20; loss: 1.94; acc: 0.39
Batch: 40; loss: 1.87; acc: 0.44
Batch: 60; loss: 1.94; acc: 0.34
Batch: 80; loss: 1.76; acc: 0.52
Batch: 100; loss: 1.81; acc: 0.47
Batch: 120; loss: 1.86; acc: 0.39
Batch: 140; loss: 1.83; acc: 0.41
Batch: 160; loss: 1.96; acc: 0.3
Batch: 180; loss: 1.9; acc: 0.34
Batch: 200; loss: 1.86; acc: 0.41
Batch: 220; loss: 1.9; acc: 0.34
Batch: 240; loss: 1.84; acc: 0.42
Batch: 260; loss: 1.85; acc: 0.39
Batch: 280; loss: 2.04; acc: 0.31
Batch: 300; loss: 1.91; acc: 0.33
Batch: 320; loss: 1.8; acc: 0.44
Batch: 340; loss: 1.86; acc: 0.42
Batch: 360; loss: 1.84; acc: 0.38
Batch: 380; loss: 1.78; acc: 0.47
Batch: 400; loss: 1.84; acc: 0.34
Batch: 420; loss: 1.92; acc: 0.42
Batch: 440; loss: 1.89; acc: 0.47
Batch: 460; loss: 1.85; acc: 0.41
Batch: 480; loss: 1.86; acc: 0.39
Batch: 500; loss: 1.79; acc: 0.48
Batch: 520; loss: 1.85; acc: 0.38
Batch: 540; loss: 1.95; acc: 0.33
Batch: 560; loss: 1.87; acc: 0.38
Batch: 580; loss: 1.81; acc: 0.41
Batch: 600; loss: 1.81; acc: 0.41
Batch: 620; loss: 1.82; acc: 0.44
Batch: 640; loss: 1.74; acc: 0.56
Batch: 660; loss: 1.75; acc: 0.56
Batch: 680; loss: 1.89; acc: 0.34
Batch: 700; loss: 1.9; acc: 0.38
Batch: 720; loss: 1.81; acc: 0.47
Batch: 740; loss: 2.0; acc: 0.28
Batch: 760; loss: 1.9; acc: 0.28
Batch: 780; loss: 1.93; acc: 0.34
Train Epoch over. train_loss: 1.87; train_accuracy: 0.39 

3.368525722180493e-05
7.760182597849052e-06
Batch: 0; loss: 1.79; acc: 0.39
Batch: 20; loss: 2.06; acc: 0.33
Batch: 40; loss: 1.69; acc: 0.52
Batch: 60; loss: 1.78; acc: 0.44
Batch: 80; loss: 1.72; acc: 0.52
Batch: 100; loss: 1.77; acc: 0.45
Batch: 120; loss: 1.84; acc: 0.47
Batch: 140; loss: 1.77; acc: 0.53
Val Epoch over. val_loss: 1.8314583833050575; val_accuracy: 0.4254578025477707 

The current subspace-distance is: 7.760182597849052e-06 

Epoch 26 start
The current lr is: 0.09
Batch: 0; loss: 1.84; acc: 0.42
Batch: 20; loss: 1.81; acc: 0.44
Batch: 40; loss: 2.01; acc: 0.27
Batch: 60; loss: 1.82; acc: 0.38
Batch: 80; loss: 1.99; acc: 0.31
Batch: 100; loss: 2.03; acc: 0.23
Batch: 120; loss: 1.76; acc: 0.53
Batch: 140; loss: 1.84; acc: 0.39
Batch: 160; loss: 1.91; acc: 0.36
Batch: 180; loss: 1.84; acc: 0.36
Batch: 200; loss: 1.89; acc: 0.38
Batch: 220; loss: 1.83; acc: 0.31
Batch: 240; loss: 1.85; acc: 0.44
Batch: 260; loss: 1.85; acc: 0.42
Batch: 280; loss: 1.93; acc: 0.34
Batch: 300; loss: 1.91; acc: 0.33
Batch: 320; loss: 1.83; acc: 0.39
Batch: 340; loss: 1.83; acc: 0.41
Batch: 360; loss: 1.77; acc: 0.39
Batch: 380; loss: 1.97; acc: 0.25
Batch: 400; loss: 1.89; acc: 0.45
Batch: 420; loss: 1.73; acc: 0.41
Batch: 440; loss: 1.79; acc: 0.41
Batch: 460; loss: 1.85; acc: 0.45
Batch: 480; loss: 1.77; acc: 0.48
Batch: 500; loss: 1.86; acc: 0.36
Batch: 520; loss: 1.92; acc: 0.36
Batch: 540; loss: 1.87; acc: 0.48
Batch: 560; loss: 1.91; acc: 0.38
Batch: 580; loss: 1.78; acc: 0.44
Batch: 600; loss: 1.79; acc: 0.5
Batch: 620; loss: 1.87; acc: 0.38
Batch: 640; loss: 1.69; acc: 0.5
Batch: 660; loss: 1.77; acc: 0.48
Batch: 680; loss: 1.79; acc: 0.45
Batch: 700; loss: 1.89; acc: 0.48
Batch: 720; loss: 1.85; acc: 0.39
Batch: 740; loss: 1.81; acc: 0.44
Batch: 760; loss: 1.89; acc: 0.36
Batch: 780; loss: 1.91; acc: 0.39
Train Epoch over. train_loss: 1.87; train_accuracy: 0.39 

3.370429840288125e-05
9.011153451865539e-06
Batch: 0; loss: 1.79; acc: 0.44
Batch: 20; loss: 2.03; acc: 0.34
Batch: 40; loss: 1.7; acc: 0.52
Batch: 60; loss: 1.78; acc: 0.47
Batch: 80; loss: 1.72; acc: 0.53
Batch: 100; loss: 1.76; acc: 0.48
Batch: 120; loss: 1.84; acc: 0.5
Batch: 140; loss: 1.77; acc: 0.47
Val Epoch over. val_loss: 1.8262886530274798; val_accuracy: 0.4238654458598726 

The current subspace-distance is: 9.011153451865539e-06 

Epoch 27 start
The current lr is: 0.09
Batch: 0; loss: 1.83; acc: 0.39
Batch: 20; loss: 1.92; acc: 0.34
Batch: 40; loss: 1.87; acc: 0.44
Batch: 60; loss: 1.86; acc: 0.34
Batch: 80; loss: 1.87; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.27
Batch: 120; loss: 1.9; acc: 0.42
Batch: 140; loss: 1.83; acc: 0.39
Batch: 160; loss: 1.8; acc: 0.42
Batch: 180; loss: 1.86; acc: 0.41
Batch: 200; loss: 1.81; acc: 0.41
Batch: 220; loss: 1.89; acc: 0.41
Batch: 240; loss: 1.89; acc: 0.41
Batch: 260; loss: 1.8; acc: 0.48
Batch: 280; loss: 1.84; acc: 0.39
Batch: 300; loss: 1.73; acc: 0.5
Batch: 320; loss: 1.77; acc: 0.41
Batch: 340; loss: 1.86; acc: 0.5
Batch: 360; loss: 1.85; acc: 0.42
Batch: 380; loss: 1.77; acc: 0.45
Batch: 400; loss: 1.99; acc: 0.34
Batch: 420; loss: 1.87; acc: 0.36
Batch: 440; loss: 1.93; acc: 0.28
Batch: 460; loss: 1.75; acc: 0.5
Batch: 480; loss: 1.92; acc: 0.41
Batch: 500; loss: 1.89; acc: 0.41
Batch: 520; loss: 1.84; acc: 0.39
Batch: 540; loss: 1.66; acc: 0.58
Batch: 560; loss: 1.83; acc: 0.45
Batch: 580; loss: 1.84; acc: 0.47
Batch: 600; loss: 1.84; acc: 0.44
Batch: 620; loss: 1.86; acc: 0.36
Batch: 640; loss: 1.82; acc: 0.44
Batch: 660; loss: 1.8; acc: 0.47
Batch: 680; loss: 1.73; acc: 0.44
Batch: 700; loss: 1.82; acc: 0.36
Batch: 720; loss: 1.98; acc: 0.27
Batch: 740; loss: 1.77; acc: 0.41
Batch: 760; loss: 1.9; acc: 0.34
Batch: 780; loss: 1.96; acc: 0.36
Train Epoch over. train_loss: 1.86; train_accuracy: 0.39 

3.4178396163042635e-05
7.787919457769021e-06
Batch: 0; loss: 1.79; acc: 0.44
Batch: 20; loss: 2.02; acc: 0.33
Batch: 40; loss: 1.69; acc: 0.56
Batch: 60; loss: 1.78; acc: 0.44
Batch: 80; loss: 1.71; acc: 0.52
Batch: 100; loss: 1.76; acc: 0.5
Batch: 120; loss: 1.84; acc: 0.48
Batch: 140; loss: 1.76; acc: 0.48
Val Epoch over. val_loss: 1.820140262318265; val_accuracy: 0.4286425159235669 

The current subspace-distance is: 7.787919457769021e-06 

Epoch 28 start
The current lr is: 0.09
Batch: 0; loss: 1.74; acc: 0.52
Batch: 20; loss: 1.98; acc: 0.39
Batch: 40; loss: 1.86; acc: 0.34
Batch: 60; loss: 1.93; acc: 0.31
Batch: 80; loss: 1.89; acc: 0.36
Batch: 100; loss: 1.85; acc: 0.41
Batch: 120; loss: 1.79; acc: 0.41
Batch: 140; loss: 1.77; acc: 0.52
Batch: 160; loss: 1.96; acc: 0.31
Batch: 180; loss: 1.87; acc: 0.34
Batch: 200; loss: 1.84; acc: 0.36
Batch: 220; loss: 1.83; acc: 0.47
Batch: 240; loss: 1.91; acc: 0.36
Batch: 260; loss: 1.85; acc: 0.44
Batch: 280; loss: 1.83; acc: 0.38
Batch: 300; loss: 1.88; acc: 0.45
Batch: 320; loss: 1.79; acc: 0.42
Batch: 340; loss: 1.89; acc: 0.47
Batch: 360; loss: 1.91; acc: 0.44
Batch: 380; loss: 2.01; acc: 0.3
Batch: 400; loss: 1.82; acc: 0.44
Batch: 420; loss: 1.81; acc: 0.45
Batch: 440; loss: 1.9; acc: 0.34
Batch: 460; loss: 1.85; acc: 0.47
Batch: 480; loss: 1.87; acc: 0.45
Batch: 500; loss: 1.87; acc: 0.38
Batch: 520; loss: 1.9; acc: 0.38
Batch: 540; loss: 1.77; acc: 0.47
Batch: 560; loss: 1.95; acc: 0.33
Batch: 580; loss: 1.93; acc: 0.42
Batch: 600; loss: 1.81; acc: 0.42
Batch: 620; loss: 1.81; acc: 0.41
Batch: 640; loss: 1.89; acc: 0.39
Batch: 660; loss: 1.94; acc: 0.41
Batch: 680; loss: 1.79; acc: 0.38
Batch: 700; loss: 1.83; acc: 0.38
Batch: 720; loss: 1.89; acc: 0.38
Batch: 740; loss: 1.8; acc: 0.41
Batch: 760; loss: 1.8; acc: 0.41
Batch: 780; loss: 2.06; acc: 0.22
Train Epoch over. train_loss: 1.86; train_accuracy: 0.4 

3.3405576687073335e-05
9.031178706209175e-06
Batch: 0; loss: 1.77; acc: 0.45
Batch: 20; loss: 2.03; acc: 0.3
Batch: 40; loss: 1.68; acc: 0.52
Batch: 60; loss: 1.77; acc: 0.42
Batch: 80; loss: 1.7; acc: 0.53
Batch: 100; loss: 1.76; acc: 0.47
Batch: 120; loss: 1.83; acc: 0.47
Batch: 140; loss: 1.76; acc: 0.48
Val Epoch over. val_loss: 1.812666921858575; val_accuracy: 0.4198845541401274 

The current subspace-distance is: 9.031178706209175e-06 

Epoch 29 start
The current lr is: 0.09
Batch: 0; loss: 1.9; acc: 0.36
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.9; acc: 0.36
Batch: 60; loss: 1.75; acc: 0.42
Batch: 80; loss: 2.02; acc: 0.19
Batch: 100; loss: 1.99; acc: 0.28
Batch: 120; loss: 1.73; acc: 0.42
Batch: 140; loss: 1.66; acc: 0.5
Batch: 160; loss: 1.8; acc: 0.47
Batch: 180; loss: 1.75; acc: 0.48
Batch: 200; loss: 1.83; acc: 0.44
Batch: 220; loss: 2.02; acc: 0.33
Batch: 240; loss: 1.88; acc: 0.44
Batch: 260; loss: 1.86; acc: 0.39
Batch: 280; loss: 2.06; acc: 0.19
Batch: 300; loss: 1.79; acc: 0.42
Batch: 320; loss: 1.85; acc: 0.36
Batch: 340; loss: 1.86; acc: 0.34
Batch: 360; loss: 1.91; acc: 0.44
Batch: 380; loss: 1.83; acc: 0.36
Batch: 400; loss: 1.95; acc: 0.39
Batch: 420; loss: 1.92; acc: 0.36
Batch: 440; loss: 1.8; acc: 0.42
Batch: 460; loss: 1.94; acc: 0.36
Batch: 480; loss: 1.94; acc: 0.33
Batch: 500; loss: 1.79; acc: 0.39
Batch: 520; loss: 1.83; acc: 0.45
Batch: 540; loss: 1.84; acc: 0.31
Batch: 560; loss: 1.81; acc: 0.36
Batch: 580; loss: 1.82; acc: 0.44
Batch: 600; loss: 1.86; acc: 0.42
Batch: 620; loss: 1.86; acc: 0.36
Batch: 640; loss: 1.75; acc: 0.41
Batch: 660; loss: 1.91; acc: 0.36
Batch: 680; loss: 1.97; acc: 0.28
Batch: 700; loss: 1.87; acc: 0.44
Batch: 720; loss: 1.79; acc: 0.44
Batch: 740; loss: 1.97; acc: 0.28
Batch: 760; loss: 1.84; acc: 0.42
Batch: 780; loss: 1.8; acc: 0.44
Train Epoch over. train_loss: 1.85; train_accuracy: 0.4 

3.405610550544225e-05
7.705965799686965e-06
Batch: 0; loss: 1.79; acc: 0.45
Batch: 20; loss: 2.02; acc: 0.31
Batch: 40; loss: 1.7; acc: 0.5
Batch: 60; loss: 1.79; acc: 0.42
Batch: 80; loss: 1.72; acc: 0.48
Batch: 100; loss: 1.77; acc: 0.53
Batch: 120; loss: 1.84; acc: 0.45
Batch: 140; loss: 1.77; acc: 0.5
Val Epoch over. val_loss: 1.8209378947118284; val_accuracy: 0.4304339171974522 

The current subspace-distance is: 7.705965799686965e-06 

Epoch 30 start
The current lr is: 0.09
Batch: 0; loss: 1.94; acc: 0.34
Batch: 20; loss: 1.9; acc: 0.44
Batch: 40; loss: 1.9; acc: 0.36
Batch: 60; loss: 1.92; acc: 0.27
Batch: 80; loss: 1.75; acc: 0.41
Batch: 100; loss: 1.88; acc: 0.38
Batch: 120; loss: 1.9; acc: 0.38
Batch: 140; loss: 1.94; acc: 0.33
Batch: 160; loss: 1.84; acc: 0.39
Batch: 180; loss: 1.86; acc: 0.34
Batch: 200; loss: 1.8; acc: 0.47
Batch: 220; loss: 1.81; acc: 0.33
Batch: 240; loss: 1.95; acc: 0.33
Batch: 260; loss: 1.75; acc: 0.47
Batch: 280; loss: 1.84; acc: 0.38
Batch: 300; loss: 1.89; acc: 0.42
Batch: 320; loss: 1.91; acc: 0.39
Batch: 340; loss: 1.92; acc: 0.36
Batch: 360; loss: 1.65; acc: 0.55
Batch: 380; loss: 1.91; acc: 0.39
Batch: 400; loss: 1.83; acc: 0.5
Batch: 420; loss: 1.79; acc: 0.5
Batch: 440; loss: 1.98; acc: 0.3
Batch: 460; loss: 1.86; acc: 0.33
Batch: 480; loss: 1.95; acc: 0.3
Batch: 500; loss: 1.9; acc: 0.36
Batch: 520; loss: 1.87; acc: 0.38
Batch: 540; loss: 1.74; acc: 0.47
Batch: 560; loss: 1.88; acc: 0.36
Batch: 580; loss: 1.81; acc: 0.44
Batch: 600; loss: 1.77; acc: 0.44
Batch: 620; loss: 1.81; acc: 0.36
Batch: 640; loss: 1.85; acc: 0.39
Batch: 660; loss: 1.85; acc: 0.42
Batch: 680; loss: 1.89; acc: 0.31
Batch: 700; loss: 1.86; acc: 0.39
Batch: 720; loss: 1.76; acc: 0.5
Batch: 740; loss: 1.84; acc: 0.39
Batch: 760; loss: 1.82; acc: 0.42
Batch: 780; loss: 1.94; acc: 0.31
Train Epoch over. train_loss: 1.85; train_accuracy: 0.4 

3.374670632183552e-05
8.138933480950072e-06
Batch: 0; loss: 1.78; acc: 0.45
Batch: 20; loss: 2.01; acc: 0.31
Batch: 40; loss: 1.7; acc: 0.48
Batch: 60; loss: 1.79; acc: 0.42
Batch: 80; loss: 1.71; acc: 0.45
Batch: 100; loss: 1.78; acc: 0.52
Batch: 120; loss: 1.84; acc: 0.45
Batch: 140; loss: 1.77; acc: 0.48
Val Epoch over. val_loss: 1.819789193997717; val_accuracy: 0.4260549363057325 

The current subspace-distance is: 8.138933480950072e-06 

plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_50_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64

Channel scaling factor: 13.5

The number of parameters is: 279504

The number of individual parameters is:

108
432
108
108
162
52488
162
162
324
157464
324
324
64
62208
64
64
4096
64
640
10
64
64

nonzero elements in E: 27950397
elements in E: 27950400
fraction nonzero: 0.9999998926670102
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.34; acc: 0.2
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.06; acc: 0.3
Batch: 60; loss: 2.14; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.22
Batch: 100; loss: 2.03; acc: 0.28
Batch: 120; loss: 2.02; acc: 0.33
Batch: 140; loss: 1.97; acc: 0.3
Batch: 160; loss: 2.16; acc: 0.12
Batch: 180; loss: 1.94; acc: 0.33
Batch: 200; loss: 1.99; acc: 0.36
Batch: 220; loss: 1.99; acc: 0.42
Batch: 240; loss: 1.94; acc: 0.39
Batch: 260; loss: 1.93; acc: 0.38
Batch: 280; loss: 1.9; acc: 0.38
Batch: 300; loss: 1.88; acc: 0.44
Batch: 320; loss: 1.97; acc: 0.31
Batch: 340; loss: 1.85; acc: 0.41
Batch: 360; loss: 1.94; acc: 0.39
Batch: 380; loss: 1.93; acc: 0.33
Batch: 400; loss: 1.84; acc: 0.5
Batch: 420; loss: 1.97; acc: 0.3
Batch: 440; loss: 1.9; acc: 0.38
Batch: 460; loss: 1.78; acc: 0.5
Batch: 480; loss: 1.8; acc: 0.45
Batch: 500; loss: 1.87; acc: 0.34
Batch: 520; loss: 1.9; acc: 0.34
Batch: 540; loss: 1.93; acc: 0.3
Batch: 560; loss: 1.84; acc: 0.39
Batch: 580; loss: 1.96; acc: 0.36
Batch: 600; loss: 1.91; acc: 0.28
Batch: 620; loss: 1.91; acc: 0.31
Batch: 640; loss: 1.76; acc: 0.5
Batch: 660; loss: 1.71; acc: 0.48
Batch: 680; loss: 1.82; acc: 0.38
Batch: 700; loss: 1.99; acc: 0.31
Batch: 720; loss: 1.96; acc: 0.33
Batch: 740; loss: 1.97; acc: 0.33
Batch: 760; loss: 1.98; acc: 0.34
Batch: 780; loss: 1.98; acc: 0.27
Train Epoch over. train_loss: 1.94; train_accuracy: 0.35 

4.5460794353857636e-05
3.5280485462863e-05
Batch: 0; loss: 1.71; acc: 0.48
Batch: 20; loss: 1.93; acc: 0.44
Batch: 40; loss: 1.65; acc: 0.55
Batch: 60; loss: 1.73; acc: 0.47
Batch: 80; loss: 1.74; acc: 0.39
Batch: 100; loss: 1.81; acc: 0.47
Batch: 120; loss: 1.81; acc: 0.47
Batch: 140; loss: 1.84; acc: 0.42
Val Epoch over. val_loss: 1.8159911571794254; val_accuracy: 0.4114251592356688 

The current subspace-distance is: 3.5280485462863e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.72; acc: 0.45
Batch: 20; loss: 1.99; acc: 0.28
Batch: 40; loss: 1.85; acc: 0.38
Batch: 60; loss: 1.79; acc: 0.48
Batch: 80; loss: 1.92; acc: 0.36
Batch: 100; loss: 1.83; acc: 0.42
Batch: 120; loss: 1.92; acc: 0.38
Batch: 140; loss: 1.81; acc: 0.41
Batch: 160; loss: 1.93; acc: 0.36
Batch: 180; loss: 1.86; acc: 0.34
Batch: 200; loss: 1.77; acc: 0.45
Batch: 220; loss: 1.88; acc: 0.34
Batch: 240; loss: 1.82; acc: 0.42
Batch: 260; loss: 1.9; acc: 0.34
Batch: 280; loss: 1.94; acc: 0.33
Batch: 300; loss: 1.85; acc: 0.39
Batch: 320; loss: 1.88; acc: 0.42
Batch: 340; loss: 1.88; acc: 0.36
Batch: 360; loss: 2.07; acc: 0.3
Batch: 380; loss: 1.86; acc: 0.38
Batch: 400; loss: 1.85; acc: 0.41
Batch: 420; loss: 1.85; acc: 0.45
Batch: 440; loss: 1.84; acc: 0.47
Batch: 460; loss: 1.91; acc: 0.36
Batch: 480; loss: 1.73; acc: 0.53
Batch: 500; loss: 1.74; acc: 0.52
Batch: 520; loss: 1.66; acc: 0.5
Batch: 540; loss: 1.83; acc: 0.34
Batch: 560; loss: 1.82; acc: 0.47
Batch: 580; loss: 1.79; acc: 0.41
Batch: 600; loss: 1.76; acc: 0.5
Batch: 620; loss: 1.82; acc: 0.39
Batch: 640; loss: 1.74; acc: 0.44
Batch: 660; loss: 1.9; acc: 0.34
Batch: 680; loss: 1.91; acc: 0.34
Batch: 700; loss: 1.72; acc: 0.47
Batch: 720; loss: 1.83; acc: 0.38
Batch: 740; loss: 1.81; acc: 0.45
Batch: 760; loss: 1.8; acc: 0.41
Batch: 780; loss: 1.72; acc: 0.47
Train Epoch over. train_loss: 1.82; train_accuracy: 0.42 

5.130249337526038e-05
4.2585939809214324e-05
Batch: 0; loss: 1.73; acc: 0.48
Batch: 20; loss: 2.02; acc: 0.34
Batch: 40; loss: 1.66; acc: 0.47
Batch: 60; loss: 1.7; acc: 0.55
Batch: 80; loss: 1.79; acc: 0.42
Batch: 100; loss: 1.84; acc: 0.44
Batch: 120; loss: 1.83; acc: 0.5
Batch: 140; loss: 1.8; acc: 0.44
Val Epoch over. val_loss: 1.8185259589723721; val_accuracy: 0.4075437898089172 

The current subspace-distance is: 4.2585939809214324e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.8; acc: 0.42
Batch: 20; loss: 1.73; acc: 0.44
Batch: 40; loss: 1.68; acc: 0.48
Batch: 60; loss: 1.81; acc: 0.45
Batch: 80; loss: 1.72; acc: 0.53
Batch: 100; loss: 1.75; acc: 0.41
Batch: 120; loss: 1.8; acc: 0.45
Batch: 140; loss: 1.93; acc: 0.33
Batch: 160; loss: 1.84; acc: 0.41
Batch: 180; loss: 1.74; acc: 0.5
Batch: 200; loss: 1.89; acc: 0.36
Batch: 220; loss: 1.88; acc: 0.36
Batch: 240; loss: 1.84; acc: 0.36
Batch: 260; loss: 1.86; acc: 0.38
Batch: 280; loss: 1.8; acc: 0.44
Batch: 300; loss: 1.7; acc: 0.52
Batch: 320; loss: 1.8; acc: 0.42
Batch: 340; loss: 1.71; acc: 0.45
Batch: 360; loss: 1.64; acc: 0.58
Batch: 380; loss: 1.78; acc: 0.45
Batch: 400; loss: 1.87; acc: 0.41
Batch: 420; loss: 1.81; acc: 0.42
Batch: 440; loss: 1.74; acc: 0.47
Batch: 460; loss: 1.68; acc: 0.53
Batch: 480; loss: 1.71; acc: 0.45
Batch: 500; loss: 1.74; acc: 0.41
Batch: 520; loss: 1.64; acc: 0.58
Batch: 540; loss: 1.93; acc: 0.3
Batch: 560; loss: 1.99; acc: 0.34
Batch: 580; loss: 1.73; acc: 0.53
Batch: 600; loss: 1.76; acc: 0.45
Batch: 620; loss: 1.77; acc: 0.42
Batch: 640; loss: 1.8; acc: 0.39
Batch: 660; loss: 1.73; acc: 0.5
Batch: 680; loss: 1.91; acc: 0.36
Batch: 700; loss: 1.9; acc: 0.36
Batch: 720; loss: 1.86; acc: 0.36
Batch: 740; loss: 1.8; acc: 0.41
Batch: 760; loss: 1.76; acc: 0.44
Batch: 780; loss: 1.55; acc: 0.64
Train Epoch over. train_loss: 1.78; train_accuracy: 0.44 

5.7744793593883514e-05
4.9260546802543104e-05
Batch: 0; loss: 1.66; acc: 0.48
Batch: 20; loss: 1.92; acc: 0.42
Batch: 40; loss: 1.58; acc: 0.5
Batch: 60; loss: 1.63; acc: 0.5
Batch: 80; loss: 1.65; acc: 0.41
Batch: 100; loss: 1.73; acc: 0.48
Batch: 120; loss: 1.79; acc: 0.48
Batch: 140; loss: 1.69; acc: 0.48
Val Epoch over. val_loss: 1.7549825603035605; val_accuracy: 0.4557125796178344 

The current subspace-distance is: 4.9260546802543104e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.74; acc: 0.44
Batch: 20; loss: 1.61; acc: 0.64
Batch: 40; loss: 1.84; acc: 0.42
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.67; acc: 0.52
Batch: 100; loss: 1.72; acc: 0.5
Batch: 120; loss: 1.77; acc: 0.45
Batch: 140; loss: 1.78; acc: 0.42
Batch: 160; loss: 1.7; acc: 0.55
Batch: 180; loss: 1.76; acc: 0.47
Batch: 200; loss: 1.74; acc: 0.48
Batch: 220; loss: 1.59; acc: 0.55
Batch: 240; loss: 1.75; acc: 0.47
Batch: 260; loss: 1.81; acc: 0.38
Batch: 280; loss: 1.73; acc: 0.44
Batch: 300; loss: 1.79; acc: 0.42
Batch: 320; loss: 1.77; acc: 0.44
Batch: 340; loss: 1.89; acc: 0.39
Batch: 360; loss: 1.76; acc: 0.48
Batch: 380; loss: 1.84; acc: 0.42
Batch: 400; loss: 1.74; acc: 0.42
Batch: 420; loss: 1.72; acc: 0.45
Batch: 440; loss: 1.81; acc: 0.34
Batch: 460; loss: 1.9; acc: 0.34
Batch: 480; loss: 2.01; acc: 0.19
Batch: 500; loss: 1.71; acc: 0.44
Batch: 520; loss: 1.87; acc: 0.42
Batch: 540; loss: 1.82; acc: 0.42
Batch: 560; loss: 1.75; acc: 0.42
Batch: 580; loss: 1.76; acc: 0.47
Batch: 600; loss: 1.88; acc: 0.39
Batch: 620; loss: 1.81; acc: 0.38
Batch: 640; loss: 1.86; acc: 0.36
Batch: 660; loss: 1.8; acc: 0.36
Batch: 680; loss: 1.98; acc: 0.3
Batch: 700; loss: 1.87; acc: 0.39
Batch: 720; loss: 1.75; acc: 0.5
Batch: 740; loss: 1.79; acc: 0.45
Batch: 760; loss: 1.64; acc: 0.59
Batch: 780; loss: 1.78; acc: 0.42
Train Epoch over. train_loss: 1.75; train_accuracy: 0.45 

6.563491479028016e-05
5.769001290900633e-05
Batch: 0; loss: 1.62; acc: 0.56
Batch: 20; loss: 1.88; acc: 0.45
Batch: 40; loss: 1.54; acc: 0.56
Batch: 60; loss: 1.59; acc: 0.48
Batch: 80; loss: 1.6; acc: 0.45
Batch: 100; loss: 1.72; acc: 0.47
Batch: 120; loss: 1.79; acc: 0.52
Batch: 140; loss: 1.65; acc: 0.58
Val Epoch over. val_loss: 1.7279093356648827; val_accuracy: 0.46576433121019106 

The current subspace-distance is: 5.769001290900633e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.79; acc: 0.47
Batch: 20; loss: 1.72; acc: 0.48
Batch: 40; loss: 1.66; acc: 0.53
Batch: 60; loss: 1.61; acc: 0.58
Batch: 80; loss: 1.71; acc: 0.53
Batch: 100; loss: 1.7; acc: 0.45
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.66; acc: 0.48
Batch: 160; loss: 1.85; acc: 0.45
Batch: 180; loss: 1.64; acc: 0.56
Batch: 200; loss: 2.03; acc: 0.38
Batch: 220; loss: 1.69; acc: 0.55
Batch: 240; loss: 1.81; acc: 0.36
Batch: 260; loss: 1.67; acc: 0.5
Batch: 280; loss: 1.66; acc: 0.55
Batch: 300; loss: 1.72; acc: 0.48
Batch: 320; loss: 1.71; acc: 0.44
Batch: 340; loss: 1.73; acc: 0.47
Batch: 360; loss: 1.76; acc: 0.47
Batch: 380; loss: 1.74; acc: 0.45
Batch: 400; loss: 1.54; acc: 0.61
Batch: 420; loss: 1.63; acc: 0.55
Batch: 440; loss: 1.65; acc: 0.48
Batch: 460; loss: 1.65; acc: 0.5
Batch: 480; loss: 1.69; acc: 0.39
Batch: 500; loss: 1.85; acc: 0.36
Batch: 520; loss: 1.87; acc: 0.42
Batch: 540; loss: 1.7; acc: 0.52
Batch: 560; loss: 1.64; acc: 0.48
Batch: 580; loss: 1.71; acc: 0.48
Batch: 600; loss: 1.67; acc: 0.47
Batch: 620; loss: 1.54; acc: 0.62
Batch: 640; loss: 1.62; acc: 0.5
Batch: 660; loss: 1.47; acc: 0.7
Batch: 680; loss: 1.61; acc: 0.5
Batch: 700; loss: 1.58; acc: 0.59
Batch: 720; loss: 1.63; acc: 0.5
Batch: 740; loss: 1.69; acc: 0.48
Batch: 760; loss: 1.57; acc: 0.55
Batch: 780; loss: 1.6; acc: 0.55
Train Epoch over. train_loss: 1.72; train_accuracy: 0.47 

6.989246321609244e-05
6.246980046853423e-05
Batch: 0; loss: 1.53; acc: 0.59
Batch: 20; loss: 1.79; acc: 0.5
Batch: 40; loss: 1.47; acc: 0.64
Batch: 60; loss: 1.55; acc: 0.59
Batch: 80; loss: 1.5; acc: 0.58
Batch: 100; loss: 1.66; acc: 0.52
Batch: 120; loss: 1.75; acc: 0.45
Batch: 140; loss: 1.56; acc: 0.61
Val Epoch over. val_loss: 1.6671975494190385; val_accuracy: 0.5000995222929936 

The current subspace-distance is: 6.246980046853423e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.72; acc: 0.52
Batch: 20; loss: 1.83; acc: 0.41
Batch: 40; loss: 1.79; acc: 0.5
Batch: 60; loss: 1.67; acc: 0.48
Batch: 80; loss: 1.71; acc: 0.55
Batch: 100; loss: 1.66; acc: 0.5
Batch: 120; loss: 1.73; acc: 0.53
Batch: 140; loss: 1.8; acc: 0.36
Batch: 160; loss: 1.6; acc: 0.56
Batch: 180; loss: 1.74; acc: 0.47
Batch: 200; loss: 1.73; acc: 0.44
Batch: 220; loss: 1.77; acc: 0.45
Batch: 240; loss: 1.58; acc: 0.55
Batch: 260; loss: 1.61; acc: 0.52
Batch: 280; loss: 1.75; acc: 0.53
Batch: 300; loss: 1.59; acc: 0.61
Batch: 320; loss: 1.66; acc: 0.5
Batch: 340; loss: 1.77; acc: 0.39
Batch: 360; loss: 1.66; acc: 0.55
Batch: 380; loss: 1.71; acc: 0.47
Batch: 400; loss: 1.64; acc: 0.52
Batch: 420; loss: 1.79; acc: 0.48
Batch: 440; loss: 1.64; acc: 0.52
Batch: 460; loss: 1.84; acc: 0.39
Batch: 480; loss: 1.62; acc: 0.52
Batch: 500; loss: 1.66; acc: 0.53
Batch: 520; loss: 1.83; acc: 0.41
Batch: 540; loss: 1.8; acc: 0.42
Batch: 560; loss: 1.73; acc: 0.44
Batch: 580; loss: 1.73; acc: 0.5
Batch: 600; loss: 1.82; acc: 0.45
Batch: 620; loss: 1.84; acc: 0.42
Batch: 640; loss: 1.66; acc: 0.48
Batch: 660; loss: 1.78; acc: 0.44
Batch: 680; loss: 1.54; acc: 0.53
Batch: 700; loss: 1.66; acc: 0.59
Batch: 720; loss: 1.68; acc: 0.45
Batch: 740; loss: 1.57; acc: 0.53
Batch: 760; loss: 1.73; acc: 0.52
Batch: 780; loss: 1.69; acc: 0.5
Train Epoch over. train_loss: 1.69; train_accuracy: 0.5 

7.362807082245126e-05
6.724608829244971e-05
Batch: 0; loss: 1.61; acc: 0.53
Batch: 20; loss: 1.79; acc: 0.53
Batch: 40; loss: 1.46; acc: 0.7
Batch: 60; loss: 1.57; acc: 0.56
Batch: 80; loss: 1.54; acc: 0.58
Batch: 100; loss: 1.72; acc: 0.45
Batch: 120; loss: 1.76; acc: 0.44
Batch: 140; loss: 1.54; acc: 0.73
Val Epoch over. val_loss: 1.6677916452383539; val_accuracy: 0.5308519108280255 

The current subspace-distance is: 6.724608829244971e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.73; acc: 0.5
Batch: 20; loss: 1.78; acc: 0.42
Batch: 40; loss: 1.79; acc: 0.45
Batch: 60; loss: 1.76; acc: 0.47
Batch: 80; loss: 1.57; acc: 0.58
Batch: 100; loss: 1.78; acc: 0.45
Batch: 120; loss: 1.63; acc: 0.58
Batch: 140; loss: 1.76; acc: 0.48
Batch: 160; loss: 1.74; acc: 0.39
Batch: 180; loss: 1.63; acc: 0.53
Batch: 200; loss: 1.62; acc: 0.48
Batch: 220; loss: 1.65; acc: 0.58
Batch: 240; loss: 1.73; acc: 0.42
Batch: 260; loss: 1.8; acc: 0.41
Batch: 280; loss: 1.75; acc: 0.48
Batch: 300; loss: 1.73; acc: 0.42
Batch: 320; loss: 1.6; acc: 0.55
Batch: 340; loss: 1.52; acc: 0.53
Batch: 360; loss: 1.65; acc: 0.52
Batch: 380; loss: 1.58; acc: 0.55
Batch: 400; loss: 1.86; acc: 0.39
Batch: 420; loss: 1.69; acc: 0.5
Batch: 440; loss: 1.68; acc: 0.45
Batch: 460; loss: 1.64; acc: 0.52
Batch: 480; loss: 1.68; acc: 0.47
Batch: 500; loss: 1.72; acc: 0.45
Batch: 520; loss: 1.69; acc: 0.47
Batch: 540; loss: 1.69; acc: 0.48
Batch: 560; loss: 1.58; acc: 0.59
Batch: 580; loss: 1.64; acc: 0.42
Batch: 600; loss: 1.59; acc: 0.5
Batch: 620; loss: 1.61; acc: 0.53
Batch: 640; loss: 1.63; acc: 0.48
Batch: 660; loss: 1.79; acc: 0.44
Batch: 680; loss: 1.59; acc: 0.52
Batch: 700; loss: 1.64; acc: 0.52
Batch: 720; loss: 1.54; acc: 0.58
Batch: 740; loss: 1.62; acc: 0.53
Batch: 760; loss: 1.69; acc: 0.56
Batch: 780; loss: 1.6; acc: 0.55
Train Epoch over. train_loss: 1.66; train_accuracy: 0.51 

7.572526374133304e-05
6.791329360567033e-05
Batch: 0; loss: 1.58; acc: 0.61
Batch: 20; loss: 1.78; acc: 0.48
Batch: 40; loss: 1.44; acc: 0.69
Batch: 60; loss: 1.49; acc: 0.62
Batch: 80; loss: 1.52; acc: 0.56
Batch: 100; loss: 1.69; acc: 0.48
Batch: 120; loss: 1.7; acc: 0.5
Batch: 140; loss: 1.49; acc: 0.69
Val Epoch over. val_loss: 1.6383245948013987; val_accuracy: 0.5356289808917197 

The current subspace-distance is: 6.791329360567033e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.62; acc: 0.47
Batch: 20; loss: 1.79; acc: 0.41
Batch: 40; loss: 1.68; acc: 0.53
Batch: 60; loss: 1.7; acc: 0.47
Batch: 80; loss: 1.51; acc: 0.53
Batch: 100; loss: 1.74; acc: 0.44
Batch: 120; loss: 1.62; acc: 0.56
Batch: 140; loss: 1.57; acc: 0.53
Batch: 160; loss: 1.65; acc: 0.55
Batch: 180; loss: 1.77; acc: 0.44
Batch: 200; loss: 1.63; acc: 0.45
Batch: 220; loss: 1.62; acc: 0.48
Batch: 240; loss: 1.51; acc: 0.59
Batch: 260; loss: 1.79; acc: 0.48
Batch: 280; loss: 1.75; acc: 0.42
Batch: 300; loss: 1.59; acc: 0.47
Batch: 320; loss: 1.6; acc: 0.53
Batch: 340; loss: 1.8; acc: 0.39
Batch: 360; loss: 1.6; acc: 0.58
Batch: 380; loss: 1.58; acc: 0.62
Batch: 400; loss: 1.75; acc: 0.36
Batch: 420; loss: 1.68; acc: 0.44
Batch: 440; loss: 1.71; acc: 0.52
Batch: 460; loss: 1.82; acc: 0.45
Batch: 480; loss: 1.67; acc: 0.52
Batch: 500; loss: 1.46; acc: 0.64
Batch: 520; loss: 1.6; acc: 0.58
Batch: 540; loss: 1.75; acc: 0.42
Batch: 560; loss: 1.55; acc: 0.56
Batch: 580; loss: 1.66; acc: 0.5
Batch: 600; loss: 1.72; acc: 0.42
Batch: 620; loss: 1.64; acc: 0.5
Batch: 640; loss: 1.58; acc: 0.53
Batch: 660; loss: 1.54; acc: 0.55
Batch: 680; loss: 1.73; acc: 0.39
Batch: 700; loss: 1.58; acc: 0.58
Batch: 720; loss: 1.49; acc: 0.59
Batch: 740; loss: 1.81; acc: 0.41
Batch: 760; loss: 1.55; acc: 0.56
Batch: 780; loss: 1.64; acc: 0.56
Train Epoch over. train_loss: 1.64; train_accuracy: 0.51 

7.629745232407004e-05
6.869113713037223e-05
Batch: 0; loss: 1.54; acc: 0.58
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.43; acc: 0.56
Batch: 60; loss: 1.49; acc: 0.58
Batch: 80; loss: 1.47; acc: 0.58
Batch: 100; loss: 1.66; acc: 0.58
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.49; acc: 0.59
Val Epoch over. val_loss: 1.6394109217224606; val_accuracy: 0.49522292993630573 

The current subspace-distance is: 6.869113713037223e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.52; acc: 0.61
Batch: 20; loss: 1.7; acc: 0.47
Batch: 40; loss: 1.64; acc: 0.42
Batch: 60; loss: 1.72; acc: 0.48
Batch: 80; loss: 1.82; acc: 0.45
Batch: 100; loss: 1.63; acc: 0.45
Batch: 120; loss: 1.76; acc: 0.42
Batch: 140; loss: 1.79; acc: 0.44
Batch: 160; loss: 1.51; acc: 0.62
Batch: 180; loss: 1.65; acc: 0.52
Batch: 200; loss: 1.69; acc: 0.48
Batch: 220; loss: 1.57; acc: 0.56
Batch: 240; loss: 1.5; acc: 0.61
Batch: 260; loss: 1.67; acc: 0.45
Batch: 280; loss: 1.77; acc: 0.41
Batch: 300; loss: 1.63; acc: 0.55
Batch: 320; loss: 1.55; acc: 0.58
Batch: 340; loss: 1.82; acc: 0.31
Batch: 360; loss: 1.59; acc: 0.52
Batch: 380; loss: 1.55; acc: 0.55
Batch: 400; loss: 1.82; acc: 0.31
Batch: 420; loss: 1.73; acc: 0.48
Batch: 440; loss: 1.67; acc: 0.47
Batch: 460; loss: 1.6; acc: 0.5
Batch: 480; loss: 1.67; acc: 0.48
Batch: 500; loss: 1.67; acc: 0.53
Batch: 520; loss: 1.69; acc: 0.5
Batch: 540; loss: 1.64; acc: 0.42
Batch: 560; loss: 1.59; acc: 0.53
Batch: 580; loss: 1.67; acc: 0.41
Batch: 600; loss: 1.54; acc: 0.58
Batch: 620; loss: 1.65; acc: 0.53
Batch: 640; loss: 1.64; acc: 0.44
Batch: 660; loss: 1.55; acc: 0.56
Batch: 680; loss: 1.6; acc: 0.5
Batch: 700; loss: 1.85; acc: 0.41
Batch: 720; loss: 1.53; acc: 0.55
Batch: 740; loss: 1.62; acc: 0.42
Batch: 760; loss: 1.62; acc: 0.47
Batch: 780; loss: 1.52; acc: 0.56
Train Epoch over. train_loss: 1.63; train_accuracy: 0.51 

7.698573608649895e-05
6.932883843546733e-05
Batch: 0; loss: 1.52; acc: 0.59
Batch: 20; loss: 1.77; acc: 0.44
Batch: 40; loss: 1.36; acc: 0.67
Batch: 60; loss: 1.41; acc: 0.62
Batch: 80; loss: 1.46; acc: 0.61
Batch: 100; loss: 1.59; acc: 0.58
Batch: 120; loss: 1.71; acc: 0.44
Batch: 140; loss: 1.44; acc: 0.64
Val Epoch over. val_loss: 1.597578750294485; val_accuracy: 0.536922770700637 

The current subspace-distance is: 6.932883843546733e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.64; acc: 0.42
Batch: 20; loss: 1.62; acc: 0.53
Batch: 40; loss: 1.66; acc: 0.45
Batch: 60; loss: 1.57; acc: 0.55
Batch: 80; loss: 1.57; acc: 0.61
Batch: 100; loss: 1.62; acc: 0.55
Batch: 120; loss: 1.64; acc: 0.53
Batch: 140; loss: 1.67; acc: 0.45
Batch: 160; loss: 1.48; acc: 0.55
Batch: 180; loss: 1.73; acc: 0.48
Batch: 200; loss: 1.57; acc: 0.55
Batch: 220; loss: 1.65; acc: 0.45
Batch: 240; loss: 1.52; acc: 0.59
Batch: 260; loss: 1.64; acc: 0.42
Batch: 280; loss: 1.46; acc: 0.62
Batch: 300; loss: 1.49; acc: 0.59
Batch: 320; loss: 1.64; acc: 0.41
Batch: 340; loss: 1.48; acc: 0.58
Batch: 360; loss: 1.6; acc: 0.5
Batch: 380; loss: 1.74; acc: 0.36
Batch: 400; loss: 1.61; acc: 0.45
Batch: 420; loss: 1.63; acc: 0.55
Batch: 440; loss: 1.52; acc: 0.56
Batch: 460; loss: 1.51; acc: 0.61
Batch: 480; loss: 1.6; acc: 0.53
Batch: 500; loss: 1.73; acc: 0.39
Batch: 520; loss: 1.56; acc: 0.5
Batch: 540; loss: 1.66; acc: 0.5
Batch: 560; loss: 1.58; acc: 0.55
Batch: 580; loss: 1.62; acc: 0.47
Batch: 600; loss: 1.67; acc: 0.52
Batch: 620; loss: 1.59; acc: 0.55
Batch: 640; loss: 1.43; acc: 0.66
Batch: 660; loss: 1.7; acc: 0.55
Batch: 680; loss: 1.55; acc: 0.5
Batch: 700; loss: 1.71; acc: 0.39
Batch: 720; loss: 1.55; acc: 0.56
Batch: 740; loss: 1.5; acc: 0.59
Batch: 760; loss: 1.66; acc: 0.47
Batch: 780; loss: 1.8; acc: 0.34
Train Epoch over. train_loss: 1.62; train_accuracy: 0.51 

7.945074321469292e-05
7.225402077892795e-05
Batch: 0; loss: 1.49; acc: 0.58
Batch: 20; loss: 1.77; acc: 0.5
Batch: 40; loss: 1.36; acc: 0.64
Batch: 60; loss: 1.44; acc: 0.61
Batch: 80; loss: 1.47; acc: 0.56
Batch: 100; loss: 1.62; acc: 0.53
Batch: 120; loss: 1.71; acc: 0.38
Batch: 140; loss: 1.41; acc: 0.61
Val Epoch over. val_loss: 1.5927954130111985; val_accuracy: 0.5198049363057324 

The current subspace-distance is: 7.225402077892795e-05 

Epoch 11 start
The current lr is: 0.3
Batch: 0; loss: 1.77; acc: 0.42
Batch: 20; loss: 1.6; acc: 0.53
Batch: 40; loss: 1.6; acc: 0.48
Batch: 60; loss: 1.61; acc: 0.53
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.52
Batch: 120; loss: 1.67; acc: 0.47
Batch: 140; loss: 1.39; acc: 0.7
Batch: 160; loss: 1.71; acc: 0.41
Batch: 180; loss: 1.42; acc: 0.61
Batch: 200; loss: 1.56; acc: 0.5
Batch: 220; loss: 1.75; acc: 0.36
Batch: 240; loss: 1.57; acc: 0.56
Batch: 260; loss: 1.55; acc: 0.47
Batch: 280; loss: 1.73; acc: 0.42
Batch: 300; loss: 1.6; acc: 0.53
Batch: 320; loss: 1.51; acc: 0.53
Batch: 340; loss: 1.67; acc: 0.48
Batch: 360; loss: 1.5; acc: 0.59
Batch: 380; loss: 1.67; acc: 0.41
Batch: 400; loss: 1.7; acc: 0.48
Batch: 420; loss: 1.62; acc: 0.42
Batch: 440; loss: 1.6; acc: 0.58
Batch: 460; loss: 1.58; acc: 0.53
Batch: 480; loss: 1.81; acc: 0.39
Batch: 500; loss: 1.69; acc: 0.48
Batch: 520; loss: 1.57; acc: 0.53
Batch: 540; loss: 1.77; acc: 0.39
Batch: 560; loss: 1.55; acc: 0.53
Batch: 580; loss: 1.7; acc: 0.47
Batch: 600; loss: 1.64; acc: 0.55
Batch: 620; loss: 1.48; acc: 0.55
Batch: 640; loss: 1.58; acc: 0.52
Batch: 660; loss: 1.55; acc: 0.5
Batch: 680; loss: 1.61; acc: 0.47
Batch: 700; loss: 1.62; acc: 0.5
Batch: 720; loss: 1.66; acc: 0.45
Batch: 740; loss: 1.58; acc: 0.55
Batch: 760; loss: 1.48; acc: 0.58
Batch: 780; loss: 1.71; acc: 0.45
Train Epoch over. train_loss: 1.61; train_accuracy: 0.51 

7.920022471807897e-05
7.133161125238985e-05
Batch: 0; loss: 1.47; acc: 0.61
Batch: 20; loss: 1.71; acc: 0.52
Batch: 40; loss: 1.33; acc: 0.69
Batch: 60; loss: 1.4; acc: 0.67
Batch: 80; loss: 1.45; acc: 0.61
Batch: 100; loss: 1.58; acc: 0.56
Batch: 120; loss: 1.7; acc: 0.47
Batch: 140; loss: 1.41; acc: 0.66
Val Epoch over. val_loss: 1.5712977488329456; val_accuracy: 0.5518511146496815 

The current subspace-distance is: 7.133161125238985e-05 

Epoch 12 start
The current lr is: 0.3
Batch: 0; loss: 1.71; acc: 0.48
Batch: 20; loss: 1.59; acc: 0.5
Batch: 40; loss: 1.62; acc: 0.5
Batch: 60; loss: 1.63; acc: 0.5
Batch: 80; loss: 1.62; acc: 0.42
Batch: 100; loss: 1.63; acc: 0.53
Batch: 120; loss: 1.52; acc: 0.61
Batch: 140; loss: 1.65; acc: 0.47
Batch: 160; loss: 1.55; acc: 0.48
Batch: 180; loss: 1.48; acc: 0.56
Batch: 200; loss: 1.54; acc: 0.59
Batch: 220; loss: 1.51; acc: 0.58
Batch: 240; loss: 1.56; acc: 0.58
Batch: 260; loss: 1.64; acc: 0.53
Batch: 280; loss: 1.49; acc: 0.59
Batch: 300; loss: 1.75; acc: 0.41
Batch: 320; loss: 1.78; acc: 0.44
Batch: 340; loss: 1.48; acc: 0.61
Batch: 360; loss: 1.52; acc: 0.52
Batch: 380; loss: 1.51; acc: 0.58
Batch: 400; loss: 1.51; acc: 0.58
Batch: 420; loss: 1.62; acc: 0.53
Batch: 440; loss: 1.63; acc: 0.41
Batch: 460; loss: 1.61; acc: 0.56
Batch: 480; loss: 1.5; acc: 0.59
Batch: 500; loss: 1.49; acc: 0.58
Batch: 520; loss: 1.62; acc: 0.52
Batch: 540; loss: 1.62; acc: 0.45
Batch: 560; loss: 1.52; acc: 0.56
Batch: 580; loss: 1.69; acc: 0.42
Batch: 600; loss: 1.65; acc: 0.47
Batch: 620; loss: 1.69; acc: 0.47
Batch: 640; loss: 1.6; acc: 0.45
Batch: 660; loss: 1.66; acc: 0.55
Batch: 680; loss: 1.65; acc: 0.47
Batch: 700; loss: 1.59; acc: 0.55
Batch: 720; loss: 1.71; acc: 0.42
Batch: 740; loss: 1.75; acc: 0.42
Batch: 760; loss: 1.54; acc: 0.56
Batch: 780; loss: 1.59; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.51 

8.126084139803424e-05
7.339270086959004e-05
Batch: 0; loss: 1.47; acc: 0.58
Batch: 20; loss: 1.73; acc: 0.48
Batch: 40; loss: 1.33; acc: 0.69
Batch: 60; loss: 1.4; acc: 0.69
Batch: 80; loss: 1.44; acc: 0.62
Batch: 100; loss: 1.62; acc: 0.52
Batch: 120; loss: 1.71; acc: 0.45
Batch: 140; loss: 1.41; acc: 0.64
Val Epoch over. val_loss: 1.5746272863096493; val_accuracy: 0.5388136942675159 

The current subspace-distance is: 7.339270086959004e-05 

Epoch 13 start
The current lr is: 0.3
Batch: 0; loss: 1.5; acc: 0.52
Batch: 20; loss: 1.59; acc: 0.48
Batch: 40; loss: 1.87; acc: 0.36
Batch: 60; loss: 1.68; acc: 0.44
Batch: 80; loss: 1.57; acc: 0.58
Batch: 100; loss: 1.43; acc: 0.66
Batch: 120; loss: 1.69; acc: 0.42
Batch: 140; loss: 1.65; acc: 0.53
Batch: 160; loss: 1.59; acc: 0.48
Batch: 180; loss: 1.97; acc: 0.34
Batch: 200; loss: 1.72; acc: 0.45
Batch: 220; loss: 1.55; acc: 0.56
Batch: 240; loss: 1.65; acc: 0.44
Batch: 260; loss: 1.67; acc: 0.5
Batch: 280; loss: 1.59; acc: 0.53
Batch: 300; loss: 1.53; acc: 0.56
Batch: 320; loss: 1.61; acc: 0.45
Batch: 340; loss: 1.69; acc: 0.5
Batch: 360; loss: 1.67; acc: 0.5
Batch: 380; loss: 1.65; acc: 0.53
Batch: 400; loss: 1.67; acc: 0.48
Batch: 420; loss: 1.65; acc: 0.44
Batch: 440; loss: 1.61; acc: 0.52
Batch: 460; loss: 1.57; acc: 0.52
Batch: 480; loss: 1.71; acc: 0.44
Batch: 500; loss: 1.68; acc: 0.45
Batch: 520; loss: 1.37; acc: 0.69
Batch: 540; loss: 1.75; acc: 0.45
Batch: 560; loss: 1.47; acc: 0.55
Batch: 580; loss: 1.52; acc: 0.56
Batch: 600; loss: 1.73; acc: 0.42
Batch: 620; loss: 1.58; acc: 0.53
Batch: 640; loss: 1.56; acc: 0.55
Batch: 660; loss: 1.65; acc: 0.44
Batch: 680; loss: 1.61; acc: 0.5
Batch: 700; loss: 1.56; acc: 0.61
Batch: 720; loss: 1.56; acc: 0.55
Batch: 740; loss: 1.63; acc: 0.58
Batch: 760; loss: 1.7; acc: 0.41
Batch: 780; loss: 1.55; acc: 0.62
Train Epoch over. train_loss: 1.61; train_accuracy: 0.51 

8.026779687497765e-05
7.467890827683732e-05
Batch: 0; loss: 1.45; acc: 0.59
Batch: 20; loss: 1.71; acc: 0.48
Batch: 40; loss: 1.33; acc: 0.67
Batch: 60; loss: 1.4; acc: 0.67
Batch: 80; loss: 1.44; acc: 0.62
Batch: 100; loss: 1.59; acc: 0.58
Batch: 120; loss: 1.67; acc: 0.5
Batch: 140; loss: 1.41; acc: 0.66
Val Epoch over. val_loss: 1.5667963134255378; val_accuracy: 0.549562101910828 

The current subspace-distance is: 7.467890827683732e-05 

Epoch 14 start
The current lr is: 0.3
Batch: 0; loss: 1.73; acc: 0.44
Batch: 20; loss: 1.63; acc: 0.48
Batch: 40; loss: 1.59; acc: 0.53
Batch: 60; loss: 1.59; acc: 0.52
Batch: 80; loss: 1.69; acc: 0.52
Batch: 100; loss: 1.49; acc: 0.58
Batch: 120; loss: 1.62; acc: 0.5
Batch: 140; loss: 1.64; acc: 0.53
Batch: 160; loss: 1.38; acc: 0.62
Batch: 180; loss: 1.83; acc: 0.42
Batch: 200; loss: 1.6; acc: 0.52
Batch: 220; loss: 1.46; acc: 0.58
Batch: 240; loss: 1.59; acc: 0.61
Batch: 260; loss: 1.66; acc: 0.48
Batch: 280; loss: 1.49; acc: 0.62
Batch: 300; loss: 1.65; acc: 0.45
Batch: 320; loss: 1.45; acc: 0.59
Batch: 340; loss: 1.75; acc: 0.5
Batch: 360; loss: 1.51; acc: 0.61
Batch: 380; loss: 1.57; acc: 0.53
Batch: 400; loss: 1.57; acc: 0.52
Batch: 420; loss: 1.58; acc: 0.58
Batch: 440; loss: 1.45; acc: 0.66
Batch: 460; loss: 1.68; acc: 0.5
Batch: 480; loss: 1.6; acc: 0.47
Batch: 500; loss: 1.57; acc: 0.58
Batch: 520; loss: 1.62; acc: 0.44
Batch: 540; loss: 1.45; acc: 0.59
Batch: 560; loss: 1.65; acc: 0.5
Batch: 580; loss: 1.61; acc: 0.45
Batch: 600; loss: 1.68; acc: 0.45
Batch: 620; loss: 1.67; acc: 0.5
Batch: 640; loss: 1.69; acc: 0.36
Batch: 660; loss: 1.74; acc: 0.47
Batch: 680; loss: 1.57; acc: 0.5
Batch: 700; loss: 1.53; acc: 0.53
Batch: 720; loss: 1.51; acc: 0.52
Batch: 740; loss: 1.65; acc: 0.45
Batch: 760; loss: 1.56; acc: 0.55
Batch: 780; loss: 1.58; acc: 0.56
Train Epoch over. train_loss: 1.6; train_accuracy: 0.51 

8.23504087748006e-05
7.483700755983591e-05
Batch: 0; loss: 1.43; acc: 0.59
Batch: 20; loss: 1.7; acc: 0.52
Batch: 40; loss: 1.34; acc: 0.7
Batch: 60; loss: 1.39; acc: 0.67
Batch: 80; loss: 1.44; acc: 0.62
Batch: 100; loss: 1.58; acc: 0.58
Batch: 120; loss: 1.66; acc: 0.5
Batch: 140; loss: 1.42; acc: 0.64
Val Epoch over. val_loss: 1.5615538366281303; val_accuracy: 0.5448845541401274 

The current subspace-distance is: 7.483700755983591e-05 

Epoch 15 start
The current lr is: 0.3
Batch: 0; loss: 1.74; acc: 0.45
Batch: 20; loss: 1.6; acc: 0.47
Batch: 40; loss: 1.61; acc: 0.56
Batch: 60; loss: 1.66; acc: 0.53
Batch: 80; loss: 1.45; acc: 0.64
Batch: 100; loss: 1.5; acc: 0.61
Batch: 120; loss: 1.72; acc: 0.41
Batch: 140; loss: 1.8; acc: 0.42
Batch: 160; loss: 1.57; acc: 0.59
Batch: 180; loss: 1.49; acc: 0.59
Batch: 200; loss: 1.63; acc: 0.47
Batch: 220; loss: 1.57; acc: 0.58
Batch: 240; loss: 1.75; acc: 0.41
Batch: 260; loss: 1.61; acc: 0.5
Batch: 280; loss: 1.5; acc: 0.58
Batch: 300; loss: 1.52; acc: 0.52
Batch: 320; loss: 1.58; acc: 0.56
Batch: 340; loss: 1.42; acc: 0.61
Batch: 360; loss: 1.72; acc: 0.5
Batch: 380; loss: 1.42; acc: 0.62
Batch: 400; loss: 1.43; acc: 0.62
Batch: 420; loss: 1.59; acc: 0.53
Batch: 440; loss: 1.56; acc: 0.48
Batch: 460; loss: 1.59; acc: 0.45
Batch: 480; loss: 1.74; acc: 0.48
Batch: 500; loss: 1.78; acc: 0.48
Batch: 520; loss: 1.54; acc: 0.53
Batch: 540; loss: 1.56; acc: 0.52
Batch: 560; loss: 1.58; acc: 0.5
Batch: 580; loss: 1.69; acc: 0.42
Batch: 600; loss: 1.51; acc: 0.59
Batch: 620; loss: 1.59; acc: 0.55
Batch: 640; loss: 1.62; acc: 0.47
Batch: 660; loss: 1.55; acc: 0.52
Batch: 680; loss: 1.48; acc: 0.59
Batch: 700; loss: 1.65; acc: 0.45
Batch: 720; loss: 1.5; acc: 0.5
Batch: 740; loss: 1.65; acc: 0.44
Batch: 760; loss: 1.76; acc: 0.47
Batch: 780; loss: 1.54; acc: 0.53
Train Epoch over. train_loss: 1.6; train_accuracy: 0.51 

8.334117592312396e-05
7.67117744544521e-05
Batch: 0; loss: 1.43; acc: 0.56
Batch: 20; loss: 1.7; acc: 0.5
Batch: 40; loss: 1.32; acc: 0.67
Batch: 60; loss: 1.39; acc: 0.69
Batch: 80; loss: 1.44; acc: 0.58
Batch: 100; loss: 1.59; acc: 0.58
Batch: 120; loss: 1.67; acc: 0.48
Batch: 140; loss: 1.39; acc: 0.61
Val Epoch over. val_loss: 1.55981740374474; val_accuracy: 0.542296974522293 

The current subspace-distance is: 7.67117744544521e-05 

Epoch 16 start
The current lr is: 0.3
Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 1.6; acc: 0.52
Batch: 40; loss: 1.61; acc: 0.59
Batch: 60; loss: 1.58; acc: 0.48
Batch: 80; loss: 1.54; acc: 0.58
Batch: 100; loss: 1.49; acc: 0.58
Batch: 120; loss: 1.58; acc: 0.58
Batch: 140; loss: 1.49; acc: 0.56
Batch: 160; loss: 1.62; acc: 0.47
Batch: 180; loss: 1.79; acc: 0.36
Batch: 200; loss: 1.58; acc: 0.53
Batch: 220; loss: 1.61; acc: 0.53
Batch: 240; loss: 1.7; acc: 0.47
Batch: 260; loss: 1.61; acc: 0.5
Batch: 280; loss: 1.68; acc: 0.47
Batch: 300; loss: 1.49; acc: 0.48
Batch: 320; loss: 1.57; acc: 0.56
Batch: 340; loss: 1.6; acc: 0.52
Batch: 360; loss: 1.59; acc: 0.53
Batch: 380; loss: 1.52; acc: 0.55
Batch: 400; loss: 1.47; acc: 0.61
Batch: 420; loss: 1.6; acc: 0.59
Batch: 440; loss: 1.65; acc: 0.55
Batch: 460; loss: 1.57; acc: 0.52
Batch: 480; loss: 1.47; acc: 0.59
Batch: 500; loss: 1.63; acc: 0.41
Batch: 520; loss: 1.5; acc: 0.58
Batch: 540; loss: 1.46; acc: 0.58
Batch: 560; loss: 1.42; acc: 0.59
Batch: 580; loss: 1.53; acc: 0.56
Batch: 600; loss: 1.54; acc: 0.5
Batch: 620; loss: 1.85; acc: 0.44
Batch: 640; loss: 1.66; acc: 0.47
Batch: 660; loss: 1.58; acc: 0.53
Batch: 680; loss: 1.55; acc: 0.52
Batch: 700; loss: 1.49; acc: 0.53
Batch: 720; loss: 1.52; acc: 0.58
Batch: 740; loss: 1.68; acc: 0.52
Batch: 760; loss: 1.57; acc: 0.59
Batch: 780; loss: 1.75; acc: 0.39
Train Epoch over. train_loss: 1.6; train_accuracy: 0.51 

8.409592555835843e-05
7.708783959969878e-05
Batch: 0; loss: 1.42; acc: 0.59
Batch: 20; loss: 1.68; acc: 0.5
Batch: 40; loss: 1.31; acc: 0.67
Batch: 60; loss: 1.38; acc: 0.67
Batch: 80; loss: 1.45; acc: 0.58
Batch: 100; loss: 1.58; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.52
Batch: 140; loss: 1.39; acc: 0.61
Val Epoch over. val_loss: 1.5551197384573092; val_accuracy: 0.5459792993630573 

The current subspace-distance is: 7.708783959969878e-05 

Epoch 17 start
The current lr is: 0.3
Batch: 0; loss: 1.45; acc: 0.66
Batch: 20; loss: 1.54; acc: 0.58
Batch: 40; loss: 1.47; acc: 0.61
Batch: 60; loss: 1.84; acc: 0.38
Batch: 80; loss: 1.74; acc: 0.38
Batch: 100; loss: 1.76; acc: 0.48
Batch: 120; loss: 1.46; acc: 0.66
Batch: 140; loss: 1.65; acc: 0.53
Batch: 160; loss: 1.6; acc: 0.47
Batch: 180; loss: 1.49; acc: 0.58
Batch: 200; loss: 1.45; acc: 0.62
Batch: 220; loss: 1.54; acc: 0.55
Batch: 240; loss: 1.57; acc: 0.48
Batch: 260; loss: 1.71; acc: 0.42
Batch: 280; loss: 1.64; acc: 0.44
Batch: 300; loss: 1.58; acc: 0.48
Batch: 320; loss: 1.65; acc: 0.42
Batch: 340; loss: 1.42; acc: 0.67
Batch: 360; loss: 1.61; acc: 0.53
Batch: 380; loss: 1.61; acc: 0.5
Batch: 400; loss: 1.69; acc: 0.47
Batch: 420; loss: 1.68; acc: 0.44
Batch: 440; loss: 1.65; acc: 0.45
Batch: 460; loss: 1.69; acc: 0.48
Batch: 480; loss: 1.71; acc: 0.42
Batch: 500; loss: 1.57; acc: 0.53
Batch: 520; loss: 1.56; acc: 0.5
Batch: 540; loss: 1.45; acc: 0.58
Batch: 560; loss: 1.51; acc: 0.56
Batch: 580; loss: 1.52; acc: 0.56
Batch: 600; loss: 1.57; acc: 0.56
Batch: 620; loss: 1.41; acc: 0.58
Batch: 640; loss: 1.49; acc: 0.56
Batch: 660; loss: 1.58; acc: 0.55
Batch: 680; loss: 1.59; acc: 0.53
Batch: 700; loss: 1.64; acc: 0.42
Batch: 720; loss: 1.52; acc: 0.55
Batch: 740; loss: 1.59; acc: 0.55
Batch: 760; loss: 1.5; acc: 0.5
Batch: 780; loss: 1.63; acc: 0.53
Train Epoch over. train_loss: 1.6; train_accuracy: 0.51 

8.459983655484393e-05
7.653732609469444e-05
Batch: 0; loss: 1.39; acc: 0.66
Batch: 20; loss: 1.67; acc: 0.5
Batch: 40; loss: 1.3; acc: 0.69
Batch: 60; loss: 1.36; acc: 0.69
Batch: 80; loss: 1.42; acc: 0.61
Batch: 100; loss: 1.56; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.38; acc: 0.62
Val Epoch over. val_loss: 1.5431021991049407; val_accuracy: 0.552547770700637 

The current subspace-distance is: 7.653732609469444e-05 

Epoch 18 start
The current lr is: 0.3
Batch: 0; loss: 1.65; acc: 0.53
Batch: 20; loss: 1.49; acc: 0.58
Batch: 40; loss: 1.57; acc: 0.53
Batch: 60; loss: 1.69; acc: 0.44
Batch: 80; loss: 1.81; acc: 0.41
Batch: 100; loss: 1.65; acc: 0.55
Batch: 120; loss: 1.76; acc: 0.42
Batch: 140; loss: 1.55; acc: 0.53
Batch: 160; loss: 1.63; acc: 0.5
Batch: 180; loss: 1.59; acc: 0.52
Batch: 200; loss: 1.51; acc: 0.55
Batch: 220; loss: 1.57; acc: 0.5
Batch: 240; loss: 1.52; acc: 0.52
Batch: 260; loss: 1.87; acc: 0.39
Batch: 280; loss: 1.57; acc: 0.53
Batch: 300; loss: 1.56; acc: 0.55
Batch: 320; loss: 1.6; acc: 0.52
Batch: 340; loss: 1.67; acc: 0.5
Batch: 360; loss: 1.53; acc: 0.53
Batch: 380; loss: 1.6; acc: 0.48
Batch: 400; loss: 1.53; acc: 0.5
Batch: 420; loss: 1.47; acc: 0.55
Batch: 440; loss: 1.57; acc: 0.53
Batch: 460; loss: 1.73; acc: 0.38
Batch: 480; loss: 1.75; acc: 0.41
Batch: 500; loss: 1.66; acc: 0.52
Batch: 520; loss: 1.52; acc: 0.52
Batch: 540; loss: 1.59; acc: 0.52
Batch: 560; loss: 1.57; acc: 0.52
Batch: 580; loss: 1.61; acc: 0.5
Batch: 600; loss: 1.48; acc: 0.64
Batch: 620; loss: 1.72; acc: 0.36
Batch: 640; loss: 1.59; acc: 0.53
Batch: 660; loss: 1.53; acc: 0.52
Batch: 680; loss: 1.51; acc: 0.5
Batch: 700; loss: 1.73; acc: 0.41
Batch: 720; loss: 1.69; acc: 0.52
Batch: 740; loss: 1.53; acc: 0.53
Batch: 760; loss: 1.6; acc: 0.53
Batch: 780; loss: 1.66; acc: 0.52
Train Epoch over. train_loss: 1.6; train_accuracy: 0.51 

8.529191109118983e-05
7.824021304259077e-05
Batch: 0; loss: 1.43; acc: 0.61
Batch: 20; loss: 1.68; acc: 0.52
Batch: 40; loss: 1.32; acc: 0.67
Batch: 60; loss: 1.4; acc: 0.69
Batch: 80; loss: 1.46; acc: 0.61
Batch: 100; loss: 1.59; acc: 0.61
Batch: 120; loss: 1.67; acc: 0.52
Batch: 140; loss: 1.39; acc: 0.69
Val Epoch over. val_loss: 1.5628651843708792; val_accuracy: 0.5505573248407644 

The current subspace-distance is: 7.824021304259077e-05 

Epoch 19 start
The current lr is: 0.3
Batch: 0; loss: 1.61; acc: 0.48
Batch: 20; loss: 1.58; acc: 0.52
Batch: 40; loss: 1.57; acc: 0.48
Batch: 60; loss: 1.68; acc: 0.41
Batch: 80; loss: 1.69; acc: 0.52
Batch: 100; loss: 1.5; acc: 0.56
Batch: 120; loss: 1.72; acc: 0.42
Batch: 140; loss: 1.68; acc: 0.58
Batch: 160; loss: 1.57; acc: 0.5
Batch: 180; loss: 1.62; acc: 0.48
Batch: 200; loss: 1.6; acc: 0.44
Batch: 220; loss: 1.61; acc: 0.45
Batch: 240; loss: 1.6; acc: 0.5
Batch: 260; loss: 1.63; acc: 0.45
Batch: 280; loss: 1.61; acc: 0.52
Batch: 300; loss: 1.56; acc: 0.52
Batch: 320; loss: 1.67; acc: 0.42
Batch: 340; loss: 1.66; acc: 0.5
Batch: 360; loss: 1.62; acc: 0.44
Batch: 380; loss: 1.68; acc: 0.44
Batch: 400; loss: 1.32; acc: 0.69
Batch: 420; loss: 1.62; acc: 0.52
Batch: 440; loss: 1.69; acc: 0.48
Batch: 460; loss: 1.7; acc: 0.39
Batch: 480; loss: 1.53; acc: 0.55
Batch: 500; loss: 1.53; acc: 0.53
Batch: 520; loss: 1.67; acc: 0.48
Batch: 540; loss: 1.43; acc: 0.62
Batch: 560; loss: 1.66; acc: 0.45
Batch: 580; loss: 1.5; acc: 0.58
Batch: 600; loss: 1.57; acc: 0.58
Batch: 620; loss: 1.56; acc: 0.48
Batch: 640; loss: 1.59; acc: 0.47
Batch: 660; loss: 1.49; acc: 0.56
Batch: 680; loss: 1.63; acc: 0.5
Batch: 700; loss: 1.59; acc: 0.58
Batch: 720; loss: 1.49; acc: 0.48
Batch: 740; loss: 1.62; acc: 0.55
Batch: 760; loss: 1.65; acc: 0.52
Batch: 780; loss: 1.58; acc: 0.47
Train Epoch over. train_loss: 1.6; train_accuracy: 0.51 

8.622359746368602e-05
7.906706014182419e-05
Batch: 0; loss: 1.4; acc: 0.64
Batch: 20; loss: 1.67; acc: 0.48
Batch: 40; loss: 1.3; acc: 0.66
Batch: 60; loss: 1.37; acc: 0.7
Batch: 80; loss: 1.44; acc: 0.58
Batch: 100; loss: 1.58; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.37; acc: 0.64
Val Epoch over. val_loss: 1.5529491939362448; val_accuracy: 0.5409036624203821 

The current subspace-distance is: 7.906706014182419e-05 

Epoch 20 start
The current lr is: 0.3
Batch: 0; loss: 1.55; acc: 0.5
Batch: 20; loss: 1.66; acc: 0.48
Batch: 40; loss: 1.56; acc: 0.59
Batch: 60; loss: 1.64; acc: 0.52
Batch: 80; loss: 1.58; acc: 0.52
Batch: 100; loss: 1.58; acc: 0.52
Batch: 120; loss: 1.61; acc: 0.47
Batch: 140; loss: 1.39; acc: 0.62
Batch: 160; loss: 1.8; acc: 0.39
Batch: 180; loss: 1.54; acc: 0.58
Batch: 200; loss: 1.59; acc: 0.48
Batch: 220; loss: 1.48; acc: 0.62
Batch: 240; loss: 1.51; acc: 0.52
Batch: 260; loss: 1.64; acc: 0.52
Batch: 280; loss: 1.53; acc: 0.59
Batch: 300; loss: 1.42; acc: 0.59
Batch: 320; loss: 1.5; acc: 0.52
Batch: 340; loss: 1.64; acc: 0.52
Batch: 360; loss: 1.64; acc: 0.48
Batch: 380; loss: 1.71; acc: 0.52
Batch: 400; loss: 1.58; acc: 0.53
Batch: 420; loss: 1.81; acc: 0.36
Batch: 440; loss: 1.6; acc: 0.52
Batch: 460; loss: 1.53; acc: 0.53
Batch: 480; loss: 1.6; acc: 0.47
Batch: 500; loss: 1.74; acc: 0.41
Batch: 520; loss: 1.49; acc: 0.56
Batch: 540; loss: 1.52; acc: 0.52
Batch: 560; loss: 1.41; acc: 0.62
Batch: 580; loss: 1.68; acc: 0.47
Batch: 600; loss: 1.75; acc: 0.41
Batch: 620; loss: 1.52; acc: 0.5
Batch: 640; loss: 1.63; acc: 0.47
Batch: 660; loss: 1.53; acc: 0.61
Batch: 680; loss: 1.59; acc: 0.56
Batch: 700; loss: 1.59; acc: 0.56
Batch: 720; loss: 1.69; acc: 0.44
Batch: 740; loss: 1.61; acc: 0.47
Batch: 760; loss: 1.57; acc: 0.53
Batch: 780; loss: 1.5; acc: 0.64
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.725565567146987e-05
8.034791244426742e-05
Batch: 0; loss: 1.42; acc: 0.64
Batch: 20; loss: 1.68; acc: 0.47
Batch: 40; loss: 1.3; acc: 0.66
Batch: 60; loss: 1.38; acc: 0.67
Batch: 80; loss: 1.44; acc: 0.61
Batch: 100; loss: 1.58; acc: 0.59
Batch: 120; loss: 1.67; acc: 0.47
Batch: 140; loss: 1.4; acc: 0.69
Val Epoch over. val_loss: 1.5609847185718027; val_accuracy: 0.5471735668789809 

The current subspace-distance is: 8.034791244426742e-05 

Epoch 21 start
The current lr is: 0.09
Batch: 0; loss: 1.47; acc: 0.64
Batch: 20; loss: 1.55; acc: 0.56
Batch: 40; loss: 1.4; acc: 0.66
Batch: 60; loss: 1.43; acc: 0.56
Batch: 80; loss: 1.61; acc: 0.59
Batch: 100; loss: 1.72; acc: 0.5
Batch: 120; loss: 1.56; acc: 0.55
Batch: 140; loss: 1.57; acc: 0.53
Batch: 160; loss: 1.77; acc: 0.41
Batch: 180; loss: 1.71; acc: 0.45
Batch: 200; loss: 1.86; acc: 0.31
Batch: 220; loss: 1.61; acc: 0.5
Batch: 240; loss: 1.57; acc: 0.47
Batch: 260; loss: 1.69; acc: 0.44
Batch: 280; loss: 1.65; acc: 0.42
Batch: 300; loss: 1.58; acc: 0.48
Batch: 320; loss: 1.57; acc: 0.56
Batch: 340; loss: 1.63; acc: 0.47
Batch: 360; loss: 1.44; acc: 0.56
Batch: 380; loss: 1.47; acc: 0.62
Batch: 400; loss: 1.63; acc: 0.52
Batch: 420; loss: 1.61; acc: 0.53
Batch: 440; loss: 1.58; acc: 0.48
Batch: 460; loss: 1.56; acc: 0.55
Batch: 480; loss: 1.48; acc: 0.58
Batch: 500; loss: 1.61; acc: 0.52
Batch: 520; loss: 1.49; acc: 0.64
Batch: 540; loss: 1.5; acc: 0.55
Batch: 560; loss: 1.56; acc: 0.58
Batch: 580; loss: 1.52; acc: 0.55
Batch: 600; loss: 1.76; acc: 0.47
Batch: 620; loss: 1.58; acc: 0.52
Batch: 640; loss: 1.5; acc: 0.55
Batch: 660; loss: 1.59; acc: 0.48
Batch: 680; loss: 1.59; acc: 0.55
Batch: 700; loss: 1.51; acc: 0.59
Batch: 720; loss: 1.62; acc: 0.52
Batch: 740; loss: 1.65; acc: 0.5
Batch: 760; loss: 1.6; acc: 0.45
Batch: 780; loss: 1.49; acc: 0.66
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.777761104283854e-05
8.085453737294301e-05
Batch: 0; loss: 1.41; acc: 0.66
Batch: 20; loss: 1.69; acc: 0.47
Batch: 40; loss: 1.31; acc: 0.64
Batch: 60; loss: 1.39; acc: 0.69
Batch: 80; loss: 1.44; acc: 0.56
Batch: 100; loss: 1.59; acc: 0.56
Batch: 120; loss: 1.66; acc: 0.48
Batch: 140; loss: 1.39; acc: 0.66
Val Epoch over. val_loss: 1.5576538158829805; val_accuracy: 0.5423964968152867 

The current subspace-distance is: 8.085453737294301e-05 

Epoch 22 start
The current lr is: 0.09
Batch: 0; loss: 1.61; acc: 0.5
Batch: 20; loss: 1.52; acc: 0.62
Batch: 40; loss: 1.57; acc: 0.55
Batch: 60; loss: 1.68; acc: 0.48
Batch: 80; loss: 1.56; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.56
Batch: 120; loss: 1.6; acc: 0.39
Batch: 140; loss: 1.61; acc: 0.48
Batch: 160; loss: 1.81; acc: 0.47
Batch: 180; loss: 1.57; acc: 0.47
Batch: 200; loss: 1.73; acc: 0.42
Batch: 220; loss: 1.49; acc: 0.59
Batch: 240; loss: 1.64; acc: 0.5
Batch: 260; loss: 1.67; acc: 0.5
Batch: 280; loss: 1.6; acc: 0.48
Batch: 300; loss: 1.44; acc: 0.64
Batch: 320; loss: 1.53; acc: 0.5
Batch: 340; loss: 1.57; acc: 0.56
Batch: 360; loss: 1.6; acc: 0.52
Batch: 380; loss: 1.62; acc: 0.47
Batch: 400; loss: 1.69; acc: 0.44
Batch: 420; loss: 1.69; acc: 0.41
Batch: 440; loss: 1.48; acc: 0.56
Batch: 460; loss: 1.68; acc: 0.42
Batch: 480; loss: 1.67; acc: 0.44
Batch: 500; loss: 1.59; acc: 0.41
Batch: 520; loss: 1.67; acc: 0.55
Batch: 540; loss: 1.37; acc: 0.67
Batch: 560; loss: 1.59; acc: 0.55
Batch: 580; loss: 1.64; acc: 0.45
Batch: 600; loss: 1.66; acc: 0.36
Batch: 620; loss: 1.46; acc: 0.58
Batch: 640; loss: 1.67; acc: 0.45
Batch: 660; loss: 1.5; acc: 0.64
Batch: 680; loss: 1.43; acc: 0.56
Batch: 700; loss: 1.78; acc: 0.42
Batch: 720; loss: 1.47; acc: 0.55
Batch: 740; loss: 1.63; acc: 0.48
Batch: 760; loss: 1.51; acc: 0.48
Batch: 780; loss: 1.61; acc: 0.56
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.754174632485956e-05
8.13838341855444e-05
Batch: 0; loss: 1.39; acc: 0.66
Batch: 20; loss: 1.65; acc: 0.5
Batch: 40; loss: 1.29; acc: 0.67
Batch: 60; loss: 1.36; acc: 0.72
Batch: 80; loss: 1.42; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.61
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.38; acc: 0.66
Val Epoch over. val_loss: 1.5494303521077344; val_accuracy: 0.5464769108280255 

The current subspace-distance is: 8.13838341855444e-05 

Epoch 23 start
The current lr is: 0.09
Batch: 0; loss: 1.72; acc: 0.45
Batch: 20; loss: 1.49; acc: 0.56
Batch: 40; loss: 1.52; acc: 0.56
Batch: 60; loss: 1.6; acc: 0.47
Batch: 80; loss: 1.52; acc: 0.55
Batch: 100; loss: 1.45; acc: 0.64
Batch: 120; loss: 1.4; acc: 0.62
Batch: 140; loss: 1.63; acc: 0.47
Batch: 160; loss: 1.53; acc: 0.56
Batch: 180; loss: 1.67; acc: 0.53
Batch: 200; loss: 1.57; acc: 0.48
Batch: 220; loss: 1.4; acc: 0.58
Batch: 240; loss: 1.5; acc: 0.61
Batch: 260; loss: 1.56; acc: 0.48
Batch: 280; loss: 1.63; acc: 0.5
Batch: 300; loss: 1.54; acc: 0.58
Batch: 320; loss: 1.56; acc: 0.53
Batch: 340; loss: 1.54; acc: 0.55
Batch: 360; loss: 1.67; acc: 0.47
Batch: 380; loss: 1.55; acc: 0.55
Batch: 400; loss: 1.7; acc: 0.41
Batch: 420; loss: 1.57; acc: 0.5
Batch: 440; loss: 1.57; acc: 0.55
Batch: 460; loss: 1.51; acc: 0.58
Batch: 480; loss: 1.67; acc: 0.41
Batch: 500; loss: 1.52; acc: 0.53
Batch: 520; loss: 1.74; acc: 0.39
Batch: 540; loss: 1.43; acc: 0.55
Batch: 560; loss: 1.67; acc: 0.42
Batch: 580; loss: 1.55; acc: 0.56
Batch: 600; loss: 1.57; acc: 0.44
Batch: 620; loss: 1.55; acc: 0.56
Batch: 640; loss: 1.52; acc: 0.5
Batch: 660; loss: 1.55; acc: 0.58
Batch: 680; loss: 1.68; acc: 0.45
Batch: 700; loss: 1.59; acc: 0.47
Batch: 720; loss: 1.63; acc: 0.53
Batch: 740; loss: 1.65; acc: 0.48
Batch: 760; loss: 1.6; acc: 0.45
Batch: 780; loss: 1.48; acc: 0.67
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.766185055719689e-05
7.945234392536804e-05
Batch: 0; loss: 1.4; acc: 0.67
Batch: 20; loss: 1.67; acc: 0.5
Batch: 40; loss: 1.31; acc: 0.64
Batch: 60; loss: 1.38; acc: 0.7
Batch: 80; loss: 1.44; acc: 0.56
Batch: 100; loss: 1.58; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.5
Batch: 140; loss: 1.38; acc: 0.64
Val Epoch over. val_loss: 1.5562919712370369; val_accuracy: 0.5485668789808917 

The current subspace-distance is: 7.945234392536804e-05 

Epoch 24 start
The current lr is: 0.09
Batch: 0; loss: 1.68; acc: 0.45
Batch: 20; loss: 1.53; acc: 0.52
Batch: 40; loss: 1.68; acc: 0.44
Batch: 60; loss: 1.62; acc: 0.55
Batch: 80; loss: 1.49; acc: 0.56
Batch: 100; loss: 1.55; acc: 0.58
Batch: 120; loss: 1.54; acc: 0.56
Batch: 140; loss: 1.47; acc: 0.56
Batch: 160; loss: 1.52; acc: 0.59
Batch: 180; loss: 1.57; acc: 0.44
Batch: 200; loss: 1.56; acc: 0.58
Batch: 220; loss: 1.47; acc: 0.55
Batch: 240; loss: 1.67; acc: 0.41
Batch: 260; loss: 1.66; acc: 0.42
Batch: 280; loss: 1.52; acc: 0.5
Batch: 300; loss: 1.77; acc: 0.45
Batch: 320; loss: 1.68; acc: 0.48
Batch: 340; loss: 1.86; acc: 0.39
Batch: 360; loss: 1.54; acc: 0.59
Batch: 380; loss: 1.55; acc: 0.5
Batch: 400; loss: 1.81; acc: 0.38
Batch: 420; loss: 1.72; acc: 0.44
Batch: 440; loss: 1.51; acc: 0.55
Batch: 460; loss: 1.58; acc: 0.52
Batch: 480; loss: 1.65; acc: 0.5
Batch: 500; loss: 1.56; acc: 0.45
Batch: 520; loss: 1.52; acc: 0.58
Batch: 540; loss: 1.51; acc: 0.58
Batch: 560; loss: 1.53; acc: 0.55
Batch: 580; loss: 1.43; acc: 0.58
Batch: 600; loss: 1.65; acc: 0.5
Batch: 620; loss: 1.66; acc: 0.5
Batch: 640; loss: 1.32; acc: 0.69
Batch: 660; loss: 1.76; acc: 0.45
Batch: 680; loss: 1.55; acc: 0.5
Batch: 700; loss: 1.65; acc: 0.48
Batch: 720; loss: 1.6; acc: 0.56
Batch: 740; loss: 1.57; acc: 0.53
Batch: 760; loss: 1.69; acc: 0.5
Batch: 780; loss: 1.55; acc: 0.53
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.807407721178606e-05
8.09569246484898e-05
Batch: 0; loss: 1.39; acc: 0.7
Batch: 20; loss: 1.65; acc: 0.5
Batch: 40; loss: 1.29; acc: 0.67
Batch: 60; loss: 1.37; acc: 0.7
Batch: 80; loss: 1.44; acc: 0.55
Batch: 100; loss: 1.56; acc: 0.62
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.37; acc: 0.69
Val Epoch over. val_loss: 1.5456173139013303; val_accuracy: 0.5508558917197452 

The current subspace-distance is: 8.09569246484898e-05 

Epoch 25 start
The current lr is: 0.09
Batch: 0; loss: 1.55; acc: 0.5
Batch: 20; loss: 1.79; acc: 0.39
Batch: 40; loss: 1.6; acc: 0.45
Batch: 60; loss: 1.66; acc: 0.52
Batch: 80; loss: 1.71; acc: 0.5
Batch: 100; loss: 1.53; acc: 0.64
Batch: 120; loss: 1.6; acc: 0.47
Batch: 140; loss: 1.69; acc: 0.41
Batch: 160; loss: 1.6; acc: 0.53
Batch: 180; loss: 1.47; acc: 0.58
Batch: 200; loss: 1.59; acc: 0.53
Batch: 220; loss: 1.54; acc: 0.52
Batch: 240; loss: 1.66; acc: 0.41
Batch: 260; loss: 1.65; acc: 0.53
Batch: 280; loss: 1.55; acc: 0.5
Batch: 300; loss: 1.67; acc: 0.45
Batch: 320; loss: 1.55; acc: 0.56
Batch: 340; loss: 1.54; acc: 0.55
Batch: 360; loss: 1.62; acc: 0.47
Batch: 380; loss: 1.56; acc: 0.5
Batch: 400; loss: 1.56; acc: 0.55
Batch: 420; loss: 1.52; acc: 0.56
Batch: 440; loss: 1.73; acc: 0.42
Batch: 460; loss: 1.54; acc: 0.48
Batch: 480; loss: 1.53; acc: 0.56
Batch: 500; loss: 1.59; acc: 0.47
Batch: 520; loss: 1.59; acc: 0.45
Batch: 540; loss: 1.61; acc: 0.5
Batch: 560; loss: 1.49; acc: 0.56
Batch: 580; loss: 1.62; acc: 0.47
Batch: 600; loss: 1.73; acc: 0.36
Batch: 620; loss: 1.63; acc: 0.56
Batch: 640; loss: 1.69; acc: 0.47
Batch: 660; loss: 1.73; acc: 0.47
Batch: 680; loss: 1.6; acc: 0.52
Batch: 700; loss: 1.62; acc: 0.53
Batch: 720; loss: 1.48; acc: 0.53
Batch: 740; loss: 1.66; acc: 0.45
Batch: 760; loss: 1.71; acc: 0.48
Batch: 780; loss: 1.64; acc: 0.53
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.776725007919595e-05
8.041087858146057e-05
Batch: 0; loss: 1.4; acc: 0.67
Batch: 20; loss: 1.65; acc: 0.52
Batch: 40; loss: 1.29; acc: 0.66
Batch: 60; loss: 1.37; acc: 0.69
Batch: 80; loss: 1.43; acc: 0.55
Batch: 100; loss: 1.57; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.37; acc: 0.64
Val Epoch over. val_loss: 1.549802415689845; val_accuracy: 0.5500597133757962 

The current subspace-distance is: 8.041087858146057e-05 

Epoch 26 start
The current lr is: 0.09
Batch: 0; loss: 1.61; acc: 0.42
Batch: 20; loss: 1.72; acc: 0.47
Batch: 40; loss: 1.54; acc: 0.59
Batch: 60; loss: 1.58; acc: 0.55
Batch: 80; loss: 1.69; acc: 0.47
Batch: 100; loss: 1.68; acc: 0.45
Batch: 120; loss: 1.54; acc: 0.53
Batch: 140; loss: 1.56; acc: 0.62
Batch: 160; loss: 1.48; acc: 0.55
Batch: 180; loss: 1.71; acc: 0.41
Batch: 200; loss: 1.6; acc: 0.52
Batch: 220; loss: 1.79; acc: 0.39
Batch: 240; loss: 1.47; acc: 0.61
Batch: 260; loss: 1.56; acc: 0.52
Batch: 280; loss: 1.46; acc: 0.58
Batch: 300; loss: 1.5; acc: 0.53
Batch: 320; loss: 1.49; acc: 0.56
Batch: 340; loss: 1.53; acc: 0.56
Batch: 360; loss: 1.63; acc: 0.48
Batch: 380; loss: 1.59; acc: 0.5
Batch: 400; loss: 1.52; acc: 0.52
Batch: 420; loss: 1.51; acc: 0.55
Batch: 440; loss: 1.5; acc: 0.56
Batch: 460; loss: 1.57; acc: 0.45
Batch: 480; loss: 1.27; acc: 0.61
Batch: 500; loss: 1.64; acc: 0.5
Batch: 520; loss: 1.53; acc: 0.55
Batch: 540; loss: 1.69; acc: 0.42
Batch: 560; loss: 1.58; acc: 0.56
Batch: 580; loss: 1.64; acc: 0.45
Batch: 600; loss: 1.51; acc: 0.59
Batch: 620; loss: 1.75; acc: 0.41
Batch: 640; loss: 1.52; acc: 0.52
Batch: 660; loss: 1.55; acc: 0.55
Batch: 680; loss: 1.67; acc: 0.44
Batch: 700; loss: 1.55; acc: 0.53
Batch: 720; loss: 1.56; acc: 0.55
Batch: 740; loss: 1.77; acc: 0.45
Batch: 760; loss: 1.5; acc: 0.58
Batch: 780; loss: 1.58; acc: 0.47
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.725949737709016e-05
8.016385254450142e-05
Batch: 0; loss: 1.38; acc: 0.7
Batch: 20; loss: 1.65; acc: 0.52
Batch: 40; loss: 1.29; acc: 0.66
Batch: 60; loss: 1.37; acc: 0.72
Batch: 80; loss: 1.41; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.37; acc: 0.66
Val Epoch over. val_loss: 1.5460118776673724; val_accuracy: 0.546875 

The current subspace-distance is: 8.016385254450142e-05 

Epoch 27 start
The current lr is: 0.09
Batch: 0; loss: 1.76; acc: 0.45
Batch: 20; loss: 1.67; acc: 0.5
Batch: 40; loss: 1.54; acc: 0.56
Batch: 60; loss: 1.48; acc: 0.59
Batch: 80; loss: 1.49; acc: 0.62
Batch: 100; loss: 1.7; acc: 0.44
Batch: 120; loss: 1.51; acc: 0.53
Batch: 140; loss: 1.75; acc: 0.41
Batch: 160; loss: 1.6; acc: 0.55
Batch: 180; loss: 1.71; acc: 0.45
Batch: 200; loss: 1.66; acc: 0.42
Batch: 220; loss: 1.64; acc: 0.42
Batch: 240; loss: 1.75; acc: 0.47
Batch: 260; loss: 1.49; acc: 0.59
Batch: 280; loss: 1.42; acc: 0.61
Batch: 300; loss: 1.6; acc: 0.47
Batch: 320; loss: 1.71; acc: 0.39
Batch: 340; loss: 1.7; acc: 0.44
Batch: 360; loss: 1.54; acc: 0.58
Batch: 380; loss: 1.53; acc: 0.58
Batch: 400; loss: 1.42; acc: 0.58
Batch: 420; loss: 1.48; acc: 0.59
Batch: 440; loss: 1.61; acc: 0.44
Batch: 460; loss: 1.37; acc: 0.67
Batch: 480; loss: 1.56; acc: 0.58
Batch: 500; loss: 1.61; acc: 0.52
Batch: 520; loss: 1.68; acc: 0.45
Batch: 540; loss: 1.83; acc: 0.42
Batch: 560; loss: 1.62; acc: 0.53
Batch: 580; loss: 1.65; acc: 0.44
Batch: 600; loss: 1.53; acc: 0.52
Batch: 620; loss: 1.59; acc: 0.5
Batch: 640; loss: 1.44; acc: 0.56
Batch: 660; loss: 1.58; acc: 0.58
Batch: 680; loss: 1.58; acc: 0.56
Batch: 700; loss: 1.55; acc: 0.5
Batch: 720; loss: 1.59; acc: 0.52
Batch: 740; loss: 1.56; acc: 0.5
Batch: 760; loss: 1.57; acc: 0.58
Batch: 780; loss: 1.43; acc: 0.56
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.882163092494011e-05
8.190910011762753e-05
Batch: 0; loss: 1.41; acc: 0.67
Batch: 20; loss: 1.65; acc: 0.52
Batch: 40; loss: 1.29; acc: 0.66
Batch: 60; loss: 1.38; acc: 0.69
Batch: 80; loss: 1.43; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.5
Batch: 140; loss: 1.38; acc: 0.67
Val Epoch over. val_loss: 1.5510103034365708; val_accuracy: 0.5485668789808917 

The current subspace-distance is: 8.190910011762753e-05 

Epoch 28 start
The current lr is: 0.09
Batch: 0; loss: 1.7; acc: 0.48
Batch: 20; loss: 1.69; acc: 0.45
Batch: 40; loss: 1.59; acc: 0.45
Batch: 60; loss: 1.6; acc: 0.48
Batch: 80; loss: 1.81; acc: 0.41
Batch: 100; loss: 1.66; acc: 0.48
Batch: 120; loss: 1.42; acc: 0.66
Batch: 140; loss: 1.58; acc: 0.52
Batch: 160; loss: 1.59; acc: 0.47
Batch: 180; loss: 1.71; acc: 0.41
Batch: 200; loss: 1.45; acc: 0.55
Batch: 220; loss: 1.76; acc: 0.47
Batch: 240; loss: 1.58; acc: 0.58
Batch: 260; loss: 1.6; acc: 0.52
Batch: 280; loss: 1.48; acc: 0.58
Batch: 300; loss: 1.49; acc: 0.55
Batch: 320; loss: 1.44; acc: 0.61
Batch: 340; loss: 1.54; acc: 0.56
Batch: 360; loss: 1.68; acc: 0.34
Batch: 380; loss: 1.61; acc: 0.47
Batch: 400; loss: 1.6; acc: 0.53
Batch: 420; loss: 1.54; acc: 0.53
Batch: 440; loss: 1.69; acc: 0.39
Batch: 460; loss: 1.46; acc: 0.66
Batch: 480; loss: 1.75; acc: 0.38
Batch: 500; loss: 1.47; acc: 0.56
Batch: 520; loss: 1.49; acc: 0.5
Batch: 540; loss: 1.51; acc: 0.61
Batch: 560; loss: 1.63; acc: 0.47
Batch: 580; loss: 1.62; acc: 0.47
Batch: 600; loss: 1.57; acc: 0.53
Batch: 620; loss: 1.79; acc: 0.39
Batch: 640; loss: 1.52; acc: 0.59
Batch: 660; loss: 1.47; acc: 0.61
Batch: 680; loss: 1.57; acc: 0.53
Batch: 700; loss: 1.67; acc: 0.47
Batch: 720; loss: 1.48; acc: 0.64
Batch: 740; loss: 1.69; acc: 0.52
Batch: 760; loss: 1.45; acc: 0.62
Batch: 780; loss: 1.59; acc: 0.56
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.87594505911693e-05
8.053777128225192e-05
Batch: 0; loss: 1.4; acc: 0.66
Batch: 20; loss: 1.65; acc: 0.5
Batch: 40; loss: 1.3; acc: 0.67
Batch: 60; loss: 1.38; acc: 0.7
Batch: 80; loss: 1.43; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.5
Batch: 140; loss: 1.39; acc: 0.69
Val Epoch over. val_loss: 1.554350522673054; val_accuracy: 0.5523487261146497 

The current subspace-distance is: 8.053777128225192e-05 

Epoch 29 start
The current lr is: 0.09
Batch: 0; loss: 1.61; acc: 0.58
Batch: 20; loss: 1.59; acc: 0.56
Batch: 40; loss: 1.64; acc: 0.55
Batch: 60; loss: 1.72; acc: 0.45
Batch: 80; loss: 1.44; acc: 0.59
Batch: 100; loss: 1.47; acc: 0.61
Batch: 120; loss: 1.53; acc: 0.53
Batch: 140; loss: 1.65; acc: 0.47
Batch: 160; loss: 1.44; acc: 0.59
Batch: 180; loss: 1.54; acc: 0.58
Batch: 200; loss: 1.59; acc: 0.52
Batch: 220; loss: 1.54; acc: 0.58
Batch: 240; loss: 1.53; acc: 0.61
Batch: 260; loss: 1.67; acc: 0.42
Batch: 280; loss: 1.56; acc: 0.5
Batch: 300; loss: 1.54; acc: 0.52
Batch: 320; loss: 1.84; acc: 0.42
Batch: 340; loss: 1.53; acc: 0.48
Batch: 360; loss: 1.59; acc: 0.52
Batch: 380; loss: 1.42; acc: 0.56
Batch: 400; loss: 1.49; acc: 0.59
Batch: 420; loss: 1.45; acc: 0.62
Batch: 440; loss: 1.76; acc: 0.44
Batch: 460; loss: 1.44; acc: 0.58
Batch: 480; loss: 1.47; acc: 0.48
Batch: 500; loss: 1.63; acc: 0.52
Batch: 520; loss: 1.53; acc: 0.52
Batch: 540; loss: 1.59; acc: 0.47
Batch: 560; loss: 1.75; acc: 0.5
Batch: 580; loss: 1.59; acc: 0.52
Batch: 600; loss: 1.55; acc: 0.62
Batch: 620; loss: 1.65; acc: 0.41
Batch: 640; loss: 1.5; acc: 0.56
Batch: 660; loss: 1.58; acc: 0.47
Batch: 680; loss: 1.56; acc: 0.53
Batch: 700; loss: 1.53; acc: 0.58
Batch: 720; loss: 1.43; acc: 0.62
Batch: 740; loss: 1.5; acc: 0.45
Batch: 760; loss: 1.58; acc: 0.5
Batch: 780; loss: 1.74; acc: 0.45
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.741243073018268e-05
8.108545443974435e-05
Batch: 0; loss: 1.38; acc: 0.72
Batch: 20; loss: 1.65; acc: 0.47
Batch: 40; loss: 1.29; acc: 0.69
Batch: 60; loss: 1.38; acc: 0.7
Batch: 80; loss: 1.43; acc: 0.55
Batch: 100; loss: 1.56; acc: 0.61
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.37; acc: 0.66
Val Epoch over. val_loss: 1.547497783496881; val_accuracy: 0.5496616242038217 

The current subspace-distance is: 8.108545443974435e-05 

Epoch 30 start
The current lr is: 0.09
Batch: 0; loss: 1.53; acc: 0.55
Batch: 20; loss: 1.51; acc: 0.53
Batch: 40; loss: 1.62; acc: 0.53
Batch: 60; loss: 1.67; acc: 0.48
Batch: 80; loss: 1.74; acc: 0.44
Batch: 100; loss: 1.64; acc: 0.55
Batch: 120; loss: 1.58; acc: 0.5
Batch: 140; loss: 1.64; acc: 0.48
Batch: 160; loss: 1.54; acc: 0.48
Batch: 180; loss: 1.72; acc: 0.44
Batch: 200; loss: 1.58; acc: 0.48
Batch: 220; loss: 1.47; acc: 0.56
Batch: 240; loss: 1.69; acc: 0.5
Batch: 260; loss: 1.66; acc: 0.44
Batch: 280; loss: 1.58; acc: 0.56
Batch: 300; loss: 1.61; acc: 0.53
Batch: 320; loss: 1.61; acc: 0.58
Batch: 340; loss: 1.68; acc: 0.44
Batch: 360; loss: 1.74; acc: 0.47
Batch: 380; loss: 1.79; acc: 0.33
Batch: 400; loss: 1.73; acc: 0.5
Batch: 420; loss: 1.69; acc: 0.42
Batch: 440; loss: 1.79; acc: 0.34
Batch: 460; loss: 1.55; acc: 0.55
Batch: 480; loss: 1.57; acc: 0.53
Batch: 500; loss: 1.59; acc: 0.48
Batch: 520; loss: 1.67; acc: 0.58
Batch: 540; loss: 1.57; acc: 0.44
Batch: 560; loss: 1.55; acc: 0.58
Batch: 580; loss: 1.67; acc: 0.45
Batch: 600; loss: 1.5; acc: 0.55
Batch: 620; loss: 1.66; acc: 0.48
Batch: 640; loss: 1.51; acc: 0.52
Batch: 660; loss: 1.68; acc: 0.5
Batch: 680; loss: 1.67; acc: 0.38
Batch: 700; loss: 1.46; acc: 0.61
Batch: 720; loss: 1.81; acc: 0.42
Batch: 740; loss: 1.63; acc: 0.55
Batch: 760; loss: 1.58; acc: 0.48
Batch: 780; loss: 1.65; acc: 0.47
Train Epoch over. train_loss: 1.59; train_accuracy: 0.51 

8.974520460469648e-05
8.294355211546645e-05
Batch: 0; loss: 1.4; acc: 0.69
Batch: 20; loss: 1.66; acc: 0.53
Batch: 40; loss: 1.29; acc: 0.69
Batch: 60; loss: 1.38; acc: 0.7
Batch: 80; loss: 1.43; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.38; acc: 0.7
Val Epoch over. val_loss: 1.5534577111529697; val_accuracy: 0.5473726114649682 

The current subspace-distance is: 8.294355211546645e-05 

plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_100_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64

Channel scaling factor: 13.5

The number of parameters is: 279504

The number of individual parameters is:

108
432
108
108
162
52488
162
162
324
157464
324
324
64
62208
64
64
4096
64
640
10
64
64

nonzero elements in E: 55900796
elements in E: 55900800
fraction nonzero: 0.9999999284446734
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.37; acc: 0.11
Batch: 20; loss: 2.12; acc: 0.19
Batch: 40; loss: 2.04; acc: 0.33
Batch: 60; loss: 2.06; acc: 0.23
Batch: 80; loss: 1.97; acc: 0.36
Batch: 100; loss: 2.04; acc: 0.33
Batch: 120; loss: 1.93; acc: 0.38
Batch: 140; loss: 1.83; acc: 0.44
Batch: 160; loss: 1.93; acc: 0.39
Batch: 180; loss: 1.87; acc: 0.36
Batch: 200; loss: 1.76; acc: 0.5
Batch: 220; loss: 1.92; acc: 0.36
Batch: 240; loss: 1.82; acc: 0.47
Batch: 260; loss: 1.82; acc: 0.47
Batch: 280; loss: 1.67; acc: 0.55
Batch: 300; loss: 1.87; acc: 0.38
Batch: 320; loss: 1.82; acc: 0.39
Batch: 340; loss: 1.85; acc: 0.39
Batch: 360; loss: 1.84; acc: 0.44
Batch: 380; loss: 1.75; acc: 0.45
Batch: 400; loss: 1.79; acc: 0.5
Batch: 420; loss: 1.61; acc: 0.53
Batch: 440; loss: 1.68; acc: 0.48
Batch: 460; loss: 1.77; acc: 0.47
Batch: 480; loss: 1.78; acc: 0.47
Batch: 500; loss: 1.7; acc: 0.48
Batch: 520; loss: 1.76; acc: 0.48
Batch: 540; loss: 1.76; acc: 0.41
Batch: 560; loss: 1.67; acc: 0.45
Batch: 580; loss: 1.65; acc: 0.45
Batch: 600; loss: 1.69; acc: 0.5
Batch: 620; loss: 1.69; acc: 0.52
Batch: 640; loss: 1.99; acc: 0.3
Batch: 660; loss: 1.62; acc: 0.58
Batch: 680; loss: 1.7; acc: 0.45
Batch: 700; loss: 1.7; acc: 0.48
Batch: 720; loss: 1.73; acc: 0.5
Batch: 740; loss: 1.68; acc: 0.55
Batch: 760; loss: 1.72; acc: 0.53
Batch: 780; loss: 1.64; acc: 0.5
Train Epoch over. train_loss: 1.83; train_accuracy: 0.43 

4.614168938132934e-05
3.600372656364925e-05
Batch: 0; loss: 1.66; acc: 0.52
Batch: 20; loss: 1.79; acc: 0.47
Batch: 40; loss: 1.42; acc: 0.66
Batch: 60; loss: 1.52; acc: 0.56
Batch: 80; loss: 1.56; acc: 0.59
Batch: 100; loss: 1.71; acc: 0.58
Batch: 120; loss: 1.75; acc: 0.5
Batch: 140; loss: 1.5; acc: 0.75
Val Epoch over. val_loss: 1.6639047982586417; val_accuracy: 0.5197054140127388 

The current subspace-distance is: 3.600372656364925e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.7; acc: 0.47
Batch: 20; loss: 1.69; acc: 0.47
Batch: 40; loss: 1.86; acc: 0.45
Batch: 60; loss: 1.69; acc: 0.52
Batch: 80; loss: 1.72; acc: 0.53
Batch: 100; loss: 1.69; acc: 0.55
Batch: 120; loss: 1.68; acc: 0.5
Batch: 140; loss: 1.59; acc: 0.59
Batch: 160; loss: 1.74; acc: 0.5
Batch: 180; loss: 1.59; acc: 0.61
Batch: 200; loss: 1.64; acc: 0.55
Batch: 220; loss: 1.66; acc: 0.52
Batch: 240; loss: 1.54; acc: 0.67
Batch: 260; loss: 1.6; acc: 0.59
Batch: 280; loss: 1.62; acc: 0.47
Batch: 300; loss: 1.54; acc: 0.61
Batch: 320; loss: 1.53; acc: 0.7
Batch: 340; loss: 1.65; acc: 0.52
Batch: 360; loss: 1.73; acc: 0.52
Batch: 380; loss: 1.68; acc: 0.52
Batch: 400; loss: 1.49; acc: 0.66
Batch: 420; loss: 1.59; acc: 0.61
Batch: 440; loss: 1.63; acc: 0.56
Batch: 460; loss: 1.6; acc: 0.48
Batch: 480; loss: 1.46; acc: 0.64
Batch: 500; loss: 1.58; acc: 0.56
Batch: 520; loss: 1.68; acc: 0.52
Batch: 540; loss: 1.62; acc: 0.52
Batch: 560; loss: 1.64; acc: 0.53
Batch: 580; loss: 1.81; acc: 0.36
Batch: 600; loss: 1.6; acc: 0.52
Batch: 620; loss: 1.55; acc: 0.55
Batch: 640; loss: 1.74; acc: 0.36
Batch: 660; loss: 1.51; acc: 0.59
Batch: 680; loss: 1.49; acc: 0.58
Batch: 700; loss: 1.7; acc: 0.48
Batch: 720; loss: 1.56; acc: 0.5
Batch: 740; loss: 1.47; acc: 0.62
Batch: 760; loss: 1.46; acc: 0.61
Batch: 780; loss: 1.54; acc: 0.52
Train Epoch over. train_loss: 1.64; train_accuracy: 0.52 

5.704635987058282e-05
4.8413134209113196e-05
Batch: 0; loss: 1.49; acc: 0.55
Batch: 20; loss: 1.75; acc: 0.5
Batch: 40; loss: 1.32; acc: 0.66
Batch: 60; loss: 1.39; acc: 0.67
Batch: 80; loss: 1.52; acc: 0.58
Batch: 100; loss: 1.62; acc: 0.58
Batch: 120; loss: 1.65; acc: 0.52
Batch: 140; loss: 1.38; acc: 0.75
Val Epoch over. val_loss: 1.5650435655739656; val_accuracy: 0.5494625796178344 

The current subspace-distance is: 4.8413134209113196e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.71; acc: 0.5
Batch: 20; loss: 1.53; acc: 0.64
Batch: 40; loss: 1.61; acc: 0.59
Batch: 60; loss: 1.49; acc: 0.59
Batch: 80; loss: 1.63; acc: 0.44
Batch: 100; loss: 1.61; acc: 0.56
Batch: 120; loss: 1.62; acc: 0.55
Batch: 140; loss: 1.58; acc: 0.52
Batch: 160; loss: 1.61; acc: 0.5
Batch: 180; loss: 1.65; acc: 0.45
Batch: 200; loss: 1.46; acc: 0.62
Batch: 220; loss: 1.66; acc: 0.45
Batch: 240; loss: 1.56; acc: 0.58
Batch: 260; loss: 1.66; acc: 0.48
Batch: 280; loss: 1.6; acc: 0.52
Batch: 300; loss: 1.63; acc: 0.5
Batch: 320; loss: 1.69; acc: 0.44
Batch: 340; loss: 1.39; acc: 0.72
Batch: 360; loss: 1.55; acc: 0.58
Batch: 380; loss: 1.65; acc: 0.52
Batch: 400; loss: 1.63; acc: 0.58
Batch: 420; loss: 1.52; acc: 0.55
Batch: 440; loss: 1.53; acc: 0.55
Batch: 460; loss: 1.42; acc: 0.67
Batch: 480; loss: 1.54; acc: 0.58
Batch: 500; loss: 1.53; acc: 0.5
Batch: 520; loss: 1.42; acc: 0.62
Batch: 540; loss: 1.54; acc: 0.52
Batch: 560; loss: 1.68; acc: 0.44
Batch: 580; loss: 1.54; acc: 0.53
Batch: 600; loss: 1.37; acc: 0.66
Batch: 620; loss: 1.62; acc: 0.58
Batch: 640; loss: 1.63; acc: 0.55
Batch: 660; loss: 1.37; acc: 0.67
Batch: 680; loss: 1.52; acc: 0.58
Batch: 700; loss: 1.42; acc: 0.67
Batch: 720; loss: 1.53; acc: 0.53
Batch: 740; loss: 1.48; acc: 0.61
Batch: 760; loss: 1.52; acc: 0.53
Batch: 780; loss: 1.59; acc: 0.59
Train Epoch over. train_loss: 1.56; train_accuracy: 0.55 

6.675561598967761e-05
5.923513162997551e-05
Batch: 0; loss: 1.42; acc: 0.64
Batch: 20; loss: 1.63; acc: 0.48
Batch: 40; loss: 1.27; acc: 0.7
Batch: 60; loss: 1.39; acc: 0.62
Batch: 80; loss: 1.38; acc: 0.59
Batch: 100; loss: 1.55; acc: 0.66
Batch: 120; loss: 1.6; acc: 0.56
Batch: 140; loss: 1.36; acc: 0.75
Val Epoch over. val_loss: 1.5059176615089367; val_accuracy: 0.5879777070063694 

The current subspace-distance is: 5.923513162997551e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.6; acc: 0.53
Batch: 20; loss: 1.63; acc: 0.55
Batch: 40; loss: 1.53; acc: 0.59
Batch: 60; loss: 1.52; acc: 0.59
Batch: 80; loss: 1.54; acc: 0.61
Batch: 100; loss: 1.54; acc: 0.58
Batch: 120; loss: 1.56; acc: 0.55
Batch: 140; loss: 1.69; acc: 0.48
Batch: 160; loss: 1.45; acc: 0.64
Batch: 180; loss: 1.5; acc: 0.61
Batch: 200; loss: 1.48; acc: 0.61
Batch: 220; loss: 1.59; acc: 0.56
Batch: 240; loss: 1.55; acc: 0.53
Batch: 260; loss: 1.51; acc: 0.5
Batch: 280; loss: 1.53; acc: 0.62
Batch: 300; loss: 1.43; acc: 0.58
Batch: 320; loss: 1.58; acc: 0.53
Batch: 340; loss: 1.42; acc: 0.58
Batch: 360; loss: 1.55; acc: 0.53
Batch: 380; loss: 1.64; acc: 0.52
Batch: 400; loss: 1.62; acc: 0.55
Batch: 420; loss: 1.66; acc: 0.42
Batch: 440; loss: 1.62; acc: 0.52
Batch: 460; loss: 1.44; acc: 0.7
Batch: 480; loss: 1.65; acc: 0.52
Batch: 500; loss: 1.46; acc: 0.58
Batch: 520; loss: 1.45; acc: 0.59
Batch: 540; loss: 1.49; acc: 0.67
Batch: 560; loss: 1.69; acc: 0.45
Batch: 580; loss: 1.59; acc: 0.48
Batch: 600; loss: 1.83; acc: 0.42
Batch: 620; loss: 1.39; acc: 0.66
Batch: 640; loss: 1.51; acc: 0.59
Batch: 660; loss: 1.61; acc: 0.52
Batch: 680; loss: 1.46; acc: 0.58
Batch: 700; loss: 1.42; acc: 0.61
Batch: 720; loss: 1.61; acc: 0.55
Batch: 740; loss: 1.58; acc: 0.56
Batch: 760; loss: 1.49; acc: 0.61
Batch: 780; loss: 1.55; acc: 0.56
Train Epoch over. train_loss: 1.53; train_accuracy: 0.56 

7.403620838886127e-05
6.709361332468688e-05
Batch: 0; loss: 1.47; acc: 0.66
Batch: 20; loss: 1.76; acc: 0.39
Batch: 40; loss: 1.37; acc: 0.62
Batch: 60; loss: 1.47; acc: 0.55
Batch: 80; loss: 1.43; acc: 0.58
Batch: 100; loss: 1.58; acc: 0.58
Batch: 120; loss: 1.71; acc: 0.47
Batch: 140; loss: 1.46; acc: 0.59
Val Epoch over. val_loss: 1.557548171395709; val_accuracy: 0.5346337579617835 

The current subspace-distance is: 6.709361332468688e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.44; acc: 0.58
Batch: 20; loss: 1.48; acc: 0.56
Batch: 40; loss: 1.6; acc: 0.5
Batch: 60; loss: 1.45; acc: 0.62
Batch: 80; loss: 1.48; acc: 0.69
Batch: 100; loss: 1.45; acc: 0.69
Batch: 120; loss: 1.48; acc: 0.59
Batch: 140; loss: 1.48; acc: 0.66
Batch: 160; loss: 1.56; acc: 0.55
Batch: 180; loss: 1.55; acc: 0.53
Batch: 200; loss: 1.52; acc: 0.58
Batch: 220; loss: 1.46; acc: 0.62
Batch: 240; loss: 1.67; acc: 0.48
Batch: 260; loss: 1.56; acc: 0.47
Batch: 280; loss: 1.57; acc: 0.58
Batch: 300; loss: 1.63; acc: 0.55
Batch: 320; loss: 1.37; acc: 0.66
Batch: 340; loss: 1.55; acc: 0.55
Batch: 360; loss: 1.59; acc: 0.5
Batch: 380; loss: 1.47; acc: 0.58
Batch: 400; loss: 1.65; acc: 0.48
Batch: 420; loss: 1.83; acc: 0.42
Batch: 440; loss: 1.62; acc: 0.52
Batch: 460; loss: 1.38; acc: 0.64
Batch: 480; loss: 1.53; acc: 0.55
Batch: 500; loss: 1.58; acc: 0.56
Batch: 520; loss: 1.37; acc: 0.66
Batch: 540; loss: 1.58; acc: 0.53
Batch: 560; loss: 1.45; acc: 0.62
Batch: 580; loss: 1.35; acc: 0.69
Batch: 600; loss: 1.55; acc: 0.64
Batch: 620; loss: 1.45; acc: 0.66
Batch: 640; loss: 1.32; acc: 0.62
Batch: 660; loss: 1.52; acc: 0.56
Batch: 680; loss: 1.53; acc: 0.53
Batch: 700; loss: 1.43; acc: 0.55
Batch: 720; loss: 1.75; acc: 0.45
Batch: 740; loss: 1.49; acc: 0.58
Batch: 760; loss: 1.51; acc: 0.59
Batch: 780; loss: 1.54; acc: 0.48
Train Epoch over. train_loss: 1.51; train_accuracy: 0.57 

7.786331116221845e-05
7.215354708023369e-05
Batch: 0; loss: 1.43; acc: 0.59
Batch: 20; loss: 1.81; acc: 0.41
Batch: 40; loss: 1.35; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.45
Batch: 80; loss: 1.39; acc: 0.55
Batch: 100; loss: 1.56; acc: 0.61
Batch: 120; loss: 1.72; acc: 0.52
Batch: 140; loss: 1.45; acc: 0.55
Val Epoch over. val_loss: 1.6019543857331489; val_accuracy: 0.492734872611465 

The current subspace-distance is: 7.215354708023369e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.5; acc: 0.55
Batch: 20; loss: 1.5; acc: 0.59
Batch: 40; loss: 1.44; acc: 0.59
Batch: 60; loss: 1.36; acc: 0.66
Batch: 80; loss: 1.47; acc: 0.53
Batch: 100; loss: 1.38; acc: 0.62
Batch: 120; loss: 1.47; acc: 0.59
Batch: 140; loss: 1.35; acc: 0.7
Batch: 160; loss: 1.54; acc: 0.61
Batch: 180; loss: 1.47; acc: 0.52
Batch: 200; loss: 1.42; acc: 0.66
Batch: 220; loss: 1.44; acc: 0.66
Batch: 240; loss: 1.61; acc: 0.48
Batch: 260; loss: 1.25; acc: 0.73
Batch: 280; loss: 1.43; acc: 0.61
Batch: 300; loss: 1.65; acc: 0.56
Batch: 320; loss: 1.6; acc: 0.42
Batch: 340; loss: 1.42; acc: 0.66
Batch: 360; loss: 1.59; acc: 0.53
Batch: 380; loss: 1.43; acc: 0.64
Batch: 400; loss: 1.47; acc: 0.61
Batch: 420; loss: 1.29; acc: 0.67
Batch: 440; loss: 1.49; acc: 0.56
Batch: 460; loss: 1.69; acc: 0.44
Batch: 480; loss: 1.59; acc: 0.58
Batch: 500; loss: 1.52; acc: 0.5
Batch: 520; loss: 1.55; acc: 0.5
Batch: 540; loss: 1.42; acc: 0.62
Batch: 560; loss: 1.42; acc: 0.66
Batch: 580; loss: 1.57; acc: 0.56
Batch: 600; loss: 1.33; acc: 0.67
Batch: 620; loss: 1.46; acc: 0.64
Batch: 640; loss: 1.52; acc: 0.48
Batch: 660; loss: 1.49; acc: 0.56
Batch: 680; loss: 1.52; acc: 0.62
Batch: 700; loss: 1.49; acc: 0.62
Batch: 720; loss: 1.54; acc: 0.55
Batch: 740; loss: 1.34; acc: 0.64
Batch: 760; loss: 1.63; acc: 0.48
Batch: 780; loss: 1.47; acc: 0.61
Train Epoch over. train_loss: 1.48; train_accuracy: 0.58 

8.36040053400211e-05
7.705648749833927e-05
Batch: 0; loss: 1.4; acc: 0.61
Batch: 20; loss: 1.75; acc: 0.5
Batch: 40; loss: 1.33; acc: 0.67
Batch: 60; loss: 1.45; acc: 0.58
Batch: 80; loss: 1.4; acc: 0.5
Batch: 100; loss: 1.49; acc: 0.61
Batch: 120; loss: 1.57; acc: 0.58
Batch: 140; loss: 1.35; acc: 0.67
Val Epoch over. val_loss: 1.5362719175921884; val_accuracy: 0.5451831210191083 

The current subspace-distance is: 7.705648749833927e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.51; acc: 0.53
Batch: 20; loss: 1.49; acc: 0.58
Batch: 40; loss: 1.57; acc: 0.55
Batch: 60; loss: 1.48; acc: 0.55
Batch: 80; loss: 1.4; acc: 0.67
Batch: 100; loss: 1.54; acc: 0.53
Batch: 120; loss: 1.48; acc: 0.62
Batch: 140; loss: 1.32; acc: 0.58
Batch: 160; loss: 1.5; acc: 0.61
Batch: 180; loss: 1.41; acc: 0.66
Batch: 200; loss: 1.36; acc: 0.72
Batch: 220; loss: 1.46; acc: 0.58
Batch: 240; loss: 1.6; acc: 0.47
Batch: 260; loss: 1.51; acc: 0.56
Batch: 280; loss: 1.46; acc: 0.61
Batch: 300; loss: 1.48; acc: 0.59
Batch: 320; loss: 1.63; acc: 0.45
Batch: 340; loss: 1.4; acc: 0.64
Batch: 360; loss: 1.44; acc: 0.62
Batch: 380; loss: 1.36; acc: 0.62
Batch: 400; loss: 1.43; acc: 0.61
Batch: 420; loss: 1.54; acc: 0.58
Batch: 440; loss: 1.39; acc: 0.58
Batch: 460; loss: 1.52; acc: 0.55
Batch: 480; loss: 1.63; acc: 0.52
Batch: 500; loss: 1.31; acc: 0.7
Batch: 520; loss: 1.44; acc: 0.62
Batch: 540; loss: 1.51; acc: 0.55
Batch: 560; loss: 1.56; acc: 0.55
Batch: 580; loss: 1.42; acc: 0.62
Batch: 600; loss: 1.54; acc: 0.53
Batch: 620; loss: 1.58; acc: 0.56
Batch: 640; loss: 1.45; acc: 0.62
Batch: 660; loss: 1.3; acc: 0.62
Batch: 680; loss: 1.4; acc: 0.56
Batch: 700; loss: 1.43; acc: 0.62
Batch: 720; loss: 1.48; acc: 0.62
Batch: 740; loss: 1.5; acc: 0.5
Batch: 760; loss: 1.47; acc: 0.59
Batch: 780; loss: 1.39; acc: 0.67
Train Epoch over. train_loss: 1.46; train_accuracy: 0.59 

8.84431938175112e-05
8.235163113567978e-05
Batch: 0; loss: 1.43; acc: 0.59
Batch: 20; loss: 1.57; acc: 0.52
Batch: 40; loss: 1.31; acc: 0.66
Batch: 60; loss: 1.37; acc: 0.66
Batch: 80; loss: 1.48; acc: 0.56
Batch: 100; loss: 1.54; acc: 0.59
Batch: 120; loss: 1.54; acc: 0.55
Batch: 140; loss: 1.28; acc: 0.75
Val Epoch over. val_loss: 1.4761801160824526; val_accuracy: 0.5869824840764332 

The current subspace-distance is: 8.235163113567978e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.48; acc: 0.58
Batch: 20; loss: 1.31; acc: 0.72
Batch: 40; loss: 1.59; acc: 0.53
Batch: 60; loss: 1.33; acc: 0.7
Batch: 80; loss: 1.49; acc: 0.59
Batch: 100; loss: 1.41; acc: 0.61
Batch: 120; loss: 1.4; acc: 0.61
Batch: 140; loss: 1.41; acc: 0.64
Batch: 160; loss: 1.54; acc: 0.52
Batch: 180; loss: 1.33; acc: 0.75
Batch: 200; loss: 1.48; acc: 0.58
Batch: 220; loss: 1.38; acc: 0.55
Batch: 240; loss: 1.52; acc: 0.52
Batch: 260; loss: 1.4; acc: 0.66
Batch: 280; loss: 1.6; acc: 0.52
Batch: 300; loss: 1.39; acc: 0.62
Batch: 320; loss: 1.56; acc: 0.53
Batch: 340; loss: 1.29; acc: 0.66
Batch: 360; loss: 1.35; acc: 0.72
Batch: 380; loss: 1.31; acc: 0.62
Batch: 400; loss: 1.54; acc: 0.59
Batch: 420; loss: 1.29; acc: 0.7
Batch: 440; loss: 1.58; acc: 0.52
Batch: 460; loss: 1.4; acc: 0.66
Batch: 480; loss: 1.44; acc: 0.56
Batch: 500; loss: 1.55; acc: 0.55
Batch: 520; loss: 1.39; acc: 0.62
Batch: 540; loss: 1.46; acc: 0.53
Batch: 560; loss: 1.4; acc: 0.58
Batch: 580; loss: 1.57; acc: 0.53
Batch: 600; loss: 1.45; acc: 0.58
Batch: 620; loss: 1.36; acc: 0.69
Batch: 640; loss: 1.32; acc: 0.66
Batch: 660; loss: 1.5; acc: 0.53
Batch: 680; loss: 1.49; acc: 0.56
Batch: 700; loss: 1.26; acc: 0.66
Batch: 720; loss: 1.43; acc: 0.61
Batch: 740; loss: 1.41; acc: 0.62
Batch: 760; loss: 1.49; acc: 0.56
Batch: 780; loss: 1.46; acc: 0.52
Train Epoch over. train_loss: 1.44; train_accuracy: 0.59 

9.194378071697429e-05
8.584759052610025e-05
Batch: 0; loss: 1.32; acc: 0.69
Batch: 20; loss: 1.6; acc: 0.47
Batch: 40; loss: 1.26; acc: 0.67
Batch: 60; loss: 1.4; acc: 0.59
Batch: 80; loss: 1.49; acc: 0.52
Batch: 100; loss: 1.42; acc: 0.64
Batch: 120; loss: 1.48; acc: 0.56
Batch: 140; loss: 1.23; acc: 0.75
Val Epoch over. val_loss: 1.4605290859368196; val_accuracy: 0.5757364649681529 

The current subspace-distance is: 8.584759052610025e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.38; acc: 0.59
Batch: 20; loss: 1.46; acc: 0.58
Batch: 40; loss: 1.62; acc: 0.55
Batch: 60; loss: 1.53; acc: 0.55
Batch: 80; loss: 1.34; acc: 0.67
Batch: 100; loss: 1.34; acc: 0.64
Batch: 120; loss: 1.4; acc: 0.62
Batch: 140; loss: 1.52; acc: 0.55
Batch: 160; loss: 1.22; acc: 0.69
Batch: 180; loss: 1.31; acc: 0.69
Batch: 200; loss: 1.32; acc: 0.64
Batch: 220; loss: 1.33; acc: 0.67
Batch: 240; loss: 1.49; acc: 0.53
Batch: 260; loss: 1.5; acc: 0.53
Batch: 280; loss: 1.41; acc: 0.61
Batch: 300; loss: 1.38; acc: 0.55
Batch: 320; loss: 1.53; acc: 0.5
Batch: 340; loss: 1.42; acc: 0.61
Batch: 360; loss: 1.28; acc: 0.69
Batch: 380; loss: 1.36; acc: 0.64
Batch: 400; loss: 1.36; acc: 0.66
Batch: 420; loss: 1.26; acc: 0.67
Batch: 440; loss: 1.35; acc: 0.62
Batch: 460; loss: 1.49; acc: 0.52
Batch: 480; loss: 1.36; acc: 0.64
Batch: 500; loss: 1.46; acc: 0.58
Batch: 520; loss: 1.54; acc: 0.58
Batch: 540; loss: 1.37; acc: 0.64
Batch: 560; loss: 1.37; acc: 0.61
Batch: 580; loss: 1.47; acc: 0.56
Batch: 600; loss: 1.41; acc: 0.64
Batch: 620; loss: 1.46; acc: 0.55
Batch: 640; loss: 1.36; acc: 0.67
Batch: 660; loss: 1.39; acc: 0.62
Batch: 680; loss: 1.5; acc: 0.59
Batch: 700; loss: 1.52; acc: 0.48
Batch: 720; loss: 1.47; acc: 0.56
Batch: 740; loss: 1.43; acc: 0.59
Batch: 760; loss: 1.43; acc: 0.62
Batch: 780; loss: 1.34; acc: 0.61
Train Epoch over. train_loss: 1.41; train_accuracy: 0.6 

9.748029697220773e-05
9.112537372857332e-05
Batch: 0; loss: 1.34; acc: 0.62
Batch: 20; loss: 1.65; acc: 0.52
Batch: 40; loss: 1.3; acc: 0.67
Batch: 60; loss: 1.35; acc: 0.64
Batch: 80; loss: 1.41; acc: 0.58
Batch: 100; loss: 1.45; acc: 0.59
Batch: 120; loss: 1.49; acc: 0.58
Batch: 140; loss: 1.35; acc: 0.64
Val Epoch over. val_loss: 1.507273390034961; val_accuracy: 0.5464769108280255 

The current subspace-distance is: 9.112537372857332e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.39; acc: 0.61
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 1.33; acc: 0.67
Batch: 60; loss: 1.41; acc: 0.66
Batch: 80; loss: 1.36; acc: 0.64
Batch: 100; loss: 1.54; acc: 0.53
Batch: 120; loss: 1.26; acc: 0.7
Batch: 140; loss: 1.46; acc: 0.53
Batch: 160; loss: 1.4; acc: 0.61
Batch: 180; loss: 1.51; acc: 0.58
Batch: 200; loss: 1.47; acc: 0.58
Batch: 220; loss: 1.28; acc: 0.72
Batch: 240; loss: 1.46; acc: 0.56
Batch: 260; loss: 1.32; acc: 0.62
Batch: 280; loss: 1.33; acc: 0.66
Batch: 300; loss: 1.35; acc: 0.62
Batch: 320; loss: 1.49; acc: 0.53
Batch: 340; loss: 1.27; acc: 0.69
Batch: 360; loss: 1.33; acc: 0.62
Batch: 380; loss: 1.23; acc: 0.62
Batch: 400; loss: 1.33; acc: 0.66
Batch: 420; loss: 1.58; acc: 0.53
Batch: 440; loss: 1.39; acc: 0.59
Batch: 460; loss: 1.45; acc: 0.58
Batch: 480; loss: 1.4; acc: 0.55
Batch: 500; loss: 1.31; acc: 0.69
Batch: 520; loss: 1.35; acc: 0.59
Batch: 540; loss: 1.37; acc: 0.56
Batch: 560; loss: 1.42; acc: 0.56
Batch: 580; loss: 1.45; acc: 0.53
Batch: 600; loss: 1.29; acc: 0.66
Batch: 620; loss: 1.47; acc: 0.52
Batch: 640; loss: 1.4; acc: 0.59
Batch: 660; loss: 1.38; acc: 0.64
Batch: 680; loss: 1.23; acc: 0.7
Batch: 700; loss: 1.3; acc: 0.69
Batch: 720; loss: 1.49; acc: 0.58
Batch: 740; loss: 1.21; acc: 0.66
Batch: 760; loss: 1.44; acc: 0.66
Batch: 780; loss: 1.28; acc: 0.62
Train Epoch over. train_loss: 1.39; train_accuracy: 0.61 

0.0001001659402390942
9.372155909659341e-05
Batch: 0; loss: 1.29; acc: 0.66
Batch: 20; loss: 1.58; acc: 0.52
Batch: 40; loss: 1.23; acc: 0.72
Batch: 60; loss: 1.44; acc: 0.52
Batch: 80; loss: 1.35; acc: 0.56
Batch: 100; loss: 1.39; acc: 0.67
Batch: 120; loss: 1.52; acc: 0.5
Batch: 140; loss: 1.26; acc: 0.67
Val Epoch over. val_loss: 1.4613638387364187; val_accuracy: 0.5445859872611465 

The current subspace-distance is: 9.372155909659341e-05 

Epoch 11 start
The current lr is: 0.3
Batch: 0; loss: 1.39; acc: 0.62
Batch: 20; loss: 1.3; acc: 0.66
Batch: 40; loss: 1.26; acc: 0.66
Batch: 60; loss: 1.35; acc: 0.61
Batch: 80; loss: 1.34; acc: 0.72
Batch: 100; loss: 1.24; acc: 0.7
Batch: 120; loss: 1.43; acc: 0.62
Batch: 140; loss: 1.3; acc: 0.59
Batch: 160; loss: 1.61; acc: 0.52
Batch: 180; loss: 1.25; acc: 0.67
Batch: 200; loss: 1.23; acc: 0.7
Batch: 220; loss: 1.24; acc: 0.7
Batch: 240; loss: 1.27; acc: 0.73
Batch: 260; loss: 1.37; acc: 0.66
Batch: 280; loss: 1.42; acc: 0.59
Batch: 300; loss: 1.27; acc: 0.66
Batch: 320; loss: 1.38; acc: 0.56
Batch: 340; loss: 1.44; acc: 0.58
Batch: 360; loss: 1.47; acc: 0.55
Batch: 380; loss: 1.35; acc: 0.66
Batch: 400; loss: 1.53; acc: 0.53
Batch: 420; loss: 1.28; acc: 0.61
Batch: 440; loss: 1.35; acc: 0.66
Batch: 460; loss: 1.36; acc: 0.58
Batch: 480; loss: 1.48; acc: 0.55
Batch: 500; loss: 1.41; acc: 0.55
Batch: 520; loss: 1.41; acc: 0.55
Batch: 540; loss: 1.37; acc: 0.69
Batch: 560; loss: 1.36; acc: 0.61
Batch: 580; loss: 1.29; acc: 0.67
Batch: 600; loss: 1.29; acc: 0.67
Batch: 620; loss: 1.23; acc: 0.62
Batch: 640; loss: 1.35; acc: 0.61
Batch: 660; loss: 1.21; acc: 0.75
Batch: 680; loss: 1.31; acc: 0.64
Batch: 700; loss: 1.43; acc: 0.59
Batch: 720; loss: 1.28; acc: 0.69
Batch: 740; loss: 1.16; acc: 0.78
Batch: 760; loss: 1.33; acc: 0.61
Batch: 780; loss: 1.44; acc: 0.48
Train Epoch over. train_loss: 1.37; train_accuracy: 0.61 

0.00010139610094483942
9.463680908083916e-05
Batch: 0; loss: 1.24; acc: 0.72
Batch: 20; loss: 1.35; acc: 0.66
Batch: 40; loss: 1.11; acc: 0.75
Batch: 60; loss: 1.3; acc: 0.62
Batch: 80; loss: 1.25; acc: 0.64
Batch: 100; loss: 1.29; acc: 0.7
Batch: 120; loss: 1.39; acc: 0.62
Batch: 140; loss: 1.09; acc: 0.8
Val Epoch over. val_loss: 1.3300374495755336; val_accuracy: 0.636843152866242 

The current subspace-distance is: 9.463680908083916e-05 

Epoch 12 start
The current lr is: 0.3
Batch: 0; loss: 1.46; acc: 0.69
Batch: 20; loss: 1.33; acc: 0.64
Batch: 40; loss: 1.18; acc: 0.7
Batch: 60; loss: 1.43; acc: 0.55
Batch: 80; loss: 1.31; acc: 0.73
Batch: 100; loss: 1.22; acc: 0.66
Batch: 120; loss: 1.52; acc: 0.55
Batch: 140; loss: 1.37; acc: 0.58
Batch: 160; loss: 1.54; acc: 0.5
Batch: 180; loss: 1.41; acc: 0.59
Batch: 200; loss: 1.33; acc: 0.62
Batch: 220; loss: 1.41; acc: 0.56
Batch: 240; loss: 1.38; acc: 0.59
Batch: 260; loss: 1.3; acc: 0.72
Batch: 280; loss: 1.45; acc: 0.5
Batch: 300; loss: 1.33; acc: 0.64
Batch: 320; loss: 1.16; acc: 0.73
Batch: 340; loss: 1.47; acc: 0.58
Batch: 360; loss: 1.44; acc: 0.59
Batch: 380; loss: 1.29; acc: 0.73
Batch: 400; loss: 1.43; acc: 0.53
Batch: 420; loss: 1.54; acc: 0.52
Batch: 440; loss: 1.25; acc: 0.61
Batch: 460; loss: 1.62; acc: 0.5
Batch: 480; loss: 1.31; acc: 0.67
Batch: 500; loss: 1.22; acc: 0.66
Batch: 520; loss: 1.37; acc: 0.59
Batch: 540; loss: 1.37; acc: 0.56
Batch: 560; loss: 1.39; acc: 0.58
Batch: 580; loss: 1.42; acc: 0.52
Batch: 600; loss: 1.33; acc: 0.67
Batch: 620; loss: 1.33; acc: 0.64
Batch: 640; loss: 1.3; acc: 0.67
Batch: 660; loss: 1.33; acc: 0.69
Batch: 680; loss: 1.33; acc: 0.66
Batch: 700; loss: 1.27; acc: 0.62
Batch: 720; loss: 1.51; acc: 0.58
Batch: 740; loss: 1.37; acc: 0.62
Batch: 760; loss: 1.44; acc: 0.59
Batch: 780; loss: 1.44; acc: 0.59
Train Epoch over. train_loss: 1.37; train_accuracy: 0.61 

0.00010422378545626998
9.772648627404124e-05
Batch: 0; loss: 1.18; acc: 0.72
Batch: 20; loss: 1.47; acc: 0.53
Batch: 40; loss: 1.07; acc: 0.84
Batch: 60; loss: 1.28; acc: 0.64
Batch: 80; loss: 1.25; acc: 0.69
Batch: 100; loss: 1.31; acc: 0.72
Batch: 120; loss: 1.43; acc: 0.61
Batch: 140; loss: 1.12; acc: 0.78
Val Epoch over. val_loss: 1.342009097907194; val_accuracy: 0.6403264331210191 

The current subspace-distance is: 9.772648627404124e-05 

Epoch 13 start
The current lr is: 0.3
Batch: 0; loss: 1.34; acc: 0.58
Batch: 20; loss: 1.53; acc: 0.47
Batch: 40; loss: 1.29; acc: 0.66
Batch: 60; loss: 1.38; acc: 0.56
Batch: 80; loss: 1.38; acc: 0.64
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.23; acc: 0.64
Batch: 140; loss: 1.4; acc: 0.56
Batch: 160; loss: 1.22; acc: 0.69
Batch: 180; loss: 1.42; acc: 0.56
Batch: 200; loss: 1.28; acc: 0.69
Batch: 220; loss: 1.41; acc: 0.61
Batch: 240; loss: 1.51; acc: 0.53
Batch: 260; loss: 1.41; acc: 0.62
Batch: 280; loss: 1.4; acc: 0.59
Batch: 300; loss: 1.31; acc: 0.7
Batch: 320; loss: 1.28; acc: 0.62
Batch: 340; loss: 1.21; acc: 0.73
Batch: 360; loss: 1.32; acc: 0.59
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.44; acc: 0.59
Batch: 420; loss: 1.53; acc: 0.48
Batch: 440; loss: 1.23; acc: 0.67
Batch: 460; loss: 1.48; acc: 0.56
Batch: 480; loss: 1.31; acc: 0.67
Batch: 500; loss: 1.37; acc: 0.61
Batch: 520; loss: 1.14; acc: 0.75
Batch: 540; loss: 1.28; acc: 0.66
Batch: 560; loss: 1.49; acc: 0.53
Batch: 580; loss: 1.29; acc: 0.64
Batch: 600; loss: 1.19; acc: 0.69
Batch: 620; loss: 1.34; acc: 0.67
Batch: 640; loss: 1.31; acc: 0.64
Batch: 660; loss: 1.28; acc: 0.73
Batch: 680; loss: 1.4; acc: 0.69
Batch: 700; loss: 1.29; acc: 0.66
Batch: 720; loss: 1.33; acc: 0.69
Batch: 740; loss: 1.34; acc: 0.64
Batch: 760; loss: 1.44; acc: 0.55
Batch: 780; loss: 1.42; acc: 0.61
Train Epoch over. train_loss: 1.37; train_accuracy: 0.61 

0.00010487417603144422
9.947193029802293e-05
Batch: 0; loss: 1.22; acc: 0.73
Batch: 20; loss: 1.36; acc: 0.66
Batch: 40; loss: 1.05; acc: 0.81
Batch: 60; loss: 1.2; acc: 0.67
Batch: 80; loss: 1.24; acc: 0.62
Batch: 100; loss: 1.29; acc: 0.72
Batch: 120; loss: 1.39; acc: 0.62
Batch: 140; loss: 1.03; acc: 0.83
Val Epoch over. val_loss: 1.3012972455115834; val_accuracy: 0.6511743630573248 

The current subspace-distance is: 9.947193029802293e-05 

Epoch 14 start
The current lr is: 0.3
Batch: 0; loss: 1.23; acc: 0.69
Batch: 20; loss: 1.4; acc: 0.56
Batch: 40; loss: 1.43; acc: 0.56
Batch: 60; loss: 1.23; acc: 0.64
Batch: 80; loss: 1.4; acc: 0.61
Batch: 100; loss: 1.32; acc: 0.67
Batch: 120; loss: 1.31; acc: 0.64
Batch: 140; loss: 1.3; acc: 0.67
Batch: 160; loss: 1.23; acc: 0.69
Batch: 180; loss: 1.37; acc: 0.55
Batch: 200; loss: 1.42; acc: 0.56
Batch: 220; loss: 1.48; acc: 0.52
Batch: 240; loss: 1.41; acc: 0.56
Batch: 260; loss: 1.29; acc: 0.61
Batch: 280; loss: 1.41; acc: 0.61
Batch: 300; loss: 1.43; acc: 0.58
Batch: 320; loss: 1.37; acc: 0.62
Batch: 340; loss: 1.31; acc: 0.66
Batch: 360; loss: 1.19; acc: 0.72
Batch: 380; loss: 1.46; acc: 0.59
Batch: 400; loss: 1.28; acc: 0.61
Batch: 420; loss: 1.21; acc: 0.75
Batch: 440; loss: 1.26; acc: 0.7
Batch: 460; loss: 1.35; acc: 0.55
Batch: 480; loss: 1.22; acc: 0.69
Batch: 500; loss: 1.17; acc: 0.69
Batch: 520; loss: 1.51; acc: 0.5
Batch: 540; loss: 1.31; acc: 0.59
Batch: 560; loss: 1.31; acc: 0.64
Batch: 580; loss: 1.45; acc: 0.53
Batch: 600; loss: 1.33; acc: 0.62
Batch: 620; loss: 1.48; acc: 0.53
Batch: 640; loss: 1.36; acc: 0.64
Batch: 660; loss: 1.49; acc: 0.56
Batch: 680; loss: 1.35; acc: 0.56
Batch: 700; loss: 1.36; acc: 0.59
Batch: 720; loss: 1.19; acc: 0.72
Batch: 740; loss: 1.36; acc: 0.59
Batch: 760; loss: 1.42; acc: 0.56
Batch: 780; loss: 1.45; acc: 0.58
Train Epoch over. train_loss: 1.36; train_accuracy: 0.61 

0.00010438917524879798
9.825381130212918e-05
Batch: 0; loss: 1.18; acc: 0.77
Batch: 20; loss: 1.43; acc: 0.58
Batch: 40; loss: 1.05; acc: 0.81
Batch: 60; loss: 1.2; acc: 0.7
Batch: 80; loss: 1.24; acc: 0.64
Batch: 100; loss: 1.29; acc: 0.73
Batch: 120; loss: 1.41; acc: 0.61
Batch: 140; loss: 1.03; acc: 0.81
Val Epoch over. val_loss: 1.3105388439384995; val_accuracy: 0.6382364649681529 

The current subspace-distance is: 9.825381130212918e-05 

Epoch 15 start
The current lr is: 0.3
Batch: 0; loss: 1.37; acc: 0.59
Batch: 20; loss: 1.2; acc: 0.7
Batch: 40; loss: 1.33; acc: 0.62
Batch: 60; loss: 1.46; acc: 0.59
Batch: 80; loss: 1.49; acc: 0.52
Batch: 100; loss: 1.32; acc: 0.61
Batch: 120; loss: 1.21; acc: 0.72
Batch: 140; loss: 1.39; acc: 0.56
Batch: 160; loss: 1.41; acc: 0.58
Batch: 180; loss: 1.32; acc: 0.66
Batch: 200; loss: 1.59; acc: 0.45
Batch: 220; loss: 1.44; acc: 0.56
Batch: 240; loss: 1.32; acc: 0.64
Batch: 260; loss: 1.38; acc: 0.56
Batch: 280; loss: 1.2; acc: 0.8
Batch: 300; loss: 1.27; acc: 0.69
Batch: 320; loss: 1.45; acc: 0.62
Batch: 340; loss: 1.36; acc: 0.62
Batch: 360; loss: 1.4; acc: 0.59
Batch: 380; loss: 1.45; acc: 0.5
Batch: 400; loss: 1.41; acc: 0.55
Batch: 420; loss: 1.33; acc: 0.62
Batch: 440; loss: 1.45; acc: 0.62
Batch: 460; loss: 1.44; acc: 0.58
Batch: 480; loss: 1.35; acc: 0.61
Batch: 500; loss: 1.47; acc: 0.55
Batch: 520; loss: 1.39; acc: 0.62
Batch: 540; loss: 1.35; acc: 0.64
Batch: 560; loss: 1.56; acc: 0.52
Batch: 580; loss: 1.21; acc: 0.66
Batch: 600; loss: 1.28; acc: 0.64
Batch: 620; loss: 1.22; acc: 0.62
Batch: 640; loss: 1.2; acc: 0.7
Batch: 660; loss: 1.1; acc: 0.81
Batch: 680; loss: 1.29; acc: 0.61
Batch: 700; loss: 1.27; acc: 0.69
Batch: 720; loss: 1.33; acc: 0.62
Batch: 740; loss: 1.37; acc: 0.62
Batch: 760; loss: 1.36; acc: 0.64
Batch: 780; loss: 1.37; acc: 0.61
Train Epoch over. train_loss: 1.36; train_accuracy: 0.61 

0.0001067226767190732
9.981422772398219e-05
Batch: 0; loss: 1.21; acc: 0.75
Batch: 20; loss: 1.39; acc: 0.62
Batch: 40; loss: 1.06; acc: 0.77
Batch: 60; loss: 1.23; acc: 0.67
Batch: 80; loss: 1.22; acc: 0.62
Batch: 100; loss: 1.29; acc: 0.69
Batch: 120; loss: 1.38; acc: 0.64
Batch: 140; loss: 1.06; acc: 0.78
Val Epoch over. val_loss: 1.3009184530586193; val_accuracy: 0.6484872611464968 

The current subspace-distance is: 9.981422772398219e-05 

Epoch 16 start
The current lr is: 0.3
Batch: 0; loss: 1.44; acc: 0.52
Batch: 20; loss: 1.25; acc: 0.69
Batch: 40; loss: 1.41; acc: 0.59
Batch: 60; loss: 1.37; acc: 0.64
Batch: 80; loss: 1.37; acc: 0.52
Batch: 100; loss: 1.33; acc: 0.67
Batch: 120; loss: 1.35; acc: 0.55
Batch: 140; loss: 1.28; acc: 0.58
Batch: 160; loss: 1.43; acc: 0.56
Batch: 180; loss: 1.25; acc: 0.69
Batch: 200; loss: 1.32; acc: 0.61
Batch: 220; loss: 1.25; acc: 0.69
Batch: 240; loss: 1.4; acc: 0.58
Batch: 260; loss: 1.52; acc: 0.56
Batch: 280; loss: 1.26; acc: 0.56
Batch: 300; loss: 1.24; acc: 0.67
Batch: 320; loss: 1.36; acc: 0.62
Batch: 340; loss: 1.44; acc: 0.56
Batch: 360; loss: 1.38; acc: 0.59
Batch: 380; loss: 1.32; acc: 0.58
Batch: 400; loss: 1.47; acc: 0.53
Batch: 420; loss: 1.39; acc: 0.67
Batch: 440; loss: 1.43; acc: 0.56
Batch: 460; loss: 1.38; acc: 0.62
Batch: 480; loss: 1.38; acc: 0.59
Batch: 500; loss: 1.35; acc: 0.62
Batch: 520; loss: 1.45; acc: 0.55
Batch: 540; loss: 1.21; acc: 0.75
Batch: 560; loss: 1.32; acc: 0.62
Batch: 580; loss: 1.33; acc: 0.59
Batch: 600; loss: 1.46; acc: 0.58
Batch: 620; loss: 1.15; acc: 0.7
Batch: 640; loss: 1.36; acc: 0.55
Batch: 660; loss: 1.22; acc: 0.69
Batch: 680; loss: 1.33; acc: 0.62
Batch: 700; loss: 1.25; acc: 0.62
Batch: 720; loss: 1.35; acc: 0.55
Batch: 740; loss: 1.08; acc: 0.81
Batch: 760; loss: 1.21; acc: 0.66
Batch: 780; loss: 1.34; acc: 0.66
Train Epoch over. train_loss: 1.35; train_accuracy: 0.61 

0.00010798836592584848
0.00010264087904943153
Batch: 0; loss: 1.16; acc: 0.7
Batch: 20; loss: 1.41; acc: 0.61
Batch: 40; loss: 1.05; acc: 0.81
Batch: 60; loss: 1.18; acc: 0.7
Batch: 80; loss: 1.21; acc: 0.58
Batch: 100; loss: 1.3; acc: 0.69
Batch: 120; loss: 1.37; acc: 0.67
Batch: 140; loss: 1.04; acc: 0.83
Val Epoch over. val_loss: 1.3038635550031237; val_accuracy: 0.6370421974522293 

The current subspace-distance is: 0.00010264087904943153 

Epoch 17 start
The current lr is: 0.3
Batch: 0; loss: 1.37; acc: 0.66
Batch: 20; loss: 1.17; acc: 0.72
Batch: 40; loss: 1.35; acc: 0.66
Batch: 60; loss: 1.2; acc: 0.7
Batch: 80; loss: 1.25; acc: 0.67
Batch: 100; loss: 1.47; acc: 0.53
Batch: 120; loss: 1.4; acc: 0.61
Batch: 140; loss: 1.16; acc: 0.77
Batch: 160; loss: 1.41; acc: 0.56
Batch: 180; loss: 1.25; acc: 0.59
Batch: 200; loss: 1.37; acc: 0.58
Batch: 220; loss: 1.37; acc: 0.62
Batch: 240; loss: 1.23; acc: 0.66
Batch: 260; loss: 1.24; acc: 0.69
Batch: 280; loss: 1.25; acc: 0.69
Batch: 300; loss: 1.58; acc: 0.53
Batch: 320; loss: 1.49; acc: 0.48
Batch: 340; loss: 1.57; acc: 0.47
Batch: 360; loss: 1.25; acc: 0.58
Batch: 380; loss: 1.36; acc: 0.58
Batch: 400; loss: 1.34; acc: 0.61
Batch: 420; loss: 1.42; acc: 0.56
Batch: 440; loss: 1.37; acc: 0.58
Batch: 460; loss: 1.51; acc: 0.58
Batch: 480; loss: 1.34; acc: 0.58
Batch: 500; loss: 1.35; acc: 0.66
Batch: 520; loss: 1.27; acc: 0.72
Batch: 540; loss: 1.42; acc: 0.56
Batch: 560; loss: 1.28; acc: 0.67
Batch: 580; loss: 1.36; acc: 0.62
Batch: 600; loss: 1.51; acc: 0.52
Batch: 620; loss: 1.48; acc: 0.52
Batch: 640; loss: 1.37; acc: 0.56
Batch: 660; loss: 1.4; acc: 0.61
Batch: 680; loss: 1.42; acc: 0.53
Batch: 700; loss: 1.48; acc: 0.53
Batch: 720; loss: 1.36; acc: 0.67
Batch: 740; loss: 1.39; acc: 0.58
Batch: 760; loss: 1.15; acc: 0.75
Batch: 780; loss: 1.29; acc: 0.67
Train Epoch over. train_loss: 1.35; train_accuracy: 0.62 

0.0001071367078111507
0.0001001049968181178
Batch: 0; loss: 1.16; acc: 0.72
Batch: 20; loss: 1.49; acc: 0.58
Batch: 40; loss: 1.06; acc: 0.78
Batch: 60; loss: 1.18; acc: 0.69
Batch: 80; loss: 1.25; acc: 0.62
Batch: 100; loss: 1.3; acc: 0.69
Batch: 120; loss: 1.38; acc: 0.64
Batch: 140; loss: 1.05; acc: 0.8
Val Epoch over. val_loss: 1.356378772456175; val_accuracy: 0.5990246815286624 

The current subspace-distance is: 0.0001001049968181178 

Epoch 18 start
The current lr is: 0.3
Batch: 0; loss: 1.2; acc: 0.73
Batch: 20; loss: 1.24; acc: 0.67
Batch: 40; loss: 1.29; acc: 0.69
Batch: 60; loss: 1.37; acc: 0.66
Batch: 80; loss: 1.32; acc: 0.61
Batch: 100; loss: 1.37; acc: 0.61
Batch: 120; loss: 1.36; acc: 0.59
Batch: 140; loss: 1.36; acc: 0.62
Batch: 160; loss: 1.26; acc: 0.64
Batch: 180; loss: 1.4; acc: 0.53
Batch: 200; loss: 1.42; acc: 0.62
Batch: 220; loss: 1.37; acc: 0.56
Batch: 240; loss: 1.2; acc: 0.67
Batch: 260; loss: 1.23; acc: 0.77
Batch: 280; loss: 1.18; acc: 0.67
Batch: 300; loss: 1.53; acc: 0.53
Batch: 320; loss: 1.24; acc: 0.72
Batch: 340; loss: 1.32; acc: 0.61
Batch: 360; loss: 1.24; acc: 0.69
Batch: 380; loss: 1.28; acc: 0.62
Batch: 400; loss: 1.56; acc: 0.48
Batch: 420; loss: 1.32; acc: 0.64
Batch: 440; loss: 1.17; acc: 0.7
Batch: 460; loss: 1.37; acc: 0.53
Batch: 480; loss: 1.32; acc: 0.66
Batch: 500; loss: 1.39; acc: 0.58
Batch: 520; loss: 1.28; acc: 0.61
Batch: 540; loss: 1.22; acc: 0.67
Batch: 560; loss: 1.6; acc: 0.48
Batch: 580; loss: 1.2; acc: 0.72
Batch: 600; loss: 1.39; acc: 0.61
Batch: 620; loss: 1.29; acc: 0.62
Batch: 640; loss: 1.45; acc: 0.59
Batch: 660; loss: 1.62; acc: 0.48
Batch: 680; loss: 1.42; acc: 0.56
Batch: 700; loss: 1.45; acc: 0.52
Batch: 720; loss: 1.4; acc: 0.59
Batch: 740; loss: 1.22; acc: 0.67
Batch: 760; loss: 1.28; acc: 0.67
Batch: 780; loss: 1.38; acc: 0.59
Train Epoch over. train_loss: 1.34; train_accuracy: 0.62 

0.00011042133701266721
0.00010299211135134101
Batch: 0; loss: 1.16; acc: 0.75
Batch: 20; loss: 1.47; acc: 0.58
Batch: 40; loss: 1.02; acc: 0.78
Batch: 60; loss: 1.17; acc: 0.67
Batch: 80; loss: 1.21; acc: 0.59
Batch: 100; loss: 1.29; acc: 0.69
Batch: 120; loss: 1.37; acc: 0.62
Batch: 140; loss: 1.0; acc: 0.8
Val Epoch over. val_loss: 1.3149785444994642; val_accuracy: 0.6198248407643312 

The current subspace-distance is: 0.00010299211135134101 

Epoch 19 start
The current lr is: 0.3
Batch: 0; loss: 1.39; acc: 0.55
Batch: 20; loss: 1.36; acc: 0.64
Batch: 40; loss: 1.41; acc: 0.58
Batch: 60; loss: 1.39; acc: 0.58
Batch: 80; loss: 1.23; acc: 0.69
Batch: 100; loss: 1.41; acc: 0.52
Batch: 120; loss: 1.37; acc: 0.52
Batch: 140; loss: 1.44; acc: 0.5
Batch: 160; loss: 1.48; acc: 0.53
Batch: 180; loss: 1.18; acc: 0.75
Batch: 200; loss: 1.23; acc: 0.61
Batch: 220; loss: 1.26; acc: 0.64
Batch: 240; loss: 1.44; acc: 0.55
Batch: 260; loss: 1.46; acc: 0.64
Batch: 280; loss: 1.23; acc: 0.69
Batch: 300; loss: 1.48; acc: 0.61
Batch: 320; loss: 1.41; acc: 0.5
Batch: 340; loss: 1.49; acc: 0.53
Batch: 360; loss: 1.21; acc: 0.69
Batch: 380; loss: 1.39; acc: 0.56
Batch: 400; loss: 1.38; acc: 0.59
Batch: 420; loss: 1.33; acc: 0.67
Batch: 440; loss: 1.37; acc: 0.61
Batch: 460; loss: 1.41; acc: 0.52
Batch: 480; loss: 1.31; acc: 0.52
Batch: 500; loss: 1.46; acc: 0.62
Batch: 520; loss: 1.29; acc: 0.64
Batch: 540; loss: 1.4; acc: 0.53
Batch: 560; loss: 1.21; acc: 0.72
Batch: 580; loss: 1.29; acc: 0.66
Batch: 600; loss: 1.37; acc: 0.61
Batch: 620; loss: 1.33; acc: 0.61
Batch: 640; loss: 1.36; acc: 0.56
Batch: 660; loss: 1.24; acc: 0.73
Batch: 680; loss: 1.45; acc: 0.62
Batch: 700; loss: 1.33; acc: 0.66
Batch: 720; loss: 1.13; acc: 0.78
Batch: 740; loss: 1.37; acc: 0.62
Batch: 760; loss: 1.21; acc: 0.7
Batch: 780; loss: 1.24; acc: 0.69
Train Epoch over. train_loss: 1.33; train_accuracy: 0.62 

0.00011165788600919768
0.00010585335257928818
Batch: 0; loss: 1.17; acc: 0.72
Batch: 20; loss: 1.39; acc: 0.66
Batch: 40; loss: 1.01; acc: 0.77
Batch: 60; loss: 1.15; acc: 0.72
Batch: 80; loss: 1.23; acc: 0.61
Batch: 100; loss: 1.28; acc: 0.69
Batch: 120; loss: 1.32; acc: 0.7
Batch: 140; loss: 0.98; acc: 0.81
Val Epoch over. val_loss: 1.2781529703717323; val_accuracy: 0.6493829617834395 

The current subspace-distance is: 0.00010585335257928818 

Epoch 20 start
The current lr is: 0.3
Batch: 0; loss: 1.45; acc: 0.58
Batch: 20; loss: 1.43; acc: 0.59
Batch: 40; loss: 1.29; acc: 0.7
Batch: 60; loss: 1.18; acc: 0.67
Batch: 80; loss: 1.25; acc: 0.72
Batch: 100; loss: 1.31; acc: 0.61
Batch: 120; loss: 1.4; acc: 0.61
Batch: 140; loss: 1.24; acc: 0.69
Batch: 160; loss: 1.32; acc: 0.59
Batch: 180; loss: 1.39; acc: 0.67
Batch: 200; loss: 1.54; acc: 0.52
Batch: 220; loss: 1.34; acc: 0.56
Batch: 240; loss: 1.28; acc: 0.67
Batch: 260; loss: 1.27; acc: 0.7
Batch: 280; loss: 1.27; acc: 0.67
Batch: 300; loss: 1.41; acc: 0.56
Batch: 320; loss: 1.32; acc: 0.58
Batch: 340; loss: 1.46; acc: 0.56
Batch: 360; loss: 1.35; acc: 0.58
Batch: 380; loss: 1.35; acc: 0.73
Batch: 400; loss: 1.35; acc: 0.61
Batch: 420; loss: 1.36; acc: 0.64
Batch: 440; loss: 1.23; acc: 0.73
Batch: 460; loss: 1.47; acc: 0.53
Batch: 480; loss: 1.34; acc: 0.66
Batch: 500; loss: 1.37; acc: 0.61
Batch: 520; loss: 1.5; acc: 0.55
Batch: 540; loss: 1.36; acc: 0.58
Batch: 560; loss: 1.37; acc: 0.64
Batch: 580; loss: 1.24; acc: 0.69
Batch: 600; loss: 1.37; acc: 0.59
Batch: 620; loss: 1.47; acc: 0.58
Batch: 640; loss: 1.42; acc: 0.62
Batch: 660; loss: 1.3; acc: 0.64
Batch: 680; loss: 1.27; acc: 0.66
Batch: 700; loss: 1.37; acc: 0.59
Batch: 720; loss: 1.24; acc: 0.69
Batch: 740; loss: 1.25; acc: 0.67
Batch: 760; loss: 1.44; acc: 0.55
Batch: 780; loss: 1.31; acc: 0.64
Train Epoch over. train_loss: 1.33; train_accuracy: 0.62 

0.00011377035843906924
0.00010654947254806757
Batch: 0; loss: 1.16; acc: 0.67
Batch: 20; loss: 1.43; acc: 0.59
Batch: 40; loss: 1.03; acc: 0.8
Batch: 60; loss: 1.16; acc: 0.72
Batch: 80; loss: 1.23; acc: 0.59
Batch: 100; loss: 1.29; acc: 0.7
Batch: 120; loss: 1.33; acc: 0.62
Batch: 140; loss: 1.06; acc: 0.78
Val Epoch over. val_loss: 1.3284837569400763; val_accuracy: 0.6110668789808917 

The current subspace-distance is: 0.00010654947254806757 

Epoch 21 start
The current lr is: 0.09
Batch: 0; loss: 1.46; acc: 0.56
Batch: 20; loss: 1.38; acc: 0.56
Batch: 40; loss: 1.44; acc: 0.56
Batch: 60; loss: 1.33; acc: 0.61
Batch: 80; loss: 1.42; acc: 0.61
Batch: 100; loss: 1.28; acc: 0.67
Batch: 120; loss: 1.25; acc: 0.64
Batch: 140; loss: 1.24; acc: 0.62
Batch: 160; loss: 1.29; acc: 0.64
Batch: 180; loss: 1.33; acc: 0.56
Batch: 200; loss: 1.37; acc: 0.56
Batch: 220; loss: 1.56; acc: 0.61
Batch: 240; loss: 1.31; acc: 0.61
Batch: 260; loss: 1.32; acc: 0.61
Batch: 280; loss: 1.45; acc: 0.5
Batch: 300; loss: 1.35; acc: 0.61
Batch: 320; loss: 1.29; acc: 0.66
Batch: 340; loss: 1.29; acc: 0.64
Batch: 360; loss: 1.3; acc: 0.69
Batch: 380; loss: 1.37; acc: 0.66
Batch: 400; loss: 1.3; acc: 0.7
Batch: 420; loss: 1.37; acc: 0.61
Batch: 440; loss: 1.29; acc: 0.62
Batch: 460; loss: 1.45; acc: 0.53
Batch: 480; loss: 1.38; acc: 0.62
Batch: 500; loss: 1.27; acc: 0.7
Batch: 520; loss: 1.21; acc: 0.61
Batch: 540; loss: 1.37; acc: 0.58
Batch: 560; loss: 1.21; acc: 0.64
Batch: 580; loss: 1.34; acc: 0.61
Batch: 600; loss: 1.2; acc: 0.67
Batch: 620; loss: 1.55; acc: 0.48
Batch: 640; loss: 1.29; acc: 0.62
Batch: 660; loss: 1.24; acc: 0.67
Batch: 680; loss: 1.27; acc: 0.61
Batch: 700; loss: 1.14; acc: 0.75
Batch: 720; loss: 1.26; acc: 0.64
Batch: 740; loss: 1.36; acc: 0.62
Batch: 760; loss: 1.36; acc: 0.59
Batch: 780; loss: 1.39; acc: 0.55
Train Epoch over. train_loss: 1.32; train_accuracy: 0.62 

0.00011354753223713487
0.00010764238686533645
Batch: 0; loss: 1.13; acc: 0.77
Batch: 20; loss: 1.36; acc: 0.64
Batch: 40; loss: 1.0; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.73
Batch: 80; loss: 1.19; acc: 0.62
Batch: 100; loss: 1.29; acc: 0.69
Batch: 120; loss: 1.31; acc: 0.69
Batch: 140; loss: 0.97; acc: 0.81
Val Epoch over. val_loss: 1.2691176666575632; val_accuracy: 0.647890127388535 

The current subspace-distance is: 0.00010764238686533645 

Epoch 22 start
The current lr is: 0.09
Batch: 0; loss: 1.38; acc: 0.58
Batch: 20; loss: 1.42; acc: 0.59
Batch: 40; loss: 1.3; acc: 0.67
Batch: 60; loss: 1.29; acc: 0.64
Batch: 80; loss: 1.33; acc: 0.59
Batch: 100; loss: 1.35; acc: 0.59
Batch: 120; loss: 1.42; acc: 0.56
Batch: 140; loss: 1.17; acc: 0.67
Batch: 160; loss: 1.19; acc: 0.67
Batch: 180; loss: 1.4; acc: 0.59
Batch: 200; loss: 1.3; acc: 0.58
Batch: 220; loss: 1.31; acc: 0.62
Batch: 240; loss: 1.36; acc: 0.61
Batch: 260; loss: 1.3; acc: 0.62
Batch: 280; loss: 1.24; acc: 0.59
Batch: 300; loss: 1.26; acc: 0.64
Batch: 320; loss: 1.28; acc: 0.56
Batch: 340; loss: 1.35; acc: 0.59
Batch: 360; loss: 1.44; acc: 0.55
Batch: 380; loss: 1.3; acc: 0.73
Batch: 400; loss: 1.31; acc: 0.67
Batch: 420; loss: 1.4; acc: 0.59
Batch: 440; loss: 1.4; acc: 0.59
Batch: 460; loss: 1.33; acc: 0.59
Batch: 480; loss: 1.53; acc: 0.48
Batch: 500; loss: 1.39; acc: 0.64
Batch: 520; loss: 1.15; acc: 0.72
Batch: 540; loss: 1.23; acc: 0.66
Batch: 560; loss: 1.24; acc: 0.66
Batch: 580; loss: 1.36; acc: 0.61
Batch: 600; loss: 1.33; acc: 0.67
Batch: 620; loss: 1.23; acc: 0.67
Batch: 640; loss: 1.26; acc: 0.64
Batch: 660; loss: 1.26; acc: 0.62
Batch: 680; loss: 1.33; acc: 0.64
Batch: 700; loss: 1.29; acc: 0.62
Batch: 720; loss: 1.38; acc: 0.58
Batch: 740; loss: 1.27; acc: 0.64
Batch: 760; loss: 1.35; acc: 0.62
Batch: 780; loss: 1.23; acc: 0.66
Train Epoch over. train_loss: 1.32; train_accuracy: 0.63 

0.00011446107237134129
0.0001075819309335202
Batch: 0; loss: 1.16; acc: 0.69
Batch: 20; loss: 1.38; acc: 0.61
Batch: 40; loss: 0.98; acc: 0.78
Batch: 60; loss: 1.14; acc: 0.75
Batch: 80; loss: 1.22; acc: 0.61
Batch: 100; loss: 1.31; acc: 0.69
Batch: 120; loss: 1.35; acc: 0.67
Batch: 140; loss: 0.96; acc: 0.86
Val Epoch over. val_loss: 1.2637132193632186; val_accuracy: 0.658140923566879 

The current subspace-distance is: 0.0001075819309335202 

Epoch 23 start
The current lr is: 0.09
Batch: 0; loss: 1.37; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.67
Batch: 40; loss: 1.3; acc: 0.64
Batch: 60; loss: 1.27; acc: 0.64
Batch: 80; loss: 1.29; acc: 0.62
Batch: 100; loss: 1.27; acc: 0.61
Batch: 120; loss: 1.42; acc: 0.52
Batch: 140; loss: 1.28; acc: 0.61
Batch: 160; loss: 1.42; acc: 0.56
Batch: 180; loss: 1.23; acc: 0.69
Batch: 200; loss: 1.11; acc: 0.75
Batch: 220; loss: 1.32; acc: 0.64
Batch: 240; loss: 1.34; acc: 0.62
Batch: 260; loss: 1.5; acc: 0.58
Batch: 280; loss: 1.3; acc: 0.66
Batch: 300; loss: 1.25; acc: 0.64
Batch: 320; loss: 1.21; acc: 0.66
Batch: 340; loss: 1.31; acc: 0.62
Batch: 360; loss: 1.19; acc: 0.69
Batch: 380; loss: 1.42; acc: 0.52
Batch: 400; loss: 1.33; acc: 0.66
Batch: 420; loss: 1.28; acc: 0.64
Batch: 440; loss: 1.43; acc: 0.55
Batch: 460; loss: 1.24; acc: 0.61
Batch: 480; loss: 1.24; acc: 0.7
Batch: 500; loss: 1.26; acc: 0.62
Batch: 520; loss: 1.48; acc: 0.47
Batch: 540; loss: 1.44; acc: 0.52
Batch: 560; loss: 1.28; acc: 0.69
Batch: 580; loss: 1.35; acc: 0.64
Batch: 600; loss: 1.29; acc: 0.64
Batch: 620; loss: 1.24; acc: 0.67
Batch: 640; loss: 1.43; acc: 0.61
Batch: 660; loss: 1.64; acc: 0.48
Batch: 680; loss: 1.13; acc: 0.73
Batch: 700; loss: 1.33; acc: 0.56
Batch: 720; loss: 1.29; acc: 0.66
Batch: 740; loss: 1.45; acc: 0.56
Batch: 760; loss: 1.34; acc: 0.58
Batch: 780; loss: 1.41; acc: 0.62
Train Epoch over. train_loss: 1.32; train_accuracy: 0.63 

0.0001154355049948208
0.00010937835759250447
Batch: 0; loss: 1.14; acc: 0.73
Batch: 20; loss: 1.34; acc: 0.64
Batch: 40; loss: 0.97; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.7
Batch: 80; loss: 1.2; acc: 0.61
Batch: 100; loss: 1.29; acc: 0.72
Batch: 120; loss: 1.32; acc: 0.69
Batch: 140; loss: 0.95; acc: 0.83
Val Epoch over. val_loss: 1.2574122270960717; val_accuracy: 0.6563495222929936 

The current subspace-distance is: 0.00010937835759250447 

Epoch 24 start
The current lr is: 0.09
Batch: 0; loss: 1.14; acc: 0.7
Batch: 20; loss: 1.26; acc: 0.66
Batch: 40; loss: 1.31; acc: 0.62
Batch: 60; loss: 1.44; acc: 0.53
Batch: 80; loss: 1.33; acc: 0.64
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.4; acc: 0.5
Batch: 140; loss: 1.36; acc: 0.56
Batch: 160; loss: 1.32; acc: 0.64
Batch: 180; loss: 1.32; acc: 0.59
Batch: 200; loss: 1.15; acc: 0.73
Batch: 220; loss: 1.45; acc: 0.64
Batch: 240; loss: 1.32; acc: 0.64
Batch: 260; loss: 1.25; acc: 0.69
Batch: 280; loss: 1.37; acc: 0.59
Batch: 300; loss: 1.41; acc: 0.55
Batch: 320; loss: 1.34; acc: 0.58
Batch: 340; loss: 1.29; acc: 0.55
Batch: 360; loss: 1.28; acc: 0.61
Batch: 380; loss: 1.44; acc: 0.56
Batch: 400; loss: 1.39; acc: 0.62
Batch: 420; loss: 1.26; acc: 0.64
Batch: 440; loss: 1.14; acc: 0.7
Batch: 460; loss: 1.25; acc: 0.7
Batch: 480; loss: 1.51; acc: 0.53
Batch: 500; loss: 1.46; acc: 0.56
Batch: 520; loss: 1.43; acc: 0.58
Batch: 540; loss: 1.3; acc: 0.62
Batch: 560; loss: 1.37; acc: 0.59
Batch: 580; loss: 1.32; acc: 0.62
Batch: 600; loss: 1.3; acc: 0.59
Batch: 620; loss: 1.38; acc: 0.62
Batch: 640; loss: 1.36; acc: 0.62
Batch: 660; loss: 1.39; acc: 0.56
Batch: 680; loss: 1.36; acc: 0.56
Batch: 700; loss: 1.4; acc: 0.62
Batch: 720; loss: 1.23; acc: 0.69
Batch: 740; loss: 1.41; acc: 0.55
Batch: 760; loss: 1.23; acc: 0.72
Batch: 780; loss: 1.22; acc: 0.69
Train Epoch over. train_loss: 1.32; train_accuracy: 0.63 

0.0001158861123258248
0.00011000080849044025
Batch: 0; loss: 1.15; acc: 0.75
Batch: 20; loss: 1.32; acc: 0.69
Batch: 40; loss: 0.99; acc: 0.8
Batch: 60; loss: 1.14; acc: 0.72
Batch: 80; loss: 1.2; acc: 0.66
Batch: 100; loss: 1.3; acc: 0.7
Batch: 120; loss: 1.33; acc: 0.64
Batch: 140; loss: 0.96; acc: 0.81
Val Epoch over. val_loss: 1.2527261756028338; val_accuracy: 0.6624203821656051 

The current subspace-distance is: 0.00011000080849044025 

Epoch 25 start
The current lr is: 0.09
Batch: 0; loss: 1.15; acc: 0.72
Batch: 20; loss: 1.31; acc: 0.64
Batch: 40; loss: 1.39; acc: 0.59
Batch: 60; loss: 1.19; acc: 0.64
Batch: 80; loss: 1.48; acc: 0.56
Batch: 100; loss: 1.41; acc: 0.58
Batch: 120; loss: 1.44; acc: 0.52
Batch: 140; loss: 1.47; acc: 0.56
Batch: 160; loss: 1.24; acc: 0.69
Batch: 180; loss: 1.38; acc: 0.52
Batch: 200; loss: 1.27; acc: 0.61
Batch: 220; loss: 1.42; acc: 0.52
Batch: 240; loss: 1.23; acc: 0.7
Batch: 260; loss: 1.31; acc: 0.64
Batch: 280; loss: 1.23; acc: 0.66
Batch: 300; loss: 1.42; acc: 0.64
Batch: 320; loss: 1.35; acc: 0.67
Batch: 340; loss: 1.39; acc: 0.62
Batch: 360; loss: 1.28; acc: 0.58
Batch: 380; loss: 1.14; acc: 0.73
Batch: 400; loss: 1.45; acc: 0.55
Batch: 420; loss: 1.36; acc: 0.56
Batch: 440; loss: 1.13; acc: 0.67
Batch: 460; loss: 1.24; acc: 0.66
Batch: 480; loss: 1.36; acc: 0.61
Batch: 500; loss: 1.33; acc: 0.59
Batch: 520; loss: 1.44; acc: 0.59
Batch: 540; loss: 1.36; acc: 0.64
Batch: 560; loss: 1.38; acc: 0.5
Batch: 580; loss: 1.3; acc: 0.64
Batch: 600; loss: 1.28; acc: 0.64
Batch: 620; loss: 1.36; acc: 0.5
Batch: 640; loss: 1.46; acc: 0.53
Batch: 660; loss: 1.48; acc: 0.5
Batch: 680; loss: 1.35; acc: 0.67
Batch: 700; loss: 1.24; acc: 0.64
Batch: 720; loss: 1.47; acc: 0.48
Batch: 740; loss: 1.32; acc: 0.64
Batch: 760; loss: 1.25; acc: 0.62
Batch: 780; loss: 1.51; acc: 0.5
Train Epoch over. train_loss: 1.31; train_accuracy: 0.63 

0.00011603740858845413
0.0001090210207621567
Batch: 0; loss: 1.17; acc: 0.73
Batch: 20; loss: 1.35; acc: 0.66
Batch: 40; loss: 0.98; acc: 0.78
Batch: 60; loss: 1.16; acc: 0.67
Batch: 80; loss: 1.22; acc: 0.61
Batch: 100; loss: 1.31; acc: 0.72
Batch: 120; loss: 1.34; acc: 0.64
Batch: 140; loss: 0.97; acc: 0.8
Val Epoch over. val_loss: 1.2634445808495685; val_accuracy: 0.6617237261146497 

The current subspace-distance is: 0.0001090210207621567 

Epoch 26 start
The current lr is: 0.09
Batch: 0; loss: 1.24; acc: 0.69
Batch: 20; loss: 1.28; acc: 0.67
Batch: 40; loss: 1.39; acc: 0.58
Batch: 60; loss: 1.29; acc: 0.61
Batch: 80; loss: 1.32; acc: 0.67
Batch: 100; loss: 1.36; acc: 0.64
Batch: 120; loss: 1.32; acc: 0.64
Batch: 140; loss: 1.27; acc: 0.66
Batch: 160; loss: 1.15; acc: 0.72
Batch: 180; loss: 1.52; acc: 0.5
Batch: 200; loss: 1.47; acc: 0.55
Batch: 220; loss: 1.22; acc: 0.61
Batch: 240; loss: 1.19; acc: 0.66
Batch: 260; loss: 1.17; acc: 0.75
Batch: 280; loss: 1.28; acc: 0.7
Batch: 300; loss: 1.16; acc: 0.69
Batch: 320; loss: 1.2; acc: 0.66
Batch: 340; loss: 1.38; acc: 0.55
Batch: 360; loss: 1.18; acc: 0.59
Batch: 380; loss: 1.31; acc: 0.59
Batch: 400; loss: 1.08; acc: 0.81
Batch: 420; loss: 1.39; acc: 0.56
Batch: 440; loss: 1.3; acc: 0.67
Batch: 460; loss: 1.19; acc: 0.69
Batch: 480; loss: 1.32; acc: 0.61
Batch: 500; loss: 1.32; acc: 0.62
Batch: 520; loss: 1.3; acc: 0.55
Batch: 540; loss: 1.36; acc: 0.62
Batch: 560; loss: 1.25; acc: 0.66
Batch: 580; loss: 1.32; acc: 0.59
Batch: 600; loss: 1.38; acc: 0.56
Batch: 620; loss: 1.15; acc: 0.75
Batch: 640; loss: 1.3; acc: 0.61
Batch: 660; loss: 1.43; acc: 0.62
Batch: 680; loss: 1.52; acc: 0.45
Batch: 700; loss: 1.25; acc: 0.62
Batch: 720; loss: 1.34; acc: 0.61
Batch: 740; loss: 1.15; acc: 0.75
Batch: 760; loss: 1.25; acc: 0.64
Batch: 780; loss: 1.18; acc: 0.75
Train Epoch over. train_loss: 1.31; train_accuracy: 0.63 

0.00011786552931880578
0.00011217544670216739
Batch: 0; loss: 1.15; acc: 0.75
Batch: 20; loss: 1.35; acc: 0.64
Batch: 40; loss: 0.97; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.7
Batch: 80; loss: 1.2; acc: 0.62
Batch: 100; loss: 1.32; acc: 0.69
Batch: 120; loss: 1.33; acc: 0.64
Batch: 140; loss: 0.94; acc: 0.83
Val Epoch over. val_loss: 1.251127388826601; val_accuracy: 0.6604299363057324 

The current subspace-distance is: 0.00011217544670216739 

Epoch 27 start
The current lr is: 0.09
Batch: 0; loss: 1.33; acc: 0.58
Batch: 20; loss: 1.41; acc: 0.55
Batch: 40; loss: 1.36; acc: 0.59
Batch: 60; loss: 1.31; acc: 0.56
Batch: 80; loss: 1.24; acc: 0.66
Batch: 100; loss: 1.36; acc: 0.59
Batch: 120; loss: 1.25; acc: 0.69
Batch: 140; loss: 1.25; acc: 0.64
Batch: 160; loss: 1.28; acc: 0.67
Batch: 180; loss: 1.19; acc: 0.66
Batch: 200; loss: 1.2; acc: 0.73
Batch: 220; loss: 1.1; acc: 0.75
Batch: 240; loss: 1.2; acc: 0.72
Batch: 260; loss: 1.29; acc: 0.59
Batch: 280; loss: 1.08; acc: 0.75
Batch: 300; loss: 1.34; acc: 0.64
Batch: 320; loss: 1.19; acc: 0.67
Batch: 340; loss: 1.27; acc: 0.62
Batch: 360; loss: 1.32; acc: 0.62
Batch: 380; loss: 1.31; acc: 0.62
Batch: 400; loss: 1.39; acc: 0.58
Batch: 420; loss: 1.18; acc: 0.7
Batch: 440; loss: 1.22; acc: 0.61
Batch: 460; loss: 1.29; acc: 0.69
Batch: 480; loss: 1.35; acc: 0.61
Batch: 500; loss: 1.17; acc: 0.69
Batch: 520; loss: 1.16; acc: 0.7
Batch: 540; loss: 1.33; acc: 0.59
Batch: 560; loss: 1.47; acc: 0.59
Batch: 580; loss: 1.33; acc: 0.61
Batch: 600; loss: 1.47; acc: 0.56
Batch: 620; loss: 1.21; acc: 0.69
Batch: 640; loss: 1.47; acc: 0.61
Batch: 660; loss: 1.32; acc: 0.62
Batch: 680; loss: 1.57; acc: 0.5
Batch: 700; loss: 1.2; acc: 0.69
Batch: 720; loss: 1.32; acc: 0.59
Batch: 740; loss: 1.26; acc: 0.62
Batch: 760; loss: 1.21; acc: 0.67
Batch: 780; loss: 1.22; acc: 0.66
Train Epoch over. train_loss: 1.31; train_accuracy: 0.63 

0.00011641115270322189
0.00010991935414494947
Batch: 0; loss: 1.15; acc: 0.73
Batch: 20; loss: 1.35; acc: 0.66
Batch: 40; loss: 0.97; acc: 0.8
Batch: 60; loss: 1.15; acc: 0.72
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.31; acc: 0.73
Batch: 120; loss: 1.34; acc: 0.62
Batch: 140; loss: 0.96; acc: 0.83
Val Epoch over. val_loss: 1.2653180239306894; val_accuracy: 0.6553542993630573 

The current subspace-distance is: 0.00010991935414494947 

Epoch 28 start
The current lr is: 0.09
Batch: 0; loss: 1.31; acc: 0.69
Batch: 20; loss: 1.3; acc: 0.61
Batch: 40; loss: 1.31; acc: 0.56
Batch: 60; loss: 1.19; acc: 0.67
Batch: 80; loss: 1.17; acc: 0.67
Batch: 100; loss: 1.35; acc: 0.62
Batch: 120; loss: 1.41; acc: 0.66
Batch: 140; loss: 1.21; acc: 0.67
Batch: 160; loss: 1.32; acc: 0.56
Batch: 180; loss: 1.27; acc: 0.62
Batch: 200; loss: 1.25; acc: 0.67
Batch: 220; loss: 1.25; acc: 0.62
Batch: 240; loss: 1.24; acc: 0.69
Batch: 260; loss: 1.4; acc: 0.58
Batch: 280; loss: 1.35; acc: 0.64
Batch: 300; loss: 1.28; acc: 0.67
Batch: 320; loss: 1.11; acc: 0.7
Batch: 340; loss: 1.44; acc: 0.55
Batch: 360; loss: 1.31; acc: 0.61
Batch: 380; loss: 1.26; acc: 0.69
Batch: 400; loss: 1.43; acc: 0.61
Batch: 420; loss: 1.35; acc: 0.59
Batch: 440; loss: 1.24; acc: 0.66
Batch: 460; loss: 1.29; acc: 0.61
Batch: 480; loss: 1.31; acc: 0.64
Batch: 500; loss: 1.42; acc: 0.58
Batch: 520; loss: 1.29; acc: 0.58
Batch: 540; loss: 1.37; acc: 0.58
Batch: 560; loss: 1.49; acc: 0.58
Batch: 580; loss: 1.24; acc: 0.7
Batch: 600; loss: 1.12; acc: 0.73
Batch: 620; loss: 1.4; acc: 0.56
Batch: 640; loss: 1.19; acc: 0.73
Batch: 660; loss: 1.38; acc: 0.58
Batch: 680; loss: 1.21; acc: 0.67
Batch: 700; loss: 1.49; acc: 0.55
Batch: 720; loss: 1.35; acc: 0.61
Batch: 740; loss: 1.36; acc: 0.55
Batch: 760; loss: 1.3; acc: 0.61
Batch: 780; loss: 1.43; acc: 0.58
Train Epoch over. train_loss: 1.31; train_accuracy: 0.63 

0.00011730905680451542
0.00011199380969628692
Batch: 0; loss: 1.15; acc: 0.73
Batch: 20; loss: 1.33; acc: 0.64
Batch: 40; loss: 0.97; acc: 0.8
Batch: 60; loss: 1.15; acc: 0.73
Batch: 80; loss: 1.18; acc: 0.62
Batch: 100; loss: 1.3; acc: 0.69
Batch: 120; loss: 1.33; acc: 0.62
Batch: 140; loss: 0.96; acc: 0.81
Val Epoch over. val_loss: 1.249339517514417; val_accuracy: 0.6640127388535032 

The current subspace-distance is: 0.00011199380969628692 

Epoch 29 start
The current lr is: 0.09
Batch: 0; loss: 1.28; acc: 0.62
Batch: 20; loss: 1.35; acc: 0.61
Batch: 40; loss: 1.35; acc: 0.62
Batch: 60; loss: 1.13; acc: 0.77
Batch: 80; loss: 1.15; acc: 0.7
Batch: 100; loss: 1.2; acc: 0.61
Batch: 120; loss: 1.22; acc: 0.64
Batch: 140; loss: 1.25; acc: 0.7
Batch: 160; loss: 1.22; acc: 0.61
Batch: 180; loss: 1.23; acc: 0.67
Batch: 200; loss: 1.49; acc: 0.48
Batch: 220; loss: 1.53; acc: 0.56
Batch: 240; loss: 1.36; acc: 0.64
Batch: 260; loss: 1.11; acc: 0.77
Batch: 280; loss: 1.22; acc: 0.7
Batch: 300; loss: 1.18; acc: 0.7
Batch: 320; loss: 1.26; acc: 0.69
Batch: 340; loss: 1.47; acc: 0.62
Batch: 360; loss: 1.28; acc: 0.59
Batch: 380; loss: 1.41; acc: 0.62
Batch: 400; loss: 1.27; acc: 0.67
Batch: 420; loss: 1.34; acc: 0.64
Batch: 440; loss: 1.29; acc: 0.61
Batch: 460; loss: 1.41; acc: 0.64
Batch: 480; loss: 1.36; acc: 0.69
Batch: 500; loss: 1.42; acc: 0.58
Batch: 520; loss: 1.36; acc: 0.59
Batch: 540; loss: 1.43; acc: 0.53
Batch: 560; loss: 1.39; acc: 0.61
Batch: 580; loss: 1.31; acc: 0.66
Batch: 600; loss: 1.16; acc: 0.73
Batch: 620; loss: 1.31; acc: 0.64
Batch: 640; loss: 1.29; acc: 0.61
Batch: 660; loss: 1.22; acc: 0.72
Batch: 680; loss: 1.34; acc: 0.59
Batch: 700; loss: 1.4; acc: 0.59
Batch: 720; loss: 1.16; acc: 0.69
Batch: 740; loss: 1.15; acc: 0.72
Batch: 760; loss: 1.35; acc: 0.62
Batch: 780; loss: 1.36; acc: 0.67
Train Epoch over. train_loss: 1.31; train_accuracy: 0.63 

0.00011759655899368227
0.00011214100231882185
Batch: 0; loss: 1.18; acc: 0.67
Batch: 20; loss: 1.34; acc: 0.61
Batch: 40; loss: 0.98; acc: 0.78
Batch: 60; loss: 1.17; acc: 0.72
Batch: 80; loss: 1.21; acc: 0.61
Batch: 100; loss: 1.32; acc: 0.67
Batch: 120; loss: 1.34; acc: 0.64
Batch: 140; loss: 0.96; acc: 0.81
Val Epoch over. val_loss: 1.2579956886115347; val_accuracy: 0.6620222929936306 

The current subspace-distance is: 0.00011214100231882185 

Epoch 30 start
The current lr is: 0.09
Batch: 0; loss: 1.45; acc: 0.61
Batch: 20; loss: 1.31; acc: 0.64
Batch: 40; loss: 1.43; acc: 0.55
Batch: 60; loss: 1.29; acc: 0.59
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.53; acc: 0.5
Batch: 140; loss: 1.23; acc: 0.64
Batch: 160; loss: 1.23; acc: 0.7
Batch: 180; loss: 1.21; acc: 0.66
Batch: 200; loss: 1.27; acc: 0.62
Batch: 220; loss: 1.18; acc: 0.69
Batch: 240; loss: 1.36; acc: 0.58
Batch: 260; loss: 1.29; acc: 0.66
Batch: 280; loss: 1.23; acc: 0.67
Batch: 300; loss: 1.29; acc: 0.61
Batch: 320; loss: 1.63; acc: 0.41
Batch: 340; loss: 1.41; acc: 0.58
Batch: 360; loss: 1.41; acc: 0.59
Batch: 380; loss: 1.21; acc: 0.67
Batch: 400; loss: 1.49; acc: 0.59
Batch: 420; loss: 1.28; acc: 0.64
Batch: 440; loss: 1.42; acc: 0.52
Batch: 460; loss: 1.29; acc: 0.7
Batch: 480; loss: 1.31; acc: 0.64
Batch: 500; loss: 1.22; acc: 0.67
Batch: 520; loss: 1.36; acc: 0.67
Batch: 540; loss: 1.17; acc: 0.67
Batch: 560; loss: 1.14; acc: 0.78
Batch: 580; loss: 1.31; acc: 0.64
Batch: 600; loss: 1.26; acc: 0.62
Batch: 620; loss: 1.46; acc: 0.56
Batch: 640; loss: 1.23; acc: 0.66
Batch: 660; loss: 1.43; acc: 0.58
Batch: 680; loss: 1.31; acc: 0.53
Batch: 700; loss: 1.41; acc: 0.53
Batch: 720; loss: 1.42; acc: 0.56
Batch: 740; loss: 1.18; acc: 0.62
Batch: 760; loss: 1.23; acc: 0.72
Batch: 780; loss: 1.24; acc: 0.66
Train Epoch over. train_loss: 1.31; train_accuracy: 0.63 

0.00011832495511043817
0.00011097046808572486
Batch: 0; loss: 1.15; acc: 0.73
Batch: 20; loss: 1.33; acc: 0.67
Batch: 40; loss: 0.96; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.72
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.31; acc: 0.72
Batch: 120; loss: 1.33; acc: 0.62
Batch: 140; loss: 0.95; acc: 0.84
Val Epoch over. val_loss: 1.248654373891794; val_accuracy: 0.6618232484076433 

The current subspace-distance is: 0.00011097046808572486 

plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_200_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64

Channel scaling factor: 13.5

The number of parameters is: 279504

The number of individual parameters is:

108
432
108
108
162
52488
162
162
324
157464
324
324
64
62208
64
64
4096
64
640
10
64
64

nonzero elements in E: 83851192
elements in E: 83851200
fraction nonzero: 0.9999999045928979
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.48; acc: 0.05
Batch: 20; loss: 2.12; acc: 0.2
Batch: 40; loss: 2.09; acc: 0.2
Batch: 60; loss: 2.04; acc: 0.25
Batch: 80; loss: 1.96; acc: 0.38
Batch: 100; loss: 1.91; acc: 0.34
Batch: 120; loss: 1.97; acc: 0.36
Batch: 140; loss: 1.93; acc: 0.38
Batch: 160; loss: 2.08; acc: 0.23
Batch: 180; loss: 1.64; acc: 0.53
Batch: 200; loss: 1.89; acc: 0.38
Batch: 220; loss: 1.64; acc: 0.62
Batch: 240; loss: 1.8; acc: 0.44
Batch: 260; loss: 1.66; acc: 0.59
Batch: 280; loss: 1.71; acc: 0.44
Batch: 300; loss: 1.64; acc: 0.47
Batch: 320; loss: 1.62; acc: 0.5
Batch: 340; loss: 1.65; acc: 0.58
Batch: 360; loss: 1.63; acc: 0.53
Batch: 380; loss: 1.59; acc: 0.58
Batch: 400; loss: 1.59; acc: 0.52
Batch: 420; loss: 1.74; acc: 0.45
Batch: 440; loss: 1.77; acc: 0.47
Batch: 460; loss: 1.78; acc: 0.36
Batch: 480; loss: 1.56; acc: 0.58
Batch: 500; loss: 1.65; acc: 0.44
Batch: 520; loss: 1.47; acc: 0.56
Batch: 540; loss: 1.53; acc: 0.61
Batch: 560; loss: 1.54; acc: 0.61
Batch: 580; loss: 1.53; acc: 0.58
Batch: 600; loss: 1.67; acc: 0.47
Batch: 620; loss: 1.48; acc: 0.55
Batch: 640; loss: 1.68; acc: 0.44
Batch: 660; loss: 1.68; acc: 0.48
Batch: 680; loss: 1.61; acc: 0.53
Batch: 700; loss: 1.66; acc: 0.47
Batch: 720; loss: 1.47; acc: 0.61
Batch: 740; loss: 1.51; acc: 0.58
Batch: 760; loss: 1.36; acc: 0.64
Batch: 780; loss: 1.47; acc: 0.61
Train Epoch over. train_loss: 1.69; train_accuracy: 0.49 

5.3903157095192e-05
4.5736444008070976e-05
Batch: 0; loss: 1.46; acc: 0.55
Batch: 20; loss: 1.75; acc: 0.41
Batch: 40; loss: 1.27; acc: 0.62
Batch: 60; loss: 1.4; acc: 0.55
Batch: 80; loss: 1.53; acc: 0.48
Batch: 100; loss: 1.53; acc: 0.61
Batch: 120; loss: 1.6; acc: 0.56
Batch: 140; loss: 1.4; acc: 0.59
Val Epoch over. val_loss: 1.5307237031353507; val_accuracy: 0.5379179936305732 

The current subspace-distance is: 4.5736444008070976e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.48; acc: 0.58
Batch: 20; loss: 1.62; acc: 0.52
Batch: 40; loss: 1.55; acc: 0.48
Batch: 60; loss: 1.44; acc: 0.61
Batch: 80; loss: 1.45; acc: 0.59
Batch: 100; loss: 1.5; acc: 0.58
Batch: 120; loss: 1.62; acc: 0.58
Batch: 140; loss: 1.37; acc: 0.67
Batch: 160; loss: 1.29; acc: 0.77
Batch: 180; loss: 1.71; acc: 0.42
Batch: 200; loss: 1.44; acc: 0.55
Batch: 220; loss: 1.35; acc: 0.61
Batch: 240; loss: 1.51; acc: 0.59
Batch: 260; loss: 1.44; acc: 0.59
Batch: 280; loss: 1.6; acc: 0.52
Batch: 300; loss: 1.45; acc: 0.66
Batch: 320; loss: 1.42; acc: 0.69
Batch: 340; loss: 1.41; acc: 0.61
Batch: 360; loss: 1.6; acc: 0.5
Batch: 380; loss: 1.55; acc: 0.55
Batch: 400; loss: 1.23; acc: 0.69
Batch: 420; loss: 1.44; acc: 0.58
Batch: 440; loss: 1.36; acc: 0.64
Batch: 460; loss: 1.36; acc: 0.61
Batch: 480; loss: 1.31; acc: 0.67
Batch: 500; loss: 1.5; acc: 0.55
Batch: 520; loss: 1.57; acc: 0.52
Batch: 540; loss: 1.53; acc: 0.53
Batch: 560; loss: 1.35; acc: 0.7
Batch: 580; loss: 1.32; acc: 0.58
Batch: 600; loss: 1.39; acc: 0.61
Batch: 620; loss: 1.3; acc: 0.66
Batch: 640; loss: 1.5; acc: 0.55
Batch: 660; loss: 1.34; acc: 0.64
Batch: 680; loss: 1.3; acc: 0.67
Batch: 700; loss: 1.42; acc: 0.55
Batch: 720; loss: 1.22; acc: 0.72
Batch: 740; loss: 1.43; acc: 0.64
Batch: 760; loss: 1.3; acc: 0.62
Batch: 780; loss: 1.44; acc: 0.62
Train Epoch over. train_loss: 1.43; train_accuracy: 0.6 

7.200511754490435e-05
6.49628127575852e-05
Batch: 0; loss: 1.24; acc: 0.66
Batch: 20; loss: 1.58; acc: 0.56
Batch: 40; loss: 1.19; acc: 0.61
Batch: 60; loss: 1.28; acc: 0.66
Batch: 80; loss: 1.31; acc: 0.59
Batch: 100; loss: 1.42; acc: 0.61
Batch: 120; loss: 1.5; acc: 0.59
Batch: 140; loss: 1.24; acc: 0.7
Val Epoch over. val_loss: 1.3851625433393344; val_accuracy: 0.6087778662420382 

The current subspace-distance is: 6.49628127575852e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.37; acc: 0.58
Batch: 20; loss: 1.58; acc: 0.45
Batch: 40; loss: 1.5; acc: 0.58
Batch: 60; loss: 1.42; acc: 0.62
Batch: 80; loss: 1.43; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.58
Batch: 120; loss: 1.45; acc: 0.62
Batch: 140; loss: 1.32; acc: 0.69
Batch: 160; loss: 1.27; acc: 0.69
Batch: 180; loss: 1.45; acc: 0.5
Batch: 200; loss: 1.36; acc: 0.61
Batch: 220; loss: 1.28; acc: 0.62
Batch: 240; loss: 1.27; acc: 0.62
Batch: 260; loss: 1.4; acc: 0.58
Batch: 280; loss: 1.31; acc: 0.66
Batch: 300; loss: 1.24; acc: 0.66
Batch: 320; loss: 1.4; acc: 0.61
Batch: 340; loss: 1.57; acc: 0.58
Batch: 360; loss: 1.57; acc: 0.48
Batch: 380; loss: 1.38; acc: 0.59
Batch: 400; loss: 1.31; acc: 0.62
Batch: 420; loss: 1.23; acc: 0.66
Batch: 440; loss: 1.23; acc: 0.62
Batch: 460; loss: 1.41; acc: 0.55
Batch: 480; loss: 1.29; acc: 0.66
Batch: 500; loss: 1.45; acc: 0.58
Batch: 520; loss: 1.41; acc: 0.59
Batch: 540; loss: 1.22; acc: 0.67
Batch: 560; loss: 1.28; acc: 0.67
Batch: 580; loss: 1.24; acc: 0.67
Batch: 600; loss: 1.17; acc: 0.66
Batch: 620; loss: 1.24; acc: 0.77
Batch: 640; loss: 1.21; acc: 0.77
Batch: 660; loss: 1.41; acc: 0.64
Batch: 680; loss: 1.29; acc: 0.62
Batch: 700; loss: 1.22; acc: 0.75
Batch: 720; loss: 1.42; acc: 0.53
Batch: 740; loss: 1.34; acc: 0.59
Batch: 760; loss: 1.42; acc: 0.53
Batch: 780; loss: 1.16; acc: 0.72
Train Epoch over. train_loss: 1.33; train_accuracy: 0.63 

8.409184374613687e-05
7.731212099315599e-05
Batch: 0; loss: 1.13; acc: 0.73
Batch: 20; loss: 1.46; acc: 0.58
Batch: 40; loss: 1.04; acc: 0.8
Batch: 60; loss: 1.18; acc: 0.69
Batch: 80; loss: 1.14; acc: 0.72
Batch: 100; loss: 1.27; acc: 0.7
Batch: 120; loss: 1.39; acc: 0.67
Batch: 140; loss: 1.14; acc: 0.77
Val Epoch over. val_loss: 1.2801931003096756; val_accuracy: 0.6765525477707006 

The current subspace-distance is: 7.731212099315599e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.33; acc: 0.66
Batch: 20; loss: 1.18; acc: 0.69
Batch: 40; loss: 1.26; acc: 0.62
Batch: 60; loss: 1.24; acc: 0.66
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.33; acc: 0.69
Batch: 120; loss: 1.22; acc: 0.72
Batch: 140; loss: 1.31; acc: 0.64
Batch: 160; loss: 1.29; acc: 0.66
Batch: 180; loss: 1.26; acc: 0.7
Batch: 200; loss: 1.23; acc: 0.69
Batch: 220; loss: 1.14; acc: 0.75
Batch: 240; loss: 1.15; acc: 0.7
Batch: 260; loss: 1.14; acc: 0.69
Batch: 280; loss: 1.31; acc: 0.64
Batch: 300; loss: 1.35; acc: 0.56
Batch: 320; loss: 1.25; acc: 0.62
Batch: 340; loss: 1.3; acc: 0.66
Batch: 360; loss: 1.45; acc: 0.56
Batch: 380; loss: 1.38; acc: 0.56
Batch: 400; loss: 1.36; acc: 0.62
Batch: 420; loss: 1.41; acc: 0.59
Batch: 440; loss: 1.27; acc: 0.67
Batch: 460; loss: 1.41; acc: 0.61
Batch: 480; loss: 1.29; acc: 0.72
Batch: 500; loss: 1.22; acc: 0.64
Batch: 520; loss: 1.43; acc: 0.55
Batch: 540; loss: 1.18; acc: 0.67
Batch: 560; loss: 1.21; acc: 0.64
Batch: 580; loss: 1.23; acc: 0.72
Batch: 600; loss: 1.32; acc: 0.62
Batch: 620; loss: 1.25; acc: 0.61
Batch: 640; loss: 1.3; acc: 0.62
Batch: 660; loss: 1.2; acc: 0.64
Batch: 680; loss: 1.15; acc: 0.72
Batch: 700; loss: 1.41; acc: 0.58
Batch: 720; loss: 1.27; acc: 0.64
Batch: 740; loss: 1.25; acc: 0.67
Batch: 760; loss: 1.3; acc: 0.67
Batch: 780; loss: 1.24; acc: 0.7
Train Epoch over. train_loss: 1.28; train_accuracy: 0.65 

9.207421680912375e-05
8.547617471776903e-05
Batch: 0; loss: 1.09; acc: 0.75
Batch: 20; loss: 1.53; acc: 0.48
Batch: 40; loss: 1.0; acc: 0.84
Batch: 60; loss: 1.17; acc: 0.7
Batch: 80; loss: 1.09; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.69
Batch: 120; loss: 1.35; acc: 0.64
Batch: 140; loss: 1.12; acc: 0.75
Val Epoch over. val_loss: 1.2814005488043378; val_accuracy: 0.6507762738853503 

The current subspace-distance is: 8.547617471776903e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.34; acc: 0.67
Batch: 20; loss: 1.41; acc: 0.62
Batch: 40; loss: 1.15; acc: 0.69
Batch: 60; loss: 1.18; acc: 0.7
Batch: 80; loss: 1.27; acc: 0.64
Batch: 100; loss: 1.37; acc: 0.58
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 1.44; acc: 0.56
Batch: 160; loss: 1.19; acc: 0.66
Batch: 180; loss: 1.15; acc: 0.69
Batch: 200; loss: 1.2; acc: 0.69
Batch: 220; loss: 1.24; acc: 0.75
Batch: 240; loss: 1.15; acc: 0.7
Batch: 260; loss: 1.23; acc: 0.7
Batch: 280; loss: 1.25; acc: 0.7
Batch: 300; loss: 1.31; acc: 0.66
Batch: 320; loss: 1.3; acc: 0.69
Batch: 340; loss: 1.45; acc: 0.55
Batch: 360; loss: 1.22; acc: 0.7
Batch: 380; loss: 1.1; acc: 0.75
Batch: 400; loss: 1.3; acc: 0.69
Batch: 420; loss: 1.29; acc: 0.7
Batch: 440; loss: 1.16; acc: 0.67
Batch: 460; loss: 0.99; acc: 0.77
Batch: 480; loss: 1.34; acc: 0.61
Batch: 500; loss: 1.11; acc: 0.72
Batch: 520; loss: 1.22; acc: 0.64
Batch: 540; loss: 1.47; acc: 0.52
Batch: 560; loss: 1.48; acc: 0.52
Batch: 580; loss: 1.22; acc: 0.61
Batch: 600; loss: 1.18; acc: 0.69
Batch: 620; loss: 1.08; acc: 0.81
Batch: 640; loss: 1.3; acc: 0.55
Batch: 660; loss: 1.22; acc: 0.7
Batch: 680; loss: 1.25; acc: 0.69
Batch: 700; loss: 1.37; acc: 0.62
Batch: 720; loss: 1.22; acc: 0.73
Batch: 740; loss: 1.18; acc: 0.73
Batch: 760; loss: 1.32; acc: 0.67
Batch: 780; loss: 1.08; acc: 0.77
Train Epoch over. train_loss: 1.25; train_accuracy: 0.66 

0.00010018831380875781
9.34300187509507e-05
Batch: 0; loss: 1.16; acc: 0.72
Batch: 20; loss: 1.41; acc: 0.66
Batch: 40; loss: 1.04; acc: 0.67
Batch: 60; loss: 1.2; acc: 0.67
Batch: 80; loss: 1.12; acc: 0.7
Batch: 100; loss: 1.19; acc: 0.69
Batch: 120; loss: 1.41; acc: 0.61
Batch: 140; loss: 1.19; acc: 0.7
Val Epoch over. val_loss: 1.29151936397431; val_accuracy: 0.6412221337579618 

The current subspace-distance is: 9.34300187509507e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.09; acc: 0.77
Batch: 20; loss: 1.19; acc: 0.7
Batch: 40; loss: 1.07; acc: 0.73
Batch: 60; loss: 1.26; acc: 0.69
Batch: 80; loss: 1.15; acc: 0.7
Batch: 100; loss: 1.07; acc: 0.69
Batch: 120; loss: 1.21; acc: 0.66
Batch: 140; loss: 1.27; acc: 0.66
Batch: 160; loss: 1.06; acc: 0.81
Batch: 180; loss: 1.14; acc: 0.7
Batch: 200; loss: 1.08; acc: 0.8
Batch: 220; loss: 1.22; acc: 0.64
Batch: 240; loss: 1.33; acc: 0.62
Batch: 260; loss: 1.16; acc: 0.72
Batch: 280; loss: 1.33; acc: 0.61
Batch: 300; loss: 1.11; acc: 0.75
Batch: 320; loss: 1.0; acc: 0.78
Batch: 340; loss: 1.16; acc: 0.72
Batch: 360; loss: 1.24; acc: 0.7
Batch: 380; loss: 1.15; acc: 0.7
Batch: 400; loss: 1.37; acc: 0.56
Batch: 420; loss: 1.33; acc: 0.67
Batch: 440; loss: 1.45; acc: 0.53
Batch: 460; loss: 1.25; acc: 0.62
Batch: 480; loss: 1.27; acc: 0.62
Batch: 500; loss: 1.02; acc: 0.77
Batch: 520; loss: 1.3; acc: 0.66
Batch: 540; loss: 1.24; acc: 0.62
Batch: 560; loss: 1.24; acc: 0.7
Batch: 580; loss: 1.34; acc: 0.64
Batch: 600; loss: 1.31; acc: 0.62
Batch: 620; loss: 1.1; acc: 0.69
Batch: 640; loss: 1.25; acc: 0.67
Batch: 660; loss: 1.13; acc: 0.7
Batch: 680; loss: 1.09; acc: 0.8
Batch: 700; loss: 1.25; acc: 0.58
Batch: 720; loss: 1.14; acc: 0.73
Batch: 740; loss: 1.26; acc: 0.59
Batch: 760; loss: 1.24; acc: 0.67
Batch: 780; loss: 1.22; acc: 0.7
Train Epoch over. train_loss: 1.22; train_accuracy: 0.67 

0.00010682173888199031
0.00010037568426923826
Batch: 0; loss: 1.1; acc: 0.78
Batch: 20; loss: 1.64; acc: 0.47
Batch: 40; loss: 1.01; acc: 0.66
Batch: 60; loss: 1.24; acc: 0.67
Batch: 80; loss: 1.07; acc: 0.67
Batch: 100; loss: 1.29; acc: 0.66
Batch: 120; loss: 1.37; acc: 0.59
Batch: 140; loss: 1.2; acc: 0.61
Val Epoch over. val_loss: 1.3267720375850702; val_accuracy: 0.5860867834394905 

The current subspace-distance is: 0.00010037568426923826 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.26; acc: 0.59
Batch: 20; loss: 1.0; acc: 0.77
Batch: 40; loss: 1.28; acc: 0.62
Batch: 60; loss: 1.03; acc: 0.73
Batch: 80; loss: 1.12; acc: 0.69
Batch: 100; loss: 1.22; acc: 0.67
Batch: 120; loss: 1.25; acc: 0.7
Batch: 140; loss: 1.24; acc: 0.66
Batch: 160; loss: 1.23; acc: 0.61
Batch: 180; loss: 1.19; acc: 0.69
Batch: 200; loss: 1.26; acc: 0.67
Batch: 220; loss: 1.25; acc: 0.69
Batch: 240; loss: 1.1; acc: 0.78
Batch: 260; loss: 1.34; acc: 0.58
Batch: 280; loss: 1.09; acc: 0.75
Batch: 300; loss: 1.22; acc: 0.66
Batch: 320; loss: 1.27; acc: 0.67
Batch: 340; loss: 1.26; acc: 0.62
Batch: 360; loss: 1.19; acc: 0.61
Batch: 380; loss: 1.33; acc: 0.59
Batch: 400; loss: 1.1; acc: 0.75
Batch: 420; loss: 1.44; acc: 0.5
Batch: 440; loss: 1.13; acc: 0.7
Batch: 460; loss: 1.28; acc: 0.62
Batch: 480; loss: 1.21; acc: 0.66
Batch: 500; loss: 1.22; acc: 0.69
Batch: 520; loss: 1.01; acc: 0.81
Batch: 540; loss: 1.22; acc: 0.67
Batch: 560; loss: 1.19; acc: 0.69
Batch: 580; loss: 1.46; acc: 0.48
Batch: 600; loss: 1.39; acc: 0.62
Batch: 620; loss: 1.3; acc: 0.62
Batch: 640; loss: 1.0; acc: 0.83
Batch: 660; loss: 1.22; acc: 0.61
Batch: 680; loss: 1.18; acc: 0.69
Batch: 700; loss: 1.01; acc: 0.72
Batch: 720; loss: 1.39; acc: 0.66
Batch: 740; loss: 1.2; acc: 0.66
Batch: 760; loss: 1.0; acc: 0.75
Batch: 780; loss: 1.14; acc: 0.75
Train Epoch over. train_loss: 1.2; train_accuracy: 0.68 

0.00011337501928210258
0.0001068216297426261
Batch: 0; loss: 1.18; acc: 0.73
Batch: 20; loss: 1.42; acc: 0.61
Batch: 40; loss: 0.97; acc: 0.77
Batch: 60; loss: 1.22; acc: 0.73
Batch: 80; loss: 1.1; acc: 0.72
Batch: 100; loss: 1.2; acc: 0.69
Batch: 120; loss: 1.31; acc: 0.66
Batch: 140; loss: 1.14; acc: 0.78
Val Epoch over. val_loss: 1.2543847348280013; val_accuracy: 0.6688893312101911 

The current subspace-distance is: 0.0001068216297426261 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.05; acc: 0.7
Batch: 20; loss: 1.22; acc: 0.67
Batch: 40; loss: 1.1; acc: 0.73
Batch: 60; loss: 1.18; acc: 0.62
Batch: 80; loss: 1.12; acc: 0.77
Batch: 100; loss: 1.16; acc: 0.72
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 1.06; acc: 0.78
Batch: 160; loss: 1.11; acc: 0.69
Batch: 180; loss: 1.2; acc: 0.64
Batch: 200; loss: 1.12; acc: 0.73
Batch: 220; loss: 1.16; acc: 0.69
Batch: 240; loss: 1.3; acc: 0.61
Batch: 260; loss: 1.14; acc: 0.7
Batch: 280; loss: 1.24; acc: 0.64
Batch: 300; loss: 1.18; acc: 0.67
Batch: 320; loss: 1.0; acc: 0.8
Batch: 340; loss: 1.09; acc: 0.73
Batch: 360; loss: 1.28; acc: 0.67
Batch: 380; loss: 1.38; acc: 0.58
Batch: 400; loss: 1.21; acc: 0.67
Batch: 420; loss: 1.17; acc: 0.67
Batch: 440; loss: 1.35; acc: 0.59
Batch: 460; loss: 1.25; acc: 0.66
Batch: 480; loss: 1.28; acc: 0.67
Batch: 500; loss: 1.21; acc: 0.59
Batch: 520; loss: 1.07; acc: 0.78
Batch: 540; loss: 1.23; acc: 0.67
Batch: 560; loss: 1.16; acc: 0.66
Batch: 580; loss: 1.12; acc: 0.73
Batch: 600; loss: 1.15; acc: 0.62
Batch: 620; loss: 1.31; acc: 0.7
Batch: 640; loss: 1.22; acc: 0.66
Batch: 660; loss: 1.16; acc: 0.67
Batch: 680; loss: 1.29; acc: 0.61
Batch: 700; loss: 1.1; acc: 0.69
Batch: 720; loss: 1.3; acc: 0.62
Batch: 740; loss: 1.1; acc: 0.72
Batch: 760; loss: 1.23; acc: 0.66
Batch: 780; loss: 1.2; acc: 0.61
Train Epoch over. train_loss: 1.18; train_accuracy: 0.68 

0.0001194738651975058
0.00011337609612382948
Batch: 0; loss: 1.18; acc: 0.72
Batch: 20; loss: 1.49; acc: 0.52
Batch: 40; loss: 1.04; acc: 0.72
Batch: 60; loss: 1.24; acc: 0.69
Batch: 80; loss: 1.13; acc: 0.66
Batch: 100; loss: 1.21; acc: 0.69
Batch: 120; loss: 1.36; acc: 0.67
Batch: 140; loss: 1.08; acc: 0.75
Val Epoch over. val_loss: 1.2718671286941334; val_accuracy: 0.6439092356687898 

The current subspace-distance is: 0.00011337609612382948 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.67
Batch: 20; loss: 1.05; acc: 0.73
Batch: 40; loss: 1.29; acc: 0.66
Batch: 60; loss: 1.14; acc: 0.61
Batch: 80; loss: 1.17; acc: 0.67
Batch: 100; loss: 1.2; acc: 0.59
Batch: 120; loss: 1.03; acc: 0.78
Batch: 140; loss: 1.11; acc: 0.75
Batch: 160; loss: 1.39; acc: 0.53
Batch: 180; loss: 1.08; acc: 0.67
Batch: 200; loss: 1.17; acc: 0.67
Batch: 220; loss: 1.22; acc: 0.73
Batch: 240; loss: 1.28; acc: 0.61
Batch: 260; loss: 1.25; acc: 0.61
Batch: 280; loss: 1.22; acc: 0.7
Batch: 300; loss: 1.11; acc: 0.67
Batch: 320; loss: 1.05; acc: 0.73
Batch: 340; loss: 1.12; acc: 0.72
Batch: 360; loss: 1.13; acc: 0.67
Batch: 380; loss: 1.25; acc: 0.67
Batch: 400; loss: 1.12; acc: 0.7
Batch: 420; loss: 1.13; acc: 0.75
Batch: 440; loss: 1.03; acc: 0.72
Batch: 460; loss: 0.95; acc: 0.81
Batch: 480; loss: 1.38; acc: 0.55
Batch: 500; loss: 1.16; acc: 0.64
Batch: 520; loss: 1.1; acc: 0.72
Batch: 540; loss: 1.39; acc: 0.58
Batch: 560; loss: 1.26; acc: 0.62
Batch: 580; loss: 1.21; acc: 0.61
Batch: 600; loss: 1.14; acc: 0.77
Batch: 620; loss: 0.97; acc: 0.78
Batch: 640; loss: 1.18; acc: 0.67
Batch: 660; loss: 1.13; acc: 0.72
Batch: 680; loss: 1.17; acc: 0.69
Batch: 700; loss: 1.11; acc: 0.7
Batch: 720; loss: 1.31; acc: 0.62
Batch: 740; loss: 1.22; acc: 0.69
Batch: 760; loss: 1.11; acc: 0.78
Batch: 780; loss: 1.12; acc: 0.7
Train Epoch over. train_loss: 1.16; train_accuracy: 0.69 

0.0001235971285495907
0.00011771657591452822
Batch: 0; loss: 1.1; acc: 0.64
Batch: 20; loss: 1.51; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 1.21; acc: 0.58
Batch: 80; loss: 1.21; acc: 0.58
Batch: 100; loss: 1.13; acc: 0.66
Batch: 120; loss: 1.31; acc: 0.61
Batch: 140; loss: 1.11; acc: 0.64
Val Epoch over. val_loss: 1.2681604361837837; val_accuracy: 0.5961385350318471 

The current subspace-distance is: 0.00011771657591452822 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.25; acc: 0.67
Batch: 20; loss: 1.12; acc: 0.72
Batch: 40; loss: 1.36; acc: 0.58
Batch: 60; loss: 1.11; acc: 0.72
Batch: 80; loss: 1.15; acc: 0.67
Batch: 100; loss: 1.19; acc: 0.72
Batch: 120; loss: 0.97; acc: 0.78
Batch: 140; loss: 1.19; acc: 0.67
Batch: 160; loss: 1.28; acc: 0.59
Batch: 180; loss: 1.07; acc: 0.66
Batch: 200; loss: 1.08; acc: 0.73
Batch: 220; loss: 1.2; acc: 0.64
Batch: 240; loss: 0.93; acc: 0.8
Batch: 260; loss: 1.01; acc: 0.77
Batch: 280; loss: 1.11; acc: 0.77
Batch: 300; loss: 1.04; acc: 0.78
Batch: 320; loss: 1.29; acc: 0.59
Batch: 340; loss: 1.41; acc: 0.59
Batch: 360; loss: 1.17; acc: 0.72
Batch: 380; loss: 1.14; acc: 0.7
Batch: 400; loss: 1.16; acc: 0.66
Batch: 420; loss: 1.26; acc: 0.61
Batch: 440; loss: 1.28; acc: 0.69
Batch: 460; loss: 0.97; acc: 0.81
Batch: 480; loss: 1.31; acc: 0.53
Batch: 500; loss: 1.17; acc: 0.7
Batch: 520; loss: 1.34; acc: 0.66
Batch: 540; loss: 1.19; acc: 0.69
Batch: 560; loss: 0.99; acc: 0.83
Batch: 580; loss: 0.98; acc: 0.78
Batch: 600; loss: 1.18; acc: 0.7
Batch: 620; loss: 1.12; acc: 0.67
Batch: 640; loss: 1.22; acc: 0.64
Batch: 660; loss: 1.08; acc: 0.78
Batch: 680; loss: 1.2; acc: 0.64
Batch: 700; loss: 1.06; acc: 0.78
Batch: 720; loss: 1.18; acc: 0.7
Batch: 740; loss: 1.17; acc: 0.67
Batch: 760; loss: 1.14; acc: 0.56
Batch: 780; loss: 0.97; acc: 0.8
Train Epoch over. train_loss: 1.14; train_accuracy: 0.69 

0.0001314518740400672
0.00012476534175220877
Batch: 0; loss: 1.13; acc: 0.64
Batch: 20; loss: 1.42; acc: 0.59
Batch: 40; loss: 1.02; acc: 0.69
Batch: 60; loss: 1.14; acc: 0.69
Batch: 80; loss: 1.05; acc: 0.73
Batch: 100; loss: 1.09; acc: 0.64
Batch: 120; loss: 1.3; acc: 0.64
Batch: 140; loss: 1.09; acc: 0.73
Val Epoch over. val_loss: 1.196460849540249; val_accuracy: 0.642515923566879 

The current subspace-distance is: 0.00012476534175220877 

Epoch 11 start
The current lr is: 0.3
Batch: 0; loss: 1.18; acc: 0.66
Batch: 20; loss: 1.14; acc: 0.69
Batch: 40; loss: 0.95; acc: 0.8
Batch: 60; loss: 1.18; acc: 0.7
Batch: 80; loss: 1.02; acc: 0.75
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 1.14; acc: 0.61
Batch: 140; loss: 1.26; acc: 0.69
Batch: 160; loss: 1.25; acc: 0.56
Batch: 180; loss: 1.11; acc: 0.66
Batch: 200; loss: 1.06; acc: 0.73
Batch: 220; loss: 1.27; acc: 0.67
Batch: 240; loss: 1.06; acc: 0.78
Batch: 260; loss: 1.03; acc: 0.75
Batch: 280; loss: 1.26; acc: 0.64
Batch: 300; loss: 1.15; acc: 0.66
Batch: 320; loss: 1.13; acc: 0.67
Batch: 340; loss: 1.16; acc: 0.69
Batch: 360; loss: 1.06; acc: 0.7
Batch: 380; loss: 1.2; acc: 0.64
Batch: 400; loss: 0.97; acc: 0.78
Batch: 420; loss: 1.31; acc: 0.59
Batch: 440; loss: 1.31; acc: 0.62
Batch: 460; loss: 1.28; acc: 0.69
Batch: 480; loss: 1.04; acc: 0.75
Batch: 500; loss: 1.09; acc: 0.64
Batch: 520; loss: 1.14; acc: 0.72
Batch: 540; loss: 1.15; acc: 0.69
Batch: 560; loss: 1.22; acc: 0.66
Batch: 580; loss: 1.16; acc: 0.62
Batch: 600; loss: 1.04; acc: 0.78
Batch: 620; loss: 1.17; acc: 0.67
Batch: 640; loss: 1.42; acc: 0.56
Batch: 660; loss: 1.21; acc: 0.67
Batch: 680; loss: 1.18; acc: 0.67
Batch: 700; loss: 1.03; acc: 0.77
Batch: 720; loss: 0.98; acc: 0.8
Batch: 740; loss: 1.23; acc: 0.64
Batch: 760; loss: 1.14; acc: 0.66
Batch: 780; loss: 1.27; acc: 0.7
Train Epoch over. train_loss: 1.12; train_accuracy: 0.69 

0.00013138726353645325
0.00012649012205656618
Batch: 0; loss: 0.96; acc: 0.78
Batch: 20; loss: 1.33; acc: 0.64
Batch: 40; loss: 0.79; acc: 0.83
Batch: 60; loss: 1.01; acc: 0.73
Batch: 80; loss: 0.85; acc: 0.78
Batch: 100; loss: 0.98; acc: 0.7
Batch: 120; loss: 1.17; acc: 0.66
Batch: 140; loss: 0.84; acc: 0.83
Val Epoch over. val_loss: 1.0541775511328582; val_accuracy: 0.7154657643312102 

The current subspace-distance is: 0.00012649012205656618 

Epoch 12 start
The current lr is: 0.3
Batch: 0; loss: 1.01; acc: 0.73
Batch: 20; loss: 1.17; acc: 0.69
Batch: 40; loss: 1.05; acc: 0.72
Batch: 60; loss: 1.16; acc: 0.66
Batch: 80; loss: 1.11; acc: 0.78
Batch: 100; loss: 1.29; acc: 0.69
Batch: 120; loss: 1.1; acc: 0.73
Batch: 140; loss: 1.21; acc: 0.66
Batch: 160; loss: 0.97; acc: 0.77
Batch: 180; loss: 1.18; acc: 0.62
Batch: 200; loss: 1.07; acc: 0.67
Batch: 220; loss: 0.83; acc: 0.88
Batch: 240; loss: 1.31; acc: 0.62
Batch: 260; loss: 1.04; acc: 0.75
Batch: 280; loss: 1.02; acc: 0.73
Batch: 300; loss: 1.08; acc: 0.72
Batch: 320; loss: 0.98; acc: 0.72
Batch: 340; loss: 1.13; acc: 0.66
Batch: 360; loss: 1.17; acc: 0.7
Batch: 380; loss: 1.13; acc: 0.66
Batch: 400; loss: 1.26; acc: 0.59
Batch: 420; loss: 1.24; acc: 0.59
Batch: 440; loss: 1.12; acc: 0.7
Batch: 460; loss: 1.19; acc: 0.67
Batch: 480; loss: 1.01; acc: 0.78
Batch: 500; loss: 1.23; acc: 0.69
Batch: 520; loss: 1.01; acc: 0.8
Batch: 540; loss: 1.12; acc: 0.72
Batch: 560; loss: 0.99; acc: 0.78
Batch: 580; loss: 1.27; acc: 0.61
Batch: 600; loss: 1.01; acc: 0.73
Batch: 620; loss: 1.08; acc: 0.67
Batch: 640; loss: 1.04; acc: 0.67
Batch: 660; loss: 1.38; acc: 0.64
Batch: 680; loss: 1.07; acc: 0.72
Batch: 700; loss: 1.12; acc: 0.64
Batch: 720; loss: 1.12; acc: 0.67
Batch: 740; loss: 1.1; acc: 0.77
Batch: 760; loss: 1.06; acc: 0.73
Batch: 780; loss: 1.02; acc: 0.77
Train Epoch over. train_loss: 1.12; train_accuracy: 0.7 

0.0001346744247712195
0.00012840986892115325
Batch: 0; loss: 0.92; acc: 0.81
Batch: 20; loss: 1.32; acc: 0.61
Batch: 40; loss: 0.79; acc: 0.83
Batch: 60; loss: 1.04; acc: 0.7
Batch: 80; loss: 0.8; acc: 0.81
Batch: 100; loss: 1.01; acc: 0.75
Batch: 120; loss: 1.18; acc: 0.73
Batch: 140; loss: 0.88; acc: 0.83
Val Epoch over. val_loss: 1.0622645164750943; val_accuracy: 0.7186504777070064 

The current subspace-distance is: 0.00012840986892115325 

Epoch 13 start
The current lr is: 0.3
Batch: 0; loss: 1.19; acc: 0.64
Batch: 20; loss: 1.25; acc: 0.67
Batch: 40; loss: 1.15; acc: 0.73
Batch: 60; loss: 1.23; acc: 0.64
Batch: 80; loss: 1.04; acc: 0.78
Batch: 100; loss: 1.11; acc: 0.72
Batch: 120; loss: 1.17; acc: 0.67
Batch: 140; loss: 1.19; acc: 0.72
Batch: 160; loss: 1.04; acc: 0.67
Batch: 180; loss: 1.21; acc: 0.75
Batch: 200; loss: 1.24; acc: 0.62
Batch: 220; loss: 1.06; acc: 0.8
Batch: 240; loss: 1.12; acc: 0.67
Batch: 260; loss: 1.09; acc: 0.69
Batch: 280; loss: 1.13; acc: 0.73
Batch: 300; loss: 1.19; acc: 0.66
Batch: 320; loss: 1.12; acc: 0.7
Batch: 340; loss: 0.97; acc: 0.73
Batch: 360; loss: 1.17; acc: 0.67
Batch: 380; loss: 1.23; acc: 0.67
Batch: 400; loss: 1.11; acc: 0.66
Batch: 420; loss: 0.95; acc: 0.78
Batch: 440; loss: 1.18; acc: 0.67
Batch: 460; loss: 1.11; acc: 0.64
Batch: 480; loss: 1.02; acc: 0.73
Batch: 500; loss: 1.27; acc: 0.62
Batch: 520; loss: 1.07; acc: 0.7
Batch: 540; loss: 1.08; acc: 0.7
Batch: 560; loss: 1.11; acc: 0.73
Batch: 580; loss: 1.15; acc: 0.69
Batch: 600; loss: 0.97; acc: 0.78
Batch: 620; loss: 1.2; acc: 0.61
Batch: 640; loss: 1.1; acc: 0.67
Batch: 660; loss: 1.12; acc: 0.77
Batch: 680; loss: 1.3; acc: 0.56
Batch: 700; loss: 1.12; acc: 0.77
Batch: 720; loss: 1.11; acc: 0.69
Batch: 740; loss: 1.12; acc: 0.69
Batch: 760; loss: 1.15; acc: 0.64
Batch: 780; loss: 1.25; acc: 0.66
Train Epoch over. train_loss: 1.11; train_accuracy: 0.7 

0.0001363899646094069
0.0001296249101869762
Batch: 0; loss: 0.93; acc: 0.8
Batch: 20; loss: 1.27; acc: 0.67
Batch: 40; loss: 0.82; acc: 0.81
Batch: 60; loss: 1.03; acc: 0.73
Batch: 80; loss: 0.81; acc: 0.81
Batch: 100; loss: 0.98; acc: 0.77
Batch: 120; loss: 1.17; acc: 0.73
Batch: 140; loss: 0.89; acc: 0.86
Val Epoch over. val_loss: 1.0581563350501333; val_accuracy: 0.7289012738853503 

The current subspace-distance is: 0.0001296249101869762 

Epoch 14 start
The current lr is: 0.3
Batch: 0; loss: 0.93; acc: 0.8
Batch: 20; loss: 1.1; acc: 0.7
Batch: 40; loss: 1.21; acc: 0.67
Batch: 60; loss: 1.11; acc: 0.67
Batch: 80; loss: 1.09; acc: 0.69
Batch: 100; loss: 1.17; acc: 0.62
Batch: 120; loss: 1.12; acc: 0.67
Batch: 140; loss: 1.18; acc: 0.66
Batch: 160; loss: 1.15; acc: 0.66
Batch: 180; loss: 1.2; acc: 0.7
Batch: 200; loss: 1.19; acc: 0.62
Batch: 220; loss: 1.05; acc: 0.7
Batch: 240; loss: 1.13; acc: 0.62
Batch: 260; loss: 1.2; acc: 0.61
Batch: 280; loss: 1.16; acc: 0.66
Batch: 300; loss: 1.09; acc: 0.67
Batch: 320; loss: 1.07; acc: 0.75
Batch: 340; loss: 1.26; acc: 0.64
Batch: 360; loss: 1.17; acc: 0.64
Batch: 380; loss: 1.14; acc: 0.72
Batch: 400; loss: 1.26; acc: 0.59
Batch: 420; loss: 0.88; acc: 0.86
Batch: 440; loss: 1.07; acc: 0.69
Batch: 460; loss: 1.07; acc: 0.77
Batch: 480; loss: 1.08; acc: 0.77
Batch: 500; loss: 0.98; acc: 0.69
Batch: 520; loss: 1.05; acc: 0.73
Batch: 540; loss: 1.18; acc: 0.59
Batch: 560; loss: 1.1; acc: 0.67
Batch: 580; loss: 1.18; acc: 0.66
Batch: 600; loss: 1.12; acc: 0.7
Batch: 620; loss: 1.09; acc: 0.7
Batch: 640; loss: 1.15; acc: 0.7
Batch: 660; loss: 1.08; acc: 0.72
Batch: 680; loss: 1.02; acc: 0.78
Batch: 700; loss: 1.23; acc: 0.66
Batch: 720; loss: 1.15; acc: 0.7
Batch: 740; loss: 1.15; acc: 0.66
Batch: 760; loss: 1.11; acc: 0.61
Batch: 780; loss: 1.12; acc: 0.7
Train Epoch over. train_loss: 1.11; train_accuracy: 0.7 

0.00013728240446653217
0.00013133182073943317
Batch: 0; loss: 0.96; acc: 0.77
Batch: 20; loss: 1.25; acc: 0.66
Batch: 40; loss: 0.84; acc: 0.77
Batch: 60; loss: 1.02; acc: 0.77
Batch: 80; loss: 0.9; acc: 0.75
Batch: 100; loss: 0.97; acc: 0.72
Batch: 120; loss: 1.17; acc: 0.72
Batch: 140; loss: 0.88; acc: 0.83
Val Epoch over. val_loss: 1.0670680631497862; val_accuracy: 0.714968152866242 

The current subspace-distance is: 0.00013133182073943317 

Epoch 15 start
The current lr is: 0.3
Batch: 0; loss: 1.08; acc: 0.77
Batch: 20; loss: 1.14; acc: 0.64
Batch: 40; loss: 1.27; acc: 0.59
Batch: 60; loss: 1.28; acc: 0.62
Batch: 80; loss: 1.18; acc: 0.59
Batch: 100; loss: 1.06; acc: 0.72
Batch: 120; loss: 1.22; acc: 0.61
Batch: 140; loss: 1.15; acc: 0.73
Batch: 160; loss: 1.05; acc: 0.72
Batch: 180; loss: 1.14; acc: 0.67
Batch: 200; loss: 1.07; acc: 0.69
Batch: 220; loss: 1.16; acc: 0.61
Batch: 240; loss: 1.28; acc: 0.62
Batch: 260; loss: 1.14; acc: 0.72
Batch: 280; loss: 0.91; acc: 0.83
Batch: 300; loss: 1.18; acc: 0.7
Batch: 320; loss: 1.16; acc: 0.66
Batch: 340; loss: 1.01; acc: 0.78
Batch: 360; loss: 0.93; acc: 0.78
Batch: 380; loss: 1.07; acc: 0.64
Batch: 400; loss: 1.31; acc: 0.62
Batch: 420; loss: 0.96; acc: 0.72
Batch: 440; loss: 1.09; acc: 0.67
Batch: 460; loss: 1.05; acc: 0.73
Batch: 480; loss: 1.1; acc: 0.75
Batch: 500; loss: 1.34; acc: 0.59
Batch: 520; loss: 1.02; acc: 0.77
Batch: 540; loss: 0.96; acc: 0.75
Batch: 560; loss: 1.14; acc: 0.7
Batch: 580; loss: 1.11; acc: 0.7
Batch: 600; loss: 1.19; acc: 0.64
Batch: 620; loss: 1.09; acc: 0.67
Batch: 640; loss: 0.99; acc: 0.77
Batch: 660; loss: 1.13; acc: 0.73
Batch: 680; loss: 1.02; acc: 0.77
Batch: 700; loss: 1.14; acc: 0.66
Batch: 720; loss: 1.17; acc: 0.61
Batch: 740; loss: 1.05; acc: 0.7
Batch: 760; loss: 1.19; acc: 0.59
Batch: 780; loss: 1.1; acc: 0.7
Train Epoch over. train_loss: 1.11; train_accuracy: 0.7 

0.00013945178943686187
0.00013248910545371473
Batch: 0; loss: 0.97; acc: 0.8
Batch: 20; loss: 1.32; acc: 0.66
Batch: 40; loss: 0.82; acc: 0.8
Batch: 60; loss: 1.03; acc: 0.72
Batch: 80; loss: 0.86; acc: 0.78
Batch: 100; loss: 0.97; acc: 0.73
Batch: 120; loss: 1.16; acc: 0.78
Batch: 140; loss: 0.88; acc: 0.84
Val Epoch over. val_loss: 1.0724489840732259; val_accuracy: 0.7146695859872612 

The current subspace-distance is: 0.00013248910545371473 

Epoch 16 start
The current lr is: 0.3
Batch: 0; loss: 1.44; acc: 0.62
Batch: 20; loss: 1.02; acc: 0.77
Batch: 40; loss: 0.97; acc: 0.78
Batch: 60; loss: 1.18; acc: 0.67
Batch: 80; loss: 1.22; acc: 0.67
Batch: 100; loss: 1.09; acc: 0.75
Batch: 120; loss: 1.03; acc: 0.75
Batch: 140; loss: 1.11; acc: 0.7
Batch: 160; loss: 0.96; acc: 0.67
Batch: 180; loss: 1.23; acc: 0.62
Batch: 200; loss: 1.02; acc: 0.73
Batch: 220; loss: 1.2; acc: 0.67
Batch: 240; loss: 1.03; acc: 0.69
Batch: 260; loss: 1.05; acc: 0.66
Batch: 280; loss: 1.16; acc: 0.72
Batch: 300; loss: 1.2; acc: 0.62
Batch: 320; loss: 1.01; acc: 0.78
Batch: 340; loss: 1.04; acc: 0.77
Batch: 360; loss: 1.21; acc: 0.72
Batch: 380; loss: 1.01; acc: 0.72
Batch: 400; loss: 1.13; acc: 0.66
Batch: 420; loss: 1.01; acc: 0.69
Batch: 440; loss: 1.08; acc: 0.7
Batch: 460; loss: 1.01; acc: 0.72
Batch: 480; loss: 1.13; acc: 0.62
Batch: 500; loss: 1.02; acc: 0.72
Batch: 520; loss: 0.97; acc: 0.69
Batch: 540; loss: 1.27; acc: 0.66
Batch: 560; loss: 1.1; acc: 0.7
Batch: 580; loss: 1.19; acc: 0.62
Batch: 600; loss: 1.06; acc: 0.72
Batch: 620; loss: 0.98; acc: 0.7
Batch: 640; loss: 1.0; acc: 0.69
Batch: 660; loss: 1.01; acc: 0.73
Batch: 680; loss: 1.24; acc: 0.62
Batch: 700; loss: 1.06; acc: 0.73
Batch: 720; loss: 0.98; acc: 0.81
Batch: 740; loss: 1.04; acc: 0.69
Batch: 760; loss: 1.0; acc: 0.75
Batch: 780; loss: 1.08; acc: 0.66
Train Epoch over. train_loss: 1.1; train_accuracy: 0.7 

0.0001421398774255067
0.00013380304153542966
Batch: 0; loss: 0.92; acc: 0.8
Batch: 20; loss: 1.25; acc: 0.67
Batch: 40; loss: 0.82; acc: 0.8
Batch: 60; loss: 1.03; acc: 0.72
Batch: 80; loss: 0.81; acc: 0.78
Batch: 100; loss: 0.99; acc: 0.75
Batch: 120; loss: 1.14; acc: 0.73
Batch: 140; loss: 0.9; acc: 0.84
Val Epoch over. val_loss: 1.0458448916483836; val_accuracy: 0.723328025477707 

The current subspace-distance is: 0.00013380304153542966 

Epoch 17 start
The current lr is: 0.3
Batch: 0; loss: 1.15; acc: 0.7
Batch: 20; loss: 1.27; acc: 0.66
Batch: 40; loss: 1.01; acc: 0.73
Batch: 60; loss: 0.95; acc: 0.83
Batch: 80; loss: 1.01; acc: 0.73
Batch: 100; loss: 1.0; acc: 0.77
Batch: 120; loss: 1.13; acc: 0.7
Batch: 140; loss: 0.97; acc: 0.77
Batch: 160; loss: 1.05; acc: 0.72
Batch: 180; loss: 1.14; acc: 0.72
Batch: 200; loss: 0.94; acc: 0.77
Batch: 220; loss: 1.07; acc: 0.75
Batch: 240; loss: 0.96; acc: 0.72
Batch: 260; loss: 1.2; acc: 0.66
Batch: 280; loss: 1.28; acc: 0.61
Batch: 300; loss: 0.97; acc: 0.77
Batch: 320; loss: 1.04; acc: 0.75
Batch: 340; loss: 1.12; acc: 0.69
Batch: 360; loss: 1.03; acc: 0.73
Batch: 380; loss: 0.9; acc: 0.8
Batch: 400; loss: 1.24; acc: 0.64
Batch: 420; loss: 1.17; acc: 0.61
Batch: 440; loss: 1.07; acc: 0.75
Batch: 460; loss: 0.91; acc: 0.81
Batch: 480; loss: 0.98; acc: 0.72
Batch: 500; loss: 1.12; acc: 0.7
Batch: 520; loss: 1.08; acc: 0.7
Batch: 540; loss: 1.11; acc: 0.66
Batch: 560; loss: 1.17; acc: 0.7
Batch: 580; loss: 1.01; acc: 0.72
Batch: 600; loss: 1.05; acc: 0.75
Batch: 620; loss: 1.13; acc: 0.66
Batch: 640; loss: 1.03; acc: 0.72
Batch: 660; loss: 1.25; acc: 0.66
Batch: 680; loss: 1.15; acc: 0.67
Batch: 700; loss: 1.08; acc: 0.72
Batch: 720; loss: 1.05; acc: 0.75
Batch: 740; loss: 0.86; acc: 0.77
Batch: 760; loss: 1.17; acc: 0.66
Batch: 780; loss: 1.24; acc: 0.58
Train Epoch over. train_loss: 1.1; train_accuracy: 0.7 

0.00014254309644456953
0.00013556145131587982
Batch: 0; loss: 0.93; acc: 0.8
Batch: 20; loss: 1.29; acc: 0.66
Batch: 40; loss: 0.8; acc: 0.78
Batch: 60; loss: 0.98; acc: 0.77
Batch: 80; loss: 0.82; acc: 0.75
Batch: 100; loss: 0.96; acc: 0.77
Batch: 120; loss: 1.12; acc: 0.75
Batch: 140; loss: 0.82; acc: 0.86
Val Epoch over. val_loss: 1.0309384985334555; val_accuracy: 0.721437101910828 

The current subspace-distance is: 0.00013556145131587982 

Epoch 18 start
The current lr is: 0.3
Batch: 0; loss: 1.15; acc: 0.69
Batch: 20; loss: 1.11; acc: 0.72
Batch: 40; loss: 1.14; acc: 0.69
Batch: 60; loss: 1.23; acc: 0.67
Batch: 80; loss: 1.07; acc: 0.66
Batch: 100; loss: 1.0; acc: 0.73
Batch: 120; loss: 0.98; acc: 0.77
Batch: 140; loss: 1.33; acc: 0.62
Batch: 160; loss: 1.19; acc: 0.61
Batch: 180; loss: 1.08; acc: 0.62
Batch: 200; loss: 1.02; acc: 0.72
Batch: 220; loss: 1.02; acc: 0.72
Batch: 240; loss: 0.96; acc: 0.78
Batch: 260; loss: 1.2; acc: 0.73
Batch: 280; loss: 0.93; acc: 0.7
Batch: 300; loss: 1.0; acc: 0.75
Batch: 320; loss: 1.02; acc: 0.73
Batch: 340; loss: 1.03; acc: 0.66
Batch: 360; loss: 1.18; acc: 0.62
Batch: 380; loss: 1.15; acc: 0.67
Batch: 400; loss: 1.17; acc: 0.64
Batch: 420; loss: 1.13; acc: 0.7
Batch: 440; loss: 1.34; acc: 0.64
Batch: 460; loss: 1.06; acc: 0.69
Batch: 480; loss: 0.92; acc: 0.8
Batch: 500; loss: 1.0; acc: 0.72
Batch: 520; loss: 1.05; acc: 0.72
Batch: 540; loss: 0.87; acc: 0.84
Batch: 560; loss: 0.98; acc: 0.67
Batch: 580; loss: 1.21; acc: 0.62
Batch: 600; loss: 1.21; acc: 0.64
Batch: 620; loss: 1.12; acc: 0.72
Batch: 640; loss: 1.15; acc: 0.7
Batch: 660; loss: 0.96; acc: 0.69
Batch: 680; loss: 1.03; acc: 0.7
Batch: 700; loss: 0.94; acc: 0.77
Batch: 720; loss: 1.01; acc: 0.73
Batch: 740; loss: 0.93; acc: 0.73
Batch: 760; loss: 0.94; acc: 0.72
Batch: 780; loss: 0.97; acc: 0.78
Train Epoch over. train_loss: 1.09; train_accuracy: 0.7 

0.00014390962314791977
0.00013904446677770466
Batch: 0; loss: 0.92; acc: 0.83
Batch: 20; loss: 1.23; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.73
Batch: 80; loss: 0.83; acc: 0.73
Batch: 100; loss: 0.97; acc: 0.75
Batch: 120; loss: 1.12; acc: 0.75
Batch: 140; loss: 0.86; acc: 0.86
Val Epoch over. val_loss: 1.0389498012840368; val_accuracy: 0.7224323248407644 

The current subspace-distance is: 0.00013904446677770466 

Epoch 19 start
The current lr is: 0.3
Batch: 0; loss: 1.0; acc: 0.8
Batch: 20; loss: 1.16; acc: 0.7
Batch: 40; loss: 1.16; acc: 0.62
Batch: 60; loss: 0.88; acc: 0.81
Batch: 80; loss: 1.22; acc: 0.67
Batch: 100; loss: 1.13; acc: 0.64
Batch: 120; loss: 1.11; acc: 0.72
Batch: 140; loss: 1.12; acc: 0.62
Batch: 160; loss: 1.09; acc: 0.7
Batch: 180; loss: 1.02; acc: 0.72
Batch: 200; loss: 1.06; acc: 0.73
Batch: 220; loss: 1.04; acc: 0.78
Batch: 240; loss: 0.96; acc: 0.8
Batch: 260; loss: 0.99; acc: 0.72
Batch: 280; loss: 1.02; acc: 0.69
Batch: 300; loss: 1.07; acc: 0.59
Batch: 320; loss: 1.01; acc: 0.7
Batch: 340; loss: 1.06; acc: 0.72
Batch: 360; loss: 0.95; acc: 0.77
Batch: 380; loss: 0.95; acc: 0.77
Batch: 400; loss: 1.22; acc: 0.62
Batch: 420; loss: 1.13; acc: 0.7
Batch: 440; loss: 0.99; acc: 0.75
Batch: 460; loss: 1.19; acc: 0.66
Batch: 480; loss: 0.95; acc: 0.72
Batch: 500; loss: 1.13; acc: 0.67
Batch: 520; loss: 1.34; acc: 0.59
Batch: 540; loss: 1.0; acc: 0.77
Batch: 560; loss: 1.29; acc: 0.64
Batch: 580; loss: 1.05; acc: 0.72
Batch: 600; loss: 1.09; acc: 0.75
Batch: 620; loss: 1.11; acc: 0.7
Batch: 640; loss: 1.08; acc: 0.78
Batch: 660; loss: 0.99; acc: 0.75
Batch: 680; loss: 0.96; acc: 0.78
Batch: 700; loss: 1.22; acc: 0.62
Batch: 720; loss: 0.93; acc: 0.78
Batch: 740; loss: 0.95; acc: 0.7
Batch: 760; loss: 1.26; acc: 0.69
Batch: 780; loss: 1.19; acc: 0.61
Train Epoch over. train_loss: 1.09; train_accuracy: 0.7 

0.00014596324763260782
0.00014031192404218018
Batch: 0; loss: 0.93; acc: 0.78
Batch: 20; loss: 1.3; acc: 0.64
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 1.01; acc: 0.75
Batch: 80; loss: 0.82; acc: 0.77
Batch: 100; loss: 0.98; acc: 0.72
Batch: 120; loss: 1.12; acc: 0.73
Batch: 140; loss: 0.85; acc: 0.84
Val Epoch over. val_loss: 1.0429185222668254; val_accuracy: 0.7085987261146497 

The current subspace-distance is: 0.00014031192404218018 

Epoch 20 start
The current lr is: 0.3
Batch: 0; loss: 1.1; acc: 0.73
Batch: 20; loss: 1.08; acc: 0.7
Batch: 40; loss: 0.95; acc: 0.75
Batch: 60; loss: 0.91; acc: 0.78
Batch: 80; loss: 0.99; acc: 0.73
Batch: 100; loss: 1.17; acc: 0.72
Batch: 120; loss: 0.91; acc: 0.8
Batch: 140; loss: 0.9; acc: 0.77
Batch: 160; loss: 1.04; acc: 0.7
Batch: 180; loss: 1.12; acc: 0.67
Batch: 200; loss: 1.13; acc: 0.7
Batch: 220; loss: 1.4; acc: 0.56
Batch: 240; loss: 1.11; acc: 0.69
Batch: 260; loss: 1.02; acc: 0.81
Batch: 280; loss: 1.03; acc: 0.7
Batch: 300; loss: 1.15; acc: 0.69
Batch: 320; loss: 0.93; acc: 0.81
Batch: 340; loss: 0.83; acc: 0.81
Batch: 360; loss: 1.05; acc: 0.7
Batch: 380; loss: 1.23; acc: 0.69
Batch: 400; loss: 1.05; acc: 0.67
Batch: 420; loss: 1.13; acc: 0.61
Batch: 440; loss: 1.07; acc: 0.7
Batch: 460; loss: 1.1; acc: 0.64
Batch: 480; loss: 0.98; acc: 0.77
Batch: 500; loss: 1.09; acc: 0.67
Batch: 520; loss: 1.06; acc: 0.72
Batch: 540; loss: 1.34; acc: 0.59
Batch: 560; loss: 1.13; acc: 0.72
Batch: 580; loss: 1.18; acc: 0.73
Batch: 600; loss: 0.97; acc: 0.69
Batch: 620; loss: 0.99; acc: 0.78
Batch: 640; loss: 1.13; acc: 0.67
Batch: 660; loss: 1.04; acc: 0.69
Batch: 680; loss: 1.18; acc: 0.67
Batch: 700; loss: 1.07; acc: 0.72
Batch: 720; loss: 0.97; acc: 0.75
Batch: 740; loss: 1.19; acc: 0.62
Batch: 760; loss: 0.95; acc: 0.78
Batch: 780; loss: 1.26; acc: 0.58
Train Epoch over. train_loss: 1.08; train_accuracy: 0.7 

0.0001468084956286475
0.00013967245467938483
Batch: 0; loss: 0.9; acc: 0.8
Batch: 20; loss: 1.27; acc: 0.67
Batch: 40; loss: 0.76; acc: 0.81
Batch: 60; loss: 0.98; acc: 0.73
Batch: 80; loss: 0.8; acc: 0.73
Batch: 100; loss: 0.98; acc: 0.73
Batch: 120; loss: 1.1; acc: 0.77
Batch: 140; loss: 0.83; acc: 0.84
Val Epoch over. val_loss: 1.0211290375442261; val_accuracy: 0.7142714968152867 

The current subspace-distance is: 0.00013967245467938483 

Epoch 21 start
The current lr is: 0.09
Batch: 0; loss: 1.03; acc: 0.72
Batch: 20; loss: 0.95; acc: 0.78
Batch: 40; loss: 1.23; acc: 0.62
Batch: 60; loss: 1.06; acc: 0.72
Batch: 80; loss: 1.06; acc: 0.77
Batch: 100; loss: 1.0; acc: 0.77
Batch: 120; loss: 1.03; acc: 0.72
Batch: 140; loss: 1.14; acc: 0.7
Batch: 160; loss: 1.24; acc: 0.64
Batch: 180; loss: 1.13; acc: 0.69
Batch: 200; loss: 1.02; acc: 0.7
Batch: 220; loss: 1.24; acc: 0.7
Batch: 240; loss: 1.0; acc: 0.75
Batch: 260; loss: 1.32; acc: 0.55
Batch: 280; loss: 1.15; acc: 0.69
Batch: 300; loss: 1.13; acc: 0.66
Batch: 320; loss: 1.07; acc: 0.67
Batch: 340; loss: 1.1; acc: 0.7
Batch: 360; loss: 0.99; acc: 0.66
Batch: 380; loss: 1.21; acc: 0.62
Batch: 400; loss: 1.18; acc: 0.64
Batch: 420; loss: 1.02; acc: 0.75
Batch: 440; loss: 1.05; acc: 0.7
Batch: 460; loss: 1.33; acc: 0.64
Batch: 480; loss: 1.09; acc: 0.7
Batch: 500; loss: 1.26; acc: 0.58
Batch: 520; loss: 0.87; acc: 0.83
Batch: 540; loss: 1.19; acc: 0.69
Batch: 560; loss: 1.2; acc: 0.67
Batch: 580; loss: 1.07; acc: 0.67
Batch: 600; loss: 1.01; acc: 0.77
Batch: 620; loss: 1.21; acc: 0.62
Batch: 640; loss: 1.13; acc: 0.72
Batch: 660; loss: 1.04; acc: 0.73
Batch: 680; loss: 1.11; acc: 0.66
Batch: 700; loss: 1.07; acc: 0.69
Batch: 720; loss: 1.16; acc: 0.67
Batch: 740; loss: 0.99; acc: 0.8
Batch: 760; loss: 0.93; acc: 0.81
Batch: 780; loss: 1.34; acc: 0.56
Train Epoch over. train_loss: 1.08; train_accuracy: 0.7 

0.00014707533409819007
0.00014040098176337779
Batch: 0; loss: 0.94; acc: 0.77
Batch: 20; loss: 1.23; acc: 0.69
Batch: 40; loss: 0.79; acc: 0.78
Batch: 60; loss: 0.98; acc: 0.75
Batch: 80; loss: 0.87; acc: 0.75
Batch: 100; loss: 0.97; acc: 0.73
Batch: 120; loss: 1.13; acc: 0.77
Batch: 140; loss: 0.84; acc: 0.84
Val Epoch over. val_loss: 1.026044685369844; val_accuracy: 0.7345740445859873 

The current subspace-distance is: 0.00014040098176337779 

Epoch 22 start
The current lr is: 0.09
Batch: 0; loss: 0.98; acc: 0.77
Batch: 20; loss: 1.03; acc: 0.66
Batch: 40; loss: 1.02; acc: 0.7
Batch: 60; loss: 1.04; acc: 0.69
Batch: 80; loss: 1.01; acc: 0.72
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.13; acc: 0.62
Batch: 140; loss: 0.98; acc: 0.75
Batch: 160; loss: 1.01; acc: 0.7
Batch: 180; loss: 1.08; acc: 0.72
Batch: 200; loss: 0.89; acc: 0.83
Batch: 220; loss: 1.11; acc: 0.64
Batch: 240; loss: 1.06; acc: 0.66
Batch: 260; loss: 1.01; acc: 0.78
Batch: 280; loss: 1.25; acc: 0.62
Batch: 300; loss: 1.0; acc: 0.75
Batch: 320; loss: 1.13; acc: 0.73
Batch: 340; loss: 0.86; acc: 0.8
Batch: 360; loss: 0.88; acc: 0.81
Batch: 380; loss: 1.02; acc: 0.66
Batch: 400; loss: 1.02; acc: 0.66
Batch: 420; loss: 1.21; acc: 0.62
Batch: 440; loss: 1.11; acc: 0.72
Batch: 460; loss: 1.15; acc: 0.61
Batch: 480; loss: 1.15; acc: 0.62
Batch: 500; loss: 1.06; acc: 0.69
Batch: 520; loss: 1.2; acc: 0.72
Batch: 540; loss: 1.03; acc: 0.67
Batch: 560; loss: 1.01; acc: 0.75
Batch: 580; loss: 1.14; acc: 0.7
Batch: 600; loss: 1.14; acc: 0.67
Batch: 620; loss: 1.29; acc: 0.62
Batch: 640; loss: 1.06; acc: 0.72
Batch: 660; loss: 1.22; acc: 0.59
Batch: 680; loss: 1.02; acc: 0.75
Batch: 700; loss: 1.01; acc: 0.72
Batch: 720; loss: 1.14; acc: 0.66
Batch: 740; loss: 1.27; acc: 0.58
Batch: 760; loss: 1.09; acc: 0.77
Batch: 780; loss: 1.27; acc: 0.61
Train Epoch over. train_loss: 1.08; train_accuracy: 0.7 

0.00014753460709471256
0.00014061579713597894
Batch: 0; loss: 0.92; acc: 0.77
Batch: 20; loss: 1.23; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.81
Batch: 60; loss: 0.99; acc: 0.73
Batch: 80; loss: 0.83; acc: 0.78
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.1; acc: 0.8
Batch: 140; loss: 0.84; acc: 0.86
Val Epoch over. val_loss: 1.0191054310008978; val_accuracy: 0.7327826433121019 

The current subspace-distance is: 0.00014061579713597894 

Epoch 23 start
The current lr is: 0.09
Batch: 0; loss: 1.11; acc: 0.72
Batch: 20; loss: 0.99; acc: 0.72
Batch: 40; loss: 1.02; acc: 0.69
Batch: 60; loss: 1.02; acc: 0.69
Batch: 80; loss: 1.16; acc: 0.72
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 1.19; acc: 0.69
Batch: 160; loss: 1.04; acc: 0.7
Batch: 180; loss: 1.21; acc: 0.64
Batch: 200; loss: 0.99; acc: 0.78
Batch: 220; loss: 0.89; acc: 0.8
Batch: 240; loss: 0.93; acc: 0.78
Batch: 260; loss: 0.96; acc: 0.77
Batch: 280; loss: 1.16; acc: 0.66
Batch: 300; loss: 1.1; acc: 0.67
Batch: 320; loss: 0.98; acc: 0.72
Batch: 340; loss: 1.04; acc: 0.73
Batch: 360; loss: 1.14; acc: 0.73
Batch: 380; loss: 1.07; acc: 0.72
Batch: 400; loss: 0.97; acc: 0.8
Batch: 420; loss: 1.03; acc: 0.72
Batch: 440; loss: 1.05; acc: 0.72
Batch: 460; loss: 0.92; acc: 0.77
Batch: 480; loss: 1.02; acc: 0.73
Batch: 500; loss: 1.22; acc: 0.64
Batch: 520; loss: 0.96; acc: 0.81
Batch: 540; loss: 1.01; acc: 0.77
Batch: 560; loss: 1.08; acc: 0.72
Batch: 580; loss: 0.92; acc: 0.8
Batch: 600; loss: 1.1; acc: 0.7
Batch: 620; loss: 1.3; acc: 0.59
Batch: 640; loss: 1.06; acc: 0.75
Batch: 660; loss: 1.0; acc: 0.73
Batch: 680; loss: 1.02; acc: 0.67
Batch: 700; loss: 0.97; acc: 0.7
Batch: 720; loss: 1.1; acc: 0.67
Batch: 740; loss: 1.1; acc: 0.72
Batch: 760; loss: 1.09; acc: 0.64
Batch: 780; loss: 1.13; acc: 0.66
Train Epoch over. train_loss: 1.07; train_accuracy: 0.71 

0.00014794032904319465
0.0001415891310898587
Batch: 0; loss: 0.89; acc: 0.84
Batch: 20; loss: 1.23; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 0.96; acc: 0.77
Batch: 80; loss: 0.85; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 1.07; acc: 0.77
Batch: 140; loss: 0.81; acc: 0.88
Val Epoch over. val_loss: 1.008616516924208; val_accuracy: 0.729796974522293 

The current subspace-distance is: 0.0001415891310898587 

Epoch 24 start
The current lr is: 0.09
Batch: 0; loss: 1.24; acc: 0.61
Batch: 20; loss: 1.1; acc: 0.7
Batch: 40; loss: 1.01; acc: 0.72
Batch: 60; loss: 1.27; acc: 0.61
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.05; acc: 0.73
Batch: 120; loss: 1.17; acc: 0.64
Batch: 140; loss: 1.19; acc: 0.62
Batch: 160; loss: 0.94; acc: 0.77
Batch: 180; loss: 1.12; acc: 0.66
Batch: 200; loss: 1.18; acc: 0.67
Batch: 220; loss: 1.08; acc: 0.62
Batch: 240; loss: 1.16; acc: 0.69
Batch: 260; loss: 1.09; acc: 0.72
Batch: 280; loss: 1.05; acc: 0.73
Batch: 300; loss: 1.17; acc: 0.62
Batch: 320; loss: 1.2; acc: 0.69
Batch: 340; loss: 1.07; acc: 0.75
Batch: 360; loss: 1.14; acc: 0.62
Batch: 380; loss: 1.04; acc: 0.69
Batch: 400; loss: 0.89; acc: 0.78
Batch: 420; loss: 1.22; acc: 0.61
Batch: 440; loss: 1.11; acc: 0.67
Batch: 460; loss: 1.14; acc: 0.72
Batch: 480; loss: 1.08; acc: 0.7
Batch: 500; loss: 0.95; acc: 0.72
Batch: 520; loss: 1.19; acc: 0.59
Batch: 540; loss: 1.02; acc: 0.75
Batch: 560; loss: 1.24; acc: 0.59
Batch: 580; loss: 0.91; acc: 0.83
Batch: 600; loss: 1.39; acc: 0.52
Batch: 620; loss: 0.98; acc: 0.73
Batch: 640; loss: 1.21; acc: 0.66
Batch: 660; loss: 1.18; acc: 0.62
Batch: 680; loss: 0.93; acc: 0.77
Batch: 700; loss: 1.07; acc: 0.69
Batch: 720; loss: 1.21; acc: 0.66
Batch: 740; loss: 1.0; acc: 0.72
Batch: 760; loss: 1.05; acc: 0.77
Batch: 780; loss: 1.33; acc: 0.58
Train Epoch over. train_loss: 1.08; train_accuracy: 0.7 

0.00014799172640778124
0.00014149289927445352
Batch: 0; loss: 0.89; acc: 0.83
Batch: 20; loss: 1.22; acc: 0.69
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 0.97; acc: 0.75
Batch: 80; loss: 0.82; acc: 0.81
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 1.08; acc: 0.77
Batch: 140; loss: 0.83; acc: 0.89
Val Epoch over. val_loss: 1.0045185233377347; val_accuracy: 0.7368630573248408 

The current subspace-distance is: 0.00014149289927445352 

Epoch 25 start
The current lr is: 0.09
Batch: 0; loss: 1.13; acc: 0.7
Batch: 20; loss: 1.05; acc: 0.73
Batch: 40; loss: 1.05; acc: 0.75
Batch: 60; loss: 0.96; acc: 0.67
Batch: 80; loss: 1.02; acc: 0.72
Batch: 100; loss: 0.86; acc: 0.84
Batch: 120; loss: 1.1; acc: 0.72
Batch: 140; loss: 1.27; acc: 0.62
Batch: 160; loss: 0.98; acc: 0.73
Batch: 180; loss: 1.2; acc: 0.66
Batch: 200; loss: 1.14; acc: 0.7
Batch: 220; loss: 1.11; acc: 0.66
Batch: 240; loss: 0.92; acc: 0.77
Batch: 260; loss: 1.08; acc: 0.73
Batch: 280; loss: 0.98; acc: 0.72
Batch: 300; loss: 1.22; acc: 0.66
Batch: 320; loss: 0.97; acc: 0.73
Batch: 340; loss: 0.89; acc: 0.84
Batch: 360; loss: 1.06; acc: 0.69
Batch: 380; loss: 0.97; acc: 0.75
Batch: 400; loss: 0.95; acc: 0.72
Batch: 420; loss: 1.02; acc: 0.72
Batch: 440; loss: 1.16; acc: 0.64
Batch: 460; loss: 0.85; acc: 0.81
Batch: 480; loss: 0.93; acc: 0.77
Batch: 500; loss: 1.23; acc: 0.64
Batch: 520; loss: 1.01; acc: 0.78
Batch: 540; loss: 1.03; acc: 0.7
Batch: 560; loss: 0.99; acc: 0.77
Batch: 580; loss: 1.34; acc: 0.62
Batch: 600; loss: 1.15; acc: 0.7
Batch: 620; loss: 1.13; acc: 0.66
Batch: 640; loss: 1.04; acc: 0.69
Batch: 660; loss: 1.22; acc: 0.58
Batch: 680; loss: 1.16; acc: 0.69
Batch: 700; loss: 1.01; acc: 0.75
Batch: 720; loss: 1.05; acc: 0.7
Batch: 740; loss: 1.05; acc: 0.66
Batch: 760; loss: 1.12; acc: 0.66
Batch: 780; loss: 1.13; acc: 0.62
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

0.00014889294106978923
0.00014221643505152315
Batch: 0; loss: 0.91; acc: 0.8
Batch: 20; loss: 1.22; acc: 0.7
Batch: 40; loss: 0.79; acc: 0.78
Batch: 60; loss: 0.96; acc: 0.73
Batch: 80; loss: 0.84; acc: 0.77
Batch: 100; loss: 0.94; acc: 0.75
Batch: 120; loss: 1.09; acc: 0.77
Batch: 140; loss: 0.81; acc: 0.88
Val Epoch over. val_loss: 1.0076944125685723; val_accuracy: 0.7319864649681529 

The current subspace-distance is: 0.00014221643505152315 

Epoch 26 start
The current lr is: 0.09
Batch: 0; loss: 1.12; acc: 0.67
Batch: 20; loss: 1.12; acc: 0.7
Batch: 40; loss: 0.98; acc: 0.78
Batch: 60; loss: 1.12; acc: 0.62
Batch: 80; loss: 1.22; acc: 0.61
Batch: 100; loss: 0.96; acc: 0.77
Batch: 120; loss: 1.05; acc: 0.66
Batch: 140; loss: 0.97; acc: 0.73
Batch: 160; loss: 1.11; acc: 0.7
Batch: 180; loss: 1.13; acc: 0.64
Batch: 200; loss: 1.32; acc: 0.67
Batch: 220; loss: 1.47; acc: 0.53
Batch: 240; loss: 1.22; acc: 0.66
Batch: 260; loss: 1.08; acc: 0.67
Batch: 280; loss: 1.12; acc: 0.67
Batch: 300; loss: 1.21; acc: 0.62
Batch: 320; loss: 1.11; acc: 0.7
Batch: 340; loss: 0.89; acc: 0.81
Batch: 360; loss: 1.04; acc: 0.7
Batch: 380; loss: 0.97; acc: 0.72
Batch: 400; loss: 1.23; acc: 0.66
Batch: 420; loss: 0.97; acc: 0.75
Batch: 440; loss: 1.24; acc: 0.62
Batch: 460; loss: 0.91; acc: 0.67
Batch: 480; loss: 0.96; acc: 0.73
Batch: 500; loss: 1.09; acc: 0.67
Batch: 520; loss: 1.18; acc: 0.64
Batch: 540; loss: 0.9; acc: 0.78
Batch: 560; loss: 1.09; acc: 0.7
Batch: 580; loss: 1.07; acc: 0.72
Batch: 600; loss: 1.07; acc: 0.73
Batch: 620; loss: 0.99; acc: 0.72
Batch: 640; loss: 1.07; acc: 0.62
Batch: 660; loss: 1.05; acc: 0.67
Batch: 680; loss: 1.2; acc: 0.62
Batch: 700; loss: 0.97; acc: 0.7
Batch: 720; loss: 1.0; acc: 0.78
Batch: 740; loss: 1.12; acc: 0.66
Batch: 760; loss: 0.98; acc: 0.77
Batch: 780; loss: 1.01; acc: 0.7
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

0.00015078169235493988
0.00014244821795728058
Batch: 0; loss: 0.91; acc: 0.77
Batch: 20; loss: 1.22; acc: 0.7
Batch: 40; loss: 0.78; acc: 0.78
Batch: 60; loss: 0.95; acc: 0.78
Batch: 80; loss: 0.83; acc: 0.77
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.09; acc: 0.77
Batch: 140; loss: 0.81; acc: 0.89
Val Epoch over. val_loss: 1.0093425333879555; val_accuracy: 0.7357683121019108 

The current subspace-distance is: 0.00014244821795728058 

Epoch 27 start
The current lr is: 0.09
Batch: 0; loss: 1.18; acc: 0.72
Batch: 20; loss: 1.21; acc: 0.69
Batch: 40; loss: 0.98; acc: 0.72
Batch: 60; loss: 1.18; acc: 0.66
Batch: 80; loss: 1.06; acc: 0.7
Batch: 100; loss: 1.06; acc: 0.7
Batch: 120; loss: 1.01; acc: 0.67
Batch: 140; loss: 1.0; acc: 0.75
Batch: 160; loss: 0.9; acc: 0.73
Batch: 180; loss: 1.0; acc: 0.75
Batch: 200; loss: 1.0; acc: 0.75
Batch: 220; loss: 1.0; acc: 0.75
Batch: 240; loss: 1.01; acc: 0.66
Batch: 260; loss: 0.92; acc: 0.77
Batch: 280; loss: 1.05; acc: 0.67
Batch: 300; loss: 1.35; acc: 0.67
Batch: 320; loss: 1.12; acc: 0.64
Batch: 340; loss: 1.06; acc: 0.7
Batch: 360; loss: 0.98; acc: 0.8
Batch: 380; loss: 1.07; acc: 0.69
Batch: 400; loss: 1.2; acc: 0.62
Batch: 420; loss: 1.0; acc: 0.72
Batch: 440; loss: 1.16; acc: 0.69
Batch: 460; loss: 1.06; acc: 0.67
Batch: 480; loss: 0.99; acc: 0.7
Batch: 500; loss: 1.05; acc: 0.67
Batch: 520; loss: 0.9; acc: 0.81
Batch: 540; loss: 1.01; acc: 0.73
Batch: 560; loss: 1.09; acc: 0.66
Batch: 580; loss: 1.02; acc: 0.72
Batch: 600; loss: 1.32; acc: 0.64
Batch: 620; loss: 1.27; acc: 0.58
Batch: 640; loss: 1.14; acc: 0.69
Batch: 660; loss: 1.02; acc: 0.72
Batch: 680; loss: 1.09; acc: 0.66
Batch: 700; loss: 1.14; acc: 0.69
Batch: 720; loss: 0.98; acc: 0.73
Batch: 740; loss: 1.1; acc: 0.66
Batch: 760; loss: 0.98; acc: 0.72
Batch: 780; loss: 1.04; acc: 0.64
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

0.00015009063645265996
0.00014485942665487528
Batch: 0; loss: 0.9; acc: 0.8
Batch: 20; loss: 1.22; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.78
Batch: 60; loss: 0.97; acc: 0.75
Batch: 80; loss: 0.84; acc: 0.8
Batch: 100; loss: 0.97; acc: 0.73
Batch: 120; loss: 1.09; acc: 0.75
Batch: 140; loss: 0.83; acc: 0.89
Val Epoch over. val_loss: 1.0122673279920202; val_accuracy: 0.7350716560509554 

The current subspace-distance is: 0.00014485942665487528 

Epoch 28 start
The current lr is: 0.09
Batch: 0; loss: 1.02; acc: 0.72
Batch: 20; loss: 1.28; acc: 0.61
Batch: 40; loss: 1.09; acc: 0.69
Batch: 60; loss: 1.16; acc: 0.66
Batch: 80; loss: 1.01; acc: 0.64
Batch: 100; loss: 1.1; acc: 0.67
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 1.1; acc: 0.7
Batch: 160; loss: 1.03; acc: 0.72
Batch: 180; loss: 1.0; acc: 0.73
Batch: 200; loss: 1.01; acc: 0.7
Batch: 220; loss: 1.14; acc: 0.69
Batch: 240; loss: 1.05; acc: 0.66
Batch: 260; loss: 1.21; acc: 0.61
Batch: 280; loss: 1.01; acc: 0.73
Batch: 300; loss: 1.03; acc: 0.7
Batch: 320; loss: 0.99; acc: 0.75
Batch: 340; loss: 1.08; acc: 0.72
Batch: 360; loss: 1.08; acc: 0.73
Batch: 380; loss: 0.97; acc: 0.7
Batch: 400; loss: 1.16; acc: 0.64
Batch: 420; loss: 0.99; acc: 0.8
Batch: 440; loss: 1.06; acc: 0.73
Batch: 460; loss: 1.08; acc: 0.66
Batch: 480; loss: 0.94; acc: 0.75
Batch: 500; loss: 1.03; acc: 0.77
Batch: 520; loss: 0.93; acc: 0.8
Batch: 540; loss: 1.28; acc: 0.61
Batch: 560; loss: 1.23; acc: 0.64
Batch: 580; loss: 1.04; acc: 0.7
Batch: 600; loss: 1.0; acc: 0.69
Batch: 620; loss: 1.22; acc: 0.64
Batch: 640; loss: 0.96; acc: 0.72
Batch: 660; loss: 1.12; acc: 0.66
Batch: 680; loss: 0.94; acc: 0.73
Batch: 700; loss: 1.2; acc: 0.7
Batch: 720; loss: 1.04; acc: 0.75
Batch: 740; loss: 1.12; acc: 0.73
Batch: 760; loss: 0.86; acc: 0.83
Batch: 780; loss: 1.18; acc: 0.58
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

0.00014917134831193835
0.00014218380965758115
Batch: 0; loss: 0.9; acc: 0.8
Batch: 20; loss: 1.25; acc: 0.69
Batch: 40; loss: 0.77; acc: 0.8
Batch: 60; loss: 0.95; acc: 0.77
Batch: 80; loss: 0.83; acc: 0.81
Batch: 100; loss: 0.97; acc: 0.73
Batch: 120; loss: 1.08; acc: 0.78
Batch: 140; loss: 0.82; acc: 0.88
Val Epoch over. val_loss: 1.0110221573501637; val_accuracy: 0.725218949044586 

The current subspace-distance is: 0.00014218380965758115 

Epoch 29 start
The current lr is: 0.09
Batch: 0; loss: 1.06; acc: 0.77
Batch: 20; loss: 1.16; acc: 0.61
Batch: 40; loss: 0.98; acc: 0.7
Batch: 60; loss: 1.16; acc: 0.66
Batch: 80; loss: 1.08; acc: 0.69
Batch: 100; loss: 1.06; acc: 0.72
Batch: 120; loss: 1.2; acc: 0.69
Batch: 140; loss: 0.99; acc: 0.77
Batch: 160; loss: 0.99; acc: 0.75
Batch: 180; loss: 1.06; acc: 0.69
Batch: 200; loss: 0.97; acc: 0.7
Batch: 220; loss: 1.08; acc: 0.72
Batch: 240; loss: 1.15; acc: 0.72
Batch: 260; loss: 0.96; acc: 0.75
Batch: 280; loss: 0.98; acc: 0.77
Batch: 300; loss: 1.04; acc: 0.73
Batch: 320; loss: 0.89; acc: 0.77
Batch: 340; loss: 1.09; acc: 0.67
Batch: 360; loss: 1.2; acc: 0.67
Batch: 380; loss: 1.02; acc: 0.69
Batch: 400; loss: 0.98; acc: 0.72
Batch: 420; loss: 1.15; acc: 0.66
Batch: 440; loss: 0.99; acc: 0.8
Batch: 460; loss: 1.19; acc: 0.61
Batch: 480; loss: 1.07; acc: 0.69
Batch: 500; loss: 1.32; acc: 0.59
Batch: 520; loss: 1.19; acc: 0.7
Batch: 540; loss: 1.15; acc: 0.62
Batch: 560; loss: 1.09; acc: 0.69
Batch: 580; loss: 1.1; acc: 0.67
Batch: 600; loss: 1.15; acc: 0.58
Batch: 620; loss: 1.15; acc: 0.66
Batch: 640; loss: 1.06; acc: 0.73
Batch: 660; loss: 1.05; acc: 0.72
Batch: 680; loss: 1.15; acc: 0.66
Batch: 700; loss: 0.94; acc: 0.77
Batch: 720; loss: 1.12; acc: 0.67
Batch: 740; loss: 1.21; acc: 0.66
Batch: 760; loss: 0.99; acc: 0.73
Batch: 780; loss: 1.18; acc: 0.62
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

0.000150674328324385
0.00014485052088275552
Batch: 0; loss: 0.88; acc: 0.81
Batch: 20; loss: 1.22; acc: 0.67
Batch: 40; loss: 0.77; acc: 0.8
Batch: 60; loss: 0.95; acc: 0.75
Batch: 80; loss: 0.82; acc: 0.8
Batch: 100; loss: 0.94; acc: 0.73
Batch: 120; loss: 1.08; acc: 0.78
Batch: 140; loss: 0.79; acc: 0.88
Val Epoch over. val_loss: 1.0004830432545608; val_accuracy: 0.7304936305732485 

The current subspace-distance is: 0.00014485052088275552 

Epoch 30 start
The current lr is: 0.09
Batch: 0; loss: 1.09; acc: 0.67
Batch: 20; loss: 1.23; acc: 0.62
Batch: 40; loss: 1.02; acc: 0.72
Batch: 60; loss: 1.08; acc: 0.66
Batch: 80; loss: 1.11; acc: 0.66
Batch: 100; loss: 1.02; acc: 0.67
Batch: 120; loss: 1.05; acc: 0.66
Batch: 140; loss: 1.0; acc: 0.75
Batch: 160; loss: 1.02; acc: 0.69
Batch: 180; loss: 1.0; acc: 0.7
Batch: 200; loss: 1.06; acc: 0.66
Batch: 220; loss: 1.07; acc: 0.73
Batch: 240; loss: 0.98; acc: 0.72
Batch: 260; loss: 1.03; acc: 0.73
Batch: 280; loss: 1.04; acc: 0.67
Batch: 300; loss: 1.3; acc: 0.58
Batch: 320; loss: 1.13; acc: 0.66
Batch: 340; loss: 1.03; acc: 0.69
Batch: 360; loss: 1.08; acc: 0.75
Batch: 380; loss: 1.15; acc: 0.67
Batch: 400; loss: 0.99; acc: 0.66
Batch: 420; loss: 1.12; acc: 0.7
Batch: 440; loss: 1.23; acc: 0.62
Batch: 460; loss: 1.07; acc: 0.69
Batch: 480; loss: 1.01; acc: 0.73
Batch: 500; loss: 1.11; acc: 0.64
Batch: 520; loss: 1.01; acc: 0.67
Batch: 540; loss: 0.99; acc: 0.78
Batch: 560; loss: 1.22; acc: 0.64
Batch: 580; loss: 0.95; acc: 0.69
Batch: 600; loss: 1.17; acc: 0.7
Batch: 620; loss: 0.88; acc: 0.81
Batch: 640; loss: 1.08; acc: 0.67
Batch: 660; loss: 0.98; acc: 0.73
Batch: 680; loss: 1.04; acc: 0.7
Batch: 700; loss: 0.98; acc: 0.81
Batch: 720; loss: 1.15; acc: 0.66
Batch: 740; loss: 0.93; acc: 0.7
Batch: 760; loss: 1.01; acc: 0.67
Batch: 780; loss: 1.26; acc: 0.62
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

0.00015063848695717752
0.00014352732978295535
Batch: 0; loss: 0.89; acc: 0.84
Batch: 20; loss: 1.22; acc: 0.67
Batch: 40; loss: 0.77; acc: 0.78
Batch: 60; loss: 0.95; acc: 0.77
Batch: 80; loss: 0.82; acc: 0.78
Batch: 100; loss: 0.96; acc: 0.75
Batch: 120; loss: 1.08; acc: 0.78
Batch: 140; loss: 0.79; acc: 0.89
Val Epoch over. val_loss: 0.9993527057064566; val_accuracy: 0.7329816878980892 

The current subspace-distance is: 0.00014352732978295535 

plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_300_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64

Channel scaling factor: 13.5

The number of parameters is: 279504

The number of individual parameters is:

108
432
108
108
162
52488
162
162
324
157464
324
324
64
62208
64
64
4096
64
640
10
64
64

nonzero elements in E: 111801589
elements in E: 111801600
fraction nonzero: 0.9999999016114259
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.33; acc: 0.12
Batch: 20; loss: 2.02; acc: 0.38
Batch: 40; loss: 1.99; acc: 0.36
Batch: 60; loss: 1.81; acc: 0.41
Batch: 80; loss: 1.74; acc: 0.47
Batch: 100; loss: 1.72; acc: 0.47
Batch: 120; loss: 1.71; acc: 0.47
Batch: 140; loss: 1.7; acc: 0.47
Batch: 160; loss: 1.78; acc: 0.41
Batch: 180; loss: 1.52; acc: 0.66
Batch: 200; loss: 1.81; acc: 0.41
Batch: 220; loss: 1.5; acc: 0.61
Batch: 240; loss: 1.65; acc: 0.56
Batch: 260; loss: 1.6; acc: 0.55
Batch: 280; loss: 1.73; acc: 0.48
Batch: 300; loss: 1.6; acc: 0.52
Batch: 320; loss: 1.52; acc: 0.59
Batch: 340; loss: 1.68; acc: 0.48
Batch: 360; loss: 1.56; acc: 0.52
Batch: 380; loss: 1.51; acc: 0.59
Batch: 400; loss: 1.48; acc: 0.58
Batch: 420; loss: 1.52; acc: 0.58
Batch: 440; loss: 1.44; acc: 0.58
Batch: 460; loss: 1.5; acc: 0.64
Batch: 480; loss: 1.52; acc: 0.56
Batch: 500; loss: 1.5; acc: 0.61
Batch: 520; loss: 1.33; acc: 0.67
Batch: 540; loss: 1.46; acc: 0.64
Batch: 560; loss: 1.43; acc: 0.58
Batch: 580; loss: 1.46; acc: 0.58
Batch: 600; loss: 1.37; acc: 0.61
Batch: 620; loss: 1.43; acc: 0.58
Batch: 640; loss: 1.37; acc: 0.69
Batch: 660; loss: 1.25; acc: 0.66
Batch: 680; loss: 1.46; acc: 0.58
Batch: 700; loss: 1.53; acc: 0.52
Batch: 720; loss: 1.41; acc: 0.64
Batch: 740; loss: 1.54; acc: 0.53
Batch: 760; loss: 1.37; acc: 0.62
Batch: 780; loss: 1.44; acc: 0.56
Train Epoch over. train_loss: 1.6; train_accuracy: 0.53 

3.0176210202625953e-05
6.2691906350664794e-06
Batch: 0; loss: 1.38; acc: 0.64
Batch: 20; loss: 1.67; acc: 0.42
Batch: 40; loss: 1.23; acc: 0.72
Batch: 60; loss: 1.28; acc: 0.66
Batch: 80; loss: 1.41; acc: 0.66
Batch: 100; loss: 1.44; acc: 0.62
Batch: 120; loss: 1.48; acc: 0.53
Batch: 140; loss: 1.35; acc: 0.75
Val Epoch over. val_loss: 1.4778500256265046; val_accuracy: 0.5868829617834395 

The current subspace-distance is: 6.2691906350664794e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.37; acc: 0.66
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 1.37; acc: 0.58
Batch: 60; loss: 1.24; acc: 0.69
Batch: 80; loss: 1.32; acc: 0.62
Batch: 100; loss: 1.41; acc: 0.58
Batch: 120; loss: 1.28; acc: 0.66
Batch: 140; loss: 1.42; acc: 0.66
Batch: 160; loss: 1.25; acc: 0.67
Batch: 180; loss: 1.52; acc: 0.53
Batch: 200; loss: 1.42; acc: 0.55
Batch: 220; loss: 1.28; acc: 0.66
Batch: 240; loss: 1.49; acc: 0.55
Batch: 260; loss: 1.5; acc: 0.52
Batch: 280; loss: 1.39; acc: 0.59
Batch: 300; loss: 1.45; acc: 0.56
Batch: 320; loss: 1.64; acc: 0.47
Batch: 340; loss: 1.44; acc: 0.61
Batch: 360; loss: 1.33; acc: 0.64
Batch: 380; loss: 1.23; acc: 0.66
Batch: 400; loss: 1.23; acc: 0.7
Batch: 420; loss: 1.26; acc: 0.69
Batch: 440; loss: 1.22; acc: 0.66
Batch: 460; loss: 1.45; acc: 0.59
Batch: 480; loss: 1.29; acc: 0.64
Batch: 500; loss: 1.33; acc: 0.64
Batch: 520; loss: 1.24; acc: 0.66
Batch: 540; loss: 1.29; acc: 0.59
Batch: 560; loss: 1.27; acc: 0.62
Batch: 580; loss: 1.32; acc: 0.59
Batch: 600; loss: 1.07; acc: 0.75
Batch: 620; loss: 1.21; acc: 0.66
Batch: 640; loss: 1.21; acc: 0.64
Batch: 660; loss: 1.34; acc: 0.61
Batch: 680; loss: 1.26; acc: 0.66
Batch: 700; loss: 1.35; acc: 0.58
Batch: 720; loss: 1.18; acc: 0.69
Batch: 740; loss: 1.21; acc: 0.67
Batch: 760; loss: 1.26; acc: 0.64
Batch: 780; loss: 1.4; acc: 0.55
Train Epoch over. train_loss: 1.34; train_accuracy: 0.62 

3.1849041988607496e-05
8.704999345354736e-06
Batch: 0; loss: 1.2; acc: 0.66
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.16; acc: 0.66
Batch: 60; loss: 1.28; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.59
Batch: 100; loss: 1.31; acc: 0.67
Batch: 120; loss: 1.45; acc: 0.55
Batch: 140; loss: 1.26; acc: 0.66
Val Epoch over. val_loss: 1.3891667127609253; val_accuracy: 0.5604100318471338 

The current subspace-distance is: 8.704999345354736e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.33; acc: 0.62
Batch: 20; loss: 1.33; acc: 0.61
Batch: 40; loss: 1.34; acc: 0.62
Batch: 60; loss: 1.21; acc: 0.66
Batch: 80; loss: 1.23; acc: 0.69
Batch: 100; loss: 1.23; acc: 0.64
Batch: 120; loss: 1.16; acc: 0.72
Batch: 140; loss: 1.35; acc: 0.58
Batch: 160; loss: 1.18; acc: 0.64
Batch: 180; loss: 1.3; acc: 0.55
Batch: 200; loss: 1.29; acc: 0.7
Batch: 220; loss: 1.09; acc: 0.67
Batch: 240; loss: 1.37; acc: 0.59
Batch: 260; loss: 1.14; acc: 0.73
Batch: 280; loss: 1.36; acc: 0.64
Batch: 300; loss: 1.17; acc: 0.66
Batch: 320; loss: 1.24; acc: 0.64
Batch: 340; loss: 1.15; acc: 0.75
Batch: 360; loss: 1.1; acc: 0.72
Batch: 380; loss: 1.02; acc: 0.77
Batch: 400; loss: 1.2; acc: 0.64
Batch: 420; loss: 1.04; acc: 0.75
Batch: 440; loss: 1.24; acc: 0.61
Batch: 460; loss: 1.39; acc: 0.58
Batch: 480; loss: 1.15; acc: 0.72
Batch: 500; loss: 1.09; acc: 0.67
Batch: 520; loss: 1.28; acc: 0.61
Batch: 540; loss: 1.25; acc: 0.72
Batch: 560; loss: 1.14; acc: 0.66
Batch: 580; loss: 1.18; acc: 0.62
Batch: 600; loss: 1.27; acc: 0.66
Batch: 620; loss: 1.52; acc: 0.52
Batch: 640; loss: 1.14; acc: 0.7
Batch: 660; loss: 1.15; acc: 0.72
Batch: 680; loss: 1.0; acc: 0.81
Batch: 700; loss: 1.08; acc: 0.7
Batch: 720; loss: 1.09; acc: 0.77
Batch: 740; loss: 1.2; acc: 0.7
Batch: 760; loss: 1.38; acc: 0.55
Batch: 780; loss: 1.01; acc: 0.69
Train Epoch over. train_loss: 1.24; train_accuracy: 0.65 

3.4339547710260376e-05
1.0316725820302963e-05
Batch: 0; loss: 1.16; acc: 0.64
Batch: 20; loss: 1.77; acc: 0.38
Batch: 40; loss: 1.23; acc: 0.66
Batch: 60; loss: 1.37; acc: 0.53
Batch: 80; loss: 1.2; acc: 0.66
Batch: 100; loss: 1.35; acc: 0.67
Batch: 120; loss: 1.51; acc: 0.5
Batch: 140; loss: 1.38; acc: 0.59
Val Epoch over. val_loss: 1.4536826056279954; val_accuracy: 0.5253781847133758 

The current subspace-distance is: 1.0316725820302963e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.26; acc: 0.61
Batch: 20; loss: 1.12; acc: 0.75
Batch: 40; loss: 1.2; acc: 0.69
Batch: 60; loss: 1.27; acc: 0.64
Batch: 80; loss: 1.13; acc: 0.72
Batch: 100; loss: 1.18; acc: 0.69
Batch: 120; loss: 1.13; acc: 0.72
Batch: 140; loss: 1.38; acc: 0.56
Batch: 160; loss: 1.21; acc: 0.61
Batch: 180; loss: 1.05; acc: 0.73
Batch: 200; loss: 1.16; acc: 0.67
Batch: 220; loss: 1.27; acc: 0.59
Batch: 240; loss: 1.28; acc: 0.69
Batch: 260; loss: 1.09; acc: 0.73
Batch: 280; loss: 1.09; acc: 0.69
Batch: 300; loss: 1.33; acc: 0.59
Batch: 320; loss: 1.04; acc: 0.67
Batch: 340; loss: 1.18; acc: 0.75
Batch: 360; loss: 1.0; acc: 0.77
Batch: 380; loss: 1.18; acc: 0.69
Batch: 400; loss: 0.94; acc: 0.8
Batch: 420; loss: 1.4; acc: 0.56
Batch: 440; loss: 1.18; acc: 0.66
Batch: 460; loss: 1.08; acc: 0.66
Batch: 480; loss: 1.17; acc: 0.75
Batch: 500; loss: 1.36; acc: 0.53
Batch: 520; loss: 1.08; acc: 0.77
Batch: 540; loss: 1.09; acc: 0.69
Batch: 560; loss: 1.29; acc: 0.58
Batch: 580; loss: 1.16; acc: 0.73
Batch: 600; loss: 0.98; acc: 0.8
Batch: 620; loss: 1.07; acc: 0.72
Batch: 640; loss: 1.32; acc: 0.59
Batch: 660; loss: 1.39; acc: 0.58
Batch: 680; loss: 1.27; acc: 0.59
Batch: 700; loss: 1.28; acc: 0.59
Batch: 720; loss: 1.04; acc: 0.72
Batch: 740; loss: 1.11; acc: 0.67
Batch: 760; loss: 1.2; acc: 0.69
Batch: 780; loss: 1.32; acc: 0.61
Train Epoch over. train_loss: 1.18; train_accuracy: 0.67 

3.550618203007616e-05
1.098931079468457e-05
Batch: 0; loss: 0.97; acc: 0.72
Batch: 20; loss: 1.47; acc: 0.5
Batch: 40; loss: 0.92; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.73
Batch: 80; loss: 1.0; acc: 0.7
Batch: 100; loss: 1.12; acc: 0.69
Batch: 120; loss: 1.26; acc: 0.66
Batch: 140; loss: 0.98; acc: 0.78
Val Epoch over. val_loss: 1.1786146665075024; val_accuracy: 0.6601313694267515 

The current subspace-distance is: 1.098931079468457e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.03; acc: 0.69
Batch: 20; loss: 1.08; acc: 0.7
Batch: 40; loss: 1.12; acc: 0.77
Batch: 60; loss: 1.18; acc: 0.7
Batch: 80; loss: 1.17; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.75
Batch: 120; loss: 1.26; acc: 0.64
Batch: 140; loss: 1.14; acc: 0.62
Batch: 160; loss: 1.28; acc: 0.62
Batch: 180; loss: 1.06; acc: 0.69
Batch: 200; loss: 1.1; acc: 0.69
Batch: 220; loss: 1.09; acc: 0.73
Batch: 240; loss: 1.04; acc: 0.73
Batch: 260; loss: 1.18; acc: 0.69
Batch: 280; loss: 1.15; acc: 0.66
Batch: 300; loss: 1.06; acc: 0.72
Batch: 320; loss: 1.03; acc: 0.78
Batch: 340; loss: 1.21; acc: 0.64
Batch: 360; loss: 1.25; acc: 0.58
Batch: 380; loss: 1.03; acc: 0.72
Batch: 400; loss: 1.26; acc: 0.7
Batch: 420; loss: 1.41; acc: 0.52
Batch: 440; loss: 1.04; acc: 0.7
Batch: 460; loss: 1.22; acc: 0.58
Batch: 480; loss: 1.22; acc: 0.62
Batch: 500; loss: 1.08; acc: 0.72
Batch: 520; loss: 1.13; acc: 0.67
Batch: 540; loss: 1.07; acc: 0.7
Batch: 560; loss: 1.2; acc: 0.66
Batch: 580; loss: 1.2; acc: 0.62
Batch: 600; loss: 1.15; acc: 0.67
Batch: 620; loss: 0.92; acc: 0.8
Batch: 640; loss: 1.26; acc: 0.62
Batch: 660; loss: 1.18; acc: 0.62
Batch: 680; loss: 1.33; acc: 0.56
Batch: 700; loss: 1.01; acc: 0.77
Batch: 720; loss: 1.29; acc: 0.64
Batch: 740; loss: 1.13; acc: 0.67
Batch: 760; loss: 1.35; acc: 0.58
Batch: 780; loss: 1.1; acc: 0.69
Train Epoch over. train_loss: 1.14; train_accuracy: 0.68 

3.734257188625634e-05
1.2366301234578714e-05
Batch: 0; loss: 0.98; acc: 0.73
Batch: 20; loss: 1.59; acc: 0.52
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 1.13; acc: 0.7
Batch: 80; loss: 1.22; acc: 0.62
Batch: 100; loss: 1.12; acc: 0.72
Batch: 120; loss: 1.36; acc: 0.58
Batch: 140; loss: 0.98; acc: 0.83
Val Epoch over. val_loss: 1.19753246018841; val_accuracy: 0.6510748407643312 

The current subspace-distance is: 1.2366301234578714e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.99; acc: 0.75
Batch: 20; loss: 1.21; acc: 0.67
Batch: 40; loss: 1.28; acc: 0.58
Batch: 60; loss: 1.05; acc: 0.77
Batch: 80; loss: 1.14; acc: 0.67
Batch: 100; loss: 1.09; acc: 0.7
Batch: 120; loss: 0.92; acc: 0.72
Batch: 140; loss: 1.31; acc: 0.56
Batch: 160; loss: 1.13; acc: 0.66
Batch: 180; loss: 0.99; acc: 0.8
Batch: 200; loss: 1.18; acc: 0.73
Batch: 220; loss: 1.04; acc: 0.69
Batch: 240; loss: 1.13; acc: 0.73
Batch: 260; loss: 1.07; acc: 0.72
Batch: 280; loss: 1.34; acc: 0.58
Batch: 300; loss: 0.9; acc: 0.81
Batch: 320; loss: 1.13; acc: 0.7
Batch: 340; loss: 1.15; acc: 0.62
Batch: 360; loss: 1.09; acc: 0.7
Batch: 380; loss: 1.35; acc: 0.53
Batch: 400; loss: 1.09; acc: 0.73
Batch: 420; loss: 1.06; acc: 0.73
Batch: 440; loss: 0.99; acc: 0.77
Batch: 460; loss: 1.03; acc: 0.67
Batch: 480; loss: 1.11; acc: 0.73
Batch: 500; loss: 1.08; acc: 0.69
Batch: 520; loss: 1.11; acc: 0.69
Batch: 540; loss: 0.98; acc: 0.77
Batch: 560; loss: 1.07; acc: 0.7
Batch: 580; loss: 1.02; acc: 0.67
Batch: 600; loss: 1.04; acc: 0.69
Batch: 620; loss: 1.09; acc: 0.73
Batch: 640; loss: 0.97; acc: 0.72
Batch: 660; loss: 0.97; acc: 0.77
Batch: 680; loss: 1.06; acc: 0.69
Batch: 700; loss: 1.01; acc: 0.75
Batch: 720; loss: 1.24; acc: 0.61
Batch: 740; loss: 0.98; acc: 0.73
Batch: 760; loss: 1.14; acc: 0.66
Batch: 780; loss: 1.28; acc: 0.59
Train Epoch over. train_loss: 1.1; train_accuracy: 0.69 

3.930656748707406e-05
1.352899653284112e-05
Batch: 0; loss: 0.9; acc: 0.77
Batch: 20; loss: 1.38; acc: 0.56
Batch: 40; loss: 0.84; acc: 0.81
Batch: 60; loss: 0.92; acc: 0.78
Batch: 80; loss: 0.97; acc: 0.72
Batch: 100; loss: 1.03; acc: 0.73
Batch: 120; loss: 1.27; acc: 0.62
Batch: 140; loss: 0.79; acc: 0.89
Val Epoch over. val_loss: 1.0621533830454395; val_accuracy: 0.7127786624203821 

The current subspace-distance is: 1.352899653284112e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.95; acc: 0.77
Batch: 20; loss: 1.15; acc: 0.7
Batch: 40; loss: 1.06; acc: 0.73
Batch: 60; loss: 1.04; acc: 0.72
Batch: 80; loss: 1.09; acc: 0.73
Batch: 100; loss: 1.0; acc: 0.75
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.91; acc: 0.75
Batch: 160; loss: 1.14; acc: 0.67
Batch: 180; loss: 1.25; acc: 0.69
Batch: 200; loss: 1.05; acc: 0.69
Batch: 220; loss: 1.22; acc: 0.64
Batch: 240; loss: 1.12; acc: 0.64
Batch: 260; loss: 1.04; acc: 0.73
Batch: 280; loss: 1.04; acc: 0.72
Batch: 300; loss: 1.1; acc: 0.75
Batch: 320; loss: 1.09; acc: 0.7
Batch: 340; loss: 1.13; acc: 0.7
Batch: 360; loss: 1.28; acc: 0.62
Batch: 380; loss: 1.09; acc: 0.67
Batch: 400; loss: 1.1; acc: 0.7
Batch: 420; loss: 1.04; acc: 0.73
Batch: 440; loss: 1.24; acc: 0.66
Batch: 460; loss: 1.15; acc: 0.69
Batch: 480; loss: 1.09; acc: 0.66
Batch: 500; loss: 1.12; acc: 0.64
Batch: 520; loss: 0.96; acc: 0.72
Batch: 540; loss: 0.87; acc: 0.81
Batch: 560; loss: 0.95; acc: 0.72
Batch: 580; loss: 1.18; acc: 0.62
Batch: 600; loss: 1.0; acc: 0.7
Batch: 620; loss: 1.18; acc: 0.67
Batch: 640; loss: 1.03; acc: 0.72
Batch: 660; loss: 1.11; acc: 0.69
Batch: 680; loss: 1.15; acc: 0.7
Batch: 700; loss: 1.0; acc: 0.7
Batch: 720; loss: 1.13; acc: 0.64
Batch: 740; loss: 1.08; acc: 0.67
Batch: 760; loss: 1.02; acc: 0.64
Batch: 780; loss: 1.09; acc: 0.67
Train Epoch over. train_loss: 1.07; train_accuracy: 0.7 

4.106368942302652e-05
1.4652739082521293e-05
Batch: 0; loss: 0.97; acc: 0.73
Batch: 20; loss: 1.58; acc: 0.5
Batch: 40; loss: 0.99; acc: 0.72
Batch: 60; loss: 1.17; acc: 0.61
Batch: 80; loss: 1.29; acc: 0.55
Batch: 100; loss: 1.19; acc: 0.66
Batch: 120; loss: 1.36; acc: 0.58
Batch: 140; loss: 0.95; acc: 0.81
Val Epoch over. val_loss: 1.2071510306589164; val_accuracy: 0.6282842356687898 

The current subspace-distance is: 1.4652739082521293e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.7
Batch: 20; loss: 1.09; acc: 0.7
Batch: 40; loss: 1.28; acc: 0.62
Batch: 60; loss: 1.2; acc: 0.66
Batch: 80; loss: 0.97; acc: 0.69
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.18; acc: 0.67
Batch: 140; loss: 1.0; acc: 0.69
Batch: 160; loss: 1.17; acc: 0.56
Batch: 180; loss: 1.04; acc: 0.62
Batch: 200; loss: 1.14; acc: 0.66
Batch: 220; loss: 1.02; acc: 0.75
Batch: 240; loss: 0.94; acc: 0.78
Batch: 260; loss: 0.91; acc: 0.77
Batch: 280; loss: 1.1; acc: 0.7
Batch: 300; loss: 1.35; acc: 0.53
Batch: 320; loss: 1.17; acc: 0.66
Batch: 340; loss: 1.09; acc: 0.73
Batch: 360; loss: 0.98; acc: 0.69
Batch: 380; loss: 0.96; acc: 0.72
Batch: 400; loss: 1.03; acc: 0.72
Batch: 420; loss: 0.91; acc: 0.73
Batch: 440; loss: 0.93; acc: 0.75
Batch: 460; loss: 1.15; acc: 0.58
Batch: 480; loss: 1.07; acc: 0.72
Batch: 500; loss: 1.01; acc: 0.7
Batch: 520; loss: 1.09; acc: 0.64
Batch: 540; loss: 1.07; acc: 0.7
Batch: 560; loss: 1.09; acc: 0.72
Batch: 580; loss: 1.15; acc: 0.62
Batch: 600; loss: 1.11; acc: 0.64
Batch: 620; loss: 0.91; acc: 0.8
Batch: 640; loss: 0.97; acc: 0.75
Batch: 660; loss: 1.1; acc: 0.69
Batch: 680; loss: 1.11; acc: 0.69
Batch: 700; loss: 0.96; acc: 0.81
Batch: 720; loss: 0.94; acc: 0.73
Batch: 740; loss: 0.99; acc: 0.73
Batch: 760; loss: 1.13; acc: 0.67
Batch: 780; loss: 1.18; acc: 0.73
Train Epoch over. train_loss: 1.05; train_accuracy: 0.7 

4.1947801946662366e-05
1.7096728697651997e-05
Batch: 0; loss: 0.81; acc: 0.84
Batch: 20; loss: 1.23; acc: 0.62
Batch: 40; loss: 0.77; acc: 0.77
Batch: 60; loss: 0.95; acc: 0.72
Batch: 80; loss: 0.91; acc: 0.72
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.25; acc: 0.56
Batch: 140; loss: 0.73; acc: 0.89
Val Epoch over. val_loss: 1.0230938993441832; val_accuracy: 0.700437898089172 

The current subspace-distance is: 1.7096728697651997e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.98; acc: 0.73
Batch: 20; loss: 1.0; acc: 0.77
Batch: 40; loss: 1.13; acc: 0.67
Batch: 60; loss: 1.01; acc: 0.73
Batch: 80; loss: 1.25; acc: 0.66
Batch: 100; loss: 0.99; acc: 0.72
Batch: 120; loss: 1.17; acc: 0.58
Batch: 140; loss: 0.93; acc: 0.75
Batch: 160; loss: 1.01; acc: 0.73
Batch: 180; loss: 1.18; acc: 0.67
Batch: 200; loss: 0.9; acc: 0.78
Batch: 220; loss: 1.16; acc: 0.64
Batch: 240; loss: 1.03; acc: 0.72
Batch: 260; loss: 1.05; acc: 0.73
Batch: 280; loss: 1.04; acc: 0.72
Batch: 300; loss: 0.85; acc: 0.8
Batch: 320; loss: 1.07; acc: 0.72
Batch: 340; loss: 1.14; acc: 0.67
Batch: 360; loss: 1.13; acc: 0.7
Batch: 380; loss: 1.14; acc: 0.62
Batch: 400; loss: 0.99; acc: 0.73
Batch: 420; loss: 1.11; acc: 0.64
Batch: 440; loss: 1.09; acc: 0.61
Batch: 460; loss: 1.06; acc: 0.7
Batch: 480; loss: 1.08; acc: 0.66
Batch: 500; loss: 0.98; acc: 0.72
Batch: 520; loss: 1.11; acc: 0.72
Batch: 540; loss: 0.87; acc: 0.78
Batch: 560; loss: 1.19; acc: 0.66
Batch: 580; loss: 1.12; acc: 0.67
Batch: 600; loss: 1.04; acc: 0.69
Batch: 620; loss: 1.05; acc: 0.69
Batch: 640; loss: 0.94; acc: 0.72
Batch: 660; loss: 0.93; acc: 0.7
Batch: 680; loss: 1.0; acc: 0.64
Batch: 700; loss: 0.92; acc: 0.77
Batch: 720; loss: 1.07; acc: 0.75
Batch: 740; loss: 1.07; acc: 0.69
Batch: 760; loss: 1.11; acc: 0.69
Batch: 780; loss: 0.88; acc: 0.84
Train Epoch over. train_loss: 1.03; train_accuracy: 0.7 

4.413673377712257e-05
1.6869811588549055e-05
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.83; acc: 0.36
Batch: 40; loss: 1.33; acc: 0.56
Batch: 60; loss: 1.52; acc: 0.5
Batch: 80; loss: 1.75; acc: 0.5
Batch: 100; loss: 1.4; acc: 0.55
Batch: 120; loss: 1.54; acc: 0.5
Batch: 140; loss: 1.46; acc: 0.55
Val Epoch over. val_loss: 1.6105146704206041; val_accuracy: 0.4914410828025478 

The current subspace-distance is: 1.6869811588549055e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.03; acc: 0.67
Batch: 20; loss: 0.97; acc: 0.7
Batch: 40; loss: 1.06; acc: 0.69
Batch: 60; loss: 1.08; acc: 0.64
Batch: 80; loss: 0.95; acc: 0.78
Batch: 100; loss: 1.11; acc: 0.67
Batch: 120; loss: 0.9; acc: 0.75
Batch: 140; loss: 1.01; acc: 0.77
Batch: 160; loss: 1.08; acc: 0.69
Batch: 180; loss: 0.92; acc: 0.73
Batch: 200; loss: 1.11; acc: 0.69
Batch: 220; loss: 1.02; acc: 0.69
Batch: 240; loss: 0.97; acc: 0.78
Batch: 260; loss: 0.93; acc: 0.8
Batch: 280; loss: 1.02; acc: 0.72
Batch: 300; loss: 0.98; acc: 0.72
Batch: 320; loss: 1.27; acc: 0.59
Batch: 340; loss: 1.08; acc: 0.73
Batch: 360; loss: 1.13; acc: 0.66
Batch: 380; loss: 1.07; acc: 0.77
Batch: 400; loss: 1.07; acc: 0.69
Batch: 420; loss: 1.06; acc: 0.69
Batch: 440; loss: 1.05; acc: 0.66
Batch: 460; loss: 1.26; acc: 0.59
Batch: 480; loss: 1.08; acc: 0.69
Batch: 500; loss: 1.2; acc: 0.64
Batch: 520; loss: 0.97; acc: 0.77
Batch: 540; loss: 0.99; acc: 0.69
Batch: 560; loss: 0.99; acc: 0.7
Batch: 580; loss: 1.02; acc: 0.69
Batch: 600; loss: 0.89; acc: 0.81
Batch: 620; loss: 0.96; acc: 0.69
Batch: 640; loss: 1.1; acc: 0.64
Batch: 660; loss: 0.9; acc: 0.73
Batch: 680; loss: 0.98; acc: 0.67
Batch: 700; loss: 0.92; acc: 0.77
Batch: 720; loss: 0.85; acc: 0.72
Batch: 740; loss: 0.98; acc: 0.73
Batch: 760; loss: 0.94; acc: 0.73
Batch: 780; loss: 0.99; acc: 0.78
Train Epoch over. train_loss: 1.02; train_accuracy: 0.71 

4.484917371883057e-05
1.7667192878434435e-05
Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 1.25; acc: 0.61
Batch: 40; loss: 0.88; acc: 0.69
Batch: 60; loss: 1.07; acc: 0.66
Batch: 80; loss: 0.99; acc: 0.7
Batch: 100; loss: 1.2; acc: 0.58
Batch: 120; loss: 1.4; acc: 0.62
Batch: 140; loss: 0.9; acc: 0.73
Val Epoch over. val_loss: 1.0780860140065478; val_accuracy: 0.6592356687898089 

The current subspace-distance is: 1.7667192878434435e-05 

Epoch 11 start
The current lr is: 0.3
Batch: 0; loss: 1.33; acc: 0.59
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 0.84; acc: 0.78
Batch: 60; loss: 0.86; acc: 0.77
Batch: 80; loss: 0.93; acc: 0.75
Batch: 100; loss: 0.96; acc: 0.73
Batch: 120; loss: 0.97; acc: 0.7
Batch: 140; loss: 1.12; acc: 0.75
Batch: 160; loss: 0.94; acc: 0.67
Batch: 180; loss: 0.89; acc: 0.72
Batch: 200; loss: 0.91; acc: 0.78
Batch: 220; loss: 0.87; acc: 0.78
Batch: 240; loss: 1.01; acc: 0.7
Batch: 260; loss: 1.13; acc: 0.64
Batch: 280; loss: 1.05; acc: 0.62
Batch: 300; loss: 1.19; acc: 0.61
Batch: 320; loss: 1.09; acc: 0.72
Batch: 340; loss: 1.05; acc: 0.75
Batch: 360; loss: 0.96; acc: 0.7
Batch: 380; loss: 1.21; acc: 0.66
Batch: 400; loss: 0.72; acc: 0.83
Batch: 420; loss: 0.96; acc: 0.78
Batch: 440; loss: 1.01; acc: 0.7
Batch: 460; loss: 1.06; acc: 0.77
Batch: 480; loss: 0.84; acc: 0.8
Batch: 500; loss: 0.83; acc: 0.73
Batch: 520; loss: 1.01; acc: 0.73
Batch: 540; loss: 0.7; acc: 0.84
Batch: 560; loss: 1.0; acc: 0.73
Batch: 580; loss: 1.11; acc: 0.67
Batch: 600; loss: 1.06; acc: 0.7
Batch: 620; loss: 0.77; acc: 0.81
Batch: 640; loss: 1.06; acc: 0.67
Batch: 660; loss: 1.03; acc: 0.77
Batch: 680; loss: 0.68; acc: 0.83
Batch: 700; loss: 0.88; acc: 0.83
Batch: 720; loss: 0.95; acc: 0.72
Batch: 740; loss: 1.18; acc: 0.64
Batch: 760; loss: 0.82; acc: 0.83
Batch: 780; loss: 0.96; acc: 0.77
Train Epoch over. train_loss: 1.0; train_accuracy: 0.71 

4.636450103134848e-05
1.8241846191813238e-05
Batch: 0; loss: 0.7; acc: 0.91
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.69; acc: 0.83
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.78; acc: 0.83
Batch: 100; loss: 0.95; acc: 0.69
Batch: 120; loss: 1.12; acc: 0.67
Batch: 140; loss: 0.66; acc: 0.88
Val Epoch over. val_loss: 0.9277089044546626; val_accuracy: 0.7429339171974523 

The current subspace-distance is: 1.8241846191813238e-05 

Epoch 12 start
The current lr is: 0.3
Batch: 0; loss: 0.78; acc: 0.83
Batch: 20; loss: 0.97; acc: 0.78
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 1.07; acc: 0.72
Batch: 100; loss: 0.98; acc: 0.75
Batch: 120; loss: 1.0; acc: 0.67
Batch: 140; loss: 1.02; acc: 0.75
Batch: 160; loss: 0.92; acc: 0.75
Batch: 180; loss: 1.19; acc: 0.56
Batch: 200; loss: 0.98; acc: 0.69
Batch: 220; loss: 1.03; acc: 0.69
Batch: 240; loss: 1.06; acc: 0.77
Batch: 260; loss: 0.99; acc: 0.78
Batch: 280; loss: 0.92; acc: 0.7
Batch: 300; loss: 0.99; acc: 0.72
Batch: 320; loss: 0.82; acc: 0.84
Batch: 340; loss: 1.02; acc: 0.7
Batch: 360; loss: 1.08; acc: 0.7
Batch: 380; loss: 0.99; acc: 0.75
Batch: 400; loss: 1.35; acc: 0.61
Batch: 420; loss: 0.98; acc: 0.72
Batch: 440; loss: 1.15; acc: 0.59
Batch: 460; loss: 1.17; acc: 0.64
Batch: 480; loss: 0.95; acc: 0.77
Batch: 500; loss: 0.92; acc: 0.75
Batch: 520; loss: 0.98; acc: 0.72
Batch: 540; loss: 0.86; acc: 0.83
Batch: 560; loss: 1.02; acc: 0.7
Batch: 580; loss: 0.95; acc: 0.72
Batch: 600; loss: 1.02; acc: 0.66
Batch: 620; loss: 0.97; acc: 0.75
Batch: 640; loss: 1.16; acc: 0.67
Batch: 660; loss: 1.04; acc: 0.77
Batch: 680; loss: 1.02; acc: 0.77
Batch: 700; loss: 1.0; acc: 0.7
Batch: 720; loss: 0.82; acc: 0.78
Batch: 740; loss: 0.88; acc: 0.77
Batch: 760; loss: 0.91; acc: 0.78
Batch: 780; loss: 1.13; acc: 0.67
Train Epoch over. train_loss: 0.99; train_accuracy: 0.72 

4.647788591682911e-05
1.8334863852942362e-05
Batch: 0; loss: 0.72; acc: 0.88
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.68; acc: 0.86
Batch: 60; loss: 0.87; acc: 0.73
Batch: 80; loss: 0.8; acc: 0.8
Batch: 100; loss: 0.94; acc: 0.7
Batch: 120; loss: 1.12; acc: 0.67
Batch: 140; loss: 0.67; acc: 0.88
Val Epoch over. val_loss: 0.9217676455807534; val_accuracy: 0.7512937898089171 

The current subspace-distance is: 1.8334863852942362e-05 

Epoch 13 start
The current lr is: 0.3
Batch: 0; loss: 1.09; acc: 0.72
Batch: 20; loss: 1.08; acc: 0.66
Batch: 40; loss: 1.1; acc: 0.62
Batch: 60; loss: 1.0; acc: 0.77
Batch: 80; loss: 0.71; acc: 0.86
Batch: 100; loss: 0.88; acc: 0.73
Batch: 120; loss: 0.75; acc: 0.84
Batch: 140; loss: 1.11; acc: 0.67
Batch: 160; loss: 1.1; acc: 0.67
Batch: 180; loss: 1.08; acc: 0.67
Batch: 200; loss: 0.93; acc: 0.78
Batch: 220; loss: 0.95; acc: 0.78
Batch: 240; loss: 1.06; acc: 0.73
Batch: 260; loss: 1.13; acc: 0.64
Batch: 280; loss: 0.96; acc: 0.73
Batch: 300; loss: 1.05; acc: 0.69
Batch: 320; loss: 0.98; acc: 0.73
Batch: 340; loss: 1.24; acc: 0.66
Batch: 360; loss: 0.91; acc: 0.8
Batch: 380; loss: 1.06; acc: 0.67
Batch: 400; loss: 1.1; acc: 0.72
Batch: 420; loss: 1.17; acc: 0.66
Batch: 440; loss: 1.03; acc: 0.64
Batch: 460; loss: 1.08; acc: 0.62
Batch: 480; loss: 0.98; acc: 0.69
Batch: 500; loss: 1.11; acc: 0.72
Batch: 520; loss: 1.0; acc: 0.75
Batch: 540; loss: 0.85; acc: 0.77
Batch: 560; loss: 1.03; acc: 0.7
Batch: 580; loss: 0.97; acc: 0.7
Batch: 600; loss: 0.94; acc: 0.7
Batch: 620; loss: 1.05; acc: 0.67
Batch: 640; loss: 0.91; acc: 0.81
Batch: 660; loss: 0.98; acc: 0.69
Batch: 680; loss: 0.92; acc: 0.77
Batch: 700; loss: 0.95; acc: 0.72
Batch: 720; loss: 1.03; acc: 0.72
Batch: 740; loss: 0.85; acc: 0.75
Batch: 760; loss: 0.94; acc: 0.72
Batch: 780; loss: 0.95; acc: 0.77
Train Epoch over. train_loss: 0.99; train_accuracy: 0.72 

4.6405850298469886e-05
1.8957505744765513e-05
Batch: 0; loss: 0.74; acc: 0.84
Batch: 20; loss: 1.12; acc: 0.66
Batch: 40; loss: 0.74; acc: 0.83
Batch: 60; loss: 0.96; acc: 0.69
Batch: 80; loss: 0.82; acc: 0.75
Batch: 100; loss: 0.95; acc: 0.7
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 0.7; acc: 0.89
Val Epoch over. val_loss: 0.969454895538889; val_accuracy: 0.726015127388535 

The current subspace-distance is: 1.8957505744765513e-05 

Epoch 14 start
The current lr is: 0.3
Batch: 0; loss: 0.99; acc: 0.66
Batch: 20; loss: 1.07; acc: 0.69
Batch: 40; loss: 0.94; acc: 0.66
Batch: 60; loss: 1.03; acc: 0.7
Batch: 80; loss: 0.93; acc: 0.73
Batch: 100; loss: 0.98; acc: 0.72
Batch: 120; loss: 1.12; acc: 0.73
Batch: 140; loss: 0.91; acc: 0.73
Batch: 160; loss: 0.83; acc: 0.75
Batch: 180; loss: 0.97; acc: 0.75
Batch: 200; loss: 1.0; acc: 0.75
Batch: 220; loss: 1.1; acc: 0.61
Batch: 240; loss: 1.09; acc: 0.64
Batch: 260; loss: 1.04; acc: 0.67
Batch: 280; loss: 1.11; acc: 0.67
Batch: 300; loss: 0.99; acc: 0.67
Batch: 320; loss: 0.99; acc: 0.72
Batch: 340; loss: 1.2; acc: 0.67
Batch: 360; loss: 1.12; acc: 0.67
Batch: 380; loss: 0.82; acc: 0.75
Batch: 400; loss: 1.09; acc: 0.77
Batch: 420; loss: 0.99; acc: 0.7
Batch: 440; loss: 1.04; acc: 0.66
Batch: 460; loss: 0.96; acc: 0.7
Batch: 480; loss: 0.92; acc: 0.77
Batch: 500; loss: 1.23; acc: 0.59
Batch: 520; loss: 0.97; acc: 0.66
Batch: 540; loss: 0.95; acc: 0.73
Batch: 560; loss: 0.99; acc: 0.72
Batch: 580; loss: 0.97; acc: 0.7
Batch: 600; loss: 1.07; acc: 0.7
Batch: 620; loss: 0.88; acc: 0.81
Batch: 640; loss: 0.84; acc: 0.77
Batch: 660; loss: 0.85; acc: 0.77
Batch: 680; loss: 0.8; acc: 0.75
Batch: 700; loss: 0.97; acc: 0.72
Batch: 720; loss: 0.88; acc: 0.75
Batch: 740; loss: 0.85; acc: 0.77
Batch: 760; loss: 1.01; acc: 0.73
Batch: 780; loss: 1.05; acc: 0.62
Train Epoch over. train_loss: 0.99; train_accuracy: 0.72 

4.6442841266980395e-05
1.8416958482703194e-05
Batch: 0; loss: 0.7; acc: 0.89
Batch: 20; loss: 1.08; acc: 0.64
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.95; acc: 0.67
Batch: 120; loss: 1.13; acc: 0.69
Batch: 140; loss: 0.64; acc: 0.88
Val Epoch over. val_loss: 0.9106246160853441; val_accuracy: 0.7386544585987261 

The current subspace-distance is: 1.8416958482703194e-05 

Epoch 15 start
The current lr is: 0.3
Batch: 0; loss: 0.79; acc: 0.78
Batch: 20; loss: 1.0; acc: 0.73
Batch: 40; loss: 1.19; acc: 0.61
Batch: 60; loss: 0.89; acc: 0.8
Batch: 80; loss: 0.89; acc: 0.75
Batch: 100; loss: 1.11; acc: 0.69
Batch: 120; loss: 1.02; acc: 0.72
Batch: 140; loss: 0.93; acc: 0.75
Batch: 160; loss: 1.0; acc: 0.67
Batch: 180; loss: 0.99; acc: 0.75
Batch: 200; loss: 1.04; acc: 0.7
Batch: 220; loss: 1.0; acc: 0.7
Batch: 240; loss: 1.11; acc: 0.66
Batch: 260; loss: 1.06; acc: 0.73
Batch: 280; loss: 0.9; acc: 0.78
Batch: 300; loss: 1.1; acc: 0.66
Batch: 320; loss: 0.77; acc: 0.78
Batch: 340; loss: 1.08; acc: 0.67
Batch: 360; loss: 1.01; acc: 0.7
Batch: 380; loss: 1.07; acc: 0.62
Batch: 400; loss: 1.0; acc: 0.69
Batch: 420; loss: 0.92; acc: 0.77
Batch: 440; loss: 0.96; acc: 0.77
Batch: 460; loss: 0.89; acc: 0.75
Batch: 480; loss: 1.11; acc: 0.7
Batch: 500; loss: 0.83; acc: 0.86
Batch: 520; loss: 1.08; acc: 0.67
Batch: 540; loss: 0.97; acc: 0.69
Batch: 560; loss: 1.09; acc: 0.67
Batch: 580; loss: 1.05; acc: 0.7
Batch: 600; loss: 1.06; acc: 0.7
Batch: 620; loss: 1.0; acc: 0.73
Batch: 640; loss: 1.05; acc: 0.75
Batch: 660; loss: 0.92; acc: 0.7
Batch: 680; loss: 0.92; acc: 0.75
Batch: 700; loss: 0.95; acc: 0.8
Batch: 720; loss: 0.98; acc: 0.67
Batch: 740; loss: 1.09; acc: 0.61
Batch: 760; loss: 0.81; acc: 0.83
Batch: 780; loss: 0.93; acc: 0.67
Train Epoch over. train_loss: 0.98; train_accuracy: 0.72 

4.73656618851237e-05
1.8073891624226235e-05
Batch: 0; loss: 0.73; acc: 0.86
Batch: 20; loss: 1.11; acc: 0.66
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.95; acc: 0.72
Batch: 80; loss: 0.81; acc: 0.78
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.14; acc: 0.67
Batch: 140; loss: 0.69; acc: 0.88
Val Epoch over. val_loss: 0.9587665663403311; val_accuracy: 0.7302945859872612 

The current subspace-distance is: 1.8073891624226235e-05 

Epoch 16 start
The current lr is: 0.3
Batch: 0; loss: 0.9; acc: 0.78
Batch: 20; loss: 0.85; acc: 0.72
Batch: 40; loss: 1.07; acc: 0.69
Batch: 60; loss: 0.82; acc: 0.78
Batch: 80; loss: 1.11; acc: 0.67
Batch: 100; loss: 1.19; acc: 0.59
Batch: 120; loss: 1.13; acc: 0.59
Batch: 140; loss: 0.94; acc: 0.73
Batch: 160; loss: 0.99; acc: 0.7
Batch: 180; loss: 1.0; acc: 0.72
Batch: 200; loss: 0.97; acc: 0.75
Batch: 220; loss: 1.06; acc: 0.67
Batch: 240; loss: 0.81; acc: 0.8
Batch: 260; loss: 0.89; acc: 0.78
Batch: 280; loss: 0.87; acc: 0.72
Batch: 300; loss: 0.97; acc: 0.72
Batch: 320; loss: 0.85; acc: 0.81
Batch: 340; loss: 1.05; acc: 0.69
Batch: 360; loss: 0.74; acc: 0.86
Batch: 380; loss: 0.84; acc: 0.73
Batch: 400; loss: 1.03; acc: 0.7
Batch: 420; loss: 0.88; acc: 0.73
Batch: 440; loss: 0.86; acc: 0.78
Batch: 460; loss: 1.19; acc: 0.69
Batch: 480; loss: 1.04; acc: 0.66
Batch: 500; loss: 0.86; acc: 0.78
Batch: 520; loss: 1.03; acc: 0.73
Batch: 540; loss: 0.94; acc: 0.77
Batch: 560; loss: 0.94; acc: 0.77
Batch: 580; loss: 1.0; acc: 0.69
Batch: 600; loss: 0.89; acc: 0.77
Batch: 620; loss: 0.88; acc: 0.73
Batch: 640; loss: 0.98; acc: 0.75
Batch: 660; loss: 0.98; acc: 0.73
Batch: 680; loss: 1.07; acc: 0.58
Batch: 700; loss: 0.93; acc: 0.75
Batch: 720; loss: 0.86; acc: 0.78
Batch: 740; loss: 1.06; acc: 0.72
Batch: 760; loss: 0.85; acc: 0.78
Batch: 780; loss: 1.06; acc: 0.66
Train Epoch over. train_loss: 0.98; train_accuracy: 0.72 

4.7342102334368974e-05
1.9556227925932035e-05
Batch: 0; loss: 0.71; acc: 0.88
Batch: 20; loss: 1.18; acc: 0.64
Batch: 40; loss: 0.74; acc: 0.83
Batch: 60; loss: 0.94; acc: 0.72
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.99; acc: 0.73
Batch: 120; loss: 1.17; acc: 0.67
Batch: 140; loss: 0.72; acc: 0.83
Val Epoch over. val_loss: 0.9615469350936307; val_accuracy: 0.7288017515923567 

The current subspace-distance is: 1.9556227925932035e-05 

Epoch 17 start
The current lr is: 0.3
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 1.02; acc: 0.73
Batch: 40; loss: 0.73; acc: 0.83
Batch: 60; loss: 1.04; acc: 0.69
Batch: 80; loss: 1.0; acc: 0.72
Batch: 100; loss: 0.97; acc: 0.69
Batch: 120; loss: 0.78; acc: 0.83
Batch: 140; loss: 0.82; acc: 0.72
Batch: 160; loss: 1.04; acc: 0.7
Batch: 180; loss: 0.93; acc: 0.72
Batch: 200; loss: 0.95; acc: 0.69
Batch: 220; loss: 0.96; acc: 0.78
Batch: 240; loss: 1.16; acc: 0.69
Batch: 260; loss: 1.12; acc: 0.69
Batch: 280; loss: 0.92; acc: 0.73
Batch: 300; loss: 0.87; acc: 0.78
Batch: 320; loss: 1.06; acc: 0.72
Batch: 340; loss: 1.0; acc: 0.66
Batch: 360; loss: 0.83; acc: 0.8
Batch: 380; loss: 1.09; acc: 0.62
Batch: 400; loss: 0.87; acc: 0.73
Batch: 420; loss: 0.91; acc: 0.72
Batch: 440; loss: 0.94; acc: 0.73
Batch: 460; loss: 0.75; acc: 0.78
Batch: 480; loss: 1.03; acc: 0.69
Batch: 500; loss: 0.84; acc: 0.77
Batch: 520; loss: 1.12; acc: 0.66
Batch: 540; loss: 1.0; acc: 0.67
Batch: 560; loss: 0.89; acc: 0.78
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 1.03; acc: 0.67
Batch: 620; loss: 0.98; acc: 0.8
Batch: 640; loss: 1.0; acc: 0.75
Batch: 660; loss: 0.9; acc: 0.67
Batch: 680; loss: 1.16; acc: 0.69
Batch: 700; loss: 0.88; acc: 0.75
Batch: 720; loss: 0.85; acc: 0.8
Batch: 740; loss: 1.07; acc: 0.59
Batch: 760; loss: 0.99; acc: 0.73
Batch: 780; loss: 1.21; acc: 0.62
Train Epoch over. train_loss: 0.97; train_accuracy: 0.72 

4.673330477089621e-05
1.844709004217293e-05
Batch: 0; loss: 0.69; acc: 0.86
Batch: 20; loss: 1.1; acc: 0.69
Batch: 40; loss: 0.69; acc: 0.8
Batch: 60; loss: 0.86; acc: 0.75
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.96; acc: 0.69
Batch: 120; loss: 1.15; acc: 0.66
Batch: 140; loss: 0.67; acc: 0.86
Val Epoch over. val_loss: 0.9177466927060656; val_accuracy: 0.736265923566879 

The current subspace-distance is: 1.844709004217293e-05 

Epoch 18 start
The current lr is: 0.3
Batch: 0; loss: 0.92; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.77
Batch: 40; loss: 0.93; acc: 0.81
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.99; acc: 0.73
Batch: 100; loss: 0.91; acc: 0.78
Batch: 120; loss: 1.01; acc: 0.67
Batch: 140; loss: 1.03; acc: 0.64
Batch: 160; loss: 1.01; acc: 0.62
Batch: 180; loss: 0.76; acc: 0.81
Batch: 200; loss: 1.04; acc: 0.72
Batch: 220; loss: 0.93; acc: 0.75
Batch: 240; loss: 1.0; acc: 0.67
Batch: 260; loss: 0.99; acc: 0.73
Batch: 280; loss: 0.98; acc: 0.72
Batch: 300; loss: 0.89; acc: 0.75
Batch: 320; loss: 1.07; acc: 0.72
Batch: 340; loss: 0.79; acc: 0.83
Batch: 360; loss: 1.03; acc: 0.67
Batch: 380; loss: 0.82; acc: 0.8
Batch: 400; loss: 0.84; acc: 0.72
Batch: 420; loss: 0.83; acc: 0.84
Batch: 440; loss: 0.9; acc: 0.72
Batch: 460; loss: 1.06; acc: 0.7
Batch: 480; loss: 1.05; acc: 0.66
Batch: 500; loss: 0.85; acc: 0.78
Batch: 520; loss: 0.94; acc: 0.72
Batch: 540; loss: 0.85; acc: 0.78
Batch: 560; loss: 1.06; acc: 0.72
Batch: 580; loss: 1.06; acc: 0.67
Batch: 600; loss: 0.91; acc: 0.73
Batch: 620; loss: 1.17; acc: 0.59
Batch: 640; loss: 1.16; acc: 0.58
Batch: 660; loss: 0.9; acc: 0.77
Batch: 680; loss: 0.9; acc: 0.66
Batch: 700; loss: 0.85; acc: 0.83
Batch: 720; loss: 0.86; acc: 0.8
Batch: 740; loss: 0.8; acc: 0.77
Batch: 760; loss: 1.11; acc: 0.64
Batch: 780; loss: 1.07; acc: 0.72
Train Epoch over. train_loss: 0.97; train_accuracy: 0.72 

4.812862607650459e-05
1.89870988833718e-05
Batch: 0; loss: 0.7; acc: 0.86
Batch: 20; loss: 1.08; acc: 0.67
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.9; acc: 0.73
Batch: 80; loss: 0.78; acc: 0.81
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 1.12; acc: 0.67
Batch: 140; loss: 0.67; acc: 0.88
Val Epoch over. val_loss: 0.9167235489863499; val_accuracy: 0.7474124203821656 

The current subspace-distance is: 1.89870988833718e-05 

Epoch 19 start
The current lr is: 0.3
Batch: 0; loss: 0.83; acc: 0.81
Batch: 20; loss: 0.96; acc: 0.78
Batch: 40; loss: 1.23; acc: 0.62
Batch: 60; loss: 0.87; acc: 0.75
Batch: 80; loss: 1.01; acc: 0.7
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 1.13; acc: 0.61
Batch: 140; loss: 1.09; acc: 0.7
Batch: 160; loss: 0.94; acc: 0.8
Batch: 180; loss: 0.9; acc: 0.72
Batch: 200; loss: 0.9; acc: 0.77
Batch: 220; loss: 0.88; acc: 0.73
Batch: 240; loss: 0.95; acc: 0.78
Batch: 260; loss: 0.95; acc: 0.75
Batch: 280; loss: 0.89; acc: 0.77
Batch: 300; loss: 0.91; acc: 0.75
Batch: 320; loss: 0.8; acc: 0.8
Batch: 340; loss: 1.03; acc: 0.7
Batch: 360; loss: 0.81; acc: 0.7
Batch: 380; loss: 1.13; acc: 0.73
Batch: 400; loss: 0.92; acc: 0.73
Batch: 420; loss: 0.96; acc: 0.8
Batch: 440; loss: 0.95; acc: 0.69
Batch: 460; loss: 0.8; acc: 0.8
Batch: 480; loss: 1.09; acc: 0.75
Batch: 500; loss: 1.07; acc: 0.66
Batch: 520; loss: 0.9; acc: 0.78
Batch: 540; loss: 0.95; acc: 0.7
Batch: 560; loss: 0.79; acc: 0.83
Batch: 580; loss: 0.99; acc: 0.7
Batch: 600; loss: 1.29; acc: 0.56
Batch: 620; loss: 0.77; acc: 0.86
Batch: 640; loss: 0.96; acc: 0.69
Batch: 660; loss: 1.08; acc: 0.67
Batch: 680; loss: 1.04; acc: 0.69
Batch: 700; loss: 1.06; acc: 0.67
Batch: 720; loss: 0.89; acc: 0.73
Batch: 740; loss: 0.96; acc: 0.73
Batch: 760; loss: 0.93; acc: 0.8
Batch: 780; loss: 0.93; acc: 0.7
Train Epoch over. train_loss: 0.97; train_accuracy: 0.72 

4.839746543439105e-05
1.9145358237437904e-05
Batch: 0; loss: 0.75; acc: 0.83
Batch: 20; loss: 1.23; acc: 0.62
Batch: 40; loss: 0.74; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.72
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 1.22; acc: 0.59
Batch: 140; loss: 0.68; acc: 0.88
Val Epoch over. val_loss: 0.9414979048595307; val_accuracy: 0.7237261146496815 

The current subspace-distance is: 1.9145358237437904e-05 

Epoch 20 start
The current lr is: 0.3
Batch: 0; loss: 1.03; acc: 0.72
Batch: 20; loss: 0.92; acc: 0.73
Batch: 40; loss: 0.9; acc: 0.75
Batch: 60; loss: 0.92; acc: 0.77
Batch: 80; loss: 0.87; acc: 0.75
Batch: 100; loss: 1.03; acc: 0.72
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 1.13; acc: 0.64
Batch: 160; loss: 1.0; acc: 0.7
Batch: 180; loss: 0.82; acc: 0.8
Batch: 200; loss: 1.06; acc: 0.64
Batch: 220; loss: 0.95; acc: 0.78
Batch: 240; loss: 1.19; acc: 0.56
Batch: 260; loss: 0.94; acc: 0.73
Batch: 280; loss: 0.83; acc: 0.8
Batch: 300; loss: 0.9; acc: 0.8
Batch: 320; loss: 0.9; acc: 0.73
Batch: 340; loss: 0.9; acc: 0.77
Batch: 360; loss: 0.82; acc: 0.77
Batch: 380; loss: 0.95; acc: 0.69
Batch: 400; loss: 0.97; acc: 0.69
Batch: 420; loss: 0.87; acc: 0.78
Batch: 440; loss: 0.93; acc: 0.73
Batch: 460; loss: 1.0; acc: 0.7
Batch: 480; loss: 1.14; acc: 0.67
Batch: 500; loss: 0.94; acc: 0.7
Batch: 520; loss: 0.99; acc: 0.73
Batch: 540; loss: 1.19; acc: 0.64
Batch: 560; loss: 1.15; acc: 0.67
Batch: 580; loss: 0.97; acc: 0.75
Batch: 600; loss: 1.03; acc: 0.72
Batch: 620; loss: 1.09; acc: 0.69
Batch: 640; loss: 1.12; acc: 0.66
Batch: 660; loss: 1.14; acc: 0.64
Batch: 680; loss: 0.9; acc: 0.75
Batch: 700; loss: 0.99; acc: 0.72
Batch: 720; loss: 1.09; acc: 0.7
Batch: 740; loss: 0.84; acc: 0.8
Batch: 760; loss: 0.73; acc: 0.83
Batch: 780; loss: 0.92; acc: 0.78
Train Epoch over. train_loss: 0.96; train_accuracy: 0.72 

4.896530299447477e-05
1.994915510294959e-05
Batch: 0; loss: 0.7; acc: 0.83
Batch: 20; loss: 1.21; acc: 0.66
Batch: 40; loss: 0.71; acc: 0.8
Batch: 60; loss: 0.94; acc: 0.73
Batch: 80; loss: 0.82; acc: 0.73
Batch: 100; loss: 0.99; acc: 0.7
Batch: 120; loss: 1.18; acc: 0.64
Batch: 140; loss: 0.7; acc: 0.84
Val Epoch over. val_loss: 0.9486531372282915; val_accuracy: 0.7207404458598726 

The current subspace-distance is: 1.994915510294959e-05 

Epoch 21 start
The current lr is: 0.09
Batch: 0; loss: 0.73; acc: 0.84
Batch: 20; loss: 0.93; acc: 0.75
Batch: 40; loss: 0.98; acc: 0.78
Batch: 60; loss: 0.92; acc: 0.73
Batch: 80; loss: 0.75; acc: 0.83
Batch: 100; loss: 0.97; acc: 0.72
Batch: 120; loss: 1.01; acc: 0.7
Batch: 140; loss: 0.83; acc: 0.8
Batch: 160; loss: 1.04; acc: 0.72
Batch: 180; loss: 0.89; acc: 0.75
Batch: 200; loss: 1.06; acc: 0.69
Batch: 220; loss: 0.8; acc: 0.77
Batch: 240; loss: 0.72; acc: 0.81
Batch: 260; loss: 1.01; acc: 0.73
Batch: 280; loss: 0.95; acc: 0.64
Batch: 300; loss: 1.06; acc: 0.67
Batch: 320; loss: 1.01; acc: 0.72
Batch: 340; loss: 0.99; acc: 0.69
Batch: 360; loss: 0.74; acc: 0.83
Batch: 380; loss: 0.91; acc: 0.7
Batch: 400; loss: 1.11; acc: 0.67
Batch: 420; loss: 1.0; acc: 0.62
Batch: 440; loss: 1.01; acc: 0.75
Batch: 460; loss: 0.95; acc: 0.75
Batch: 480; loss: 0.87; acc: 0.81
Batch: 500; loss: 0.89; acc: 0.75
Batch: 520; loss: 0.94; acc: 0.8
Batch: 540; loss: 0.9; acc: 0.72
Batch: 560; loss: 0.82; acc: 0.81
Batch: 580; loss: 0.91; acc: 0.77
Batch: 600; loss: 0.91; acc: 0.77
Batch: 620; loss: 0.82; acc: 0.75
Batch: 640; loss: 0.93; acc: 0.75
Batch: 660; loss: 1.1; acc: 0.64
Batch: 680; loss: 0.95; acc: 0.67
Batch: 700; loss: 0.93; acc: 0.72
Batch: 720; loss: 0.86; acc: 0.73
Batch: 740; loss: 1.0; acc: 0.75
Batch: 760; loss: 0.95; acc: 0.72
Batch: 780; loss: 0.82; acc: 0.8
Train Epoch over. train_loss: 0.96; train_accuracy: 0.73 

4.987011197954416e-05
1.9841480025206693e-05
Batch: 0; loss: 0.66; acc: 0.86
Batch: 20; loss: 1.05; acc: 0.7
Batch: 40; loss: 0.65; acc: 0.84
Batch: 60; loss: 0.84; acc: 0.78
Batch: 80; loss: 0.74; acc: 0.83
Batch: 100; loss: 0.93; acc: 0.72
Batch: 120; loss: 1.13; acc: 0.67
Batch: 140; loss: 0.64; acc: 0.86
Val Epoch over. val_loss: 0.875084854235315; val_accuracy: 0.7571656050955414 

The current subspace-distance is: 1.9841480025206693e-05 

Epoch 22 start
The current lr is: 0.09
Batch: 0; loss: 0.97; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.7
Batch: 40; loss: 0.86; acc: 0.75
Batch: 60; loss: 1.05; acc: 0.72
Batch: 80; loss: 0.96; acc: 0.75
Batch: 100; loss: 1.01; acc: 0.7
Batch: 120; loss: 1.05; acc: 0.7
Batch: 140; loss: 0.83; acc: 0.77
Batch: 160; loss: 1.03; acc: 0.67
Batch: 180; loss: 1.02; acc: 0.69
Batch: 200; loss: 0.84; acc: 0.75
Batch: 220; loss: 0.83; acc: 0.8
Batch: 240; loss: 0.85; acc: 0.75
Batch: 260; loss: 1.13; acc: 0.62
Batch: 280; loss: 0.9; acc: 0.78
Batch: 300; loss: 0.87; acc: 0.8
Batch: 320; loss: 0.98; acc: 0.66
Batch: 340; loss: 1.07; acc: 0.67
Batch: 360; loss: 1.04; acc: 0.77
Batch: 380; loss: 1.04; acc: 0.7
Batch: 400; loss: 0.95; acc: 0.73
Batch: 420; loss: 1.15; acc: 0.64
Batch: 440; loss: 0.89; acc: 0.73
Batch: 460; loss: 0.88; acc: 0.75
Batch: 480; loss: 0.82; acc: 0.78
Batch: 500; loss: 0.96; acc: 0.78
Batch: 520; loss: 1.01; acc: 0.69
Batch: 540; loss: 0.79; acc: 0.8
Batch: 560; loss: 1.02; acc: 0.66
Batch: 580; loss: 0.84; acc: 0.81
Batch: 600; loss: 1.0; acc: 0.72
Batch: 620; loss: 0.88; acc: 0.8
Batch: 640; loss: 0.99; acc: 0.67
Batch: 660; loss: 0.9; acc: 0.73
Batch: 680; loss: 1.09; acc: 0.64
Batch: 700; loss: 0.97; acc: 0.72
Batch: 720; loss: 0.91; acc: 0.7
Batch: 740; loss: 0.87; acc: 0.75
Batch: 760; loss: 0.81; acc: 0.8
Batch: 780; loss: 0.88; acc: 0.77
Train Epoch over. train_loss: 0.96; train_accuracy: 0.73 

5.0042159273289144e-05
2.0325456716818735e-05
Batch: 0; loss: 0.67; acc: 0.84
Batch: 20; loss: 1.06; acc: 0.72
Batch: 40; loss: 0.67; acc: 0.86
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.75; acc: 0.83
Batch: 100; loss: 0.96; acc: 0.73
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.63; acc: 0.84
Val Epoch over. val_loss: 0.8839447088302321; val_accuracy: 0.7593550955414012 

The current subspace-distance is: 2.0325456716818735e-05 

Epoch 23 start
The current lr is: 0.09
Batch: 0; loss: 0.94; acc: 0.72
Batch: 20; loss: 0.82; acc: 0.81
Batch: 40; loss: 1.11; acc: 0.66
Batch: 60; loss: 0.87; acc: 0.72
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 0.98; acc: 0.69
Batch: 120; loss: 1.05; acc: 0.67
Batch: 140; loss: 0.72; acc: 0.81
Batch: 160; loss: 1.04; acc: 0.67
Batch: 180; loss: 0.84; acc: 0.75
Batch: 200; loss: 0.96; acc: 0.7
Batch: 220; loss: 1.0; acc: 0.72
Batch: 240; loss: 0.99; acc: 0.72
Batch: 260; loss: 0.92; acc: 0.69
Batch: 280; loss: 0.88; acc: 0.86
Batch: 300; loss: 0.86; acc: 0.75
Batch: 320; loss: 0.75; acc: 0.83
Batch: 340; loss: 0.79; acc: 0.77
Batch: 360; loss: 1.2; acc: 0.61
Batch: 380; loss: 0.82; acc: 0.75
Batch: 400; loss: 1.01; acc: 0.66
Batch: 420; loss: 1.14; acc: 0.67
Batch: 440; loss: 0.94; acc: 0.72
Batch: 460; loss: 1.15; acc: 0.66
Batch: 480; loss: 0.88; acc: 0.77
Batch: 500; loss: 0.79; acc: 0.8
Batch: 520; loss: 1.01; acc: 0.67
Batch: 540; loss: 0.93; acc: 0.73
Batch: 560; loss: 0.9; acc: 0.75
Batch: 580; loss: 0.97; acc: 0.7
Batch: 600; loss: 1.1; acc: 0.66
Batch: 620; loss: 1.14; acc: 0.61
Batch: 640; loss: 0.95; acc: 0.72
Batch: 660; loss: 0.88; acc: 0.77
Batch: 680; loss: 0.95; acc: 0.72
Batch: 700; loss: 0.8; acc: 0.83
Batch: 720; loss: 0.94; acc: 0.75
Batch: 740; loss: 1.13; acc: 0.69
Batch: 760; loss: 1.1; acc: 0.67
Batch: 780; loss: 0.92; acc: 0.73
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

4.8493991926079616e-05
1.9584627807489596e-05
Batch: 0; loss: 0.67; acc: 0.86
Batch: 20; loss: 1.07; acc: 0.69
Batch: 40; loss: 0.65; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.8
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 1.11; acc: 0.67
Batch: 140; loss: 0.61; acc: 0.88
Val Epoch over. val_loss: 0.8777043777666275; val_accuracy: 0.7580613057324841 

The current subspace-distance is: 1.9584627807489596e-05 

Epoch 24 start
The current lr is: 0.09
Batch: 0; loss: 0.9; acc: 0.7
Batch: 20; loss: 1.0; acc: 0.7
Batch: 40; loss: 0.84; acc: 0.77
Batch: 60; loss: 1.15; acc: 0.62
Batch: 80; loss: 0.99; acc: 0.72
Batch: 100; loss: 0.67; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.66
Batch: 140; loss: 0.93; acc: 0.67
Batch: 160; loss: 0.85; acc: 0.75
Batch: 180; loss: 1.05; acc: 0.72
Batch: 200; loss: 1.04; acc: 0.66
Batch: 220; loss: 0.84; acc: 0.78
Batch: 240; loss: 1.13; acc: 0.67
Batch: 260; loss: 0.86; acc: 0.69
Batch: 280; loss: 0.86; acc: 0.8
Batch: 300; loss: 0.92; acc: 0.69
Batch: 320; loss: 0.91; acc: 0.78
Batch: 340; loss: 1.0; acc: 0.7
Batch: 360; loss: 0.91; acc: 0.77
Batch: 380; loss: 1.04; acc: 0.69
Batch: 400; loss: 0.84; acc: 0.8
Batch: 420; loss: 0.91; acc: 0.73
Batch: 440; loss: 0.76; acc: 0.86
Batch: 460; loss: 0.87; acc: 0.8
Batch: 480; loss: 0.92; acc: 0.75
Batch: 500; loss: 0.94; acc: 0.75
Batch: 520; loss: 1.01; acc: 0.73
Batch: 540; loss: 0.83; acc: 0.77
Batch: 560; loss: 0.93; acc: 0.72
Batch: 580; loss: 0.99; acc: 0.72
Batch: 600; loss: 1.06; acc: 0.75
Batch: 620; loss: 1.04; acc: 0.62
Batch: 640; loss: 1.01; acc: 0.69
Batch: 660; loss: 1.03; acc: 0.61
Batch: 680; loss: 0.9; acc: 0.73
Batch: 700; loss: 0.85; acc: 0.77
Batch: 720; loss: 1.02; acc: 0.67
Batch: 740; loss: 0.92; acc: 0.75
Batch: 760; loss: 0.85; acc: 0.75
Batch: 780; loss: 0.98; acc: 0.73
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

4.9225909606320783e-05
1.9804278053925373e-05
Batch: 0; loss: 0.67; acc: 0.86
Batch: 20; loss: 1.07; acc: 0.7
Batch: 40; loss: 0.66; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.81
Batch: 100; loss: 0.95; acc: 0.73
Batch: 120; loss: 1.12; acc: 0.67
Batch: 140; loss: 0.62; acc: 0.86
Val Epoch over. val_loss: 0.8812111335195554; val_accuracy: 0.7606488853503185 

The current subspace-distance is: 1.9804278053925373e-05 

Epoch 25 start
The current lr is: 0.09
Batch: 0; loss: 0.97; acc: 0.75
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 1.07; acc: 0.62
Batch: 60; loss: 0.85; acc: 0.72
Batch: 80; loss: 1.09; acc: 0.66
Batch: 100; loss: 0.83; acc: 0.77
Batch: 120; loss: 0.85; acc: 0.78
Batch: 140; loss: 1.23; acc: 0.64
Batch: 160; loss: 0.86; acc: 0.77
Batch: 180; loss: 1.01; acc: 0.67
Batch: 200; loss: 0.9; acc: 0.75
Batch: 220; loss: 0.88; acc: 0.78
Batch: 240; loss: 1.14; acc: 0.59
Batch: 260; loss: 0.71; acc: 0.83
Batch: 280; loss: 0.96; acc: 0.69
Batch: 300; loss: 1.1; acc: 0.67
Batch: 320; loss: 1.02; acc: 0.67
Batch: 340; loss: 0.8; acc: 0.8
Batch: 360; loss: 0.8; acc: 0.8
Batch: 380; loss: 0.69; acc: 0.86
Batch: 400; loss: 0.98; acc: 0.73
Batch: 420; loss: 1.16; acc: 0.66
Batch: 440; loss: 0.99; acc: 0.75
Batch: 460; loss: 1.02; acc: 0.77
Batch: 480; loss: 1.1; acc: 0.67
Batch: 500; loss: 0.94; acc: 0.7
Batch: 520; loss: 0.95; acc: 0.73
Batch: 540; loss: 1.02; acc: 0.73
Batch: 560; loss: 0.92; acc: 0.69
Batch: 580; loss: 1.04; acc: 0.66
Batch: 600; loss: 0.86; acc: 0.69
Batch: 620; loss: 0.81; acc: 0.78
Batch: 640; loss: 0.97; acc: 0.69
Batch: 660; loss: 0.86; acc: 0.75
Batch: 680; loss: 1.06; acc: 0.66
Batch: 700; loss: 0.84; acc: 0.72
Batch: 720; loss: 0.93; acc: 0.77
Batch: 740; loss: 1.14; acc: 0.64
Batch: 760; loss: 1.08; acc: 0.61
Batch: 780; loss: 0.93; acc: 0.78
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

5.0558242946863174e-05
2.0938419766025618e-05
Batch: 0; loss: 0.68; acc: 0.86
Batch: 20; loss: 1.06; acc: 0.67
Batch: 40; loss: 0.66; acc: 0.83
Batch: 60; loss: 0.84; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.81
Batch: 100; loss: 0.95; acc: 0.73
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.63; acc: 0.88
Val Epoch over. val_loss: 0.8911488921778976; val_accuracy: 0.7541799363057324 

The current subspace-distance is: 2.0938419766025618e-05 

Epoch 26 start
The current lr is: 0.09
Batch: 0; loss: 1.02; acc: 0.72
Batch: 20; loss: 0.89; acc: 0.77
Batch: 40; loss: 0.88; acc: 0.77
Batch: 60; loss: 0.94; acc: 0.7
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.87; acc: 0.81
Batch: 120; loss: 0.9; acc: 0.78
Batch: 140; loss: 0.94; acc: 0.73
Batch: 160; loss: 0.73; acc: 0.88
Batch: 180; loss: 1.02; acc: 0.77
Batch: 200; loss: 0.91; acc: 0.73
Batch: 220; loss: 0.93; acc: 0.77
Batch: 240; loss: 0.84; acc: 0.8
Batch: 260; loss: 1.13; acc: 0.67
Batch: 280; loss: 0.98; acc: 0.67
Batch: 300; loss: 1.03; acc: 0.72
Batch: 320; loss: 1.02; acc: 0.72
Batch: 340; loss: 0.93; acc: 0.73
Batch: 360; loss: 0.85; acc: 0.8
Batch: 380; loss: 0.96; acc: 0.7
Batch: 400; loss: 0.9; acc: 0.75
Batch: 420; loss: 0.8; acc: 0.81
Batch: 440; loss: 0.85; acc: 0.77
Batch: 460; loss: 0.95; acc: 0.72
Batch: 480; loss: 1.13; acc: 0.66
Batch: 500; loss: 0.82; acc: 0.67
Batch: 520; loss: 0.99; acc: 0.73
Batch: 540; loss: 0.98; acc: 0.72
Batch: 560; loss: 1.05; acc: 0.7
Batch: 580; loss: 1.12; acc: 0.67
Batch: 600; loss: 0.87; acc: 0.77
Batch: 620; loss: 1.11; acc: 0.67
Batch: 640; loss: 0.98; acc: 0.75
Batch: 660; loss: 1.18; acc: 0.72
Batch: 680; loss: 1.0; acc: 0.67
Batch: 700; loss: 1.01; acc: 0.69
Batch: 720; loss: 1.04; acc: 0.72
Batch: 740; loss: 0.86; acc: 0.77
Batch: 760; loss: 1.13; acc: 0.7
Batch: 780; loss: 1.06; acc: 0.62
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

4.989069566363469e-05
1.974920633074362e-05
Batch: 0; loss: 0.66; acc: 0.88
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 0.65; acc: 0.84
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.72; acc: 0.83
Batch: 100; loss: 0.94; acc: 0.7
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.66; acc: 0.86
Val Epoch over. val_loss: 0.8852661354526593; val_accuracy: 0.7512937898089171 

The current subspace-distance is: 1.974920633074362e-05 

Epoch 27 start
The current lr is: 0.09
Batch: 0; loss: 0.81; acc: 0.83
Batch: 20; loss: 0.91; acc: 0.78
Batch: 40; loss: 0.95; acc: 0.72
Batch: 60; loss: 0.98; acc: 0.72
Batch: 80; loss: 0.84; acc: 0.78
Batch: 100; loss: 1.15; acc: 0.66
Batch: 120; loss: 0.76; acc: 0.83
Batch: 140; loss: 1.1; acc: 0.66
Batch: 160; loss: 0.81; acc: 0.73
Batch: 180; loss: 0.85; acc: 0.8
Batch: 200; loss: 0.77; acc: 0.81
Batch: 220; loss: 0.94; acc: 0.75
Batch: 240; loss: 1.08; acc: 0.61
Batch: 260; loss: 1.07; acc: 0.75
Batch: 280; loss: 0.89; acc: 0.78
Batch: 300; loss: 0.86; acc: 0.77
Batch: 320; loss: 1.14; acc: 0.62
Batch: 340; loss: 0.93; acc: 0.72
Batch: 360; loss: 1.13; acc: 0.7
Batch: 380; loss: 0.95; acc: 0.72
Batch: 400; loss: 1.14; acc: 0.59
Batch: 420; loss: 1.07; acc: 0.69
Batch: 440; loss: 0.91; acc: 0.73
Batch: 460; loss: 0.99; acc: 0.73
Batch: 480; loss: 1.09; acc: 0.64
Batch: 500; loss: 1.1; acc: 0.64
Batch: 520; loss: 0.86; acc: 0.77
Batch: 540; loss: 1.11; acc: 0.66
Batch: 560; loss: 0.92; acc: 0.78
Batch: 580; loss: 0.88; acc: 0.78
Batch: 600; loss: 1.15; acc: 0.64
Batch: 620; loss: 0.93; acc: 0.72
Batch: 640; loss: 0.89; acc: 0.7
Batch: 660; loss: 0.93; acc: 0.77
Batch: 680; loss: 0.89; acc: 0.77
Batch: 700; loss: 0.93; acc: 0.7
Batch: 720; loss: 1.01; acc: 0.7
Batch: 740; loss: 1.0; acc: 0.73
Batch: 760; loss: 0.96; acc: 0.72
Batch: 780; loss: 1.07; acc: 0.69
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

4.9412490625400096e-05
2.0251169189577922e-05
Batch: 0; loss: 0.68; acc: 0.86
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 0.66; acc: 0.83
Batch: 60; loss: 0.83; acc: 0.77
Batch: 80; loss: 0.76; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.77
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.63; acc: 0.86
Val Epoch over. val_loss: 0.8896729319718233; val_accuracy: 0.7570660828025477 

The current subspace-distance is: 2.0251169189577922e-05 

Epoch 28 start
The current lr is: 0.09
Batch: 0; loss: 1.04; acc: 0.69
Batch: 20; loss: 1.1; acc: 0.7
Batch: 40; loss: 0.77; acc: 0.81
Batch: 60; loss: 0.87; acc: 0.78
Batch: 80; loss: 1.19; acc: 0.64
Batch: 100; loss: 1.04; acc: 0.69
Batch: 120; loss: 0.99; acc: 0.69
Batch: 140; loss: 0.97; acc: 0.72
Batch: 160; loss: 0.97; acc: 0.73
Batch: 180; loss: 0.85; acc: 0.78
Batch: 200; loss: 0.97; acc: 0.72
Batch: 220; loss: 1.18; acc: 0.66
Batch: 240; loss: 0.91; acc: 0.67
Batch: 260; loss: 0.8; acc: 0.8
Batch: 280; loss: 0.83; acc: 0.8
Batch: 300; loss: 0.83; acc: 0.81
Batch: 320; loss: 1.02; acc: 0.66
Batch: 340; loss: 1.12; acc: 0.59
Batch: 360; loss: 0.95; acc: 0.77
Batch: 380; loss: 0.96; acc: 0.75
Batch: 400; loss: 0.81; acc: 0.78
Batch: 420; loss: 1.15; acc: 0.67
Batch: 440; loss: 0.91; acc: 0.73
Batch: 460; loss: 0.76; acc: 0.83
Batch: 480; loss: 0.75; acc: 0.83
Batch: 500; loss: 1.03; acc: 0.75
Batch: 520; loss: 0.84; acc: 0.81
Batch: 540; loss: 0.9; acc: 0.83
Batch: 560; loss: 0.92; acc: 0.73
Batch: 580; loss: 0.9; acc: 0.73
Batch: 600; loss: 0.92; acc: 0.77
Batch: 620; loss: 0.9; acc: 0.77
Batch: 640; loss: 0.84; acc: 0.7
Batch: 660; loss: 0.92; acc: 0.81
Batch: 680; loss: 0.79; acc: 0.83
Batch: 700; loss: 1.1; acc: 0.66
Batch: 720; loss: 0.71; acc: 0.89
Batch: 740; loss: 1.03; acc: 0.73
Batch: 760; loss: 0.94; acc: 0.66
Batch: 780; loss: 0.88; acc: 0.78
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

5.070858242106624e-05
2.0514904463198036e-05
Batch: 0; loss: 0.67; acc: 0.88
Batch: 20; loss: 1.08; acc: 0.66
Batch: 40; loss: 0.66; acc: 0.86
Batch: 60; loss: 0.84; acc: 0.77
Batch: 80; loss: 0.74; acc: 0.81
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.14; acc: 0.66
Batch: 140; loss: 0.65; acc: 0.86
Val Epoch over. val_loss: 0.8903185098793855; val_accuracy: 0.7524880573248408 

The current subspace-distance is: 2.0514904463198036e-05 

Epoch 29 start
The current lr is: 0.09
Batch: 0; loss: 0.86; acc: 0.81
Batch: 20; loss: 0.93; acc: 0.69
Batch: 40; loss: 0.84; acc: 0.78
Batch: 60; loss: 0.98; acc: 0.7
Batch: 80; loss: 0.78; acc: 0.8
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.02; acc: 0.77
Batch: 140; loss: 1.09; acc: 0.67
Batch: 160; loss: 0.74; acc: 0.86
Batch: 180; loss: 0.92; acc: 0.77
Batch: 200; loss: 0.99; acc: 0.69
Batch: 220; loss: 1.01; acc: 0.7
Batch: 240; loss: 1.09; acc: 0.69
Batch: 260; loss: 0.97; acc: 0.73
Batch: 280; loss: 1.13; acc: 0.66
Batch: 300; loss: 0.88; acc: 0.78
Batch: 320; loss: 1.07; acc: 0.67
Batch: 340; loss: 1.06; acc: 0.73
Batch: 360; loss: 0.96; acc: 0.75
Batch: 380; loss: 0.89; acc: 0.78
Batch: 400; loss: 0.78; acc: 0.8
Batch: 420; loss: 0.94; acc: 0.73
Batch: 440; loss: 1.12; acc: 0.61
Batch: 460; loss: 1.18; acc: 0.58
Batch: 480; loss: 1.11; acc: 0.64
Batch: 500; loss: 0.91; acc: 0.7
Batch: 520; loss: 0.85; acc: 0.75
Batch: 540; loss: 1.09; acc: 0.61
Batch: 560; loss: 0.91; acc: 0.77
Batch: 580; loss: 0.8; acc: 0.77
Batch: 600; loss: 0.99; acc: 0.67
Batch: 620; loss: 1.0; acc: 0.67
Batch: 640; loss: 1.06; acc: 0.7
Batch: 660; loss: 0.8; acc: 0.8
Batch: 680; loss: 0.89; acc: 0.77
Batch: 700; loss: 0.97; acc: 0.73
Batch: 720; loss: 0.97; acc: 0.73
Batch: 740; loss: 1.24; acc: 0.61
Batch: 760; loss: 0.92; acc: 0.75
Batch: 780; loss: 0.8; acc: 0.78
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

5.0445985834812745e-05
1.9890503608621657e-05
Batch: 0; loss: 0.66; acc: 0.86
Batch: 20; loss: 1.06; acc: 0.7
Batch: 40; loss: 0.65; acc: 0.83
Batch: 60; loss: 0.82; acc: 0.77
Batch: 80; loss: 0.76; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.75
Batch: 120; loss: 1.13; acc: 0.67
Batch: 140; loss: 0.63; acc: 0.86
Val Epoch over. val_loss: 0.8785817482668883; val_accuracy: 0.7595541401273885 

The current subspace-distance is: 1.9890503608621657e-05 

Epoch 30 start
The current lr is: 0.09
Batch: 0; loss: 0.94; acc: 0.72
Batch: 20; loss: 0.99; acc: 0.73
Batch: 40; loss: 0.96; acc: 0.73
Batch: 60; loss: 1.02; acc: 0.69
Batch: 80; loss: 0.96; acc: 0.75
Batch: 100; loss: 0.79; acc: 0.8
Batch: 120; loss: 0.92; acc: 0.72
Batch: 140; loss: 1.04; acc: 0.7
Batch: 160; loss: 0.94; acc: 0.73
Batch: 180; loss: 1.0; acc: 0.73
Batch: 200; loss: 0.94; acc: 0.78
Batch: 220; loss: 0.92; acc: 0.72
Batch: 240; loss: 0.8; acc: 0.75
Batch: 260; loss: 1.01; acc: 0.75
Batch: 280; loss: 1.02; acc: 0.66
Batch: 300; loss: 0.89; acc: 0.7
Batch: 320; loss: 1.05; acc: 0.61
Batch: 340; loss: 0.97; acc: 0.72
Batch: 360; loss: 0.74; acc: 0.84
Batch: 380; loss: 0.81; acc: 0.81
Batch: 400; loss: 0.85; acc: 0.73
Batch: 420; loss: 1.0; acc: 0.73
Batch: 440; loss: 0.76; acc: 0.75
Batch: 460; loss: 0.87; acc: 0.78
Batch: 480; loss: 1.13; acc: 0.69
Batch: 500; loss: 0.75; acc: 0.84
Batch: 520; loss: 1.08; acc: 0.61
Batch: 540; loss: 0.98; acc: 0.72
Batch: 560; loss: 1.0; acc: 0.69
Batch: 580; loss: 0.99; acc: 0.72
Batch: 600; loss: 0.88; acc: 0.8
Batch: 620; loss: 0.92; acc: 0.72
Batch: 640; loss: 0.99; acc: 0.7
Batch: 660; loss: 1.07; acc: 0.69
Batch: 680; loss: 0.86; acc: 0.75
Batch: 700; loss: 0.92; acc: 0.75
Batch: 720; loss: 1.12; acc: 0.64
Batch: 740; loss: 1.18; acc: 0.61
Batch: 760; loss: 0.96; acc: 0.7
Batch: 780; loss: 0.98; acc: 0.66
Train Epoch over. train_loss: 0.95; train_accuracy: 0.73 

5.0148159061791375e-05
2.05514625122305e-05
Batch: 0; loss: 0.68; acc: 0.84
Batch: 20; loss: 1.08; acc: 0.7
Batch: 40; loss: 0.66; acc: 0.83
Batch: 60; loss: 0.84; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.73
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.62; acc: 0.86
Val Epoch over. val_loss: 0.8864478362593681; val_accuracy: 0.7570660828025477 

The current subspace-distance is: 2.05514625122305e-05 

plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_400_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64

Channel scaling factor: 13.5

The number of parameters is: 279504

The number of individual parameters is:

108
432
108
108
162
52488
162
162
324
157464
324
324
64
62208
64
64
4096
64
640
10
64
64

nonzero elements in E: 139751988
elements in E: 139752000
fraction nonzero: 0.9999999141336081
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.41; acc: 0.16
Batch: 20; loss: 1.98; acc: 0.33
Batch: 40; loss: 2.02; acc: 0.28
Batch: 60; loss: 1.88; acc: 0.41
Batch: 80; loss: 1.81; acc: 0.41
Batch: 100; loss: 1.75; acc: 0.5
Batch: 120; loss: 1.72; acc: 0.47
Batch: 140; loss: 1.81; acc: 0.42
Batch: 160; loss: 1.58; acc: 0.64
Batch: 180; loss: 1.55; acc: 0.59
Batch: 200; loss: 1.65; acc: 0.48
Batch: 220; loss: 1.45; acc: 0.67
Batch: 240; loss: 1.38; acc: 0.66
Batch: 260; loss: 1.42; acc: 0.66
Batch: 280; loss: 1.49; acc: 0.56
Batch: 300; loss: 1.41; acc: 0.62
Batch: 320; loss: 1.45; acc: 0.61
Batch: 340; loss: 1.33; acc: 0.69
Batch: 360; loss: 1.32; acc: 0.69
Batch: 380; loss: 1.42; acc: 0.59
Batch: 400; loss: 1.56; acc: 0.52
Batch: 420; loss: 1.51; acc: 0.52
Batch: 440; loss: 1.41; acc: 0.59
Batch: 460; loss: 1.48; acc: 0.66
Batch: 480; loss: 1.42; acc: 0.61
Batch: 500; loss: 1.31; acc: 0.72
Batch: 520; loss: 1.51; acc: 0.56
Batch: 540; loss: 1.47; acc: 0.52
Batch: 560; loss: 1.24; acc: 0.69
Batch: 580; loss: 1.42; acc: 0.59
Batch: 600; loss: 1.35; acc: 0.66
Batch: 620; loss: 1.35; acc: 0.69
Batch: 640; loss: 1.45; acc: 0.59
Batch: 660; loss: 1.51; acc: 0.55
Batch: 680; loss: 1.17; acc: 0.7
Batch: 700; loss: 1.23; acc: 0.64
Batch: 720; loss: 1.2; acc: 0.69
Batch: 740; loss: 1.47; acc: 0.61
Batch: 760; loss: 1.42; acc: 0.59
Batch: 780; loss: 1.4; acc: 0.61
Train Epoch over. train_loss: 1.5; train_accuracy: 0.57 

3.0579241865780205e-05
6.459330052166479e-06
Batch: 0; loss: 1.26; acc: 0.7
Batch: 20; loss: 1.71; acc: 0.47
Batch: 40; loss: 1.21; acc: 0.66
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.28; acc: 0.66
Batch: 100; loss: 1.4; acc: 0.61
Batch: 120; loss: 1.47; acc: 0.59
Batch: 140; loss: 1.34; acc: 0.7
Val Epoch over. val_loss: 1.4378768327129874; val_accuracy: 0.5870820063694268 

The current subspace-distance is: 6.459330052166479e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.24; acc: 0.78
Batch: 20; loss: 1.24; acc: 0.7
Batch: 40; loss: 1.31; acc: 0.53
Batch: 60; loss: 1.19; acc: 0.66
Batch: 80; loss: 1.46; acc: 0.61
Batch: 100; loss: 1.39; acc: 0.53
Batch: 120; loss: 1.39; acc: 0.64
Batch: 140; loss: 1.34; acc: 0.59
Batch: 160; loss: 1.25; acc: 0.69
Batch: 180; loss: 1.27; acc: 0.69
Batch: 200; loss: 1.42; acc: 0.56
Batch: 220; loss: 1.17; acc: 0.67
Batch: 240; loss: 1.26; acc: 0.62
Batch: 260; loss: 1.24; acc: 0.72
Batch: 280; loss: 1.2; acc: 0.69
Batch: 300; loss: 1.15; acc: 0.69
Batch: 320; loss: 1.12; acc: 0.73
Batch: 340; loss: 1.27; acc: 0.61
Batch: 360; loss: 1.18; acc: 0.69
Batch: 380; loss: 1.24; acc: 0.7
Batch: 400; loss: 1.24; acc: 0.56
Batch: 420; loss: 1.21; acc: 0.67
Batch: 440; loss: 1.36; acc: 0.58
Batch: 460; loss: 1.36; acc: 0.62
Batch: 480; loss: 1.33; acc: 0.56
Batch: 500; loss: 1.08; acc: 0.73
Batch: 520; loss: 1.04; acc: 0.75
Batch: 540; loss: 1.29; acc: 0.62
Batch: 560; loss: 1.21; acc: 0.69
Batch: 580; loss: 1.13; acc: 0.67
Batch: 600; loss: 1.13; acc: 0.72
Batch: 620; loss: 1.32; acc: 0.64
Batch: 640; loss: 1.25; acc: 0.64
Batch: 660; loss: 1.09; acc: 0.69
Batch: 680; loss: 1.28; acc: 0.59
Batch: 700; loss: 1.09; acc: 0.69
Batch: 720; loss: 1.17; acc: 0.66
Batch: 740; loss: 1.35; acc: 0.61
Batch: 760; loss: 1.33; acc: 0.61
Batch: 780; loss: 1.08; acc: 0.69
Train Epoch over. train_loss: 1.22; train_accuracy: 0.67 

3.238030330976471e-05
8.718830940779299e-06
Batch: 0; loss: 1.16; acc: 0.75
Batch: 20; loss: 1.53; acc: 0.58
Batch: 40; loss: 0.99; acc: 0.77
Batch: 60; loss: 1.11; acc: 0.73
Batch: 80; loss: 1.14; acc: 0.64
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.23; acc: 0.66
Batch: 140; loss: 1.1; acc: 0.72
Val Epoch over. val_loss: 1.2738473681127949; val_accuracy: 0.6326632165605095 

The current subspace-distance is: 8.718830940779299e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.37; acc: 0.61
Batch: 20; loss: 1.0; acc: 0.78
Batch: 40; loss: 1.06; acc: 0.75
Batch: 60; loss: 1.28; acc: 0.61
Batch: 80; loss: 1.12; acc: 0.73
Batch: 100; loss: 1.26; acc: 0.61
Batch: 120; loss: 1.07; acc: 0.72
Batch: 140; loss: 1.24; acc: 0.67
Batch: 160; loss: 1.07; acc: 0.75
Batch: 180; loss: 1.15; acc: 0.73
Batch: 200; loss: 1.02; acc: 0.77
Batch: 220; loss: 1.06; acc: 0.64
Batch: 240; loss: 1.22; acc: 0.64
Batch: 260; loss: 1.09; acc: 0.69
Batch: 280; loss: 1.15; acc: 0.69
Batch: 300; loss: 1.11; acc: 0.7
Batch: 320; loss: 1.09; acc: 0.72
Batch: 340; loss: 1.0; acc: 0.81
Batch: 360; loss: 1.11; acc: 0.67
Batch: 380; loss: 0.9; acc: 0.8
Batch: 400; loss: 1.03; acc: 0.72
Batch: 420; loss: 1.33; acc: 0.61
Batch: 440; loss: 0.84; acc: 0.84
Batch: 460; loss: 1.11; acc: 0.67
Batch: 480; loss: 1.01; acc: 0.78
Batch: 500; loss: 1.09; acc: 0.73
Batch: 520; loss: 1.25; acc: 0.66
Batch: 540; loss: 1.19; acc: 0.66
Batch: 560; loss: 1.01; acc: 0.72
Batch: 580; loss: 1.05; acc: 0.73
Batch: 600; loss: 1.15; acc: 0.72
Batch: 620; loss: 1.23; acc: 0.7
Batch: 640; loss: 1.23; acc: 0.66
Batch: 660; loss: 1.15; acc: 0.64
Batch: 680; loss: 1.0; acc: 0.77
Batch: 700; loss: 1.05; acc: 0.7
Batch: 720; loss: 1.05; acc: 0.75
Batch: 740; loss: 1.15; acc: 0.69
Batch: 760; loss: 0.92; acc: 0.75
Batch: 780; loss: 1.09; acc: 0.67
Train Epoch over. train_loss: 1.12; train_accuracy: 0.69 

3.49897745763883e-05
1.0807907528942451e-05
Batch: 0; loss: 1.23; acc: 0.58
Batch: 20; loss: 1.65; acc: 0.45
Batch: 40; loss: 1.45; acc: 0.5
Batch: 60; loss: 1.52; acc: 0.55
Batch: 80; loss: 1.47; acc: 0.48
Batch: 100; loss: 1.43; acc: 0.56
Batch: 120; loss: 1.41; acc: 0.52
Batch: 140; loss: 1.6; acc: 0.39
Val Epoch over. val_loss: 1.6023190902296904; val_accuracy: 0.48158837579617836 

The current subspace-distance is: 1.0807907528942451e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.22; acc: 0.64
Batch: 20; loss: 1.21; acc: 0.64
Batch: 40; loss: 1.19; acc: 0.64
Batch: 60; loss: 1.11; acc: 0.67
Batch: 80; loss: 1.08; acc: 0.66
Batch: 100; loss: 1.2; acc: 0.66
Batch: 120; loss: 1.01; acc: 0.75
Batch: 140; loss: 1.05; acc: 0.7
Batch: 160; loss: 1.06; acc: 0.7
Batch: 180; loss: 1.08; acc: 0.7
Batch: 200; loss: 0.99; acc: 0.7
Batch: 220; loss: 0.95; acc: 0.73
Batch: 240; loss: 0.97; acc: 0.75
Batch: 260; loss: 1.12; acc: 0.64
Batch: 280; loss: 0.93; acc: 0.75
Batch: 300; loss: 1.04; acc: 0.75
Batch: 320; loss: 1.22; acc: 0.64
Batch: 340; loss: 1.22; acc: 0.59
Batch: 360; loss: 0.84; acc: 0.77
Batch: 380; loss: 0.81; acc: 0.81
Batch: 400; loss: 1.14; acc: 0.62
Batch: 420; loss: 1.11; acc: 0.66
Batch: 440; loss: 1.14; acc: 0.66
Batch: 460; loss: 1.05; acc: 0.72
Batch: 480; loss: 1.05; acc: 0.73
Batch: 500; loss: 1.01; acc: 0.72
Batch: 520; loss: 1.12; acc: 0.62
Batch: 540; loss: 0.96; acc: 0.73
Batch: 560; loss: 1.21; acc: 0.62
Batch: 580; loss: 0.84; acc: 0.84
Batch: 600; loss: 1.06; acc: 0.67
Batch: 620; loss: 0.97; acc: 0.73
Batch: 640; loss: 1.03; acc: 0.75
Batch: 660; loss: 0.99; acc: 0.77
Batch: 680; loss: 1.17; acc: 0.66
Batch: 700; loss: 1.17; acc: 0.64
Batch: 720; loss: 1.06; acc: 0.66
Batch: 740; loss: 1.11; acc: 0.7
Batch: 760; loss: 1.12; acc: 0.67
Batch: 780; loss: 0.82; acc: 0.84
Train Epoch over. train_loss: 1.05; train_accuracy: 0.71 

3.641392322606407e-05
1.187723501061555e-05
Batch: 0; loss: 1.03; acc: 0.7
Batch: 20; loss: 1.68; acc: 0.42
Batch: 40; loss: 1.13; acc: 0.66
Batch: 60; loss: 1.17; acc: 0.67
Batch: 80; loss: 1.49; acc: 0.52
Batch: 100; loss: 1.19; acc: 0.62
Batch: 120; loss: 1.31; acc: 0.59
Batch: 140; loss: 1.26; acc: 0.53
Val Epoch over. val_loss: 1.4178697296008942; val_accuracy: 0.5367237261146497 

The current subspace-distance is: 1.187723501061555e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.72
Batch: 20; loss: 1.0; acc: 0.75
Batch: 40; loss: 0.98; acc: 0.73
Batch: 60; loss: 0.92; acc: 0.81
Batch: 80; loss: 0.9; acc: 0.77
Batch: 100; loss: 1.06; acc: 0.66
Batch: 120; loss: 1.14; acc: 0.7
Batch: 140; loss: 1.01; acc: 0.73
Batch: 160; loss: 1.13; acc: 0.72
Batch: 180; loss: 0.97; acc: 0.77
Batch: 200; loss: 0.96; acc: 0.72
Batch: 220; loss: 1.01; acc: 0.72
Batch: 240; loss: 0.98; acc: 0.73
Batch: 260; loss: 0.85; acc: 0.77
Batch: 280; loss: 1.03; acc: 0.72
Batch: 300; loss: 0.95; acc: 0.78
Batch: 320; loss: 1.04; acc: 0.72
Batch: 340; loss: 0.89; acc: 0.78
Batch: 360; loss: 1.08; acc: 0.67
Batch: 380; loss: 0.87; acc: 0.72
Batch: 400; loss: 0.84; acc: 0.77
Batch: 420; loss: 0.95; acc: 0.73
Batch: 440; loss: 0.98; acc: 0.73
Batch: 460; loss: 0.8; acc: 0.8
Batch: 480; loss: 0.98; acc: 0.77
Batch: 500; loss: 1.04; acc: 0.69
Batch: 520; loss: 1.13; acc: 0.64
Batch: 540; loss: 0.86; acc: 0.78
Batch: 560; loss: 0.83; acc: 0.77
Batch: 580; loss: 0.78; acc: 0.83
Batch: 600; loss: 0.88; acc: 0.77
Batch: 620; loss: 0.94; acc: 0.78
Batch: 640; loss: 1.06; acc: 0.78
Batch: 660; loss: 1.11; acc: 0.69
Batch: 680; loss: 0.89; acc: 0.81
Batch: 700; loss: 1.13; acc: 0.64
Batch: 720; loss: 0.84; acc: 0.77
Batch: 740; loss: 0.79; acc: 0.84
Batch: 760; loss: 0.83; acc: 0.8
Batch: 780; loss: 0.96; acc: 0.7
Train Epoch over. train_loss: 1.0; train_accuracy: 0.72 

3.923156691598706e-05
1.4069693861529231e-05
Batch: 0; loss: 1.04; acc: 0.67
Batch: 20; loss: 1.43; acc: 0.56
Batch: 40; loss: 1.04; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.66
Batch: 80; loss: 1.27; acc: 0.55
Batch: 100; loss: 1.23; acc: 0.58
Batch: 120; loss: 1.25; acc: 0.64
Batch: 140; loss: 0.98; acc: 0.73
Val Epoch over. val_loss: 1.2585133397655122; val_accuracy: 0.5974323248407644 

The current subspace-distance is: 1.4069693861529231e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.01; acc: 0.73
Batch: 20; loss: 0.88; acc: 0.77
Batch: 40; loss: 1.08; acc: 0.69
Batch: 60; loss: 0.96; acc: 0.7
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 0.83; acc: 0.78
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 1.06; acc: 0.7
Batch: 160; loss: 0.85; acc: 0.83
Batch: 180; loss: 0.96; acc: 0.72
Batch: 200; loss: 0.93; acc: 0.78
Batch: 220; loss: 1.13; acc: 0.69
Batch: 240; loss: 1.2; acc: 0.67
Batch: 260; loss: 0.95; acc: 0.69
Batch: 280; loss: 0.88; acc: 0.78
Batch: 300; loss: 1.0; acc: 0.69
Batch: 320; loss: 1.12; acc: 0.64
Batch: 340; loss: 0.95; acc: 0.69
Batch: 360; loss: 0.8; acc: 0.84
Batch: 380; loss: 0.79; acc: 0.8
Batch: 400; loss: 0.93; acc: 0.75
Batch: 420; loss: 0.78; acc: 0.8
Batch: 440; loss: 1.0; acc: 0.75
Batch: 460; loss: 0.95; acc: 0.75
Batch: 480; loss: 1.02; acc: 0.67
Batch: 500; loss: 1.12; acc: 0.67
Batch: 520; loss: 0.86; acc: 0.77
Batch: 540; loss: 0.74; acc: 0.86
Batch: 560; loss: 0.94; acc: 0.75
Batch: 580; loss: 0.98; acc: 0.67
Batch: 600; loss: 0.92; acc: 0.73
Batch: 620; loss: 0.84; acc: 0.8
Batch: 640; loss: 1.2; acc: 0.58
Batch: 660; loss: 0.91; acc: 0.69
Batch: 680; loss: 0.94; acc: 0.73
Batch: 700; loss: 0.86; acc: 0.81
Batch: 720; loss: 1.08; acc: 0.67
Batch: 740; loss: 0.9; acc: 0.75
Batch: 760; loss: 0.94; acc: 0.75
Batch: 780; loss: 1.1; acc: 0.62
Train Epoch over. train_loss: 0.97; train_accuracy: 0.73 

3.976515290560201e-05
1.392761078022886e-05
Batch: 0; loss: 0.78; acc: 0.84
Batch: 20; loss: 1.34; acc: 0.5
Batch: 40; loss: 0.82; acc: 0.77
Batch: 60; loss: 0.96; acc: 0.73
Batch: 80; loss: 0.97; acc: 0.69
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 1.05; acc: 0.75
Batch: 140; loss: 0.87; acc: 0.73
Val Epoch over. val_loss: 1.113704453608033; val_accuracy: 0.658140923566879 

The current subspace-distance is: 1.392761078022886e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.9; acc: 0.78
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.8; acc: 0.8
Batch: 60; loss: 1.09; acc: 0.7
Batch: 80; loss: 1.06; acc: 0.72
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 0.92; acc: 0.78
Batch: 140; loss: 0.99; acc: 0.67
Batch: 160; loss: 0.9; acc: 0.72
Batch: 180; loss: 1.01; acc: 0.64
Batch: 200; loss: 0.89; acc: 0.75
Batch: 220; loss: 0.9; acc: 0.77
Batch: 240; loss: 0.98; acc: 0.67
Batch: 260; loss: 0.92; acc: 0.73
Batch: 280; loss: 0.78; acc: 0.78
Batch: 300; loss: 0.85; acc: 0.77
Batch: 320; loss: 0.92; acc: 0.77
Batch: 340; loss: 0.91; acc: 0.8
Batch: 360; loss: 0.96; acc: 0.75
Batch: 380; loss: 0.9; acc: 0.7
Batch: 400; loss: 0.98; acc: 0.75
Batch: 420; loss: 0.83; acc: 0.78
Batch: 440; loss: 0.84; acc: 0.8
Batch: 460; loss: 1.0; acc: 0.72
Batch: 480; loss: 0.88; acc: 0.75
Batch: 500; loss: 0.74; acc: 0.83
Batch: 520; loss: 0.99; acc: 0.7
Batch: 540; loss: 0.99; acc: 0.75
Batch: 560; loss: 0.85; acc: 0.8
Batch: 580; loss: 0.95; acc: 0.7
Batch: 600; loss: 0.92; acc: 0.73
Batch: 620; loss: 1.01; acc: 0.7
Batch: 640; loss: 0.78; acc: 0.77
Batch: 660; loss: 1.04; acc: 0.73
Batch: 680; loss: 0.97; acc: 0.77
Batch: 700; loss: 0.89; acc: 0.75
Batch: 720; loss: 1.19; acc: 0.62
Batch: 740; loss: 0.85; acc: 0.72
Batch: 760; loss: 0.87; acc: 0.75
Batch: 780; loss: 0.83; acc: 0.78
Train Epoch over. train_loss: 0.94; train_accuracy: 0.73 

4.095045005669817e-05
1.5263283785316162e-05
Batch: 0; loss: 0.77; acc: 0.8
Batch: 20; loss: 1.18; acc: 0.58
Batch: 40; loss: 0.76; acc: 0.77
Batch: 60; loss: 0.87; acc: 0.8
Batch: 80; loss: 0.9; acc: 0.7
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 1.14; acc: 0.67
Batch: 140; loss: 0.71; acc: 0.88
Val Epoch over. val_loss: 0.9959699807653002; val_accuracy: 0.6989450636942676 

The current subspace-distance is: 1.5263283785316162e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.87; acc: 0.75
Batch: 20; loss: 0.86; acc: 0.81
Batch: 40; loss: 0.9; acc: 0.73
Batch: 60; loss: 0.85; acc: 0.75
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 1.24; acc: 0.58
Batch: 120; loss: 0.94; acc: 0.77
Batch: 140; loss: 0.87; acc: 0.72
Batch: 160; loss: 1.0; acc: 0.69
Batch: 180; loss: 1.03; acc: 0.67
Batch: 200; loss: 0.91; acc: 0.8
Batch: 220; loss: 0.98; acc: 0.72
Batch: 240; loss: 0.74; acc: 0.86
Batch: 260; loss: 1.05; acc: 0.72
Batch: 280; loss: 0.8; acc: 0.81
Batch: 300; loss: 0.83; acc: 0.77
Batch: 320; loss: 1.07; acc: 0.69
Batch: 340; loss: 0.89; acc: 0.72
Batch: 360; loss: 0.95; acc: 0.72
Batch: 380; loss: 0.97; acc: 0.72
Batch: 400; loss: 0.92; acc: 0.73
Batch: 420; loss: 1.01; acc: 0.72
Batch: 440; loss: 0.79; acc: 0.78
Batch: 460; loss: 0.96; acc: 0.69
Batch: 480; loss: 0.94; acc: 0.7
Batch: 500; loss: 0.82; acc: 0.83
Batch: 520; loss: 1.1; acc: 0.64
Batch: 540; loss: 0.82; acc: 0.8
Batch: 560; loss: 0.87; acc: 0.75
Batch: 580; loss: 0.91; acc: 0.73
Batch: 600; loss: 0.79; acc: 0.83
Batch: 620; loss: 0.85; acc: 0.75
Batch: 640; loss: 0.98; acc: 0.7
Batch: 660; loss: 0.96; acc: 0.8
Batch: 680; loss: 1.01; acc: 0.69
Batch: 700; loss: 0.77; acc: 0.81
Batch: 720; loss: 0.89; acc: 0.78
Batch: 740; loss: 0.93; acc: 0.77
Batch: 760; loss: 0.97; acc: 0.72
Batch: 780; loss: 0.92; acc: 0.77
Train Epoch over. train_loss: 0.92; train_accuracy: 0.74 

4.284259557607584e-05
1.6478528777952306e-05
Batch: 0; loss: 0.81; acc: 0.83
Batch: 20; loss: 1.19; acc: 0.7
Batch: 40; loss: 0.98; acc: 0.72
Batch: 60; loss: 1.12; acc: 0.66
Batch: 80; loss: 0.91; acc: 0.75
Batch: 100; loss: 1.03; acc: 0.73
Batch: 120; loss: 1.09; acc: 0.73
Batch: 140; loss: 0.89; acc: 0.77
Val Epoch over. val_loss: 1.1129587691300993; val_accuracy: 0.680234872611465 

The current subspace-distance is: 1.6478528777952306e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.03; acc: 0.7
Batch: 20; loss: 0.79; acc: 0.78
Batch: 40; loss: 0.76; acc: 0.75
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.86; acc: 0.73
Batch: 100; loss: 0.77; acc: 0.83
Batch: 120; loss: 0.92; acc: 0.73
Batch: 140; loss: 0.87; acc: 0.8
Batch: 160; loss: 0.95; acc: 0.75
Batch: 180; loss: 0.96; acc: 0.67
Batch: 200; loss: 0.94; acc: 0.7
Batch: 220; loss: 1.03; acc: 0.72
Batch: 240; loss: 0.77; acc: 0.78
Batch: 260; loss: 0.77; acc: 0.83
Batch: 280; loss: 0.86; acc: 0.72
Batch: 300; loss: 0.89; acc: 0.75
Batch: 320; loss: 1.0; acc: 0.64
Batch: 340; loss: 0.99; acc: 0.73
Batch: 360; loss: 0.89; acc: 0.73
Batch: 380; loss: 0.82; acc: 0.84
Batch: 400; loss: 0.72; acc: 0.86
Batch: 420; loss: 0.96; acc: 0.72
Batch: 440; loss: 0.61; acc: 0.88
Batch: 460; loss: 1.08; acc: 0.72
Batch: 480; loss: 0.96; acc: 0.77
Batch: 500; loss: 0.98; acc: 0.78
Batch: 520; loss: 1.0; acc: 0.7
Batch: 540; loss: 0.84; acc: 0.75
Batch: 560; loss: 0.89; acc: 0.75
Batch: 580; loss: 0.89; acc: 0.67
Batch: 600; loss: 1.15; acc: 0.66
Batch: 620; loss: 0.81; acc: 0.77
Batch: 640; loss: 1.11; acc: 0.72
Batch: 660; loss: 0.89; acc: 0.77
Batch: 680; loss: 0.71; acc: 0.73
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 1.08; acc: 0.72
Batch: 740; loss: 0.95; acc: 0.66
Batch: 760; loss: 0.8; acc: 0.78
Batch: 780; loss: 0.97; acc: 0.73
Train Epoch over. train_loss: 0.9; train_accuracy: 0.74 

4.471007559914142e-05
1.7546703020343557e-05
Batch: 0; loss: 0.94; acc: 0.73
Batch: 20; loss: 1.44; acc: 0.52
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.23; acc: 0.7
Batch: 80; loss: 0.98; acc: 0.72
Batch: 100; loss: 1.1; acc: 0.66
Batch: 120; loss: 1.18; acc: 0.61
Batch: 140; loss: 1.04; acc: 0.69
Val Epoch over. val_loss: 1.3282144274681238; val_accuracy: 0.6064888535031847 

The current subspace-distance is: 1.7546703020343557e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.87; acc: 0.73
Batch: 40; loss: 0.88; acc: 0.75
Batch: 60; loss: 0.97; acc: 0.72
Batch: 80; loss: 1.17; acc: 0.69
Batch: 100; loss: 0.76; acc: 0.81
Batch: 120; loss: 0.85; acc: 0.72
Batch: 140; loss: 0.87; acc: 0.75
Batch: 160; loss: 0.93; acc: 0.73
Batch: 180; loss: 1.16; acc: 0.64
Batch: 200; loss: 1.05; acc: 0.73
Batch: 220; loss: 1.09; acc: 0.7
Batch: 240; loss: 0.8; acc: 0.77
Batch: 260; loss: 0.74; acc: 0.78
Batch: 280; loss: 0.66; acc: 0.78
Batch: 300; loss: 0.84; acc: 0.73
Batch: 320; loss: 0.81; acc: 0.8
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.91; acc: 0.73
Batch: 380; loss: 0.98; acc: 0.69
Batch: 400; loss: 0.82; acc: 0.81
Batch: 420; loss: 0.9; acc: 0.72
Batch: 440; loss: 0.89; acc: 0.7
Batch: 460; loss: 0.77; acc: 0.8
Batch: 480; loss: 0.74; acc: 0.83
Batch: 500; loss: 0.84; acc: 0.69
Batch: 520; loss: 0.8; acc: 0.78
Batch: 540; loss: 1.01; acc: 0.69
Batch: 560; loss: 0.99; acc: 0.73
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 1.0; acc: 0.72
Batch: 620; loss: 0.98; acc: 0.75
Batch: 640; loss: 0.97; acc: 0.72
Batch: 660; loss: 0.95; acc: 0.67
Batch: 680; loss: 0.86; acc: 0.75
Batch: 700; loss: 1.07; acc: 0.64
Batch: 720; loss: 1.02; acc: 0.69
Batch: 740; loss: 0.78; acc: 0.81
Batch: 760; loss: 0.93; acc: 0.73
Batch: 780; loss: 1.04; acc: 0.72
Train Epoch over. train_loss: 0.89; train_accuracy: 0.74 

4.556140993372537e-05
1.8189159163739532e-05
Batch: 0; loss: 1.09; acc: 0.61
Batch: 20; loss: 1.48; acc: 0.48
Batch: 40; loss: 0.95; acc: 0.67
Batch: 60; loss: 0.95; acc: 0.67
Batch: 80; loss: 1.12; acc: 0.62
Batch: 100; loss: 1.24; acc: 0.59
Batch: 120; loss: 1.55; acc: 0.53
Batch: 140; loss: 0.87; acc: 0.69
Val Epoch over. val_loss: 1.1917699670336048; val_accuracy: 0.5883757961783439 

The current subspace-distance is: 1.8189159163739532e-05 

Epoch 11 start
The current lr is: 0.3
Batch: 0; loss: 0.91; acc: 0.73
Batch: 20; loss: 0.78; acc: 0.78
Batch: 40; loss: 0.89; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.86
Batch: 80; loss: 1.07; acc: 0.62
Batch: 100; loss: 0.88; acc: 0.7
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.92; acc: 0.77
Batch: 160; loss: 0.81; acc: 0.8
Batch: 180; loss: 0.85; acc: 0.75
Batch: 200; loss: 0.87; acc: 0.77
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 1.01; acc: 0.67
Batch: 260; loss: 0.96; acc: 0.69
Batch: 280; loss: 0.77; acc: 0.78
Batch: 300; loss: 0.71; acc: 0.83
Batch: 320; loss: 1.14; acc: 0.64
Batch: 340; loss: 0.83; acc: 0.73
Batch: 360; loss: 0.85; acc: 0.77
Batch: 380; loss: 1.04; acc: 0.67
Batch: 400; loss: 0.89; acc: 0.75
Batch: 420; loss: 0.72; acc: 0.81
Batch: 440; loss: 0.79; acc: 0.77
Batch: 460; loss: 0.95; acc: 0.73
Batch: 480; loss: 0.89; acc: 0.72
Batch: 500; loss: 0.83; acc: 0.73
Batch: 520; loss: 0.87; acc: 0.75
Batch: 540; loss: 0.81; acc: 0.73
Batch: 560; loss: 0.95; acc: 0.78
Batch: 580; loss: 0.72; acc: 0.83
Batch: 600; loss: 0.83; acc: 0.77
Batch: 620; loss: 0.92; acc: 0.7
Batch: 640; loss: 0.96; acc: 0.77
Batch: 660; loss: 0.8; acc: 0.77
Batch: 680; loss: 0.71; acc: 0.75
Batch: 700; loss: 0.96; acc: 0.72
Batch: 720; loss: 0.69; acc: 0.81
Batch: 740; loss: 0.62; acc: 0.83
Batch: 760; loss: 0.94; acc: 0.69
Batch: 780; loss: 0.79; acc: 0.78
Train Epoch over. train_loss: 0.86; train_accuracy: 0.76 

4.646301385946572e-05
1.868808794824872e-05
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 0.63; acc: 0.86
Batch: 60; loss: 0.76; acc: 0.83
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.84; acc: 0.77
Batch: 120; loss: 1.03; acc: 0.72
Batch: 140; loss: 0.51; acc: 0.91
Val Epoch over. val_loss: 0.8061356309113229; val_accuracy: 0.7721934713375797 

The current subspace-distance is: 1.868808794824872e-05 

Epoch 12 start
The current lr is: 0.3
Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 0.85; acc: 0.75
Batch: 40; loss: 0.95; acc: 0.75
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 0.85; acc: 0.7
Batch: 100; loss: 0.95; acc: 0.72
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.74; acc: 0.83
Batch: 160; loss: 0.76; acc: 0.81
Batch: 180; loss: 0.84; acc: 0.75
Batch: 200; loss: 0.8; acc: 0.8
Batch: 220; loss: 0.93; acc: 0.66
Batch: 240; loss: 0.72; acc: 0.77
Batch: 260; loss: 0.94; acc: 0.67
Batch: 280; loss: 0.8; acc: 0.77
Batch: 300; loss: 0.89; acc: 0.78
Batch: 320; loss: 0.87; acc: 0.73
Batch: 340; loss: 0.73; acc: 0.8
Batch: 360; loss: 0.73; acc: 0.77
Batch: 380; loss: 1.01; acc: 0.7
Batch: 400; loss: 0.94; acc: 0.7
Batch: 420; loss: 0.82; acc: 0.78
Batch: 440; loss: 0.89; acc: 0.77
Batch: 460; loss: 0.76; acc: 0.77
Batch: 480; loss: 0.86; acc: 0.81
Batch: 500; loss: 1.12; acc: 0.62
Batch: 520; loss: 0.84; acc: 0.81
Batch: 540; loss: 0.63; acc: 0.8
Batch: 560; loss: 0.87; acc: 0.73
Batch: 580; loss: 0.99; acc: 0.69
Batch: 600; loss: 0.66; acc: 0.83
Batch: 620; loss: 0.86; acc: 0.78
Batch: 640; loss: 0.86; acc: 0.75
Batch: 660; loss: 0.78; acc: 0.77
Batch: 680; loss: 0.92; acc: 0.72
Batch: 700; loss: 0.71; acc: 0.77
Batch: 720; loss: 0.87; acc: 0.75
Batch: 740; loss: 0.75; acc: 0.83
Batch: 760; loss: 0.89; acc: 0.69
Batch: 780; loss: 0.68; acc: 0.84
Train Epoch over. train_loss: 0.85; train_accuracy: 0.76 

4.6854311221977696e-05
1.8478333004168235e-05
Batch: 0; loss: 0.63; acc: 0.84
Batch: 20; loss: 1.04; acc: 0.69
Batch: 40; loss: 0.61; acc: 0.88
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.86; acc: 0.8
Batch: 120; loss: 1.06; acc: 0.67
Batch: 140; loss: 0.5; acc: 0.92
Val Epoch over. val_loss: 0.8151176397208195; val_accuracy: 0.7787619426751592 

The current subspace-distance is: 1.8478333004168235e-05 

Epoch 13 start
The current lr is: 0.3
Batch: 0; loss: 0.71; acc: 0.81
Batch: 20; loss: 0.75; acc: 0.8
Batch: 40; loss: 0.83; acc: 0.77
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 1.12; acc: 0.67
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.74; acc: 0.84
Batch: 160; loss: 1.11; acc: 0.67
Batch: 180; loss: 0.66; acc: 0.86
Batch: 200; loss: 0.86; acc: 0.77
Batch: 220; loss: 0.92; acc: 0.7
Batch: 240; loss: 0.8; acc: 0.77
Batch: 260; loss: 0.78; acc: 0.78
Batch: 280; loss: 0.99; acc: 0.69
Batch: 300; loss: 0.85; acc: 0.7
Batch: 320; loss: 0.87; acc: 0.7
Batch: 340; loss: 0.79; acc: 0.78
Batch: 360; loss: 0.94; acc: 0.73
Batch: 380; loss: 0.78; acc: 0.75
Batch: 400; loss: 0.87; acc: 0.78
Batch: 420; loss: 0.98; acc: 0.7
Batch: 440; loss: 0.78; acc: 0.8
Batch: 460; loss: 0.93; acc: 0.7
Batch: 480; loss: 0.85; acc: 0.75
Batch: 500; loss: 0.68; acc: 0.8
Batch: 520; loss: 0.7; acc: 0.83
Batch: 540; loss: 0.84; acc: 0.69
Batch: 560; loss: 0.88; acc: 0.77
Batch: 580; loss: 0.94; acc: 0.77
Batch: 600; loss: 0.82; acc: 0.73
Batch: 620; loss: 0.94; acc: 0.72
Batch: 640; loss: 0.85; acc: 0.78
Batch: 660; loss: 0.84; acc: 0.72
Batch: 680; loss: 0.85; acc: 0.75
Batch: 700; loss: 0.75; acc: 0.84
Batch: 720; loss: 0.94; acc: 0.7
Batch: 740; loss: 0.76; acc: 0.8
Batch: 760; loss: 0.8; acc: 0.72
Batch: 780; loss: 0.96; acc: 0.67
Train Epoch over. train_loss: 0.85; train_accuracy: 0.76 

4.7495384933426976e-05
1.9825594790745527e-05
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 1.02; acc: 0.69
Batch: 40; loss: 0.66; acc: 0.84
Batch: 60; loss: 0.88; acc: 0.77
Batch: 80; loss: 0.56; acc: 0.88
Batch: 100; loss: 0.87; acc: 0.78
Batch: 120; loss: 1.02; acc: 0.67
Batch: 140; loss: 0.56; acc: 0.88
Val Epoch over. val_loss: 0.861991884791927; val_accuracy: 0.7568670382165605 

The current subspace-distance is: 1.9825594790745527e-05 

Epoch 14 start
The current lr is: 0.3
Batch: 0; loss: 0.99; acc: 0.7
Batch: 20; loss: 0.88; acc: 0.67
Batch: 40; loss: 0.83; acc: 0.73
Batch: 60; loss: 0.99; acc: 0.66
Batch: 80; loss: 0.84; acc: 0.73
Batch: 100; loss: 0.72; acc: 0.88
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.66; acc: 0.78
Batch: 160; loss: 0.72; acc: 0.77
Batch: 180; loss: 0.72; acc: 0.78
Batch: 200; loss: 0.79; acc: 0.73
Batch: 220; loss: 0.73; acc: 0.8
Batch: 240; loss: 1.02; acc: 0.66
Batch: 260; loss: 0.81; acc: 0.81
Batch: 280; loss: 0.69; acc: 0.84
Batch: 300; loss: 0.81; acc: 0.78
Batch: 320; loss: 0.83; acc: 0.78
Batch: 340; loss: 0.86; acc: 0.72
Batch: 360; loss: 0.76; acc: 0.8
Batch: 380; loss: 0.91; acc: 0.72
Batch: 400; loss: 0.88; acc: 0.72
Batch: 420; loss: 0.84; acc: 0.75
Batch: 440; loss: 0.99; acc: 0.7
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.93; acc: 0.73
Batch: 500; loss: 0.88; acc: 0.77
Batch: 520; loss: 0.74; acc: 0.8
Batch: 540; loss: 0.79; acc: 0.75
Batch: 560; loss: 0.73; acc: 0.81
Batch: 580; loss: 0.96; acc: 0.73
Batch: 600; loss: 0.69; acc: 0.86
Batch: 620; loss: 0.87; acc: 0.73
Batch: 640; loss: 0.91; acc: 0.72
Batch: 660; loss: 0.99; acc: 0.73
Batch: 680; loss: 0.88; acc: 0.77
Batch: 700; loss: 0.88; acc: 0.73
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.68; acc: 0.83
Batch: 760; loss: 0.79; acc: 0.78
Batch: 780; loss: 0.81; acc: 0.73
Train Epoch over. train_loss: 0.84; train_accuracy: 0.76 

4.7185887524392456e-05
1.8828275642590597e-05
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 1.0; acc: 0.66
Batch: 40; loss: 0.56; acc: 0.89
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.57; acc: 0.84
Batch: 100; loss: 0.81; acc: 0.78
Batch: 120; loss: 1.1; acc: 0.67
Batch: 140; loss: 0.45; acc: 0.92
Val Epoch over. val_loss: 0.7694578282772355; val_accuracy: 0.7843351910828026 

The current subspace-distance is: 1.8828275642590597e-05 

Epoch 15 start
The current lr is: 0.3
Batch: 0; loss: 1.09; acc: 0.67
Batch: 20; loss: 0.71; acc: 0.84
Batch: 40; loss: 0.87; acc: 0.78
Batch: 60; loss: 0.78; acc: 0.75
Batch: 80; loss: 0.83; acc: 0.73
Batch: 100; loss: 0.81; acc: 0.8
Batch: 120; loss: 0.64; acc: 0.88
Batch: 140; loss: 0.71; acc: 0.88
Batch: 160; loss: 0.79; acc: 0.81
Batch: 180; loss: 0.86; acc: 0.75
Batch: 200; loss: 0.9; acc: 0.67
Batch: 220; loss: 0.93; acc: 0.77
Batch: 240; loss: 0.85; acc: 0.72
Batch: 260; loss: 0.81; acc: 0.78
Batch: 280; loss: 0.91; acc: 0.72
Batch: 300; loss: 0.97; acc: 0.75
Batch: 320; loss: 0.73; acc: 0.78
Batch: 340; loss: 0.88; acc: 0.78
Batch: 360; loss: 0.77; acc: 0.8
Batch: 380; loss: 0.82; acc: 0.81
Batch: 400; loss: 0.72; acc: 0.81
Batch: 420; loss: 0.81; acc: 0.78
Batch: 440; loss: 0.71; acc: 0.86
Batch: 460; loss: 0.62; acc: 0.8
Batch: 480; loss: 0.87; acc: 0.73
Batch: 500; loss: 1.19; acc: 0.59
Batch: 520; loss: 0.65; acc: 0.83
Batch: 540; loss: 0.99; acc: 0.69
Batch: 560; loss: 0.84; acc: 0.75
Batch: 580; loss: 0.68; acc: 0.81
Batch: 600; loss: 0.71; acc: 0.83
Batch: 620; loss: 0.91; acc: 0.75
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 0.99; acc: 0.67
Batch: 680; loss: 0.71; acc: 0.83
Batch: 700; loss: 0.89; acc: 0.73
Batch: 720; loss: 0.82; acc: 0.75
Batch: 740; loss: 0.71; acc: 0.8
Batch: 760; loss: 0.91; acc: 0.7
Batch: 780; loss: 0.83; acc: 0.75
Train Epoch over. train_loss: 0.84; train_accuracy: 0.76 

4.794056076207198e-05
1.8837119569070637e-05
Batch: 0; loss: 0.64; acc: 0.88
Batch: 20; loss: 1.04; acc: 0.66
Batch: 40; loss: 0.6; acc: 0.83
Batch: 60; loss: 0.73; acc: 0.83
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.83; acc: 0.75
Batch: 120; loss: 1.02; acc: 0.7
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8172264672388696; val_accuracy: 0.7639331210191083 

The current subspace-distance is: 1.8837119569070637e-05 

Epoch 16 start
The current lr is: 0.3
Batch: 0; loss: 0.96; acc: 0.7
Batch: 20; loss: 0.85; acc: 0.77
Batch: 40; loss: 1.11; acc: 0.66
Batch: 60; loss: 0.84; acc: 0.77
Batch: 80; loss: 0.74; acc: 0.73
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.77; acc: 0.78
Batch: 160; loss: 0.83; acc: 0.72
Batch: 180; loss: 0.88; acc: 0.77
Batch: 200; loss: 0.83; acc: 0.77
Batch: 220; loss: 0.86; acc: 0.78
Batch: 240; loss: 0.84; acc: 0.8
Batch: 260; loss: 0.88; acc: 0.73
Batch: 280; loss: 1.13; acc: 0.69
Batch: 300; loss: 0.9; acc: 0.69
Batch: 320; loss: 0.78; acc: 0.75
Batch: 340; loss: 0.75; acc: 0.73
Batch: 360; loss: 0.76; acc: 0.78
Batch: 380; loss: 0.75; acc: 0.77
Batch: 400; loss: 0.82; acc: 0.83
Batch: 420; loss: 0.78; acc: 0.8
Batch: 440; loss: 0.69; acc: 0.81
Batch: 460; loss: 0.85; acc: 0.73
Batch: 480; loss: 0.88; acc: 0.77
Batch: 500; loss: 0.62; acc: 0.81
Batch: 520; loss: 0.82; acc: 0.77
Batch: 540; loss: 0.81; acc: 0.8
Batch: 560; loss: 0.98; acc: 0.73
Batch: 580; loss: 0.94; acc: 0.72
Batch: 600; loss: 0.84; acc: 0.81
Batch: 620; loss: 0.74; acc: 0.75
Batch: 640; loss: 0.69; acc: 0.8
Batch: 660; loss: 0.91; acc: 0.7
Batch: 680; loss: 0.76; acc: 0.8
Batch: 700; loss: 0.77; acc: 0.75
Batch: 720; loss: 0.99; acc: 0.73
Batch: 740; loss: 0.81; acc: 0.8
Batch: 760; loss: 0.73; acc: 0.81
Batch: 780; loss: 0.8; acc: 0.84
Train Epoch over. train_loss: 0.83; train_accuracy: 0.76 

4.77847752335947e-05
1.9049990441999398e-05
Batch: 0; loss: 0.59; acc: 0.88
Batch: 20; loss: 1.03; acc: 0.66
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.81
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.52; acc: 0.89
Val Epoch over. val_loss: 0.8109759340999992; val_accuracy: 0.7615445859872612 

The current subspace-distance is: 1.9049990441999398e-05 

Epoch 17 start
The current lr is: 0.3
Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 0.92; acc: 0.78
Batch: 40; loss: 0.71; acc: 0.78
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.84; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.81
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.91; acc: 0.72
Batch: 160; loss: 1.03; acc: 0.67
Batch: 180; loss: 0.75; acc: 0.75
Batch: 200; loss: 0.9; acc: 0.77
Batch: 220; loss: 0.75; acc: 0.75
Batch: 240; loss: 0.81; acc: 0.81
Batch: 260; loss: 0.56; acc: 0.91
Batch: 280; loss: 0.8; acc: 0.83
Batch: 300; loss: 0.87; acc: 0.69
Batch: 320; loss: 0.97; acc: 0.69
Batch: 340; loss: 0.67; acc: 0.86
Batch: 360; loss: 0.79; acc: 0.78
Batch: 380; loss: 1.02; acc: 0.69
Batch: 400; loss: 0.85; acc: 0.69
Batch: 420; loss: 0.77; acc: 0.78
Batch: 440; loss: 0.85; acc: 0.78
Batch: 460; loss: 0.67; acc: 0.81
Batch: 480; loss: 0.69; acc: 0.83
Batch: 500; loss: 0.84; acc: 0.81
Batch: 520; loss: 1.0; acc: 0.67
Batch: 540; loss: 0.65; acc: 0.84
Batch: 560; loss: 0.93; acc: 0.7
Batch: 580; loss: 0.96; acc: 0.66
Batch: 600; loss: 0.62; acc: 0.84
Batch: 620; loss: 0.81; acc: 0.75
Batch: 640; loss: 0.86; acc: 0.75
Batch: 660; loss: 0.73; acc: 0.78
Batch: 680; loss: 0.7; acc: 0.84
Batch: 700; loss: 0.87; acc: 0.69
Batch: 720; loss: 0.72; acc: 0.77
Batch: 740; loss: 0.64; acc: 0.84
Batch: 760; loss: 0.89; acc: 0.69
Batch: 780; loss: 0.92; acc: 0.72
Train Epoch over. train_loss: 0.83; train_accuracy: 0.76 

4.838970198761672e-05
1.8786106011248194e-05
Batch: 0; loss: 0.59; acc: 0.88
Batch: 20; loss: 1.01; acc: 0.66
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 1.04; acc: 0.67
Batch: 140; loss: 0.43; acc: 0.94
Val Epoch over. val_loss: 0.7491360766113184; val_accuracy: 0.7934912420382165 

The current subspace-distance is: 1.8786106011248194e-05 

Epoch 18 start
The current lr is: 0.3
Batch: 0; loss: 0.88; acc: 0.72
Batch: 20; loss: 1.0; acc: 0.7
Batch: 40; loss: 0.73; acc: 0.8
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 0.88; acc: 0.72
Batch: 120; loss: 0.99; acc: 0.75
Batch: 140; loss: 0.81; acc: 0.8
Batch: 160; loss: 0.85; acc: 0.77
Batch: 180; loss: 0.93; acc: 0.73
Batch: 200; loss: 0.66; acc: 0.84
Batch: 220; loss: 0.88; acc: 0.72
Batch: 240; loss: 0.86; acc: 0.75
Batch: 260; loss: 0.63; acc: 0.84
Batch: 280; loss: 0.87; acc: 0.77
Batch: 300; loss: 0.86; acc: 0.72
Batch: 320; loss: 0.78; acc: 0.73
Batch: 340; loss: 0.76; acc: 0.78
Batch: 360; loss: 0.89; acc: 0.81
Batch: 380; loss: 0.76; acc: 0.77
Batch: 400; loss: 0.72; acc: 0.78
Batch: 420; loss: 0.81; acc: 0.73
Batch: 440; loss: 1.02; acc: 0.7
Batch: 460; loss: 0.97; acc: 0.69
Batch: 480; loss: 0.78; acc: 0.81
Batch: 500; loss: 0.76; acc: 0.72
Batch: 520; loss: 0.87; acc: 0.77
Batch: 540; loss: 0.75; acc: 0.78
Batch: 560; loss: 1.16; acc: 0.66
Batch: 580; loss: 0.81; acc: 0.73
Batch: 600; loss: 1.0; acc: 0.73
Batch: 620; loss: 1.0; acc: 0.69
Batch: 640; loss: 0.79; acc: 0.77
Batch: 660; loss: 0.94; acc: 0.67
Batch: 680; loss: 0.82; acc: 0.69
Batch: 700; loss: 0.73; acc: 0.78
Batch: 720; loss: 0.84; acc: 0.77
Batch: 740; loss: 0.68; acc: 0.77
Batch: 760; loss: 0.92; acc: 0.72
Batch: 780; loss: 1.02; acc: 0.67
Train Epoch over. train_loss: 0.82; train_accuracy: 0.76 

4.899137275060639e-05
1.977424108190462e-05
Batch: 0; loss: 0.65; acc: 0.83
Batch: 20; loss: 0.96; acc: 0.66
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.57; acc: 0.86
Batch: 100; loss: 0.81; acc: 0.78
Batch: 120; loss: 0.99; acc: 0.67
Batch: 140; loss: 0.48; acc: 0.88
Val Epoch over. val_loss: 0.784592382087829; val_accuracy: 0.7758757961783439 

The current subspace-distance is: 1.977424108190462e-05 

Epoch 19 start
The current lr is: 0.3
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.92; acc: 0.78
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 0.93; acc: 0.77
Batch: 80; loss: 0.81; acc: 0.78
Batch: 100; loss: 1.03; acc: 0.73
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.88; acc: 0.75
Batch: 160; loss: 0.76; acc: 0.77
Batch: 180; loss: 0.89; acc: 0.7
Batch: 200; loss: 0.89; acc: 0.7
Batch: 220; loss: 0.93; acc: 0.75
Batch: 240; loss: 0.96; acc: 0.72
Batch: 260; loss: 0.78; acc: 0.78
Batch: 280; loss: 0.92; acc: 0.72
Batch: 300; loss: 0.73; acc: 0.8
Batch: 320; loss: 0.87; acc: 0.66
Batch: 340; loss: 0.88; acc: 0.75
Batch: 360; loss: 0.7; acc: 0.77
Batch: 380; loss: 0.9; acc: 0.66
Batch: 400; loss: 0.69; acc: 0.83
Batch: 420; loss: 0.86; acc: 0.75
Batch: 440; loss: 0.98; acc: 0.72
Batch: 460; loss: 0.8; acc: 0.8
Batch: 480; loss: 0.65; acc: 0.88
Batch: 500; loss: 0.79; acc: 0.73
Batch: 520; loss: 0.63; acc: 0.78
Batch: 540; loss: 0.91; acc: 0.73
Batch: 560; loss: 0.99; acc: 0.61
Batch: 580; loss: 0.86; acc: 0.75
Batch: 600; loss: 0.83; acc: 0.8
Batch: 620; loss: 0.79; acc: 0.78
Batch: 640; loss: 0.88; acc: 0.67
Batch: 660; loss: 0.82; acc: 0.8
Batch: 680; loss: 0.84; acc: 0.78
Batch: 700; loss: 0.81; acc: 0.78
Batch: 720; loss: 0.7; acc: 0.88
Batch: 740; loss: 0.93; acc: 0.69
Batch: 760; loss: 0.64; acc: 0.83
Batch: 780; loss: 0.53; acc: 0.92
Train Epoch over. train_loss: 0.82; train_accuracy: 0.77 

4.891606658929959e-05
2.0236853742972016e-05
Batch: 0; loss: 0.6; acc: 0.89
Batch: 20; loss: 1.04; acc: 0.67
Batch: 40; loss: 0.62; acc: 0.84
Batch: 60; loss: 0.75; acc: 0.84
Batch: 80; loss: 0.6; acc: 0.84
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.56; acc: 0.91
Val Epoch over. val_loss: 0.793839060576858; val_accuracy: 0.775577229299363 

The current subspace-distance is: 2.0236853742972016e-05 

Epoch 20 start
The current lr is: 0.3
Batch: 0; loss: 0.9; acc: 0.77
Batch: 20; loss: 0.84; acc: 0.69
Batch: 40; loss: 0.74; acc: 0.81
Batch: 60; loss: 0.93; acc: 0.77
Batch: 80; loss: 0.95; acc: 0.72
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 0.74; acc: 0.83
Batch: 140; loss: 0.72; acc: 0.84
Batch: 160; loss: 0.79; acc: 0.73
Batch: 180; loss: 0.8; acc: 0.75
Batch: 200; loss: 0.96; acc: 0.69
Batch: 220; loss: 0.61; acc: 0.84
Batch: 240; loss: 0.91; acc: 0.69
Batch: 260; loss: 0.81; acc: 0.8
Batch: 280; loss: 0.85; acc: 0.8
Batch: 300; loss: 0.7; acc: 0.84
Batch: 320; loss: 0.76; acc: 0.83
Batch: 340; loss: 0.76; acc: 0.84
Batch: 360; loss: 0.85; acc: 0.75
Batch: 380; loss: 0.84; acc: 0.75
Batch: 400; loss: 0.89; acc: 0.73
Batch: 420; loss: 1.2; acc: 0.62
Batch: 440; loss: 0.78; acc: 0.81
Batch: 460; loss: 1.06; acc: 0.72
Batch: 480; loss: 0.61; acc: 0.84
Batch: 500; loss: 0.87; acc: 0.75
Batch: 520; loss: 0.91; acc: 0.69
Batch: 540; loss: 0.8; acc: 0.77
Batch: 560; loss: 0.88; acc: 0.69
Batch: 580; loss: 0.85; acc: 0.73
Batch: 600; loss: 0.72; acc: 0.81
Batch: 620; loss: 0.72; acc: 0.84
Batch: 640; loss: 0.92; acc: 0.75
Batch: 660; loss: 0.82; acc: 0.8
Batch: 680; loss: 0.95; acc: 0.75
Batch: 700; loss: 0.78; acc: 0.81
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.63; acc: 0.86
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.74; acc: 0.8
Train Epoch over. train_loss: 0.81; train_accuracy: 0.77 

4.9395104724681005e-05
2.050926923402585e-05
Batch: 0; loss: 0.59; acc: 0.88
Batch: 20; loss: 0.96; acc: 0.67
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.75; acc: 0.8
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.79; acc: 0.7
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.86
Val Epoch over. val_loss: 0.7878180060796677; val_accuracy: 0.7662221337579618 

The current subspace-distance is: 2.050926923402585e-05 

Epoch 21 start
The current lr is: 0.09
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.86; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 1.04; acc: 0.67
Batch: 80; loss: 0.6; acc: 0.86
Batch: 100; loss: 0.83; acc: 0.73
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.69; acc: 0.83
Batch: 160; loss: 0.83; acc: 0.7
Batch: 180; loss: 0.66; acc: 0.83
Batch: 200; loss: 0.63; acc: 0.83
Batch: 220; loss: 0.93; acc: 0.7
Batch: 240; loss: 0.83; acc: 0.77
Batch: 260; loss: 0.85; acc: 0.77
Batch: 280; loss: 0.71; acc: 0.8
Batch: 300; loss: 0.9; acc: 0.73
Batch: 320; loss: 0.95; acc: 0.72
Batch: 340; loss: 0.89; acc: 0.72
Batch: 360; loss: 0.84; acc: 0.78
Batch: 380; loss: 0.79; acc: 0.78
Batch: 400; loss: 0.72; acc: 0.81
Batch: 420; loss: 0.89; acc: 0.69
Batch: 440; loss: 0.78; acc: 0.8
Batch: 460; loss: 0.74; acc: 0.8
Batch: 480; loss: 0.85; acc: 0.8
Batch: 500; loss: 0.81; acc: 0.81
Batch: 520; loss: 0.88; acc: 0.7
Batch: 540; loss: 0.92; acc: 0.75
Batch: 560; loss: 1.07; acc: 0.66
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 0.71; acc: 0.78
Batch: 620; loss: 0.76; acc: 0.8
Batch: 640; loss: 0.76; acc: 0.8
Batch: 660; loss: 0.7; acc: 0.8
Batch: 680; loss: 0.82; acc: 0.8
Batch: 700; loss: 0.82; acc: 0.72
Batch: 720; loss: 0.65; acc: 0.88
Batch: 740; loss: 1.13; acc: 0.66
Batch: 760; loss: 0.71; acc: 0.84
Batch: 780; loss: 0.72; acc: 0.81
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

4.96014254167676e-05
2.0656376364058815e-05
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.9; acc: 0.75
Batch: 40; loss: 0.52; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.79; acc: 0.77
Batch: 120; loss: 1.02; acc: 0.67
Batch: 140; loss: 0.42; acc: 0.92
Val Epoch over. val_loss: 0.7202626626203015; val_accuracy: 0.8055334394904459 

The current subspace-distance is: 2.0656376364058815e-05 

Epoch 22 start
The current lr is: 0.09
Batch: 0; loss: 0.85; acc: 0.8
Batch: 20; loss: 0.94; acc: 0.73
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 0.6; acc: 0.91
Batch: 80; loss: 0.83; acc: 0.75
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.78; acc: 0.77
Batch: 160; loss: 0.82; acc: 0.75
Batch: 180; loss: 1.04; acc: 0.7
Batch: 200; loss: 0.83; acc: 0.8
Batch: 220; loss: 0.76; acc: 0.8
Batch: 240; loss: 1.12; acc: 0.61
Batch: 260; loss: 0.76; acc: 0.78
Batch: 280; loss: 0.72; acc: 0.78
Batch: 300; loss: 0.7; acc: 0.81
Batch: 320; loss: 0.75; acc: 0.8
Batch: 340; loss: 0.81; acc: 0.78
Batch: 360; loss: 0.75; acc: 0.78
Batch: 380; loss: 1.06; acc: 0.64
Batch: 400; loss: 0.82; acc: 0.78
Batch: 420; loss: 0.86; acc: 0.72
Batch: 440; loss: 0.8; acc: 0.78
Batch: 460; loss: 0.8; acc: 0.77
Batch: 480; loss: 0.89; acc: 0.7
Batch: 500; loss: 0.69; acc: 0.77
Batch: 520; loss: 1.1; acc: 0.61
Batch: 540; loss: 0.52; acc: 0.89
Batch: 560; loss: 0.86; acc: 0.7
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 0.6; acc: 0.84
Batch: 620; loss: 0.86; acc: 0.72
Batch: 640; loss: 0.97; acc: 0.75
Batch: 660; loss: 0.92; acc: 0.73
Batch: 680; loss: 1.06; acc: 0.69
Batch: 700; loss: 0.86; acc: 0.67
Batch: 720; loss: 0.83; acc: 0.73
Batch: 740; loss: 0.96; acc: 0.7
Batch: 760; loss: 0.7; acc: 0.8
Batch: 780; loss: 0.68; acc: 0.84
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

5.0559880037326366e-05
2.0810954083572142e-05
Batch: 0; loss: 0.55; acc: 0.89
Batch: 20; loss: 0.92; acc: 0.73
Batch: 40; loss: 0.54; acc: 0.86
Batch: 60; loss: 0.72; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.83; acc: 0.77
Batch: 120; loss: 1.01; acc: 0.66
Batch: 140; loss: 0.46; acc: 0.91
Val Epoch over. val_loss: 0.7466249281813384; val_accuracy: 0.7897093949044586 

The current subspace-distance is: 2.0810954083572142e-05 

Epoch 23 start
The current lr is: 0.09
Batch: 0; loss: 0.78; acc: 0.73
Batch: 20; loss: 0.84; acc: 0.77
Batch: 40; loss: 0.69; acc: 0.83
Batch: 60; loss: 0.85; acc: 0.77
Batch: 80; loss: 0.68; acc: 0.83
Batch: 100; loss: 0.76; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.84
Batch: 140; loss: 0.75; acc: 0.77
Batch: 160; loss: 0.66; acc: 0.84
Batch: 180; loss: 0.83; acc: 0.77
Batch: 200; loss: 0.65; acc: 0.81
Batch: 220; loss: 0.69; acc: 0.78
Batch: 240; loss: 0.71; acc: 0.78
Batch: 260; loss: 0.79; acc: 0.75
Batch: 280; loss: 0.87; acc: 0.77
Batch: 300; loss: 0.95; acc: 0.72
Batch: 320; loss: 0.68; acc: 0.81
Batch: 340; loss: 0.91; acc: 0.73
Batch: 360; loss: 0.92; acc: 0.78
Batch: 380; loss: 0.72; acc: 0.83
Batch: 400; loss: 0.84; acc: 0.7
Batch: 420; loss: 0.97; acc: 0.75
Batch: 440; loss: 1.06; acc: 0.67
Batch: 460; loss: 0.77; acc: 0.78
Batch: 480; loss: 0.68; acc: 0.83
Batch: 500; loss: 0.79; acc: 0.81
Batch: 520; loss: 0.82; acc: 0.73
Batch: 540; loss: 1.16; acc: 0.7
Batch: 560; loss: 0.78; acc: 0.75
Batch: 580; loss: 0.89; acc: 0.75
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 0.55; acc: 0.86
Batch: 640; loss: 0.81; acc: 0.8
Batch: 660; loss: 0.64; acc: 0.83
Batch: 680; loss: 0.71; acc: 0.86
Batch: 700; loss: 0.65; acc: 0.8
Batch: 720; loss: 0.75; acc: 0.81
Batch: 740; loss: 0.88; acc: 0.75
Batch: 760; loss: 1.06; acc: 0.69
Batch: 780; loss: 0.57; acc: 0.86
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

4.9885493353940547e-05
1.949515899468679e-05
Batch: 0; loss: 0.54; acc: 0.89
Batch: 20; loss: 0.92; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.84
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.43; acc: 0.89
Val Epoch over. val_loss: 0.7293025071074248; val_accuracy: 0.7975716560509554 

The current subspace-distance is: 1.949515899468679e-05 

Epoch 24 start
The current lr is: 0.09
Batch: 0; loss: 0.68; acc: 0.83
Batch: 20; loss: 0.78; acc: 0.81
Batch: 40; loss: 0.95; acc: 0.67
Batch: 60; loss: 0.97; acc: 0.72
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.74; acc: 0.78
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.83; acc: 0.77
Batch: 160; loss: 0.98; acc: 0.69
Batch: 180; loss: 0.67; acc: 0.86
Batch: 200; loss: 0.66; acc: 0.78
Batch: 220; loss: 0.76; acc: 0.78
Batch: 240; loss: 0.76; acc: 0.8
Batch: 260; loss: 0.56; acc: 0.89
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.99; acc: 0.72
Batch: 320; loss: 0.85; acc: 0.78
Batch: 340; loss: 0.77; acc: 0.77
Batch: 360; loss: 0.74; acc: 0.73
Batch: 380; loss: 0.77; acc: 0.77
Batch: 400; loss: 0.96; acc: 0.72
Batch: 420; loss: 0.77; acc: 0.75
Batch: 440; loss: 0.78; acc: 0.78
Batch: 460; loss: 0.88; acc: 0.72
Batch: 480; loss: 0.87; acc: 0.75
Batch: 500; loss: 0.8; acc: 0.75
Batch: 520; loss: 0.82; acc: 0.78
Batch: 540; loss: 0.68; acc: 0.78
Batch: 560; loss: 0.75; acc: 0.78
Batch: 580; loss: 1.02; acc: 0.69
Batch: 600; loss: 0.95; acc: 0.66
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.76; acc: 0.73
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.71; acc: 0.81
Batch: 700; loss: 0.94; acc: 0.7
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.77; acc: 0.78
Batch: 760; loss: 0.76; acc: 0.78
Batch: 780; loss: 0.75; acc: 0.75
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

4.983580220141448e-05
1.9957084077759646e-05
Batch: 0; loss: 0.55; acc: 0.89
Batch: 20; loss: 0.87; acc: 0.75
Batch: 40; loss: 0.5; acc: 0.92
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.79; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.42; acc: 0.92
Val Epoch over. val_loss: 0.7167512971884126; val_accuracy: 0.8017515923566879 

The current subspace-distance is: 1.9957084077759646e-05 

Epoch 25 start
The current lr is: 0.09
Batch: 0; loss: 0.7; acc: 0.83
Batch: 20; loss: 0.95; acc: 0.72
Batch: 40; loss: 0.66; acc: 0.81
Batch: 60; loss: 0.96; acc: 0.73
Batch: 80; loss: 0.73; acc: 0.73
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 1.01; acc: 0.73
Batch: 180; loss: 0.73; acc: 0.84
Batch: 200; loss: 0.81; acc: 0.73
Batch: 220; loss: 0.76; acc: 0.84
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 0.73; acc: 0.8
Batch: 280; loss: 0.85; acc: 0.7
Batch: 300; loss: 0.71; acc: 0.81
Batch: 320; loss: 0.84; acc: 0.73
Batch: 340; loss: 0.78; acc: 0.75
Batch: 360; loss: 0.91; acc: 0.69
Batch: 380; loss: 0.69; acc: 0.81
Batch: 400; loss: 0.76; acc: 0.78
Batch: 420; loss: 0.71; acc: 0.84
Batch: 440; loss: 0.96; acc: 0.73
Batch: 460; loss: 0.79; acc: 0.8
Batch: 480; loss: 0.78; acc: 0.77
Batch: 500; loss: 1.06; acc: 0.67
Batch: 520; loss: 0.76; acc: 0.77
Batch: 540; loss: 0.74; acc: 0.84
Batch: 560; loss: 0.69; acc: 0.81
Batch: 580; loss: 0.77; acc: 0.83
Batch: 600; loss: 0.82; acc: 0.72
Batch: 620; loss: 0.69; acc: 0.81
Batch: 640; loss: 0.96; acc: 0.7
Batch: 660; loss: 0.92; acc: 0.75
Batch: 680; loss: 0.84; acc: 0.77
Batch: 700; loss: 0.94; acc: 0.75
Batch: 720; loss: 0.92; acc: 0.77
Batch: 740; loss: 0.62; acc: 0.89
Batch: 760; loss: 0.85; acc: 0.69
Batch: 780; loss: 0.84; acc: 0.73
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

5.078527829027735e-05
2.1113957700436004e-05
Batch: 0; loss: 0.53; acc: 0.91
Batch: 20; loss: 0.87; acc: 0.72
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.77; acc: 0.83
Batch: 120; loss: 0.96; acc: 0.69
Batch: 140; loss: 0.43; acc: 0.91
Val Epoch over. val_loss: 0.7126710435767083; val_accuracy: 0.8036425159235668 

The current subspace-distance is: 2.1113957700436004e-05 

Epoch 26 start
The current lr is: 0.09
Batch: 0; loss: 0.78; acc: 0.8
Batch: 20; loss: 0.79; acc: 0.78
Batch: 40; loss: 0.56; acc: 0.84
Batch: 60; loss: 0.72; acc: 0.83
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 0.83; acc: 0.75
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.73; acc: 0.81
Batch: 160; loss: 0.78; acc: 0.77
Batch: 180; loss: 0.68; acc: 0.8
Batch: 200; loss: 0.85; acc: 0.78
Batch: 220; loss: 0.76; acc: 0.78
Batch: 240; loss: 0.82; acc: 0.73
Batch: 260; loss: 0.62; acc: 0.84
Batch: 280; loss: 0.99; acc: 0.67
Batch: 300; loss: 0.93; acc: 0.75
Batch: 320; loss: 0.87; acc: 0.77
Batch: 340; loss: 0.96; acc: 0.69
Batch: 360; loss: 0.83; acc: 0.81
Batch: 380; loss: 0.7; acc: 0.77
Batch: 400; loss: 0.85; acc: 0.75
Batch: 420; loss: 0.86; acc: 0.72
Batch: 440; loss: 0.88; acc: 0.73
Batch: 460; loss: 0.67; acc: 0.77
Batch: 480; loss: 0.89; acc: 0.8
Batch: 500; loss: 0.64; acc: 0.84
Batch: 520; loss: 0.86; acc: 0.77
Batch: 540; loss: 0.56; acc: 0.89
Batch: 560; loss: 0.99; acc: 0.72
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 0.86; acc: 0.64
Batch: 620; loss: 0.87; acc: 0.73
Batch: 640; loss: 0.74; acc: 0.8
Batch: 660; loss: 0.9; acc: 0.77
Batch: 680; loss: 0.84; acc: 0.73
Batch: 700; loss: 0.76; acc: 0.78
Batch: 720; loss: 1.02; acc: 0.69
Batch: 740; loss: 0.7; acc: 0.81
Batch: 760; loss: 0.67; acc: 0.84
Batch: 780; loss: 0.66; acc: 0.84
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

4.985977284377441e-05
1.8859986084862612e-05
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.9; acc: 0.75
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.72; acc: 0.8
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.78; acc: 0.81
Batch: 120; loss: 0.97; acc: 0.7
Batch: 140; loss: 0.44; acc: 0.92
Val Epoch over. val_loss: 0.736580749795695; val_accuracy: 0.7977707006369427 

The current subspace-distance is: 1.8859986084862612e-05 

Epoch 27 start
The current lr is: 0.09
Batch: 0; loss: 0.77; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.78
Batch: 40; loss: 0.73; acc: 0.81
Batch: 60; loss: 0.57; acc: 0.88
Batch: 80; loss: 0.99; acc: 0.67
Batch: 100; loss: 0.78; acc: 0.72
Batch: 120; loss: 0.56; acc: 0.89
Batch: 140; loss: 0.67; acc: 0.81
Batch: 160; loss: 0.79; acc: 0.8
Batch: 180; loss: 0.84; acc: 0.81
Batch: 200; loss: 0.65; acc: 0.8
Batch: 220; loss: 0.86; acc: 0.77
Batch: 240; loss: 0.81; acc: 0.78
Batch: 260; loss: 0.67; acc: 0.84
Batch: 280; loss: 0.7; acc: 0.81
Batch: 300; loss: 0.85; acc: 0.73
Batch: 320; loss: 0.69; acc: 0.75
Batch: 340; loss: 0.86; acc: 0.72
Batch: 360; loss: 0.73; acc: 0.81
Batch: 380; loss: 0.64; acc: 0.86
Batch: 400; loss: 0.65; acc: 0.84
Batch: 420; loss: 0.72; acc: 0.8
Batch: 440; loss: 0.85; acc: 0.75
Batch: 460; loss: 0.81; acc: 0.7
Batch: 480; loss: 0.9; acc: 0.72
Batch: 500; loss: 0.9; acc: 0.69
Batch: 520; loss: 0.82; acc: 0.72
Batch: 540; loss: 0.82; acc: 0.73
Batch: 560; loss: 0.87; acc: 0.77
Batch: 580; loss: 0.69; acc: 0.78
Batch: 600; loss: 0.94; acc: 0.66
Batch: 620; loss: 0.73; acc: 0.83
Batch: 640; loss: 0.62; acc: 0.86
Batch: 660; loss: 0.84; acc: 0.77
Batch: 680; loss: 0.61; acc: 0.88
Batch: 700; loss: 0.68; acc: 0.78
Batch: 720; loss: 0.79; acc: 0.78
Batch: 740; loss: 0.86; acc: 0.75
Batch: 760; loss: 0.84; acc: 0.72
Batch: 780; loss: 0.96; acc: 0.75
Train Epoch over. train_loss: 0.8; train_accuracy: 0.77 

5.015249553252943e-05
2.0583796867867932e-05
Batch: 0; loss: 0.53; acc: 0.91
Batch: 20; loss: 0.88; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.76; acc: 0.8
Batch: 120; loss: 0.96; acc: 0.7
Batch: 140; loss: 0.42; acc: 0.91
Val Epoch over. val_loss: 0.7195495103195215; val_accuracy: 0.8002587579617835 

The current subspace-distance is: 2.0583796867867932e-05 

Epoch 28 start
The current lr is: 0.09
Batch: 0; loss: 0.79; acc: 0.7
Batch: 20; loss: 0.78; acc: 0.77
Batch: 40; loss: 0.65; acc: 0.81
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.78
Batch: 140; loss: 0.82; acc: 0.77
Batch: 160; loss: 0.72; acc: 0.83
Batch: 180; loss: 0.92; acc: 0.72
Batch: 200; loss: 0.73; acc: 0.77
Batch: 220; loss: 0.61; acc: 0.84
Batch: 240; loss: 0.86; acc: 0.75
Batch: 260; loss: 0.89; acc: 0.77
Batch: 280; loss: 0.85; acc: 0.69
Batch: 300; loss: 0.67; acc: 0.84
Batch: 320; loss: 0.55; acc: 0.89
Batch: 340; loss: 0.73; acc: 0.78
Batch: 360; loss: 0.91; acc: 0.78
Batch: 380; loss: 0.85; acc: 0.73
Batch: 400; loss: 0.86; acc: 0.73
Batch: 420; loss: 0.78; acc: 0.81
Batch: 440; loss: 0.9; acc: 0.72
Batch: 460; loss: 0.64; acc: 0.88
Batch: 480; loss: 0.83; acc: 0.73
Batch: 500; loss: 0.83; acc: 0.7
Batch: 520; loss: 0.75; acc: 0.77
Batch: 540; loss: 0.85; acc: 0.75
Batch: 560; loss: 0.66; acc: 0.83
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.63; acc: 0.78
Batch: 620; loss: 0.86; acc: 0.77
Batch: 640; loss: 0.9; acc: 0.72
Batch: 660; loss: 0.88; acc: 0.77
Batch: 680; loss: 0.92; acc: 0.75
Batch: 700; loss: 0.96; acc: 0.73
Batch: 720; loss: 0.87; acc: 0.77
Batch: 740; loss: 1.09; acc: 0.72
Batch: 760; loss: 0.91; acc: 0.75
Batch: 780; loss: 0.79; acc: 0.77
Train Epoch over. train_loss: 0.79; train_accuracy: 0.77 

5.098628389532678e-05
2.134030182787683e-05
Batch: 0; loss: 0.56; acc: 0.92
Batch: 20; loss: 0.9; acc: 0.73
Batch: 40; loss: 0.55; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.8; acc: 0.83
Batch: 120; loss: 0.99; acc: 0.67
Batch: 140; loss: 0.44; acc: 0.92
Val Epoch over. val_loss: 0.7389565212711408; val_accuracy: 0.798765923566879 

The current subspace-distance is: 2.134030182787683e-05 

Epoch 29 start
The current lr is: 0.09
Batch: 0; loss: 0.64; acc: 0.86
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.76; acc: 0.78
Batch: 80; loss: 0.76; acc: 0.78
Batch: 100; loss: 0.77; acc: 0.81
Batch: 120; loss: 0.88; acc: 0.67
Batch: 140; loss: 0.74; acc: 0.86
Batch: 160; loss: 0.63; acc: 0.86
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.68; acc: 0.81
Batch: 220; loss: 0.95; acc: 0.69
Batch: 240; loss: 0.7; acc: 0.81
Batch: 260; loss: 0.82; acc: 0.8
Batch: 280; loss: 0.97; acc: 0.73
Batch: 300; loss: 0.72; acc: 0.78
Batch: 320; loss: 0.57; acc: 0.91
Batch: 340; loss: 0.81; acc: 0.8
Batch: 360; loss: 0.91; acc: 0.77
Batch: 380; loss: 0.71; acc: 0.75
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 0.85; acc: 0.75
Batch: 440; loss: 0.82; acc: 0.8
Batch: 460; loss: 0.67; acc: 0.86
Batch: 480; loss: 0.58; acc: 0.86
Batch: 500; loss: 0.65; acc: 0.78
Batch: 520; loss: 0.8; acc: 0.8
Batch: 540; loss: 0.8; acc: 0.73
Batch: 560; loss: 0.91; acc: 0.7
Batch: 580; loss: 0.73; acc: 0.8
Batch: 600; loss: 0.9; acc: 0.75
Batch: 620; loss: 0.8; acc: 0.75
Batch: 640; loss: 1.08; acc: 0.72
Batch: 660; loss: 0.63; acc: 0.83
Batch: 680; loss: 0.7; acc: 0.83
Batch: 700; loss: 0.7; acc: 0.81
Batch: 720; loss: 0.87; acc: 0.72
Batch: 740; loss: 0.78; acc: 0.8
Batch: 760; loss: 0.76; acc: 0.75
Batch: 780; loss: 0.8; acc: 0.84
Train Epoch over. train_loss: 0.79; train_accuracy: 0.77 

5.085306474938989e-05
2.055300683423411e-05
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.94; acc: 0.72
Batch: 40; loss: 0.53; acc: 0.89
Batch: 60; loss: 0.68; acc: 0.81
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 1.01; acc: 0.67
Batch: 140; loss: 0.44; acc: 0.92
Val Epoch over. val_loss: 0.7386316036342815; val_accuracy: 0.799562101910828 

The current subspace-distance is: 2.055300683423411e-05 

Epoch 30 start
The current lr is: 0.09
Batch: 0; loss: 0.8; acc: 0.83
Batch: 20; loss: 0.73; acc: 0.81
Batch: 40; loss: 1.01; acc: 0.64
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.86; acc: 0.77
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 0.85; acc: 0.72
Batch: 140; loss: 0.74; acc: 0.8
Batch: 160; loss: 0.77; acc: 0.75
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.71; acc: 0.73
Batch: 220; loss: 0.83; acc: 0.77
Batch: 240; loss: 0.68; acc: 0.84
Batch: 260; loss: 0.81; acc: 0.75
Batch: 280; loss: 0.59; acc: 0.86
Batch: 300; loss: 0.8; acc: 0.84
Batch: 320; loss: 0.68; acc: 0.81
Batch: 340; loss: 0.78; acc: 0.78
Batch: 360; loss: 0.92; acc: 0.72
Batch: 380; loss: 0.76; acc: 0.8
Batch: 400; loss: 0.94; acc: 0.73
Batch: 420; loss: 0.68; acc: 0.88
Batch: 440; loss: 0.67; acc: 0.86
Batch: 460; loss: 0.75; acc: 0.81
Batch: 480; loss: 0.94; acc: 0.73
Batch: 500; loss: 1.01; acc: 0.7
Batch: 520; loss: 0.69; acc: 0.83
Batch: 540; loss: 1.15; acc: 0.64
Batch: 560; loss: 0.73; acc: 0.83
Batch: 580; loss: 0.65; acc: 0.83
Batch: 600; loss: 0.76; acc: 0.77
Batch: 620; loss: 0.69; acc: 0.83
Batch: 640; loss: 0.69; acc: 0.8
Batch: 660; loss: 0.83; acc: 0.73
Batch: 680; loss: 0.93; acc: 0.66
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.79; acc: 0.8
Batch: 740; loss: 1.03; acc: 0.75
Batch: 760; loss: 0.73; acc: 0.81
Batch: 780; loss: 0.51; acc: 0.84
Train Epoch over. train_loss: 0.79; train_accuracy: 0.77 

5.054807843407616e-05
2.0636281988117844e-05
Batch: 0; loss: 0.51; acc: 0.91
Batch: 20; loss: 0.91; acc: 0.73
Batch: 40; loss: 0.52; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.8; acc: 0.78
Batch: 120; loss: 0.97; acc: 0.66
Batch: 140; loss: 0.44; acc: 0.88
Val Epoch over. val_loss: 0.7309127362670412; val_accuracy: 0.7983678343949044 

The current subspace-distance is: 2.0636281988117844e-05 

plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_500_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64
plots/subspace_training/table13slim/2020-01-29 15:59:47/N_1_flips_False_d_dim_XXXXX_lr_1.0_gamma_0.3_sched_freq_10_seed_1_epochs_30_batchsize_64
