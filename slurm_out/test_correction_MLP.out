model : MLP
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 2
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : True
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 20:43:18
nonzero elements in E: 45047
elements in E: 19921000
fraction nonzero: 0.002261282064153406
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.32; acc: 0.05
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.2
Batch: 140; loss: 2.31; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.17
Batch: 180; loss: 2.29; acc: 0.14
Batch: 200; loss: 2.29; acc: 0.22
Batch: 220; loss: 2.29; acc: 0.19
Batch: 240; loss: 2.29; acc: 0.16
Batch: 260; loss: 2.27; acc: 0.2
Batch: 280; loss: 2.28; acc: 0.17
Batch: 300; loss: 2.28; acc: 0.16
Batch: 320; loss: 2.27; acc: 0.2
Batch: 340; loss: 2.28; acc: 0.16
Batch: 360; loss: 2.28; acc: 0.09
Batch: 380; loss: 2.26; acc: 0.23
Batch: 400; loss: 2.26; acc: 0.25
Batch: 420; loss: 2.25; acc: 0.23
Batch: 440; loss: 2.27; acc: 0.12
Batch: 460; loss: 2.26; acc: 0.22
Batch: 480; loss: 2.27; acc: 0.17
Batch: 500; loss: 2.25; acc: 0.22
Batch: 520; loss: 2.23; acc: 0.28
Batch: 540; loss: 2.27; acc: 0.2
Batch: 560; loss: 2.28; acc: 0.16
Batch: 580; loss: 2.24; acc: 0.22
Batch: 600; loss: 2.23; acc: 0.25
Batch: 620; loss: 2.24; acc: 0.27
Batch: 640; loss: 2.22; acc: 0.28
Batch: 660; loss: 2.25; acc: 0.19
Batch: 680; loss: 2.21; acc: 0.3
Batch: 700; loss: 2.21; acc: 0.34
Batch: 720; loss: 2.21; acc: 0.33
Batch: 740; loss: 2.22; acc: 0.2
Batch: 760; loss: 2.2; acc: 0.31
Batch: 780; loss: 2.19; acc: 0.33
Train Epoch over. train_loss: 2.26; train_accuracy: 0.2 

5.905490525037749e-06
3.857533101836452e-06
Batch: 0; loss: 2.19; acc: 0.31
Batch: 20; loss: 2.21; acc: 0.28
Batch: 40; loss: 2.17; acc: 0.44
Batch: 60; loss: 2.18; acc: 0.41
Batch: 80; loss: 2.18; acc: 0.34
Batch: 100; loss: 2.21; acc: 0.28
Batch: 120; loss: 2.22; acc: 0.23
Batch: 140; loss: 2.18; acc: 0.39
Val Epoch over. val_loss: 2.2000808412102377; val_accuracy: 0.3304140127388535 

The current subspace-distance is: 3.857533101836452e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.2; acc: 0.33
Batch: 20; loss: 2.19; acc: 0.31
Batch: 40; loss: 2.18; acc: 0.33
Batch: 60; loss: 2.16; acc: 0.47
Batch: 80; loss: 2.18; acc: 0.38
Batch: 100; loss: 2.18; acc: 0.25
Batch: 120; loss: 2.13; acc: 0.45
Batch: 140; loss: 2.16; acc: 0.47
Batch: 160; loss: 2.14; acc: 0.42
Batch: 180; loss: 2.15; acc: 0.33
Batch: 200; loss: 2.12; acc: 0.42
Batch: 220; loss: 2.12; acc: 0.41
Batch: 240; loss: 2.12; acc: 0.31
Batch: 260; loss: 2.07; acc: 0.38
Batch: 280; loss: 2.08; acc: 0.39
Batch: 300; loss: 2.05; acc: 0.45
Batch: 320; loss: 2.06; acc: 0.44
Batch: 340; loss: 2.04; acc: 0.44
Batch: 360; loss: 2.02; acc: 0.42
Batch: 380; loss: 2.04; acc: 0.44
Batch: 400; loss: 2.04; acc: 0.38
Batch: 420; loss: 1.99; acc: 0.47
Batch: 440; loss: 2.03; acc: 0.36
Batch: 460; loss: 1.99; acc: 0.36
Batch: 480; loss: 1.99; acc: 0.39
Batch: 500; loss: 1.86; acc: 0.5
Batch: 520; loss: 1.89; acc: 0.48
Batch: 540; loss: 1.81; acc: 0.53
Batch: 560; loss: 1.84; acc: 0.38
Batch: 580; loss: 1.89; acc: 0.44
Batch: 600; loss: 1.76; acc: 0.56
Batch: 620; loss: 1.85; acc: 0.36
Batch: 640; loss: 1.85; acc: 0.44
Batch: 660; loss: 1.84; acc: 0.48
Batch: 680; loss: 1.63; acc: 0.58
Batch: 700; loss: 1.73; acc: 0.41
Batch: 720; loss: 1.72; acc: 0.47
Batch: 740; loss: 1.59; acc: 0.47
Batch: 760; loss: 1.74; acc: 0.41
Batch: 780; loss: 1.64; acc: 0.47
Train Epoch over. train_loss: 1.97; train_accuracy: 0.41 

1.5692878150730394e-05
1.0578796718618833e-05
Batch: 0; loss: 1.75; acc: 0.41
Batch: 20; loss: 1.7; acc: 0.44
Batch: 40; loss: 1.4; acc: 0.62
Batch: 60; loss: 1.53; acc: 0.56
Batch: 80; loss: 1.61; acc: 0.52
Batch: 100; loss: 1.61; acc: 0.5
Batch: 120; loss: 1.73; acc: 0.53
Batch: 140; loss: 1.46; acc: 0.64
Val Epoch over. val_loss: 1.623929149785619; val_accuracy: 0.49960191082802546 

The current subspace-distance is: 1.0578796718618833e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.57; acc: 0.53
Batch: 20; loss: 1.64; acc: 0.48
Batch: 40; loss: 1.66; acc: 0.45
Batch: 60; loss: 1.53; acc: 0.61
Batch: 80; loss: 1.55; acc: 0.53
Batch: 100; loss: 1.71; acc: 0.39
Batch: 120; loss: 1.49; acc: 0.61
Batch: 140; loss: 1.53; acc: 0.53
Batch: 160; loss: 1.6; acc: 0.5
Batch: 180; loss: 1.44; acc: 0.58
Batch: 200; loss: 1.51; acc: 0.52
Batch: 220; loss: 1.58; acc: 0.53
Batch: 240; loss: 1.56; acc: 0.62
Batch: 260; loss: 1.53; acc: 0.53
Batch: 280; loss: 1.4; acc: 0.58
Batch: 300; loss: 1.58; acc: 0.47
Batch: 320; loss: 1.3; acc: 0.53
Batch: 340; loss: 1.4; acc: 0.5
Batch: 360; loss: 1.4; acc: 0.48
Batch: 380; loss: 1.33; acc: 0.5
Batch: 400; loss: 1.28; acc: 0.64
Batch: 420; loss: 1.66; acc: 0.44
Batch: 440; loss: 1.59; acc: 0.42
Batch: 460; loss: 1.42; acc: 0.52
Batch: 480; loss: 1.37; acc: 0.52
Batch: 500; loss: 1.24; acc: 0.55
Batch: 520; loss: 1.73; acc: 0.44
Batch: 540; loss: 1.38; acc: 0.56
Batch: 560; loss: 1.47; acc: 0.47
Batch: 580; loss: 1.44; acc: 0.55
Batch: 600; loss: 1.28; acc: 0.58
Batch: 620; loss: 1.42; acc: 0.52
Batch: 640; loss: 1.27; acc: 0.67
Batch: 660; loss: 1.25; acc: 0.58
Batch: 680; loss: 1.25; acc: 0.55
Batch: 700; loss: 1.28; acc: 0.59
Batch: 720; loss: 1.43; acc: 0.56
Batch: 740; loss: 1.19; acc: 0.62
Batch: 760; loss: 1.27; acc: 0.69
Batch: 780; loss: 1.06; acc: 0.64
Train Epoch over. train_loss: 1.43; train_accuracy: 0.53 

2.4325157937710173e-05
1.689014425210189e-05
Batch: 0; loss: 1.57; acc: 0.42
Batch: 20; loss: 1.39; acc: 0.55
Batch: 40; loss: 1.01; acc: 0.64
Batch: 60; loss: 1.16; acc: 0.62
Batch: 80; loss: 1.13; acc: 0.61
Batch: 100; loss: 1.35; acc: 0.59
Batch: 120; loss: 1.5; acc: 0.53
Batch: 140; loss: 1.09; acc: 0.67
Val Epoch over. val_loss: 1.2650524837196253; val_accuracy: 0.5763335987261147 

The current subspace-distance is: 1.689014425210189e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.45; acc: 0.53
Batch: 20; loss: 1.01; acc: 0.69
Batch: 40; loss: 1.49; acc: 0.47
Batch: 60; loss: 1.46; acc: 0.5
Batch: 80; loss: 1.17; acc: 0.61
Batch: 100; loss: 1.34; acc: 0.58
Batch: 120; loss: 1.35; acc: 0.52
Batch: 140; loss: 1.46; acc: 0.55
Batch: 160; loss: 1.36; acc: 0.53
Batch: 180; loss: 1.21; acc: 0.56
Batch: 200; loss: 1.13; acc: 0.66
Batch: 220; loss: 1.38; acc: 0.59
Batch: 240; loss: 1.31; acc: 0.55
Batch: 260; loss: 1.45; acc: 0.48
Batch: 280; loss: 1.14; acc: 0.61
Batch: 300; loss: 1.4; acc: 0.55
Batch: 320; loss: 1.28; acc: 0.58
Batch: 340; loss: 1.19; acc: 0.59
Batch: 360; loss: 1.3; acc: 0.58
Batch: 380; loss: 1.51; acc: 0.39
Batch: 400; loss: 1.01; acc: 0.7
Batch: 420; loss: 1.2; acc: 0.62
Batch: 440; loss: 1.23; acc: 0.53
Batch: 460; loss: 1.17; acc: 0.58
Batch: 480; loss: 1.24; acc: 0.61
Batch: 500; loss: 1.3; acc: 0.53
Batch: 520; loss: 1.22; acc: 0.53
Batch: 540; loss: 1.23; acc: 0.58
Batch: 560; loss: 1.13; acc: 0.59
Batch: 580; loss: 1.38; acc: 0.52
Batch: 600; loss: 1.26; acc: 0.58
Batch: 620; loss: 1.22; acc: 0.61
Batch: 640; loss: 1.45; acc: 0.44
Batch: 660; loss: 1.06; acc: 0.64
Batch: 680; loss: 1.12; acc: 0.55
Batch: 700; loss: 1.19; acc: 0.61
Batch: 720; loss: 1.36; acc: 0.59
Batch: 740; loss: 1.33; acc: 0.53
Batch: 760; loss: 1.23; acc: 0.56
Batch: 780; loss: 0.92; acc: 0.7
Train Epoch over. train_loss: 1.26; train_accuracy: 0.57 

2.733470500970725e-05
1.765420165611431e-05
Batch: 0; loss: 1.57; acc: 0.47
Batch: 20; loss: 1.31; acc: 0.62
Batch: 40; loss: 0.96; acc: 0.64
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 1.02; acc: 0.67
Batch: 100; loss: 1.28; acc: 0.61
Batch: 120; loss: 1.46; acc: 0.53
Batch: 140; loss: 0.96; acc: 0.7
Val Epoch over. val_loss: 1.1997748480480948; val_accuracy: 0.595640923566879 

The current subspace-distance is: 1.765420165611431e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.55
Batch: 20; loss: 1.38; acc: 0.55
Batch: 40; loss: 1.08; acc: 0.66
Batch: 60; loss: 1.17; acc: 0.64
Batch: 80; loss: 1.28; acc: 0.53
Batch: 100; loss: 0.98; acc: 0.66
Batch: 120; loss: 1.38; acc: 0.5
Batch: 140; loss: 1.05; acc: 0.69
Batch: 160; loss: 1.07; acc: 0.69
Batch: 180; loss: 1.31; acc: 0.55
Batch: 200; loss: 1.25; acc: 0.58
Batch: 220; loss: 1.17; acc: 0.62
Batch: 240; loss: 1.22; acc: 0.52
Batch: 260; loss: 1.31; acc: 0.58
Batch: 280; loss: 1.27; acc: 0.58
Batch: 300; loss: 1.17; acc: 0.59
Batch: 320; loss: 1.15; acc: 0.62
Batch: 340; loss: 1.13; acc: 0.67
Batch: 360; loss: 0.89; acc: 0.75
Batch: 380; loss: 1.59; acc: 0.53
Batch: 400; loss: 1.1; acc: 0.56
Batch: 420; loss: 0.96; acc: 0.66
Batch: 440; loss: 1.29; acc: 0.56
Batch: 460; loss: 1.06; acc: 0.62
Batch: 480; loss: 1.31; acc: 0.56
Batch: 500; loss: 1.37; acc: 0.58
Batch: 520; loss: 1.25; acc: 0.52
Batch: 540; loss: 1.6; acc: 0.47
Batch: 560; loss: 1.14; acc: 0.59
Batch: 580; loss: 1.02; acc: 0.67
Batch: 600; loss: 1.15; acc: 0.64
Batch: 620; loss: 1.11; acc: 0.67
Batch: 640; loss: 1.29; acc: 0.5
Batch: 660; loss: 1.27; acc: 0.5
Batch: 680; loss: 1.52; acc: 0.45
Batch: 700; loss: 1.34; acc: 0.56
Batch: 720; loss: 1.01; acc: 0.59
Batch: 740; loss: 1.11; acc: 0.66
Batch: 760; loss: 1.36; acc: 0.56
Batch: 780; loss: 1.27; acc: 0.58
Train Epoch over. train_loss: 1.23; train_accuracy: 0.58 

2.777820009214338e-05
1.641711060074158e-05
Batch: 0; loss: 1.57; acc: 0.55
Batch: 20; loss: 1.28; acc: 0.58
Batch: 40; loss: 0.92; acc: 0.69
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 0.96; acc: 0.7
Batch: 100; loss: 1.31; acc: 0.61
Batch: 120; loss: 1.46; acc: 0.58
Batch: 140; loss: 0.9; acc: 0.73
Val Epoch over. val_loss: 1.181069025568142; val_accuracy: 0.6043988853503185 

The current subspace-distance is: 1.641711060074158e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.53; acc: 0.61
Batch: 20; loss: 1.23; acc: 0.61
Batch: 40; loss: 1.22; acc: 0.58
Batch: 60; loss: 1.48; acc: 0.44
Batch: 80; loss: 1.22; acc: 0.53
Batch: 100; loss: 1.42; acc: 0.52
Batch: 120; loss: 1.34; acc: 0.52
Batch: 140; loss: 1.27; acc: 0.52
Batch: 160; loss: 1.2; acc: 0.62
Batch: 180; loss: 1.25; acc: 0.58
Batch: 200; loss: 1.14; acc: 0.56
Batch: 220; loss: 1.16; acc: 0.66
Batch: 240; loss: 1.16; acc: 0.61
Batch: 260; loss: 1.06; acc: 0.61
Batch: 280; loss: 1.17; acc: 0.64
Batch: 300; loss: 1.01; acc: 0.7
Batch: 320; loss: 1.06; acc: 0.58
Batch: 340; loss: 1.25; acc: 0.59
Batch: 360; loss: 1.17; acc: 0.56
Batch: 380; loss: 1.21; acc: 0.58
Batch: 400; loss: 1.03; acc: 0.62
Batch: 420; loss: 1.15; acc: 0.62
Batch: 440; loss: 1.0; acc: 0.7
Batch: 460; loss: 1.47; acc: 0.47
Batch: 480; loss: 1.28; acc: 0.61
Batch: 500; loss: 1.14; acc: 0.66
Batch: 520; loss: 1.43; acc: 0.47
Batch: 540; loss: 1.16; acc: 0.59
Batch: 560; loss: 1.36; acc: 0.5
Batch: 580; loss: 1.03; acc: 0.69
Batch: 600; loss: 1.08; acc: 0.56
Batch: 620; loss: 1.12; acc: 0.64
Batch: 640; loss: 1.3; acc: 0.56
Batch: 660; loss: 1.23; acc: 0.58
Batch: 680; loss: 1.1; acc: 0.59
Batch: 700; loss: 1.19; acc: 0.62
Batch: 720; loss: 1.09; acc: 0.62
Batch: 740; loss: 1.31; acc: 0.55
Batch: 760; loss: 1.23; acc: 0.55
Batch: 780; loss: 1.08; acc: 0.67
Train Epoch over. train_loss: 1.22; train_accuracy: 0.59 

2.7932346711168066e-05
1.782017898221966e-05
Batch: 0; loss: 1.55; acc: 0.58
Batch: 20; loss: 1.26; acc: 0.55
Batch: 40; loss: 0.92; acc: 0.66
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 0.91; acc: 0.72
Batch: 100; loss: 1.34; acc: 0.56
Batch: 120; loss: 1.47; acc: 0.53
Batch: 140; loss: 0.87; acc: 0.7
Val Epoch over. val_loss: 1.167745154374724; val_accuracy: 0.6088773885350318 

The current subspace-distance is: 1.782017898221966e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.01; acc: 0.7
Batch: 40; loss: 1.18; acc: 0.67
Batch: 60; loss: 1.22; acc: 0.61
Batch: 80; loss: 1.39; acc: 0.58
Batch: 100; loss: 1.2; acc: 0.62
Batch: 120; loss: 1.55; acc: 0.45
Batch: 140; loss: 1.11; acc: 0.64
Batch: 160; loss: 1.14; acc: 0.62
Batch: 180; loss: 1.37; acc: 0.52
Batch: 200; loss: 1.03; acc: 0.69
Batch: 220; loss: 1.18; acc: 0.62
Batch: 240; loss: 1.26; acc: 0.66
Batch: 260; loss: 1.0; acc: 0.59
Batch: 280; loss: 1.21; acc: 0.59
Batch: 300; loss: 1.26; acc: 0.55
Batch: 320; loss: 1.29; acc: 0.56
Batch: 340; loss: 1.18; acc: 0.67
Batch: 360; loss: 1.42; acc: 0.52
Batch: 380; loss: 1.12; acc: 0.61
Batch: 400; loss: 1.41; acc: 0.55
Batch: 420; loss: 1.37; acc: 0.62
Batch: 440; loss: 1.1; acc: 0.56
Batch: 460; loss: 1.14; acc: 0.62
Batch: 480; loss: 1.31; acc: 0.47
Batch: 500; loss: 1.34; acc: 0.5
Batch: 520; loss: 1.15; acc: 0.59
Batch: 540; loss: 1.34; acc: 0.58
Batch: 560; loss: 1.19; acc: 0.64
Batch: 580; loss: 1.02; acc: 0.59
Batch: 600; loss: 1.19; acc: 0.58
Batch: 620; loss: 1.44; acc: 0.53
Batch: 640; loss: 1.12; acc: 0.62
Batch: 660; loss: 1.17; acc: 0.56
Batch: 680; loss: 1.43; acc: 0.53
Batch: 700; loss: 1.29; acc: 0.58
Batch: 720; loss: 1.24; acc: 0.55
Batch: 740; loss: 1.43; acc: 0.59
Batch: 760; loss: 1.16; acc: 0.58
Batch: 780; loss: 1.29; acc: 0.52
Train Epoch over. train_loss: 1.21; train_accuracy: 0.59 

3.1065817893249914e-05
1.86331362783676e-05
Batch: 0; loss: 1.49; acc: 0.58
Batch: 20; loss: 1.24; acc: 0.58
Batch: 40; loss: 0.91; acc: 0.7
Batch: 60; loss: 1.12; acc: 0.66
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 1.37; acc: 0.56
Batch: 120; loss: 1.46; acc: 0.53
Batch: 140; loss: 0.84; acc: 0.72
Val Epoch over. val_loss: 1.1571715641173588; val_accuracy: 0.6098726114649682 

The current subspace-distance is: 1.86331362783676e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.04; acc: 0.64
Batch: 20; loss: 1.23; acc: 0.61
Batch: 40; loss: 1.43; acc: 0.55
Batch: 60; loss: 1.24; acc: 0.58
Batch: 80; loss: 1.33; acc: 0.58
Batch: 100; loss: 1.23; acc: 0.52
Batch: 120; loss: 1.35; acc: 0.56
Batch: 140; loss: 1.25; acc: 0.62
Batch: 160; loss: 1.43; acc: 0.5
Batch: 180; loss: 1.32; acc: 0.56
Batch: 200; loss: 1.15; acc: 0.62
Batch: 220; loss: 1.09; acc: 0.64
Batch: 240; loss: 1.11; acc: 0.62
Batch: 260; loss: 1.12; acc: 0.67
Batch: 280; loss: 1.22; acc: 0.53
Batch: 300; loss: 1.13; acc: 0.66
Batch: 320; loss: 1.1; acc: 0.61
Batch: 340; loss: 1.47; acc: 0.52
Batch: 360; loss: 1.11; acc: 0.61
Batch: 380; loss: 1.2; acc: 0.61
Batch: 400; loss: 1.35; acc: 0.56
Batch: 420; loss: 1.07; acc: 0.64
Batch: 440; loss: 1.18; acc: 0.59
Batch: 460; loss: 1.4; acc: 0.45
Batch: 480; loss: 1.6; acc: 0.47
Batch: 500; loss: 1.33; acc: 0.55
Batch: 520; loss: 1.22; acc: 0.55
Batch: 540; loss: 1.33; acc: 0.53
Batch: 560; loss: 0.88; acc: 0.67
Batch: 580; loss: 0.9; acc: 0.69
Batch: 600; loss: 1.08; acc: 0.62
Batch: 620; loss: 1.12; acc: 0.61
Batch: 640; loss: 0.87; acc: 0.72
Batch: 660; loss: 1.17; acc: 0.59
Batch: 680; loss: 1.21; acc: 0.64
Batch: 700; loss: 1.23; acc: 0.62
Batch: 720; loss: 1.11; acc: 0.69
Batch: 740; loss: 1.03; acc: 0.61
Batch: 760; loss: 1.15; acc: 0.59
Batch: 780; loss: 1.12; acc: 0.61
Train Epoch over. train_loss: 1.2; train_accuracy: 0.6 

2.7016263629775494e-05
1.90598402696196e-05
Batch: 0; loss: 1.45; acc: 0.58
Batch: 20; loss: 1.24; acc: 0.58
Batch: 40; loss: 0.9; acc: 0.69
Batch: 60; loss: 1.12; acc: 0.66
Batch: 80; loss: 0.88; acc: 0.75
Batch: 100; loss: 1.34; acc: 0.56
Batch: 120; loss: 1.44; acc: 0.55
Batch: 140; loss: 0.81; acc: 0.69
Val Epoch over. val_loss: 1.1491458150231915; val_accuracy: 0.6136544585987261 

The current subspace-distance is: 1.90598402696196e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.08; acc: 0.66
Batch: 20; loss: 1.4; acc: 0.59
Batch: 40; loss: 1.25; acc: 0.59
Batch: 60; loss: 1.18; acc: 0.56
Batch: 80; loss: 1.19; acc: 0.66
Batch: 100; loss: 1.2; acc: 0.58
Batch: 120; loss: 1.24; acc: 0.61
Batch: 140; loss: 1.23; acc: 0.66
Batch: 160; loss: 1.08; acc: 0.59
Batch: 180; loss: 1.09; acc: 0.66
Batch: 200; loss: 0.9; acc: 0.7
Batch: 220; loss: 1.3; acc: 0.59
Batch: 240; loss: 1.15; acc: 0.58
Batch: 260; loss: 1.2; acc: 0.62
Batch: 280; loss: 1.18; acc: 0.62
Batch: 300; loss: 1.3; acc: 0.58
Batch: 320; loss: 1.12; acc: 0.61
Batch: 340; loss: 0.78; acc: 0.78
Batch: 360; loss: 1.12; acc: 0.61
Batch: 380; loss: 0.99; acc: 0.64
Batch: 400; loss: 1.22; acc: 0.61
Batch: 420; loss: 0.78; acc: 0.75
Batch: 440; loss: 1.19; acc: 0.62
Batch: 460; loss: 1.36; acc: 0.58
Batch: 480; loss: 1.13; acc: 0.58
Batch: 500; loss: 0.97; acc: 0.67
Batch: 520; loss: 0.98; acc: 0.69
Batch: 540; loss: 1.32; acc: 0.59
Batch: 560; loss: 1.29; acc: 0.55
Batch: 580; loss: 1.26; acc: 0.58
Batch: 600; loss: 1.16; acc: 0.59
Batch: 620; loss: 1.06; acc: 0.59
Batch: 640; loss: 0.96; acc: 0.69
Batch: 660; loss: 1.24; acc: 0.59
Batch: 680; loss: 1.06; acc: 0.62
Batch: 700; loss: 1.2; acc: 0.66
Batch: 720; loss: 0.99; acc: 0.72
Batch: 740; loss: 1.33; acc: 0.53
Batch: 760; loss: 1.08; acc: 0.75
Batch: 780; loss: 1.38; acc: 0.55
Train Epoch over. train_loss: 1.19; train_accuracy: 0.6 

2.7366333597456105e-05
1.890709791041445e-05
Batch: 0; loss: 1.42; acc: 0.55
Batch: 20; loss: 1.24; acc: 0.58
Batch: 40; loss: 0.89; acc: 0.7
Batch: 60; loss: 1.1; acc: 0.66
Batch: 80; loss: 0.86; acc: 0.78
Batch: 100; loss: 1.36; acc: 0.56
Batch: 120; loss: 1.42; acc: 0.56
Batch: 140; loss: 0.78; acc: 0.67
Val Epoch over. val_loss: 1.1407082923658334; val_accuracy: 0.6202229299363057 

The current subspace-distance is: 1.890709791041445e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 0.94; acc: 0.64
Batch: 60; loss: 1.04; acc: 0.64
Batch: 80; loss: 1.06; acc: 0.69
Batch: 100; loss: 1.19; acc: 0.67
Batch: 120; loss: 1.24; acc: 0.59
Batch: 140; loss: 1.46; acc: 0.55
Batch: 160; loss: 1.07; acc: 0.61
Batch: 180; loss: 1.18; acc: 0.61
Batch: 200; loss: 1.42; acc: 0.53
Batch: 220; loss: 1.38; acc: 0.48
Batch: 240; loss: 1.3; acc: 0.5
Batch: 260; loss: 1.11; acc: 0.62
Batch: 280; loss: 1.16; acc: 0.66
Batch: 300; loss: 1.45; acc: 0.56
Batch: 320; loss: 1.27; acc: 0.61
Batch: 340; loss: 1.17; acc: 0.56
Batch: 360; loss: 1.08; acc: 0.64
Batch: 380; loss: 1.03; acc: 0.72
Batch: 400; loss: 1.08; acc: 0.66
Batch: 420; loss: 1.0; acc: 0.72
Batch: 440; loss: 1.15; acc: 0.56
Batch: 460; loss: 1.19; acc: 0.61
Batch: 480; loss: 1.11; acc: 0.64
Batch: 500; loss: 1.18; acc: 0.59
Batch: 520; loss: 1.07; acc: 0.69
Batch: 540; loss: 1.14; acc: 0.56
Batch: 560; loss: 1.05; acc: 0.73
Batch: 580; loss: 1.16; acc: 0.56
Batch: 600; loss: 1.35; acc: 0.53
Batch: 620; loss: 1.34; acc: 0.56
Batch: 640; loss: 1.04; acc: 0.66
Batch: 660; loss: 1.24; acc: 0.52
Batch: 680; loss: 1.11; acc: 0.61
Batch: 700; loss: 0.92; acc: 0.77
Batch: 720; loss: 1.29; acc: 0.58
Batch: 740; loss: 1.4; acc: 0.53
Batch: 760; loss: 1.26; acc: 0.58
Batch: 780; loss: 0.95; acc: 0.67
Train Epoch over. train_loss: 1.19; train_accuracy: 0.6 

2.902983942476567e-05
1.7606223991606385e-05
Batch: 0; loss: 1.39; acc: 0.59
Batch: 20; loss: 1.24; acc: 0.58
Batch: 40; loss: 0.88; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 0.87; acc: 0.78
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.45; acc: 0.55
Batch: 140; loss: 0.76; acc: 0.73
Val Epoch over. val_loss: 1.132367021338955; val_accuracy: 0.6242038216560509 

The current subspace-distance is: 1.7606223991606385e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.04; acc: 0.64
Batch: 20; loss: 1.23; acc: 0.53
Batch: 40; loss: 1.09; acc: 0.7
Batch: 60; loss: 1.08; acc: 0.67
Batch: 80; loss: 1.16; acc: 0.61
Batch: 100; loss: 1.13; acc: 0.64
Batch: 120; loss: 1.11; acc: 0.66
Batch: 140; loss: 1.06; acc: 0.62
Batch: 160; loss: 1.37; acc: 0.56
Batch: 180; loss: 1.14; acc: 0.59
Batch: 200; loss: 1.09; acc: 0.64
Batch: 220; loss: 1.26; acc: 0.56
Batch: 240; loss: 1.37; acc: 0.53
Batch: 260; loss: 1.24; acc: 0.55
Batch: 280; loss: 1.24; acc: 0.66
Batch: 300; loss: 1.12; acc: 0.64
Batch: 320; loss: 1.19; acc: 0.58
Batch: 340; loss: 1.32; acc: 0.59
Batch: 360; loss: 0.82; acc: 0.73
Batch: 380; loss: 1.49; acc: 0.62
Batch: 400; loss: 1.15; acc: 0.61
Batch: 420; loss: 0.98; acc: 0.7
Batch: 440; loss: 1.08; acc: 0.62
Batch: 460; loss: 1.29; acc: 0.56
Batch: 480; loss: 1.29; acc: 0.55
Batch: 500; loss: 1.19; acc: 0.64
Batch: 520; loss: 1.21; acc: 0.62
Batch: 540; loss: 1.08; acc: 0.64
Batch: 560; loss: 1.22; acc: 0.59
Batch: 580; loss: 0.9; acc: 0.75
Batch: 600; loss: 1.02; acc: 0.7
Batch: 620; loss: 1.28; acc: 0.52
Batch: 640; loss: 0.98; acc: 0.67
Batch: 660; loss: 1.07; acc: 0.59
Batch: 680; loss: 1.21; acc: 0.58
Batch: 700; loss: 1.21; acc: 0.59
Batch: 720; loss: 1.14; acc: 0.69
Batch: 740; loss: 0.94; acc: 0.67
Batch: 760; loss: 1.17; acc: 0.62
Batch: 780; loss: 1.43; acc: 0.53
Train Epoch over. train_loss: 1.18; train_accuracy: 0.6 

2.9367816750891507e-05
1.768514994182624e-05
Batch: 0; loss: 1.37; acc: 0.61
Batch: 20; loss: 1.24; acc: 0.59
Batch: 40; loss: 0.87; acc: 0.72
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 0.87; acc: 0.78
Batch: 100; loss: 1.35; acc: 0.55
Batch: 120; loss: 1.44; acc: 0.55
Batch: 140; loss: 0.76; acc: 0.73
Val Epoch over. val_loss: 1.1294924886363327; val_accuracy: 0.6249004777070064 

The current subspace-distance is: 1.768514994182624e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.36; acc: 0.56
Batch: 20; loss: 0.86; acc: 0.73
Batch: 40; loss: 1.18; acc: 0.56
Batch: 60; loss: 1.18; acc: 0.66
Batch: 80; loss: 1.02; acc: 0.66
Batch: 100; loss: 1.38; acc: 0.59
Batch: 120; loss: 1.36; acc: 0.5
Batch: 140; loss: 1.27; acc: 0.55
Batch: 160; loss: 1.29; acc: 0.55
Batch: 180; loss: 0.93; acc: 0.64
Batch: 200; loss: 1.1; acc: 0.61
Batch: 220; loss: 1.3; acc: 0.61
Batch: 240; loss: 1.06; acc: 0.67
Batch: 260; loss: 1.16; acc: 0.62
Batch: 280; loss: 1.12; acc: 0.59
Batch: 300; loss: 1.18; acc: 0.62
Batch: 320; loss: 1.05; acc: 0.73
Batch: 340; loss: 1.14; acc: 0.61
Batch: 360; loss: 1.19; acc: 0.59
Batch: 380; loss: 1.04; acc: 0.58
Batch: 400; loss: 1.22; acc: 0.61
Batch: 420; loss: 0.99; acc: 0.66
Batch: 440; loss: 1.24; acc: 0.62
Batch: 460; loss: 1.1; acc: 0.59
Batch: 480; loss: 1.11; acc: 0.64
Batch: 500; loss: 1.13; acc: 0.61
Batch: 520; loss: 1.02; acc: 0.69
Batch: 540; loss: 1.11; acc: 0.64
Batch: 560; loss: 1.12; acc: 0.58
Batch: 580; loss: 1.31; acc: 0.53
Batch: 600; loss: 1.17; acc: 0.67
Batch: 620; loss: 1.1; acc: 0.61
Batch: 640; loss: 1.24; acc: 0.55
Batch: 660; loss: 1.28; acc: 0.58
Batch: 680; loss: 1.25; acc: 0.58
Batch: 700; loss: 1.17; acc: 0.59
Batch: 720; loss: 1.12; acc: 0.64
Batch: 740; loss: 1.31; acc: 0.55
Batch: 760; loss: 1.42; acc: 0.59
Batch: 780; loss: 1.08; acc: 0.61
Train Epoch over. train_loss: 1.18; train_accuracy: 0.61 

2.9628670745296404e-05
1.7141413991339505e-05
Batch: 0; loss: 1.37; acc: 0.58
Batch: 20; loss: 1.25; acc: 0.58
Batch: 40; loss: 0.86; acc: 0.72
Batch: 60; loss: 1.12; acc: 0.62
Batch: 80; loss: 0.88; acc: 0.78
Batch: 100; loss: 1.34; acc: 0.58
Batch: 120; loss: 1.44; acc: 0.52
Batch: 140; loss: 0.75; acc: 0.75
Val Epoch over. val_loss: 1.1283744387565904; val_accuracy: 0.6261942675159236 

The current subspace-distance is: 1.7141413991339505e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 1.08; acc: 0.58
Batch: 60; loss: 1.09; acc: 0.61
Batch: 80; loss: 1.24; acc: 0.62
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 0.94; acc: 0.66
Batch: 140; loss: 1.47; acc: 0.56
Batch: 160; loss: 1.38; acc: 0.58
Batch: 180; loss: 1.34; acc: 0.59
Batch: 200; loss: 1.2; acc: 0.66
Batch: 220; loss: 1.27; acc: 0.58
Batch: 240; loss: 1.04; acc: 0.59
Batch: 260; loss: 1.17; acc: 0.55
Batch: 280; loss: 0.97; acc: 0.64
Batch: 300; loss: 1.06; acc: 0.69
Batch: 320; loss: 1.18; acc: 0.59
Batch: 340; loss: 1.03; acc: 0.64
Batch: 360; loss: 0.87; acc: 0.75
Batch: 380; loss: 1.2; acc: 0.58
Batch: 400; loss: 1.25; acc: 0.56
Batch: 420; loss: 1.0; acc: 0.64
Batch: 440; loss: 1.41; acc: 0.53
Batch: 460; loss: 1.24; acc: 0.62
Batch: 480; loss: 0.93; acc: 0.69
Batch: 500; loss: 1.0; acc: 0.67
Batch: 520; loss: 1.19; acc: 0.62
Batch: 540; loss: 1.31; acc: 0.56
Batch: 560; loss: 1.4; acc: 0.53
Batch: 580; loss: 1.06; acc: 0.67
Batch: 600; loss: 0.9; acc: 0.7
Batch: 620; loss: 1.26; acc: 0.56
Batch: 640; loss: 1.25; acc: 0.64
Batch: 660; loss: 1.09; acc: 0.64
Batch: 680; loss: 1.21; acc: 0.58
Batch: 700; loss: 1.07; acc: 0.62
Batch: 720; loss: 0.84; acc: 0.75
Batch: 740; loss: 1.09; acc: 0.52
Batch: 760; loss: 1.03; acc: 0.66
Batch: 780; loss: 1.37; acc: 0.66
Train Epoch over. train_loss: 1.18; train_accuracy: 0.61 

2.7749863875214942e-05
1.7031477909768e-05
Batch: 0; loss: 1.36; acc: 0.58
Batch: 20; loss: 1.25; acc: 0.58
Batch: 40; loss: 0.86; acc: 0.72
Batch: 60; loss: 1.12; acc: 0.62
Batch: 80; loss: 0.87; acc: 0.77
Batch: 100; loss: 1.34; acc: 0.55
Batch: 120; loss: 1.44; acc: 0.52
Batch: 140; loss: 0.75; acc: 0.73
Val Epoch over. val_loss: 1.1284804017680465; val_accuracy: 0.6257961783439491 

The current subspace-distance is: 1.7031477909768e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.06; acc: 0.62
Batch: 20; loss: 1.19; acc: 0.67
Batch: 40; loss: 1.12; acc: 0.61
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.02; acc: 0.64
Batch: 100; loss: 1.22; acc: 0.62
Batch: 120; loss: 1.26; acc: 0.55
Batch: 140; loss: 0.99; acc: 0.67
Batch: 160; loss: 1.1; acc: 0.64
Batch: 180; loss: 1.1; acc: 0.64
Batch: 200; loss: 1.4; acc: 0.53
Batch: 220; loss: 1.19; acc: 0.62
Batch: 240; loss: 1.29; acc: 0.58
Batch: 260; loss: 1.01; acc: 0.66
Batch: 280; loss: 1.02; acc: 0.64
Batch: 300; loss: 0.99; acc: 0.7
Batch: 320; loss: 0.99; acc: 0.67
Batch: 340; loss: 1.05; acc: 0.64
Batch: 360; loss: 1.32; acc: 0.52
Batch: 380; loss: 1.36; acc: 0.59
Batch: 400; loss: 1.11; acc: 0.64
Batch: 420; loss: 1.38; acc: 0.47
Batch: 440; loss: 1.0; acc: 0.66
Batch: 460; loss: 0.91; acc: 0.67
Batch: 480; loss: 1.04; acc: 0.62
Batch: 500; loss: 1.37; acc: 0.56
Batch: 520; loss: 1.32; acc: 0.55
Batch: 540; loss: 1.25; acc: 0.59
Batch: 560; loss: 1.41; acc: 0.52
Batch: 580; loss: 1.23; acc: 0.56
Batch: 600; loss: 1.09; acc: 0.64
Batch: 620; loss: 1.08; acc: 0.67
Batch: 640; loss: 1.09; acc: 0.61
Batch: 660; loss: 1.29; acc: 0.59
Batch: 680; loss: 1.23; acc: 0.58
Batch: 700; loss: 1.28; acc: 0.62
Batch: 720; loss: 1.07; acc: 0.61
Batch: 740; loss: 1.18; acc: 0.62
Batch: 760; loss: 1.08; acc: 0.64
Batch: 780; loss: 0.9; acc: 0.67
Train Epoch over. train_loss: 1.18; train_accuracy: 0.61 

2.741579919529613e-05
1.90699465747457e-05
Batch: 0; loss: 1.36; acc: 0.58
Batch: 20; loss: 1.25; acc: 0.58
Batch: 40; loss: 0.85; acc: 0.72
Batch: 60; loss: 1.12; acc: 0.62
Batch: 80; loss: 0.88; acc: 0.8
Batch: 100; loss: 1.33; acc: 0.55
Batch: 120; loss: 1.43; acc: 0.52
Batch: 140; loss: 0.75; acc: 0.73
Val Epoch over. val_loss: 1.1273207227895214; val_accuracy: 0.6269904458598726 

The current subspace-distance is: 1.90699465747457e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.01; acc: 0.67
Batch: 40; loss: 1.08; acc: 0.66
Batch: 60; loss: 0.99; acc: 0.69
Batch: 80; loss: 1.28; acc: 0.61
Batch: 100; loss: 1.01; acc: 0.64
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 1.25; acc: 0.61
Batch: 160; loss: 1.35; acc: 0.55
Batch: 180; loss: 1.38; acc: 0.5
Batch: 200; loss: 0.98; acc: 0.69
Batch: 220; loss: 1.45; acc: 0.53
Batch: 240; loss: 1.05; acc: 0.64
Batch: 260; loss: 1.27; acc: 0.56
Batch: 280; loss: 1.1; acc: 0.62
Batch: 300; loss: 1.28; acc: 0.64
Batch: 320; loss: 1.03; acc: 0.69
Batch: 340; loss: 1.16; acc: 0.59
Batch: 360; loss: 1.56; acc: 0.42
Batch: 380; loss: 0.92; acc: 0.75
Batch: 400; loss: 1.4; acc: 0.5
Batch: 420; loss: 0.94; acc: 0.77
Batch: 440; loss: 1.25; acc: 0.53
Batch: 460; loss: 1.22; acc: 0.53
Batch: 480; loss: 1.2; acc: 0.59
Batch: 500; loss: 1.2; acc: 0.53
Batch: 520; loss: 1.15; acc: 0.61
Batch: 540; loss: 1.15; acc: 0.72
Batch: 560; loss: 1.21; acc: 0.62
Batch: 580; loss: 1.19; acc: 0.55
Batch: 600; loss: 1.2; acc: 0.67
Batch: 620; loss: 1.37; acc: 0.52
Batch: 640; loss: 1.21; acc: 0.66
Batch: 660; loss: 1.23; acc: 0.62
Batch: 680; loss: 1.1; acc: 0.62
Batch: 700; loss: 1.09; acc: 0.58
Batch: 720; loss: 1.11; acc: 0.62
Batch: 740; loss: 1.19; acc: 0.59
Batch: 760; loss: 1.24; acc: 0.69
Batch: 780; loss: 0.93; acc: 0.67
Train Epoch over. train_loss: 1.18; train_accuracy: 0.61 

3.0093835448496975e-05
1.9479377442621626e-05
Batch: 0; loss: 1.36; acc: 0.56
Batch: 20; loss: 1.26; acc: 0.56
Batch: 40; loss: 0.85; acc: 0.75
Batch: 60; loss: 1.12; acc: 0.62
Batch: 80; loss: 0.88; acc: 0.75
Batch: 100; loss: 1.32; acc: 0.56
Batch: 120; loss: 1.43; acc: 0.52
Batch: 140; loss: 0.75; acc: 0.77
Val Epoch over. val_loss: 1.1266149981006695; val_accuracy: 0.6264928343949044 

The current subspace-distance is: 1.9479377442621626e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.26; acc: 0.58
Batch: 20; loss: 1.05; acc: 0.66
Batch: 40; loss: 1.47; acc: 0.42
Batch: 60; loss: 1.21; acc: 0.55
Batch: 80; loss: 1.26; acc: 0.5
Batch: 100; loss: 1.23; acc: 0.61
Batch: 120; loss: 1.29; acc: 0.58
Batch: 140; loss: 1.23; acc: 0.62
Batch: 160; loss: 0.97; acc: 0.62
Batch: 180; loss: 0.95; acc: 0.66
Batch: 200; loss: 1.24; acc: 0.58
Batch: 220; loss: 1.16; acc: 0.59
Batch: 240; loss: 1.32; acc: 0.55
Batch: 260; loss: 1.08; acc: 0.67
Batch: 280; loss: 1.34; acc: 0.56
Batch: 300; loss: 1.33; acc: 0.61
Batch: 320; loss: 1.27; acc: 0.59
Batch: 340; loss: 1.16; acc: 0.56
Batch: 360; loss: 1.28; acc: 0.58
Batch: 380; loss: 1.12; acc: 0.59
Batch: 400; loss: 1.44; acc: 0.47
Batch: 420; loss: 1.37; acc: 0.52
Batch: 440; loss: 1.28; acc: 0.64
Batch: 460; loss: 1.12; acc: 0.56
Batch: 480; loss: 1.21; acc: 0.62
Batch: 500; loss: 1.35; acc: 0.53
Batch: 520; loss: 1.03; acc: 0.56
Batch: 540; loss: 1.03; acc: 0.73
Batch: 560; loss: 0.97; acc: 0.59
Batch: 580; loss: 1.33; acc: 0.58
Batch: 600; loss: 1.02; acc: 0.7
Batch: 620; loss: 0.96; acc: 0.69
Batch: 640; loss: 1.25; acc: 0.58
Batch: 660; loss: 1.33; acc: 0.55
Batch: 680; loss: 1.31; acc: 0.61
Batch: 700; loss: 1.24; acc: 0.55
Batch: 720; loss: 1.18; acc: 0.62
Batch: 740; loss: 1.09; acc: 0.66
Batch: 760; loss: 1.11; acc: 0.64
Batch: 780; loss: 1.18; acc: 0.62
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.985486207762733e-05
1.697705920378212e-05
Batch: 0; loss: 1.35; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.58
Batch: 40; loss: 0.84; acc: 0.77
Batch: 60; loss: 1.12; acc: 0.62
Batch: 80; loss: 0.89; acc: 0.77
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.43; acc: 0.5
Batch: 140; loss: 0.74; acc: 0.77
Val Epoch over. val_loss: 1.125722308827054; val_accuracy: 0.6269904458598726 

The current subspace-distance is: 1.697705920378212e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.46; acc: 0.52
Batch: 20; loss: 1.53; acc: 0.52
Batch: 40; loss: 1.07; acc: 0.53
Batch: 60; loss: 1.23; acc: 0.59
Batch: 80; loss: 1.11; acc: 0.61
Batch: 100; loss: 1.09; acc: 0.61
Batch: 120; loss: 1.13; acc: 0.66
Batch: 140; loss: 1.41; acc: 0.5
Batch: 160; loss: 1.4; acc: 0.48
Batch: 180; loss: 0.83; acc: 0.7
Batch: 200; loss: 1.19; acc: 0.55
Batch: 220; loss: 1.17; acc: 0.62
Batch: 240; loss: 1.28; acc: 0.5
Batch: 260; loss: 1.2; acc: 0.56
Batch: 280; loss: 1.4; acc: 0.5
Batch: 300; loss: 1.21; acc: 0.58
Batch: 320; loss: 1.03; acc: 0.67
Batch: 340; loss: 1.49; acc: 0.47
Batch: 360; loss: 1.22; acc: 0.58
Batch: 380; loss: 1.1; acc: 0.62
Batch: 400; loss: 1.19; acc: 0.66
Batch: 420; loss: 1.26; acc: 0.59
Batch: 440; loss: 1.2; acc: 0.53
Batch: 460; loss: 1.2; acc: 0.66
Batch: 480; loss: 1.23; acc: 0.61
Batch: 500; loss: 1.12; acc: 0.58
Batch: 520; loss: 1.25; acc: 0.55
Batch: 540; loss: 1.37; acc: 0.52
Batch: 560; loss: 1.15; acc: 0.64
Batch: 580; loss: 1.45; acc: 0.5
Batch: 600; loss: 1.21; acc: 0.61
Batch: 620; loss: 1.09; acc: 0.66
Batch: 640; loss: 1.1; acc: 0.62
Batch: 660; loss: 1.19; acc: 0.61
Batch: 680; loss: 1.09; acc: 0.66
Batch: 700; loss: 1.24; acc: 0.62
Batch: 720; loss: 1.25; acc: 0.58
Batch: 740; loss: 0.95; acc: 0.64
Batch: 760; loss: 1.38; acc: 0.52
Batch: 780; loss: 0.99; acc: 0.69
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.95162208203692e-05
1.7136831957031973e-05
Batch: 0; loss: 1.36; acc: 0.56
Batch: 20; loss: 1.26; acc: 0.58
Batch: 40; loss: 0.84; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.62
Batch: 80; loss: 0.9; acc: 0.75
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.43; acc: 0.5
Batch: 140; loss: 0.74; acc: 0.78
Val Epoch over. val_loss: 1.1243173741990593; val_accuracy: 0.626890923566879 

The current subspace-distance is: 1.7136831957031973e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.93; acc: 0.7
Batch: 20; loss: 1.04; acc: 0.69
Batch: 40; loss: 1.31; acc: 0.61
Batch: 60; loss: 1.37; acc: 0.58
Batch: 80; loss: 1.17; acc: 0.61
Batch: 100; loss: 1.17; acc: 0.55
Batch: 120; loss: 1.51; acc: 0.5
Batch: 140; loss: 1.01; acc: 0.64
Batch: 160; loss: 1.09; acc: 0.67
Batch: 180; loss: 1.18; acc: 0.58
Batch: 200; loss: 1.29; acc: 0.55
Batch: 220; loss: 1.15; acc: 0.59
Batch: 240; loss: 1.05; acc: 0.62
Batch: 260; loss: 1.36; acc: 0.62
Batch: 280; loss: 1.11; acc: 0.69
Batch: 300; loss: 0.94; acc: 0.7
Batch: 320; loss: 1.0; acc: 0.7
Batch: 340; loss: 1.2; acc: 0.64
Batch: 360; loss: 1.11; acc: 0.66
Batch: 380; loss: 1.07; acc: 0.69
Batch: 400; loss: 1.36; acc: 0.62
Batch: 420; loss: 1.18; acc: 0.58
Batch: 440; loss: 1.32; acc: 0.59
Batch: 460; loss: 0.95; acc: 0.7
Batch: 480; loss: 0.96; acc: 0.64
Batch: 500; loss: 1.29; acc: 0.53
Batch: 520; loss: 1.29; acc: 0.64
Batch: 540; loss: 1.13; acc: 0.58
Batch: 560; loss: 1.37; acc: 0.45
Batch: 580; loss: 1.13; acc: 0.55
Batch: 600; loss: 1.3; acc: 0.58
Batch: 620; loss: 1.19; acc: 0.59
Batch: 640; loss: 1.17; acc: 0.62
Batch: 660; loss: 1.16; acc: 0.59
Batch: 680; loss: 1.36; acc: 0.58
Batch: 700; loss: 1.29; acc: 0.56
Batch: 720; loss: 1.32; acc: 0.55
Batch: 740; loss: 1.11; acc: 0.62
Batch: 760; loss: 1.25; acc: 0.53
Batch: 780; loss: 1.32; acc: 0.5
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9975832148920745e-05
1.8992353943758644e-05
Batch: 0; loss: 1.35; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.82; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.61
Batch: 80; loss: 0.9; acc: 0.75
Batch: 100; loss: 1.32; acc: 0.58
Batch: 120; loss: 1.44; acc: 0.52
Batch: 140; loss: 0.75; acc: 0.78
Val Epoch over. val_loss: 1.125299954490297; val_accuracy: 0.6222133757961783 

The current subspace-distance is: 1.8992353943758644e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.08; acc: 0.69
Batch: 20; loss: 1.07; acc: 0.59
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.26; acc: 0.56
Batch: 80; loss: 1.18; acc: 0.62
Batch: 100; loss: 1.21; acc: 0.64
Batch: 120; loss: 1.33; acc: 0.55
Batch: 140; loss: 0.89; acc: 0.67
Batch: 160; loss: 1.42; acc: 0.47
Batch: 180; loss: 0.98; acc: 0.67
Batch: 200; loss: 0.96; acc: 0.64
Batch: 220; loss: 1.15; acc: 0.59
Batch: 240; loss: 1.13; acc: 0.59
Batch: 260; loss: 1.27; acc: 0.53
Batch: 280; loss: 1.17; acc: 0.62
Batch: 300; loss: 1.05; acc: 0.62
Batch: 320; loss: 1.27; acc: 0.55
Batch: 340; loss: 1.34; acc: 0.55
Batch: 360; loss: 1.02; acc: 0.69
Batch: 380; loss: 1.02; acc: 0.69
Batch: 400; loss: 1.18; acc: 0.62
Batch: 420; loss: 1.22; acc: 0.64
Batch: 440; loss: 0.97; acc: 0.69
Batch: 460; loss: 1.31; acc: 0.58
Batch: 480; loss: 1.14; acc: 0.62
Batch: 500; loss: 1.25; acc: 0.59
Batch: 520; loss: 1.29; acc: 0.53
Batch: 540; loss: 1.08; acc: 0.66
Batch: 560; loss: 1.37; acc: 0.5
Batch: 580; loss: 1.44; acc: 0.53
Batch: 600; loss: 1.05; acc: 0.58
Batch: 620; loss: 1.25; acc: 0.64
Batch: 640; loss: 1.09; acc: 0.62
Batch: 660; loss: 1.0; acc: 0.66
Batch: 680; loss: 1.16; acc: 0.64
Batch: 700; loss: 1.05; acc: 0.67
Batch: 720; loss: 1.28; acc: 0.59
Batch: 740; loss: 1.32; acc: 0.59
Batch: 760; loss: 1.13; acc: 0.58
Batch: 780; loss: 1.18; acc: 0.64
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8651236789301038e-05
1.703918860584963e-05
Batch: 0; loss: 1.35; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.83; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.62
Batch: 80; loss: 0.91; acc: 0.73
Batch: 100; loss: 1.3; acc: 0.58
Batch: 120; loss: 1.42; acc: 0.53
Batch: 140; loss: 0.75; acc: 0.78
Val Epoch over. val_loss: 1.1242886827250196; val_accuracy: 0.623109076433121 

The current subspace-distance is: 1.703918860584963e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.48; acc: 0.48
Batch: 20; loss: 0.99; acc: 0.7
Batch: 40; loss: 1.18; acc: 0.66
Batch: 60; loss: 1.25; acc: 0.59
Batch: 80; loss: 1.2; acc: 0.61
Batch: 100; loss: 1.16; acc: 0.64
Batch: 120; loss: 1.23; acc: 0.62
Batch: 140; loss: 0.95; acc: 0.64
Batch: 160; loss: 1.17; acc: 0.62
Batch: 180; loss: 1.59; acc: 0.5
Batch: 200; loss: 1.01; acc: 0.67
Batch: 220; loss: 1.34; acc: 0.45
Batch: 240; loss: 1.12; acc: 0.61
Batch: 260; loss: 1.22; acc: 0.58
Batch: 280; loss: 1.41; acc: 0.58
Batch: 300; loss: 1.08; acc: 0.61
Batch: 320; loss: 1.16; acc: 0.56
Batch: 340; loss: 1.15; acc: 0.55
Batch: 360; loss: 1.43; acc: 0.52
Batch: 380; loss: 0.93; acc: 0.7
Batch: 400; loss: 1.36; acc: 0.52
Batch: 420; loss: 1.2; acc: 0.56
Batch: 440; loss: 1.14; acc: 0.58
Batch: 460; loss: 1.09; acc: 0.67
Batch: 480; loss: 1.28; acc: 0.64
Batch: 500; loss: 1.14; acc: 0.62
Batch: 520; loss: 1.36; acc: 0.59
Batch: 540; loss: 1.17; acc: 0.64
Batch: 560; loss: 1.18; acc: 0.62
Batch: 580; loss: 1.1; acc: 0.67
Batch: 600; loss: 1.22; acc: 0.59
Batch: 620; loss: 0.93; acc: 0.59
Batch: 640; loss: 1.03; acc: 0.67
Batch: 660; loss: 0.8; acc: 0.75
Batch: 680; loss: 1.37; acc: 0.59
Batch: 700; loss: 1.33; acc: 0.48
Batch: 720; loss: 1.19; acc: 0.48
Batch: 740; loss: 1.21; acc: 0.58
Batch: 760; loss: 1.19; acc: 0.61
Batch: 780; loss: 1.27; acc: 0.58
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

3.010736509168055e-05
2.0200990547891706e-05
Batch: 0; loss: 1.35; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.82; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.62
Batch: 80; loss: 0.91; acc: 0.77
Batch: 100; loss: 1.29; acc: 0.58
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.74; acc: 0.8
Val Epoch over. val_loss: 1.123711067400161; val_accuracy: 0.6259952229299363 

The current subspace-distance is: 2.0200990547891706e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.28; acc: 0.55
Batch: 20; loss: 1.29; acc: 0.53
Batch: 40; loss: 1.24; acc: 0.56
Batch: 60; loss: 1.24; acc: 0.64
Batch: 80; loss: 1.28; acc: 0.61
Batch: 100; loss: 0.99; acc: 0.7
Batch: 120; loss: 1.14; acc: 0.59
Batch: 140; loss: 1.32; acc: 0.55
Batch: 160; loss: 1.2; acc: 0.56
Batch: 180; loss: 1.1; acc: 0.58
Batch: 200; loss: 1.03; acc: 0.64
Batch: 220; loss: 1.08; acc: 0.62
Batch: 240; loss: 1.31; acc: 0.61
Batch: 260; loss: 0.9; acc: 0.66
Batch: 280; loss: 1.47; acc: 0.48
Batch: 300; loss: 1.18; acc: 0.59
Batch: 320; loss: 0.9; acc: 0.7
Batch: 340; loss: 1.39; acc: 0.55
Batch: 360; loss: 0.9; acc: 0.69
Batch: 380; loss: 1.49; acc: 0.52
Batch: 400; loss: 1.17; acc: 0.64
Batch: 420; loss: 1.26; acc: 0.58
Batch: 440; loss: 1.29; acc: 0.67
Batch: 460; loss: 1.03; acc: 0.64
Batch: 480; loss: 1.16; acc: 0.67
Batch: 500; loss: 1.13; acc: 0.61
Batch: 520; loss: 1.0; acc: 0.69
Batch: 540; loss: 1.4; acc: 0.55
Batch: 560; loss: 1.31; acc: 0.53
Batch: 580; loss: 1.32; acc: 0.62
Batch: 600; loss: 1.17; acc: 0.62
Batch: 620; loss: 1.07; acc: 0.66
Batch: 640; loss: 1.24; acc: 0.59
Batch: 660; loss: 1.43; acc: 0.59
Batch: 680; loss: 1.18; acc: 0.67
Batch: 700; loss: 1.23; acc: 0.58
Batch: 720; loss: 1.0; acc: 0.69
Batch: 740; loss: 1.05; acc: 0.59
Batch: 760; loss: 1.02; acc: 0.66
Batch: 780; loss: 1.1; acc: 0.59
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9954606361570768e-05
1.9967374100815505e-05
Batch: 0; loss: 1.35; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.82; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.62
Batch: 80; loss: 0.91; acc: 0.73
Batch: 100; loss: 1.3; acc: 0.59
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.78
Val Epoch over. val_loss: 1.1238058194233354; val_accuracy: 0.6244028662420382 

The current subspace-distance is: 1.9967374100815505e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.42; acc: 0.53
Batch: 20; loss: 1.09; acc: 0.59
Batch: 40; loss: 0.96; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.62
Batch: 80; loss: 1.34; acc: 0.61
Batch: 100; loss: 1.04; acc: 0.7
Batch: 120; loss: 1.04; acc: 0.69
Batch: 140; loss: 1.16; acc: 0.66
Batch: 160; loss: 1.1; acc: 0.62
Batch: 180; loss: 1.05; acc: 0.62
Batch: 200; loss: 1.21; acc: 0.58
Batch: 220; loss: 0.94; acc: 0.67
Batch: 240; loss: 1.31; acc: 0.56
Batch: 260; loss: 1.19; acc: 0.62
Batch: 280; loss: 1.23; acc: 0.58
Batch: 300; loss: 1.34; acc: 0.5
Batch: 320; loss: 1.1; acc: 0.61
Batch: 340; loss: 1.12; acc: 0.61
Batch: 360; loss: 1.16; acc: 0.64
Batch: 380; loss: 1.05; acc: 0.64
Batch: 400; loss: 1.14; acc: 0.62
Batch: 420; loss: 1.25; acc: 0.55
Batch: 440; loss: 1.06; acc: 0.64
Batch: 460; loss: 0.98; acc: 0.66
Batch: 480; loss: 1.07; acc: 0.59
Batch: 500; loss: 1.22; acc: 0.52
Batch: 520; loss: 1.18; acc: 0.58
Batch: 540; loss: 1.35; acc: 0.5
Batch: 560; loss: 1.11; acc: 0.64
Batch: 580; loss: 1.31; acc: 0.56
Batch: 600; loss: 0.93; acc: 0.75
Batch: 620; loss: 1.18; acc: 0.56
Batch: 640; loss: 1.22; acc: 0.56
Batch: 660; loss: 0.94; acc: 0.7
Batch: 680; loss: 1.51; acc: 0.52
Batch: 700; loss: 1.39; acc: 0.5
Batch: 720; loss: 1.01; acc: 0.69
Batch: 740; loss: 1.16; acc: 0.67
Batch: 760; loss: 1.48; acc: 0.52
Batch: 780; loss: 1.3; acc: 0.64
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.757893525995314e-05
2.02229439310031e-05
Batch: 0; loss: 1.36; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.82; acc: 0.73
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.91; acc: 0.75
Batch: 100; loss: 1.3; acc: 0.61
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.78
Val Epoch over. val_loss: 1.1235610026462821; val_accuracy: 0.6254976114649682 

The current subspace-distance is: 2.02229439310031e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.98; acc: 0.66
Batch: 20; loss: 1.28; acc: 0.53
Batch: 40; loss: 1.34; acc: 0.52
Batch: 60; loss: 1.31; acc: 0.53
Batch: 80; loss: 1.23; acc: 0.61
Batch: 100; loss: 1.02; acc: 0.67
Batch: 120; loss: 1.18; acc: 0.5
Batch: 140; loss: 1.27; acc: 0.62
Batch: 160; loss: 0.86; acc: 0.67
Batch: 180; loss: 1.42; acc: 0.5
Batch: 200; loss: 1.17; acc: 0.66
Batch: 220; loss: 0.97; acc: 0.64
Batch: 240; loss: 1.38; acc: 0.56
Batch: 260; loss: 1.29; acc: 0.52
Batch: 280; loss: 1.31; acc: 0.55
Batch: 300; loss: 1.13; acc: 0.61
Batch: 320; loss: 1.07; acc: 0.66
Batch: 340; loss: 1.02; acc: 0.66
Batch: 360; loss: 1.21; acc: 0.59
Batch: 380; loss: 1.1; acc: 0.64
Batch: 400; loss: 1.44; acc: 0.53
Batch: 420; loss: 1.1; acc: 0.64
Batch: 440; loss: 1.59; acc: 0.42
Batch: 460; loss: 0.78; acc: 0.75
Batch: 480; loss: 1.09; acc: 0.64
Batch: 500; loss: 1.38; acc: 0.58
Batch: 520; loss: 1.06; acc: 0.66
Batch: 540; loss: 1.06; acc: 0.61
Batch: 560; loss: 1.23; acc: 0.59
Batch: 580; loss: 1.15; acc: 0.53
Batch: 600; loss: 1.31; acc: 0.55
Batch: 620; loss: 1.22; acc: 0.61
Batch: 640; loss: 1.03; acc: 0.61
Batch: 660; loss: 1.14; acc: 0.55
Batch: 680; loss: 1.0; acc: 0.72
Batch: 700; loss: 1.09; acc: 0.58
Batch: 720; loss: 1.38; acc: 0.62
Batch: 740; loss: 1.07; acc: 0.67
Batch: 760; loss: 1.22; acc: 0.58
Batch: 780; loss: 1.08; acc: 0.66
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9362779969233088e-05
1.8381235349806957e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.3; acc: 0.59
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.74; acc: 0.8
Val Epoch over. val_loss: 1.123125654117317; val_accuracy: 0.6244028662420382 

The current subspace-distance is: 1.8381235349806957e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.23; acc: 0.56
Batch: 20; loss: 1.21; acc: 0.56
Batch: 40; loss: 1.19; acc: 0.62
Batch: 60; loss: 1.22; acc: 0.62
Batch: 80; loss: 0.89; acc: 0.7
Batch: 100; loss: 1.13; acc: 0.64
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 1.06; acc: 0.7
Batch: 160; loss: 1.16; acc: 0.64
Batch: 180; loss: 1.33; acc: 0.56
Batch: 200; loss: 1.07; acc: 0.61
Batch: 220; loss: 1.13; acc: 0.67
Batch: 240; loss: 1.15; acc: 0.59
Batch: 260; loss: 1.13; acc: 0.64
Batch: 280; loss: 1.16; acc: 0.61
Batch: 300; loss: 0.97; acc: 0.62
Batch: 320; loss: 1.01; acc: 0.66
Batch: 340; loss: 1.12; acc: 0.59
Batch: 360; loss: 1.24; acc: 0.59
Batch: 380; loss: 1.3; acc: 0.66
Batch: 400; loss: 1.1; acc: 0.62
Batch: 420; loss: 1.14; acc: 0.62
Batch: 440; loss: 0.91; acc: 0.69
Batch: 460; loss: 1.17; acc: 0.61
Batch: 480; loss: 1.42; acc: 0.56
Batch: 500; loss: 1.17; acc: 0.56
Batch: 520; loss: 0.97; acc: 0.69
Batch: 540; loss: 1.17; acc: 0.59
Batch: 560; loss: 1.04; acc: 0.69
Batch: 580; loss: 1.12; acc: 0.62
Batch: 600; loss: 1.45; acc: 0.5
Batch: 620; loss: 1.35; acc: 0.55
Batch: 640; loss: 1.37; acc: 0.52
Batch: 660; loss: 1.32; acc: 0.55
Batch: 680; loss: 1.27; acc: 0.58
Batch: 700; loss: 1.02; acc: 0.66
Batch: 720; loss: 1.22; acc: 0.58
Batch: 740; loss: 0.85; acc: 0.75
Batch: 760; loss: 1.18; acc: 0.64
Batch: 780; loss: 1.24; acc: 0.59
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9678862119908445e-05
2.0074778149137273e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.73
Batch: 100; loss: 1.29; acc: 0.61
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.8
Val Epoch over. val_loss: 1.1232892536813286; val_accuracy: 0.6247014331210191 

The current subspace-distance is: 2.0074778149137273e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.41; acc: 0.53
Batch: 20; loss: 0.94; acc: 0.64
Batch: 40; loss: 1.41; acc: 0.55
Batch: 60; loss: 1.14; acc: 0.64
Batch: 80; loss: 0.96; acc: 0.66
Batch: 100; loss: 1.34; acc: 0.58
Batch: 120; loss: 1.26; acc: 0.58
Batch: 140; loss: 1.39; acc: 0.56
Batch: 160; loss: 0.96; acc: 0.69
Batch: 180; loss: 1.17; acc: 0.62
Batch: 200; loss: 1.2; acc: 0.61
Batch: 220; loss: 0.97; acc: 0.62
Batch: 240; loss: 1.16; acc: 0.56
Batch: 260; loss: 1.28; acc: 0.55
Batch: 280; loss: 1.16; acc: 0.62
Batch: 300; loss: 1.28; acc: 0.69
Batch: 320; loss: 1.28; acc: 0.62
Batch: 340; loss: 0.97; acc: 0.69
Batch: 360; loss: 1.16; acc: 0.64
Batch: 380; loss: 1.26; acc: 0.55
Batch: 400; loss: 1.29; acc: 0.61
Batch: 420; loss: 1.24; acc: 0.58
Batch: 440; loss: 1.03; acc: 0.61
Batch: 460; loss: 1.06; acc: 0.61
Batch: 480; loss: 1.06; acc: 0.56
Batch: 500; loss: 1.18; acc: 0.59
Batch: 520; loss: 1.21; acc: 0.59
Batch: 540; loss: 1.0; acc: 0.64
Batch: 560; loss: 1.48; acc: 0.58
Batch: 580; loss: 1.04; acc: 0.59
Batch: 600; loss: 1.09; acc: 0.64
Batch: 620; loss: 1.2; acc: 0.64
Batch: 640; loss: 1.16; acc: 0.55
Batch: 660; loss: 1.14; acc: 0.59
Batch: 680; loss: 1.21; acc: 0.55
Batch: 700; loss: 0.96; acc: 0.66
Batch: 720; loss: 1.12; acc: 0.62
Batch: 740; loss: 0.92; acc: 0.61
Batch: 760; loss: 1.42; acc: 0.56
Batch: 780; loss: 1.24; acc: 0.59
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9910010198364034e-05
1.851388151408173e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.73
Batch: 100; loss: 1.29; acc: 0.62
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.78
Val Epoch over. val_loss: 1.1230891483604528; val_accuracy: 0.6247014331210191 

The current subspace-distance is: 1.851388151408173e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.31; acc: 0.55
Batch: 20; loss: 1.36; acc: 0.53
Batch: 40; loss: 1.16; acc: 0.61
Batch: 60; loss: 1.11; acc: 0.61
Batch: 80; loss: 1.11; acc: 0.62
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.22; acc: 0.56
Batch: 140; loss: 1.03; acc: 0.64
Batch: 160; loss: 1.14; acc: 0.55
Batch: 180; loss: 1.15; acc: 0.62
Batch: 200; loss: 1.26; acc: 0.55
Batch: 220; loss: 1.27; acc: 0.59
Batch: 240; loss: 1.03; acc: 0.64
Batch: 260; loss: 1.51; acc: 0.45
Batch: 280; loss: 1.15; acc: 0.59
Batch: 300; loss: 1.0; acc: 0.69
Batch: 320; loss: 1.18; acc: 0.64
Batch: 340; loss: 1.14; acc: 0.61
Batch: 360; loss: 1.06; acc: 0.64
Batch: 380; loss: 1.51; acc: 0.56
Batch: 400; loss: 1.33; acc: 0.55
Batch: 420; loss: 1.22; acc: 0.53
Batch: 440; loss: 1.24; acc: 0.5
Batch: 460; loss: 1.0; acc: 0.64
Batch: 480; loss: 1.26; acc: 0.55
Batch: 500; loss: 1.07; acc: 0.64
Batch: 520; loss: 1.22; acc: 0.56
Batch: 540; loss: 1.26; acc: 0.56
Batch: 560; loss: 0.99; acc: 0.66
Batch: 580; loss: 1.13; acc: 0.7
Batch: 600; loss: 1.02; acc: 0.7
Batch: 620; loss: 0.99; acc: 0.66
Batch: 640; loss: 0.99; acc: 0.67
Batch: 660; loss: 1.07; acc: 0.67
Batch: 680; loss: 1.0; acc: 0.69
Batch: 700; loss: 1.4; acc: 0.53
Batch: 720; loss: 1.05; acc: 0.64
Batch: 740; loss: 1.22; acc: 0.64
Batch: 760; loss: 1.13; acc: 0.61
Batch: 780; loss: 1.31; acc: 0.59
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8971238862141035e-05
1.7067550288629718e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.91; acc: 0.75
Batch: 100; loss: 1.29; acc: 0.62
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.8
Val Epoch over. val_loss: 1.1231791088535528; val_accuracy: 0.6251990445859873 

The current subspace-distance is: 1.7067550288629718e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.16; acc: 0.62
Batch: 20; loss: 1.16; acc: 0.58
Batch: 40; loss: 1.26; acc: 0.61
Batch: 60; loss: 0.96; acc: 0.7
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.08; acc: 0.69
Batch: 120; loss: 1.4; acc: 0.45
Batch: 140; loss: 1.42; acc: 0.56
Batch: 160; loss: 1.38; acc: 0.59
Batch: 180; loss: 1.53; acc: 0.52
Batch: 200; loss: 1.34; acc: 0.55
Batch: 220; loss: 1.26; acc: 0.56
Batch: 240; loss: 1.21; acc: 0.61
Batch: 260; loss: 1.2; acc: 0.61
Batch: 280; loss: 1.14; acc: 0.58
Batch: 300; loss: 1.26; acc: 0.61
Batch: 320; loss: 1.06; acc: 0.61
Batch: 340; loss: 1.06; acc: 0.62
Batch: 360; loss: 1.27; acc: 0.56
Batch: 380; loss: 1.17; acc: 0.58
Batch: 400; loss: 1.15; acc: 0.62
Batch: 420; loss: 0.99; acc: 0.64
Batch: 440; loss: 1.25; acc: 0.61
Batch: 460; loss: 1.36; acc: 0.56
Batch: 480; loss: 1.19; acc: 0.64
Batch: 500; loss: 1.43; acc: 0.62
Batch: 520; loss: 1.17; acc: 0.59
Batch: 540; loss: 1.15; acc: 0.59
Batch: 560; loss: 1.17; acc: 0.66
Batch: 580; loss: 0.88; acc: 0.7
Batch: 600; loss: 1.13; acc: 0.64
Batch: 620; loss: 1.0; acc: 0.69
Batch: 640; loss: 1.23; acc: 0.67
Batch: 660; loss: 1.0; acc: 0.64
Batch: 680; loss: 0.98; acc: 0.72
Batch: 700; loss: 1.02; acc: 0.7
Batch: 720; loss: 1.12; acc: 0.69
Batch: 740; loss: 1.09; acc: 0.67
Batch: 760; loss: 0.86; acc: 0.75
Batch: 780; loss: 1.13; acc: 0.59
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9998962418176234e-05
1.7235266568604857e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.62
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1227774316338217; val_accuracy: 0.6256966560509554 

The current subspace-distance is: 1.7235266568604857e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.09; acc: 0.58
Batch: 20; loss: 1.11; acc: 0.62
Batch: 40; loss: 1.13; acc: 0.69
Batch: 60; loss: 1.25; acc: 0.58
Batch: 80; loss: 0.83; acc: 0.77
Batch: 100; loss: 1.18; acc: 0.53
Batch: 120; loss: 1.37; acc: 0.52
Batch: 140; loss: 1.29; acc: 0.64
Batch: 160; loss: 1.13; acc: 0.59
Batch: 180; loss: 1.01; acc: 0.64
Batch: 200; loss: 0.9; acc: 0.67
Batch: 220; loss: 0.84; acc: 0.77
Batch: 240; loss: 1.15; acc: 0.61
Batch: 260; loss: 1.24; acc: 0.56
Batch: 280; loss: 1.05; acc: 0.64
Batch: 300; loss: 0.96; acc: 0.7
Batch: 320; loss: 1.24; acc: 0.56
Batch: 340; loss: 1.05; acc: 0.59
Batch: 360; loss: 1.12; acc: 0.66
Batch: 380; loss: 1.41; acc: 0.55
Batch: 400; loss: 1.22; acc: 0.62
Batch: 420; loss: 1.5; acc: 0.44
Batch: 440; loss: 0.9; acc: 0.77
Batch: 460; loss: 1.11; acc: 0.61
Batch: 480; loss: 1.23; acc: 0.67
Batch: 500; loss: 1.4; acc: 0.5
Batch: 520; loss: 1.1; acc: 0.62
Batch: 540; loss: 1.3; acc: 0.55
Batch: 560; loss: 1.55; acc: 0.42
Batch: 580; loss: 1.32; acc: 0.52
Batch: 600; loss: 1.14; acc: 0.59
Batch: 620; loss: 1.02; acc: 0.67
Batch: 640; loss: 1.5; acc: 0.52
Batch: 660; loss: 1.19; acc: 0.62
Batch: 680; loss: 1.15; acc: 0.55
Batch: 700; loss: 1.22; acc: 0.62
Batch: 720; loss: 1.27; acc: 0.52
Batch: 740; loss: 1.02; acc: 0.69
Batch: 760; loss: 1.08; acc: 0.69
Batch: 780; loss: 1.31; acc: 0.58
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8529753762995824e-05
1.7678961739875376e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.74; acc: 0.83
Val Epoch over. val_loss: 1.1223811848907714; val_accuracy: 0.6255971337579618 

The current subspace-distance is: 1.7678961739875376e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.18; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.59
Batch: 40; loss: 1.23; acc: 0.56
Batch: 60; loss: 1.06; acc: 0.62
Batch: 80; loss: 0.93; acc: 0.72
Batch: 100; loss: 1.27; acc: 0.59
Batch: 120; loss: 1.06; acc: 0.69
Batch: 140; loss: 1.21; acc: 0.56
Batch: 160; loss: 1.11; acc: 0.66
Batch: 180; loss: 0.97; acc: 0.72
Batch: 200; loss: 1.23; acc: 0.62
Batch: 220; loss: 1.07; acc: 0.61
Batch: 240; loss: 1.08; acc: 0.62
Batch: 260; loss: 1.28; acc: 0.61
Batch: 280; loss: 1.44; acc: 0.56
Batch: 300; loss: 1.2; acc: 0.58
Batch: 320; loss: 1.64; acc: 0.41
Batch: 340; loss: 1.2; acc: 0.55
Batch: 360; loss: 1.22; acc: 0.56
Batch: 380; loss: 1.41; acc: 0.55
Batch: 400; loss: 1.16; acc: 0.56
Batch: 420; loss: 1.34; acc: 0.58
Batch: 440; loss: 1.16; acc: 0.59
Batch: 460; loss: 1.11; acc: 0.66
Batch: 480; loss: 1.38; acc: 0.5
Batch: 500; loss: 1.41; acc: 0.47
Batch: 520; loss: 1.38; acc: 0.56
Batch: 540; loss: 1.16; acc: 0.66
Batch: 560; loss: 1.13; acc: 0.62
Batch: 580; loss: 1.25; acc: 0.56
Batch: 600; loss: 1.27; acc: 0.59
Batch: 620; loss: 1.08; acc: 0.66
Batch: 640; loss: 1.15; acc: 0.62
Batch: 660; loss: 1.3; acc: 0.59
Batch: 680; loss: 1.01; acc: 0.7
Batch: 700; loss: 0.98; acc: 0.67
Batch: 720; loss: 1.31; acc: 0.53
Batch: 740; loss: 1.18; acc: 0.62
Batch: 760; loss: 1.22; acc: 0.61
Batch: 780; loss: 0.96; acc: 0.62
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.935962038463913e-05
1.6035013686632738e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.29; acc: 0.64
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.122560521979241; val_accuracy: 0.6246019108280255 

The current subspace-distance is: 1.6035013686632738e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.16; acc: 0.64
Batch: 20; loss: 1.24; acc: 0.59
Batch: 40; loss: 1.09; acc: 0.64
Batch: 60; loss: 1.41; acc: 0.53
Batch: 80; loss: 1.1; acc: 0.64
Batch: 100; loss: 1.42; acc: 0.48
Batch: 120; loss: 1.13; acc: 0.67
Batch: 140; loss: 0.96; acc: 0.67
Batch: 160; loss: 1.0; acc: 0.7
Batch: 180; loss: 1.19; acc: 0.66
Batch: 200; loss: 1.09; acc: 0.67
Batch: 220; loss: 1.18; acc: 0.61
Batch: 240; loss: 1.08; acc: 0.53
Batch: 260; loss: 1.02; acc: 0.7
Batch: 280; loss: 1.22; acc: 0.67
Batch: 300; loss: 1.1; acc: 0.64
Batch: 320; loss: 1.03; acc: 0.67
Batch: 340; loss: 1.09; acc: 0.67
Batch: 360; loss: 1.09; acc: 0.66
Batch: 380; loss: 1.25; acc: 0.5
Batch: 400; loss: 1.05; acc: 0.69
Batch: 420; loss: 1.37; acc: 0.52
Batch: 440; loss: 1.0; acc: 0.67
Batch: 460; loss: 1.27; acc: 0.56
Batch: 480; loss: 1.09; acc: 0.66
Batch: 500; loss: 1.1; acc: 0.62
Batch: 520; loss: 1.46; acc: 0.53
Batch: 540; loss: 1.09; acc: 0.62
Batch: 560; loss: 1.07; acc: 0.69
Batch: 580; loss: 1.03; acc: 0.72
Batch: 600; loss: 1.03; acc: 0.66
Batch: 620; loss: 1.37; acc: 0.48
Batch: 640; loss: 1.11; acc: 0.62
Batch: 660; loss: 1.21; acc: 0.52
Batch: 680; loss: 1.32; acc: 0.55
Batch: 700; loss: 1.13; acc: 0.55
Batch: 720; loss: 1.25; acc: 0.55
Batch: 740; loss: 0.8; acc: 0.72
Batch: 760; loss: 1.01; acc: 0.69
Batch: 780; loss: 1.07; acc: 0.64
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.895350735343527e-05
1.8727414499153383e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.62
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.83
Val Epoch over. val_loss: 1.1226291424909216; val_accuracy: 0.6241042993630573 

The current subspace-distance is: 1.8727414499153383e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.35; acc: 0.52
Batch: 20; loss: 1.12; acc: 0.62
Batch: 40; loss: 1.24; acc: 0.56
Batch: 60; loss: 1.2; acc: 0.61
Batch: 80; loss: 1.08; acc: 0.66
Batch: 100; loss: 1.38; acc: 0.55
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 1.09; acc: 0.59
Batch: 160; loss: 1.1; acc: 0.67
Batch: 180; loss: 1.26; acc: 0.59
Batch: 200; loss: 1.25; acc: 0.56
Batch: 220; loss: 1.12; acc: 0.58
Batch: 240; loss: 1.06; acc: 0.62
Batch: 260; loss: 1.04; acc: 0.7
Batch: 280; loss: 1.31; acc: 0.53
Batch: 300; loss: 1.21; acc: 0.55
Batch: 320; loss: 0.97; acc: 0.67
Batch: 340; loss: 1.16; acc: 0.66
Batch: 360; loss: 1.26; acc: 0.55
Batch: 380; loss: 1.22; acc: 0.59
Batch: 400; loss: 1.01; acc: 0.62
Batch: 420; loss: 1.04; acc: 0.69
Batch: 440; loss: 1.08; acc: 0.66
Batch: 460; loss: 1.14; acc: 0.64
Batch: 480; loss: 0.91; acc: 0.69
Batch: 500; loss: 1.0; acc: 0.64
Batch: 520; loss: 1.07; acc: 0.62
Batch: 540; loss: 1.08; acc: 0.61
Batch: 560; loss: 0.82; acc: 0.77
Batch: 580; loss: 1.15; acc: 0.66
Batch: 600; loss: 1.18; acc: 0.64
Batch: 620; loss: 0.95; acc: 0.61
Batch: 640; loss: 1.41; acc: 0.41
Batch: 660; loss: 1.09; acc: 0.67
Batch: 680; loss: 1.25; acc: 0.59
Batch: 700; loss: 1.09; acc: 0.64
Batch: 720; loss: 1.38; acc: 0.58
Batch: 740; loss: 0.99; acc: 0.69
Batch: 760; loss: 1.12; acc: 0.61
Batch: 780; loss: 0.98; acc: 0.69
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

3.0044058803468943e-05
2.015722384385299e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.62
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1226550781043472; val_accuracy: 0.6252985668789809 

The current subspace-distance is: 2.015722384385299e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.0; acc: 0.67
Batch: 20; loss: 1.09; acc: 0.69
Batch: 40; loss: 1.24; acc: 0.64
Batch: 60; loss: 1.24; acc: 0.55
Batch: 80; loss: 1.39; acc: 0.47
Batch: 100; loss: 1.05; acc: 0.62
Batch: 120; loss: 0.99; acc: 0.62
Batch: 140; loss: 1.39; acc: 0.52
Batch: 160; loss: 0.97; acc: 0.66
Batch: 180; loss: 1.28; acc: 0.61
Batch: 200; loss: 1.25; acc: 0.61
Batch: 220; loss: 1.04; acc: 0.62
Batch: 240; loss: 1.26; acc: 0.56
Batch: 260; loss: 1.19; acc: 0.56
Batch: 280; loss: 1.21; acc: 0.58
Batch: 300; loss: 1.24; acc: 0.56
Batch: 320; loss: 1.12; acc: 0.64
Batch: 340; loss: 1.39; acc: 0.47
Batch: 360; loss: 1.2; acc: 0.61
Batch: 380; loss: 1.11; acc: 0.61
Batch: 400; loss: 0.97; acc: 0.7
Batch: 420; loss: 1.11; acc: 0.7
Batch: 440; loss: 1.24; acc: 0.62
Batch: 460; loss: 1.13; acc: 0.58
Batch: 480; loss: 1.1; acc: 0.59
Batch: 500; loss: 1.09; acc: 0.69
Batch: 520; loss: 1.34; acc: 0.53
Batch: 540; loss: 1.29; acc: 0.62
Batch: 560; loss: 0.87; acc: 0.7
Batch: 580; loss: 1.25; acc: 0.58
Batch: 600; loss: 0.99; acc: 0.66
Batch: 620; loss: 1.05; acc: 0.64
Batch: 640; loss: 1.0; acc: 0.66
Batch: 660; loss: 1.42; acc: 0.48
Batch: 680; loss: 1.12; acc: 0.61
Batch: 700; loss: 1.01; acc: 0.69
Batch: 720; loss: 1.27; acc: 0.61
Batch: 740; loss: 0.78; acc: 0.75
Batch: 760; loss: 1.61; acc: 0.56
Batch: 780; loss: 0.91; acc: 0.7
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9190594432293437e-05
2.086280073854141e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.8
Val Epoch over. val_loss: 1.1224020332287832; val_accuracy: 0.6252985668789809 

The current subspace-distance is: 2.086280073854141e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.13; acc: 0.66
Batch: 20; loss: 1.14; acc: 0.59
Batch: 40; loss: 1.05; acc: 0.66
Batch: 60; loss: 1.38; acc: 0.59
Batch: 80; loss: 1.3; acc: 0.59
Batch: 100; loss: 1.06; acc: 0.64
Batch: 120; loss: 1.47; acc: 0.52
Batch: 140; loss: 1.23; acc: 0.61
Batch: 160; loss: 1.16; acc: 0.59
Batch: 180; loss: 1.19; acc: 0.61
Batch: 200; loss: 1.33; acc: 0.58
Batch: 220; loss: 1.11; acc: 0.61
Batch: 240; loss: 0.88; acc: 0.64
Batch: 260; loss: 1.29; acc: 0.58
Batch: 280; loss: 1.17; acc: 0.58
Batch: 300; loss: 1.19; acc: 0.61
Batch: 320; loss: 1.22; acc: 0.58
Batch: 340; loss: 1.37; acc: 0.59
Batch: 360; loss: 1.01; acc: 0.67
Batch: 380; loss: 1.21; acc: 0.58
Batch: 400; loss: 1.1; acc: 0.66
Batch: 420; loss: 1.0; acc: 0.67
Batch: 440; loss: 0.94; acc: 0.67
Batch: 460; loss: 1.06; acc: 0.64
Batch: 480; loss: 0.95; acc: 0.69
Batch: 500; loss: 1.05; acc: 0.77
Batch: 520; loss: 1.09; acc: 0.61
Batch: 540; loss: 1.27; acc: 0.61
Batch: 560; loss: 1.08; acc: 0.61
Batch: 580; loss: 0.94; acc: 0.7
Batch: 600; loss: 1.22; acc: 0.62
Batch: 620; loss: 1.09; acc: 0.61
Batch: 640; loss: 1.2; acc: 0.59
Batch: 660; loss: 1.17; acc: 0.62
Batch: 680; loss: 1.13; acc: 0.61
Batch: 700; loss: 1.05; acc: 0.64
Batch: 720; loss: 1.19; acc: 0.62
Batch: 740; loss: 1.02; acc: 0.69
Batch: 760; loss: 1.05; acc: 0.67
Batch: 780; loss: 1.05; acc: 0.62
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

3.278376971138641e-05
2.194687294831965e-05
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1222985960116052; val_accuracy: 0.6248009554140127 

The current subspace-distance is: 2.194687294831965e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.36; acc: 0.53
Batch: 20; loss: 1.37; acc: 0.59
Batch: 40; loss: 1.12; acc: 0.64
Batch: 60; loss: 0.92; acc: 0.66
Batch: 80; loss: 1.14; acc: 0.61
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 1.07; acc: 0.67
Batch: 140; loss: 1.21; acc: 0.61
Batch: 160; loss: 1.12; acc: 0.59
Batch: 180; loss: 0.96; acc: 0.73
Batch: 200; loss: 0.95; acc: 0.66
Batch: 220; loss: 1.28; acc: 0.55
Batch: 240; loss: 1.39; acc: 0.5
Batch: 260; loss: 1.21; acc: 0.58
Batch: 280; loss: 0.97; acc: 0.69
Batch: 300; loss: 1.33; acc: 0.56
Batch: 320; loss: 1.25; acc: 0.58
Batch: 340; loss: 1.16; acc: 0.64
Batch: 360; loss: 1.38; acc: 0.48
Batch: 380; loss: 1.16; acc: 0.59
Batch: 400; loss: 1.0; acc: 0.64
Batch: 420; loss: 0.97; acc: 0.7
Batch: 440; loss: 1.2; acc: 0.53
Batch: 460; loss: 1.39; acc: 0.53
Batch: 480; loss: 1.13; acc: 0.64
Batch: 500; loss: 1.23; acc: 0.59
Batch: 520; loss: 1.14; acc: 0.62
Batch: 540; loss: 1.33; acc: 0.59
Batch: 560; loss: 1.2; acc: 0.66
Batch: 580; loss: 0.68; acc: 0.75
Batch: 600; loss: 1.06; acc: 0.66
Batch: 620; loss: 1.26; acc: 0.55
Batch: 640; loss: 0.96; acc: 0.61
Batch: 660; loss: 1.09; acc: 0.62
Batch: 680; loss: 0.92; acc: 0.69
Batch: 700; loss: 1.49; acc: 0.5
Batch: 720; loss: 1.02; acc: 0.66
Batch: 740; loss: 1.11; acc: 0.66
Batch: 760; loss: 1.09; acc: 0.61
Batch: 780; loss: 1.06; acc: 0.66
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.692678572202567e-05
2.0498109734035097e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.122340359125927; val_accuracy: 0.6238057324840764 

The current subspace-distance is: 2.0498109734035097e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.19; acc: 0.69
Batch: 20; loss: 1.34; acc: 0.56
Batch: 40; loss: 1.44; acc: 0.55
Batch: 60; loss: 1.12; acc: 0.67
Batch: 80; loss: 0.96; acc: 0.62
Batch: 100; loss: 1.07; acc: 0.66
Batch: 120; loss: 1.06; acc: 0.66
Batch: 140; loss: 1.28; acc: 0.56
Batch: 160; loss: 1.1; acc: 0.62
Batch: 180; loss: 1.23; acc: 0.62
Batch: 200; loss: 1.13; acc: 0.66
Batch: 220; loss: 1.24; acc: 0.52
Batch: 240; loss: 1.51; acc: 0.53
Batch: 260; loss: 1.11; acc: 0.64
Batch: 280; loss: 1.54; acc: 0.52
Batch: 300; loss: 1.08; acc: 0.59
Batch: 320; loss: 1.35; acc: 0.5
Batch: 340; loss: 0.9; acc: 0.69
Batch: 360; loss: 0.93; acc: 0.75
Batch: 380; loss: 1.29; acc: 0.59
Batch: 400; loss: 1.06; acc: 0.64
Batch: 420; loss: 1.18; acc: 0.67
Batch: 440; loss: 1.14; acc: 0.62
Batch: 460; loss: 1.18; acc: 0.53
Batch: 480; loss: 1.18; acc: 0.59
Batch: 500; loss: 1.3; acc: 0.61
Batch: 520; loss: 1.16; acc: 0.67
Batch: 540; loss: 0.91; acc: 0.67
Batch: 560; loss: 1.12; acc: 0.64
Batch: 580; loss: 0.98; acc: 0.77
Batch: 600; loss: 1.3; acc: 0.61
Batch: 620; loss: 1.1; acc: 0.66
Batch: 640; loss: 1.18; acc: 0.66
Batch: 660; loss: 1.13; acc: 0.66
Batch: 680; loss: 1.05; acc: 0.62
Batch: 700; loss: 1.21; acc: 0.52
Batch: 720; loss: 1.21; acc: 0.56
Batch: 740; loss: 1.23; acc: 0.62
Batch: 760; loss: 1.32; acc: 0.56
Batch: 780; loss: 1.09; acc: 0.67
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9574710424640216e-05
2.0930383470840752e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1223430827165106; val_accuracy: 0.6237062101910829 

The current subspace-distance is: 2.0930383470840752e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.21; acc: 0.58
Batch: 20; loss: 1.3; acc: 0.56
Batch: 40; loss: 1.6; acc: 0.48
Batch: 60; loss: 0.94; acc: 0.66
Batch: 80; loss: 1.47; acc: 0.45
Batch: 100; loss: 1.02; acc: 0.7
Batch: 120; loss: 1.06; acc: 0.61
Batch: 140; loss: 1.35; acc: 0.53
Batch: 160; loss: 1.15; acc: 0.56
Batch: 180; loss: 1.28; acc: 0.56
Batch: 200; loss: 1.37; acc: 0.52
Batch: 220; loss: 0.91; acc: 0.72
Batch: 240; loss: 1.09; acc: 0.67
Batch: 260; loss: 1.35; acc: 0.58
Batch: 280; loss: 1.14; acc: 0.62
Batch: 300; loss: 1.13; acc: 0.53
Batch: 320; loss: 1.06; acc: 0.59
Batch: 340; loss: 1.27; acc: 0.58
Batch: 360; loss: 1.12; acc: 0.62
Batch: 380; loss: 1.03; acc: 0.69
Batch: 400; loss: 1.23; acc: 0.5
Batch: 420; loss: 1.25; acc: 0.61
Batch: 440; loss: 1.33; acc: 0.52
Batch: 460; loss: 1.46; acc: 0.42
Batch: 480; loss: 1.19; acc: 0.58
Batch: 500; loss: 1.17; acc: 0.61
Batch: 520; loss: 1.21; acc: 0.56
Batch: 540; loss: 1.24; acc: 0.53
Batch: 560; loss: 1.16; acc: 0.59
Batch: 580; loss: 1.11; acc: 0.67
Batch: 600; loss: 1.05; acc: 0.66
Batch: 620; loss: 1.25; acc: 0.61
Batch: 640; loss: 1.55; acc: 0.53
Batch: 660; loss: 1.05; acc: 0.64
Batch: 680; loss: 1.12; acc: 0.62
Batch: 700; loss: 1.02; acc: 0.61
Batch: 720; loss: 1.19; acc: 0.61
Batch: 740; loss: 1.49; acc: 0.52
Batch: 760; loss: 1.13; acc: 0.64
Batch: 780; loss: 0.99; acc: 0.67
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.889822644647211e-05
1.91835224541137e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1222611525256163; val_accuracy: 0.6240047770700637 

The current subspace-distance is: 1.91835224541137e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.04; acc: 0.62
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 1.17; acc: 0.59
Batch: 60; loss: 1.17; acc: 0.55
Batch: 80; loss: 1.25; acc: 0.59
Batch: 100; loss: 1.42; acc: 0.59
Batch: 120; loss: 1.21; acc: 0.59
Batch: 140; loss: 0.88; acc: 0.73
Batch: 160; loss: 1.31; acc: 0.56
Batch: 180; loss: 1.2; acc: 0.58
Batch: 200; loss: 1.3; acc: 0.48
Batch: 220; loss: 1.07; acc: 0.7
Batch: 240; loss: 1.16; acc: 0.66
Batch: 260; loss: 1.15; acc: 0.58
Batch: 280; loss: 1.15; acc: 0.56
Batch: 300; loss: 1.23; acc: 0.58
Batch: 320; loss: 1.1; acc: 0.61
Batch: 340; loss: 1.13; acc: 0.56
Batch: 360; loss: 1.45; acc: 0.55
Batch: 380; loss: 1.21; acc: 0.58
Batch: 400; loss: 1.17; acc: 0.61
Batch: 420; loss: 1.24; acc: 0.64
Batch: 440; loss: 1.31; acc: 0.53
Batch: 460; loss: 1.51; acc: 0.44
Batch: 480; loss: 1.08; acc: 0.64
Batch: 500; loss: 1.26; acc: 0.56
Batch: 520; loss: 1.4; acc: 0.55
Batch: 540; loss: 0.81; acc: 0.75
Batch: 560; loss: 0.85; acc: 0.77
Batch: 580; loss: 1.19; acc: 0.61
Batch: 600; loss: 1.15; acc: 0.62
Batch: 620; loss: 1.1; acc: 0.66
Batch: 640; loss: 1.27; acc: 0.55
Batch: 660; loss: 1.11; acc: 0.69
Batch: 680; loss: 1.23; acc: 0.61
Batch: 700; loss: 1.1; acc: 0.66
Batch: 720; loss: 1.29; acc: 0.55
Batch: 740; loss: 1.15; acc: 0.61
Batch: 760; loss: 1.27; acc: 0.58
Batch: 780; loss: 1.28; acc: 0.52
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9063879992463626e-05
1.9167264326824807e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1223739996837203; val_accuracy: 0.6240047770700637 

The current subspace-distance is: 1.9167264326824807e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.37; acc: 0.56
Batch: 20; loss: 1.14; acc: 0.53
Batch: 40; loss: 1.22; acc: 0.67
Batch: 60; loss: 1.17; acc: 0.66
Batch: 80; loss: 0.99; acc: 0.7
Batch: 100; loss: 1.16; acc: 0.62
Batch: 120; loss: 1.15; acc: 0.62
Batch: 140; loss: 1.07; acc: 0.7
Batch: 160; loss: 1.4; acc: 0.48
Batch: 180; loss: 1.19; acc: 0.53
Batch: 200; loss: 1.16; acc: 0.55
Batch: 220; loss: 1.17; acc: 0.66
Batch: 240; loss: 1.23; acc: 0.56
Batch: 260; loss: 1.11; acc: 0.56
Batch: 280; loss: 1.45; acc: 0.52
Batch: 300; loss: 1.19; acc: 0.58
Batch: 320; loss: 1.09; acc: 0.62
Batch: 340; loss: 1.21; acc: 0.59
Batch: 360; loss: 0.9; acc: 0.7
Batch: 380; loss: 1.35; acc: 0.52
Batch: 400; loss: 1.19; acc: 0.55
Batch: 420; loss: 1.15; acc: 0.64
Batch: 440; loss: 1.49; acc: 0.53
Batch: 460; loss: 1.13; acc: 0.62
Batch: 480; loss: 1.42; acc: 0.53
Batch: 500; loss: 1.14; acc: 0.59
Batch: 520; loss: 1.2; acc: 0.59
Batch: 540; loss: 1.31; acc: 0.59
Batch: 560; loss: 1.34; acc: 0.52
Batch: 580; loss: 1.11; acc: 0.61
Batch: 600; loss: 1.16; acc: 0.59
Batch: 620; loss: 1.1; acc: 0.64
Batch: 640; loss: 1.22; acc: 0.59
Batch: 660; loss: 1.27; acc: 0.61
Batch: 680; loss: 1.19; acc: 0.59
Batch: 700; loss: 1.32; acc: 0.56
Batch: 720; loss: 1.33; acc: 0.56
Batch: 740; loss: 1.1; acc: 0.59
Batch: 760; loss: 1.11; acc: 0.66
Batch: 780; loss: 1.6; acc: 0.48
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

3.213872332707979e-05
1.9841752873617224e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.122223729540588; val_accuracy: 0.6242038216560509 

The current subspace-distance is: 1.9841752873617224e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.26; acc: 0.53
Batch: 20; loss: 1.29; acc: 0.59
Batch: 40; loss: 1.0; acc: 0.78
Batch: 60; loss: 1.07; acc: 0.62
Batch: 80; loss: 1.13; acc: 0.69
Batch: 100; loss: 1.09; acc: 0.62
Batch: 120; loss: 1.28; acc: 0.59
Batch: 140; loss: 1.23; acc: 0.61
Batch: 160; loss: 1.06; acc: 0.58
Batch: 180; loss: 0.88; acc: 0.73
Batch: 200; loss: 1.0; acc: 0.62
Batch: 220; loss: 1.16; acc: 0.64
Batch: 240; loss: 1.36; acc: 0.52
Batch: 260; loss: 1.36; acc: 0.55
Batch: 280; loss: 1.22; acc: 0.53
Batch: 300; loss: 1.01; acc: 0.72
Batch: 320; loss: 1.15; acc: 0.62
Batch: 340; loss: 1.18; acc: 0.67
Batch: 360; loss: 1.05; acc: 0.66
Batch: 380; loss: 1.2; acc: 0.67
Batch: 400; loss: 1.34; acc: 0.5
Batch: 420; loss: 1.27; acc: 0.53
Batch: 440; loss: 1.11; acc: 0.7
Batch: 460; loss: 1.21; acc: 0.64
Batch: 480; loss: 1.2; acc: 0.64
Batch: 500; loss: 1.16; acc: 0.58
Batch: 520; loss: 1.22; acc: 0.61
Batch: 540; loss: 1.16; acc: 0.66
Batch: 560; loss: 1.16; acc: 0.62
Batch: 580; loss: 1.31; acc: 0.52
Batch: 600; loss: 1.29; acc: 0.55
Batch: 620; loss: 1.12; acc: 0.59
Batch: 640; loss: 0.87; acc: 0.69
Batch: 660; loss: 1.25; acc: 0.56
Batch: 680; loss: 1.29; acc: 0.56
Batch: 700; loss: 1.01; acc: 0.66
Batch: 720; loss: 1.41; acc: 0.52
Batch: 740; loss: 1.11; acc: 0.61
Batch: 760; loss: 1.06; acc: 0.69
Batch: 780; loss: 1.13; acc: 0.66
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8574726457009092e-05
2.070904702122789e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.122268579188426; val_accuracy: 0.62390525477707 

The current subspace-distance is: 2.070904702122789e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.36; acc: 0.59
Batch: 20; loss: 1.35; acc: 0.56
Batch: 40; loss: 0.87; acc: 0.67
Batch: 60; loss: 1.36; acc: 0.55
Batch: 80; loss: 1.34; acc: 0.55
Batch: 100; loss: 1.02; acc: 0.62
Batch: 120; loss: 1.24; acc: 0.55
Batch: 140; loss: 1.38; acc: 0.48
Batch: 160; loss: 1.12; acc: 0.59
Batch: 180; loss: 1.36; acc: 0.55
Batch: 200; loss: 1.02; acc: 0.72
Batch: 220; loss: 1.15; acc: 0.59
Batch: 240; loss: 0.9; acc: 0.78
Batch: 260; loss: 1.13; acc: 0.62
Batch: 280; loss: 1.4; acc: 0.55
Batch: 300; loss: 1.21; acc: 0.61
Batch: 320; loss: 1.16; acc: 0.56
Batch: 340; loss: 1.18; acc: 0.64
Batch: 360; loss: 0.99; acc: 0.77
Batch: 380; loss: 1.2; acc: 0.59
Batch: 400; loss: 1.17; acc: 0.56
Batch: 420; loss: 1.13; acc: 0.62
Batch: 440; loss: 1.13; acc: 0.64
Batch: 460; loss: 1.11; acc: 0.62
Batch: 480; loss: 1.58; acc: 0.53
Batch: 500; loss: 1.17; acc: 0.67
Batch: 520; loss: 1.25; acc: 0.62
Batch: 540; loss: 1.38; acc: 0.55
Batch: 560; loss: 1.2; acc: 0.61
Batch: 580; loss: 1.4; acc: 0.53
Batch: 600; loss: 1.08; acc: 0.73
Batch: 620; loss: 0.99; acc: 0.64
Batch: 640; loss: 1.37; acc: 0.55
Batch: 660; loss: 1.29; acc: 0.5
Batch: 680; loss: 1.05; acc: 0.58
Batch: 700; loss: 0.95; acc: 0.66
Batch: 720; loss: 1.17; acc: 0.59
Batch: 740; loss: 1.29; acc: 0.53
Batch: 760; loss: 1.11; acc: 0.62
Batch: 780; loss: 1.49; acc: 0.59
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

3.219143400201574e-05
2.2095548047218472e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1221711996254649; val_accuracy: 0.6238057324840764 

The current subspace-distance is: 2.2095548047218472e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.33; acc: 0.55
Batch: 20; loss: 1.26; acc: 0.62
Batch: 40; loss: 1.27; acc: 0.62
Batch: 60; loss: 1.16; acc: 0.66
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.02; acc: 0.61
Batch: 120; loss: 1.13; acc: 0.59
Batch: 140; loss: 1.02; acc: 0.62
Batch: 160; loss: 1.15; acc: 0.64
Batch: 180; loss: 1.12; acc: 0.69
Batch: 200; loss: 1.06; acc: 0.69
Batch: 220; loss: 1.27; acc: 0.64
Batch: 240; loss: 1.26; acc: 0.59
Batch: 260; loss: 1.23; acc: 0.56
Batch: 280; loss: 1.21; acc: 0.58
Batch: 300; loss: 1.26; acc: 0.53
Batch: 320; loss: 1.25; acc: 0.59
Batch: 340; loss: 1.22; acc: 0.56
Batch: 360; loss: 1.14; acc: 0.66
Batch: 380; loss: 1.03; acc: 0.62
Batch: 400; loss: 1.16; acc: 0.59
Batch: 420; loss: 1.03; acc: 0.59
Batch: 440; loss: 1.13; acc: 0.62
Batch: 460; loss: 1.1; acc: 0.64
Batch: 480; loss: 1.19; acc: 0.62
Batch: 500; loss: 1.23; acc: 0.61
Batch: 520; loss: 1.06; acc: 0.66
Batch: 540; loss: 1.05; acc: 0.62
Batch: 560; loss: 1.26; acc: 0.53
Batch: 580; loss: 0.86; acc: 0.75
Batch: 600; loss: 1.11; acc: 0.61
Batch: 620; loss: 1.29; acc: 0.58
Batch: 640; loss: 1.24; acc: 0.59
Batch: 660; loss: 1.11; acc: 0.66
Batch: 680; loss: 1.27; acc: 0.59
Batch: 700; loss: 1.28; acc: 0.53
Batch: 720; loss: 0.95; acc: 0.7
Batch: 740; loss: 1.16; acc: 0.69
Batch: 760; loss: 1.22; acc: 0.58
Batch: 780; loss: 1.12; acc: 0.61
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8769873097189702e-05
2.083764957205858e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1221699771607758; val_accuracy: 0.6238057324840764 

The current subspace-distance is: 2.083764957205858e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.31; acc: 0.62
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 1.09; acc: 0.59
Batch: 60; loss: 1.15; acc: 0.62
Batch: 80; loss: 1.28; acc: 0.59
Batch: 100; loss: 1.15; acc: 0.64
Batch: 120; loss: 1.07; acc: 0.69
Batch: 140; loss: 1.05; acc: 0.62
Batch: 160; loss: 1.23; acc: 0.64
Batch: 180; loss: 1.08; acc: 0.66
Batch: 200; loss: 0.92; acc: 0.77
Batch: 220; loss: 1.12; acc: 0.62
Batch: 240; loss: 1.23; acc: 0.56
Batch: 260; loss: 1.12; acc: 0.67
Batch: 280; loss: 1.04; acc: 0.67
Batch: 300; loss: 1.36; acc: 0.5
Batch: 320; loss: 1.05; acc: 0.64
Batch: 340; loss: 1.39; acc: 0.64
Batch: 360; loss: 1.16; acc: 0.64
Batch: 380; loss: 1.27; acc: 0.59
Batch: 400; loss: 0.95; acc: 0.77
Batch: 420; loss: 1.02; acc: 0.64
Batch: 440; loss: 1.19; acc: 0.61
Batch: 460; loss: 1.08; acc: 0.56
Batch: 480; loss: 1.35; acc: 0.58
Batch: 500; loss: 1.2; acc: 0.61
Batch: 520; loss: 1.2; acc: 0.59
Batch: 540; loss: 1.01; acc: 0.66
Batch: 560; loss: 1.03; acc: 0.61
Batch: 580; loss: 1.44; acc: 0.52
Batch: 600; loss: 1.18; acc: 0.58
Batch: 620; loss: 1.06; acc: 0.61
Batch: 640; loss: 0.97; acc: 0.69
Batch: 660; loss: 1.17; acc: 0.62
Batch: 680; loss: 1.27; acc: 0.61
Batch: 700; loss: 1.16; acc: 0.61
Batch: 720; loss: 1.14; acc: 0.62
Batch: 740; loss: 1.17; acc: 0.64
Batch: 760; loss: 1.07; acc: 0.62
Batch: 780; loss: 1.31; acc: 0.55
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.7341950044501573e-05
1.7038031728588976e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.122127073965255; val_accuracy: 0.6240047770700637 

The current subspace-distance is: 1.7038031728588976e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.06; acc: 0.55
Batch: 20; loss: 0.95; acc: 0.62
Batch: 40; loss: 1.19; acc: 0.56
Batch: 60; loss: 1.02; acc: 0.72
Batch: 80; loss: 1.11; acc: 0.69
Batch: 100; loss: 1.12; acc: 0.62
Batch: 120; loss: 1.09; acc: 0.56
Batch: 140; loss: 1.32; acc: 0.61
Batch: 160; loss: 1.28; acc: 0.52
Batch: 180; loss: 1.01; acc: 0.66
Batch: 200; loss: 0.91; acc: 0.75
Batch: 220; loss: 1.22; acc: 0.56
Batch: 240; loss: 1.13; acc: 0.56
Batch: 260; loss: 1.14; acc: 0.64
Batch: 280; loss: 1.06; acc: 0.7
Batch: 300; loss: 1.01; acc: 0.59
Batch: 320; loss: 1.1; acc: 0.56
Batch: 340; loss: 1.3; acc: 0.55
Batch: 360; loss: 1.19; acc: 0.66
Batch: 380; loss: 0.99; acc: 0.67
Batch: 400; loss: 0.91; acc: 0.77
Batch: 420; loss: 1.21; acc: 0.58
Batch: 440; loss: 1.16; acc: 0.67
Batch: 460; loss: 1.15; acc: 0.66
Batch: 480; loss: 1.08; acc: 0.61
Batch: 500; loss: 1.05; acc: 0.67
Batch: 520; loss: 1.26; acc: 0.61
Batch: 540; loss: 1.2; acc: 0.59
Batch: 560; loss: 1.14; acc: 0.62
Batch: 580; loss: 1.19; acc: 0.62
Batch: 600; loss: 1.37; acc: 0.5
Batch: 620; loss: 1.23; acc: 0.59
Batch: 640; loss: 1.03; acc: 0.62
Batch: 660; loss: 0.92; acc: 0.7
Batch: 680; loss: 1.13; acc: 0.69
Batch: 700; loss: 1.18; acc: 0.61
Batch: 720; loss: 1.0; acc: 0.67
Batch: 740; loss: 1.17; acc: 0.58
Batch: 760; loss: 1.32; acc: 0.53
Batch: 780; loss: 1.18; acc: 0.61
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8928614483447745e-05
1.8126718714484014e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1221315401374914; val_accuracy: 0.6241042993630573 

The current subspace-distance is: 1.8126718714484014e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.16; acc: 0.62
Batch: 20; loss: 1.01; acc: 0.69
Batch: 40; loss: 1.0; acc: 0.66
Batch: 60; loss: 1.16; acc: 0.67
Batch: 80; loss: 1.09; acc: 0.62
Batch: 100; loss: 1.17; acc: 0.62
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 1.31; acc: 0.55
Batch: 160; loss: 1.16; acc: 0.61
Batch: 180; loss: 1.53; acc: 0.53
Batch: 200; loss: 1.2; acc: 0.58
Batch: 220; loss: 1.09; acc: 0.64
Batch: 240; loss: 1.23; acc: 0.56
Batch: 260; loss: 1.37; acc: 0.56
Batch: 280; loss: 1.12; acc: 0.55
Batch: 300; loss: 1.36; acc: 0.53
Batch: 320; loss: 1.18; acc: 0.66
Batch: 340; loss: 1.07; acc: 0.53
Batch: 360; loss: 1.04; acc: 0.62
Batch: 380; loss: 1.45; acc: 0.61
Batch: 400; loss: 1.09; acc: 0.62
Batch: 420; loss: 1.17; acc: 0.61
Batch: 440; loss: 0.94; acc: 0.69
Batch: 460; loss: 1.07; acc: 0.62
Batch: 480; loss: 1.14; acc: 0.69
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.13; acc: 0.67
Batch: 540; loss: 1.16; acc: 0.61
Batch: 560; loss: 1.33; acc: 0.52
Batch: 580; loss: 1.25; acc: 0.56
Batch: 600; loss: 1.09; acc: 0.61
Batch: 620; loss: 1.08; acc: 0.62
Batch: 640; loss: 1.15; acc: 0.62
Batch: 660; loss: 1.08; acc: 0.66
Batch: 680; loss: 0.99; acc: 0.7
Batch: 700; loss: 1.08; acc: 0.58
Batch: 720; loss: 1.09; acc: 0.62
Batch: 740; loss: 1.04; acc: 0.7
Batch: 760; loss: 1.02; acc: 0.56
Batch: 780; loss: 1.18; acc: 0.56
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.7841535484185442e-05
1.7449192455387674e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1221287288483541; val_accuracy: 0.6243033439490446 

The current subspace-distance is: 1.7449192455387674e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.23; acc: 0.56
Batch: 20; loss: 1.35; acc: 0.56
Batch: 40; loss: 1.35; acc: 0.55
Batch: 60; loss: 1.08; acc: 0.56
Batch: 80; loss: 1.03; acc: 0.67
Batch: 100; loss: 0.85; acc: 0.77
Batch: 120; loss: 1.35; acc: 0.5
Batch: 140; loss: 0.96; acc: 0.72
Batch: 160; loss: 1.36; acc: 0.56
Batch: 180; loss: 1.27; acc: 0.52
Batch: 200; loss: 1.22; acc: 0.64
Batch: 220; loss: 1.25; acc: 0.64
Batch: 240; loss: 1.28; acc: 0.47
Batch: 260; loss: 1.1; acc: 0.55
Batch: 280; loss: 1.06; acc: 0.67
Batch: 300; loss: 1.07; acc: 0.64
Batch: 320; loss: 0.99; acc: 0.67
Batch: 340; loss: 1.49; acc: 0.48
Batch: 360; loss: 0.7; acc: 0.81
Batch: 380; loss: 1.25; acc: 0.62
Batch: 400; loss: 1.17; acc: 0.66
Batch: 420; loss: 1.22; acc: 0.55
Batch: 440; loss: 1.28; acc: 0.55
Batch: 460; loss: 1.41; acc: 0.58
Batch: 480; loss: 1.18; acc: 0.66
Batch: 500; loss: 1.18; acc: 0.58
Batch: 520; loss: 1.24; acc: 0.59
Batch: 540; loss: 1.14; acc: 0.61
Batch: 560; loss: 1.12; acc: 0.61
Batch: 580; loss: 1.17; acc: 0.59
Batch: 600; loss: 1.12; acc: 0.62
Batch: 620; loss: 1.29; acc: 0.56
Batch: 640; loss: 1.0; acc: 0.64
Batch: 660; loss: 1.21; acc: 0.56
Batch: 680; loss: 1.07; acc: 0.61
Batch: 700; loss: 1.05; acc: 0.69
Batch: 720; loss: 0.86; acc: 0.73
Batch: 740; loss: 1.1; acc: 0.66
Batch: 760; loss: 1.31; acc: 0.53
Batch: 780; loss: 1.2; acc: 0.62
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.6573934519547038e-05
1.978802538360469e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1220837747974761; val_accuracy: 0.6241042993630573 

The current subspace-distance is: 1.978802538360469e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.16; acc: 0.61
Batch: 20; loss: 1.24; acc: 0.62
Batch: 40; loss: 1.07; acc: 0.69
Batch: 60; loss: 1.2; acc: 0.61
Batch: 80; loss: 1.14; acc: 0.61
Batch: 100; loss: 1.08; acc: 0.61
Batch: 120; loss: 0.98; acc: 0.62
Batch: 140; loss: 1.21; acc: 0.59
Batch: 160; loss: 1.16; acc: 0.62
Batch: 180; loss: 1.4; acc: 0.41
Batch: 200; loss: 1.08; acc: 0.66
Batch: 220; loss: 0.93; acc: 0.72
Batch: 240; loss: 0.95; acc: 0.72
Batch: 260; loss: 1.16; acc: 0.64
Batch: 280; loss: 1.25; acc: 0.62
Batch: 300; loss: 1.21; acc: 0.52
Batch: 320; loss: 1.25; acc: 0.53
Batch: 340; loss: 1.02; acc: 0.66
Batch: 360; loss: 1.3; acc: 0.59
Batch: 380; loss: 1.6; acc: 0.55
Batch: 400; loss: 1.08; acc: 0.62
Batch: 420; loss: 1.11; acc: 0.62
Batch: 440; loss: 1.36; acc: 0.56
Batch: 460; loss: 1.57; acc: 0.5
Batch: 480; loss: 0.88; acc: 0.64
Batch: 500; loss: 1.1; acc: 0.67
Batch: 520; loss: 1.1; acc: 0.64
Batch: 540; loss: 1.13; acc: 0.69
Batch: 560; loss: 1.13; acc: 0.58
Batch: 580; loss: 1.37; acc: 0.56
Batch: 600; loss: 1.13; acc: 0.58
Batch: 620; loss: 1.38; acc: 0.52
Batch: 640; loss: 1.16; acc: 0.64
Batch: 660; loss: 1.35; acc: 0.55
Batch: 680; loss: 1.22; acc: 0.55
Batch: 700; loss: 1.1; acc: 0.66
Batch: 720; loss: 1.0; acc: 0.7
Batch: 740; loss: 1.1; acc: 0.66
Batch: 760; loss: 1.39; acc: 0.58
Batch: 780; loss: 1.12; acc: 0.73
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.699012475204654e-05
1.84483051270945e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1220976828010218; val_accuracy: 0.6241042993630573 

The current subspace-distance is: 1.84483051270945e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.37; acc: 0.55
Batch: 20; loss: 1.29; acc: 0.55
Batch: 40; loss: 1.17; acc: 0.62
Batch: 60; loss: 0.96; acc: 0.69
Batch: 80; loss: 1.21; acc: 0.62
Batch: 100; loss: 1.1; acc: 0.66
Batch: 120; loss: 0.99; acc: 0.67
Batch: 140; loss: 1.22; acc: 0.53
Batch: 160; loss: 1.33; acc: 0.61
Batch: 180; loss: 1.45; acc: 0.52
Batch: 200; loss: 1.24; acc: 0.62
Batch: 220; loss: 1.14; acc: 0.55
Batch: 240; loss: 1.13; acc: 0.66
Batch: 260; loss: 1.0; acc: 0.72
Batch: 280; loss: 1.44; acc: 0.45
Batch: 300; loss: 1.34; acc: 0.56
Batch: 320; loss: 1.06; acc: 0.61
Batch: 340; loss: 1.09; acc: 0.61
Batch: 360; loss: 1.03; acc: 0.64
Batch: 380; loss: 1.3; acc: 0.55
Batch: 400; loss: 1.23; acc: 0.58
Batch: 420; loss: 0.98; acc: 0.7
Batch: 440; loss: 1.16; acc: 0.62
Batch: 460; loss: 1.13; acc: 0.56
Batch: 480; loss: 1.0; acc: 0.62
Batch: 500; loss: 1.26; acc: 0.56
Batch: 520; loss: 0.87; acc: 0.7
Batch: 540; loss: 1.16; acc: 0.59
Batch: 560; loss: 1.23; acc: 0.56
Batch: 580; loss: 1.34; acc: 0.52
Batch: 600; loss: 1.45; acc: 0.58
Batch: 620; loss: 0.84; acc: 0.73
Batch: 640; loss: 1.15; acc: 0.61
Batch: 660; loss: 1.11; acc: 0.61
Batch: 680; loss: 1.08; acc: 0.62
Batch: 700; loss: 1.21; acc: 0.61
Batch: 720; loss: 1.12; acc: 0.64
Batch: 740; loss: 1.16; acc: 0.67
Batch: 760; loss: 0.98; acc: 0.62
Batch: 780; loss: 1.15; acc: 0.61
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

3.0083698220551014e-05
1.8011722204391845e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1220985480174896; val_accuracy: 0.6243033439490446 

The current subspace-distance is: 1.8011722204391845e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.28; acc: 0.53
Batch: 20; loss: 1.04; acc: 0.66
Batch: 40; loss: 1.23; acc: 0.61
Batch: 60; loss: 1.27; acc: 0.62
Batch: 80; loss: 1.14; acc: 0.62
Batch: 100; loss: 1.03; acc: 0.72
Batch: 120; loss: 1.11; acc: 0.66
Batch: 140; loss: 1.22; acc: 0.56
Batch: 160; loss: 0.97; acc: 0.61
Batch: 180; loss: 1.25; acc: 0.58
Batch: 200; loss: 1.09; acc: 0.64
Batch: 220; loss: 0.98; acc: 0.64
Batch: 240; loss: 0.8; acc: 0.8
Batch: 260; loss: 1.21; acc: 0.56
Batch: 280; loss: 0.87; acc: 0.69
Batch: 300; loss: 1.18; acc: 0.58
Batch: 320; loss: 1.32; acc: 0.58
Batch: 340; loss: 1.02; acc: 0.69
Batch: 360; loss: 1.51; acc: 0.55
Batch: 380; loss: 1.12; acc: 0.62
Batch: 400; loss: 1.2; acc: 0.62
Batch: 420; loss: 1.22; acc: 0.64
Batch: 440; loss: 1.01; acc: 0.67
Batch: 460; loss: 1.25; acc: 0.59
Batch: 480; loss: 0.89; acc: 0.75
Batch: 500; loss: 0.93; acc: 0.69
Batch: 520; loss: 1.1; acc: 0.62
Batch: 540; loss: 1.22; acc: 0.61
Batch: 560; loss: 1.37; acc: 0.52
Batch: 580; loss: 1.15; acc: 0.69
Batch: 600; loss: 1.32; acc: 0.5
Batch: 620; loss: 1.05; acc: 0.62
Batch: 640; loss: 1.16; acc: 0.55
Batch: 660; loss: 1.19; acc: 0.53
Batch: 680; loss: 1.19; acc: 0.58
Batch: 700; loss: 1.1; acc: 0.62
Batch: 720; loss: 1.18; acc: 0.58
Batch: 740; loss: 1.17; acc: 0.55
Batch: 760; loss: 1.06; acc: 0.62
Batch: 780; loss: 1.24; acc: 0.58
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8849388399976306e-05
1.744642577250488e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.122083435013036; val_accuracy: 0.6242038216560509 

The current subspace-distance is: 1.744642577250488e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.49; acc: 0.52
Batch: 20; loss: 1.0; acc: 0.62
Batch: 40; loss: 1.12; acc: 0.69
Batch: 60; loss: 1.14; acc: 0.64
Batch: 80; loss: 1.18; acc: 0.67
Batch: 100; loss: 1.34; acc: 0.53
Batch: 120; loss: 1.53; acc: 0.47
Batch: 140; loss: 1.31; acc: 0.53
Batch: 160; loss: 0.98; acc: 0.64
Batch: 180; loss: 1.12; acc: 0.61
Batch: 200; loss: 1.29; acc: 0.58
Batch: 220; loss: 1.5; acc: 0.5
Batch: 240; loss: 1.34; acc: 0.55
Batch: 260; loss: 1.32; acc: 0.59
Batch: 280; loss: 1.1; acc: 0.62
Batch: 300; loss: 0.99; acc: 0.61
Batch: 320; loss: 1.03; acc: 0.64
Batch: 340; loss: 1.39; acc: 0.56
Batch: 360; loss: 0.91; acc: 0.77
Batch: 380; loss: 1.07; acc: 0.7
Batch: 400; loss: 1.24; acc: 0.59
Batch: 420; loss: 1.29; acc: 0.52
Batch: 440; loss: 1.18; acc: 0.69
Batch: 460; loss: 1.2; acc: 0.61
Batch: 480; loss: 0.87; acc: 0.67
Batch: 500; loss: 1.18; acc: 0.64
Batch: 520; loss: 1.0; acc: 0.67
Batch: 540; loss: 1.19; acc: 0.58
Batch: 560; loss: 1.31; acc: 0.62
Batch: 580; loss: 1.28; acc: 0.61
Batch: 600; loss: 1.16; acc: 0.61
Batch: 620; loss: 1.02; acc: 0.67
Batch: 640; loss: 1.39; acc: 0.59
Batch: 660; loss: 1.18; acc: 0.62
Batch: 680; loss: 1.15; acc: 0.52
Batch: 700; loss: 1.07; acc: 0.59
Batch: 720; loss: 1.36; acc: 0.55
Batch: 740; loss: 1.4; acc: 0.62
Batch: 760; loss: 1.03; acc: 0.59
Batch: 780; loss: 1.19; acc: 0.56
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.9898632419644855e-05
1.6910347767407075e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1220392687305523; val_accuracy: 0.6247014331210191 

The current subspace-distance is: 1.6910347767407075e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.1; acc: 0.61
Batch: 20; loss: 1.18; acc: 0.61
Batch: 40; loss: 1.49; acc: 0.5
Batch: 60; loss: 1.07; acc: 0.64
Batch: 80; loss: 1.07; acc: 0.62
Batch: 100; loss: 1.04; acc: 0.64
Batch: 120; loss: 1.33; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.69
Batch: 160; loss: 1.13; acc: 0.61
Batch: 180; loss: 1.17; acc: 0.48
Batch: 200; loss: 1.29; acc: 0.59
Batch: 220; loss: 0.95; acc: 0.69
Batch: 240; loss: 1.1; acc: 0.69
Batch: 260; loss: 1.13; acc: 0.62
Batch: 280; loss: 1.01; acc: 0.66
Batch: 300; loss: 1.39; acc: 0.5
Batch: 320; loss: 1.06; acc: 0.62
Batch: 340; loss: 1.2; acc: 0.67
Batch: 360; loss: 1.26; acc: 0.55
Batch: 380; loss: 1.22; acc: 0.61
Batch: 400; loss: 1.16; acc: 0.61
Batch: 420; loss: 1.09; acc: 0.62
Batch: 440; loss: 1.36; acc: 0.59
Batch: 460; loss: 1.24; acc: 0.55
Batch: 480; loss: 1.1; acc: 0.64
Batch: 500; loss: 0.87; acc: 0.75
Batch: 520; loss: 0.97; acc: 0.66
Batch: 540; loss: 1.09; acc: 0.66
Batch: 560; loss: 1.25; acc: 0.58
Batch: 580; loss: 1.1; acc: 0.52
Batch: 600; loss: 1.17; acc: 0.59
Batch: 620; loss: 0.83; acc: 0.72
Batch: 640; loss: 1.09; acc: 0.58
Batch: 660; loss: 1.06; acc: 0.64
Batch: 680; loss: 0.92; acc: 0.67
Batch: 700; loss: 1.05; acc: 0.59
Batch: 720; loss: 1.02; acc: 0.67
Batch: 740; loss: 1.18; acc: 0.61
Batch: 760; loss: 1.19; acc: 0.56
Batch: 780; loss: 1.19; acc: 0.66
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

2.8061645934940316e-05
2.0885800040559843e-05
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.28; acc: 0.64
Batch: 120; loss: 1.41; acc: 0.55
Batch: 140; loss: 0.75; acc: 0.81
Val Epoch over. val_loss: 1.1220289586455958; val_accuracy: 0.6244028662420382 

The current subspace-distance is: 2.0885800040559843e-05 

plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 89051
elements in E: 39842000
fraction nonzero: 0.0022351036594548466
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.29; acc: 0.17
Batch: 80; loss: 2.31; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.26; acc: 0.25
Batch: 140; loss: 2.29; acc: 0.17
Batch: 160; loss: 2.27; acc: 0.3
Batch: 180; loss: 2.26; acc: 0.27
Batch: 200; loss: 2.25; acc: 0.23
Batch: 220; loss: 2.25; acc: 0.27
Batch: 240; loss: 2.24; acc: 0.28
Batch: 260; loss: 2.23; acc: 0.31
Batch: 280; loss: 2.23; acc: 0.3
Batch: 300; loss: 2.23; acc: 0.28
Batch: 320; loss: 2.24; acc: 0.31
Batch: 340; loss: 2.22; acc: 0.25
Batch: 360; loss: 2.23; acc: 0.33
Batch: 380; loss: 2.2; acc: 0.3
Batch: 400; loss: 2.2; acc: 0.31
Batch: 420; loss: 2.16; acc: 0.39
Batch: 440; loss: 2.17; acc: 0.42
Batch: 460; loss: 2.15; acc: 0.39
Batch: 480; loss: 2.17; acc: 0.39
Batch: 500; loss: 2.13; acc: 0.47
Batch: 520; loss: 2.07; acc: 0.55
Batch: 540; loss: 2.15; acc: 0.33
Batch: 560; loss: 2.16; acc: 0.34
Batch: 580; loss: 2.08; acc: 0.42
Batch: 600; loss: 2.08; acc: 0.39
Batch: 620; loss: 2.06; acc: 0.45
Batch: 640; loss: 1.96; acc: 0.56
Batch: 660; loss: 2.07; acc: 0.34
Batch: 680; loss: 1.96; acc: 0.48
Batch: 700; loss: 1.97; acc: 0.47
Batch: 720; loss: 1.88; acc: 0.52
Batch: 740; loss: 1.9; acc: 0.55
Batch: 760; loss: 1.86; acc: 0.48
Batch: 780; loss: 1.86; acc: 0.56
Train Epoch over. train_loss: 2.16; train_accuracy: 0.35 

9.79743981588399e-06
7.3668361437739804e-06
Batch: 0; loss: 1.92; acc: 0.47
Batch: 20; loss: 1.85; acc: 0.47
Batch: 40; loss: 1.68; acc: 0.69
Batch: 60; loss: 1.77; acc: 0.59
Batch: 80; loss: 1.8; acc: 0.56
Batch: 100; loss: 1.95; acc: 0.47
Batch: 120; loss: 1.89; acc: 0.5
Batch: 140; loss: 1.81; acc: 0.56
Val Epoch over. val_loss: 1.8555267942938836; val_accuracy: 0.5085589171974523 

The current subspace-distance is: 7.3668361437739804e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.82; acc: 0.59
Batch: 20; loss: 1.89; acc: 0.45
Batch: 40; loss: 1.8; acc: 0.52
Batch: 60; loss: 1.69; acc: 0.55
Batch: 80; loss: 1.8; acc: 0.45
Batch: 100; loss: 1.7; acc: 0.55
Batch: 120; loss: 1.69; acc: 0.48
Batch: 140; loss: 1.65; acc: 0.5
Batch: 160; loss: 1.61; acc: 0.55
Batch: 180; loss: 1.58; acc: 0.56
Batch: 200; loss: 1.5; acc: 0.62
Batch: 220; loss: 1.64; acc: 0.5
Batch: 240; loss: 1.53; acc: 0.55
Batch: 260; loss: 1.33; acc: 0.59
Batch: 280; loss: 1.41; acc: 0.56
Batch: 300; loss: 1.4; acc: 0.58
Batch: 320; loss: 1.4; acc: 0.56
Batch: 340; loss: 1.38; acc: 0.59
Batch: 360; loss: 1.39; acc: 0.52
Batch: 380; loss: 1.28; acc: 0.61
Batch: 400; loss: 1.4; acc: 0.55
Batch: 420; loss: 1.27; acc: 0.59
Batch: 440; loss: 1.48; acc: 0.47
Batch: 460; loss: 1.27; acc: 0.5
Batch: 480; loss: 1.23; acc: 0.61
Batch: 500; loss: 1.14; acc: 0.62
Batch: 520; loss: 1.16; acc: 0.59
Batch: 540; loss: 1.11; acc: 0.61
Batch: 560; loss: 1.13; acc: 0.64
Batch: 580; loss: 1.24; acc: 0.7
Batch: 600; loss: 1.06; acc: 0.7
Batch: 620; loss: 1.35; acc: 0.61
Batch: 640; loss: 0.98; acc: 0.64
Batch: 660; loss: 1.33; acc: 0.5
Batch: 680; loss: 0.88; acc: 0.7
Batch: 700; loss: 1.12; acc: 0.62
Batch: 720; loss: 1.3; acc: 0.56
Batch: 740; loss: 0.76; acc: 0.75
Batch: 760; loss: 0.93; acc: 0.7
Batch: 780; loss: 1.04; acc: 0.69
Train Epoch over. train_loss: 1.37; train_accuracy: 0.58 

2.4522270905436017e-05
1.4197842574503738e-05
Batch: 0; loss: 1.11; acc: 0.64
Batch: 20; loss: 1.23; acc: 0.58
Batch: 40; loss: 0.61; acc: 0.88
Batch: 60; loss: 1.06; acc: 0.64
Batch: 80; loss: 0.86; acc: 0.69
Batch: 100; loss: 1.2; acc: 0.61
Batch: 120; loss: 1.32; acc: 0.61
Batch: 140; loss: 0.96; acc: 0.67
Val Epoch over. val_loss: 1.0227224948299918; val_accuracy: 0.6721735668789809 

The current subspace-distance is: 1.4197842574503738e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.07; acc: 0.67
Batch: 20; loss: 0.91; acc: 0.69
Batch: 40; loss: 1.06; acc: 0.64
Batch: 60; loss: 1.05; acc: 0.67
Batch: 80; loss: 0.88; acc: 0.75
Batch: 100; loss: 1.08; acc: 0.58
Batch: 120; loss: 1.12; acc: 0.62
Batch: 140; loss: 1.06; acc: 0.69
Batch: 160; loss: 0.99; acc: 0.67
Batch: 180; loss: 0.99; acc: 0.64
Batch: 200; loss: 0.94; acc: 0.72
Batch: 220; loss: 1.06; acc: 0.58
Batch: 240; loss: 1.28; acc: 0.62
Batch: 260; loss: 0.92; acc: 0.67
Batch: 280; loss: 0.96; acc: 0.7
Batch: 300; loss: 0.82; acc: 0.75
Batch: 320; loss: 0.71; acc: 0.77
Batch: 340; loss: 1.11; acc: 0.7
Batch: 360; loss: 1.04; acc: 0.69
Batch: 380; loss: 1.02; acc: 0.64
Batch: 400; loss: 0.75; acc: 0.77
Batch: 420; loss: 1.03; acc: 0.64
Batch: 440; loss: 1.04; acc: 0.7
Batch: 460; loss: 1.3; acc: 0.48
Batch: 480; loss: 1.09; acc: 0.64
Batch: 500; loss: 0.75; acc: 0.8
Batch: 520; loss: 1.34; acc: 0.55
Batch: 540; loss: 1.02; acc: 0.69
Batch: 560; loss: 0.82; acc: 0.72
Batch: 580; loss: 0.99; acc: 0.69
Batch: 600; loss: 0.89; acc: 0.72
Batch: 620; loss: 0.99; acc: 0.7
Batch: 640; loss: 0.94; acc: 0.67
Batch: 660; loss: 1.04; acc: 0.77
Batch: 680; loss: 0.79; acc: 0.78
Batch: 700; loss: 0.9; acc: 0.7
Batch: 720; loss: 0.97; acc: 0.67
Batch: 740; loss: 0.87; acc: 0.73
Batch: 760; loss: 1.15; acc: 0.59
Batch: 780; loss: 0.83; acc: 0.72
Train Epoch over. train_loss: 0.97; train_accuracy: 0.68 

2.9235245165182278e-05
1.548160071251914e-05
Batch: 0; loss: 0.95; acc: 0.7
Batch: 20; loss: 1.22; acc: 0.59
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.89; acc: 0.7
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 1.17; acc: 0.61
Batch: 120; loss: 1.21; acc: 0.66
Batch: 140; loss: 0.69; acc: 0.83
Val Epoch over. val_loss: 0.8676452224801301; val_accuracy: 0.7249203821656051 

The current subspace-distance is: 1.548160071251914e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.86; acc: 0.67
Batch: 20; loss: 0.68; acc: 0.77
Batch: 40; loss: 1.0; acc: 0.61
Batch: 60; loss: 0.86; acc: 0.75
Batch: 80; loss: 1.06; acc: 0.7
Batch: 100; loss: 0.85; acc: 0.8
Batch: 120; loss: 1.02; acc: 0.69
Batch: 140; loss: 0.99; acc: 0.64
Batch: 160; loss: 0.84; acc: 0.69
Batch: 180; loss: 0.75; acc: 0.75
Batch: 200; loss: 0.58; acc: 0.81
Batch: 220; loss: 0.75; acc: 0.77
Batch: 240; loss: 1.05; acc: 0.67
Batch: 260; loss: 1.38; acc: 0.55
Batch: 280; loss: 0.62; acc: 0.78
Batch: 300; loss: 0.92; acc: 0.7
Batch: 320; loss: 1.07; acc: 0.69
Batch: 340; loss: 1.1; acc: 0.69
Batch: 360; loss: 0.96; acc: 0.73
Batch: 380; loss: 1.28; acc: 0.67
Batch: 400; loss: 0.75; acc: 0.78
Batch: 420; loss: 0.95; acc: 0.69
Batch: 440; loss: 0.94; acc: 0.67
Batch: 460; loss: 0.94; acc: 0.72
Batch: 480; loss: 1.0; acc: 0.69
Batch: 500; loss: 1.02; acc: 0.67
Batch: 520; loss: 1.01; acc: 0.73
Batch: 540; loss: 0.81; acc: 0.8
Batch: 560; loss: 0.91; acc: 0.7
Batch: 580; loss: 0.86; acc: 0.72
Batch: 600; loss: 1.05; acc: 0.66
Batch: 620; loss: 0.97; acc: 0.75
Batch: 640; loss: 1.22; acc: 0.67
Batch: 660; loss: 0.85; acc: 0.7
Batch: 680; loss: 0.83; acc: 0.75
Batch: 700; loss: 0.83; acc: 0.72
Batch: 720; loss: 0.88; acc: 0.73
Batch: 740; loss: 0.95; acc: 0.72
Batch: 760; loss: 0.86; acc: 0.78
Batch: 780; loss: 0.91; acc: 0.64
Train Epoch over. train_loss: 0.89; train_accuracy: 0.71 

3.0091039661783725e-05
1.957895074156113e-05
Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 1.21; acc: 0.59
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.72
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 1.12; acc: 0.67
Batch: 120; loss: 1.14; acc: 0.67
Batch: 140; loss: 0.59; acc: 0.84
Val Epoch over. val_loss: 0.8089824772564469; val_accuracy: 0.7428343949044586 

The current subspace-distance is: 1.957895074156113e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.72
Batch: 20; loss: 0.89; acc: 0.73
Batch: 40; loss: 0.79; acc: 0.78
Batch: 60; loss: 0.71; acc: 0.81
Batch: 80; loss: 0.85; acc: 0.73
Batch: 100; loss: 0.76; acc: 0.78
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.84; acc: 0.67
Batch: 160; loss: 0.87; acc: 0.72
Batch: 180; loss: 0.83; acc: 0.7
Batch: 200; loss: 0.8; acc: 0.72
Batch: 220; loss: 0.91; acc: 0.69
Batch: 240; loss: 0.67; acc: 0.8
Batch: 260; loss: 1.12; acc: 0.66
Batch: 280; loss: 0.78; acc: 0.73
Batch: 300; loss: 0.88; acc: 0.69
Batch: 320; loss: 0.7; acc: 0.81
Batch: 340; loss: 0.68; acc: 0.81
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 1.19; acc: 0.62
Batch: 400; loss: 0.76; acc: 0.72
Batch: 420; loss: 0.58; acc: 0.77
Batch: 440; loss: 0.98; acc: 0.73
Batch: 460; loss: 0.81; acc: 0.78
Batch: 480; loss: 0.9; acc: 0.66
Batch: 500; loss: 1.01; acc: 0.7
Batch: 520; loss: 0.75; acc: 0.77
Batch: 540; loss: 0.66; acc: 0.8
Batch: 560; loss: 0.81; acc: 0.73
Batch: 580; loss: 0.7; acc: 0.8
Batch: 600; loss: 0.73; acc: 0.8
Batch: 620; loss: 0.96; acc: 0.67
Batch: 640; loss: 0.9; acc: 0.69
Batch: 660; loss: 0.85; acc: 0.67
Batch: 680; loss: 1.29; acc: 0.58
Batch: 700; loss: 0.68; acc: 0.78
Batch: 720; loss: 0.79; acc: 0.72
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.92; acc: 0.7
Batch: 780; loss: 0.7; acc: 0.73
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

2.9781049306620844e-05
1.705259819573257e-05
Batch: 0; loss: 0.85; acc: 0.7
Batch: 20; loss: 1.18; acc: 0.67
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 1.1; acc: 0.73
Batch: 120; loss: 1.12; acc: 0.67
Batch: 140; loss: 0.54; acc: 0.83
Val Epoch over. val_loss: 0.7845082552569687; val_accuracy: 0.7482085987261147 

The current subspace-distance is: 1.705259819573257e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.77
Batch: 20; loss: 0.76; acc: 0.78
Batch: 40; loss: 0.87; acc: 0.67
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 0.65; acc: 0.83
Batch: 100; loss: 0.89; acc: 0.73
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.92; acc: 0.73
Batch: 160; loss: 0.79; acc: 0.78
Batch: 180; loss: 0.86; acc: 0.7
Batch: 200; loss: 0.71; acc: 0.77
Batch: 220; loss: 0.65; acc: 0.73
Batch: 240; loss: 0.75; acc: 0.7
Batch: 260; loss: 0.9; acc: 0.72
Batch: 280; loss: 0.7; acc: 0.77
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.71; acc: 0.8
Batch: 340; loss: 0.92; acc: 0.73
Batch: 360; loss: 0.73; acc: 0.78
Batch: 380; loss: 0.9; acc: 0.77
Batch: 400; loss: 0.74; acc: 0.75
Batch: 420; loss: 0.82; acc: 0.75
Batch: 440; loss: 0.72; acc: 0.77
Batch: 460; loss: 0.72; acc: 0.78
Batch: 480; loss: 0.73; acc: 0.78
Batch: 500; loss: 0.74; acc: 0.8
Batch: 520; loss: 1.08; acc: 0.69
Batch: 540; loss: 0.89; acc: 0.75
Batch: 560; loss: 0.73; acc: 0.78
Batch: 580; loss: 0.84; acc: 0.75
Batch: 600; loss: 0.95; acc: 0.73
Batch: 620; loss: 0.79; acc: 0.75
Batch: 640; loss: 0.68; acc: 0.73
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 0.64; acc: 0.78
Batch: 700; loss: 1.2; acc: 0.66
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.81; acc: 0.69
Batch: 760; loss: 0.7; acc: 0.81
Batch: 780; loss: 0.74; acc: 0.75
Train Epoch over. train_loss: 0.83; train_accuracy: 0.73 

3.2490253943251446e-05
1.962617716344539e-05
Batch: 0; loss: 0.83; acc: 0.72
Batch: 20; loss: 1.14; acc: 0.66
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 1.1; acc: 0.77
Batch: 120; loss: 1.14; acc: 0.62
Batch: 140; loss: 0.52; acc: 0.84
Val Epoch over. val_loss: 0.767771068462141; val_accuracy: 0.7580613057324841 

The current subspace-distance is: 1.962617716344539e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.96; acc: 0.72
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.9; acc: 0.72
Batch: 60; loss: 0.82; acc: 0.69
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.73; acc: 0.73
Batch: 120; loss: 0.89; acc: 0.72
Batch: 140; loss: 0.68; acc: 0.75
Batch: 160; loss: 0.75; acc: 0.75
Batch: 180; loss: 0.72; acc: 0.73
Batch: 200; loss: 0.83; acc: 0.75
Batch: 220; loss: 1.05; acc: 0.7
Batch: 240; loss: 0.88; acc: 0.73
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.71; acc: 0.75
Batch: 300; loss: 0.81; acc: 0.69
Batch: 320; loss: 0.81; acc: 0.77
Batch: 340; loss: 0.81; acc: 0.7
Batch: 360; loss: 0.85; acc: 0.73
Batch: 380; loss: 0.72; acc: 0.83
Batch: 400; loss: 1.12; acc: 0.66
Batch: 420; loss: 1.06; acc: 0.7
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.81; acc: 0.78
Batch: 480; loss: 0.83; acc: 0.75
Batch: 500; loss: 0.87; acc: 0.73
Batch: 520; loss: 0.78; acc: 0.8
Batch: 540; loss: 0.98; acc: 0.77
Batch: 560; loss: 0.72; acc: 0.83
Batch: 580; loss: 0.67; acc: 0.77
Batch: 600; loss: 0.81; acc: 0.75
Batch: 620; loss: 1.0; acc: 0.69
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.81; acc: 0.75
Batch: 680; loss: 1.14; acc: 0.62
Batch: 700; loss: 0.7; acc: 0.67
Batch: 720; loss: 0.93; acc: 0.7
Batch: 740; loss: 1.13; acc: 0.69
Batch: 760; loss: 0.89; acc: 0.7
Batch: 780; loss: 0.71; acc: 0.75
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

3.2247044146060944e-05
1.830524706747383e-05
Batch: 0; loss: 0.84; acc: 0.72
Batch: 20; loss: 1.1; acc: 0.67
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.78; acc: 0.78
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 1.08; acc: 0.78
Batch: 120; loss: 1.14; acc: 0.62
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.7561134789020393; val_accuracy: 0.7623407643312102 

The current subspace-distance is: 1.830524706747383e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.78
Batch: 20; loss: 0.92; acc: 0.7
Batch: 40; loss: 0.92; acc: 0.7
Batch: 60; loss: 0.87; acc: 0.69
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 1.02; acc: 0.62
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 1.27; acc: 0.69
Batch: 180; loss: 0.95; acc: 0.7
Batch: 200; loss: 0.74; acc: 0.73
Batch: 220; loss: 0.63; acc: 0.84
Batch: 240; loss: 0.89; acc: 0.8
Batch: 260; loss: 0.84; acc: 0.77
Batch: 280; loss: 0.56; acc: 0.86
Batch: 300; loss: 0.7; acc: 0.77
Batch: 320; loss: 0.77; acc: 0.72
Batch: 340; loss: 1.0; acc: 0.73
Batch: 360; loss: 0.75; acc: 0.75
Batch: 380; loss: 0.69; acc: 0.8
Batch: 400; loss: 1.06; acc: 0.58
Batch: 420; loss: 1.0; acc: 0.66
Batch: 440; loss: 0.84; acc: 0.67
Batch: 460; loss: 1.02; acc: 0.73
Batch: 480; loss: 1.04; acc: 0.64
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.69; acc: 0.81
Batch: 540; loss: 1.08; acc: 0.66
Batch: 560; loss: 0.68; acc: 0.78
Batch: 580; loss: 0.65; acc: 0.78
Batch: 600; loss: 0.64; acc: 0.77
Batch: 620; loss: 0.8; acc: 0.72
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.86; acc: 0.69
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 0.7; acc: 0.81
Batch: 740; loss: 0.74; acc: 0.75
Batch: 760; loss: 0.76; acc: 0.77
Batch: 780; loss: 0.8; acc: 0.67
Train Epoch over. train_loss: 0.81; train_accuracy: 0.74 

3.307215592940338e-05
1.9044027794734575e-05
Batch: 0; loss: 0.83; acc: 0.72
Batch: 20; loss: 1.09; acc: 0.64
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.76; acc: 0.8
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 1.04; acc: 0.78
Batch: 120; loss: 1.16; acc: 0.64
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.7499645481443709; val_accuracy: 0.7668192675159236 

The current subspace-distance is: 1.9044027794734575e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.73; acc: 0.73
Batch: 40; loss: 0.72; acc: 0.73
Batch: 60; loss: 0.87; acc: 0.78
Batch: 80; loss: 0.95; acc: 0.72
Batch: 100; loss: 0.95; acc: 0.69
Batch: 120; loss: 0.56; acc: 0.77
Batch: 140; loss: 0.59; acc: 0.81
Batch: 160; loss: 0.74; acc: 0.77
Batch: 180; loss: 0.75; acc: 0.78
Batch: 200; loss: 0.89; acc: 0.73
Batch: 220; loss: 1.06; acc: 0.69
Batch: 240; loss: 0.82; acc: 0.72
Batch: 260; loss: 1.13; acc: 0.69
Batch: 280; loss: 0.83; acc: 0.78
Batch: 300; loss: 0.92; acc: 0.67
Batch: 320; loss: 0.81; acc: 0.75
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.79; acc: 0.72
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.53; acc: 0.88
Batch: 420; loss: 0.71; acc: 0.81
Batch: 440; loss: 0.92; acc: 0.7
Batch: 460; loss: 0.48; acc: 0.83
Batch: 480; loss: 0.83; acc: 0.72
Batch: 500; loss: 0.57; acc: 0.78
Batch: 520; loss: 0.83; acc: 0.73
Batch: 540; loss: 0.97; acc: 0.7
Batch: 560; loss: 0.74; acc: 0.7
Batch: 580; loss: 0.88; acc: 0.77
Batch: 600; loss: 0.74; acc: 0.8
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.79; acc: 0.72
Batch: 680; loss: 0.79; acc: 0.72
Batch: 700; loss: 0.8; acc: 0.73
Batch: 720; loss: 0.8; acc: 0.7
Batch: 740; loss: 0.97; acc: 0.77
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 1.09; acc: 0.69
Train Epoch over. train_loss: 0.8; train_accuracy: 0.74 

3.096265209023841e-05
1.848225474532228e-05
Batch: 0; loss: 0.83; acc: 0.67
Batch: 20; loss: 1.08; acc: 0.66
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.76; acc: 0.78
Batch: 80; loss: 0.47; acc: 0.81
Batch: 100; loss: 1.04; acc: 0.77
Batch: 120; loss: 1.16; acc: 0.61
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.7432545239378692; val_accuracy: 0.7652269108280255 

The current subspace-distance is: 1.848225474532228e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.61; acc: 0.78
Batch: 60; loss: 0.75; acc: 0.75
Batch: 80; loss: 0.64; acc: 0.83
Batch: 100; loss: 0.76; acc: 0.7
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.98; acc: 0.73
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.64; acc: 0.81
Batch: 200; loss: 0.9; acc: 0.75
Batch: 220; loss: 1.1; acc: 0.62
Batch: 240; loss: 0.7; acc: 0.77
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 0.94; acc: 0.75
Batch: 300; loss: 1.11; acc: 0.61
Batch: 320; loss: 0.89; acc: 0.72
Batch: 340; loss: 0.75; acc: 0.73
Batch: 360; loss: 0.59; acc: 0.8
Batch: 380; loss: 0.6; acc: 0.78
Batch: 400; loss: 0.59; acc: 0.73
Batch: 420; loss: 0.78; acc: 0.78
Batch: 440; loss: 0.84; acc: 0.75
Batch: 460; loss: 0.83; acc: 0.72
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.85; acc: 0.72
Batch: 520; loss: 0.77; acc: 0.73
Batch: 540; loss: 0.89; acc: 0.7
Batch: 560; loss: 0.81; acc: 0.78
Batch: 580; loss: 0.68; acc: 0.78
Batch: 600; loss: 1.0; acc: 0.62
Batch: 620; loss: 0.93; acc: 0.69
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.63; acc: 0.75
Batch: 680; loss: 0.99; acc: 0.7
Batch: 700; loss: 0.65; acc: 0.77
Batch: 720; loss: 0.45; acc: 0.89
Batch: 740; loss: 0.73; acc: 0.78
Batch: 760; loss: 0.71; acc: 0.8
Batch: 780; loss: 0.73; acc: 0.78
Train Epoch over. train_loss: 0.8; train_accuracy: 0.74 

3.35102085955441e-05
1.9375496776774526e-05
Batch: 0; loss: 0.82; acc: 0.73
Batch: 20; loss: 1.1; acc: 0.62
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.49; acc: 0.83
Batch: 100; loss: 1.02; acc: 0.75
Batch: 120; loss: 1.22; acc: 0.62
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.7421946745769233; val_accuracy: 0.7647292993630573 

The current subspace-distance is: 1.9375496776774526e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.87; acc: 0.69
Batch: 40; loss: 0.76; acc: 0.72
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.76; acc: 0.8
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.89; acc: 0.72
Batch: 160; loss: 0.86; acc: 0.7
Batch: 180; loss: 0.61; acc: 0.78
Batch: 200; loss: 0.77; acc: 0.73
Batch: 220; loss: 0.87; acc: 0.73
Batch: 240; loss: 0.73; acc: 0.77
Batch: 260; loss: 1.14; acc: 0.62
Batch: 280; loss: 0.77; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.81
Batch: 320; loss: 0.83; acc: 0.78
Batch: 340; loss: 0.8; acc: 0.75
Batch: 360; loss: 0.66; acc: 0.75
Batch: 380; loss: 0.82; acc: 0.77
Batch: 400; loss: 0.81; acc: 0.75
Batch: 420; loss: 0.68; acc: 0.83
Batch: 440; loss: 0.8; acc: 0.75
Batch: 460; loss: 0.75; acc: 0.73
Batch: 480; loss: 0.83; acc: 0.7
Batch: 500; loss: 0.92; acc: 0.7
Batch: 520; loss: 0.75; acc: 0.8
Batch: 540; loss: 0.73; acc: 0.75
Batch: 560; loss: 1.0; acc: 0.67
Batch: 580; loss: 0.69; acc: 0.81
Batch: 600; loss: 0.79; acc: 0.69
Batch: 620; loss: 1.11; acc: 0.73
Batch: 640; loss: 0.84; acc: 0.67
Batch: 660; loss: 0.81; acc: 0.83
Batch: 680; loss: 0.72; acc: 0.78
Batch: 700; loss: 0.74; acc: 0.73
Batch: 720; loss: 0.91; acc: 0.66
Batch: 740; loss: 0.7; acc: 0.77
Batch: 760; loss: 0.67; acc: 0.78
Batch: 780; loss: 1.19; acc: 0.64
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

3.302805998828262e-05
1.8318409274797887e-05
Batch: 0; loss: 0.81; acc: 0.72
Batch: 20; loss: 1.07; acc: 0.64
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 1.01; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.736937802878155; val_accuracy: 0.7684116242038217 

The current subspace-distance is: 1.8318409274797887e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.66; acc: 0.84
Batch: 20; loss: 0.65; acc: 0.83
Batch: 40; loss: 0.77; acc: 0.77
Batch: 60; loss: 0.85; acc: 0.69
Batch: 80; loss: 0.62; acc: 0.84
Batch: 100; loss: 0.87; acc: 0.73
Batch: 120; loss: 0.8; acc: 0.7
Batch: 140; loss: 1.0; acc: 0.67
Batch: 160; loss: 0.79; acc: 0.72
Batch: 180; loss: 0.6; acc: 0.83
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.86; acc: 0.77
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.89; acc: 0.73
Batch: 280; loss: 0.85; acc: 0.7
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.79; acc: 0.72
Batch: 360; loss: 0.8; acc: 0.66
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.97; acc: 0.69
Batch: 420; loss: 0.67; acc: 0.77
Batch: 440; loss: 0.69; acc: 0.8
Batch: 460; loss: 0.73; acc: 0.78
Batch: 480; loss: 0.99; acc: 0.67
Batch: 500; loss: 0.78; acc: 0.72
Batch: 520; loss: 0.7; acc: 0.81
Batch: 540; loss: 0.86; acc: 0.69
Batch: 560; loss: 0.73; acc: 0.78
Batch: 580; loss: 0.85; acc: 0.69
Batch: 600; loss: 0.74; acc: 0.73
Batch: 620; loss: 0.7; acc: 0.75
Batch: 640; loss: 0.87; acc: 0.69
Batch: 660; loss: 0.78; acc: 0.77
Batch: 680; loss: 0.9; acc: 0.7
Batch: 700; loss: 0.84; acc: 0.7
Batch: 720; loss: 0.87; acc: 0.69
Batch: 740; loss: 0.75; acc: 0.78
Batch: 760; loss: 1.01; acc: 0.72
Batch: 780; loss: 0.8; acc: 0.69
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

3.305319114588201e-05
1.849898399086669e-05
Batch: 0; loss: 0.81; acc: 0.7
Batch: 20; loss: 1.08; acc: 0.62
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.74; acc: 0.77
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 1.01; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.61
Batch: 140; loss: 0.44; acc: 0.84
Val Epoch over. val_loss: 0.735711408838345; val_accuracy: 0.7680135350318471 

The current subspace-distance is: 1.849898399086669e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.96; acc: 0.72
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.69; acc: 0.75
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.71; acc: 0.72
Batch: 100; loss: 1.12; acc: 0.67
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.95; acc: 0.77
Batch: 160; loss: 0.72; acc: 0.78
Batch: 180; loss: 0.53; acc: 0.8
Batch: 200; loss: 0.75; acc: 0.8
Batch: 220; loss: 0.97; acc: 0.67
Batch: 240; loss: 0.85; acc: 0.67
Batch: 260; loss: 0.83; acc: 0.7
Batch: 280; loss: 0.58; acc: 0.81
Batch: 300; loss: 0.69; acc: 0.86
Batch: 320; loss: 0.92; acc: 0.7
Batch: 340; loss: 0.45; acc: 0.83
Batch: 360; loss: 0.6; acc: 0.77
Batch: 380; loss: 0.83; acc: 0.81
Batch: 400; loss: 0.89; acc: 0.67
Batch: 420; loss: 0.67; acc: 0.81
Batch: 440; loss: 1.08; acc: 0.66
Batch: 460; loss: 0.74; acc: 0.75
Batch: 480; loss: 0.82; acc: 0.77
Batch: 500; loss: 0.56; acc: 0.81
Batch: 520; loss: 1.02; acc: 0.72
Batch: 540; loss: 0.87; acc: 0.78
Batch: 560; loss: 0.78; acc: 0.77
Batch: 580; loss: 0.69; acc: 0.78
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.84; acc: 0.8
Batch: 640; loss: 0.68; acc: 0.78
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.9; acc: 0.7
Batch: 700; loss: 0.8; acc: 0.8
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.66; acc: 0.8
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.95; acc: 0.66
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

3.201716026524082e-05
1.872211396403145e-05
Batch: 0; loss: 0.81; acc: 0.72
Batch: 20; loss: 1.08; acc: 0.62
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.75; acc: 0.75
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 1.01; acc: 0.75
Batch: 120; loss: 1.22; acc: 0.61
Batch: 140; loss: 0.43; acc: 0.84
Val Epoch over. val_loss: 0.7349461364518305; val_accuracy: 0.7691082802547771 

The current subspace-distance is: 1.872211396403145e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.79; acc: 0.78
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.71; acc: 0.77
Batch: 60; loss: 1.0; acc: 0.64
Batch: 80; loss: 0.84; acc: 0.67
Batch: 100; loss: 0.98; acc: 0.7
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.73; acc: 0.8
Batch: 160; loss: 0.87; acc: 0.77
Batch: 180; loss: 0.77; acc: 0.8
Batch: 200; loss: 0.92; acc: 0.75
Batch: 220; loss: 0.57; acc: 0.83
Batch: 240; loss: 0.67; acc: 0.73
Batch: 260; loss: 0.84; acc: 0.77
Batch: 280; loss: 0.65; acc: 0.8
Batch: 300; loss: 0.69; acc: 0.75
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.8; acc: 0.73
Batch: 380; loss: 0.83; acc: 0.73
Batch: 400; loss: 0.91; acc: 0.7
Batch: 420; loss: 0.7; acc: 0.73
Batch: 440; loss: 0.51; acc: 0.8
Batch: 460; loss: 0.6; acc: 0.78
Batch: 480; loss: 1.15; acc: 0.73
Batch: 500; loss: 1.0; acc: 0.7
Batch: 520; loss: 0.56; acc: 0.83
Batch: 540; loss: 0.71; acc: 0.73
Batch: 560; loss: 0.99; acc: 0.62
Batch: 580; loss: 1.02; acc: 0.64
Batch: 600; loss: 0.69; acc: 0.8
Batch: 620; loss: 0.77; acc: 0.7
Batch: 640; loss: 0.8; acc: 0.73
Batch: 660; loss: 0.76; acc: 0.75
Batch: 680; loss: 0.65; acc: 0.78
Batch: 700; loss: 0.82; acc: 0.7
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.73; acc: 0.75
Batch: 760; loss: 0.68; acc: 0.77
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

3.314240530016832e-05
1.767474168445915e-05
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 1.07; acc: 0.66
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 1.01; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.61
Batch: 140; loss: 0.43; acc: 0.84
Val Epoch over. val_loss: 0.7336090114086297; val_accuracy: 0.7684116242038217 

The current subspace-distance is: 1.767474168445915e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.69; acc: 0.75
Batch: 60; loss: 0.67; acc: 0.75
Batch: 80; loss: 0.54; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.79; acc: 0.69
Batch: 160; loss: 0.74; acc: 0.75
Batch: 180; loss: 0.67; acc: 0.78
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.92; acc: 0.67
Batch: 240; loss: 0.58; acc: 0.84
Batch: 260; loss: 0.75; acc: 0.8
Batch: 280; loss: 0.83; acc: 0.72
Batch: 300; loss: 0.82; acc: 0.72
Batch: 320; loss: 0.66; acc: 0.81
Batch: 340; loss: 0.8; acc: 0.75
Batch: 360; loss: 1.09; acc: 0.61
Batch: 380; loss: 0.78; acc: 0.73
Batch: 400; loss: 1.18; acc: 0.7
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.6; acc: 0.73
Batch: 460; loss: 0.82; acc: 0.7
Batch: 480; loss: 0.85; acc: 0.66
Batch: 500; loss: 0.86; acc: 0.7
Batch: 520; loss: 0.91; acc: 0.7
Batch: 540; loss: 0.69; acc: 0.8
Batch: 560; loss: 0.65; acc: 0.8
Batch: 580; loss: 0.84; acc: 0.72
Batch: 600; loss: 0.88; acc: 0.67
Batch: 620; loss: 0.65; acc: 0.77
Batch: 640; loss: 0.92; acc: 0.72
Batch: 660; loss: 1.02; acc: 0.67
Batch: 680; loss: 0.69; acc: 0.78
Batch: 700; loss: 0.91; acc: 0.72
Batch: 720; loss: 0.88; acc: 0.73
Batch: 740; loss: 0.83; acc: 0.75
Batch: 760; loss: 0.8; acc: 0.73
Batch: 780; loss: 0.6; acc: 0.77
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.289077722001821e-05
1.7946167645277455e-05
Batch: 0; loss: 0.8; acc: 0.72
Batch: 20; loss: 1.08; acc: 0.64
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.99; acc: 0.77
Batch: 120; loss: 1.22; acc: 0.62
Batch: 140; loss: 0.42; acc: 0.86
Val Epoch over. val_loss: 0.7331862183892803; val_accuracy: 0.7689092356687898 

The current subspace-distance is: 1.7946167645277455e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.75
Batch: 20; loss: 0.92; acc: 0.77
Batch: 40; loss: 0.75; acc: 0.75
Batch: 60; loss: 0.87; acc: 0.7
Batch: 80; loss: 0.66; acc: 0.83
Batch: 100; loss: 0.94; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.69
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.71; acc: 0.78
Batch: 180; loss: 0.56; acc: 0.78
Batch: 200; loss: 0.76; acc: 0.72
Batch: 220; loss: 0.92; acc: 0.72
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 1.03; acc: 0.7
Batch: 280; loss: 0.92; acc: 0.69
Batch: 300; loss: 0.72; acc: 0.8
Batch: 320; loss: 1.1; acc: 0.66
Batch: 340; loss: 1.02; acc: 0.7
Batch: 360; loss: 1.01; acc: 0.69
Batch: 380; loss: 0.72; acc: 0.73
Batch: 400; loss: 1.17; acc: 0.69
Batch: 420; loss: 1.0; acc: 0.69
Batch: 440; loss: 0.93; acc: 0.73
Batch: 460; loss: 0.71; acc: 0.75
Batch: 480; loss: 0.67; acc: 0.83
Batch: 500; loss: 0.71; acc: 0.81
Batch: 520; loss: 0.82; acc: 0.73
Batch: 540; loss: 0.67; acc: 0.78
Batch: 560; loss: 0.69; acc: 0.73
Batch: 580; loss: 0.75; acc: 0.78
Batch: 600; loss: 0.76; acc: 0.73
Batch: 620; loss: 0.74; acc: 0.77
Batch: 640; loss: 0.75; acc: 0.75
Batch: 660; loss: 0.77; acc: 0.8
Batch: 680; loss: 0.99; acc: 0.62
Batch: 700; loss: 0.76; acc: 0.72
Batch: 720; loss: 0.67; acc: 0.8
Batch: 740; loss: 0.6; acc: 0.83
Batch: 760; loss: 0.76; acc: 0.78
Batch: 780; loss: 0.77; acc: 0.7
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.243543687858619e-05
1.6359186702175066e-05
Batch: 0; loss: 0.79; acc: 0.69
Batch: 20; loss: 1.07; acc: 0.67
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.99; acc: 0.77
Batch: 120; loss: 1.22; acc: 0.61
Batch: 140; loss: 0.42; acc: 0.86
Val Epoch over. val_loss: 0.7317908081659086; val_accuracy: 0.7692078025477707 

The current subspace-distance is: 1.6359186702175066e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.64; acc: 0.8
Batch: 80; loss: 0.68; acc: 0.84
Batch: 100; loss: 0.65; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.84
Batch: 140; loss: 0.74; acc: 0.83
Batch: 160; loss: 0.78; acc: 0.7
Batch: 180; loss: 0.83; acc: 0.7
Batch: 200; loss: 1.01; acc: 0.66
Batch: 220; loss: 0.76; acc: 0.7
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.92; acc: 0.72
Batch: 300; loss: 0.65; acc: 0.81
Batch: 320; loss: 0.88; acc: 0.73
Batch: 340; loss: 0.91; acc: 0.73
Batch: 360; loss: 0.84; acc: 0.7
Batch: 380; loss: 0.67; acc: 0.77
Batch: 400; loss: 0.72; acc: 0.73
Batch: 420; loss: 0.82; acc: 0.73
Batch: 440; loss: 0.66; acc: 0.75
Batch: 460; loss: 0.83; acc: 0.73
Batch: 480; loss: 0.81; acc: 0.75
Batch: 500; loss: 0.58; acc: 0.78
Batch: 520; loss: 0.83; acc: 0.73
Batch: 540; loss: 0.88; acc: 0.69
Batch: 560; loss: 0.87; acc: 0.73
Batch: 580; loss: 0.84; acc: 0.83
Batch: 600; loss: 0.8; acc: 0.8
Batch: 620; loss: 0.73; acc: 0.69
Batch: 640; loss: 0.67; acc: 0.73
Batch: 660; loss: 0.71; acc: 0.77
Batch: 680; loss: 0.83; acc: 0.73
Batch: 700; loss: 0.89; acc: 0.69
Batch: 720; loss: 1.01; acc: 0.67
Batch: 740; loss: 0.68; acc: 0.8
Batch: 760; loss: 0.88; acc: 0.7
Batch: 780; loss: 0.91; acc: 0.7
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.209297938155942e-05
1.867546779976692e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.06; acc: 0.67
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.99; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.61
Batch: 140; loss: 0.42; acc: 0.86
Val Epoch over. val_loss: 0.7312817919026514; val_accuracy: 0.7690087579617835 

The current subspace-distance is: 1.867546779976692e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.85; acc: 0.72
Batch: 40; loss: 0.89; acc: 0.72
Batch: 60; loss: 0.77; acc: 0.72
Batch: 80; loss: 0.72; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.94; acc: 0.72
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.82; acc: 0.75
Batch: 200; loss: 1.01; acc: 0.7
Batch: 220; loss: 0.79; acc: 0.77
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 1.17; acc: 0.7
Batch: 280; loss: 0.87; acc: 0.67
Batch: 300; loss: 0.63; acc: 0.81
Batch: 320; loss: 0.53; acc: 0.8
Batch: 340; loss: 0.72; acc: 0.78
Batch: 360; loss: 0.76; acc: 0.75
Batch: 380; loss: 0.74; acc: 0.77
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.87; acc: 0.8
Batch: 440; loss: 0.84; acc: 0.7
Batch: 460; loss: 0.78; acc: 0.72
Batch: 480; loss: 0.44; acc: 0.83
Batch: 500; loss: 0.86; acc: 0.75
Batch: 520; loss: 0.99; acc: 0.69
Batch: 540; loss: 0.82; acc: 0.75
Batch: 560; loss: 0.79; acc: 0.73
Batch: 580; loss: 0.81; acc: 0.81
Batch: 600; loss: 0.83; acc: 0.72
Batch: 620; loss: 0.73; acc: 0.81
Batch: 640; loss: 0.92; acc: 0.73
Batch: 660; loss: 0.61; acc: 0.83
Batch: 680; loss: 1.21; acc: 0.72
Batch: 700; loss: 0.76; acc: 0.78
Batch: 720; loss: 0.65; acc: 0.81
Batch: 740; loss: 0.59; acc: 0.78
Batch: 760; loss: 0.82; acc: 0.75
Batch: 780; loss: 0.84; acc: 0.75
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.230876609450206e-05
1.9105827959720045e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.06; acc: 0.66
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.75; acc: 0.75
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.98; acc: 0.75
Batch: 120; loss: 1.23; acc: 0.64
Batch: 140; loss: 0.41; acc: 0.89
Val Epoch over. val_loss: 0.7326254427053367; val_accuracy: 0.7676154458598726 

The current subspace-distance is: 1.9105827959720045e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 0.63; acc: 0.72
Batch: 40; loss: 0.69; acc: 0.73
Batch: 60; loss: 0.68; acc: 0.84
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.58; acc: 0.8
Batch: 160; loss: 0.96; acc: 0.7
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.83; acc: 0.75
Batch: 240; loss: 0.83; acc: 0.77
Batch: 260; loss: 0.53; acc: 0.8
Batch: 280; loss: 0.81; acc: 0.73
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.79; acc: 0.7
Batch: 340; loss: 0.65; acc: 0.73
Batch: 360; loss: 0.71; acc: 0.77
Batch: 380; loss: 0.87; acc: 0.73
Batch: 400; loss: 1.2; acc: 0.58
Batch: 420; loss: 0.69; acc: 0.8
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.83; acc: 0.69
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.93; acc: 0.66
Batch: 520; loss: 0.77; acc: 0.77
Batch: 540; loss: 0.87; acc: 0.69
Batch: 560; loss: 1.02; acc: 0.56
Batch: 580; loss: 0.91; acc: 0.7
Batch: 600; loss: 0.79; acc: 0.72
Batch: 620; loss: 0.67; acc: 0.8
Batch: 640; loss: 1.02; acc: 0.72
Batch: 660; loss: 0.91; acc: 0.72
Batch: 680; loss: 0.82; acc: 0.77
Batch: 700; loss: 0.68; acc: 0.81
Batch: 720; loss: 0.59; acc: 0.86
Batch: 740; loss: 0.73; acc: 0.73
Batch: 760; loss: 0.79; acc: 0.78
Batch: 780; loss: 0.9; acc: 0.67
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.045877929253038e-05
1.9580806110752746e-05
Batch: 0; loss: 0.8; acc: 0.72
Batch: 20; loss: 1.07; acc: 0.66
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.98; acc: 0.75
Batch: 120; loss: 1.22; acc: 0.62
Batch: 140; loss: 0.4; acc: 0.88
Val Epoch over. val_loss: 0.7314485131175654; val_accuracy: 0.7674164012738853 

The current subspace-distance is: 1.9580806110752746e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 1.03; acc: 0.7
Batch: 120; loss: 0.8; acc: 0.69
Batch: 140; loss: 0.77; acc: 0.73
Batch: 160; loss: 0.68; acc: 0.78
Batch: 180; loss: 1.07; acc: 0.62
Batch: 200; loss: 0.65; acc: 0.84
Batch: 220; loss: 0.91; acc: 0.72
Batch: 240; loss: 0.63; acc: 0.83
Batch: 260; loss: 0.71; acc: 0.78
Batch: 280; loss: 0.73; acc: 0.72
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.73; acc: 0.8
Batch: 340; loss: 0.65; acc: 0.81
Batch: 360; loss: 0.53; acc: 0.88
Batch: 380; loss: 0.65; acc: 0.83
Batch: 400; loss: 0.82; acc: 0.73
Batch: 420; loss: 0.84; acc: 0.7
Batch: 440; loss: 0.75; acc: 0.7
Batch: 460; loss: 0.96; acc: 0.7
Batch: 480; loss: 0.79; acc: 0.75
Batch: 500; loss: 0.85; acc: 0.72
Batch: 520; loss: 0.9; acc: 0.73
Batch: 540; loss: 0.74; acc: 0.75
Batch: 560; loss: 0.89; acc: 0.64
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.68; acc: 0.77
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.96; acc: 0.73
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 0.68; acc: 0.8
Batch: 740; loss: 0.88; acc: 0.64
Batch: 760; loss: 0.95; acc: 0.67
Batch: 780; loss: 0.85; acc: 0.67
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.192295116605237e-05
1.821384284994565e-05
Batch: 0; loss: 0.78; acc: 0.72
Batch: 20; loss: 1.05; acc: 0.69
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.72; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.96; acc: 0.75
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.7290809164001684; val_accuracy: 0.7690087579617835 

The current subspace-distance is: 1.821384284994565e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.81; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.95; acc: 0.73
Batch: 60; loss: 0.87; acc: 0.72
Batch: 80; loss: 0.79; acc: 0.75
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.8; acc: 0.72
Batch: 160; loss: 0.73; acc: 0.78
Batch: 180; loss: 0.83; acc: 0.72
Batch: 200; loss: 0.89; acc: 0.72
Batch: 220; loss: 0.81; acc: 0.69
Batch: 240; loss: 1.06; acc: 0.53
Batch: 260; loss: 0.83; acc: 0.72
Batch: 280; loss: 0.76; acc: 0.72
Batch: 300; loss: 0.75; acc: 0.77
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.8; acc: 0.69
Batch: 360; loss: 0.62; acc: 0.78
Batch: 380; loss: 0.84; acc: 0.73
Batch: 400; loss: 0.84; acc: 0.73
Batch: 420; loss: 1.11; acc: 0.73
Batch: 440; loss: 0.94; acc: 0.75
Batch: 460; loss: 0.76; acc: 0.77
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.6; acc: 0.77
Batch: 520; loss: 0.59; acc: 0.88
Batch: 540; loss: 0.92; acc: 0.75
Batch: 560; loss: 0.93; acc: 0.7
Batch: 580; loss: 0.81; acc: 0.78
Batch: 600; loss: 0.94; acc: 0.72
Batch: 620; loss: 0.78; acc: 0.73
Batch: 640; loss: 0.8; acc: 0.73
Batch: 660; loss: 0.91; acc: 0.72
Batch: 680; loss: 0.89; acc: 0.7
Batch: 700; loss: 0.9; acc: 0.73
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.7; acc: 0.75
Batch: 780; loss: 0.95; acc: 0.72
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.315217691124417e-05
1.895808964036405e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.06; acc: 0.67
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.97; acc: 0.75
Batch: 120; loss: 1.22; acc: 0.62
Batch: 140; loss: 0.4; acc: 0.88
Val Epoch over. val_loss: 0.7290022371301226; val_accuracy: 0.7676154458598726 

The current subspace-distance is: 1.895808964036405e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.85; acc: 0.75
Batch: 20; loss: 0.9; acc: 0.67
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.71; acc: 0.75
Batch: 80; loss: 0.93; acc: 0.7
Batch: 100; loss: 0.87; acc: 0.73
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.9; acc: 0.7
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 0.69; acc: 0.73
Batch: 200; loss: 1.03; acc: 0.69
Batch: 220; loss: 0.62; acc: 0.78
Batch: 240; loss: 0.88; acc: 0.72
Batch: 260; loss: 0.91; acc: 0.72
Batch: 280; loss: 0.94; acc: 0.73
Batch: 300; loss: 0.84; acc: 0.78
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.76; acc: 0.8
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.73; acc: 0.73
Batch: 420; loss: 1.09; acc: 0.69
Batch: 440; loss: 0.66; acc: 0.83
Batch: 460; loss: 0.77; acc: 0.73
Batch: 480; loss: 0.75; acc: 0.73
Batch: 500; loss: 0.67; acc: 0.75
Batch: 520; loss: 0.77; acc: 0.78
Batch: 540; loss: 0.76; acc: 0.8
Batch: 560; loss: 0.84; acc: 0.7
Batch: 580; loss: 0.73; acc: 0.77
Batch: 600; loss: 0.51; acc: 0.88
Batch: 620; loss: 0.8; acc: 0.75
Batch: 640; loss: 0.82; acc: 0.77
Batch: 660; loss: 0.71; acc: 0.73
Batch: 680; loss: 0.94; acc: 0.62
Batch: 700; loss: 1.09; acc: 0.72
Batch: 720; loss: 0.64; acc: 0.78
Batch: 740; loss: 0.69; acc: 0.78
Batch: 760; loss: 0.98; acc: 0.73
Batch: 780; loss: 1.0; acc: 0.64
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.365205702721141e-05
2.0372011931613088e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.06; acc: 0.67
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.96; acc: 0.75
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 0.4; acc: 0.88
Val Epoch over. val_loss: 0.7286668476785064; val_accuracy: 0.7685111464968153 

The current subspace-distance is: 2.0372011931613088e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.77
Batch: 20; loss: 0.99; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.73
Batch: 60; loss: 0.55; acc: 0.78
Batch: 80; loss: 0.75; acc: 0.73
Batch: 100; loss: 0.81; acc: 0.72
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.91; acc: 0.7
Batch: 160; loss: 0.9; acc: 0.73
Batch: 180; loss: 0.79; acc: 0.8
Batch: 200; loss: 0.78; acc: 0.81
Batch: 220; loss: 0.69; acc: 0.78
Batch: 240; loss: 0.96; acc: 0.67
Batch: 260; loss: 0.84; acc: 0.77
Batch: 280; loss: 0.66; acc: 0.77
Batch: 300; loss: 0.6; acc: 0.77
Batch: 320; loss: 0.82; acc: 0.77
Batch: 340; loss: 0.76; acc: 0.7
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 1.03; acc: 0.7
Batch: 400; loss: 0.79; acc: 0.7
Batch: 420; loss: 0.93; acc: 0.73
Batch: 440; loss: 0.94; acc: 0.72
Batch: 460; loss: 0.71; acc: 0.8
Batch: 480; loss: 0.71; acc: 0.81
Batch: 500; loss: 0.79; acc: 0.78
Batch: 520; loss: 0.76; acc: 0.75
Batch: 540; loss: 0.6; acc: 0.86
Batch: 560; loss: 0.69; acc: 0.77
Batch: 580; loss: 0.68; acc: 0.78
Batch: 600; loss: 0.87; acc: 0.73
Batch: 620; loss: 0.88; acc: 0.72
Batch: 640; loss: 0.57; acc: 0.8
Batch: 660; loss: 0.77; acc: 0.73
Batch: 680; loss: 0.74; acc: 0.81
Batch: 700; loss: 0.67; acc: 0.77
Batch: 720; loss: 1.02; acc: 0.73
Batch: 740; loss: 0.79; acc: 0.72
Batch: 760; loss: 0.61; acc: 0.83
Batch: 780; loss: 0.71; acc: 0.7
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.396329339011572e-05
1.980461456696503e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.96; acc: 0.75
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 0.39; acc: 0.88
Val Epoch over. val_loss: 0.7286838854953741; val_accuracy: 0.767515923566879 

The current subspace-distance is: 1.980461456696503e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.86; acc: 0.67
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.88; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.7
Batch: 80; loss: 0.78; acc: 0.8
Batch: 100; loss: 0.6; acc: 0.83
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.66; acc: 0.77
Batch: 160; loss: 0.65; acc: 0.84
Batch: 180; loss: 0.66; acc: 0.81
Batch: 200; loss: 0.76; acc: 0.72
Batch: 220; loss: 0.75; acc: 0.77
Batch: 240; loss: 0.85; acc: 0.72
Batch: 260; loss: 0.93; acc: 0.7
Batch: 280; loss: 0.58; acc: 0.81
Batch: 300; loss: 0.8; acc: 0.75
Batch: 320; loss: 0.86; acc: 0.73
Batch: 340; loss: 0.71; acc: 0.8
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.76; acc: 0.8
Batch: 400; loss: 0.78; acc: 0.69
Batch: 420; loss: 0.91; acc: 0.72
Batch: 440; loss: 0.79; acc: 0.64
Batch: 460; loss: 0.81; acc: 0.77
Batch: 480; loss: 1.04; acc: 0.67
Batch: 500; loss: 0.74; acc: 0.73
Batch: 520; loss: 0.48; acc: 0.88
Batch: 540; loss: 0.87; acc: 0.73
Batch: 560; loss: 0.93; acc: 0.69
Batch: 580; loss: 0.57; acc: 0.8
Batch: 600; loss: 0.92; acc: 0.7
Batch: 620; loss: 0.76; acc: 0.78
Batch: 640; loss: 0.82; acc: 0.72
Batch: 660; loss: 0.74; acc: 0.81
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 1.01; acc: 0.62
Batch: 740; loss: 0.68; acc: 0.78
Batch: 760; loss: 0.75; acc: 0.69
Batch: 780; loss: 0.81; acc: 0.81
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.3701639040373266e-05
1.7948616005014628e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.04; acc: 0.69
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.73; acc: 0.72
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.96; acc: 0.73
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 0.39; acc: 0.88
Val Epoch over. val_loss: 0.7285556183878783; val_accuracy: 0.7678144904458599 

The current subspace-distance is: 1.7948616005014628e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.82; acc: 0.73
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.86; acc: 0.72
Batch: 60; loss: 0.69; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.75
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.96; acc: 0.7
Batch: 160; loss: 0.73; acc: 0.73
Batch: 180; loss: 0.89; acc: 0.69
Batch: 200; loss: 0.59; acc: 0.73
Batch: 220; loss: 0.51; acc: 0.83
Batch: 240; loss: 0.7; acc: 0.77
Batch: 260; loss: 1.07; acc: 0.67
Batch: 280; loss: 0.78; acc: 0.73
Batch: 300; loss: 0.7; acc: 0.81
Batch: 320; loss: 0.68; acc: 0.72
Batch: 340; loss: 0.59; acc: 0.8
Batch: 360; loss: 0.93; acc: 0.7
Batch: 380; loss: 0.8; acc: 0.78
Batch: 400; loss: 1.05; acc: 0.7
Batch: 420; loss: 0.72; acc: 0.78
Batch: 440; loss: 0.8; acc: 0.7
Batch: 460; loss: 0.9; acc: 0.75
Batch: 480; loss: 0.69; acc: 0.75
Batch: 500; loss: 0.86; acc: 0.75
Batch: 520; loss: 0.62; acc: 0.78
Batch: 540; loss: 0.74; acc: 0.78
Batch: 560; loss: 0.77; acc: 0.72
Batch: 580; loss: 0.8; acc: 0.72
Batch: 600; loss: 0.54; acc: 0.8
Batch: 620; loss: 0.67; acc: 0.75
Batch: 640; loss: 0.69; acc: 0.81
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.56; acc: 0.78
Batch: 700; loss: 0.68; acc: 0.81
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.71; acc: 0.77
Batch: 760; loss: 0.79; acc: 0.78
Batch: 780; loss: 0.93; acc: 0.64
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.3007352612912655e-05
1.8787128283292986e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.96; acc: 0.75
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 0.39; acc: 0.88
Val Epoch over. val_loss: 0.7281264040120847; val_accuracy: 0.7692078025477707 

The current subspace-distance is: 1.8787128283292986e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.67; acc: 0.81
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.72; acc: 0.75
Batch: 60; loss: 0.78; acc: 0.75
Batch: 80; loss: 0.64; acc: 0.7
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 0.65; acc: 0.75
Batch: 140; loss: 0.91; acc: 0.67
Batch: 160; loss: 0.83; acc: 0.67
Batch: 180; loss: 0.74; acc: 0.78
Batch: 200; loss: 0.69; acc: 0.81
Batch: 220; loss: 0.63; acc: 0.81
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.75; acc: 0.81
Batch: 280; loss: 0.64; acc: 0.78
Batch: 300; loss: 0.71; acc: 0.72
Batch: 320; loss: 0.59; acc: 0.84
Batch: 340; loss: 0.96; acc: 0.66
Batch: 360; loss: 0.77; acc: 0.73
Batch: 380; loss: 1.09; acc: 0.66
Batch: 400; loss: 1.05; acc: 0.69
Batch: 420; loss: 0.78; acc: 0.69
Batch: 440; loss: 0.75; acc: 0.75
Batch: 460; loss: 0.69; acc: 0.81
Batch: 480; loss: 0.8; acc: 0.73
Batch: 500; loss: 0.65; acc: 0.73
Batch: 520; loss: 0.71; acc: 0.81
Batch: 540; loss: 0.88; acc: 0.78
Batch: 560; loss: 0.6; acc: 0.81
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.62; acc: 0.8
Batch: 620; loss: 0.7; acc: 0.75
Batch: 640; loss: 0.68; acc: 0.81
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.56; acc: 0.78
Batch: 700; loss: 1.05; acc: 0.7
Batch: 720; loss: 0.7; acc: 0.83
Batch: 740; loss: 0.8; acc: 0.73
Batch: 760; loss: 0.72; acc: 0.83
Batch: 780; loss: 0.74; acc: 0.77
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.2595817174296826e-05
1.837013041949831e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.05; acc: 0.66
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.95; acc: 0.73
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 0.39; acc: 0.88
Val Epoch over. val_loss: 0.7280916691206063; val_accuracy: 0.7693073248407644 

The current subspace-distance is: 1.837013041949831e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.8
Batch: 20; loss: 0.82; acc: 0.72
Batch: 40; loss: 0.77; acc: 0.8
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.75; acc: 0.72
Batch: 100; loss: 0.89; acc: 0.73
Batch: 120; loss: 0.97; acc: 0.8
Batch: 140; loss: 0.7; acc: 0.75
Batch: 160; loss: 0.86; acc: 0.67
Batch: 180; loss: 0.98; acc: 0.69
Batch: 200; loss: 0.96; acc: 0.77
Batch: 220; loss: 1.0; acc: 0.69
Batch: 240; loss: 0.82; acc: 0.72
Batch: 260; loss: 0.81; acc: 0.7
Batch: 280; loss: 0.53; acc: 0.81
Batch: 300; loss: 0.7; acc: 0.78
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.69; acc: 0.72
Batch: 360; loss: 0.74; acc: 0.75
Batch: 380; loss: 0.59; acc: 0.83
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.89; acc: 0.7
Batch: 440; loss: 0.63; acc: 0.75
Batch: 460; loss: 0.66; acc: 0.88
Batch: 480; loss: 0.85; acc: 0.72
Batch: 500; loss: 0.75; acc: 0.78
Batch: 520; loss: 0.83; acc: 0.73
Batch: 540; loss: 0.73; acc: 0.77
Batch: 560; loss: 0.69; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.79; acc: 0.75
Batch: 620; loss: 0.54; acc: 0.75
Batch: 640; loss: 0.93; acc: 0.67
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.62; acc: 0.81
Batch: 700; loss: 0.74; acc: 0.73
Batch: 720; loss: 0.81; acc: 0.73
Batch: 740; loss: 0.59; acc: 0.88
Batch: 760; loss: 0.76; acc: 0.8
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

3.195038152625784e-05
1.9622886611614376e-05
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 1.05; acc: 0.66
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.73
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.39; acc: 0.88
Val Epoch over. val_loss: 0.7278123581485384; val_accuracy: 0.7693073248407644 

The current subspace-distance is: 1.9622886611614376e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.77
Batch: 20; loss: 0.89; acc: 0.75
Batch: 40; loss: 0.82; acc: 0.69
Batch: 60; loss: 0.94; acc: 0.66
Batch: 80; loss: 0.64; acc: 0.78
Batch: 100; loss: 0.86; acc: 0.69
Batch: 120; loss: 1.01; acc: 0.61
Batch: 140; loss: 0.65; acc: 0.8
Batch: 160; loss: 0.69; acc: 0.78
Batch: 180; loss: 0.73; acc: 0.78
Batch: 200; loss: 0.84; acc: 0.77
Batch: 220; loss: 0.6; acc: 0.78
Batch: 240; loss: 0.65; acc: 0.78
Batch: 260; loss: 1.11; acc: 0.7
Batch: 280; loss: 0.83; acc: 0.72
Batch: 300; loss: 0.71; acc: 0.8
Batch: 320; loss: 0.71; acc: 0.78
Batch: 340; loss: 0.67; acc: 0.72
Batch: 360; loss: 0.7; acc: 0.73
Batch: 380; loss: 0.95; acc: 0.69
Batch: 400; loss: 0.95; acc: 0.72
Batch: 420; loss: 1.19; acc: 0.69
Batch: 440; loss: 0.67; acc: 0.81
Batch: 460; loss: 0.67; acc: 0.84
Batch: 480; loss: 1.07; acc: 0.69
Batch: 500; loss: 0.9; acc: 0.7
Batch: 520; loss: 0.61; acc: 0.81
Batch: 540; loss: 0.83; acc: 0.72
Batch: 560; loss: 0.88; acc: 0.69
Batch: 580; loss: 0.88; acc: 0.72
Batch: 600; loss: 0.57; acc: 0.89
Batch: 620; loss: 0.66; acc: 0.78
Batch: 640; loss: 0.88; acc: 0.75
Batch: 660; loss: 0.58; acc: 0.77
Batch: 680; loss: 0.67; acc: 0.8
Batch: 700; loss: 0.85; acc: 0.72
Batch: 720; loss: 0.68; acc: 0.75
Batch: 740; loss: 0.74; acc: 0.73
Batch: 760; loss: 0.65; acc: 0.81
Batch: 780; loss: 0.63; acc: 0.83
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.4954078728333116e-05
1.877508475445211e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.66
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.72
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.75
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.39; acc: 0.89
Val Epoch over. val_loss: 0.7276485941971943; val_accuracy: 0.7688097133757962 

The current subspace-distance is: 1.877508475445211e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.97; acc: 0.7
Batch: 20; loss: 0.96; acc: 0.7
Batch: 40; loss: 0.68; acc: 0.72
Batch: 60; loss: 0.81; acc: 0.72
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.83; acc: 0.69
Batch: 120; loss: 0.85; acc: 0.69
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.56; acc: 0.83
Batch: 180; loss: 0.82; acc: 0.69
Batch: 200; loss: 0.81; acc: 0.73
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.69; acc: 0.7
Batch: 260; loss: 0.88; acc: 0.75
Batch: 280; loss: 0.75; acc: 0.73
Batch: 300; loss: 0.99; acc: 0.69
Batch: 320; loss: 0.97; acc: 0.73
Batch: 340; loss: 0.93; acc: 0.81
Batch: 360; loss: 0.79; acc: 0.75
Batch: 380; loss: 0.78; acc: 0.78
Batch: 400; loss: 0.9; acc: 0.69
Batch: 420; loss: 1.1; acc: 0.7
Batch: 440; loss: 0.77; acc: 0.75
Batch: 460; loss: 0.9; acc: 0.69
Batch: 480; loss: 0.89; acc: 0.73
Batch: 500; loss: 0.95; acc: 0.72
Batch: 520; loss: 0.93; acc: 0.69
Batch: 540; loss: 0.72; acc: 0.78
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.83; acc: 0.73
Batch: 600; loss: 0.84; acc: 0.73
Batch: 620; loss: 0.58; acc: 0.77
Batch: 640; loss: 0.94; acc: 0.73
Batch: 660; loss: 1.01; acc: 0.66
Batch: 680; loss: 0.72; acc: 0.8
Batch: 700; loss: 0.76; acc: 0.72
Batch: 720; loss: 0.85; acc: 0.73
Batch: 740; loss: 0.74; acc: 0.67
Batch: 760; loss: 0.74; acc: 0.73
Batch: 780; loss: 0.81; acc: 0.75
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.55834599758964e-05
1.8984834241564386e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.66
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7272144497200183; val_accuracy: 0.7684116242038217 

The current subspace-distance is: 1.8984834241564386e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 1.01; acc: 0.59
Batch: 40; loss: 0.88; acc: 0.75
Batch: 60; loss: 0.72; acc: 0.73
Batch: 80; loss: 0.78; acc: 0.7
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.84; acc: 0.78
Batch: 180; loss: 0.86; acc: 0.73
Batch: 200; loss: 0.79; acc: 0.77
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.82; acc: 0.7
Batch: 260; loss: 0.67; acc: 0.78
Batch: 280; loss: 0.66; acc: 0.75
Batch: 300; loss: 0.9; acc: 0.75
Batch: 320; loss: 0.6; acc: 0.78
Batch: 340; loss: 0.95; acc: 0.77
Batch: 360; loss: 0.83; acc: 0.75
Batch: 380; loss: 0.99; acc: 0.66
Batch: 400; loss: 0.8; acc: 0.75
Batch: 420; loss: 0.94; acc: 0.67
Batch: 440; loss: 0.61; acc: 0.8
Batch: 460; loss: 0.76; acc: 0.77
Batch: 480; loss: 0.74; acc: 0.77
Batch: 500; loss: 0.74; acc: 0.75
Batch: 520; loss: 0.78; acc: 0.78
Batch: 540; loss: 0.75; acc: 0.75
Batch: 560; loss: 0.69; acc: 0.78
Batch: 580; loss: 0.65; acc: 0.75
Batch: 600; loss: 0.68; acc: 0.81
Batch: 620; loss: 1.12; acc: 0.62
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.72; acc: 0.73
Batch: 680; loss: 0.76; acc: 0.77
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.81; acc: 0.77
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.83; acc: 0.73
Batch: 780; loss: 0.82; acc: 0.73
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.189555718563497e-05
1.7462596588302404e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.72
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.75
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.727392705952286; val_accuracy: 0.7684116242038217 

The current subspace-distance is: 1.7462596588302404e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.63; acc: 0.83
Batch: 40; loss: 0.71; acc: 0.77
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 0.73; acc: 0.7
Batch: 100; loss: 0.75; acc: 0.77
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.75; acc: 0.72
Batch: 160; loss: 0.63; acc: 0.81
Batch: 180; loss: 0.82; acc: 0.75
Batch: 200; loss: 1.0; acc: 0.73
Batch: 220; loss: 0.78; acc: 0.78
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.74; acc: 0.8
Batch: 300; loss: 0.8; acc: 0.69
Batch: 320; loss: 0.71; acc: 0.75
Batch: 340; loss: 0.66; acc: 0.75
Batch: 360; loss: 0.72; acc: 0.8
Batch: 380; loss: 0.85; acc: 0.72
Batch: 400; loss: 0.69; acc: 0.84
Batch: 420; loss: 0.82; acc: 0.72
Batch: 440; loss: 0.63; acc: 0.88
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.68; acc: 0.77
Batch: 500; loss: 0.82; acc: 0.78
Batch: 520; loss: 0.71; acc: 0.77
Batch: 540; loss: 0.86; acc: 0.75
Batch: 560; loss: 0.65; acc: 0.75
Batch: 580; loss: 0.83; acc: 0.73
Batch: 600; loss: 0.73; acc: 0.73
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.82; acc: 0.7
Batch: 660; loss: 0.71; acc: 0.78
Batch: 680; loss: 0.92; acc: 0.72
Batch: 700; loss: 0.83; acc: 0.73
Batch: 720; loss: 0.9; acc: 0.7
Batch: 740; loss: 0.67; acc: 0.73
Batch: 760; loss: 0.71; acc: 0.73
Batch: 780; loss: 0.88; acc: 0.69
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.4810364013537765e-05
2.0287239749450237e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.62
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 0.39; acc: 0.89
Val Epoch over. val_loss: 0.7273854535476417; val_accuracy: 0.7686106687898089 

The current subspace-distance is: 2.0287239749450237e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.87; acc: 0.69
Batch: 40; loss: 0.87; acc: 0.7
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.67; acc: 0.77
Batch: 100; loss: 0.79; acc: 0.77
Batch: 120; loss: 0.71; acc: 0.83
Batch: 140; loss: 0.86; acc: 0.73
Batch: 160; loss: 0.71; acc: 0.69
Batch: 180; loss: 0.95; acc: 0.72
Batch: 200; loss: 0.86; acc: 0.7
Batch: 220; loss: 0.73; acc: 0.83
Batch: 240; loss: 0.84; acc: 0.67
Batch: 260; loss: 0.62; acc: 0.77
Batch: 280; loss: 0.67; acc: 0.81
Batch: 300; loss: 0.65; acc: 0.77
Batch: 320; loss: 0.75; acc: 0.73
Batch: 340; loss: 0.83; acc: 0.7
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.83; acc: 0.77
Batch: 400; loss: 0.57; acc: 0.83
Batch: 420; loss: 0.67; acc: 0.72
Batch: 440; loss: 0.8; acc: 0.72
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.71; acc: 0.77
Batch: 500; loss: 0.67; acc: 0.81
Batch: 520; loss: 0.98; acc: 0.61
Batch: 540; loss: 0.79; acc: 0.75
Batch: 560; loss: 0.53; acc: 0.88
Batch: 580; loss: 0.93; acc: 0.75
Batch: 600; loss: 0.6; acc: 0.75
Batch: 620; loss: 0.63; acc: 0.78
Batch: 640; loss: 0.79; acc: 0.77
Batch: 660; loss: 1.0; acc: 0.64
Batch: 680; loss: 0.83; acc: 0.75
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 0.94; acc: 0.64
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 1.25; acc: 0.61
Batch: 780; loss: 0.62; acc: 0.78
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.3758144127205014e-05
1.9110470020677894e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7273253559306928; val_accuracy: 0.7690087579617835 

The current subspace-distance is: 1.9110470020677894e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.9; acc: 0.66
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.78; acc: 0.75
Batch: 60; loss: 0.85; acc: 0.73
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.9; acc: 0.72
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 0.66; acc: 0.75
Batch: 180; loss: 0.71; acc: 0.78
Batch: 200; loss: 0.71; acc: 0.77
Batch: 220; loss: 0.65; acc: 0.73
Batch: 240; loss: 0.91; acc: 0.69
Batch: 260; loss: 0.81; acc: 0.73
Batch: 280; loss: 0.79; acc: 0.73
Batch: 300; loss: 0.66; acc: 0.81
Batch: 320; loss: 0.82; acc: 0.8
Batch: 340; loss: 0.85; acc: 0.67
Batch: 360; loss: 0.85; acc: 0.83
Batch: 380; loss: 0.92; acc: 0.75
Batch: 400; loss: 0.78; acc: 0.77
Batch: 420; loss: 0.72; acc: 0.75
Batch: 440; loss: 0.62; acc: 0.83
Batch: 460; loss: 0.72; acc: 0.73
Batch: 480; loss: 0.59; acc: 0.81
Batch: 500; loss: 0.74; acc: 0.77
Batch: 520; loss: 0.7; acc: 0.77
Batch: 540; loss: 0.91; acc: 0.73
Batch: 560; loss: 0.73; acc: 0.8
Batch: 580; loss: 0.74; acc: 0.73
Batch: 600; loss: 1.08; acc: 0.62
Batch: 620; loss: 0.84; acc: 0.72
Batch: 640; loss: 0.91; acc: 0.69
Batch: 660; loss: 1.04; acc: 0.75
Batch: 680; loss: 0.81; acc: 0.77
Batch: 700; loss: 0.65; acc: 0.77
Batch: 720; loss: 0.92; acc: 0.7
Batch: 740; loss: 0.75; acc: 0.75
Batch: 760; loss: 0.67; acc: 0.77
Batch: 780; loss: 0.56; acc: 0.83
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.079973976127803e-05
1.7954391296370886e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7271454956880801; val_accuracy: 0.7679140127388535 

The current subspace-distance is: 1.7954391296370886e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.93; acc: 0.67
Batch: 20; loss: 0.94; acc: 0.75
Batch: 40; loss: 0.79; acc: 0.75
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.79; acc: 0.75
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.7; acc: 0.77
Batch: 160; loss: 0.81; acc: 0.7
Batch: 180; loss: 0.7; acc: 0.73
Batch: 200; loss: 0.71; acc: 0.8
Batch: 220; loss: 0.74; acc: 0.75
Batch: 240; loss: 0.75; acc: 0.73
Batch: 260; loss: 0.76; acc: 0.78
Batch: 280; loss: 0.98; acc: 0.69
Batch: 300; loss: 0.67; acc: 0.77
Batch: 320; loss: 0.77; acc: 0.72
Batch: 340; loss: 0.69; acc: 0.73
Batch: 360; loss: 0.86; acc: 0.73
Batch: 380; loss: 0.76; acc: 0.69
Batch: 400; loss: 0.66; acc: 0.8
Batch: 420; loss: 0.7; acc: 0.81
Batch: 440; loss: 0.59; acc: 0.8
Batch: 460; loss: 0.86; acc: 0.73
Batch: 480; loss: 0.67; acc: 0.75
Batch: 500; loss: 0.72; acc: 0.81
Batch: 520; loss: 0.82; acc: 0.77
Batch: 540; loss: 0.94; acc: 0.67
Batch: 560; loss: 0.64; acc: 0.75
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.66; acc: 0.81
Batch: 620; loss: 0.94; acc: 0.67
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 1.01; acc: 0.66
Batch: 680; loss: 0.6; acc: 0.83
Batch: 700; loss: 1.32; acc: 0.61
Batch: 720; loss: 0.63; acc: 0.77
Batch: 740; loss: 0.71; acc: 0.77
Batch: 760; loss: 0.71; acc: 0.75
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.241301601519808e-05
1.9591854652389884e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7270689143496714; val_accuracy: 0.7681130573248408 

The current subspace-distance is: 1.9591854652389884e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 1.16; acc: 0.67
Batch: 40; loss: 0.65; acc: 0.7
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.86; acc: 0.73
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.82; acc: 0.81
Batch: 160; loss: 0.76; acc: 0.8
Batch: 180; loss: 1.06; acc: 0.64
Batch: 200; loss: 0.87; acc: 0.8
Batch: 220; loss: 0.66; acc: 0.73
Batch: 240; loss: 0.97; acc: 0.69
Batch: 260; loss: 0.94; acc: 0.72
Batch: 280; loss: 0.98; acc: 0.66
Batch: 300; loss: 1.0; acc: 0.69
Batch: 320; loss: 1.11; acc: 0.56
Batch: 340; loss: 0.51; acc: 0.88
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.86; acc: 0.73
Batch: 400; loss: 0.56; acc: 0.78
Batch: 420; loss: 0.78; acc: 0.73
Batch: 440; loss: 0.75; acc: 0.81
Batch: 460; loss: 0.7; acc: 0.73
Batch: 480; loss: 1.05; acc: 0.64
Batch: 500; loss: 0.9; acc: 0.7
Batch: 520; loss: 0.82; acc: 0.78
Batch: 540; loss: 0.93; acc: 0.67
Batch: 560; loss: 0.79; acc: 0.73
Batch: 580; loss: 0.89; acc: 0.77
Batch: 600; loss: 0.92; acc: 0.73
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.8; acc: 0.78
Batch: 660; loss: 0.73; acc: 0.75
Batch: 680; loss: 0.77; acc: 0.75
Batch: 700; loss: 0.86; acc: 0.67
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 1.07; acc: 0.67
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.7; acc: 0.75
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.12472038785927e-05
2.07830253202701e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.726894010404113; val_accuracy: 0.768312101910828 

The current subspace-distance is: 2.07830253202701e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 1.06; acc: 0.66
Batch: 60; loss: 0.75; acc: 0.8
Batch: 80; loss: 0.68; acc: 0.83
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.77; acc: 0.75
Batch: 160; loss: 0.84; acc: 0.73
Batch: 180; loss: 0.69; acc: 0.78
Batch: 200; loss: 0.9; acc: 0.75
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.65; acc: 0.8
Batch: 260; loss: 0.92; acc: 0.62
Batch: 280; loss: 0.84; acc: 0.67
Batch: 300; loss: 0.75; acc: 0.72
Batch: 320; loss: 0.75; acc: 0.75
Batch: 340; loss: 1.0; acc: 0.66
Batch: 360; loss: 0.76; acc: 0.72
Batch: 380; loss: 0.66; acc: 0.8
Batch: 400; loss: 0.86; acc: 0.72
Batch: 420; loss: 0.8; acc: 0.69
Batch: 440; loss: 0.89; acc: 0.8
Batch: 460; loss: 0.87; acc: 0.66
Batch: 480; loss: 1.04; acc: 0.66
Batch: 500; loss: 0.98; acc: 0.73
Batch: 520; loss: 0.62; acc: 0.72
Batch: 540; loss: 0.73; acc: 0.78
Batch: 560; loss: 0.79; acc: 0.78
Batch: 580; loss: 0.9; acc: 0.75
Batch: 600; loss: 0.63; acc: 0.8
Batch: 620; loss: 0.66; acc: 0.78
Batch: 640; loss: 0.9; acc: 0.72
Batch: 660; loss: 0.95; acc: 0.69
Batch: 680; loss: 0.52; acc: 0.88
Batch: 700; loss: 0.84; acc: 0.73
Batch: 720; loss: 0.76; acc: 0.78
Batch: 740; loss: 1.01; acc: 0.66
Batch: 760; loss: 0.64; acc: 0.83
Batch: 780; loss: 0.64; acc: 0.77
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.226535773137584e-05
2.0402589143486694e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.726933854400732; val_accuracy: 0.7681130573248408 

The current subspace-distance is: 2.0402589143486694e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.83; acc: 0.7
Batch: 20; loss: 0.85; acc: 0.73
Batch: 40; loss: 0.74; acc: 0.75
Batch: 60; loss: 0.88; acc: 0.73
Batch: 80; loss: 0.81; acc: 0.75
Batch: 100; loss: 0.88; acc: 0.7
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.61; acc: 0.81
Batch: 160; loss: 0.77; acc: 0.83
Batch: 180; loss: 0.81; acc: 0.67
Batch: 200; loss: 0.71; acc: 0.77
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.72; acc: 0.75
Batch: 260; loss: 0.6; acc: 0.8
Batch: 280; loss: 0.9; acc: 0.75
Batch: 300; loss: 0.85; acc: 0.72
Batch: 320; loss: 0.84; acc: 0.75
Batch: 340; loss: 0.76; acc: 0.72
Batch: 360; loss: 0.99; acc: 0.62
Batch: 380; loss: 1.01; acc: 0.69
Batch: 400; loss: 0.74; acc: 0.8
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.71; acc: 0.81
Batch: 460; loss: 0.93; acc: 0.61
Batch: 480; loss: 0.69; acc: 0.8
Batch: 500; loss: 0.69; acc: 0.78
Batch: 520; loss: 0.73; acc: 0.8
Batch: 540; loss: 0.74; acc: 0.8
Batch: 560; loss: 0.69; acc: 0.75
Batch: 580; loss: 0.62; acc: 0.8
Batch: 600; loss: 0.77; acc: 0.69
Batch: 620; loss: 0.7; acc: 0.77
Batch: 640; loss: 0.99; acc: 0.7
Batch: 660; loss: 0.67; acc: 0.77
Batch: 680; loss: 0.74; acc: 0.83
Batch: 700; loss: 0.78; acc: 0.72
Batch: 720; loss: 0.59; acc: 0.78
Batch: 740; loss: 0.68; acc: 0.75
Batch: 760; loss: 1.13; acc: 0.72
Batch: 780; loss: 0.97; acc: 0.69
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.2947482395684347e-05
1.733239332679659e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7268486108369888; val_accuracy: 0.7680135350318471 

The current subspace-distance is: 1.733239332679659e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.67; acc: 0.83
Batch: 20; loss: 0.96; acc: 0.66
Batch: 40; loss: 0.78; acc: 0.7
Batch: 60; loss: 1.03; acc: 0.72
Batch: 80; loss: 0.66; acc: 0.78
Batch: 100; loss: 0.6; acc: 0.75
Batch: 120; loss: 0.89; acc: 0.72
Batch: 140; loss: 0.73; acc: 0.73
Batch: 160; loss: 0.85; acc: 0.73
Batch: 180; loss: 0.72; acc: 0.8
Batch: 200; loss: 1.01; acc: 0.69
Batch: 220; loss: 0.67; acc: 0.73
Batch: 240; loss: 1.04; acc: 0.7
Batch: 260; loss: 0.72; acc: 0.8
Batch: 280; loss: 0.86; acc: 0.73
Batch: 300; loss: 0.95; acc: 0.67
Batch: 320; loss: 0.6; acc: 0.8
Batch: 340; loss: 0.7; acc: 0.73
Batch: 360; loss: 0.61; acc: 0.78
Batch: 380; loss: 0.97; acc: 0.66
Batch: 400; loss: 0.75; acc: 0.77
Batch: 420; loss: 0.81; acc: 0.73
Batch: 440; loss: 0.73; acc: 0.77
Batch: 460; loss: 0.75; acc: 0.77
Batch: 480; loss: 1.01; acc: 0.66
Batch: 500; loss: 0.92; acc: 0.69
Batch: 520; loss: 1.0; acc: 0.7
Batch: 540; loss: 1.0; acc: 0.72
Batch: 560; loss: 0.84; acc: 0.75
Batch: 580; loss: 0.93; acc: 0.67
Batch: 600; loss: 0.7; acc: 0.77
Batch: 620; loss: 0.7; acc: 0.75
Batch: 640; loss: 0.99; acc: 0.67
Batch: 660; loss: 0.72; acc: 0.77
Batch: 680; loss: 0.83; acc: 0.75
Batch: 700; loss: 0.7; acc: 0.77
Batch: 720; loss: 0.81; acc: 0.78
Batch: 740; loss: 0.79; acc: 0.77
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.95; acc: 0.69
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.273480979260057e-05
1.8715512851485983e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.93; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7266975956357968; val_accuracy: 0.7679140127388535 

The current subspace-distance is: 1.8715512851485983e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.7; acc: 0.78
Batch: 60; loss: 0.5; acc: 0.8
Batch: 80; loss: 0.6; acc: 0.81
Batch: 100; loss: 0.67; acc: 0.73
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 0.65; acc: 0.8
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.71; acc: 0.7
Batch: 220; loss: 0.69; acc: 0.83
Batch: 240; loss: 0.89; acc: 0.7
Batch: 260; loss: 1.03; acc: 0.69
Batch: 280; loss: 0.99; acc: 0.64
Batch: 300; loss: 0.72; acc: 0.8
Batch: 320; loss: 0.65; acc: 0.72
Batch: 340; loss: 1.04; acc: 0.7
Batch: 360; loss: 0.58; acc: 0.78
Batch: 380; loss: 0.85; acc: 0.75
Batch: 400; loss: 1.01; acc: 0.73
Batch: 420; loss: 0.81; acc: 0.67
Batch: 440; loss: 0.9; acc: 0.77
Batch: 460; loss: 0.69; acc: 0.8
Batch: 480; loss: 1.02; acc: 0.58
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.75; acc: 0.78
Batch: 580; loss: 1.16; acc: 0.59
Batch: 600; loss: 0.79; acc: 0.73
Batch: 620; loss: 0.65; acc: 0.81
Batch: 640; loss: 0.69; acc: 0.77
Batch: 660; loss: 1.13; acc: 0.61
Batch: 680; loss: 0.81; acc: 0.73
Batch: 700; loss: 0.8; acc: 0.69
Batch: 720; loss: 0.9; acc: 0.72
Batch: 740; loss: 0.92; acc: 0.77
Batch: 760; loss: 0.78; acc: 0.78
Batch: 780; loss: 0.86; acc: 0.66
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.260814628447406e-05
1.7902772015077062e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.72695923440016; val_accuracy: 0.7677149681528662 

The current subspace-distance is: 1.7902772015077062e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.92; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.69
Batch: 40; loss: 0.79; acc: 0.72
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 0.79; acc: 0.77
Batch: 120; loss: 0.88; acc: 0.7
Batch: 140; loss: 0.65; acc: 0.78
Batch: 160; loss: 0.78; acc: 0.72
Batch: 180; loss: 0.52; acc: 0.86
Batch: 200; loss: 0.69; acc: 0.8
Batch: 220; loss: 0.84; acc: 0.73
Batch: 240; loss: 0.85; acc: 0.73
Batch: 260; loss: 0.85; acc: 0.7
Batch: 280; loss: 1.07; acc: 0.7
Batch: 300; loss: 0.93; acc: 0.73
Batch: 320; loss: 0.74; acc: 0.78
Batch: 340; loss: 0.54; acc: 0.8
Batch: 360; loss: 0.65; acc: 0.83
Batch: 380; loss: 0.84; acc: 0.7
Batch: 400; loss: 0.81; acc: 0.75
Batch: 420; loss: 0.73; acc: 0.73
Batch: 440; loss: 0.67; acc: 0.78
Batch: 460; loss: 0.74; acc: 0.75
Batch: 480; loss: 1.21; acc: 0.64
Batch: 500; loss: 0.61; acc: 0.83
Batch: 520; loss: 0.81; acc: 0.75
Batch: 540; loss: 1.13; acc: 0.67
Batch: 560; loss: 0.78; acc: 0.72
Batch: 580; loss: 1.0; acc: 0.7
Batch: 600; loss: 0.75; acc: 0.77
Batch: 620; loss: 0.87; acc: 0.72
Batch: 640; loss: 0.99; acc: 0.73
Batch: 660; loss: 0.87; acc: 0.78
Batch: 680; loss: 0.86; acc: 0.7
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.74; acc: 0.69
Batch: 740; loss: 0.68; acc: 0.72
Batch: 760; loss: 0.71; acc: 0.78
Batch: 780; loss: 0.7; acc: 0.8
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.238342105760239e-05
1.972612699319143e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7268721350249211; val_accuracy: 0.7680135350318471 

The current subspace-distance is: 1.972612699319143e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.82; acc: 0.7
Batch: 20; loss: 0.82; acc: 0.69
Batch: 40; loss: 0.9; acc: 0.75
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.8; acc: 0.72
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.81; acc: 0.7
Batch: 140; loss: 0.87; acc: 0.81
Batch: 160; loss: 0.65; acc: 0.78
Batch: 180; loss: 0.67; acc: 0.81
Batch: 200; loss: 0.8; acc: 0.75
Batch: 220; loss: 1.06; acc: 0.62
Batch: 240; loss: 0.71; acc: 0.84
Batch: 260; loss: 0.67; acc: 0.78
Batch: 280; loss: 0.85; acc: 0.73
Batch: 300; loss: 0.83; acc: 0.72
Batch: 320; loss: 0.56; acc: 0.81
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.94; acc: 0.67
Batch: 380; loss: 0.73; acc: 0.77
Batch: 400; loss: 0.74; acc: 0.78
Batch: 420; loss: 0.84; acc: 0.72
Batch: 440; loss: 0.82; acc: 0.7
Batch: 460; loss: 0.65; acc: 0.81
Batch: 480; loss: 0.85; acc: 0.72
Batch: 500; loss: 1.01; acc: 0.67
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.69; acc: 0.77
Batch: 560; loss: 0.69; acc: 0.78
Batch: 580; loss: 0.61; acc: 0.84
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.92; acc: 0.66
Batch: 640; loss: 0.94; acc: 0.72
Batch: 660; loss: 0.73; acc: 0.75
Batch: 680; loss: 0.62; acc: 0.88
Batch: 700; loss: 0.9; acc: 0.66
Batch: 720; loss: 0.58; acc: 0.83
Batch: 740; loss: 0.79; acc: 0.75
Batch: 760; loss: 0.8; acc: 0.75
Batch: 780; loss: 0.76; acc: 0.78
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.3780695957830176e-05
1.987607538467273e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7267908184391678; val_accuracy: 0.7681130573248408 

The current subspace-distance is: 1.987607538467273e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.75; acc: 0.73
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.8; acc: 0.72
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 0.81; acc: 0.72
Batch: 120; loss: 0.8; acc: 0.72
Batch: 140; loss: 0.82; acc: 0.73
Batch: 160; loss: 0.82; acc: 0.7
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.74; acc: 0.78
Batch: 220; loss: 0.57; acc: 0.81
Batch: 240; loss: 0.76; acc: 0.75
Batch: 260; loss: 0.6; acc: 0.8
Batch: 280; loss: 0.76; acc: 0.7
Batch: 300; loss: 0.86; acc: 0.75
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.84; acc: 0.7
Batch: 360; loss: 0.75; acc: 0.77
Batch: 380; loss: 1.04; acc: 0.67
Batch: 400; loss: 0.6; acc: 0.83
Batch: 420; loss: 0.61; acc: 0.8
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.9; acc: 0.73
Batch: 480; loss: 0.84; acc: 0.75
Batch: 500; loss: 0.6; acc: 0.78
Batch: 520; loss: 0.91; acc: 0.7
Batch: 540; loss: 0.84; acc: 0.75
Batch: 560; loss: 0.83; acc: 0.77
Batch: 580; loss: 0.93; acc: 0.73
Batch: 600; loss: 0.6; acc: 0.81
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.86; acc: 0.75
Batch: 680; loss: 0.79; acc: 0.73
Batch: 700; loss: 0.66; acc: 0.8
Batch: 720; loss: 0.7; acc: 0.77
Batch: 740; loss: 0.68; acc: 0.73
Batch: 760; loss: 0.67; acc: 0.83
Batch: 780; loss: 0.8; acc: 0.77
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.205602115485817e-05
1.8536464267526753e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7266874945467445; val_accuracy: 0.768312101910828 

The current subspace-distance is: 1.8536464267526753e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.87; acc: 0.77
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.8; acc: 0.77
Batch: 100; loss: 0.72; acc: 0.73
Batch: 120; loss: 0.84; acc: 0.75
Batch: 140; loss: 1.13; acc: 0.66
Batch: 160; loss: 1.24; acc: 0.62
Batch: 180; loss: 0.71; acc: 0.78
Batch: 200; loss: 0.86; acc: 0.66
Batch: 220; loss: 0.65; acc: 0.81
Batch: 240; loss: 0.54; acc: 0.8
Batch: 260; loss: 0.63; acc: 0.77
Batch: 280; loss: 0.82; acc: 0.69
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.7; acc: 0.73
Batch: 340; loss: 0.75; acc: 0.8
Batch: 360; loss: 0.7; acc: 0.84
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.78; acc: 0.72
Batch: 420; loss: 0.66; acc: 0.78
Batch: 440; loss: 0.56; acc: 0.84
Batch: 460; loss: 0.96; acc: 0.7
Batch: 480; loss: 0.58; acc: 0.78
Batch: 500; loss: 0.74; acc: 0.72
Batch: 520; loss: 0.8; acc: 0.7
Batch: 540; loss: 0.66; acc: 0.78
Batch: 560; loss: 0.74; acc: 0.75
Batch: 580; loss: 0.82; acc: 0.69
Batch: 600; loss: 0.83; acc: 0.72
Batch: 620; loss: 0.81; acc: 0.75
Batch: 640; loss: 0.65; acc: 0.78
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.9; acc: 0.73
Batch: 720; loss: 0.84; acc: 0.75
Batch: 740; loss: 0.57; acc: 0.8
Batch: 760; loss: 0.89; acc: 0.7
Batch: 780; loss: 0.87; acc: 0.66
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.427097908570431e-05
1.7151911379187368e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7265589546625781; val_accuracy: 0.7685111464968153 

The current subspace-distance is: 1.7151911379187368e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.81; acc: 0.73
Batch: 20; loss: 0.81; acc: 0.78
Batch: 40; loss: 0.96; acc: 0.73
Batch: 60; loss: 0.81; acc: 0.73
Batch: 80; loss: 0.76; acc: 0.69
Batch: 100; loss: 0.78; acc: 0.75
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.78; acc: 0.77
Batch: 160; loss: 0.89; acc: 0.75
Batch: 180; loss: 0.93; acc: 0.62
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.68; acc: 0.77
Batch: 240; loss: 0.78; acc: 0.73
Batch: 260; loss: 0.76; acc: 0.73
Batch: 280; loss: 0.56; acc: 0.83
Batch: 300; loss: 1.15; acc: 0.59
Batch: 320; loss: 0.78; acc: 0.7
Batch: 340; loss: 0.74; acc: 0.78
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 1.01; acc: 0.69
Batch: 400; loss: 0.78; acc: 0.8
Batch: 420; loss: 0.74; acc: 0.81
Batch: 440; loss: 0.83; acc: 0.77
Batch: 460; loss: 0.79; acc: 0.77
Batch: 480; loss: 0.78; acc: 0.72
Batch: 500; loss: 0.73; acc: 0.75
Batch: 520; loss: 0.96; acc: 0.69
Batch: 540; loss: 0.7; acc: 0.67
Batch: 560; loss: 0.72; acc: 0.75
Batch: 580; loss: 0.81; acc: 0.78
Batch: 600; loss: 0.6; acc: 0.78
Batch: 620; loss: 0.77; acc: 0.8
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.94; acc: 0.66
Batch: 680; loss: 0.93; acc: 0.73
Batch: 700; loss: 0.84; acc: 0.67
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.98; acc: 0.72
Batch: 760; loss: 0.58; acc: 0.86
Batch: 780; loss: 0.74; acc: 0.78
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.182877480867319e-05
1.885360325104557e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7265929351946351; val_accuracy: 0.768312101910828 

The current subspace-distance is: 1.885360325104557e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.91; acc: 0.73
Batch: 20; loss: 1.07; acc: 0.69
Batch: 40; loss: 1.0; acc: 0.69
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.82; acc: 0.69
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.94; acc: 0.72
Batch: 140; loss: 0.7; acc: 0.78
Batch: 160; loss: 0.7; acc: 0.8
Batch: 180; loss: 0.85; acc: 0.72
Batch: 200; loss: 0.92; acc: 0.67
Batch: 220; loss: 0.88; acc: 0.7
Batch: 240; loss: 0.71; acc: 0.77
Batch: 260; loss: 0.8; acc: 0.77
Batch: 280; loss: 0.61; acc: 0.78
Batch: 300; loss: 0.78; acc: 0.75
Batch: 320; loss: 1.03; acc: 0.66
Batch: 340; loss: 0.88; acc: 0.7
Batch: 360; loss: 0.76; acc: 0.78
Batch: 380; loss: 0.95; acc: 0.69
Batch: 400; loss: 0.96; acc: 0.67
Batch: 420; loss: 0.76; acc: 0.73
Batch: 440; loss: 1.0; acc: 0.69
Batch: 460; loss: 0.88; acc: 0.69
Batch: 480; loss: 0.84; acc: 0.81
Batch: 500; loss: 0.87; acc: 0.72
Batch: 520; loss: 0.92; acc: 0.72
Batch: 540; loss: 0.89; acc: 0.72
Batch: 560; loss: 0.65; acc: 0.8
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.87; acc: 0.75
Batch: 620; loss: 0.67; acc: 0.78
Batch: 640; loss: 0.7; acc: 0.75
Batch: 660; loss: 0.63; acc: 0.78
Batch: 680; loss: 0.71; acc: 0.8
Batch: 700; loss: 0.58; acc: 0.83
Batch: 720; loss: 0.68; acc: 0.78
Batch: 740; loss: 0.81; acc: 0.7
Batch: 760; loss: 0.85; acc: 0.77
Batch: 780; loss: 0.84; acc: 0.75
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.2625066523905843e-05
1.7993030269281007e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7265217623133569; val_accuracy: 0.7690087579617835 

The current subspace-distance is: 1.7993030269281007e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.77; acc: 0.77
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.73; acc: 0.72
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.81; acc: 0.73
Batch: 160; loss: 0.6; acc: 0.78
Batch: 180; loss: 0.62; acc: 0.75
Batch: 200; loss: 0.84; acc: 0.73
Batch: 220; loss: 0.72; acc: 0.81
Batch: 240; loss: 0.66; acc: 0.8
Batch: 260; loss: 0.79; acc: 0.7
Batch: 280; loss: 0.87; acc: 0.72
Batch: 300; loss: 0.82; acc: 0.73
Batch: 320; loss: 0.76; acc: 0.72
Batch: 340; loss: 0.74; acc: 0.78
Batch: 360; loss: 0.75; acc: 0.72
Batch: 380; loss: 0.95; acc: 0.77
Batch: 400; loss: 0.84; acc: 0.73
Batch: 420; loss: 0.82; acc: 0.75
Batch: 440; loss: 0.98; acc: 0.62
Batch: 460; loss: 1.05; acc: 0.64
Batch: 480; loss: 0.58; acc: 0.8
Batch: 500; loss: 0.63; acc: 0.8
Batch: 520; loss: 0.73; acc: 0.81
Batch: 540; loss: 0.73; acc: 0.77
Batch: 560; loss: 0.73; acc: 0.75
Batch: 580; loss: 0.76; acc: 0.8
Batch: 600; loss: 0.84; acc: 0.75
Batch: 620; loss: 1.09; acc: 0.64
Batch: 640; loss: 0.9; acc: 0.67
Batch: 660; loss: 0.62; acc: 0.78
Batch: 680; loss: 0.83; acc: 0.69
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.69; acc: 0.75
Batch: 740; loss: 0.75; acc: 0.77
Batch: 760; loss: 0.9; acc: 0.62
Batch: 780; loss: 0.83; acc: 0.75
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.167604154441506e-05
1.8655448002391495e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.72650800521966; val_accuracy: 0.7673168789808917 

The current subspace-distance is: 1.8655448002391495e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.69; acc: 0.73
Batch: 40; loss: 0.89; acc: 0.64
Batch: 60; loss: 0.57; acc: 0.84
Batch: 80; loss: 0.77; acc: 0.73
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.9; acc: 0.73
Batch: 160; loss: 0.93; acc: 0.77
Batch: 180; loss: 1.01; acc: 0.72
Batch: 200; loss: 0.97; acc: 0.67
Batch: 220; loss: 0.57; acc: 0.78
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 1.0; acc: 0.69
Batch: 300; loss: 0.63; acc: 0.83
Batch: 320; loss: 0.83; acc: 0.73
Batch: 340; loss: 0.62; acc: 0.81
Batch: 360; loss: 0.73; acc: 0.73
Batch: 380; loss: 0.74; acc: 0.75
Batch: 400; loss: 1.02; acc: 0.69
Batch: 420; loss: 0.59; acc: 0.81
Batch: 440; loss: 0.99; acc: 0.69
Batch: 460; loss: 0.69; acc: 0.77
Batch: 480; loss: 0.79; acc: 0.72
Batch: 500; loss: 0.85; acc: 0.72
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.75; acc: 0.72
Batch: 560; loss: 0.77; acc: 0.78
Batch: 580; loss: 0.92; acc: 0.73
Batch: 600; loss: 0.96; acc: 0.66
Batch: 620; loss: 0.63; acc: 0.78
Batch: 640; loss: 0.78; acc: 0.73
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 0.8; acc: 0.72
Batch: 700; loss: 0.7; acc: 0.78
Batch: 720; loss: 0.83; acc: 0.77
Batch: 740; loss: 0.67; acc: 0.78
Batch: 760; loss: 0.83; acc: 0.75
Batch: 780; loss: 0.82; acc: 0.72
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.336234294692986e-05
2.0841574951191433e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7266074792974314; val_accuracy: 0.7681130573248408 

The current subspace-distance is: 2.0841574951191433e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.99; acc: 0.7
Batch: 20; loss: 0.7; acc: 0.73
Batch: 40; loss: 0.73; acc: 0.73
Batch: 60; loss: 0.71; acc: 0.75
Batch: 80; loss: 0.72; acc: 0.77
Batch: 100; loss: 0.83; acc: 0.75
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.8; acc: 0.75
Batch: 160; loss: 0.75; acc: 0.72
Batch: 180; loss: 0.58; acc: 0.81
Batch: 200; loss: 0.85; acc: 0.7
Batch: 220; loss: 0.98; acc: 0.77
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.9; acc: 0.72
Batch: 280; loss: 0.61; acc: 0.73
Batch: 300; loss: 1.0; acc: 0.66
Batch: 320; loss: 0.82; acc: 0.73
Batch: 340; loss: 0.86; acc: 0.72
Batch: 360; loss: 0.91; acc: 0.73
Batch: 380; loss: 0.58; acc: 0.77
Batch: 400; loss: 0.67; acc: 0.81
Batch: 420; loss: 0.89; acc: 0.75
Batch: 440; loss: 0.6; acc: 0.84
Batch: 460; loss: 0.64; acc: 0.73
Batch: 480; loss: 0.67; acc: 0.72
Batch: 500; loss: 0.68; acc: 0.78
Batch: 520; loss: 0.81; acc: 0.73
Batch: 540; loss: 0.91; acc: 0.72
Batch: 560; loss: 0.8; acc: 0.7
Batch: 580; loss: 0.79; acc: 0.77
Batch: 600; loss: 1.1; acc: 0.7
Batch: 620; loss: 0.81; acc: 0.83
Batch: 640; loss: 0.67; acc: 0.7
Batch: 660; loss: 0.98; acc: 0.73
Batch: 680; loss: 0.65; acc: 0.78
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 0.81; acc: 0.75
Batch: 740; loss: 0.58; acc: 0.78
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.35034383169841e-05
1.7290849427809007e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7264847428935348; val_accuracy: 0.7686106687898089 

The current subspace-distance is: 1.7290849427809007e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.99; acc: 0.7
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.71; acc: 0.86
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 1.04; acc: 0.72
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.93; acc: 0.72
Batch: 160; loss: 0.56; acc: 0.8
Batch: 180; loss: 0.63; acc: 0.75
Batch: 200; loss: 0.59; acc: 0.83
Batch: 220; loss: 0.99; acc: 0.69
Batch: 240; loss: 0.96; acc: 0.7
Batch: 260; loss: 0.93; acc: 0.67
Batch: 280; loss: 1.26; acc: 0.62
Batch: 300; loss: 0.75; acc: 0.78
Batch: 320; loss: 0.83; acc: 0.72
Batch: 340; loss: 1.05; acc: 0.72
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.72; acc: 0.72
Batch: 400; loss: 0.9; acc: 0.73
Batch: 420; loss: 0.9; acc: 0.67
Batch: 440; loss: 0.6; acc: 0.8
Batch: 460; loss: 0.91; acc: 0.7
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.74; acc: 0.8
Batch: 520; loss: 0.52; acc: 0.88
Batch: 540; loss: 0.88; acc: 0.75
Batch: 560; loss: 0.86; acc: 0.75
Batch: 580; loss: 0.87; acc: 0.7
Batch: 600; loss: 0.77; acc: 0.72
Batch: 620; loss: 0.72; acc: 0.78
Batch: 640; loss: 0.82; acc: 0.77
Batch: 660; loss: 0.83; acc: 0.78
Batch: 680; loss: 0.68; acc: 0.69
Batch: 700; loss: 0.6; acc: 0.84
Batch: 720; loss: 0.83; acc: 0.7
Batch: 740; loss: 0.8; acc: 0.75
Batch: 760; loss: 0.69; acc: 0.73
Batch: 780; loss: 0.63; acc: 0.8
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.214340904378332e-05
1.852407876867801e-05
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7264662863342626; val_accuracy: 0.7682125796178344 

The current subspace-distance is: 1.852407876867801e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.93; acc: 0.72
Batch: 20; loss: 0.87; acc: 0.75
Batch: 40; loss: 1.05; acc: 0.69
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.9; acc: 0.62
Batch: 100; loss: 0.73; acc: 0.73
Batch: 120; loss: 0.88; acc: 0.75
Batch: 140; loss: 0.66; acc: 0.75
Batch: 160; loss: 0.65; acc: 0.81
Batch: 180; loss: 0.73; acc: 0.78
Batch: 200; loss: 0.85; acc: 0.8
Batch: 220; loss: 0.77; acc: 0.72
Batch: 240; loss: 0.74; acc: 0.72
Batch: 260; loss: 0.63; acc: 0.77
Batch: 280; loss: 0.7; acc: 0.73
Batch: 300; loss: 1.02; acc: 0.7
Batch: 320; loss: 0.8; acc: 0.8
Batch: 340; loss: 0.93; acc: 0.73
Batch: 360; loss: 0.83; acc: 0.77
Batch: 380; loss: 0.7; acc: 0.81
Batch: 400; loss: 0.72; acc: 0.73
Batch: 420; loss: 0.77; acc: 0.75
Batch: 440; loss: 0.81; acc: 0.69
Batch: 460; loss: 0.84; acc: 0.73
Batch: 480; loss: 0.88; acc: 0.75
Batch: 500; loss: 0.76; acc: 0.77
Batch: 520; loss: 0.84; acc: 0.72
Batch: 540; loss: 0.78; acc: 0.75
Batch: 560; loss: 0.76; acc: 0.73
Batch: 580; loss: 0.76; acc: 0.77
Batch: 600; loss: 0.9; acc: 0.67
Batch: 620; loss: 0.66; acc: 0.77
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.99; acc: 0.75
Batch: 680; loss: 0.85; acc: 0.72
Batch: 700; loss: 0.68; acc: 0.7
Batch: 720; loss: 0.68; acc: 0.75
Batch: 740; loss: 0.52; acc: 0.81
Batch: 760; loss: 0.71; acc: 0.77
Batch: 780; loss: 0.89; acc: 0.69
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

3.425612158025615e-05
1.9710761989699677e-05
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 1.03; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.72
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.92; acc: 0.78
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7264477338191051; val_accuracy: 0.7685111464968153 

The current subspace-distance is: 1.9710761989699677e-05 

plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 178809
elements in E: 79684000
fraction nonzero: 0.002243976206013754
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.28; acc: 0.16
Batch: 60; loss: 2.27; acc: 0.25
Batch: 80; loss: 2.28; acc: 0.27
Batch: 100; loss: 2.25; acc: 0.25
Batch: 120; loss: 2.22; acc: 0.41
Batch: 140; loss: 2.24; acc: 0.33
Batch: 160; loss: 2.21; acc: 0.41
Batch: 180; loss: 2.2; acc: 0.41
Batch: 200; loss: 2.18; acc: 0.44
Batch: 220; loss: 2.16; acc: 0.48
Batch: 240; loss: 2.14; acc: 0.5
Batch: 260; loss: 2.12; acc: 0.55
Batch: 280; loss: 2.09; acc: 0.52
Batch: 300; loss: 2.1; acc: 0.52
Batch: 320; loss: 2.08; acc: 0.52
Batch: 340; loss: 2.1; acc: 0.48
Batch: 360; loss: 2.0; acc: 0.56
Batch: 380; loss: 1.98; acc: 0.62
Batch: 400; loss: 1.89; acc: 0.66
Batch: 420; loss: 1.86; acc: 0.61
Batch: 440; loss: 1.79; acc: 0.69
Batch: 460; loss: 1.76; acc: 0.69
Batch: 480; loss: 1.74; acc: 0.62
Batch: 500; loss: 1.59; acc: 0.75
Batch: 520; loss: 1.44; acc: 0.78
Batch: 540; loss: 1.57; acc: 0.67
Batch: 560; loss: 1.6; acc: 0.52
Batch: 580; loss: 1.35; acc: 0.69
Batch: 600; loss: 1.37; acc: 0.66
Batch: 620; loss: 1.4; acc: 0.64
Batch: 640; loss: 1.19; acc: 0.66
Batch: 660; loss: 1.26; acc: 0.61
Batch: 680; loss: 1.03; acc: 0.7
Batch: 700; loss: 0.99; acc: 0.67
Batch: 720; loss: 1.08; acc: 0.67
Batch: 740; loss: 1.01; acc: 0.69
Batch: 760; loss: 0.88; acc: 0.81
Batch: 780; loss: 0.72; acc: 0.83
Train Epoch over. train_loss: 1.79; train_accuracy: 0.53 

4.343247928773053e-05
4.2305411625420675e-05
Batch: 0; loss: 0.97; acc: 0.72
Batch: 20; loss: 0.97; acc: 0.62
Batch: 40; loss: 0.66; acc: 0.84
Batch: 60; loss: 0.86; acc: 0.72
Batch: 80; loss: 0.75; acc: 0.84
Batch: 100; loss: 0.95; acc: 0.8
Batch: 120; loss: 1.16; acc: 0.64
Batch: 140; loss: 0.65; acc: 0.83
Val Epoch over. val_loss: 0.915340015463009; val_accuracy: 0.7420382165605095 

The current subspace-distance is: 4.2305411625420675e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.75
Batch: 20; loss: 0.91; acc: 0.7
Batch: 40; loss: 0.82; acc: 0.8
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.96; acc: 0.7
Batch: 100; loss: 0.93; acc: 0.69
Batch: 120; loss: 0.83; acc: 0.66
Batch: 140; loss: 0.92; acc: 0.73
Batch: 160; loss: 0.84; acc: 0.77
Batch: 180; loss: 0.81; acc: 0.75
Batch: 200; loss: 0.69; acc: 0.81
Batch: 220; loss: 0.87; acc: 0.69
Batch: 240; loss: 0.89; acc: 0.73
Batch: 260; loss: 0.72; acc: 0.73
Batch: 280; loss: 0.66; acc: 0.72
Batch: 300; loss: 0.72; acc: 0.81
Batch: 320; loss: 1.02; acc: 0.64
Batch: 340; loss: 0.72; acc: 0.75
Batch: 360; loss: 0.58; acc: 0.75
Batch: 380; loss: 0.79; acc: 0.8
Batch: 400; loss: 1.03; acc: 0.66
Batch: 420; loss: 0.71; acc: 0.73
Batch: 440; loss: 0.82; acc: 0.73
Batch: 460; loss: 0.65; acc: 0.8
Batch: 480; loss: 0.76; acc: 0.78
Batch: 500; loss: 0.57; acc: 0.81
Batch: 520; loss: 0.61; acc: 0.78
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.52; acc: 0.81
Batch: 580; loss: 0.84; acc: 0.77
Batch: 600; loss: 0.98; acc: 0.72
Batch: 620; loss: 1.1; acc: 0.67
Batch: 640; loss: 0.62; acc: 0.83
Batch: 660; loss: 0.76; acc: 0.77
Batch: 680; loss: 0.55; acc: 0.83
Batch: 700; loss: 0.75; acc: 0.77
Batch: 720; loss: 0.68; acc: 0.78
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.57; acc: 0.77
Batch: 780; loss: 0.67; acc: 0.84
Train Epoch over. train_loss: 0.77; train_accuracy: 0.76 

6.0634411056526005e-05
5.57882922294084e-05
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.71; acc: 0.75
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.64; acc: 0.73
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.99; acc: 0.69
Batch: 140; loss: 0.31; acc: 0.94
Val Epoch over. val_loss: 0.6257582413163155; val_accuracy: 0.8043391719745223 

The current subspace-distance is: 5.57882922294084e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.55; acc: 0.8
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.5; acc: 0.8
Batch: 160; loss: 0.62; acc: 0.8
Batch: 180; loss: 0.57; acc: 0.8
Batch: 200; loss: 0.65; acc: 0.77
Batch: 220; loss: 0.86; acc: 0.7
Batch: 240; loss: 1.08; acc: 0.72
Batch: 260; loss: 0.69; acc: 0.8
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.66; acc: 0.77
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.68; acc: 0.81
Batch: 360; loss: 0.73; acc: 0.75
Batch: 380; loss: 0.68; acc: 0.73
Batch: 400; loss: 0.62; acc: 0.77
Batch: 420; loss: 0.71; acc: 0.77
Batch: 440; loss: 0.81; acc: 0.75
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.64; acc: 0.81
Batch: 500; loss: 0.5; acc: 0.78
Batch: 520; loss: 0.78; acc: 0.78
Batch: 540; loss: 0.52; acc: 0.81
Batch: 560; loss: 0.77; acc: 0.7
Batch: 580; loss: 0.73; acc: 0.73
Batch: 600; loss: 0.73; acc: 0.73
Batch: 620; loss: 0.93; acc: 0.7
Batch: 640; loss: 0.84; acc: 0.77
Batch: 660; loss: 0.81; acc: 0.73
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.82; acc: 0.72
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.63; acc: 0.81
Batch: 780; loss: 0.6; acc: 0.78
Train Epoch over. train_loss: 0.64; train_accuracy: 0.8 

6.541042967000976e-05
5.943196811131202e-05
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.77
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.65; acc: 0.73
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.576978908033128; val_accuracy: 0.8183718152866242 

The current subspace-distance is: 5.943196811131202e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.74; acc: 0.73
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.72; acc: 0.78
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.61; acc: 0.81
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.54; acc: 0.84
Batch: 240; loss: 0.65; acc: 0.77
Batch: 260; loss: 0.86; acc: 0.8
Batch: 280; loss: 0.41; acc: 0.91
Batch: 300; loss: 0.6; acc: 0.81
Batch: 320; loss: 0.81; acc: 0.73
Batch: 340; loss: 0.59; acc: 0.81
Batch: 360; loss: 0.6; acc: 0.84
Batch: 380; loss: 1.08; acc: 0.73
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.58; acc: 0.8
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.57; acc: 0.8
Batch: 480; loss: 0.7; acc: 0.81
Batch: 500; loss: 0.59; acc: 0.8
Batch: 520; loss: 0.69; acc: 0.8
Batch: 540; loss: 0.52; acc: 0.83
Batch: 560; loss: 0.66; acc: 0.78
Batch: 580; loss: 0.5; acc: 0.88
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.79; acc: 0.75
Batch: 660; loss: 0.68; acc: 0.78
Batch: 680; loss: 0.66; acc: 0.78
Batch: 700; loss: 0.52; acc: 0.83
Batch: 720; loss: 0.62; acc: 0.73
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.62; acc: 0.81
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

6.632163422182202e-05
6.141431367723271e-05
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.86
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.5523047788412707; val_accuracy: 0.8266321656050956 

The current subspace-distance is: 6.141431367723271e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.69; acc: 0.73
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.68; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.5; acc: 0.81
Batch: 200; loss: 0.6; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.59; acc: 0.83
Batch: 260; loss: 0.7; acc: 0.83
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.55; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.66; acc: 0.86
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.87; acc: 0.78
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.69; acc: 0.78
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.56; acc: 0.84
Batch: 500; loss: 0.78; acc: 0.7
Batch: 520; loss: 0.6; acc: 0.81
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.52; acc: 0.81
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.62; acc: 0.81
Batch: 640; loss: 0.58; acc: 0.78
Batch: 660; loss: 0.48; acc: 0.88
Batch: 680; loss: 0.67; acc: 0.81
Batch: 700; loss: 0.56; acc: 0.84
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.62; acc: 0.8
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

6.87322171870619e-05
6.188004044815898e-05
Batch: 0; loss: 0.54; acc: 0.78
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.9; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.5238994766192832; val_accuracy: 0.8382762738853503 

The current subspace-distance is: 6.188004044815898e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.78
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.81; acc: 0.78
Batch: 60; loss: 0.53; acc: 0.81
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.69; acc: 0.77
Batch: 160; loss: 0.55; acc: 0.81
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.4; acc: 0.83
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.65; acc: 0.81
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.55; acc: 0.78
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.66; acc: 0.81
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.39; acc: 0.81
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.5; acc: 0.91
Batch: 520; loss: 0.65; acc: 0.77
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.64; acc: 0.83
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

6.83246980770491e-05
6.207553087733686e-05
Batch: 0; loss: 0.55; acc: 0.73
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.49823923053065683; val_accuracy: 0.8435509554140127 

The current subspace-distance is: 6.207553087733686e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.62; acc: 0.75
Batch: 140; loss: 0.6; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.5; acc: 0.86
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.51; acc: 0.88
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.59; acc: 0.83
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.85; acc: 0.72
Batch: 380; loss: 0.58; acc: 0.81
Batch: 400; loss: 0.59; acc: 0.83
Batch: 420; loss: 0.57; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.69; acc: 0.73
Batch: 500; loss: 0.5; acc: 0.78
Batch: 520; loss: 0.73; acc: 0.78
Batch: 540; loss: 0.84; acc: 0.78
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.6; acc: 0.83
Batch: 620; loss: 0.52; acc: 0.81
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.81
Batch: 680; loss: 0.67; acc: 0.86
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.45; acc: 0.83
Batch: 740; loss: 0.75; acc: 0.73
Batch: 760; loss: 0.58; acc: 0.81
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

7.0013920776546e-05
6.378324906108901e-05
Batch: 0; loss: 0.55; acc: 0.78
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4761630068918702; val_accuracy: 0.8514132165605095 

The current subspace-distance is: 6.378324906108901e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.69; acc: 0.8
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.51; acc: 0.77
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.49; acc: 0.81
Batch: 160; loss: 0.89; acc: 0.78
Batch: 180; loss: 0.62; acc: 0.78
Batch: 200; loss: 0.56; acc: 0.8
Batch: 220; loss: 0.59; acc: 0.83
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.56; acc: 0.81
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.78; acc: 0.81
Batch: 360; loss: 0.39; acc: 0.83
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.66; acc: 0.81
Batch: 420; loss: 0.53; acc: 0.81
Batch: 440; loss: 0.58; acc: 0.78
Batch: 460; loss: 0.54; acc: 0.8
Batch: 480; loss: 0.76; acc: 0.75
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.53; acc: 0.8
Batch: 620; loss: 0.44; acc: 0.77
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.63; acc: 0.83
Batch: 700; loss: 0.48; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.91
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.45; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.5; train_accuracy: 0.84 

6.945743371034041e-05
6.200687494128942e-05
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.72
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.4658371215792978; val_accuracy: 0.8544984076433121 

The current subspace-distance is: 6.200687494128942e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.77
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.81
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.59; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.61; acc: 0.77
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.84
Batch: 280; loss: 0.47; acc: 0.86
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.81
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.74; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.81
Batch: 500; loss: 0.38; acc: 0.83
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.91
Batch: 620; loss: 0.59; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.7; acc: 0.8
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.55; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.53; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.73; acc: 0.77
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

7.060010102577507e-05
6.37751873000525e-05
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.45333840674275805; val_accuracy: 0.8575835987261147 

The current subspace-distance is: 6.37751873000525e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.48; acc: 0.83
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.53; acc: 0.8
Batch: 140; loss: 0.64; acc: 0.77
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.54; acc: 0.84
Batch: 240; loss: 0.37; acc: 0.81
Batch: 260; loss: 0.42; acc: 0.83
Batch: 280; loss: 0.67; acc: 0.84
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.59; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.42; acc: 0.83
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.81
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.58; acc: 0.83
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.83
Batch: 600; loss: 0.7; acc: 0.8
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.46; acc: 0.8
Batch: 680; loss: 0.52; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

7.105505937943235e-05
6.409690831787884e-05
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4428864143266799; val_accuracy: 0.8622611464968153 

The current subspace-distance is: 6.409690831787884e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.54; acc: 0.8
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.63; acc: 0.8
Batch: 160; loss: 0.65; acc: 0.8
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.51; acc: 0.83
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.63; acc: 0.78
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.46; acc: 0.81
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.59; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.71; acc: 0.8
Batch: 520; loss: 0.68; acc: 0.8
Batch: 540; loss: 0.47; acc: 0.8
Batch: 560; loss: 0.51; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.67; acc: 0.75
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.66; acc: 0.8
Batch: 740; loss: 0.46; acc: 0.81
Batch: 760; loss: 0.53; acc: 0.8
Batch: 780; loss: 0.74; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.030036067590117e-05
6.215597386471927e-05
Batch: 0; loss: 0.51; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.4382708696233239; val_accuracy: 0.8633558917197452 

The current subspace-distance is: 6.215597386471927e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.62; acc: 0.75
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.46; acc: 0.84
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.71; acc: 0.77
Batch: 340; loss: 0.44; acc: 0.83
Batch: 360; loss: 0.55; acc: 0.84
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.6; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.84
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.6; acc: 0.81
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.62; acc: 0.86
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.66; acc: 0.8
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.093837484717369e-05
6.318837404251099e-05
Batch: 0; loss: 0.51; acc: 0.8
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.88; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4400378134884652; val_accuracy: 0.8622611464968153 

The current subspace-distance is: 6.318837404251099e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.7; acc: 0.81
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.65; acc: 0.81
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.43; acc: 0.83
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.3; acc: 0.86
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.82; acc: 0.8
Batch: 540; loss: 0.43; acc: 0.84
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.81
Batch: 680; loss: 0.6; acc: 0.83
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.5; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.61; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.028128311503679e-05
6.30280701443553e-05
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4401322786880147; val_accuracy: 0.8625597133757962 

The current subspace-distance is: 6.30280701443553e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 1.0; acc: 0.78
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.79; acc: 0.83
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.65; acc: 0.83
Batch: 260; loss: 0.5; acc: 0.84
Batch: 280; loss: 0.34; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.77; acc: 0.75
Batch: 380; loss: 0.6; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.68; acc: 0.8
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.72; acc: 0.78
Batch: 580; loss: 0.46; acc: 0.81
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.81
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.75; acc: 0.81
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.198251114459708e-05
6.439504068112001e-05
Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4358772887450874; val_accuracy: 0.8627587579617835 

The current subspace-distance is: 6.439504068112001e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.51; acc: 0.78
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.54; acc: 0.77
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.53; acc: 0.8
Batch: 280; loss: 0.46; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.46; acc: 0.8
Batch: 360; loss: 0.63; acc: 0.83
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.75; acc: 0.81
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.58; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.36; acc: 0.94
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.72; acc: 0.78
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.0647154643666e-05
6.4033069065772e-05
Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.43583226749661624; val_accuracy: 0.8645501592356688 

The current subspace-distance is: 6.4033069065772e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.8; acc: 0.8
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.61; acc: 0.84
Batch: 220; loss: 0.5; acc: 0.84
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.49; acc: 0.81
Batch: 300; loss: 0.58; acc: 0.84
Batch: 320; loss: 0.47; acc: 0.81
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.69; acc: 0.75
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.61; acc: 0.78
Batch: 420; loss: 0.47; acc: 0.84
Batch: 440; loss: 0.9; acc: 0.83
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.86
Batch: 520; loss: 0.49; acc: 0.78
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.55; acc: 0.83
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.72; acc: 0.77
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.81
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.074860332068056e-05
6.44539759377949e-05
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4339235305406485; val_accuracy: 0.8641520700636943 

The current subspace-distance is: 6.44539759377949e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.49; acc: 0.91
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.67; acc: 0.84
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.67; acc: 0.8
Batch: 220; loss: 0.64; acc: 0.78
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.89
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.59; acc: 0.83
Batch: 360; loss: 0.61; acc: 0.84
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.67; acc: 0.75
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.5; acc: 0.78
Batch: 460; loss: 0.5; acc: 0.81
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.74; acc: 0.81
Batch: 560; loss: 0.59; acc: 0.83
Batch: 580; loss: 0.7; acc: 0.84
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.138642104109749e-05
6.455736001953483e-05
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.89; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4323715125299563; val_accuracy: 0.8659434713375797 

The current subspace-distance is: 6.455736001953483e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.48; acc: 0.81
Batch: 60; loss: 0.37; acc: 0.81
Batch: 80; loss: 0.38; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.58; acc: 0.84
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.56; acc: 0.75
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.77; acc: 0.77
Batch: 280; loss: 0.5; acc: 0.86
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.66; acc: 0.81
Batch: 400; loss: 0.38; acc: 0.84
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.54; acc: 0.81
Batch: 520; loss: 0.74; acc: 0.8
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.66; acc: 0.77
Batch: 580; loss: 0.49; acc: 0.91
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.75; acc: 0.81
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

7.228331378428265e-05
6.513653352158144e-05
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.94; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4337355560937505; val_accuracy: 0.8644506369426752 

The current subspace-distance is: 6.513653352158144e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.6; acc: 0.83
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.6; acc: 0.84
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.47; acc: 0.83
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.48; acc: 0.91
Batch: 460; loss: 0.6; acc: 0.83
Batch: 480; loss: 0.58; acc: 0.81
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.68; acc: 0.75
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.83
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.36; acc: 0.83
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

7.184442802099511e-05
6.415099778678268e-05
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.43599302003717727; val_accuracy: 0.8643511146496815 

The current subspace-distance is: 6.415099778678268e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.75
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.71; acc: 0.81
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.5; acc: 0.8
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 0.68; acc: 0.81
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.64; acc: 0.86
Batch: 280; loss: 0.35; acc: 0.86
Batch: 300; loss: 0.41; acc: 0.83
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.95
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.57; acc: 0.8
Batch: 440; loss: 0.34; acc: 0.86
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.62; acc: 0.83
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.5; acc: 0.84
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.44; acc: 0.81
Batch: 660; loss: 0.44; acc: 0.81
Batch: 680; loss: 0.63; acc: 0.83
Batch: 700; loss: 0.56; acc: 0.86
Batch: 720; loss: 0.45; acc: 0.91
Batch: 740; loss: 0.54; acc: 0.81
Batch: 760; loss: 0.53; acc: 0.8
Batch: 780; loss: 0.53; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.166100840549916e-05
6.471167580457404e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.9; acc: 0.72
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4309812142116249; val_accuracy: 0.8672372611464968 

The current subspace-distance is: 6.471167580457404e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.72; acc: 0.83
Batch: 60; loss: 0.78; acc: 0.8
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.42; acc: 0.83
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.84
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.47; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.83
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.56; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.59; acc: 0.8
Batch: 440; loss: 0.59; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.44; acc: 0.81
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.69; acc: 0.78
Batch: 560; loss: 0.54; acc: 0.8
Batch: 580; loss: 0.58; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.81
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.59; acc: 0.84
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.86
Batch: 760; loss: 0.24; acc: 0.97
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.199552783276886e-05
6.383773143170401e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.92; acc: 0.72
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4307541327586599; val_accuracy: 0.8673367834394905 

The current subspace-distance is: 6.383773143170401e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.66; acc: 0.81
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.82; acc: 0.8
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.81
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.72; acc: 0.78
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.52; acc: 0.84
Batch: 440; loss: 0.61; acc: 0.83
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.81
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.51; acc: 0.78
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.53; acc: 0.78
Batch: 700; loss: 0.55; acc: 0.88
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.78; acc: 0.7
Batch: 780; loss: 0.63; acc: 0.78
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.188476593000814e-05
6.507258513011038e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4308617454805192; val_accuracy: 0.8654458598726115 

The current subspace-distance is: 6.507258513011038e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.66; acc: 0.86
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.86
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.49; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.7; acc: 0.8
Batch: 260; loss: 0.49; acc: 0.83
Batch: 280; loss: 0.57; acc: 0.81
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.81
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.91
Batch: 400; loss: 0.64; acc: 0.83
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.71; acc: 0.73
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.71; acc: 0.77
Batch: 620; loss: 0.57; acc: 0.8
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.63; acc: 0.81
Batch: 740; loss: 0.39; acc: 0.84
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.13606714271009e-05
6.458698771893978e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4300524707717501; val_accuracy: 0.8662420382165605 

The current subspace-distance is: 6.458698771893978e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.63; acc: 0.83
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.45; acc: 0.83
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.55; acc: 0.81
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.45; acc: 0.89
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.77; acc: 0.75
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.55; acc: 0.81
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.45; acc: 0.83
Batch: 680; loss: 0.51; acc: 0.83
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.054649904603139e-05
6.359507096931338e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42972156324773836; val_accuracy: 0.866640127388535 

The current subspace-distance is: 6.359507096931338e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.8; acc: 0.8
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.56; acc: 0.78
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.8
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.55; acc: 0.86
Batch: 180; loss: 0.53; acc: 0.83
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.45; acc: 0.83
Batch: 260; loss: 0.57; acc: 0.86
Batch: 280; loss: 0.68; acc: 0.77
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.84
Batch: 340; loss: 0.34; acc: 0.86
Batch: 360; loss: 0.52; acc: 0.88
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.8
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.53; acc: 0.81
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.81
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.42; acc: 0.83
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.114541222108528e-05
6.434683018596843e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.91; acc: 0.72
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4293369249838173; val_accuracy: 0.8669386942675159 

The current subspace-distance is: 6.434683018596843e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.83
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.92
Batch: 340; loss: 0.58; acc: 0.8
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.54; acc: 0.84
Batch: 400; loss: 0.56; acc: 0.84
Batch: 420; loss: 0.44; acc: 0.78
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.55; acc: 0.86
Batch: 500; loss: 0.56; acc: 0.84
Batch: 520; loss: 0.51; acc: 0.83
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.45; acc: 0.83
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.260515121743083e-05
6.391315400833264e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.42957015895539785; val_accuracy: 0.866640127388535 

The current subspace-distance is: 6.391315400833264e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.73; acc: 0.8
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.66; acc: 0.84
Batch: 220; loss: 0.59; acc: 0.81
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.54; acc: 0.8
Batch: 420; loss: 0.66; acc: 0.73
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.6; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.173734047682956e-05
6.48629866191186e-05
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.92
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4294592486160576; val_accuracy: 0.866640127388535 

The current subspace-distance is: 6.48629866191186e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.66; acc: 0.77
Batch: 60; loss: 0.64; acc: 0.8
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.55; acc: 0.8
Batch: 120; loss: 0.65; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.56; acc: 0.78
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.58; acc: 0.77
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.58; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.59; acc: 0.83
Batch: 380; loss: 0.56; acc: 0.88
Batch: 400; loss: 0.73; acc: 0.83
Batch: 420; loss: 0.69; acc: 0.81
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.7; acc: 0.81
Batch: 500; loss: 0.45; acc: 0.81
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.57; acc: 0.78
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.141211244743317e-05
6.48614950478077e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.92
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4289313515375374; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 6.48614950478077e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.67; acc: 0.78
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.38; acc: 0.83
Batch: 180; loss: 0.67; acc: 0.73
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.92
Batch: 260; loss: 0.61; acc: 0.77
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.75; acc: 0.8
Batch: 320; loss: 0.59; acc: 0.8
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.65; acc: 0.78
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.7; acc: 0.78
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.76; acc: 0.8
Batch: 480; loss: 0.6; acc: 0.81
Batch: 500; loss: 0.61; acc: 0.78
Batch: 520; loss: 0.62; acc: 0.75
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.59; acc: 0.83
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.84
Batch: 720; loss: 0.62; acc: 0.86
Batch: 740; loss: 0.46; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.107364945113659e-05
6.376040255418047e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4293950640946437; val_accuracy: 0.8671377388535032 

The current subspace-distance is: 6.376040255418047e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.88
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.67; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.56; acc: 0.83
Batch: 100; loss: 0.5; acc: 0.8
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.46; acc: 0.83
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.5; acc: 0.78
Batch: 380; loss: 0.45; acc: 0.86
Batch: 400; loss: 0.52; acc: 0.83
Batch: 420; loss: 0.91; acc: 0.78
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.53; acc: 0.83
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.57; acc: 0.78
Batch: 660; loss: 0.36; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.52; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.65; acc: 0.81
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.121887756511569e-05
6.388895417330787e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.91; acc: 0.72
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42872995033765293; val_accuracy: 0.866640127388535 

The current subspace-distance is: 6.388895417330787e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.69; acc: 0.81
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.53; acc: 0.89
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.55; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.86
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.69; acc: 0.81
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.43; acc: 0.81
Batch: 480; loss: 0.31; acc: 0.86
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.71; acc: 0.78
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.86
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.5; acc: 0.92
Batch: 700; loss: 0.51; acc: 0.84
Batch: 720; loss: 0.73; acc: 0.77
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.57; acc: 0.78
Batch: 780; loss: 0.6; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.218973769340664e-05
6.397523975465447e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42933402760962774; val_accuracy: 0.865843949044586 

The current subspace-distance is: 6.397523975465447e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.86
Batch: 40; loss: 0.75; acc: 0.8
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.64; acc: 0.8
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.83
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.51; acc: 0.8
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.54; acc: 0.86
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.77; acc: 0.8
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.49; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.55; acc: 0.83
Batch: 700; loss: 0.38; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.88; acc: 0.72
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.180110696936026e-05
6.567261880263686e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4291304502707378; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 6.567261880263686e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.51; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.43; acc: 0.83
Batch: 200; loss: 0.7; acc: 0.81
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.62; acc: 0.8
Batch: 260; loss: 0.62; acc: 0.8
Batch: 280; loss: 0.55; acc: 0.83
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.59; acc: 0.84
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.53; acc: 0.86
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.63; acc: 0.83
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.89; acc: 0.75
Batch: 680; loss: 0.61; acc: 0.77
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.69; acc: 0.8
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.47; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.194155477918684e-05
6.540264439536259e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.91
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.428419516107459; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 6.540264439536259e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.53; acc: 0.88
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.63; acc: 0.8
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.81; acc: 0.75
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.68; acc: 0.81
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.43; acc: 0.83
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.54; acc: 0.83
Batch: 540; loss: 0.32; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.8; acc: 0.77
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.23463817848824e-05
6.532829866046086e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4283732669368671; val_accuracy: 0.8664410828025477 

The current subspace-distance is: 6.532829866046086e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.72; acc: 0.83
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.65; acc: 0.77
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.77; acc: 0.77
Batch: 300; loss: 0.55; acc: 0.83
Batch: 320; loss: 0.66; acc: 0.83
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.48; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.78; acc: 0.77
Batch: 500; loss: 0.53; acc: 0.83
Batch: 520; loss: 0.64; acc: 0.81
Batch: 540; loss: 0.34; acc: 0.94
Batch: 560; loss: 0.68; acc: 0.81
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.8
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.57; acc: 0.84
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.77; acc: 0.83
Batch: 760; loss: 0.67; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.181012188084424e-05
6.435920658987015e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42902236071172034; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 6.435920658987015e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.6; acc: 0.83
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.53; acc: 0.81
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.63; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.48; acc: 0.89
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.48; acc: 0.88
Batch: 520; loss: 0.38; acc: 0.86
Batch: 540; loss: 0.62; acc: 0.86
Batch: 560; loss: 0.54; acc: 0.88
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.58; acc: 0.83
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.68; acc: 0.78
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.068877312121913e-05
6.463519093813375e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4283396797669921; val_accuracy: 0.866640127388535 

The current subspace-distance is: 6.463519093813375e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.57; acc: 0.84
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.52; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.43; acc: 0.84
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.89
Batch: 500; loss: 0.4; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.6; acc: 0.86
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.6; acc: 0.83
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.52; acc: 0.88
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.12131368345581e-05
6.452775414800271e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.72
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4283094893500304; val_accuracy: 0.8662420382165605 

The current subspace-distance is: 6.452775414800271e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.52; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.6; acc: 0.81
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.53; acc: 0.78
Batch: 260; loss: 0.55; acc: 0.83
Batch: 280; loss: 0.63; acc: 0.81
Batch: 300; loss: 0.51; acc: 0.81
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.56; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.59; acc: 0.77
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.58; acc: 0.8
Batch: 460; loss: 0.35; acc: 0.94
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.58; acc: 0.78
Batch: 520; loss: 0.77; acc: 0.78
Batch: 540; loss: 0.72; acc: 0.83
Batch: 560; loss: 0.43; acc: 0.83
Batch: 580; loss: 0.63; acc: 0.78
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.82; acc: 0.73
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.62; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.108424324542284e-05
6.465923070209101e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4284594405893308; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 6.465923070209101e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.61; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.52; acc: 0.8
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.49; acc: 0.8
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.62; acc: 0.77
Batch: 260; loss: 0.84; acc: 0.73
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.76; acc: 0.8
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.57; acc: 0.83
Batch: 400; loss: 0.62; acc: 0.88
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.67; acc: 0.8
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.66; acc: 0.78
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.59; acc: 0.77
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.6; acc: 0.84
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.214849028969184e-05
6.459726137109101e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42850398756326386; val_accuracy: 0.8662420382165605 

The current subspace-distance is: 6.459726137109101e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.74; acc: 0.78
Batch: 20; loss: 0.71; acc: 0.77
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.52; acc: 0.81
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.91
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.49; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.8
Batch: 400; loss: 0.53; acc: 0.84
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.84
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.84; acc: 0.7
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.63; acc: 0.8
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.69; acc: 0.78
Batch: 660; loss: 0.5; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.51; acc: 0.81
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.257094694068655e-05
6.447322084568441e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42802259700882966; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 6.447322084568441e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 0.64; acc: 0.78
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.65; acc: 0.83
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.62; acc: 0.81
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.27; acc: 0.88
Batch: 220; loss: 0.55; acc: 0.89
Batch: 240; loss: 0.51; acc: 0.86
Batch: 260; loss: 0.68; acc: 0.83
Batch: 280; loss: 0.61; acc: 0.84
Batch: 300; loss: 0.55; acc: 0.83
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.63; acc: 0.84
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.62; acc: 0.8
Batch: 420; loss: 0.52; acc: 0.81
Batch: 440; loss: 0.65; acc: 0.86
Batch: 460; loss: 0.48; acc: 0.83
Batch: 480; loss: 0.6; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.59; acc: 0.78
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.3; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.131269376259297e-05
6.349547038553283e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42826935459094445; val_accuracy: 0.8663415605095541 

The current subspace-distance is: 6.349547038553283e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.8
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.39; acc: 0.84
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.5; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.63; acc: 0.86
Batch: 360; loss: 0.49; acc: 0.89
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.57; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.83
Batch: 700; loss: 0.33; acc: 0.94
Batch: 720; loss: 0.64; acc: 0.81
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.124867988750339e-05
6.348929309751838e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42825518923390443; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 6.348929309751838e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.65; acc: 0.84
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.57; acc: 0.78
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.43; acc: 0.83
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.56; acc: 0.83
Batch: 460; loss: 0.45; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.59; acc: 0.86
Batch: 540; loss: 0.61; acc: 0.78
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.46; acc: 0.83
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.78
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.72; acc: 0.86
Batch: 780; loss: 0.59; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.141877722460777e-05
6.422602746170014e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42817163429442484; val_accuracy: 0.8660429936305732 

The current subspace-distance is: 6.422602746170014e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.48; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.73; acc: 0.78
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.62; acc: 0.78
Batch: 520; loss: 0.74; acc: 0.8
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.62; acc: 0.84
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.53; acc: 0.8
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.47; acc: 0.84
Batch: 720; loss: 0.67; acc: 0.83
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.62; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.121852831915021e-05
6.41843507764861e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42815203751158565; val_accuracy: 0.865843949044586 

The current subspace-distance is: 6.41843507764861e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.92
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.58; acc: 0.8
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.84
Batch: 180; loss: 0.71; acc: 0.81
Batch: 200; loss: 0.62; acc: 0.84
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.84
Batch: 340; loss: 0.62; acc: 0.81
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.5; acc: 0.89
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.78
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.68; acc: 0.81
Batch: 760; loss: 0.49; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.125235424609855e-05
6.488950020866469e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42819668618357104; val_accuracy: 0.8662420382165605 

The current subspace-distance is: 6.488950020866469e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.5; acc: 0.88
Batch: 360; loss: 0.44; acc: 0.83
Batch: 380; loss: 1.03; acc: 0.81
Batch: 400; loss: 0.57; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.77; acc: 0.75
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.51; acc: 0.84
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.53; acc: 0.8
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.73; acc: 0.78
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.54; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.196405931608751e-05
6.441177538363263e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42818010992305294; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 6.441177538363263e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.62; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.57; acc: 0.86
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.8; acc: 0.8
Batch: 200; loss: 0.49; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.57; acc: 0.8
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.81
Batch: 580; loss: 0.67; acc: 0.75
Batch: 600; loss: 0.62; acc: 0.81
Batch: 620; loss: 0.53; acc: 0.78
Batch: 640; loss: 0.44; acc: 0.8
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.65; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.66; acc: 0.81
Batch: 780; loss: 0.47; acc: 0.84
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.203585118986666e-05
6.587579264305532e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42822129279375076; val_accuracy: 0.8660429936305732 

The current subspace-distance is: 6.587579264305532e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.8
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.62; acc: 0.83
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.42; acc: 0.83
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.46; acc: 0.81
Batch: 320; loss: 0.34; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.5; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.65; acc: 0.77
Batch: 600; loss: 0.78; acc: 0.83
Batch: 620; loss: 0.43; acc: 0.84
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.76; acc: 0.78
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.65; acc: 0.83
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.57; acc: 0.8
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.172524055931717e-05
6.458027201006189e-05
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4282173288950495; val_accuracy: 0.8660429936305732 

The current subspace-distance is: 6.458027201006189e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.6; acc: 0.83
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.48; acc: 0.88
Batch: 240; loss: 0.54; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.84
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.61; acc: 0.8
Batch: 340; loss: 0.54; acc: 0.89
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.83
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.6; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.38; acc: 0.84
Batch: 620; loss: 0.46; acc: 0.91
Batch: 640; loss: 0.75; acc: 0.81
Batch: 660; loss: 0.55; acc: 0.81
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.94
Batch: 720; loss: 0.88; acc: 0.83
Batch: 740; loss: 0.74; acc: 0.78
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.239713158924133e-05
6.536300497828051e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42813432041057353; val_accuracy: 0.8657444267515924 

The current subspace-distance is: 6.536300497828051e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.7; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.54; acc: 0.8
Batch: 200; loss: 0.52; acc: 0.81
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.59; acc: 0.86
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.3; acc: 0.95
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.59; acc: 0.78
Batch: 460; loss: 0.65; acc: 0.84
Batch: 480; loss: 0.54; acc: 0.86
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.66; acc: 0.75
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.97; acc: 0.75
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.8
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

7.1506314270664e-05
6.524477066705003e-05
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42806239250549083; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 6.524477066705003e-05 

plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 267571
elements in E: 119526000
fraction nonzero: 0.0022386008065190836
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.26; acc: 0.33
Batch: 80; loss: 2.26; acc: 0.25
Batch: 100; loss: 2.22; acc: 0.31
Batch: 120; loss: 2.19; acc: 0.42
Batch: 140; loss: 2.21; acc: 0.33
Batch: 160; loss: 2.19; acc: 0.42
Batch: 180; loss: 2.15; acc: 0.42
Batch: 200; loss: 2.1; acc: 0.48
Batch: 220; loss: 2.08; acc: 0.56
Batch: 240; loss: 2.04; acc: 0.59
Batch: 260; loss: 1.99; acc: 0.56
Batch: 280; loss: 1.97; acc: 0.48
Batch: 300; loss: 1.91; acc: 0.52
Batch: 320; loss: 1.9; acc: 0.48
Batch: 340; loss: 1.87; acc: 0.44
Batch: 360; loss: 1.75; acc: 0.55
Batch: 380; loss: 1.71; acc: 0.53
Batch: 400; loss: 1.51; acc: 0.62
Batch: 420; loss: 1.36; acc: 0.73
Batch: 440; loss: 1.41; acc: 0.61
Batch: 460; loss: 1.29; acc: 0.69
Batch: 480; loss: 1.28; acc: 0.69
Batch: 500; loss: 1.15; acc: 0.64
Batch: 520; loss: 1.01; acc: 0.75
Batch: 540; loss: 1.02; acc: 0.75
Batch: 560; loss: 1.02; acc: 0.8
Batch: 580; loss: 0.94; acc: 0.75
Batch: 600; loss: 0.89; acc: 0.75
Batch: 620; loss: 1.01; acc: 0.69
Batch: 640; loss: 0.73; acc: 0.78
Batch: 660; loss: 0.77; acc: 0.8
Batch: 680; loss: 0.62; acc: 0.83
Batch: 700; loss: 0.7; acc: 0.8
Batch: 720; loss: 0.84; acc: 0.73
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.67; acc: 0.77
Batch: 780; loss: 0.5; acc: 0.89
Train Epoch over. train_loss: 1.53; train_accuracy: 0.58 

4.377717777970247e-05
4.1553947085049e-05
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.68; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 1.04; acc: 0.67
Batch: 140; loss: 0.39; acc: 0.89
Val Epoch over. val_loss: 0.6500771136800195; val_accuracy: 0.8112062101910829 

The current subspace-distance is: 4.1553947085049e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.76; acc: 0.77
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.61; acc: 0.78
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.67; acc: 0.78
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.65; acc: 0.72
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.91
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.65; acc: 0.83
Batch: 340; loss: 0.56; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.78
Batch: 380; loss: 0.54; acc: 0.88
Batch: 400; loss: 1.02; acc: 0.77
Batch: 420; loss: 0.62; acc: 0.81
Batch: 440; loss: 0.84; acc: 0.75
Batch: 460; loss: 0.56; acc: 0.89
Batch: 480; loss: 0.61; acc: 0.8
Batch: 500; loss: 0.52; acc: 0.86
Batch: 520; loss: 0.52; acc: 0.8
Batch: 540; loss: 0.36; acc: 0.94
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.7; acc: 0.73
Batch: 600; loss: 0.62; acc: 0.8
Batch: 620; loss: 0.87; acc: 0.7
Batch: 640; loss: 0.53; acc: 0.8
Batch: 660; loss: 0.53; acc: 0.8
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.7; acc: 0.8
Batch: 720; loss: 0.63; acc: 0.77
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

5.636760761262849e-05
5.035947833675891e-05
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.53; acc: 0.91
Batch: 120; loss: 0.93; acc: 0.67
Batch: 140; loss: 0.23; acc: 0.95
Val Epoch over. val_loss: 0.47170900857182824; val_accuracy: 0.8626592356687898 

The current subspace-distance is: 5.035947833675891e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.8
Batch: 180; loss: 0.41; acc: 0.81
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.9; acc: 0.77
Batch: 260; loss: 0.62; acc: 0.8
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.5; acc: 0.84
Batch: 380; loss: 0.58; acc: 0.84
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.44; acc: 0.83
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.66; acc: 0.8
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.7; acc: 0.78
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.48; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.83
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.71; acc: 0.75
Batch: 660; loss: 0.6; acc: 0.83
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.52; acc: 0.81
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

6.104225030867383e-05
5.4250202083494514e-05
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.91; acc: 0.69
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.4296188697123983; val_accuracy: 0.8746019108280255 

The current subspace-distance is: 5.4250202083494514e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.59; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.84
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.71; acc: 0.78
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.64; acc: 0.78
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.78; acc: 0.77
Batch: 400; loss: 0.36; acc: 0.94
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.44; acc: 0.83
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.55; acc: 0.83
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.34; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.81
Batch: 600; loss: 0.57; acc: 0.83
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.58; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.55; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

6.331210170174018e-05
5.6836288422346115e-05
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.7
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.41157736092995684; val_accuracy: 0.8785828025477707 

The current subspace-distance is: 5.6836288422346115e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.51; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.83
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.56; acc: 0.81
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.72; acc: 0.8
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.95
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.5; acc: 0.83
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.86
Batch: 560; loss: 0.63; acc: 0.77
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.51; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.64; acc: 0.8
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

6.616848986595869e-05
5.929545659455471e-05
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3981802380483621; val_accuracy: 0.8804737261146497 

The current subspace-distance is: 5.929545659455471e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.49; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.86
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.51; acc: 0.8
Batch: 360; loss: 0.33; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.54; acc: 0.8
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.84
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.56; acc: 0.81
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

6.624167144764215e-05
5.926632002228871e-05
Batch: 0; loss: 0.32; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3895113791345031; val_accuracy: 0.8853503184713376 

The current subspace-distance is: 5.926632002228871e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.88
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.41; acc: 0.84
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.94
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.39; acc: 0.94
Batch: 480; loss: 0.53; acc: 0.8
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.55; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

6.769374158466235e-05
5.9827056247740984e-05
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3802258271700258; val_accuracy: 0.8872412420382165 

The current subspace-distance is: 5.9827056247740984e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.57; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.73; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.76; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.35; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.49; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.65; acc: 0.8
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.37; acc: 0.84
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

6.807452882640064e-05
6.088100781198591e-05
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.38235663380592494; val_accuracy: 0.8850517515923567 

The current subspace-distance is: 6.088100781198591e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.36; acc: 0.83
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.44; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.84
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.58; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.59; acc: 0.88
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.38; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.51; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.92
Batch: 660; loss: 0.48; acc: 0.8
Batch: 680; loss: 0.48; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.84
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.52; acc: 0.88
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.61; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

6.882011803099886e-05
6.152056448627263e-05
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3780804441850277; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 6.152056448627263e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.18; acc: 0.98
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

6.901719461893663e-05
6.151471461635083e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.36864351267647594; val_accuracy: 0.8878383757961783 

The current subspace-distance is: 6.151471461635083e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.88
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.49; acc: 0.89
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.59; acc: 0.84
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.49; acc: 0.8
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.55; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.78; acc: 0.77
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

6.985328946029767e-05
6.203648081282154e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3660905975729797; val_accuracy: 0.888734076433121 

The current subspace-distance is: 6.203648081282154e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.44; acc: 0.83
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.47; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

7.069209823384881e-05
6.243722600629553e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.89
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3636331096955925; val_accuracy: 0.8880374203821656 

The current subspace-distance is: 6.243722600629553e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.83
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.97
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.74; acc: 0.84
Batch: 540; loss: 0.51; acc: 0.84
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.81
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

6.936876161489636e-05
6.192171713337302e-05
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3645469716684833; val_accuracy: 0.8890326433121019 

The current subspace-distance is: 6.192171713337302e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.82; acc: 0.8
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.53; acc: 0.81
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.86
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.56; acc: 0.8
Batch: 380; loss: 0.54; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.88
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.5; acc: 0.81
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

7.009886030573398e-05
6.271387246670201e-05
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.36080499076444633; val_accuracy: 0.8901273885350318 

The current subspace-distance is: 6.271387246670201e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.59; acc: 0.88
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.66; acc: 0.78
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.53; acc: 0.86
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.58; acc: 0.88
Batch: 720; loss: 0.48; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.84
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

6.982737249927595e-05
6.173986184876412e-05
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3627020121569846; val_accuracy: 0.8896297770700637 

The current subspace-distance is: 6.173986184876412e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.39; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.59; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.84
Batch: 500; loss: 0.56; acc: 0.84
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.41; acc: 0.84
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

7.067206024657935e-05
6.276810745475814e-05
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.3590840818538408; val_accuracy: 0.89171974522293 

The current subspace-distance is: 6.276810745475814e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.58; acc: 0.81
Batch: 360; loss: 0.51; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.8
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.83
Batch: 560; loss: 0.56; acc: 0.88
Batch: 580; loss: 0.51; acc: 0.81
Batch: 600; loss: 0.48; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.42; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

7.067315891617909e-05
6.31357979727909e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3585153989446391; val_accuracy: 0.8916202229299363 

The current subspace-distance is: 6.31357979727909e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.54; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.63; acc: 0.84
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.64; acc: 0.78
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.89
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.73; acc: 0.8
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

7.059022027533501e-05
6.375730299623683e-05
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.35922712426941106; val_accuracy: 0.89171974522293 

The current subspace-distance is: 6.375730299623683e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.58; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.52; acc: 0.88
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.11; acc: 1.0
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.81
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.42; acc: 0.83
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.31; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.42; acc: 0.83
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.55; acc: 0.88
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

7.061060750856996e-05
6.322981062112376e-05
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3603365920531522; val_accuracy: 0.8914211783439491 

The current subspace-distance is: 6.322981062112376e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.58; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.5; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.95
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.53; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.54; acc: 0.88
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.44; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.112627645255998e-05
6.251928425626829e-05
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.35577088646638166; val_accuracy: 0.8915207006369427 

The current subspace-distance is: 6.251928425626829e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.84
Batch: 260; loss: 0.3; acc: 0.86
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.54; acc: 0.8
Batch: 400; loss: 0.22; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.86
Batch: 700; loss: 0.63; acc: 0.83
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.079336501192302e-05
6.22465813648887e-05
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3537226446494935; val_accuracy: 0.8941082802547771 

The current subspace-distance is: 6.22465813648887e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.59; acc: 0.8
Batch: 300; loss: 0.38; acc: 0.83
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.81
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.55; acc: 0.84
Batch: 700; loss: 0.6; acc: 0.84
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.83
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.146599818952382e-05
6.40912403468974e-05
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.35354993238475674; val_accuracy: 0.8934116242038217 

The current subspace-distance is: 6.40912403468974e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.58; acc: 0.88
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.45; acc: 0.83
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.71; acc: 0.86
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.52; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.51; acc: 0.8
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.177909719757736e-05
6.368523463606834e-05
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3532096001372975; val_accuracy: 0.8935111464968153 

The current subspace-distance is: 6.368523463606834e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.97
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.5; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.75; acc: 0.83
Batch: 500; loss: 0.59; acc: 0.84
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.52; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.132106111384928e-05
6.366677553160116e-05
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3519742466794078; val_accuracy: 0.8946058917197452 

The current subspace-distance is: 6.366677553160116e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.57; acc: 0.8
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.41; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.8
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.57; acc: 0.86
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.86
Batch: 460; loss: 0.52; acc: 0.83
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.83
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.23; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.221994019346312e-05
6.340238905977458e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.35202426444383184; val_accuracy: 0.8955015923566879 

The current subspace-distance is: 6.340238905977458e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.86
Batch: 540; loss: 0.54; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.119001384126022e-05
6.300207314779982e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3515856960776505; val_accuracy: 0.8938097133757962 

The current subspace-distance is: 6.300207314779982e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.88
Batch: 200; loss: 0.49; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.66; acc: 0.83
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.86
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.42; acc: 0.91
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.52; acc: 0.8
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.2; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.55; acc: 0.84
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.86
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.139511581044644e-05
6.33541276329197e-05
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3520988947029706; val_accuracy: 0.893312101910828 

The current subspace-distance is: 6.33541276329197e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.62; acc: 0.83
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.92
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.71; acc: 0.77
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.8
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.56; acc: 0.88
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.32; acc: 0.86
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.296964031411335e-05
6.537254375871271e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.35119477106602326; val_accuracy: 0.894406847133758 

The current subspace-distance is: 6.537254375871271e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.53; acc: 0.81
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.98
Batch: 180; loss: 0.48; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.78
Batch: 320; loss: 0.48; acc: 0.78
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.78
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.71; acc: 0.8
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.176803046604618e-05
6.33930612821132e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.350706793842422; val_accuracy: 0.8946058917197452 

The current subspace-distance is: 6.33930612821132e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.98
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.84; acc: 0.8
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.10519525455311e-05
6.391310307662934e-05
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.3511934086063485; val_accuracy: 0.8939092356687898 

The current subspace-distance is: 6.391310307662934e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.92
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.63; acc: 0.83
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.46; acc: 0.83
Batch: 380; loss: 0.42; acc: 0.8
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.22; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.38; acc: 0.84
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.48; acc: 0.81
Batch: 660; loss: 0.46; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.89
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.141420792322606e-05
6.350276089506224e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.35022820283178313; val_accuracy: 0.8953025477707006 

The current subspace-distance is: 6.350276089506224e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.24; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.89
Batch: 520; loss: 0.6; acc: 0.83
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.14; acc: 0.98
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.68; acc: 0.78
Batch: 680; loss: 0.45; acc: 0.81
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.136521162465215e-05
6.364701403072104e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34987033139558354; val_accuracy: 0.894406847133758 

The current subspace-distance is: 6.364701403072104e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.53; acc: 0.88
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.47; acc: 0.83
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.44; acc: 0.91
Batch: 260; loss: 0.53; acc: 0.84
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.8
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.86
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.64; acc: 0.88
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.95
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.210869080154225e-05
6.423090962925926e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3498946188646517; val_accuracy: 0.8948049363057324 

The current subspace-distance is: 6.423090962925926e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.34; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.66; acc: 0.86
Batch: 380; loss: 0.54; acc: 0.86
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.53; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.14487541699782e-05
6.360881525324658e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34970554771127216; val_accuracy: 0.8949044585987261 

The current subspace-distance is: 6.360881525324658e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.43; acc: 0.84
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.51; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.45; acc: 0.8
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.57; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.44; acc: 0.86
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.89
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.11432658135891e-05
6.329033203655854e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34965285464267065; val_accuracy: 0.8940087579617835 

The current subspace-distance is: 6.329033203655854e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.57; acc: 0.88
Batch: 40; loss: 0.59; acc: 0.75
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.32; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.65; acc: 0.84
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.62; acc: 0.81
Batch: 420; loss: 0.37; acc: 0.95
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.86
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.74; acc: 0.8
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.52; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.112799357855693e-05
6.352030322887003e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34931774261840587; val_accuracy: 0.8938097133757962 

The current subspace-distance is: 6.352030322887003e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.5; acc: 0.8
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.84
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.68; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.5; acc: 0.81
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.15330388629809e-05
6.374159420374781e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3494918440367765; val_accuracy: 0.895203025477707 

The current subspace-distance is: 6.374159420374781e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.44; acc: 0.83
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.91
Batch: 380; loss: 0.59; acc: 0.86
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.86
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.64; acc: 0.84
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.84
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.6; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.69; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

7.211515185190365e-05
6.437379488488659e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.349015477570189; val_accuracy: 0.895203025477707 

The current subspace-distance is: 6.437379488488659e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.54; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.71; acc: 0.84
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.64; acc: 0.86
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.58; acc: 0.83
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.23639823263511e-05
6.395611853804439e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.34905729827227866; val_accuracy: 0.8942078025477707 

The current subspace-distance is: 6.395611853804439e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.68; acc: 0.88
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.59; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.54; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.55; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.26; acc: 0.95
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.223965076263994e-05
6.404919258784503e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34870745471803244; val_accuracy: 0.8949044585987261 

The current subspace-distance is: 6.404919258784503e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.55; acc: 0.84
Batch: 280; loss: 0.48; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.84
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.56; acc: 0.84
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.4; acc: 0.92
Batch: 620; loss: 0.57; acc: 0.81
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.97
Batch: 720; loss: 0.37; acc: 0.83
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.161371468100697e-05
6.370776100084186e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34877727294613603; val_accuracy: 0.8950039808917197 

The current subspace-distance is: 6.370776100084186e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.98
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.47; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.28; acc: 0.88
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.5; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.5; acc: 0.84
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.98
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.46; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.143579568946734e-05
6.388926703948528e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.3486768893517886; val_accuracy: 0.8945063694267515 

The current subspace-distance is: 6.388926703948528e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.97
Batch: 40; loss: 0.42; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.58; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.5; acc: 0.83
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.189590542111546e-05
6.472526729339734e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34866670521486337; val_accuracy: 0.895203025477707 

The current subspace-distance is: 6.472526729339734e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.5; acc: 0.86
Batch: 180; loss: 0.54; acc: 0.8
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.52; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.83
Batch: 400; loss: 0.64; acc: 0.81
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.83
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.62; acc: 0.84
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.20364841981791e-05
6.343662244034931e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3486246103361534; val_accuracy: 0.8950039808917197 

The current subspace-distance is: 6.343662244034931e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.69; acc: 0.83
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.48; acc: 0.8
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.43; acc: 0.84
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.164068665588275e-05
6.402806320693344e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3485740201346054; val_accuracy: 0.8955015923566879 

The current subspace-distance is: 6.402806320693344e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.52; acc: 0.88
Batch: 380; loss: 0.65; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.81
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.63; acc: 0.84
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.12; acc: 1.0
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.18884402886033e-05
6.405488966265693e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34860398589520697; val_accuracy: 0.8954020700636943 

The current subspace-distance is: 6.405488966265693e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.52; acc: 0.88
Batch: 160; loss: 0.49; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.84
Batch: 200; loss: 0.51; acc: 0.86
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.58; acc: 0.84
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.62; acc: 0.83
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.83
Batch: 580; loss: 0.54; acc: 0.81
Batch: 600; loss: 0.38; acc: 0.84
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.238303078338504e-05
6.429119821405038e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3486198778412524; val_accuracy: 0.8948049363057324 

The current subspace-distance is: 6.429119821405038e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.46; acc: 0.81
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.56; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.92
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.59; acc: 0.88
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.6; acc: 0.75
Batch: 680; loss: 0.39; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.15981877874583e-05
6.316812505247071e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34857624391936193; val_accuracy: 0.8953025477707006 

The current subspace-distance is: 6.316812505247071e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.59; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.51; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.68; acc: 0.78
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.71; acc: 0.78
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.4; acc: 0.92
Batch: 720; loss: 0.49; acc: 0.89
Batch: 740; loss: 0.67; acc: 0.8
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.168336014728993e-05
6.353845674311742e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3483856193911118; val_accuracy: 0.8949044585987261 

The current subspace-distance is: 6.353845674311742e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.8
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.8
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.84
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.48; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.43; acc: 0.92
Batch: 380; loss: 0.51; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.47; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.75; acc: 0.78
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

7.221819396363571e-05
6.366522575262934e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3484103100457389; val_accuracy: 0.8958001592356688 

The current subspace-distance is: 6.366522575262934e-05 

plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_600_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 357713
elements in E: 159368000
fraction nonzero: 0.0022445723106269766
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.27; acc: 0.2
Batch: 60; loss: 2.24; acc: 0.34
Batch: 80; loss: 2.23; acc: 0.33
Batch: 100; loss: 2.21; acc: 0.33
Batch: 120; loss: 2.15; acc: 0.47
Batch: 140; loss: 2.17; acc: 0.39
Batch: 160; loss: 2.12; acc: 0.48
Batch: 180; loss: 2.08; acc: 0.45
Batch: 200; loss: 1.99; acc: 0.55
Batch: 220; loss: 1.91; acc: 0.64
Batch: 240; loss: 1.84; acc: 0.66
Batch: 260; loss: 1.78; acc: 0.69
Batch: 280; loss: 1.63; acc: 0.64
Batch: 300; loss: 1.64; acc: 0.61
Batch: 320; loss: 1.56; acc: 0.66
Batch: 340; loss: 1.47; acc: 0.64
Batch: 360; loss: 1.3; acc: 0.64
Batch: 380; loss: 1.2; acc: 0.67
Batch: 400; loss: 1.0; acc: 0.77
Batch: 420; loss: 0.92; acc: 0.72
Batch: 440; loss: 0.9; acc: 0.83
Batch: 460; loss: 0.88; acc: 0.77
Batch: 480; loss: 0.84; acc: 0.81
Batch: 500; loss: 0.82; acc: 0.75
Batch: 520; loss: 0.7; acc: 0.83
Batch: 540; loss: 0.63; acc: 0.88
Batch: 560; loss: 0.77; acc: 0.75
Batch: 580; loss: 0.77; acc: 0.78
Batch: 600; loss: 0.66; acc: 0.81
Batch: 620; loss: 1.03; acc: 0.72
Batch: 640; loss: 0.61; acc: 0.75
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.6; acc: 0.81
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.71; acc: 0.73
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.54; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 1.32; train_accuracy: 0.64 

4.488876948016696e-05
4.183702185400762e-05
Batch: 0; loss: 0.6; acc: 0.86
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.59; acc: 0.88
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.53102400775548; val_accuracy: 0.8393710191082803 

The current subspace-distance is: 4.183702185400762e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.92
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.79; acc: 0.8
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.55; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.88
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.52; acc: 0.86
Batch: 600; loss: 0.52; acc: 0.8
Batch: 620; loss: 0.7; acc: 0.83
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

5.5083950428524986e-05
4.9461716116638854e-05
Batch: 0; loss: 0.46; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.41231513507426926; val_accuracy: 0.8771894904458599 

The current subspace-distance is: 4.9461716116638854e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.51; acc: 0.81
Batch: 240; loss: 0.78; acc: 0.81
Batch: 260; loss: 0.52; acc: 0.8
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.95
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.61; acc: 0.83
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.84
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.49; acc: 0.8
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.5; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.88
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

5.9813482948811725e-05
5.375072578317486e-05
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.3701547500054548; val_accuracy: 0.8886345541401274 

The current subspace-distance is: 5.375072578317486e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.46; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.81
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.32; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.57; acc: 0.8
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.71; acc: 0.84
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.83
Batch: 640; loss: 0.65; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

6.284979463089257e-05
5.676385262631811e-05
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3607431073097666; val_accuracy: 0.893312101910828 

The current subspace-distance is: 5.676385262631811e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.89
Batch: 380; loss: 0.56; acc: 0.8
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.47; acc: 0.83
Batch: 500; loss: 0.56; acc: 0.8
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.86
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.94
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.65; acc: 0.84
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

6.586102972505614e-05
5.8888192143058404e-05
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3377639250295937; val_accuracy: 0.899781050955414 

The current subspace-distance is: 5.8888192143058404e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.59; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.86
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.84
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.51; acc: 0.86
Batch: 520; loss: 0.51; acc: 0.81
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.64; acc: 0.84
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.84
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

6.681475497316569e-05
5.948508623987436e-05
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.32716136738942686; val_accuracy: 0.903562898089172 

The current subspace-distance is: 5.948508623987436e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.44; acc: 0.78
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.63; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.64; acc: 0.83
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

6.784128345316276e-05
6.116392614785582e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3143140491406629; val_accuracy: 0.9077428343949044 

The current subspace-distance is: 6.116392614785582e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.56; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.6; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.86
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.77; acc: 0.77
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.59; acc: 0.78
Batch: 500; loss: 0.49; acc: 0.81
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.83
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.54; acc: 0.83
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

6.874613609397784e-05
6.16917313891463e-05
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.323772348677087; val_accuracy: 0.9034633757961783 

The current subspace-distance is: 6.16917313891463e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.54; acc: 0.81
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.24; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.39; acc: 0.83
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.66; acc: 0.84
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.95
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.49; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.84
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.51; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

7.002010534051806e-05
6.304005364654586e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.31656217646257134; val_accuracy: 0.9057523885350318 

The current subspace-distance is: 6.304005364654586e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.5; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

7.223376451293007e-05
6.480836600530893e-05
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.30267072018164737; val_accuracy: 0.9098328025477707 

The current subspace-distance is: 6.480836600530893e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.88
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.83
Batch: 520; loss: 0.69; acc: 0.84
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.5; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.71; acc: 0.83
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.69; acc: 0.83
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

7.089073187671602e-05
6.354590004775673e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2978476439691653; val_accuracy: 0.9118232484076433 

The current subspace-distance is: 6.354590004775673e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.83
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.84
Batch: 520; loss: 0.34; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

7.11247994331643e-05
6.431565998354927e-05
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2958159177166641; val_accuracy: 0.9118232484076433 

The current subspace-distance is: 6.431565998354927e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.62; acc: 0.84
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.5; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.7; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.193787314463407e-05
6.520452006952837e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.29561382980578266; val_accuracy: 0.9110270700636943 

The current subspace-distance is: 6.520452006952837e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.97
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.251747592817992e-05
6.533759005833417e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2954292705246977; val_accuracy: 0.9113256369426752 

The current subspace-distance is: 6.533759005833417e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.34; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.206916779978201e-05
6.494444096460938e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.29237182046862165; val_accuracy: 0.9120222929936306 

The current subspace-distance is: 6.494444096460938e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.53; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.5; acc: 0.88
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.64; acc: 0.83
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.86
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.35; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.97
Batch: 780; loss: 0.36; acc: 0.95
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.222100248327479e-05
6.51340014883317e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2938501581217453; val_accuracy: 0.9129179936305732 

The current subspace-distance is: 6.51340014883317e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.15; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.51; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.437195017701015e-05
6.695416232105345e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.291434022319165; val_accuracy: 0.9143113057324841 

The current subspace-distance is: 6.695416232105345e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.53; acc: 0.88
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.59; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.14; acc: 1.0
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.95
Batch: 560; loss: 0.45; acc: 0.83
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.315454422496259e-05
6.574598228326067e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2939926105414986; val_accuracy: 0.9110270700636943 

The current subspace-distance is: 6.574598228326067e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.4; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.86
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.326260674744844e-05
6.566780939465389e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.294881906882403; val_accuracy: 0.9117237261146497 

The current subspace-distance is: 6.566780939465389e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.84
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.41; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.57; acc: 0.88
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.32; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

7.33301421860233e-05
6.563273200299591e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2894421790008712; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 6.563273200299591e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.4; acc: 0.94
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.23; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.47; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.45; acc: 0.83
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.56; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.51; acc: 0.83
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.337367424042895e-05
6.619031773880124e-05
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2878321099812817; val_accuracy: 0.9150079617834395 

The current subspace-distance is: 6.619031773880124e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.08; acc: 1.0
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.37; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.83
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.458064646925777e-05
6.640607170993462e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2888238179455897; val_accuracy: 0.9150079617834395 

The current subspace-distance is: 6.640607170993462e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.61; acc: 0.83
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.48; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.396464934572577e-05
6.66606574668549e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.28749292500459467; val_accuracy: 0.9148089171974523 

The current subspace-distance is: 6.66606574668549e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.83
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.88
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.32814078219235e-05
6.602404027944431e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28634460203966516; val_accuracy: 0.9157046178343949 

The current subspace-distance is: 6.602404027944431e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.384161290246993e-05
6.655806646449491e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2866689330263502; val_accuracy: 0.915406050955414 

The current subspace-distance is: 6.655806646449491e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.83
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.33; acc: 0.84
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.375170389423147e-05
6.549631507368758e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2865596791836107; val_accuracy: 0.9165007961783439 

The current subspace-distance is: 6.549631507368758e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.58; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.21; acc: 0.88
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.31042746338062e-05
6.51182999718003e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2867050380179077; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 6.51182999718003e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.86
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.79; acc: 0.84
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.330900552915409e-05
6.611002027057111e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28586289044588237; val_accuracy: 0.9165007961783439 

The current subspace-distance is: 6.611002027057111e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.84
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.62; acc: 0.88
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.414589344989508e-05
6.576027226401493e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2859199573849417; val_accuracy: 0.9158041401273885 

The current subspace-distance is: 6.576027226401493e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.55; acc: 0.84
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.86
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.77; acc: 0.83
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.426700176438317e-05
6.71270172460936e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.28605790227461775; val_accuracy: 0.9167993630573248 

The current subspace-distance is: 6.71270172460936e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.83
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.403221388813108e-05
6.701184611301869e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2859352787446444; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 6.701184611301869e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.46; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.53; acc: 0.77
Batch: 540; loss: 0.22; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.63; acc: 0.78
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.45; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.368619117187336e-05
6.718552322126925e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2852865066497948; val_accuracy: 0.9158041401273885 

The current subspace-distance is: 6.718552322126925e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.86
Batch: 660; loss: 0.74; acc: 0.88
Batch: 680; loss: 0.52; acc: 0.81
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.55; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.412085687974468e-05
6.58456701785326e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2849469215721841; val_accuracy: 0.917296974522293 

The current subspace-distance is: 6.58456701785326e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.69; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.64; acc: 0.77
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.430817640852183e-05
6.66697378619574e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28520436485292044; val_accuracy: 0.9161027070063694 

The current subspace-distance is: 6.66697378619574e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.5; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.95
Batch: 480; loss: 0.42; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.92
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.56; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.459761400241405e-05
6.645567918894812e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2850249691089247; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 6.645567918894812e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.39; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.379733870038763e-05
6.620276690227911e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2851451981788988; val_accuracy: 0.9167993630573248 

The current subspace-distance is: 6.620276690227911e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.95
Batch: 640; loss: 0.56; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.417178858304396e-05
6.662408850388601e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2847338747351792; val_accuracy: 0.9163017515923567 

The current subspace-distance is: 6.662408850388601e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.84
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.3; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.57; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.59; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.53; acc: 0.83
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

7.44112185202539e-05
6.62324164295569e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2850728540378771; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 6.62324164295569e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.63; acc: 0.83
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.45; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.432809798046947e-05
6.670317088719457e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2848866491750547; val_accuracy: 0.917296974522293 

The current subspace-distance is: 6.670317088719457e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.63; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.59; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.98
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.64; acc: 0.83
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.424209616146982e-05
6.611960270674899e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.284229739930979; val_accuracy: 0.916202229299363 

The current subspace-distance is: 6.611960270674899e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.98
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.47; acc: 0.89
Batch: 260; loss: 0.51; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.84
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.53; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.84
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.46481673559174e-05
6.668210698990151e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2842983320165592; val_accuracy: 0.9165007961783439 

The current subspace-distance is: 6.668210698990151e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.86
Batch: 360; loss: 0.24; acc: 0.97
Batch: 380; loss: 0.43; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.429036486428231e-05
6.67291387799196e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2842604509869199; val_accuracy: 0.9169984076433121 

The current subspace-distance is: 6.67291387799196e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.43; acc: 0.83
Batch: 360; loss: 0.4; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.49; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.13; acc: 0.98
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.381190516753122e-05
6.649074930464849e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28423732822867714; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 6.649074930464849e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.37; acc: 0.84
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.23; acc: 0.97
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.49; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.88
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.8
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.392597763100639e-05
6.634462624788284e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.28426874765924587; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 6.634462624788284e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.43; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.444552466040477e-05
6.672085874015465e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2841933429905563; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 6.672085874015465e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.45; acc: 0.81
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.67; acc: 0.91
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.514154276577756e-05
6.673070311080664e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28416364094254315; val_accuracy: 0.9170979299363057 

The current subspace-distance is: 6.673070311080664e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.45; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.95
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.48; acc: 0.86
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.97
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.403305789921433e-05
6.612511788262054e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2843063555325672; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 6.612511788262054e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.43; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.57; acc: 0.89
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.25; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.37; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.516707410104573e-05
6.828061304986477e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.28421346411393705; val_accuracy: 0.9170979299363057 

The current subspace-distance is: 6.828061304986477e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.62; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.56; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.424171781167388e-05
6.740561366314068e-05
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2840234917250408; val_accuracy: 0.9166998407643312 

The current subspace-distance is: 6.740561366314068e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.91
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

7.477417238987982e-05
6.772115011699498e-05
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.28402261848852134; val_accuracy: 0.9167993630573248 

The current subspace-distance is: 6.772115011699498e-05 

plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_800_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 446105
elements in E: 199210000
fraction nonzero: 0.0022393705135284373
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.09
Batch: 40; loss: 2.26; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.34
Batch: 80; loss: 2.21; acc: 0.38
Batch: 100; loss: 2.17; acc: 0.38
Batch: 120; loss: 2.12; acc: 0.5
Batch: 140; loss: 2.12; acc: 0.44
Batch: 160; loss: 2.1; acc: 0.47
Batch: 180; loss: 2.02; acc: 0.47
Batch: 200; loss: 1.89; acc: 0.56
Batch: 220; loss: 1.84; acc: 0.66
Batch: 240; loss: 1.76; acc: 0.66
Batch: 260; loss: 1.66; acc: 0.67
Batch: 280; loss: 1.49; acc: 0.73
Batch: 300; loss: 1.5; acc: 0.61
Batch: 320; loss: 1.33; acc: 0.72
Batch: 340; loss: 1.37; acc: 0.66
Batch: 360; loss: 1.14; acc: 0.7
Batch: 380; loss: 0.9; acc: 0.8
Batch: 400; loss: 0.87; acc: 0.78
Batch: 420; loss: 0.75; acc: 0.81
Batch: 440; loss: 0.8; acc: 0.77
Batch: 460; loss: 0.75; acc: 0.81
Batch: 480; loss: 0.8; acc: 0.75
Batch: 500; loss: 0.72; acc: 0.83
Batch: 520; loss: 0.65; acc: 0.83
Batch: 540; loss: 0.66; acc: 0.81
Batch: 560; loss: 0.69; acc: 0.75
Batch: 580; loss: 0.68; acc: 0.75
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.81; acc: 0.75
Batch: 640; loss: 0.61; acc: 0.8
Batch: 660; loss: 0.5; acc: 0.89
Batch: 680; loss: 0.56; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.88
Batch: 720; loss: 0.63; acc: 0.75
Batch: 740; loss: 0.41; acc: 0.94
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.89
Train Epoch over. train_loss: 1.23; train_accuracy: 0.67 

4.257036925991997e-05
3.953768464270979e-05
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.6; acc: 0.84
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.24; acc: 0.97
Val Epoch over. val_loss: 0.46777228242272784; val_accuracy: 0.8615644904458599 

The current subspace-distance is: 3.953768464270979e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.92
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.57; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.72; acc: 0.83
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.4; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.75; acc: 0.83
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.25; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

5.254626375972293e-05
4.636027733795345e-05
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3630278799089657; val_accuracy: 0.8934116242038217 

The current subspace-distance is: 4.636027733795345e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.83
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.48; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.78
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.57; acc: 0.86
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

5.577452611760236e-05
4.908646587864496e-05
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3290597499366019; val_accuracy: 0.9030652866242038 

The current subspace-distance is: 4.908646587864496e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.25; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.95
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.81; acc: 0.78
Batch: 400; loss: 0.22; acc: 0.97
Batch: 420; loss: 0.46; acc: 0.81
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.45; acc: 0.94
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

5.8689074649009854e-05
5.176962440600619e-05
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3225285658126424; val_accuracy: 0.901671974522293 

The current subspace-distance is: 5.176962440600619e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

6.0706399381160736e-05
5.3471663704840466e-05
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3005745744297079; val_accuracy: 0.9077428343949044 

The current subspace-distance is: 5.3471663704840466e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.42; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.17; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.86
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

6.220802606549114e-05
5.5085241911001503e-05
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2839634915113829; val_accuracy: 0.9161027070063694 

The current subspace-distance is: 5.5085241911001503e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.83
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.59; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

6.39170830254443e-05
5.6621422118041664e-05
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.27822492141157956; val_accuracy: 0.9167993630573248 

The current subspace-distance is: 5.6621422118041664e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.67; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.97
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.61; acc: 0.77
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.89
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

6.524602940771729e-05
5.729283293476328e-05
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.75
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2711887481818154; val_accuracy: 0.9192874203821656 

The current subspace-distance is: 5.729283293476328e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.83
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.45; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.89
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.51; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

6.642124935751781e-05
5.886848521186039e-05
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2688589684048276; val_accuracy: 0.9210788216560509 

The current subspace-distance is: 5.886848521186039e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.81
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.98
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

6.787248275941238e-05
5.9858641179744154e-05
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26931024110241303; val_accuracy: 0.9189888535031847 

The current subspace-distance is: 5.9858641179744154e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.39; acc: 0.84
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.48; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.88
Batch: 660; loss: 0.48; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

6.740049866493791e-05
5.984507515677251e-05
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.89
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2559232310789406; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 5.984507515677251e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.84
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.15; acc: 0.98
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

6.843383744126186e-05
6.02780855842866e-05
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25411426377998797; val_accuracy: 0.9234673566878981 

The current subspace-distance is: 6.02780855842866e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.42; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.51; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.34; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.39; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

6.848466728115454e-05
5.986369797028601e-05
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2563499179994984; val_accuracy: 0.9234673566878981 

The current subspace-distance is: 5.986369797028601e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.53; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

6.85753911966458e-05
6.022178422426805e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25407856736023715; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 6.022178422426805e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.18; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.31; acc: 0.86
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.62; acc: 0.88
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

6.879149441374466e-05
6.0638452850980684e-05
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2542177242505702; val_accuracy: 0.9234673566878981 

The current subspace-distance is: 6.0638452850980684e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.19; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.945159111637622e-05
6.0853570175822824e-05
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2538175308353202; val_accuracy: 0.9233678343949044 

The current subspace-distance is: 6.0853570175822824e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.08; acc: 1.0
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.84
Batch: 360; loss: 0.44; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.81
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.84
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.940685125300661e-05
6.101524195400998e-05
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2506184360119188; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 6.101524195400998e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.51; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.57; acc: 0.84
Batch: 700; loss: 0.28; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.929432856850326e-05
6.13301745033823e-05
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.253191730161761; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 6.13301745033823e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.84
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.5; acc: 0.89
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.963118357816711e-05
6.16353063378483e-05
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25270541223466014; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 6.16353063378483e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.81
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.02955512679182e-05
6.163662328617647e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2517043398871164; val_accuracy: 0.9241640127388535 

The current subspace-distance is: 6.163662328617647e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.000221376074478e-05
6.230884173419327e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24934981312531573; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.230884173419327e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.37; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.97
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.031819404801354e-05
6.231734005268663e-05
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2493631085914791; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.231734005268663e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.97
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.48; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.977587327128276e-05
6.180660420795903e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24838215487587983; val_accuracy: 0.9258558917197452 

The current subspace-distance is: 6.180660420795903e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.37; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.996941374382004e-05
6.15413737250492e-05
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24789126146181373; val_accuracy: 0.9260549363057324 

The current subspace-distance is: 6.15413737250492e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.044523226795718e-05
6.214056338649243e-05
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2489775245071976; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 6.214056338649243e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

6.99187075952068e-05
6.205142562976107e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24839777117417117; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 6.205142562976107e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.091275620041415e-05
6.204470264492556e-05
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24837578562604393; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 6.204470264492556e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.47; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.88
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.112272578524426e-05
6.310980097623542e-05
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2486264094188335; val_accuracy: 0.9249601910828026 

The current subspace-distance is: 6.310980097623542e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.34; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.37; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

7.087690028129146e-05
6.289485463639721e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24828597132092828; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 6.289485463639721e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.48; acc: 0.91
Batch: 420; loss: 0.75; acc: 0.8
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.089100836310536e-05
6.19931670371443e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2484601095413706; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 6.19931670371443e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.141072273952886e-05
6.273265171330422e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2476025720595554; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 6.273265171330422e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.101801747921854e-05
6.288685108302161e-05
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24774762803012398; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 6.288685108302161e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.75; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.084856770234182e-05
6.27485424047336e-05
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24733277417387173; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.27485424047336e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.06; acc: 1.0
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.84
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.88
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.86
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.074471795931458e-05
6.2520157371182e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24721925907359002; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 6.2520157371182e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.47; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.88
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.063560769893229e-05
6.23408195679076e-05
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24772474964617924; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 6.23408195679076e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.112992170732468e-05
6.276994827203453e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24767101155060112; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.276994827203453e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.5; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.1; acc: 1.0
Batch: 620; loss: 0.11; acc: 0.98
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.21; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.131492748158053e-05
6.255964399315417e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24765303363181224; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 6.255964399315417e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.5; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.64; acc: 0.88
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.126482523744926e-05
6.304006092250347e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2472316984585516; val_accuracy: 0.926453025477707 

The current subspace-distance is: 6.304006092250347e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.86
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.48; acc: 0.83
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.105427357601002e-05
6.238909554667771e-05
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24723012555556692; val_accuracy: 0.9260549363057324 

The current subspace-distance is: 6.238909554667771e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.08; acc: 1.0
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.37; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.83
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.037432078504935e-05
6.230322469491512e-05
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24723390425751163; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 6.230322469491512e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.38; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.97
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.073091546772048e-05
6.243600364541635e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2471638212016054; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 6.243600364541635e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.08; acc: 1.0
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.98
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.065352110657841e-05
6.226918776519597e-05
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24707728845013935; val_accuracy: 0.9247611464968153 

The current subspace-distance is: 6.226918776519597e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.95
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.115136395441368e-05
6.239680078579113e-05
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2470134120126059; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.239680078579113e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.84
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.97
Batch: 520; loss: 0.47; acc: 0.83
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.09; acc: 1.0
Batch: 620; loss: 0.52; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.070734864100814e-05
6.179234333103523e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24712680614772875; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 6.179234333103523e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.56; acc: 0.88
Batch: 60; loss: 0.1; acc: 1.0
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.47; acc: 0.84
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.94
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.84
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.016885501798242e-05
6.209513958310708e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24706752467781876; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.209513958310708e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.86
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.91
Batch: 380; loss: 0.46; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.84
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.020997145446017e-05
6.194221350597218e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24708357118781965; val_accuracy: 0.9257563694267515 

The current subspace-distance is: 6.194221350597218e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.98
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.83
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.4; acc: 0.83
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.075016037561e-05
6.248757563298568e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24719230847278978; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.248757563298568e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.81
Batch: 600; loss: 0.68; acc: 0.83
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.94
Batch: 660; loss: 0.63; acc: 0.81
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.126680429792032e-05
6.317838415270671e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2469536315673476; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 6.317838415270671e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.44; acc: 0.83
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.88
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.44; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.106466364348307e-05
6.299779488472268e-05
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24699453461416968; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 6.299779488472268e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.57; acc: 0.88
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.89
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.31; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

7.154044578783214e-05
6.302882684394717e-05
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24691153130238983; val_accuracy: 0.9249601910828026 

The current subspace-distance is: 6.302882684394717e-05 

plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_1000_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
plots/subspace_training/MLP/2020-01-22 20:43:18/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
