model : lenet
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 1
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : False
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 14:35:09
nonzero elements in E: 2054
elements in E: 444260
fraction nonzero: 0.004623418718768289
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.32; acc: 0.06
Batch: 40; loss: 2.32; acc: 0.08
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.31; acc: 0.11
Batch: 100; loss: 2.32; acc: 0.06
Batch: 120; loss: 2.32; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.12
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.32; acc: 0.11
Batch: 200; loss: 2.32; acc: 0.06
Batch: 220; loss: 2.3; acc: 0.14
Batch: 240; loss: 2.31; acc: 0.09
Batch: 260; loss: 2.31; acc: 0.12
Batch: 280; loss: 2.32; acc: 0.08
Batch: 300; loss: 2.29; acc: 0.19
Batch: 320; loss: 2.32; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.19
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.3; acc: 0.12
Batch: 400; loss: 2.31; acc: 0.09
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.03
Batch: 480; loss: 2.3; acc: 0.12
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.32; acc: 0.05
Batch: 540; loss: 2.31; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.05
Batch: 580; loss: 2.32; acc: 0.06
Batch: 600; loss: 2.31; acc: 0.05
Batch: 620; loss: 2.31; acc: 0.09
Batch: 640; loss: 2.31; acc: 0.06
Batch: 660; loss: 2.28; acc: 0.17
Batch: 680; loss: 2.31; acc: 0.08
Batch: 700; loss: 2.31; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.08
Batch: 740; loss: 2.31; acc: 0.03
Batch: 760; loss: 2.3; acc: 0.05
Batch: 780; loss: 2.3; acc: 0.08
Train Epoch over. train_loss: 2.31; train_accuracy: 0.09 

Batch: 0; loss: 2.3; acc: 0.03
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.32; acc: 0.03
Batch: 120; loss: 2.31; acc: 0.03
Batch: 140; loss: 2.3; acc: 0.05
Val Epoch over. val_loss: 2.3027064208012478; val_accuracy: 0.07633359872611464 

The current subspace-distance is: 1.8942007500299951e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.31; acc: 0.03
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.09
Batch: 140; loss: 2.31; acc: 0.05
Batch: 160; loss: 2.31; acc: 0.06
Batch: 180; loss: 2.31; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.05
Batch: 220; loss: 2.3; acc: 0.09
Batch: 240; loss: 2.3; acc: 0.06
Batch: 260; loss: 2.31; acc: 0.02
Batch: 280; loss: 2.3; acc: 0.06
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.32; acc: 0.02
Batch: 340; loss: 2.31; acc: 0.05
Batch: 360; loss: 2.31; acc: 0.06
Batch: 380; loss: 2.29; acc: 0.09
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.31; acc: 0.09
Batch: 440; loss: 2.29; acc: 0.16
Batch: 460; loss: 2.28; acc: 0.14
Batch: 480; loss: 2.31; acc: 0.05
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.3; acc: 0.16
Batch: 540; loss: 2.31; acc: 0.09
Batch: 560; loss: 2.31; acc: 0.14
Batch: 580; loss: 2.3; acc: 0.05
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.32; acc: 0.03
Batch: 660; loss: 2.29; acc: 0.05
Batch: 680; loss: 2.32; acc: 0.09
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.09
Batch: 760; loss: 2.29; acc: 0.05
Batch: 780; loss: 2.31; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.08 

Batch: 0; loss: 2.3; acc: 0.05
Batch: 20; loss: 2.31; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.32; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.06
Val Epoch over. val_loss: 2.2986766851631697; val_accuracy: 0.08449442675159236 

The current subspace-distance is: 3.023860926987254e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.32; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.08
Batch: 40; loss: 2.29; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.29; acc: 0.06
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.31; acc: 0.05
Batch: 240; loss: 2.32; acc: 0.08
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.3; acc: 0.08
Batch: 300; loss: 2.29; acc: 0.06
Batch: 320; loss: 2.29; acc: 0.12
Batch: 340; loss: 2.28; acc: 0.09
Batch: 360; loss: 2.28; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.31; acc: 0.11
Batch: 440; loss: 2.29; acc: 0.02
Batch: 460; loss: 2.29; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.02
Batch: 500; loss: 2.29; acc: 0.11
Batch: 520; loss: 2.31; acc: 0.08
Batch: 540; loss: 2.29; acc: 0.14
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.31; acc: 0.06
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.3; acc: 0.05
Batch: 640; loss: 2.3; acc: 0.08
Batch: 660; loss: 2.3; acc: 0.12
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.3; acc: 0.06
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.28; acc: 0.19
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.09 

Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.08
Val Epoch over. val_loss: 2.294399563673955; val_accuracy: 0.11265923566878981 

The current subspace-distance is: 4.1996822801593225e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.27; acc: 0.17
Batch: 180; loss: 2.28; acc: 0.16
Batch: 200; loss: 2.3; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.19
Batch: 240; loss: 2.31; acc: 0.02
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.3; acc: 0.08
Batch: 300; loss: 2.3; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.28; acc: 0.17
Batch: 360; loss: 2.3; acc: 0.08
Batch: 380; loss: 2.28; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.08
Batch: 420; loss: 2.3; acc: 0.03
Batch: 440; loss: 2.29; acc: 0.11
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.12
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.29; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.16
Batch: 580; loss: 2.31; acc: 0.06
Batch: 600; loss: 2.28; acc: 0.17
Batch: 620; loss: 2.3; acc: 0.19
Batch: 640; loss: 2.28; acc: 0.17
Batch: 660; loss: 2.29; acc: 0.09
Batch: 680; loss: 2.29; acc: 0.17
Batch: 700; loss: 2.28; acc: 0.25
Batch: 720; loss: 2.28; acc: 0.19
Batch: 740; loss: 2.28; acc: 0.19
Batch: 760; loss: 2.27; acc: 0.2
Batch: 780; loss: 2.28; acc: 0.16
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

Batch: 0; loss: 2.29; acc: 0.16
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.28; acc: 0.11
Batch: 60; loss: 2.29; acc: 0.17
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.28; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.22
Batch: 140; loss: 2.28; acc: 0.2
Val Epoch over. val_loss: 2.2856315063063506; val_accuracy: 0.1618232484076433 

The current subspace-distance is: 5.781753316114191e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.19
Batch: 60; loss: 2.28; acc: 0.17
Batch: 80; loss: 2.28; acc: 0.17
Batch: 100; loss: 2.29; acc: 0.22
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.17
Batch: 160; loss: 2.28; acc: 0.22
Batch: 180; loss: 2.28; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.28; acc: 0.19
Batch: 240; loss: 2.28; acc: 0.2
Batch: 260; loss: 2.27; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.19
Batch: 300; loss: 2.28; acc: 0.14
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.16
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.27; acc: 0.17
Batch: 420; loss: 2.27; acc: 0.19
Batch: 440; loss: 2.28; acc: 0.11
Batch: 460; loss: 2.25; acc: 0.3
Batch: 480; loss: 2.28; acc: 0.14
Batch: 500; loss: 2.28; acc: 0.12
Batch: 520; loss: 2.27; acc: 0.17
Batch: 540; loss: 2.26; acc: 0.19
Batch: 560; loss: 2.28; acc: 0.14
Batch: 580; loss: 2.28; acc: 0.14
Batch: 600; loss: 2.28; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.16
Batch: 640; loss: 2.28; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.09
Batch: 680; loss: 2.28; acc: 0.12
Batch: 700; loss: 2.28; acc: 0.19
Batch: 720; loss: 2.27; acc: 0.19
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.27; acc: 0.11
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.28; train_accuracy: 0.14 

Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.28; acc: 0.09
Batch: 40; loss: 2.27; acc: 0.16
Batch: 60; loss: 2.28; acc: 0.17
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.25; acc: 0.17
Batch: 120; loss: 2.26; acc: 0.17
Batch: 140; loss: 2.27; acc: 0.17
Val Epoch over. val_loss: 2.2774105011277896; val_accuracy: 0.13594745222929935 

The current subspace-distance is: 6.53851066090283e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.29; acc: 0.19
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.28; acc: 0.16
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.28; acc: 0.09
Batch: 140; loss: 2.27; acc: 0.16
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.28; acc: 0.06
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.26; acc: 0.08
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.28; acc: 0.12
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.26; acc: 0.14
Batch: 380; loss: 2.28; acc: 0.11
Batch: 400; loss: 2.28; acc: 0.14
Batch: 420; loss: 2.28; acc: 0.09
Batch: 440; loss: 2.29; acc: 0.05
Batch: 460; loss: 2.26; acc: 0.09
Batch: 480; loss: 2.28; acc: 0.16
Batch: 500; loss: 2.29; acc: 0.06
Batch: 520; loss: 2.27; acc: 0.19
Batch: 540; loss: 2.27; acc: 0.14
Batch: 560; loss: 2.27; acc: 0.09
Batch: 580; loss: 2.26; acc: 0.11
Batch: 600; loss: 2.27; acc: 0.14
Batch: 620; loss: 2.28; acc: 0.08
Batch: 640; loss: 2.26; acc: 0.16
Batch: 660; loss: 2.27; acc: 0.12
Batch: 680; loss: 2.26; acc: 0.16
Batch: 700; loss: 2.27; acc: 0.12
Batch: 720; loss: 2.27; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.28; acc: 0.11
Batch: 780; loss: 2.27; acc: 0.16
Train Epoch over. train_loss: 2.28; train_accuracy: 0.12 

Batch: 0; loss: 2.27; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.25; acc: 0.11
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.23; acc: 0.19
Batch: 120; loss: 2.25; acc: 0.11
Batch: 140; loss: 2.26; acc: 0.14
Val Epoch over. val_loss: 2.27078980093549; val_accuracy: 0.12042197452229299 

The current subspace-distance is: 7.059016752464231e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.26; acc: 0.11
Batch: 40; loss: 2.27; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.25; acc: 0.09
Batch: 100; loss: 2.27; acc: 0.12
Batch: 120; loss: 2.27; acc: 0.14
Batch: 140; loss: 2.24; acc: 0.16
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.29; acc: 0.06
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.26; acc: 0.19
Batch: 240; loss: 2.27; acc: 0.05
Batch: 260; loss: 2.27; acc: 0.16
Batch: 280; loss: 2.28; acc: 0.09
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.26; acc: 0.16
Batch: 340; loss: 2.27; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.11
Batch: 380; loss: 2.27; acc: 0.14
Batch: 400; loss: 2.26; acc: 0.12
Batch: 420; loss: 2.24; acc: 0.14
Batch: 440; loss: 2.25; acc: 0.14
Batch: 460; loss: 2.25; acc: 0.14
Batch: 480; loss: 2.27; acc: 0.14
Batch: 500; loss: 2.25; acc: 0.16
Batch: 520; loss: 2.28; acc: 0.12
Batch: 540; loss: 2.27; acc: 0.12
Batch: 560; loss: 2.26; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.14
Batch: 600; loss: 2.24; acc: 0.08
Batch: 620; loss: 2.28; acc: 0.05
Batch: 640; loss: 2.28; acc: 0.09
Batch: 660; loss: 2.28; acc: 0.12
Batch: 680; loss: 2.27; acc: 0.14
Batch: 700; loss: 2.28; acc: 0.16
Batch: 720; loss: 2.25; acc: 0.16
Batch: 740; loss: 2.25; acc: 0.12
Batch: 760; loss: 2.28; acc: 0.08
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.27; train_accuracy: 0.11 

Batch: 0; loss: 2.25; acc: 0.2
Batch: 20; loss: 2.26; acc: 0.11
Batch: 40; loss: 2.24; acc: 0.12
Batch: 60; loss: 2.27; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.21; acc: 0.23
Batch: 120; loss: 2.23; acc: 0.14
Batch: 140; loss: 2.24; acc: 0.16
Val Epoch over. val_loss: 2.261957771459203; val_accuracy: 0.1259952229299363 

The current subspace-distance is: 9.637921721150633e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.11
Batch: 20; loss: 2.26; acc: 0.12
Batch: 40; loss: 2.25; acc: 0.08
Batch: 60; loss: 2.27; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.11
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.25; acc: 0.12
Batch: 140; loss: 2.26; acc: 0.17
Batch: 160; loss: 2.25; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.26; acc: 0.14
Batch: 220; loss: 2.26; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.09
Batch: 280; loss: 2.27; acc: 0.06
Batch: 300; loss: 2.28; acc: 0.11
Batch: 320; loss: 2.26; acc: 0.12
Batch: 340; loss: 2.28; acc: 0.14
Batch: 360; loss: 2.31; acc: 0.09
Batch: 380; loss: 2.26; acc: 0.09
Batch: 400; loss: 2.25; acc: 0.09
Batch: 420; loss: 2.29; acc: 0.08
Batch: 440; loss: 2.25; acc: 0.05
Batch: 460; loss: 2.27; acc: 0.09
Batch: 480; loss: 2.28; acc: 0.17
Batch: 500; loss: 2.26; acc: 0.2
Batch: 520; loss: 2.28; acc: 0.16
Batch: 540; loss: 2.27; acc: 0.12
Batch: 560; loss: 2.29; acc: 0.17
Batch: 580; loss: 2.25; acc: 0.16
Batch: 600; loss: 2.27; acc: 0.09
Batch: 620; loss: 2.28; acc: 0.06
Batch: 640; loss: 2.26; acc: 0.22
Batch: 660; loss: 2.27; acc: 0.16
Batch: 680; loss: 2.26; acc: 0.14
Batch: 700; loss: 2.23; acc: 0.17
Batch: 720; loss: 2.28; acc: 0.14
Batch: 740; loss: 2.22; acc: 0.17
Batch: 760; loss: 2.25; acc: 0.05
Batch: 780; loss: 2.25; acc: 0.11
Train Epoch over. train_loss: 2.26; train_accuracy: 0.12 

Batch: 0; loss: 2.23; acc: 0.19
Batch: 20; loss: 2.25; acc: 0.09
Batch: 40; loss: 2.22; acc: 0.19
Batch: 60; loss: 2.25; acc: 0.17
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.19; acc: 0.17
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.11
Val Epoch over. val_loss: 2.2532957678387877; val_accuracy: 0.14122213375796178 

The current subspace-distance is: 1.0900162124016788e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.22; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.08
Batch: 40; loss: 2.26; acc: 0.16
Batch: 60; loss: 2.2; acc: 0.28
Batch: 80; loss: 2.27; acc: 0.06
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.23; acc: 0.16
Batch: 160; loss: 2.27; acc: 0.14
Batch: 180; loss: 2.25; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.06
Batch: 220; loss: 2.22; acc: 0.09
Batch: 240; loss: 2.27; acc: 0.09
Batch: 260; loss: 2.26; acc: 0.12
Batch: 280; loss: 2.26; acc: 0.17
Batch: 300; loss: 2.24; acc: 0.12
Batch: 320; loss: 2.25; acc: 0.14
Batch: 340; loss: 2.26; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.22; acc: 0.23
Batch: 400; loss: 2.27; acc: 0.16
Batch: 420; loss: 2.29; acc: 0.06
Batch: 440; loss: 2.24; acc: 0.19
Batch: 460; loss: 2.25; acc: 0.11
Batch: 480; loss: 2.26; acc: 0.09
Batch: 500; loss: 2.26; acc: 0.09
Batch: 520; loss: 2.26; acc: 0.14
Batch: 540; loss: 2.27; acc: 0.2
Batch: 560; loss: 2.22; acc: 0.12
Batch: 580; loss: 2.23; acc: 0.17
Batch: 600; loss: 2.27; acc: 0.12
Batch: 620; loss: 2.21; acc: 0.2
Batch: 640; loss: 2.25; acc: 0.19
Batch: 660; loss: 2.27; acc: 0.11
Batch: 680; loss: 2.22; acc: 0.17
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.24; acc: 0.11
Batch: 740; loss: 2.23; acc: 0.17
Batch: 760; loss: 2.26; acc: 0.12
Batch: 780; loss: 2.24; acc: 0.16
Train Epoch over. train_loss: 2.26; train_accuracy: 0.14 

Batch: 0; loss: 2.22; acc: 0.2
Batch: 20; loss: 2.25; acc: 0.11
Batch: 40; loss: 2.2; acc: 0.23
Batch: 60; loss: 2.23; acc: 0.19
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.2; acc: 0.16
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.22; acc: 0.08
Val Epoch over. val_loss: 2.24570795988581; val_accuracy: 0.140625 

The current subspace-distance is: 1.1574707968975417e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.06
Batch: 20; loss: 2.24; acc: 0.09
Batch: 40; loss: 2.24; acc: 0.09
Batch: 60; loss: 2.26; acc: 0.11
Batch: 80; loss: 2.25; acc: 0.17
Batch: 100; loss: 2.23; acc: 0.17
Batch: 120; loss: 2.26; acc: 0.12
Batch: 140; loss: 2.24; acc: 0.08
Batch: 160; loss: 2.26; acc: 0.11
Batch: 180; loss: 2.34; acc: 0.12
Batch: 200; loss: 2.19; acc: 0.17
Batch: 220; loss: 2.26; acc: 0.16
Batch: 240; loss: 2.18; acc: 0.16
Batch: 260; loss: 2.19; acc: 0.25
Batch: 280; loss: 2.25; acc: 0.12
Batch: 300; loss: 2.27; acc: 0.08
Batch: 320; loss: 2.25; acc: 0.19
Batch: 340; loss: 2.27; acc: 0.11
Batch: 360; loss: 2.25; acc: 0.09
Batch: 380; loss: 2.3; acc: 0.05
Batch: 400; loss: 2.28; acc: 0.16
Batch: 420; loss: 2.25; acc: 0.17
Batch: 440; loss: 2.23; acc: 0.16
Batch: 460; loss: 2.27; acc: 0.12
Batch: 480; loss: 2.33; acc: 0.08
Batch: 500; loss: 2.24; acc: 0.14
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.24; acc: 0.12
Batch: 560; loss: 2.23; acc: 0.16
Batch: 580; loss: 2.28; acc: 0.12
Batch: 600; loss: 2.23; acc: 0.16
Batch: 620; loss: 2.22; acc: 0.16
Batch: 640; loss: 2.26; acc: 0.09
Batch: 660; loss: 2.31; acc: 0.08
Batch: 680; loss: 2.22; acc: 0.19
Batch: 700; loss: 2.24; acc: 0.17
Batch: 720; loss: 2.24; acc: 0.16
Batch: 740; loss: 2.24; acc: 0.11
Batch: 760; loss: 2.22; acc: 0.14
Batch: 780; loss: 2.32; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.14 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.26; acc: 0.08
Batch: 40; loss: 2.2; acc: 0.22
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.16
Batch: 100; loss: 2.21; acc: 0.14
Batch: 120; loss: 2.19; acc: 0.14
Batch: 140; loss: 2.22; acc: 0.05
Val Epoch over. val_loss: 2.2418841768981546; val_accuracy: 0.12679140127388536 

The current subspace-distance is: 1.2987939953745808e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.12
Batch: 40; loss: 2.21; acc: 0.11
Batch: 60; loss: 2.19; acc: 0.12
Batch: 80; loss: 2.25; acc: 0.09
Batch: 100; loss: 2.28; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.25; acc: 0.19
Batch: 160; loss: 2.21; acc: 0.17
Batch: 180; loss: 2.19; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.22; acc: 0.2
Batch: 240; loss: 2.26; acc: 0.12
Batch: 260; loss: 2.19; acc: 0.12
Batch: 280; loss: 2.32; acc: 0.12
Batch: 300; loss: 2.26; acc: 0.09
Batch: 320; loss: 2.3; acc: 0.06
Batch: 340; loss: 2.25; acc: 0.11
Batch: 360; loss: 2.24; acc: 0.14
Batch: 380; loss: 2.27; acc: 0.12
Batch: 400; loss: 2.27; acc: 0.09
Batch: 420; loss: 2.27; acc: 0.06
Batch: 440; loss: 2.24; acc: 0.11
Batch: 460; loss: 2.28; acc: 0.22
Batch: 480; loss: 2.24; acc: 0.17
Batch: 500; loss: 2.23; acc: 0.14
Batch: 520; loss: 2.27; acc: 0.08
Batch: 540; loss: 2.26; acc: 0.14
Batch: 560; loss: 2.27; acc: 0.05
Batch: 580; loss: 2.27; acc: 0.19
Batch: 600; loss: 2.28; acc: 0.11
Batch: 620; loss: 2.25; acc: 0.08
Batch: 640; loss: 2.23; acc: 0.17
Batch: 660; loss: 2.21; acc: 0.09
Batch: 680; loss: 2.27; acc: 0.09
Batch: 700; loss: 2.23; acc: 0.12
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.26; acc: 0.19
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.2; acc: 0.22
Train Epoch over. train_loss: 2.25; train_accuracy: 0.13 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.26; acc: 0.08
Batch: 40; loss: 2.2; acc: 0.22
Batch: 60; loss: 2.22; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.16
Batch: 100; loss: 2.21; acc: 0.14
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413840354627865; val_accuracy: 0.12320859872611464 

The current subspace-distance is: 1.6775371477706358e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.21; acc: 0.14
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.22; acc: 0.16
Batch: 80; loss: 2.25; acc: 0.2
Batch: 100; loss: 2.25; acc: 0.11
Batch: 120; loss: 2.25; acc: 0.14
Batch: 140; loss: 2.24; acc: 0.16
Batch: 160; loss: 2.22; acc: 0.16
Batch: 180; loss: 2.25; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.25; acc: 0.08
Batch: 260; loss: 2.26; acc: 0.08
Batch: 280; loss: 2.22; acc: 0.28
Batch: 300; loss: 2.26; acc: 0.11
Batch: 320; loss: 2.29; acc: 0.17
Batch: 340; loss: 2.26; acc: 0.05
Batch: 360; loss: 2.24; acc: 0.19
Batch: 380; loss: 2.26; acc: 0.19
Batch: 400; loss: 2.25; acc: 0.06
Batch: 420; loss: 2.27; acc: 0.09
Batch: 440; loss: 2.25; acc: 0.11
Batch: 460; loss: 2.28; acc: 0.09
Batch: 480; loss: 2.31; acc: 0.14
Batch: 500; loss: 2.26; acc: 0.08
Batch: 520; loss: 2.27; acc: 0.09
Batch: 540; loss: 2.24; acc: 0.14
Batch: 560; loss: 2.17; acc: 0.19
Batch: 580; loss: 2.19; acc: 0.23
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.24; acc: 0.16
Batch: 640; loss: 2.22; acc: 0.14
Batch: 660; loss: 2.23; acc: 0.09
Batch: 680; loss: 2.21; acc: 0.09
Batch: 700; loss: 2.26; acc: 0.17
Batch: 720; loss: 2.26; acc: 0.09
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.23; acc: 0.11
Batch: 780; loss: 2.25; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.22
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.21; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241214343696643; val_accuracy: 0.12151671974522293 

The current subspace-distance is: 1.646619421080686e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.24; acc: 0.12
Batch: 40; loss: 2.32; acc: 0.16
Batch: 60; loss: 2.22; acc: 0.19
Batch: 80; loss: 2.24; acc: 0.11
Batch: 100; loss: 2.25; acc: 0.08
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.22; acc: 0.17
Batch: 160; loss: 2.28; acc: 0.09
Batch: 180; loss: 2.27; acc: 0.06
Batch: 200; loss: 2.26; acc: 0.09
Batch: 220; loss: 2.33; acc: 0.03
Batch: 240; loss: 2.27; acc: 0.08
Batch: 260; loss: 2.24; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.11
Batch: 300; loss: 2.25; acc: 0.12
Batch: 320; loss: 2.23; acc: 0.12
Batch: 340; loss: 2.2; acc: 0.12
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.11
Batch: 400; loss: 2.23; acc: 0.08
Batch: 420; loss: 2.3; acc: 0.19
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.25; acc: 0.16
Batch: 480; loss: 2.27; acc: 0.09
Batch: 500; loss: 2.25; acc: 0.12
Batch: 520; loss: 2.23; acc: 0.12
Batch: 540; loss: 2.26; acc: 0.19
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.31; acc: 0.08
Batch: 600; loss: 2.32; acc: 0.06
Batch: 620; loss: 2.25; acc: 0.09
Batch: 640; loss: 2.28; acc: 0.08
Batch: 660; loss: 2.22; acc: 0.06
Batch: 680; loss: 2.26; acc: 0.09
Batch: 700; loss: 2.22; acc: 0.12
Batch: 720; loss: 2.23; acc: 0.14
Batch: 740; loss: 2.23; acc: 0.17
Batch: 760; loss: 2.26; acc: 0.08
Batch: 780; loss: 2.32; acc: 0.11
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241244650190803; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 1.942523340403568e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 2.26; acc: 0.09
Batch: 20; loss: 2.25; acc: 0.09
Batch: 40; loss: 2.21; acc: 0.14
Batch: 60; loss: 2.22; acc: 0.17
Batch: 80; loss: 2.23; acc: 0.06
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.25; acc: 0.16
Batch: 160; loss: 2.23; acc: 0.12
Batch: 180; loss: 2.2; acc: 0.16
Batch: 200; loss: 2.2; acc: 0.14
Batch: 220; loss: 2.23; acc: 0.12
Batch: 240; loss: 2.25; acc: 0.2
Batch: 260; loss: 2.28; acc: 0.2
Batch: 280; loss: 2.28; acc: 0.14
Batch: 300; loss: 2.27; acc: 0.11
Batch: 320; loss: 2.21; acc: 0.16
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.26; acc: 0.09
Batch: 380; loss: 2.2; acc: 0.16
Batch: 400; loss: 2.36; acc: 0.06
Batch: 420; loss: 2.21; acc: 0.12
Batch: 440; loss: 2.34; acc: 0.08
Batch: 460; loss: 2.26; acc: 0.12
Batch: 480; loss: 2.27; acc: 0.08
Batch: 500; loss: 2.27; acc: 0.16
Batch: 520; loss: 2.2; acc: 0.11
Batch: 540; loss: 2.25; acc: 0.09
Batch: 560; loss: 2.24; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.11
Batch: 600; loss: 2.23; acc: 0.12
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.23; acc: 0.09
Batch: 660; loss: 2.24; acc: 0.14
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.18; acc: 0.06
Batch: 720; loss: 2.27; acc: 0.06
Batch: 740; loss: 2.32; acc: 0.12
Batch: 760; loss: 2.28; acc: 0.19
Batch: 780; loss: 2.24; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.16
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2412631223156194; val_accuracy: 0.12191480891719746 

The current subspace-distance is: 2.084760672005359e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 2.26; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.26; acc: 0.14
Batch: 80; loss: 2.25; acc: 0.05
Batch: 100; loss: 2.21; acc: 0.09
Batch: 120; loss: 2.26; acc: 0.09
Batch: 140; loss: 2.27; acc: 0.11
Batch: 160; loss: 2.24; acc: 0.14
Batch: 180; loss: 2.14; acc: 0.2
Batch: 200; loss: 2.27; acc: 0.14
Batch: 220; loss: 2.23; acc: 0.08
Batch: 240; loss: 2.29; acc: 0.08
Batch: 260; loss: 2.26; acc: 0.09
Batch: 280; loss: 2.22; acc: 0.14
Batch: 300; loss: 2.24; acc: 0.09
Batch: 320; loss: 2.24; acc: 0.12
Batch: 340; loss: 2.22; acc: 0.19
Batch: 360; loss: 2.24; acc: 0.11
Batch: 380; loss: 2.22; acc: 0.12
Batch: 400; loss: 2.21; acc: 0.14
Batch: 420; loss: 2.32; acc: 0.14
Batch: 440; loss: 2.28; acc: 0.14
Batch: 460; loss: 2.3; acc: 0.12
Batch: 480; loss: 2.22; acc: 0.14
Batch: 500; loss: 2.22; acc: 0.19
Batch: 520; loss: 2.28; acc: 0.11
Batch: 540; loss: 2.24; acc: 0.11
Batch: 560; loss: 2.22; acc: 0.11
Batch: 580; loss: 2.21; acc: 0.08
Batch: 600; loss: 2.23; acc: 0.14
Batch: 620; loss: 2.27; acc: 0.05
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.31; acc: 0.09
Batch: 680; loss: 2.21; acc: 0.11
Batch: 700; loss: 2.26; acc: 0.11
Batch: 720; loss: 2.25; acc: 0.08
Batch: 740; loss: 2.27; acc: 0.06
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.24; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.21; acc: 0.09
Batch: 120; loss: 2.2; acc: 0.14
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241263629524571; val_accuracy: 0.11972531847133758 

The current subspace-distance is: 2.249202771054115e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 2.25; acc: 0.08
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.23; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.06
Batch: 100; loss: 2.25; acc: 0.11
Batch: 120; loss: 2.24; acc: 0.12
Batch: 140; loss: 2.25; acc: 0.16
Batch: 160; loss: 2.32; acc: 0.05
Batch: 180; loss: 2.16; acc: 0.16
Batch: 200; loss: 2.23; acc: 0.06
Batch: 220; loss: 2.21; acc: 0.17
Batch: 240; loss: 2.28; acc: 0.16
Batch: 260; loss: 2.21; acc: 0.09
Batch: 280; loss: 2.25; acc: 0.08
Batch: 300; loss: 2.27; acc: 0.11
Batch: 320; loss: 2.24; acc: 0.16
Batch: 340; loss: 2.27; acc: 0.09
Batch: 360; loss: 2.25; acc: 0.14
Batch: 380; loss: 2.26; acc: 0.16
Batch: 400; loss: 2.18; acc: 0.14
Batch: 420; loss: 2.22; acc: 0.12
Batch: 440; loss: 2.24; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.09
Batch: 480; loss: 2.24; acc: 0.08
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.3; acc: 0.12
Batch: 540; loss: 2.26; acc: 0.05
Batch: 560; loss: 2.19; acc: 0.11
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.24; acc: 0.17
Batch: 620; loss: 2.22; acc: 0.14
Batch: 640; loss: 2.26; acc: 0.14
Batch: 660; loss: 2.18; acc: 0.09
Batch: 680; loss: 2.23; acc: 0.14
Batch: 700; loss: 2.18; acc: 0.17
Batch: 720; loss: 2.26; acc: 0.06
Batch: 740; loss: 2.29; acc: 0.11
Batch: 760; loss: 2.2; acc: 0.11
Batch: 780; loss: 2.33; acc: 0.06
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413640341181664; val_accuracy: 0.11972531847133758 

The current subspace-distance is: 1.914368476718664e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 2.26; acc: 0.08
Batch: 20; loss: 2.25; acc: 0.09
Batch: 40; loss: 2.24; acc: 0.19
Batch: 60; loss: 2.27; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.06
Batch: 100; loss: 2.24; acc: 0.12
Batch: 120; loss: 2.25; acc: 0.19
Batch: 140; loss: 2.17; acc: 0.12
Batch: 160; loss: 2.27; acc: 0.08
Batch: 180; loss: 2.25; acc: 0.17
Batch: 200; loss: 2.28; acc: 0.09
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.25; acc: 0.16
Batch: 260; loss: 2.27; acc: 0.14
Batch: 280; loss: 2.22; acc: 0.19
Batch: 300; loss: 2.29; acc: 0.14
Batch: 320; loss: 2.2; acc: 0.14
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.18; acc: 0.16
Batch: 380; loss: 2.28; acc: 0.16
Batch: 400; loss: 2.26; acc: 0.08
Batch: 420; loss: 2.27; acc: 0.11
Batch: 440; loss: 2.25; acc: 0.12
Batch: 460; loss: 2.26; acc: 0.09
Batch: 480; loss: 2.18; acc: 0.16
Batch: 500; loss: 2.22; acc: 0.16
Batch: 520; loss: 2.29; acc: 0.16
Batch: 540; loss: 2.23; acc: 0.14
Batch: 560; loss: 2.28; acc: 0.09
Batch: 580; loss: 2.3; acc: 0.11
Batch: 600; loss: 2.23; acc: 0.16
Batch: 620; loss: 2.24; acc: 0.17
Batch: 640; loss: 2.23; acc: 0.12
Batch: 660; loss: 2.21; acc: 0.08
Batch: 680; loss: 2.24; acc: 0.12
Batch: 700; loss: 2.21; acc: 0.11
Batch: 720; loss: 2.22; acc: 0.12
Batch: 740; loss: 2.2; acc: 0.23
Batch: 760; loss: 2.19; acc: 0.16
Batch: 780; loss: 2.25; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241345490619635; val_accuracy: 0.11922770700636942 

The current subspace-distance is: 2.063219108094927e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 2.23; acc: 0.19
Batch: 20; loss: 2.29; acc: 0.08
Batch: 40; loss: 2.24; acc: 0.22
Batch: 60; loss: 2.24; acc: 0.09
Batch: 80; loss: 2.32; acc: 0.11
Batch: 100; loss: 2.24; acc: 0.16
Batch: 120; loss: 2.32; acc: 0.06
Batch: 140; loss: 2.27; acc: 0.14
Batch: 160; loss: 2.25; acc: 0.06
Batch: 180; loss: 2.19; acc: 0.2
Batch: 200; loss: 2.23; acc: 0.06
Batch: 220; loss: 2.17; acc: 0.17
Batch: 240; loss: 2.26; acc: 0.11
Batch: 260; loss: 2.19; acc: 0.14
Batch: 280; loss: 2.24; acc: 0.14
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.02
Batch: 380; loss: 2.2; acc: 0.14
Batch: 400; loss: 2.26; acc: 0.05
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.16
Batch: 460; loss: 2.26; acc: 0.12
Batch: 480; loss: 2.31; acc: 0.11
Batch: 500; loss: 2.22; acc: 0.11
Batch: 520; loss: 2.16; acc: 0.2
Batch: 540; loss: 2.15; acc: 0.22
Batch: 560; loss: 2.23; acc: 0.16
Batch: 580; loss: 2.22; acc: 0.2
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.27; acc: 0.12
Batch: 640; loss: 2.24; acc: 0.17
Batch: 660; loss: 2.22; acc: 0.2
Batch: 680; loss: 2.26; acc: 0.11
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.21; acc: 0.16
Batch: 740; loss: 2.21; acc: 0.11
Batch: 760; loss: 2.22; acc: 0.12
Batch: 780; loss: 2.23; acc: 0.06
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.16
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241293336175809; val_accuracy: 0.11992436305732485 

The current subspace-distance is: 2.0911757019348443e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.25; acc: 0.12
Batch: 40; loss: 2.25; acc: 0.09
Batch: 60; loss: 2.27; acc: 0.08
Batch: 80; loss: 2.33; acc: 0.06
Batch: 100; loss: 2.24; acc: 0.08
Batch: 120; loss: 2.24; acc: 0.09
Batch: 140; loss: 2.3; acc: 0.05
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.26; acc: 0.16
Batch: 200; loss: 2.23; acc: 0.17
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.24; acc: 0.19
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.27; acc: 0.09
Batch: 300; loss: 2.23; acc: 0.09
Batch: 320; loss: 2.21; acc: 0.11
Batch: 340; loss: 2.19; acc: 0.16
Batch: 360; loss: 2.31; acc: 0.09
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.21; acc: 0.12
Batch: 420; loss: 2.26; acc: 0.09
Batch: 440; loss: 2.27; acc: 0.09
Batch: 460; loss: 2.22; acc: 0.09
Batch: 480; loss: 2.21; acc: 0.12
Batch: 500; loss: 2.27; acc: 0.14
Batch: 520; loss: 2.31; acc: 0.12
Batch: 540; loss: 2.27; acc: 0.05
Batch: 560; loss: 2.2; acc: 0.16
Batch: 580; loss: 2.24; acc: 0.19
Batch: 600; loss: 2.27; acc: 0.05
Batch: 620; loss: 2.27; acc: 0.17
Batch: 640; loss: 2.25; acc: 0.08
Batch: 660; loss: 2.24; acc: 0.14
Batch: 680; loss: 2.27; acc: 0.12
Batch: 700; loss: 2.22; acc: 0.12
Batch: 720; loss: 2.23; acc: 0.14
Batch: 740; loss: 2.21; acc: 0.09
Batch: 760; loss: 2.22; acc: 0.05
Batch: 780; loss: 2.19; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.16
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2412712771421783; val_accuracy: 0.12131767515923567 

The current subspace-distance is: 2.0586441678460687e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 2.23; acc: 0.11
Batch: 20; loss: 2.25; acc: 0.08
Batch: 40; loss: 2.18; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.16
Batch: 80; loss: 2.16; acc: 0.19
Batch: 100; loss: 2.23; acc: 0.09
Batch: 120; loss: 2.23; acc: 0.16
Batch: 140; loss: 2.26; acc: 0.14
Batch: 160; loss: 2.24; acc: 0.14
Batch: 180; loss: 2.28; acc: 0.09
Batch: 200; loss: 2.21; acc: 0.23
Batch: 220; loss: 2.25; acc: 0.12
Batch: 240; loss: 2.26; acc: 0.14
Batch: 260; loss: 2.2; acc: 0.2
Batch: 280; loss: 2.2; acc: 0.16
Batch: 300; loss: 2.25; acc: 0.09
Batch: 320; loss: 2.27; acc: 0.2
Batch: 340; loss: 2.23; acc: 0.14
Batch: 360; loss: 2.17; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.08
Batch: 400; loss: 2.16; acc: 0.17
Batch: 420; loss: 2.3; acc: 0.08
Batch: 440; loss: 2.22; acc: 0.2
Batch: 460; loss: 2.32; acc: 0.12
Batch: 480; loss: 2.26; acc: 0.12
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.23; acc: 0.11
Batch: 540; loss: 2.23; acc: 0.12
Batch: 560; loss: 2.22; acc: 0.08
Batch: 580; loss: 2.23; acc: 0.11
Batch: 600; loss: 2.24; acc: 0.14
Batch: 620; loss: 2.25; acc: 0.12
Batch: 640; loss: 2.25; acc: 0.12
Batch: 660; loss: 2.24; acc: 0.17
Batch: 680; loss: 2.18; acc: 0.16
Batch: 700; loss: 2.19; acc: 0.19
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.05
Batch: 760; loss: 2.26; acc: 0.12
Batch: 780; loss: 2.25; acc: 0.16
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.03
Val Epoch over. val_loss: 2.2413980824172874; val_accuracy: 0.11863057324840764 

The current subspace-distance is: 2.5252511477447115e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.25; acc: 0.12
Batch: 20; loss: 2.25; acc: 0.08
Batch: 40; loss: 2.26; acc: 0.16
Batch: 60; loss: 2.23; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.06
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.21; acc: 0.14
Batch: 140; loss: 2.24; acc: 0.16
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.26; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.08
Batch: 220; loss: 2.21; acc: 0.12
Batch: 240; loss: 2.26; acc: 0.11
Batch: 260; loss: 2.22; acc: 0.23
Batch: 280; loss: 2.29; acc: 0.08
Batch: 300; loss: 2.25; acc: 0.11
Batch: 320; loss: 2.24; acc: 0.05
Batch: 340; loss: 2.21; acc: 0.12
Batch: 360; loss: 2.2; acc: 0.2
Batch: 380; loss: 2.26; acc: 0.09
Batch: 400; loss: 2.28; acc: 0.14
Batch: 420; loss: 2.25; acc: 0.14
Batch: 440; loss: 2.24; acc: 0.11
Batch: 460; loss: 2.26; acc: 0.05
Batch: 480; loss: 2.21; acc: 0.14
Batch: 500; loss: 2.29; acc: 0.06
Batch: 520; loss: 2.22; acc: 0.17
Batch: 540; loss: 2.24; acc: 0.06
Batch: 560; loss: 2.22; acc: 0.17
Batch: 580; loss: 2.19; acc: 0.14
Batch: 600; loss: 2.26; acc: 0.14
Batch: 620; loss: 2.26; acc: 0.06
Batch: 640; loss: 2.28; acc: 0.11
Batch: 660; loss: 2.26; acc: 0.06
Batch: 680; loss: 2.24; acc: 0.06
Batch: 700; loss: 2.27; acc: 0.14
Batch: 720; loss: 2.2; acc: 0.08
Batch: 740; loss: 2.27; acc: 0.17
Batch: 760; loss: 2.25; acc: 0.14
Batch: 780; loss: 2.2; acc: 0.11
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413632125611516; val_accuracy: 0.11962579617834394 

The current subspace-distance is: 2.808951830957085e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.23; acc: 0.09
Batch: 20; loss: 2.25; acc: 0.09
Batch: 40; loss: 2.28; acc: 0.06
Batch: 60; loss: 2.22; acc: 0.09
Batch: 80; loss: 2.19; acc: 0.19
Batch: 100; loss: 2.19; acc: 0.2
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.27; acc: 0.09
Batch: 180; loss: 2.21; acc: 0.09
Batch: 200; loss: 2.23; acc: 0.14
Batch: 220; loss: 2.23; acc: 0.09
Batch: 240; loss: 2.26; acc: 0.08
Batch: 260; loss: 2.22; acc: 0.12
Batch: 280; loss: 2.32; acc: 0.06
Batch: 300; loss: 2.18; acc: 0.19
Batch: 320; loss: 2.19; acc: 0.17
Batch: 340; loss: 2.21; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.08
Batch: 380; loss: 2.24; acc: 0.14
Batch: 400; loss: 2.24; acc: 0.16
Batch: 420; loss: 2.22; acc: 0.11
Batch: 440; loss: 2.22; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.16; acc: 0.16
Batch: 520; loss: 2.29; acc: 0.09
Batch: 540; loss: 2.23; acc: 0.14
Batch: 560; loss: 2.22; acc: 0.08
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.25; acc: 0.09
Batch: 620; loss: 2.2; acc: 0.14
Batch: 640; loss: 2.28; acc: 0.14
Batch: 660; loss: 2.24; acc: 0.11
Batch: 680; loss: 2.26; acc: 0.08
Batch: 700; loss: 2.27; acc: 0.11
Batch: 720; loss: 2.24; acc: 0.14
Batch: 740; loss: 2.21; acc: 0.12
Batch: 760; loss: 2.26; acc: 0.09
Batch: 780; loss: 2.32; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241331729159993; val_accuracy: 0.11962579617834394 

The current subspace-distance is: 2.5592469683033414e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.27; acc: 0.08
Batch: 20; loss: 2.26; acc: 0.12
Batch: 40; loss: 2.23; acc: 0.14
Batch: 60; loss: 2.23; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.12
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.22; acc: 0.05
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.23; acc: 0.08
Batch: 200; loss: 2.22; acc: 0.16
Batch: 220; loss: 2.27; acc: 0.08
Batch: 240; loss: 2.23; acc: 0.14
Batch: 260; loss: 2.24; acc: 0.11
Batch: 280; loss: 2.33; acc: 0.12
Batch: 300; loss: 2.22; acc: 0.09
Batch: 320; loss: 2.25; acc: 0.2
Batch: 340; loss: 2.22; acc: 0.11
Batch: 360; loss: 2.25; acc: 0.19
Batch: 380; loss: 2.31; acc: 0.03
Batch: 400; loss: 2.23; acc: 0.16
Batch: 420; loss: 2.19; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.14
Batch: 460; loss: 2.25; acc: 0.16
Batch: 480; loss: 2.2; acc: 0.11
Batch: 500; loss: 2.23; acc: 0.17
Batch: 520; loss: 2.23; acc: 0.19
Batch: 540; loss: 2.29; acc: 0.06
Batch: 560; loss: 2.18; acc: 0.19
Batch: 580; loss: 2.26; acc: 0.08
Batch: 600; loss: 2.24; acc: 0.09
Batch: 620; loss: 2.32; acc: 0.14
Batch: 640; loss: 2.33; acc: 0.08
Batch: 660; loss: 2.2; acc: 0.17
Batch: 680; loss: 2.24; acc: 0.12
Batch: 700; loss: 2.21; acc: 0.23
Batch: 720; loss: 2.22; acc: 0.22
Batch: 740; loss: 2.28; acc: 0.08
Batch: 760; loss: 2.32; acc: 0.12
Batch: 780; loss: 2.28; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.22; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.21; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2412979921717553; val_accuracy: 0.1201234076433121 

The current subspace-distance is: 2.2530748537974432e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.22; acc: 0.11
Batch: 20; loss: 2.27; acc: 0.06
Batch: 40; loss: 2.27; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.06
Batch: 80; loss: 2.23; acc: 0.12
Batch: 100; loss: 2.27; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.14
Batch: 160; loss: 2.22; acc: 0.08
Batch: 180; loss: 2.28; acc: 0.08
Batch: 200; loss: 2.31; acc: 0.05
Batch: 220; loss: 2.28; acc: 0.11
Batch: 240; loss: 2.27; acc: 0.19
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.25; acc: 0.14
Batch: 300; loss: 2.24; acc: 0.12
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.26; acc: 0.16
Batch: 360; loss: 2.24; acc: 0.16
Batch: 380; loss: 2.19; acc: 0.19
Batch: 400; loss: 2.24; acc: 0.16
Batch: 420; loss: 2.2; acc: 0.17
Batch: 440; loss: 2.28; acc: 0.11
Batch: 460; loss: 2.29; acc: 0.09
Batch: 480; loss: 2.28; acc: 0.08
Batch: 500; loss: 2.26; acc: 0.17
Batch: 520; loss: 2.29; acc: 0.08
Batch: 540; loss: 2.26; acc: 0.08
Batch: 560; loss: 2.19; acc: 0.14
Batch: 580; loss: 2.17; acc: 0.22
Batch: 600; loss: 2.28; acc: 0.14
Batch: 620; loss: 2.2; acc: 0.16
Batch: 640; loss: 2.24; acc: 0.09
Batch: 660; loss: 2.23; acc: 0.09
Batch: 680; loss: 2.22; acc: 0.14
Batch: 700; loss: 2.21; acc: 0.22
Batch: 720; loss: 2.22; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.16
Batch: 760; loss: 2.27; acc: 0.12
Batch: 780; loss: 2.27; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.21; acc: 0.09
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413105524269636; val_accuracy: 0.11992436305732485 

The current subspace-distance is: 2.1432819266919978e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.25; acc: 0.09
Batch: 20; loss: 2.2; acc: 0.11
Batch: 40; loss: 2.26; acc: 0.06
Batch: 60; loss: 2.24; acc: 0.11
Batch: 80; loss: 2.23; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.16
Batch: 120; loss: 2.23; acc: 0.12
Batch: 140; loss: 2.22; acc: 0.16
Batch: 160; loss: 2.23; acc: 0.16
Batch: 180; loss: 2.23; acc: 0.19
Batch: 200; loss: 2.18; acc: 0.17
Batch: 220; loss: 2.3; acc: 0.08
Batch: 240; loss: 2.22; acc: 0.17
Batch: 260; loss: 2.26; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.22; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.11
Batch: 340; loss: 2.23; acc: 0.16
Batch: 360; loss: 2.24; acc: 0.17
Batch: 380; loss: 2.29; acc: 0.14
Batch: 400; loss: 2.31; acc: 0.05
Batch: 420; loss: 2.25; acc: 0.05
Batch: 440; loss: 2.27; acc: 0.12
Batch: 460; loss: 2.26; acc: 0.14
Batch: 480; loss: 2.31; acc: 0.02
Batch: 500; loss: 2.23; acc: 0.14
Batch: 520; loss: 2.16; acc: 0.17
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.2; acc: 0.12
Batch: 580; loss: 2.22; acc: 0.14
Batch: 600; loss: 2.28; acc: 0.14
Batch: 620; loss: 2.22; acc: 0.14
Batch: 640; loss: 2.23; acc: 0.06
Batch: 660; loss: 2.23; acc: 0.19
Batch: 680; loss: 2.27; acc: 0.2
Batch: 700; loss: 2.25; acc: 0.09
Batch: 720; loss: 2.27; acc: 0.09
Batch: 740; loss: 2.24; acc: 0.22
Batch: 760; loss: 2.22; acc: 0.19
Batch: 780; loss: 2.25; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.24134551491707; val_accuracy: 0.12032245222929937 

The current subspace-distance is: 2.241109177703038e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.31; acc: 0.05
Batch: 20; loss: 2.23; acc: 0.12
Batch: 40; loss: 2.25; acc: 0.11
Batch: 60; loss: 2.26; acc: 0.12
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.26; acc: 0.17
Batch: 120; loss: 2.19; acc: 0.14
Batch: 140; loss: 2.25; acc: 0.14
Batch: 160; loss: 2.26; acc: 0.11
Batch: 180; loss: 2.23; acc: 0.05
Batch: 200; loss: 2.25; acc: 0.12
Batch: 220; loss: 2.23; acc: 0.16
Batch: 240; loss: 2.28; acc: 0.11
Batch: 260; loss: 2.24; acc: 0.14
Batch: 280; loss: 2.23; acc: 0.17
Batch: 300; loss: 2.27; acc: 0.11
Batch: 320; loss: 2.28; acc: 0.17
Batch: 340; loss: 2.25; acc: 0.14
Batch: 360; loss: 2.28; acc: 0.12
Batch: 380; loss: 2.22; acc: 0.03
Batch: 400; loss: 2.23; acc: 0.09
Batch: 420; loss: 2.27; acc: 0.16
Batch: 440; loss: 2.23; acc: 0.08
Batch: 460; loss: 2.24; acc: 0.08
Batch: 480; loss: 2.3; acc: 0.03
Batch: 500; loss: 2.24; acc: 0.09
Batch: 520; loss: 2.23; acc: 0.06
Batch: 540; loss: 2.31; acc: 0.05
Batch: 560; loss: 2.22; acc: 0.17
Batch: 580; loss: 2.2; acc: 0.11
Batch: 600; loss: 2.25; acc: 0.08
Batch: 620; loss: 2.33; acc: 0.09
Batch: 640; loss: 2.28; acc: 0.09
Batch: 660; loss: 2.24; acc: 0.08
Batch: 680; loss: 2.2; acc: 0.2
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.22; acc: 0.11
Batch: 740; loss: 2.27; acc: 0.16
Batch: 760; loss: 2.27; acc: 0.09
Batch: 780; loss: 2.31; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241325287302588; val_accuracy: 0.12002388535031847 

The current subspace-distance is: 2.2708625692757778e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.26; acc: 0.16
Batch: 20; loss: 2.19; acc: 0.2
Batch: 40; loss: 2.21; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.24; acc: 0.09
Batch: 100; loss: 2.22; acc: 0.17
Batch: 120; loss: 2.24; acc: 0.09
Batch: 140; loss: 2.26; acc: 0.11
Batch: 160; loss: 2.22; acc: 0.08
Batch: 180; loss: 2.25; acc: 0.12
Batch: 200; loss: 2.25; acc: 0.16
Batch: 220; loss: 2.28; acc: 0.06
Batch: 240; loss: 2.28; acc: 0.03
Batch: 260; loss: 2.31; acc: 0.08
Batch: 280; loss: 2.22; acc: 0.12
Batch: 300; loss: 2.22; acc: 0.14
Batch: 320; loss: 2.26; acc: 0.17
Batch: 340; loss: 2.27; acc: 0.14
Batch: 360; loss: 2.29; acc: 0.12
Batch: 380; loss: 2.28; acc: 0.12
Batch: 400; loss: 2.28; acc: 0.09
Batch: 420; loss: 2.24; acc: 0.12
Batch: 440; loss: 2.19; acc: 0.11
Batch: 460; loss: 2.34; acc: 0.09
Batch: 480; loss: 2.22; acc: 0.25
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.12
Batch: 540; loss: 2.16; acc: 0.22
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.26; acc: 0.09
Batch: 600; loss: 2.25; acc: 0.05
Batch: 620; loss: 2.24; acc: 0.17
Batch: 640; loss: 2.18; acc: 0.22
Batch: 660; loss: 2.18; acc: 0.11
Batch: 680; loss: 2.25; acc: 0.12
Batch: 700; loss: 2.24; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.26; acc: 0.08
Batch: 760; loss: 2.24; acc: 0.19
Batch: 780; loss: 2.3; acc: 0.08
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241336693429643; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 2.4553250113967806e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.21; acc: 0.11
Batch: 20; loss: 2.24; acc: 0.08
Batch: 40; loss: 2.22; acc: 0.11
Batch: 60; loss: 2.32; acc: 0.08
Batch: 80; loss: 2.26; acc: 0.06
Batch: 100; loss: 2.23; acc: 0.11
Batch: 120; loss: 2.28; acc: 0.09
Batch: 140; loss: 2.22; acc: 0.16
Batch: 160; loss: 2.32; acc: 0.06
Batch: 180; loss: 2.25; acc: 0.19
Batch: 200; loss: 2.22; acc: 0.17
Batch: 220; loss: 2.21; acc: 0.2
Batch: 240; loss: 2.22; acc: 0.17
Batch: 260; loss: 2.32; acc: 0.08
Batch: 280; loss: 2.22; acc: 0.19
Batch: 300; loss: 2.18; acc: 0.12
Batch: 320; loss: 2.22; acc: 0.2
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.32; acc: 0.08
Batch: 380; loss: 2.27; acc: 0.09
Batch: 400; loss: 2.23; acc: 0.12
Batch: 420; loss: 2.24; acc: 0.16
Batch: 440; loss: 2.22; acc: 0.09
Batch: 460; loss: 2.26; acc: 0.14
Batch: 480; loss: 2.22; acc: 0.12
Batch: 500; loss: 2.16; acc: 0.2
Batch: 520; loss: 2.25; acc: 0.12
Batch: 540; loss: 2.2; acc: 0.14
Batch: 560; loss: 2.23; acc: 0.11
Batch: 580; loss: 2.27; acc: 0.08
Batch: 600; loss: 2.25; acc: 0.06
Batch: 620; loss: 2.2; acc: 0.14
Batch: 640; loss: 2.27; acc: 0.16
Batch: 660; loss: 2.23; acc: 0.17
Batch: 680; loss: 2.24; acc: 0.12
Batch: 700; loss: 2.19; acc: 0.12
Batch: 720; loss: 2.18; acc: 0.2
Batch: 740; loss: 2.26; acc: 0.14
Batch: 760; loss: 2.22; acc: 0.12
Batch: 780; loss: 2.28; acc: 0.16
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413299645587896; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 2.666905493242666e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.24; acc: 0.14
Batch: 20; loss: 2.21; acc: 0.08
Batch: 40; loss: 2.19; acc: 0.12
Batch: 60; loss: 2.2; acc: 0.25
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.24; acc: 0.12
Batch: 140; loss: 2.23; acc: 0.08
Batch: 160; loss: 2.27; acc: 0.14
Batch: 180; loss: 2.23; acc: 0.14
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.26; acc: 0.09
Batch: 260; loss: 2.2; acc: 0.16
Batch: 280; loss: 2.21; acc: 0.14
Batch: 300; loss: 2.31; acc: 0.09
Batch: 320; loss: 2.3; acc: 0.12
Batch: 340; loss: 2.22; acc: 0.06
Batch: 360; loss: 2.23; acc: 0.11
Batch: 380; loss: 2.21; acc: 0.14
Batch: 400; loss: 2.18; acc: 0.19
Batch: 420; loss: 2.25; acc: 0.08
Batch: 440; loss: 2.26; acc: 0.16
Batch: 460; loss: 2.19; acc: 0.19
Batch: 480; loss: 2.23; acc: 0.23
Batch: 500; loss: 2.26; acc: 0.09
Batch: 520; loss: 2.28; acc: 0.12
Batch: 540; loss: 2.25; acc: 0.08
Batch: 560; loss: 2.24; acc: 0.22
Batch: 580; loss: 2.28; acc: 0.11
Batch: 600; loss: 2.23; acc: 0.16
Batch: 620; loss: 2.18; acc: 0.16
Batch: 640; loss: 2.32; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.27; acc: 0.14
Batch: 700; loss: 2.25; acc: 0.16
Batch: 720; loss: 2.2; acc: 0.16
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.21; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.16
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241344544538267; val_accuracy: 0.12042197452229299 

The current subspace-distance is: 2.8438771551009268e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.21; acc: 0.22
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.25; acc: 0.11
Batch: 80; loss: 2.22; acc: 0.14
Batch: 100; loss: 2.25; acc: 0.11
Batch: 120; loss: 2.27; acc: 0.23
Batch: 140; loss: 2.19; acc: 0.05
Batch: 160; loss: 2.25; acc: 0.08
Batch: 180; loss: 2.2; acc: 0.17
Batch: 200; loss: 2.22; acc: 0.06
Batch: 220; loss: 2.22; acc: 0.16
Batch: 240; loss: 2.26; acc: 0.14
Batch: 260; loss: 2.2; acc: 0.16
Batch: 280; loss: 2.26; acc: 0.05
Batch: 300; loss: 2.22; acc: 0.16
Batch: 320; loss: 2.24; acc: 0.16
Batch: 340; loss: 2.24; acc: 0.09
Batch: 360; loss: 2.25; acc: 0.11
Batch: 380; loss: 2.24; acc: 0.19
Batch: 400; loss: 2.22; acc: 0.08
Batch: 420; loss: 2.2; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.06
Batch: 480; loss: 2.19; acc: 0.06
Batch: 500; loss: 2.27; acc: 0.17
Batch: 520; loss: 2.24; acc: 0.11
Batch: 540; loss: 2.21; acc: 0.17
Batch: 560; loss: 2.26; acc: 0.11
Batch: 580; loss: 2.2; acc: 0.22
Batch: 600; loss: 2.24; acc: 0.14
Batch: 620; loss: 2.27; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.09
Batch: 660; loss: 2.27; acc: 0.12
Batch: 680; loss: 2.27; acc: 0.09
Batch: 700; loss: 2.26; acc: 0.11
Batch: 720; loss: 2.26; acc: 0.05
Batch: 740; loss: 2.32; acc: 0.08
Batch: 760; loss: 2.28; acc: 0.06
Batch: 780; loss: 2.3; acc: 0.05
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413454602478415; val_accuracy: 0.12022292993630573 

The current subspace-distance is: 2.7616722945822403e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.28; acc: 0.06
Batch: 20; loss: 2.26; acc: 0.09
Batch: 40; loss: 2.18; acc: 0.19
Batch: 60; loss: 2.23; acc: 0.12
Batch: 80; loss: 2.19; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.36; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.24; acc: 0.09
Batch: 180; loss: 2.23; acc: 0.2
Batch: 200; loss: 2.21; acc: 0.16
Batch: 220; loss: 2.26; acc: 0.12
Batch: 240; loss: 2.21; acc: 0.09
Batch: 260; loss: 2.27; acc: 0.16
Batch: 280; loss: 2.23; acc: 0.16
Batch: 300; loss: 2.24; acc: 0.16
Batch: 320; loss: 2.24; acc: 0.08
Batch: 340; loss: 2.2; acc: 0.09
Batch: 360; loss: 2.26; acc: 0.02
Batch: 380; loss: 2.25; acc: 0.19
Batch: 400; loss: 2.27; acc: 0.11
Batch: 420; loss: 2.31; acc: 0.06
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.26; acc: 0.11
Batch: 480; loss: 2.22; acc: 0.08
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.24; acc: 0.17
Batch: 560; loss: 2.31; acc: 0.09
Batch: 580; loss: 2.24; acc: 0.05
Batch: 600; loss: 2.21; acc: 0.19
Batch: 620; loss: 2.22; acc: 0.09
Batch: 640; loss: 2.26; acc: 0.11
Batch: 660; loss: 2.26; acc: 0.08
Batch: 680; loss: 2.17; acc: 0.2
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.28; acc: 0.11
Batch: 760; loss: 2.28; acc: 0.12
Batch: 780; loss: 2.23; acc: 0.11
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241352577877652; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.049908991670236e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.22; acc: 0.16
Batch: 20; loss: 2.23; acc: 0.09
Batch: 40; loss: 2.24; acc: 0.08
Batch: 60; loss: 2.28; acc: 0.12
Batch: 80; loss: 2.21; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.22; acc: 0.16
Batch: 140; loss: 2.26; acc: 0.12
Batch: 160; loss: 2.27; acc: 0.08
Batch: 180; loss: 2.28; acc: 0.08
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.25; acc: 0.11
Batch: 240; loss: 2.19; acc: 0.17
Batch: 260; loss: 2.25; acc: 0.11
Batch: 280; loss: 2.32; acc: 0.09
Batch: 300; loss: 2.19; acc: 0.22
Batch: 320; loss: 2.22; acc: 0.2
Batch: 340; loss: 2.26; acc: 0.14
Batch: 360; loss: 2.2; acc: 0.16
Batch: 380; loss: 2.27; acc: 0.08
Batch: 400; loss: 2.3; acc: 0.06
Batch: 420; loss: 2.21; acc: 0.16
Batch: 440; loss: 2.29; acc: 0.14
Batch: 460; loss: 2.25; acc: 0.16
Batch: 480; loss: 2.25; acc: 0.12
Batch: 500; loss: 2.26; acc: 0.16
Batch: 520; loss: 2.21; acc: 0.16
Batch: 540; loss: 2.28; acc: 0.11
Batch: 560; loss: 2.26; acc: 0.11
Batch: 580; loss: 2.21; acc: 0.16
Batch: 600; loss: 2.24; acc: 0.11
Batch: 620; loss: 2.19; acc: 0.19
Batch: 640; loss: 2.2; acc: 0.2
Batch: 660; loss: 2.33; acc: 0.0
Batch: 680; loss: 2.22; acc: 0.09
Batch: 700; loss: 2.27; acc: 0.12
Batch: 720; loss: 2.23; acc: 0.09
Batch: 740; loss: 2.25; acc: 0.12
Batch: 760; loss: 2.25; acc: 0.19
Batch: 780; loss: 2.19; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413540007961785; val_accuracy: 0.12052149681528662 

The current subspace-distance is: 3.246520645916462e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.3; acc: 0.22
Batch: 20; loss: 2.27; acc: 0.09
Batch: 40; loss: 2.26; acc: 0.11
Batch: 60; loss: 2.22; acc: 0.17
Batch: 80; loss: 2.2; acc: 0.19
Batch: 100; loss: 2.29; acc: 0.16
Batch: 120; loss: 2.32; acc: 0.08
Batch: 140; loss: 2.25; acc: 0.16
Batch: 160; loss: 2.22; acc: 0.08
Batch: 180; loss: 2.24; acc: 0.09
Batch: 200; loss: 2.29; acc: 0.16
Batch: 220; loss: 2.34; acc: 0.06
Batch: 240; loss: 2.22; acc: 0.16
Batch: 260; loss: 2.22; acc: 0.09
Batch: 280; loss: 2.26; acc: 0.12
Batch: 300; loss: 2.22; acc: 0.22
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.32; acc: 0.02
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.18; acc: 0.14
Batch: 400; loss: 2.27; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.2
Batch: 440; loss: 2.25; acc: 0.12
Batch: 460; loss: 2.23; acc: 0.17
Batch: 480; loss: 2.34; acc: 0.06
Batch: 500; loss: 2.17; acc: 0.2
Batch: 520; loss: 2.3; acc: 0.08
Batch: 540; loss: 2.27; acc: 0.14
Batch: 560; loss: 2.31; acc: 0.12
Batch: 580; loss: 2.16; acc: 0.19
Batch: 600; loss: 2.16; acc: 0.2
Batch: 620; loss: 2.25; acc: 0.14
Batch: 640; loss: 2.25; acc: 0.12
Batch: 660; loss: 2.21; acc: 0.16
Batch: 680; loss: 2.24; acc: 0.17
Batch: 700; loss: 2.22; acc: 0.19
Batch: 720; loss: 2.25; acc: 0.17
Batch: 740; loss: 2.21; acc: 0.17
Batch: 760; loss: 2.27; acc: 0.14
Batch: 780; loss: 2.22; acc: 0.19
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241347930993244; val_accuracy: 0.12052149681528662 

The current subspace-distance is: 3.0293091185740195e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.25; acc: 0.08
Batch: 20; loss: 2.27; acc: 0.09
Batch: 40; loss: 2.24; acc: 0.17
Batch: 60; loss: 2.2; acc: 0.17
Batch: 80; loss: 2.27; acc: 0.09
Batch: 100; loss: 2.25; acc: 0.12
Batch: 120; loss: 2.25; acc: 0.11
Batch: 140; loss: 2.25; acc: 0.08
Batch: 160; loss: 2.23; acc: 0.14
Batch: 180; loss: 2.22; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.19; acc: 0.14
Batch: 240; loss: 2.3; acc: 0.08
Batch: 260; loss: 2.23; acc: 0.14
Batch: 280; loss: 2.24; acc: 0.27
Batch: 300; loss: 2.28; acc: 0.03
Batch: 320; loss: 2.25; acc: 0.16
Batch: 340; loss: 2.28; acc: 0.14
Batch: 360; loss: 2.27; acc: 0.14
Batch: 380; loss: 2.25; acc: 0.12
Batch: 400; loss: 2.25; acc: 0.14
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.05
Batch: 460; loss: 2.25; acc: 0.17
Batch: 480; loss: 2.31; acc: 0.09
Batch: 500; loss: 2.28; acc: 0.11
Batch: 520; loss: 2.26; acc: 0.14
Batch: 540; loss: 2.23; acc: 0.16
Batch: 560; loss: 2.26; acc: 0.16
Batch: 580; loss: 2.26; acc: 0.12
Batch: 600; loss: 2.34; acc: 0.12
Batch: 620; loss: 2.27; acc: 0.14
Batch: 640; loss: 2.31; acc: 0.12
Batch: 660; loss: 2.26; acc: 0.08
Batch: 680; loss: 2.23; acc: 0.16
Batch: 700; loss: 2.27; acc: 0.11
Batch: 720; loss: 2.24; acc: 0.12
Batch: 740; loss: 2.26; acc: 0.11
Batch: 760; loss: 2.31; acc: 0.09
Batch: 780; loss: 2.21; acc: 0.17
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241351454121292; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 2.6835048629436642e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.26; acc: 0.08
Batch: 20; loss: 2.21; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.03
Batch: 60; loss: 2.2; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.11
Batch: 100; loss: 2.21; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.23; acc: 0.12
Batch: 160; loss: 2.24; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.24; acc: 0.09
Batch: 220; loss: 2.25; acc: 0.14
Batch: 240; loss: 2.21; acc: 0.14
Batch: 260; loss: 2.22; acc: 0.12
Batch: 280; loss: 2.23; acc: 0.17
Batch: 300; loss: 2.17; acc: 0.19
Batch: 320; loss: 2.25; acc: 0.06
Batch: 340; loss: 2.27; acc: 0.09
Batch: 360; loss: 2.26; acc: 0.14
Batch: 380; loss: 2.33; acc: 0.08
Batch: 400; loss: 2.18; acc: 0.19
Batch: 420; loss: 2.25; acc: 0.11
Batch: 440; loss: 2.23; acc: 0.12
Batch: 460; loss: 2.24; acc: 0.12
Batch: 480; loss: 2.27; acc: 0.17
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.24; acc: 0.16
Batch: 540; loss: 2.23; acc: 0.09
Batch: 560; loss: 2.25; acc: 0.08
Batch: 580; loss: 2.25; acc: 0.14
Batch: 600; loss: 2.26; acc: 0.09
Batch: 620; loss: 2.29; acc: 0.12
Batch: 640; loss: 2.23; acc: 0.08
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.37; acc: 0.02
Batch: 700; loss: 2.28; acc: 0.08
Batch: 720; loss: 2.26; acc: 0.11
Batch: 740; loss: 2.2; acc: 0.19
Batch: 760; loss: 2.23; acc: 0.14
Batch: 780; loss: 2.24; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413563409428687; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 2.881117325159721e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.18; acc: 0.19
Batch: 20; loss: 2.32; acc: 0.06
Batch: 40; loss: 2.28; acc: 0.03
Batch: 60; loss: 2.18; acc: 0.16
Batch: 80; loss: 2.25; acc: 0.14
Batch: 100; loss: 2.18; acc: 0.16
Batch: 120; loss: 2.26; acc: 0.11
Batch: 140; loss: 2.15; acc: 0.19
Batch: 160; loss: 2.27; acc: 0.16
Batch: 180; loss: 2.23; acc: 0.17
Batch: 200; loss: 2.24; acc: 0.19
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.24; acc: 0.09
Batch: 260; loss: 2.21; acc: 0.09
Batch: 280; loss: 2.2; acc: 0.16
Batch: 300; loss: 2.17; acc: 0.19
Batch: 320; loss: 2.24; acc: 0.14
Batch: 340; loss: 2.31; acc: 0.08
Batch: 360; loss: 2.32; acc: 0.06
Batch: 380; loss: 2.23; acc: 0.08
Batch: 400; loss: 2.2; acc: 0.16
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.27; acc: 0.12
Batch: 460; loss: 2.31; acc: 0.11
Batch: 480; loss: 2.22; acc: 0.09
Batch: 500; loss: 2.3; acc: 0.05
Batch: 520; loss: 2.23; acc: 0.16
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.32; acc: 0.09
Batch: 580; loss: 2.24; acc: 0.11
Batch: 600; loss: 2.26; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.08
Batch: 640; loss: 2.26; acc: 0.08
Batch: 660; loss: 2.26; acc: 0.16
Batch: 680; loss: 2.23; acc: 0.12
Batch: 700; loss: 2.18; acc: 0.2
Batch: 720; loss: 2.31; acc: 0.11
Batch: 740; loss: 2.26; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.05
Batch: 780; loss: 2.18; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413551139224106; val_accuracy: 0.12052149681528662 

The current subspace-distance is: 3.389248013263568e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.32; acc: 0.06
Batch: 20; loss: 2.16; acc: 0.19
Batch: 40; loss: 2.19; acc: 0.06
Batch: 60; loss: 2.28; acc: 0.09
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.26; acc: 0.14
Batch: 120; loss: 2.23; acc: 0.12
Batch: 140; loss: 2.25; acc: 0.12
Batch: 160; loss: 2.23; acc: 0.12
Batch: 180; loss: 2.21; acc: 0.14
Batch: 200; loss: 2.23; acc: 0.11
Batch: 220; loss: 2.27; acc: 0.09
Batch: 240; loss: 2.18; acc: 0.19
Batch: 260; loss: 2.27; acc: 0.14
Batch: 280; loss: 2.26; acc: 0.17
Batch: 300; loss: 2.2; acc: 0.17
Batch: 320; loss: 2.2; acc: 0.08
Batch: 340; loss: 2.32; acc: 0.14
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.24; acc: 0.08
Batch: 400; loss: 2.26; acc: 0.19
Batch: 420; loss: 2.3; acc: 0.06
Batch: 440; loss: 2.23; acc: 0.11
Batch: 460; loss: 2.24; acc: 0.12
Batch: 480; loss: 2.25; acc: 0.12
Batch: 500; loss: 2.24; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.09
Batch: 540; loss: 2.24; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.17
Batch: 580; loss: 2.28; acc: 0.06
Batch: 600; loss: 2.27; acc: 0.14
Batch: 620; loss: 2.2; acc: 0.16
Batch: 640; loss: 2.25; acc: 0.05
Batch: 660; loss: 2.25; acc: 0.17
Batch: 680; loss: 2.32; acc: 0.06
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.23; acc: 0.17
Batch: 740; loss: 2.27; acc: 0.08
Batch: 760; loss: 2.23; acc: 0.14
Batch: 780; loss: 2.27; acc: 0.08
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413545960833314; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.751772237592377e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.24; acc: 0.08
Batch: 20; loss: 2.2; acc: 0.12
Batch: 40; loss: 2.31; acc: 0.06
Batch: 60; loss: 2.22; acc: 0.2
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.21; acc: 0.11
Batch: 120; loss: 2.27; acc: 0.2
Batch: 140; loss: 2.24; acc: 0.06
Batch: 160; loss: 2.17; acc: 0.23
Batch: 180; loss: 2.25; acc: 0.05
Batch: 200; loss: 2.2; acc: 0.19
Batch: 220; loss: 2.21; acc: 0.19
Batch: 240; loss: 2.21; acc: 0.16
Batch: 260; loss: 2.36; acc: 0.05
Batch: 280; loss: 2.24; acc: 0.17
Batch: 300; loss: 2.22; acc: 0.12
Batch: 320; loss: 2.29; acc: 0.12
Batch: 340; loss: 2.26; acc: 0.08
Batch: 360; loss: 2.26; acc: 0.09
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.25; acc: 0.12
Batch: 420; loss: 2.25; acc: 0.09
Batch: 440; loss: 2.3; acc: 0.11
Batch: 460; loss: 2.2; acc: 0.14
Batch: 480; loss: 2.26; acc: 0.08
Batch: 500; loss: 2.22; acc: 0.09
Batch: 520; loss: 2.26; acc: 0.08
Batch: 540; loss: 2.3; acc: 0.19
Batch: 560; loss: 2.28; acc: 0.06
Batch: 580; loss: 2.2; acc: 0.16
Batch: 600; loss: 2.26; acc: 0.11
Batch: 620; loss: 2.28; acc: 0.08
Batch: 640; loss: 2.23; acc: 0.17
Batch: 660; loss: 2.27; acc: 0.14
Batch: 680; loss: 2.26; acc: 0.12
Batch: 700; loss: 2.22; acc: 0.14
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.22; acc: 0.09
Batch: 760; loss: 2.25; acc: 0.11
Batch: 780; loss: 2.27; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413557760275094; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.6642170016421005e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.3; acc: 0.06
Batch: 20; loss: 2.23; acc: 0.16
Batch: 40; loss: 2.32; acc: 0.08
Batch: 60; loss: 2.24; acc: 0.09
Batch: 80; loss: 2.21; acc: 0.17
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.23; acc: 0.09
Batch: 140; loss: 2.2; acc: 0.17
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.24; acc: 0.14
Batch: 200; loss: 2.25; acc: 0.16
Batch: 220; loss: 2.18; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.23; acc: 0.19
Batch: 280; loss: 2.23; acc: 0.14
Batch: 300; loss: 2.28; acc: 0.05
Batch: 320; loss: 2.32; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.28; acc: 0.06
Batch: 380; loss: 2.32; acc: 0.08
Batch: 400; loss: 2.21; acc: 0.12
Batch: 420; loss: 2.19; acc: 0.14
Batch: 440; loss: 2.28; acc: 0.11
Batch: 460; loss: 2.18; acc: 0.12
Batch: 480; loss: 2.24; acc: 0.16
Batch: 500; loss: 2.28; acc: 0.17
Batch: 520; loss: 2.21; acc: 0.2
Batch: 540; loss: 2.22; acc: 0.14
Batch: 560; loss: 2.34; acc: 0.09
Batch: 580; loss: 2.18; acc: 0.16
Batch: 600; loss: 2.26; acc: 0.12
Batch: 620; loss: 2.24; acc: 0.16
Batch: 640; loss: 2.3; acc: 0.08
Batch: 660; loss: 2.25; acc: 0.09
Batch: 680; loss: 2.26; acc: 0.05
Batch: 700; loss: 2.22; acc: 0.16
Batch: 720; loss: 2.25; acc: 0.09
Batch: 740; loss: 2.25; acc: 0.12
Batch: 760; loss: 2.24; acc: 0.16
Batch: 780; loss: 2.29; acc: 0.06
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413540326865617; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 3.484596891212277e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.2; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.26; acc: 0.11
Batch: 60; loss: 2.27; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.28; acc: 0.08
Batch: 120; loss: 2.23; acc: 0.16
Batch: 140; loss: 2.22; acc: 0.19
Batch: 160; loss: 2.26; acc: 0.09
Batch: 180; loss: 2.25; acc: 0.16
Batch: 200; loss: 2.24; acc: 0.14
Batch: 220; loss: 2.26; acc: 0.11
Batch: 240; loss: 2.22; acc: 0.14
Batch: 260; loss: 2.18; acc: 0.11
Batch: 280; loss: 2.17; acc: 0.14
Batch: 300; loss: 2.28; acc: 0.11
Batch: 320; loss: 2.27; acc: 0.14
Batch: 340; loss: 2.22; acc: 0.12
Batch: 360; loss: 2.2; acc: 0.17
Batch: 380; loss: 2.26; acc: 0.09
Batch: 400; loss: 2.33; acc: 0.17
Batch: 420; loss: 2.21; acc: 0.19
Batch: 440; loss: 2.26; acc: 0.11
Batch: 460; loss: 2.26; acc: 0.09
Batch: 480; loss: 2.21; acc: 0.17
Batch: 500; loss: 2.27; acc: 0.11
Batch: 520; loss: 2.2; acc: 0.14
Batch: 540; loss: 2.21; acc: 0.16
Batch: 560; loss: 2.22; acc: 0.12
Batch: 580; loss: 2.25; acc: 0.08
Batch: 600; loss: 2.25; acc: 0.09
Batch: 620; loss: 2.24; acc: 0.16
Batch: 640; loss: 2.22; acc: 0.12
Batch: 660; loss: 2.24; acc: 0.16
Batch: 680; loss: 2.21; acc: 0.14
Batch: 700; loss: 2.2; acc: 0.11
Batch: 720; loss: 2.27; acc: 0.08
Batch: 740; loss: 2.22; acc: 0.09
Batch: 760; loss: 2.28; acc: 0.05
Batch: 780; loss: 2.25; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.24135596129545; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 3.423909583943896e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.26; acc: 0.09
Batch: 20; loss: 2.26; acc: 0.16
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.14
Batch: 100; loss: 2.26; acc: 0.11
Batch: 120; loss: 2.17; acc: 0.19
Batch: 140; loss: 2.23; acc: 0.16
Batch: 160; loss: 2.19; acc: 0.08
Batch: 180; loss: 2.26; acc: 0.12
Batch: 200; loss: 2.24; acc: 0.14
Batch: 220; loss: 2.23; acc: 0.14
Batch: 240; loss: 2.2; acc: 0.19
Batch: 260; loss: 2.2; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.06
Batch: 300; loss: 2.23; acc: 0.19
Batch: 320; loss: 2.28; acc: 0.06
Batch: 340; loss: 2.19; acc: 0.08
Batch: 360; loss: 2.23; acc: 0.12
Batch: 380; loss: 2.2; acc: 0.14
Batch: 400; loss: 2.27; acc: 0.11
Batch: 420; loss: 2.23; acc: 0.09
Batch: 440; loss: 2.25; acc: 0.16
Batch: 460; loss: 2.23; acc: 0.19
Batch: 480; loss: 2.26; acc: 0.17
Batch: 500; loss: 2.24; acc: 0.16
Batch: 520; loss: 2.2; acc: 0.14
Batch: 540; loss: 2.31; acc: 0.08
Batch: 560; loss: 2.28; acc: 0.05
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.23; acc: 0.16
Batch: 620; loss: 2.27; acc: 0.06
Batch: 640; loss: 2.21; acc: 0.19
Batch: 660; loss: 2.25; acc: 0.08
Batch: 680; loss: 2.21; acc: 0.11
Batch: 700; loss: 2.21; acc: 0.11
Batch: 720; loss: 2.25; acc: 0.11
Batch: 740; loss: 2.21; acc: 0.14
Batch: 760; loss: 2.25; acc: 0.06
Batch: 780; loss: 2.22; acc: 0.09
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241356611251831; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 3.4889231756096706e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.27; acc: 0.09
Batch: 20; loss: 2.18; acc: 0.17
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.21; acc: 0.25
Batch: 80; loss: 2.24; acc: 0.08
Batch: 100; loss: 2.27; acc: 0.08
Batch: 120; loss: 2.24; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.06
Batch: 160; loss: 2.25; acc: 0.11
Batch: 180; loss: 2.22; acc: 0.16
Batch: 200; loss: 2.28; acc: 0.09
Batch: 220; loss: 2.23; acc: 0.12
Batch: 240; loss: 2.23; acc: 0.14
Batch: 260; loss: 2.24; acc: 0.06
Batch: 280; loss: 2.26; acc: 0.14
Batch: 300; loss: 2.27; acc: 0.14
Batch: 320; loss: 2.28; acc: 0.05
Batch: 340; loss: 2.24; acc: 0.09
Batch: 360; loss: 2.25; acc: 0.11
Batch: 380; loss: 2.23; acc: 0.17
Batch: 400; loss: 2.16; acc: 0.17
Batch: 420; loss: 2.22; acc: 0.09
Batch: 440; loss: 2.25; acc: 0.14
Batch: 460; loss: 2.26; acc: 0.09
Batch: 480; loss: 2.27; acc: 0.16
Batch: 500; loss: 2.25; acc: 0.09
Batch: 520; loss: 2.26; acc: 0.11
Batch: 540; loss: 2.23; acc: 0.17
Batch: 560; loss: 2.22; acc: 0.12
Batch: 580; loss: 2.2; acc: 0.16
Batch: 600; loss: 2.26; acc: 0.08
Batch: 620; loss: 2.17; acc: 0.22
Batch: 640; loss: 2.19; acc: 0.11
Batch: 660; loss: 2.27; acc: 0.12
Batch: 680; loss: 2.21; acc: 0.14
Batch: 700; loss: 2.21; acc: 0.14
Batch: 720; loss: 2.23; acc: 0.11
Batch: 740; loss: 2.23; acc: 0.16
Batch: 760; loss: 2.2; acc: 0.16
Batch: 780; loss: 2.24; acc: 0.17
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241356911932587; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 3.5124128771713004e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.25; acc: 0.16
Batch: 20; loss: 2.27; acc: 0.2
Batch: 40; loss: 2.27; acc: 0.12
Batch: 60; loss: 2.25; acc: 0.03
Batch: 80; loss: 2.32; acc: 0.06
Batch: 100; loss: 2.28; acc: 0.11
Batch: 120; loss: 2.23; acc: 0.16
Batch: 140; loss: 2.25; acc: 0.19
Batch: 160; loss: 2.26; acc: 0.06
Batch: 180; loss: 2.24; acc: 0.16
Batch: 200; loss: 2.31; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.09
Batch: 240; loss: 2.22; acc: 0.14
Batch: 260; loss: 2.32; acc: 0.09
Batch: 280; loss: 2.24; acc: 0.16
Batch: 300; loss: 2.28; acc: 0.11
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.24; acc: 0.12
Batch: 360; loss: 2.25; acc: 0.11
Batch: 380; loss: 2.27; acc: 0.12
Batch: 400; loss: 2.21; acc: 0.14
Batch: 420; loss: 2.34; acc: 0.06
Batch: 440; loss: 2.23; acc: 0.06
Batch: 460; loss: 2.24; acc: 0.12
Batch: 480; loss: 2.2; acc: 0.17
Batch: 500; loss: 2.16; acc: 0.16
Batch: 520; loss: 2.24; acc: 0.12
Batch: 540; loss: 2.25; acc: 0.05
Batch: 560; loss: 2.28; acc: 0.09
Batch: 580; loss: 2.24; acc: 0.11
Batch: 600; loss: 2.26; acc: 0.19
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.27; acc: 0.14
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.28; acc: 0.11
Batch: 700; loss: 2.24; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.06
Batch: 760; loss: 2.24; acc: 0.14
Batch: 780; loss: 2.3; acc: 0.06
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413573629537207; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.8792055420344695e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.21; acc: 0.17
Batch: 20; loss: 2.27; acc: 0.12
Batch: 40; loss: 2.25; acc: 0.14
Batch: 60; loss: 2.21; acc: 0.06
Batch: 80; loss: 2.23; acc: 0.12
Batch: 100; loss: 2.33; acc: 0.11
Batch: 120; loss: 2.25; acc: 0.06
Batch: 140; loss: 2.28; acc: 0.11
Batch: 160; loss: 2.24; acc: 0.11
Batch: 180; loss: 2.18; acc: 0.17
Batch: 200; loss: 2.23; acc: 0.06
Batch: 220; loss: 2.29; acc: 0.06
Batch: 240; loss: 2.29; acc: 0.06
Batch: 260; loss: 2.2; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.21; acc: 0.22
Batch: 320; loss: 2.28; acc: 0.12
Batch: 340; loss: 2.28; acc: 0.12
Batch: 360; loss: 2.22; acc: 0.14
Batch: 380; loss: 2.28; acc: 0.17
Batch: 400; loss: 2.27; acc: 0.12
Batch: 420; loss: 2.27; acc: 0.17
Batch: 440; loss: 2.27; acc: 0.12
Batch: 460; loss: 2.28; acc: 0.14
Batch: 480; loss: 2.27; acc: 0.11
Batch: 500; loss: 2.27; acc: 0.12
Batch: 520; loss: 2.23; acc: 0.16
Batch: 540; loss: 2.26; acc: 0.09
Batch: 560; loss: 2.25; acc: 0.06
Batch: 580; loss: 2.2; acc: 0.12
Batch: 600; loss: 2.21; acc: 0.16
Batch: 620; loss: 2.26; acc: 0.16
Batch: 640; loss: 2.24; acc: 0.2
Batch: 660; loss: 2.25; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.06
Batch: 700; loss: 2.25; acc: 0.09
Batch: 720; loss: 2.33; acc: 0.14
Batch: 740; loss: 2.31; acc: 0.09
Batch: 760; loss: 2.24; acc: 0.09
Batch: 780; loss: 2.21; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241357871681262; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 4.010112752439454e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.22; acc: 0.09
Batch: 20; loss: 2.18; acc: 0.16
Batch: 40; loss: 2.27; acc: 0.09
Batch: 60; loss: 2.28; acc: 0.06
Batch: 80; loss: 2.22; acc: 0.19
Batch: 100; loss: 2.32; acc: 0.03
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.24; acc: 0.09
Batch: 160; loss: 2.21; acc: 0.14
Batch: 180; loss: 2.25; acc: 0.09
Batch: 200; loss: 2.32; acc: 0.12
Batch: 220; loss: 2.27; acc: 0.09
Batch: 240; loss: 2.25; acc: 0.14
Batch: 260; loss: 2.21; acc: 0.12
Batch: 280; loss: 2.26; acc: 0.11
Batch: 300; loss: 2.25; acc: 0.22
Batch: 320; loss: 2.29; acc: 0.11
Batch: 340; loss: 2.23; acc: 0.12
Batch: 360; loss: 2.25; acc: 0.08
Batch: 380; loss: 2.17; acc: 0.14
Batch: 400; loss: 2.24; acc: 0.12
Batch: 420; loss: 2.22; acc: 0.12
Batch: 440; loss: 2.22; acc: 0.11
Batch: 460; loss: 2.23; acc: 0.14
Batch: 480; loss: 2.3; acc: 0.06
Batch: 500; loss: 2.26; acc: 0.12
Batch: 520; loss: 2.29; acc: 0.12
Batch: 540; loss: 2.26; acc: 0.14
Batch: 560; loss: 2.25; acc: 0.14
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.27; acc: 0.09
Batch: 620; loss: 2.26; acc: 0.14
Batch: 640; loss: 2.28; acc: 0.08
Batch: 660; loss: 2.24; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.19
Batch: 720; loss: 2.25; acc: 0.14
Batch: 740; loss: 2.19; acc: 0.2
Batch: 760; loss: 2.25; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.03
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241357660597297; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.523933264659718e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.23; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.24; acc: 0.16
Batch: 60; loss: 2.26; acc: 0.11
Batch: 80; loss: 2.25; acc: 0.09
Batch: 100; loss: 2.32; acc: 0.05
Batch: 120; loss: 2.21; acc: 0.09
Batch: 140; loss: 2.27; acc: 0.14
Batch: 160; loss: 2.22; acc: 0.14
Batch: 180; loss: 2.31; acc: 0.14
Batch: 200; loss: 2.22; acc: 0.12
Batch: 220; loss: 2.31; acc: 0.11
Batch: 240; loss: 2.25; acc: 0.12
Batch: 260; loss: 2.25; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.14
Batch: 300; loss: 2.29; acc: 0.09
Batch: 320; loss: 2.35; acc: 0.05
Batch: 340; loss: 2.25; acc: 0.08
Batch: 360; loss: 2.25; acc: 0.16
Batch: 380; loss: 2.25; acc: 0.08
Batch: 400; loss: 2.27; acc: 0.06
Batch: 420; loss: 2.27; acc: 0.06
Batch: 440; loss: 2.2; acc: 0.19
Batch: 460; loss: 2.25; acc: 0.09
Batch: 480; loss: 2.21; acc: 0.14
Batch: 500; loss: 2.25; acc: 0.12
Batch: 520; loss: 2.22; acc: 0.12
Batch: 540; loss: 2.23; acc: 0.23
Batch: 560; loss: 2.27; acc: 0.14
Batch: 580; loss: 2.23; acc: 0.19
Batch: 600; loss: 2.27; acc: 0.11
Batch: 620; loss: 2.28; acc: 0.09
Batch: 640; loss: 2.24; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.12
Batch: 680; loss: 2.23; acc: 0.16
Batch: 700; loss: 2.28; acc: 0.09
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.22; acc: 0.11
Batch: 760; loss: 2.3; acc: 0.06
Batch: 780; loss: 2.27; acc: 0.16
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241356015964678; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.4418204450048506e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.18; acc: 0.16
Batch: 20; loss: 2.24; acc: 0.14
Batch: 40; loss: 2.22; acc: 0.11
Batch: 60; loss: 2.37; acc: 0.11
Batch: 80; loss: 2.18; acc: 0.12
Batch: 100; loss: 2.27; acc: 0.12
Batch: 120; loss: 2.27; acc: 0.09
Batch: 140; loss: 2.23; acc: 0.16
Batch: 160; loss: 2.26; acc: 0.09
Batch: 180; loss: 2.31; acc: 0.03
Batch: 200; loss: 2.24; acc: 0.11
Batch: 220; loss: 2.22; acc: 0.11
Batch: 240; loss: 2.24; acc: 0.08
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.26; acc: 0.11
Batch: 300; loss: 2.31; acc: 0.09
Batch: 320; loss: 2.17; acc: 0.14
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.21; acc: 0.16
Batch: 380; loss: 2.27; acc: 0.08
Batch: 400; loss: 2.27; acc: 0.14
Batch: 420; loss: 2.23; acc: 0.12
Batch: 440; loss: 2.24; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.05
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.23; acc: 0.09
Batch: 520; loss: 2.33; acc: 0.17
Batch: 540; loss: 2.23; acc: 0.16
Batch: 560; loss: 2.2; acc: 0.2
Batch: 580; loss: 2.26; acc: 0.12
Batch: 600; loss: 2.23; acc: 0.14
Batch: 620; loss: 2.27; acc: 0.05
Batch: 640; loss: 2.29; acc: 0.08
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.22; acc: 0.11
Batch: 700; loss: 2.25; acc: 0.11
Batch: 720; loss: 2.23; acc: 0.16
Batch: 740; loss: 2.22; acc: 0.16
Batch: 760; loss: 2.27; acc: 0.11
Batch: 780; loss: 2.27; acc: 0.05
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413564548370943; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 3.7150897696847096e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.24; acc: 0.09
Batch: 40; loss: 2.23; acc: 0.09
Batch: 60; loss: 2.31; acc: 0.12
Batch: 80; loss: 2.22; acc: 0.09
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.25; acc: 0.11
Batch: 140; loss: 2.32; acc: 0.12
Batch: 160; loss: 2.24; acc: 0.2
Batch: 180; loss: 2.31; acc: 0.08
Batch: 200; loss: 2.24; acc: 0.14
Batch: 220; loss: 2.33; acc: 0.06
Batch: 240; loss: 2.22; acc: 0.06
Batch: 260; loss: 2.18; acc: 0.14
Batch: 280; loss: 2.25; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.19
Batch: 320; loss: 2.23; acc: 0.08
Batch: 340; loss: 2.23; acc: 0.08
Batch: 360; loss: 2.25; acc: 0.09
Batch: 380; loss: 2.28; acc: 0.09
Batch: 400; loss: 2.22; acc: 0.17
Batch: 420; loss: 2.3; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.08
Batch: 460; loss: 2.31; acc: 0.16
Batch: 480; loss: 2.21; acc: 0.19
Batch: 500; loss: 2.26; acc: 0.08
Batch: 520; loss: 2.22; acc: 0.14
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.31; acc: 0.09
Batch: 580; loss: 2.24; acc: 0.12
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.21; acc: 0.2
Batch: 640; loss: 2.22; acc: 0.09
Batch: 660; loss: 2.27; acc: 0.14
Batch: 680; loss: 2.32; acc: 0.09
Batch: 700; loss: 2.2; acc: 0.09
Batch: 720; loss: 2.25; acc: 0.19
Batch: 740; loss: 2.21; acc: 0.12
Batch: 760; loss: 2.22; acc: 0.11
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.24135675551785; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 4.045354580739513e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.19; acc: 0.19
Batch: 20; loss: 2.19; acc: 0.11
Batch: 40; loss: 2.27; acc: 0.09
Batch: 60; loss: 2.25; acc: 0.16
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.31; acc: 0.12
Batch: 160; loss: 2.25; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.08
Batch: 200; loss: 2.26; acc: 0.11
Batch: 220; loss: 2.24; acc: 0.12
Batch: 240; loss: 2.2; acc: 0.23
Batch: 260; loss: 2.25; acc: 0.14
Batch: 280; loss: 2.19; acc: 0.17
Batch: 300; loss: 2.23; acc: 0.19
Batch: 320; loss: 2.19; acc: 0.14
Batch: 340; loss: 2.24; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.24; acc: 0.11
Batch: 400; loss: 2.23; acc: 0.17
Batch: 420; loss: 2.2; acc: 0.17
Batch: 440; loss: 2.29; acc: 0.11
Batch: 460; loss: 2.26; acc: 0.11
Batch: 480; loss: 2.23; acc: 0.14
Batch: 500; loss: 2.25; acc: 0.14
Batch: 520; loss: 2.22; acc: 0.12
Batch: 540; loss: 2.31; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.12
Batch: 580; loss: 2.26; acc: 0.12
Batch: 600; loss: 2.31; acc: 0.05
Batch: 620; loss: 2.27; acc: 0.12
Batch: 640; loss: 2.28; acc: 0.12
Batch: 660; loss: 2.32; acc: 0.09
Batch: 680; loss: 2.25; acc: 0.12
Batch: 700; loss: 2.2; acc: 0.2
Batch: 720; loss: 2.27; acc: 0.16
Batch: 740; loss: 2.2; acc: 0.09
Batch: 760; loss: 2.25; acc: 0.11
Batch: 780; loss: 2.31; acc: 0.14
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.08
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.2413580751722786; val_accuracy: 0.12062101910828026 

The current subspace-distance is: 4.3993153667543083e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.31; acc: 0.05
Batch: 20; loss: 2.21; acc: 0.16
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.27; acc: 0.14
Batch: 80; loss: 2.25; acc: 0.14
Batch: 100; loss: 2.27; acc: 0.08
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.21; acc: 0.09
Batch: 160; loss: 2.32; acc: 0.09
Batch: 180; loss: 2.24; acc: 0.08
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.27; acc: 0.09
Batch: 240; loss: 2.25; acc: 0.08
Batch: 260; loss: 2.2; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.11
Batch: 300; loss: 2.25; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.25; acc: 0.11
Batch: 360; loss: 2.26; acc: 0.11
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.2; acc: 0.2
Batch: 420; loss: 2.16; acc: 0.17
Batch: 440; loss: 2.25; acc: 0.08
Batch: 460; loss: 2.27; acc: 0.14
Batch: 480; loss: 2.22; acc: 0.16
Batch: 500; loss: 2.27; acc: 0.09
Batch: 520; loss: 2.28; acc: 0.11
Batch: 540; loss: 2.26; acc: 0.17
Batch: 560; loss: 2.22; acc: 0.17
Batch: 580; loss: 2.3; acc: 0.16
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.2; acc: 0.08
Batch: 640; loss: 2.32; acc: 0.17
Batch: 660; loss: 2.23; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.08
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.26; acc: 0.14
Batch: 740; loss: 2.21; acc: 0.08
Batch: 760; loss: 2.27; acc: 0.06
Batch: 780; loss: 2.26; acc: 0.11
Train Epoch over. train_loss: 2.25; train_accuracy: 0.12 

Batch: 0; loss: 2.21; acc: 0.23
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.21; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.22; acc: 0.09
Batch: 120; loss: 2.19; acc: 0.17
Batch: 140; loss: 2.23; acc: 0.05
Val Epoch over. val_loss: 2.241357545184482; val_accuracy: 0.12072054140127389 

The current subspace-distance is: 4.1909213905455545e-05 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_10_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 5222
elements in E: 1110650
fraction nonzero: 0.004701751226759105
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.32; acc: 0.06
Batch: 40; loss: 2.32; acc: 0.08
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.31; acc: 0.11
Batch: 100; loss: 2.32; acc: 0.06
Batch: 120; loss: 2.32; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.12
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.32; acc: 0.11
Batch: 200; loss: 2.32; acc: 0.06
Batch: 220; loss: 2.3; acc: 0.14
Batch: 240; loss: 2.31; acc: 0.09
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.32; acc: 0.08
Batch: 300; loss: 2.29; acc: 0.2
Batch: 320; loss: 2.31; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.16
Batch: 360; loss: 2.29; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.31; acc: 0.11
Batch: 420; loss: 2.3; acc: 0.16
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.31; acc: 0.03
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.31; acc: 0.06
Batch: 540; loss: 2.32; acc: 0.06
Batch: 560; loss: 2.3; acc: 0.06
Batch: 580; loss: 2.32; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.06
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.28; acc: 0.17
Batch: 680; loss: 2.31; acc: 0.09
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.3; acc: 0.14
Batch: 740; loss: 2.31; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.05
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.32; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.11
Val Epoch over. val_loss: 2.2998734963168004; val_accuracy: 0.10459792993630573 

The current subspace-distance is: 2.132833515133825e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.31; acc: 0.05
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.31; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.14
Batch: 240; loss: 2.3; acc: 0.14
Batch: 260; loss: 2.31; acc: 0.08
Batch: 280; loss: 2.3; acc: 0.08
Batch: 300; loss: 2.3; acc: 0.12
Batch: 320; loss: 2.32; acc: 0.03
Batch: 340; loss: 2.3; acc: 0.06
Batch: 360; loss: 2.31; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.14
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.11
Batch: 440; loss: 2.27; acc: 0.25
Batch: 460; loss: 2.27; acc: 0.16
Batch: 480; loss: 2.31; acc: 0.09
Batch: 500; loss: 2.29; acc: 0.16
Batch: 520; loss: 2.3; acc: 0.16
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.14
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.27; acc: 0.23
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.31; acc: 0.08
Batch: 660; loss: 2.28; acc: 0.17
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.28; acc: 0.2
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.19
Batch: 760; loss: 2.27; acc: 0.12
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

Batch: 0; loss: 2.27; acc: 0.23
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.28; acc: 0.2
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.28; acc: 0.11
Batch: 140; loss: 2.27; acc: 0.16
Val Epoch over. val_loss: 2.276750459792508; val_accuracy: 0.14759156050955413 

The current subspace-distance is: 4.392106802697526e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.27; acc: 0.16
Batch: 40; loss: 2.27; acc: 0.2
Batch: 60; loss: 2.28; acc: 0.16
Batch: 80; loss: 2.27; acc: 0.14
Batch: 100; loss: 2.26; acc: 0.14
Batch: 120; loss: 2.24; acc: 0.23
Batch: 140; loss: 2.26; acc: 0.14
Batch: 160; loss: 2.26; acc: 0.16
Batch: 180; loss: 2.24; acc: 0.19
Batch: 200; loss: 2.27; acc: 0.16
Batch: 220; loss: 2.25; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.09
Batch: 260; loss: 2.24; acc: 0.12
Batch: 280; loss: 2.26; acc: 0.08
Batch: 300; loss: 2.25; acc: 0.19
Batch: 320; loss: 2.24; acc: 0.22
Batch: 340; loss: 2.22; acc: 0.17
Batch: 360; loss: 2.23; acc: 0.17
Batch: 380; loss: 2.24; acc: 0.17
Batch: 400; loss: 2.21; acc: 0.28
Batch: 420; loss: 2.24; acc: 0.22
Batch: 440; loss: 2.22; acc: 0.2
Batch: 460; loss: 2.23; acc: 0.22
Batch: 480; loss: 2.21; acc: 0.28
Batch: 500; loss: 2.24; acc: 0.16
Batch: 520; loss: 2.18; acc: 0.2
Batch: 540; loss: 2.19; acc: 0.22
Batch: 560; loss: 2.23; acc: 0.19
Batch: 580; loss: 2.17; acc: 0.22
Batch: 600; loss: 2.19; acc: 0.23
Batch: 620; loss: 2.19; acc: 0.25
Batch: 640; loss: 2.2; acc: 0.22
Batch: 660; loss: 2.17; acc: 0.27
Batch: 680; loss: 2.15; acc: 0.3
Batch: 700; loss: 2.18; acc: 0.2
Batch: 720; loss: 2.15; acc: 0.27
Batch: 740; loss: 2.16; acc: 0.2
Batch: 760; loss: 2.13; acc: 0.28
Batch: 780; loss: 2.12; acc: 0.27
Train Epoch over. train_loss: 2.22; train_accuracy: 0.2 

Batch: 0; loss: 2.16; acc: 0.17
Batch: 20; loss: 2.2; acc: 0.19
Batch: 40; loss: 2.12; acc: 0.23
Batch: 60; loss: 2.1; acc: 0.33
Batch: 80; loss: 2.15; acc: 0.25
Batch: 100; loss: 2.17; acc: 0.19
Batch: 120; loss: 2.14; acc: 0.19
Batch: 140; loss: 2.09; acc: 0.3
Val Epoch over. val_loss: 2.1475583109886025; val_accuracy: 0.24721337579617833 

The current subspace-distance is: 7.888522304710932e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.09; acc: 0.28
Batch: 20; loss: 2.19; acc: 0.23
Batch: 40; loss: 2.13; acc: 0.3
Batch: 60; loss: 2.11; acc: 0.23
Batch: 80; loss: 2.13; acc: 0.27
Batch: 100; loss: 2.15; acc: 0.3
Batch: 120; loss: 2.14; acc: 0.31
Batch: 140; loss: 2.12; acc: 0.3
Batch: 160; loss: 2.07; acc: 0.3
Batch: 180; loss: 2.06; acc: 0.3
Batch: 200; loss: 2.1; acc: 0.38
Batch: 220; loss: 2.12; acc: 0.28
Batch: 240; loss: 2.15; acc: 0.22
Batch: 260; loss: 2.06; acc: 0.27
Batch: 280; loss: 2.16; acc: 0.23
Batch: 300; loss: 2.05; acc: 0.33
Batch: 320; loss: 2.12; acc: 0.17
Batch: 340; loss: 2.14; acc: 0.17
Batch: 360; loss: 2.09; acc: 0.2
Batch: 380; loss: 2.07; acc: 0.3
Batch: 400; loss: 2.11; acc: 0.3
Batch: 420; loss: 2.0; acc: 0.36
Batch: 440; loss: 1.97; acc: 0.39
Batch: 460; loss: 2.13; acc: 0.28
Batch: 480; loss: 2.13; acc: 0.25
Batch: 500; loss: 2.02; acc: 0.28
Batch: 520; loss: 1.99; acc: 0.38
Batch: 540; loss: 1.91; acc: 0.47
Batch: 560; loss: 2.09; acc: 0.2
Batch: 580; loss: 1.97; acc: 0.34
Batch: 600; loss: 1.93; acc: 0.38
Batch: 620; loss: 1.88; acc: 0.41
Batch: 640; loss: 1.92; acc: 0.34
Batch: 660; loss: 1.89; acc: 0.34
Batch: 680; loss: 1.89; acc: 0.34
Batch: 700; loss: 2.01; acc: 0.28
Batch: 720; loss: 1.97; acc: 0.27
Batch: 740; loss: 1.94; acc: 0.34
Batch: 760; loss: 1.86; acc: 0.34
Batch: 780; loss: 1.92; acc: 0.31
Train Epoch over. train_loss: 2.05; train_accuracy: 0.29 

Batch: 0; loss: 1.84; acc: 0.3
Batch: 20; loss: 1.91; acc: 0.36
Batch: 40; loss: 1.63; acc: 0.42
Batch: 60; loss: 1.62; acc: 0.53
Batch: 80; loss: 1.74; acc: 0.42
Batch: 100; loss: 1.9; acc: 0.31
Batch: 120; loss: 1.97; acc: 0.34
Batch: 140; loss: 1.79; acc: 0.34
Val Epoch over. val_loss: 1.8257134332778349; val_accuracy: 0.35668789808917195 

The current subspace-distance is: 1.1695699868141674e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.84; acc: 0.34
Batch: 20; loss: 1.86; acc: 0.3
Batch: 40; loss: 1.68; acc: 0.34
Batch: 60; loss: 1.83; acc: 0.39
Batch: 80; loss: 1.9; acc: 0.34
Batch: 100; loss: 1.85; acc: 0.3
Batch: 120; loss: 1.75; acc: 0.42
Batch: 140; loss: 1.87; acc: 0.33
Batch: 160; loss: 1.94; acc: 0.31
Batch: 180; loss: 1.7; acc: 0.38
Batch: 200; loss: 1.8; acc: 0.38
Batch: 220; loss: 1.82; acc: 0.39
Batch: 240; loss: 1.81; acc: 0.33
Batch: 260; loss: 1.83; acc: 0.31
Batch: 280; loss: 1.83; acc: 0.33
Batch: 300; loss: 1.84; acc: 0.34
Batch: 320; loss: 1.81; acc: 0.41
Batch: 340; loss: 1.72; acc: 0.42
Batch: 360; loss: 1.83; acc: 0.31
Batch: 380; loss: 1.74; acc: 0.42
Batch: 400; loss: 1.55; acc: 0.53
Batch: 420; loss: 1.7; acc: 0.36
Batch: 440; loss: 1.74; acc: 0.33
Batch: 460; loss: 1.68; acc: 0.33
Batch: 480; loss: 1.67; acc: 0.36
Batch: 500; loss: 1.89; acc: 0.38
Batch: 520; loss: 1.64; acc: 0.42
Batch: 540; loss: 1.59; acc: 0.5
Batch: 560; loss: 1.81; acc: 0.38
Batch: 580; loss: 1.78; acc: 0.33
Batch: 600; loss: 1.85; acc: 0.3
Batch: 620; loss: 2.03; acc: 0.33
Batch: 640; loss: 1.74; acc: 0.34
Batch: 660; loss: 2.03; acc: 0.16
Batch: 680; loss: 2.04; acc: 0.23
Batch: 700; loss: 1.89; acc: 0.36
Batch: 720; loss: 1.87; acc: 0.33
Batch: 740; loss: 1.77; acc: 0.39
Batch: 760; loss: 1.72; acc: 0.47
Batch: 780; loss: 1.72; acc: 0.39
Train Epoch over. train_loss: 1.81; train_accuracy: 0.36 

Batch: 0; loss: 1.78; acc: 0.41
Batch: 20; loss: 1.98; acc: 0.27
Batch: 40; loss: 1.52; acc: 0.5
Batch: 60; loss: 1.56; acc: 0.55
Batch: 80; loss: 1.66; acc: 0.42
Batch: 100; loss: 1.96; acc: 0.33
Batch: 120; loss: 1.99; acc: 0.31
Batch: 140; loss: 1.64; acc: 0.39
Val Epoch over. val_loss: 1.7842679350239457; val_accuracy: 0.36046974522292996 

The current subspace-distance is: 1.5527952200500295e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.93; acc: 0.36
Batch: 20; loss: 1.94; acc: 0.31
Batch: 40; loss: 1.84; acc: 0.34
Batch: 60; loss: 1.83; acc: 0.3
Batch: 80; loss: 1.79; acc: 0.34
Batch: 100; loss: 1.7; acc: 0.44
Batch: 120; loss: 1.68; acc: 0.45
Batch: 140; loss: 1.56; acc: 0.42
Batch: 160; loss: 1.91; acc: 0.25
Batch: 180; loss: 1.9; acc: 0.41
Batch: 200; loss: 1.62; acc: 0.38
Batch: 220; loss: 1.92; acc: 0.28
Batch: 240; loss: 1.66; acc: 0.44
Batch: 260; loss: 1.75; acc: 0.39
Batch: 280; loss: 1.86; acc: 0.38
Batch: 300; loss: 1.92; acc: 0.33
Batch: 320; loss: 1.8; acc: 0.31
Batch: 340; loss: 1.74; acc: 0.47
Batch: 360; loss: 1.56; acc: 0.41
Batch: 380; loss: 1.79; acc: 0.28
Batch: 400; loss: 1.83; acc: 0.34
Batch: 420; loss: 1.6; acc: 0.5
Batch: 440; loss: 1.7; acc: 0.3
Batch: 460; loss: 1.9; acc: 0.34
Batch: 480; loss: 1.89; acc: 0.39
Batch: 500; loss: 1.74; acc: 0.41
Batch: 520; loss: 1.76; acc: 0.36
Batch: 540; loss: 1.9; acc: 0.34
Batch: 560; loss: 1.84; acc: 0.34
Batch: 580; loss: 1.86; acc: 0.38
Batch: 600; loss: 1.76; acc: 0.36
Batch: 620; loss: 1.83; acc: 0.3
Batch: 640; loss: 1.67; acc: 0.45
Batch: 660; loss: 1.77; acc: 0.31
Batch: 680; loss: 1.83; acc: 0.33
Batch: 700; loss: 1.87; acc: 0.33
Batch: 720; loss: 1.86; acc: 0.36
Batch: 740; loss: 1.94; acc: 0.28
Batch: 760; loss: 1.68; acc: 0.47
Batch: 780; loss: 1.63; acc: 0.45
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.77; acc: 0.39
Batch: 20; loss: 2.02; acc: 0.28
Batch: 40; loss: 1.53; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.55
Batch: 80; loss: 1.69; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.31
Batch: 120; loss: 2.01; acc: 0.36
Batch: 140; loss: 1.68; acc: 0.38
Val Epoch over. val_loss: 1.7837352016169554; val_accuracy: 0.3600716560509554 

The current subspace-distance is: 1.8469976566848345e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.72; acc: 0.34
Batch: 20; loss: 1.88; acc: 0.3
Batch: 40; loss: 1.83; acc: 0.31
Batch: 60; loss: 1.77; acc: 0.36
Batch: 80; loss: 1.78; acc: 0.39
Batch: 100; loss: 1.72; acc: 0.47
Batch: 120; loss: 1.92; acc: 0.27
Batch: 140; loss: 1.54; acc: 0.5
Batch: 160; loss: 1.83; acc: 0.34
Batch: 180; loss: 1.94; acc: 0.34
Batch: 200; loss: 1.84; acc: 0.39
Batch: 220; loss: 1.85; acc: 0.38
Batch: 240; loss: 1.75; acc: 0.42
Batch: 260; loss: 1.79; acc: 0.48
Batch: 280; loss: 1.87; acc: 0.3
Batch: 300; loss: 1.74; acc: 0.41
Batch: 320; loss: 1.82; acc: 0.39
Batch: 340; loss: 1.82; acc: 0.38
Batch: 360; loss: 1.85; acc: 0.3
Batch: 380; loss: 1.79; acc: 0.36
Batch: 400; loss: 1.63; acc: 0.47
Batch: 420; loss: 1.73; acc: 0.39
Batch: 440; loss: 1.8; acc: 0.38
Batch: 460; loss: 1.76; acc: 0.41
Batch: 480; loss: 1.77; acc: 0.42
Batch: 500; loss: 1.79; acc: 0.39
Batch: 520; loss: 1.72; acc: 0.36
Batch: 540; loss: 1.84; acc: 0.33
Batch: 560; loss: 1.81; acc: 0.44
Batch: 580; loss: 1.83; acc: 0.34
Batch: 600; loss: 1.82; acc: 0.28
Batch: 620; loss: 1.86; acc: 0.3
Batch: 640; loss: 1.75; acc: 0.38
Batch: 660; loss: 2.01; acc: 0.28
Batch: 680; loss: 1.81; acc: 0.34
Batch: 700; loss: 1.72; acc: 0.44
Batch: 720; loss: 1.79; acc: 0.31
Batch: 740; loss: 1.94; acc: 0.23
Batch: 760; loss: 1.73; acc: 0.44
Batch: 780; loss: 1.87; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.03; acc: 0.27
Batch: 40; loss: 1.49; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.31
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.34
Val Epoch over. val_loss: 1.7880220268941989; val_accuracy: 0.36027070063694266 

The current subspace-distance is: 1.8807129890774377e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.18; acc: 0.28
Batch: 20; loss: 1.89; acc: 0.39
Batch: 40; loss: 1.84; acc: 0.31
Batch: 60; loss: 1.8; acc: 0.33
Batch: 80; loss: 1.82; acc: 0.38
Batch: 100; loss: 1.8; acc: 0.36
Batch: 120; loss: 1.65; acc: 0.36
Batch: 140; loss: 1.91; acc: 0.3
Batch: 160; loss: 1.79; acc: 0.42
Batch: 180; loss: 1.85; acc: 0.36
Batch: 200; loss: 1.84; acc: 0.39
Batch: 220; loss: 1.73; acc: 0.41
Batch: 240; loss: 1.85; acc: 0.42
Batch: 260; loss: 1.9; acc: 0.3
Batch: 280; loss: 1.83; acc: 0.39
Batch: 300; loss: 1.81; acc: 0.33
Batch: 320; loss: 1.79; acc: 0.39
Batch: 340; loss: 1.83; acc: 0.28
Batch: 360; loss: 1.87; acc: 0.31
Batch: 380; loss: 1.98; acc: 0.33
Batch: 400; loss: 1.84; acc: 0.34
Batch: 420; loss: 1.91; acc: 0.27
Batch: 440; loss: 1.83; acc: 0.39
Batch: 460; loss: 1.83; acc: 0.33
Batch: 480; loss: 1.73; acc: 0.39
Batch: 500; loss: 1.82; acc: 0.42
Batch: 520; loss: 1.81; acc: 0.33
Batch: 540; loss: 1.83; acc: 0.31
Batch: 560; loss: 1.97; acc: 0.17
Batch: 580; loss: 1.66; acc: 0.47
Batch: 600; loss: 1.67; acc: 0.44
Batch: 620; loss: 1.68; acc: 0.42
Batch: 640; loss: 1.65; acc: 0.34
Batch: 660; loss: 1.92; acc: 0.34
Batch: 680; loss: 1.76; acc: 0.42
Batch: 700; loss: 1.72; acc: 0.42
Batch: 720; loss: 1.81; acc: 0.36
Batch: 740; loss: 1.92; acc: 0.27
Batch: 760; loss: 1.73; acc: 0.45
Batch: 780; loss: 1.77; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 2.05; acc: 0.23
Batch: 40; loss: 1.5; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.68; acc: 0.47
Batch: 100; loss: 1.95; acc: 0.3
Batch: 120; loss: 2.0; acc: 0.33
Batch: 140; loss: 1.7; acc: 0.38
Val Epoch over. val_loss: 1.7852399774417755; val_accuracy: 0.363953025477707 

The current subspace-distance is: 2.1114959963597357e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.67; acc: 0.39
Batch: 20; loss: 2.06; acc: 0.25
Batch: 40; loss: 1.85; acc: 0.34
Batch: 60; loss: 1.85; acc: 0.27
Batch: 80; loss: 1.8; acc: 0.38
Batch: 100; loss: 1.58; acc: 0.45
Batch: 120; loss: 1.78; acc: 0.34
Batch: 140; loss: 1.93; acc: 0.34
Batch: 160; loss: 1.71; acc: 0.45
Batch: 180; loss: 1.83; acc: 0.36
Batch: 200; loss: 1.95; acc: 0.34
Batch: 220; loss: 1.68; acc: 0.41
Batch: 240; loss: 1.85; acc: 0.33
Batch: 260; loss: 1.82; acc: 0.47
Batch: 280; loss: 1.83; acc: 0.3
Batch: 300; loss: 1.84; acc: 0.33
Batch: 320; loss: 1.84; acc: 0.38
Batch: 340; loss: 1.8; acc: 0.41
Batch: 360; loss: 1.79; acc: 0.41
Batch: 380; loss: 1.82; acc: 0.39
Batch: 400; loss: 1.92; acc: 0.34
Batch: 420; loss: 1.86; acc: 0.34
Batch: 440; loss: 1.7; acc: 0.41
Batch: 460; loss: 1.88; acc: 0.34
Batch: 480; loss: 1.83; acc: 0.39
Batch: 500; loss: 1.89; acc: 0.27
Batch: 520; loss: 1.78; acc: 0.38
Batch: 540; loss: 1.8; acc: 0.39
Batch: 560; loss: 1.92; acc: 0.31
Batch: 580; loss: 1.69; acc: 0.39
Batch: 600; loss: 1.79; acc: 0.36
Batch: 620; loss: 1.84; acc: 0.38
Batch: 640; loss: 1.68; acc: 0.41
Batch: 660; loss: 1.83; acc: 0.31
Batch: 680; loss: 1.74; acc: 0.42
Batch: 700; loss: 1.79; acc: 0.38
Batch: 720; loss: 1.93; acc: 0.3
Batch: 740; loss: 1.78; acc: 0.45
Batch: 760; loss: 1.7; acc: 0.38
Batch: 780; loss: 1.94; acc: 0.33
Train Epoch over. train_loss: 1.81; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.3
Batch: 40; loss: 1.5; acc: 0.53
Batch: 60; loss: 1.55; acc: 0.55
Batch: 80; loss: 1.66; acc: 0.42
Batch: 100; loss: 1.97; acc: 0.3
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.39
Val Epoch over. val_loss: 1.7829264873152326; val_accuracy: 0.36315684713375795 

The current subspace-distance is: 2.3512377083534375e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.86; acc: 0.34
Batch: 20; loss: 1.85; acc: 0.33
Batch: 40; loss: 1.82; acc: 0.42
Batch: 60; loss: 1.9; acc: 0.3
Batch: 80; loss: 1.85; acc: 0.39
Batch: 100; loss: 1.69; acc: 0.39
Batch: 120; loss: 1.89; acc: 0.3
Batch: 140; loss: 1.84; acc: 0.25
Batch: 160; loss: 1.84; acc: 0.34
Batch: 180; loss: 1.92; acc: 0.3
Batch: 200; loss: 1.78; acc: 0.33
Batch: 220; loss: 1.57; acc: 0.42
Batch: 240; loss: 1.87; acc: 0.33
Batch: 260; loss: 1.87; acc: 0.27
Batch: 280; loss: 1.57; acc: 0.48
Batch: 300; loss: 1.73; acc: 0.39
Batch: 320; loss: 1.83; acc: 0.38
Batch: 340; loss: 2.04; acc: 0.28
Batch: 360; loss: 1.88; acc: 0.31
Batch: 380; loss: 1.74; acc: 0.41
Batch: 400; loss: 1.77; acc: 0.3
Batch: 420; loss: 1.71; acc: 0.39
Batch: 440; loss: 1.69; acc: 0.38
Batch: 460; loss: 1.76; acc: 0.33
Batch: 480; loss: 1.94; acc: 0.33
Batch: 500; loss: 1.76; acc: 0.33
Batch: 520; loss: 1.91; acc: 0.42
Batch: 540; loss: 1.78; acc: 0.33
Batch: 560; loss: 1.76; acc: 0.36
Batch: 580; loss: 1.87; acc: 0.27
Batch: 600; loss: 1.76; acc: 0.39
Batch: 620; loss: 1.77; acc: 0.31
Batch: 640; loss: 1.7; acc: 0.42
Batch: 660; loss: 1.79; acc: 0.33
Batch: 680; loss: 1.82; acc: 0.39
Batch: 700; loss: 1.95; acc: 0.3
Batch: 720; loss: 1.71; acc: 0.42
Batch: 740; loss: 1.76; acc: 0.36
Batch: 760; loss: 1.75; acc: 0.38
Batch: 780; loss: 1.67; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 2.03; acc: 0.25
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.48
Batch: 80; loss: 1.66; acc: 0.45
Batch: 100; loss: 1.96; acc: 0.33
Batch: 120; loss: 1.98; acc: 0.31
Batch: 140; loss: 1.68; acc: 0.38
Val Epoch over. val_loss: 1.7832661677318014; val_accuracy: 0.368531050955414 

The current subspace-distance is: 2.4735387341934256e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.2; acc: 0.31
Batch: 20; loss: 1.69; acc: 0.41
Batch: 40; loss: 1.87; acc: 0.31
Batch: 60; loss: 1.74; acc: 0.33
Batch: 80; loss: 1.92; acc: 0.3
Batch: 100; loss: 1.89; acc: 0.3
Batch: 120; loss: 1.92; acc: 0.39
Batch: 140; loss: 1.82; acc: 0.34
Batch: 160; loss: 2.02; acc: 0.27
Batch: 180; loss: 1.83; acc: 0.38
Batch: 200; loss: 1.81; acc: 0.33
Batch: 220; loss: 1.69; acc: 0.44
Batch: 240; loss: 1.88; acc: 0.25
Batch: 260; loss: 1.97; acc: 0.3
Batch: 280; loss: 1.82; acc: 0.44
Batch: 300; loss: 1.7; acc: 0.31
Batch: 320; loss: 1.9; acc: 0.36
Batch: 340; loss: 1.86; acc: 0.33
Batch: 360; loss: 1.61; acc: 0.47
Batch: 380; loss: 1.78; acc: 0.36
Batch: 400; loss: 1.7; acc: 0.38
Batch: 420; loss: 2.05; acc: 0.27
Batch: 440; loss: 2.02; acc: 0.3
Batch: 460; loss: 1.88; acc: 0.34
Batch: 480; loss: 1.7; acc: 0.36
Batch: 500; loss: 1.73; acc: 0.33
Batch: 520; loss: 1.88; acc: 0.36
Batch: 540; loss: 1.65; acc: 0.41
Batch: 560; loss: 1.75; acc: 0.33
Batch: 580; loss: 1.79; acc: 0.34
Batch: 600; loss: 1.89; acc: 0.34
Batch: 620; loss: 1.91; acc: 0.3
Batch: 640; loss: 1.82; acc: 0.34
Batch: 660; loss: 1.95; acc: 0.28
Batch: 680; loss: 1.8; acc: 0.44
Batch: 700; loss: 1.88; acc: 0.36
Batch: 720; loss: 1.77; acc: 0.42
Batch: 740; loss: 1.78; acc: 0.3
Batch: 760; loss: 1.81; acc: 0.34
Batch: 780; loss: 1.91; acc: 0.36
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.3
Batch: 40; loss: 1.52; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.56
Batch: 80; loss: 1.68; acc: 0.36
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.68; acc: 0.38
Val Epoch over. val_loss: 1.7797398119215753; val_accuracy: 0.3632563694267516 

The current subspace-distance is: 2.7077130653196946e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.86; acc: 0.36
Batch: 20; loss: 2.02; acc: 0.3
Batch: 40; loss: 1.84; acc: 0.36
Batch: 60; loss: 1.59; acc: 0.45
Batch: 80; loss: 1.73; acc: 0.38
Batch: 100; loss: 1.79; acc: 0.44
Batch: 120; loss: 1.71; acc: 0.3
Batch: 140; loss: 1.78; acc: 0.41
Batch: 160; loss: 1.57; acc: 0.48
Batch: 180; loss: 1.86; acc: 0.34
Batch: 200; loss: 1.9; acc: 0.3
Batch: 220; loss: 1.79; acc: 0.39
Batch: 240; loss: 1.87; acc: 0.42
Batch: 260; loss: 1.72; acc: 0.38
Batch: 280; loss: 1.72; acc: 0.42
Batch: 300; loss: 1.64; acc: 0.39
Batch: 320; loss: 1.81; acc: 0.38
Batch: 340; loss: 1.72; acc: 0.42
Batch: 360; loss: 1.91; acc: 0.38
Batch: 380; loss: 1.71; acc: 0.44
Batch: 400; loss: 1.87; acc: 0.34
Batch: 420; loss: 1.88; acc: 0.33
Batch: 440; loss: 1.76; acc: 0.38
Batch: 460; loss: 2.02; acc: 0.33
Batch: 480; loss: 2.11; acc: 0.28
Batch: 500; loss: 1.94; acc: 0.34
Batch: 520; loss: 1.81; acc: 0.38
Batch: 540; loss: 1.71; acc: 0.41
Batch: 560; loss: 1.84; acc: 0.31
Batch: 580; loss: 1.9; acc: 0.3
Batch: 600; loss: 1.81; acc: 0.34
Batch: 620; loss: 1.97; acc: 0.3
Batch: 640; loss: 2.12; acc: 0.3
Batch: 660; loss: 1.75; acc: 0.41
Batch: 680; loss: 2.12; acc: 0.25
Batch: 700; loss: 1.81; acc: 0.36
Batch: 720; loss: 1.94; acc: 0.28
Batch: 740; loss: 1.76; acc: 0.38
Batch: 760; loss: 1.85; acc: 0.34
Batch: 780; loss: 1.89; acc: 0.28
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.77; acc: 0.38
Batch: 20; loss: 2.0; acc: 0.28
Batch: 40; loss: 1.52; acc: 0.5
Batch: 60; loss: 1.56; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.38
Batch: 140; loss: 1.66; acc: 0.38
Val Epoch over. val_loss: 1.7790453661778929; val_accuracy: 0.3638535031847134 

The current subspace-distance is: 3.058727816096507e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.74; acc: 0.39
Batch: 20; loss: 1.91; acc: 0.3
Batch: 40; loss: 1.96; acc: 0.25
Batch: 60; loss: 1.77; acc: 0.42
Batch: 80; loss: 1.79; acc: 0.36
Batch: 100; loss: 1.81; acc: 0.27
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.7; acc: 0.33
Batch: 160; loss: 1.74; acc: 0.41
Batch: 180; loss: 1.86; acc: 0.28
Batch: 200; loss: 1.72; acc: 0.41
Batch: 220; loss: 1.82; acc: 0.31
Batch: 240; loss: 1.85; acc: 0.33
Batch: 260; loss: 1.86; acc: 0.39
Batch: 280; loss: 1.92; acc: 0.3
Batch: 300; loss: 1.85; acc: 0.34
Batch: 320; loss: 1.67; acc: 0.47
Batch: 340; loss: 1.84; acc: 0.31
Batch: 360; loss: 1.81; acc: 0.38
Batch: 380; loss: 1.65; acc: 0.39
Batch: 400; loss: 1.75; acc: 0.39
Batch: 420; loss: 1.93; acc: 0.28
Batch: 440; loss: 1.83; acc: 0.3
Batch: 460; loss: 1.77; acc: 0.33
Batch: 480; loss: 1.85; acc: 0.38
Batch: 500; loss: 1.85; acc: 0.42
Batch: 520; loss: 1.95; acc: 0.3
Batch: 540; loss: 1.89; acc: 0.42
Batch: 560; loss: 1.86; acc: 0.33
Batch: 580; loss: 1.74; acc: 0.38
Batch: 600; loss: 1.74; acc: 0.31
Batch: 620; loss: 1.66; acc: 0.38
Batch: 640; loss: 1.86; acc: 0.23
Batch: 660; loss: 1.7; acc: 0.39
Batch: 680; loss: 1.84; acc: 0.38
Batch: 700; loss: 1.9; acc: 0.3
Batch: 720; loss: 1.96; acc: 0.27
Batch: 740; loss: 1.9; acc: 0.39
Batch: 760; loss: 1.85; acc: 0.34
Batch: 780; loss: 1.81; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 2.02; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.53
Batch: 60; loss: 1.54; acc: 0.52
Batch: 80; loss: 1.68; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 2.0; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.779361952641967; val_accuracy: 0.36375398089171973 

The current subspace-distance is: 2.941649108834099e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.84; acc: 0.42
Batch: 20; loss: 2.09; acc: 0.23
Batch: 40; loss: 1.55; acc: 0.5
Batch: 60; loss: 1.81; acc: 0.36
Batch: 80; loss: 1.83; acc: 0.28
Batch: 100; loss: 1.71; acc: 0.36
Batch: 120; loss: 1.82; acc: 0.36
Batch: 140; loss: 1.8; acc: 0.31
Batch: 160; loss: 1.92; acc: 0.22
Batch: 180; loss: 1.79; acc: 0.38
Batch: 200; loss: 1.92; acc: 0.25
Batch: 220; loss: 1.73; acc: 0.42
Batch: 240; loss: 1.77; acc: 0.31
Batch: 260; loss: 1.66; acc: 0.52
Batch: 280; loss: 1.76; acc: 0.36
Batch: 300; loss: 1.75; acc: 0.36
Batch: 320; loss: 1.68; acc: 0.52
Batch: 340; loss: 2.04; acc: 0.28
Batch: 360; loss: 1.79; acc: 0.39
Batch: 380; loss: 1.73; acc: 0.3
Batch: 400; loss: 1.75; acc: 0.45
Batch: 420; loss: 1.96; acc: 0.31
Batch: 440; loss: 1.76; acc: 0.39
Batch: 460; loss: 1.95; acc: 0.36
Batch: 480; loss: 1.79; acc: 0.33
Batch: 500; loss: 1.7; acc: 0.38
Batch: 520; loss: 1.74; acc: 0.41
Batch: 540; loss: 1.53; acc: 0.5
Batch: 560; loss: 1.92; acc: 0.33
Batch: 580; loss: 1.5; acc: 0.41
Batch: 600; loss: 1.9; acc: 0.28
Batch: 620; loss: 1.93; acc: 0.31
Batch: 640; loss: 1.82; acc: 0.34
Batch: 660; loss: 1.66; acc: 0.34
Batch: 680; loss: 1.94; acc: 0.34
Batch: 700; loss: 1.87; acc: 0.34
Batch: 720; loss: 1.62; acc: 0.42
Batch: 740; loss: 1.67; acc: 0.34
Batch: 760; loss: 1.68; acc: 0.41
Batch: 780; loss: 1.95; acc: 0.34
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 2.02; acc: 0.27
Batch: 40; loss: 1.52; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.69; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7812886655710305; val_accuracy: 0.3613654458598726 

The current subspace-distance is: 3.1195020710583776e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.8; acc: 0.34
Batch: 20; loss: 1.58; acc: 0.44
Batch: 40; loss: 1.86; acc: 0.38
Batch: 60; loss: 1.63; acc: 0.41
Batch: 80; loss: 1.72; acc: 0.39
Batch: 100; loss: 1.76; acc: 0.42
Batch: 120; loss: 1.66; acc: 0.38
Batch: 140; loss: 1.89; acc: 0.3
Batch: 160; loss: 1.85; acc: 0.33
Batch: 180; loss: 1.72; acc: 0.36
Batch: 200; loss: 1.72; acc: 0.45
Batch: 220; loss: 1.78; acc: 0.36
Batch: 240; loss: 1.87; acc: 0.27
Batch: 260; loss: 1.93; acc: 0.28
Batch: 280; loss: 1.81; acc: 0.33
Batch: 300; loss: 1.83; acc: 0.33
Batch: 320; loss: 1.9; acc: 0.3
Batch: 340; loss: 1.64; acc: 0.44
Batch: 360; loss: 1.75; acc: 0.42
Batch: 380; loss: 1.79; acc: 0.38
Batch: 400; loss: 1.62; acc: 0.44
Batch: 420; loss: 1.89; acc: 0.38
Batch: 440; loss: 1.85; acc: 0.34
Batch: 460; loss: 1.93; acc: 0.36
Batch: 480; loss: 1.77; acc: 0.39
Batch: 500; loss: 1.83; acc: 0.39
Batch: 520; loss: 1.93; acc: 0.28
Batch: 540; loss: 1.84; acc: 0.39
Batch: 560; loss: 1.77; acc: 0.42
Batch: 580; loss: 1.75; acc: 0.39
Batch: 600; loss: 1.76; acc: 0.34
Batch: 620; loss: 1.76; acc: 0.44
Batch: 640; loss: 1.86; acc: 0.33
Batch: 660; loss: 1.55; acc: 0.45
Batch: 680; loss: 1.6; acc: 0.47
Batch: 700; loss: 2.0; acc: 0.23
Batch: 720; loss: 1.78; acc: 0.33
Batch: 740; loss: 1.73; acc: 0.38
Batch: 760; loss: 1.87; acc: 0.33
Batch: 780; loss: 1.76; acc: 0.41
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.28
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.56
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.96; acc: 0.31
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.65; acc: 0.39
Val Epoch over. val_loss: 1.7792363349039844; val_accuracy: 0.3613654458598726 

The current subspace-distance is: 3.406109317438677e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.66; acc: 0.39
Batch: 20; loss: 1.85; acc: 0.33
Batch: 40; loss: 1.75; acc: 0.38
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.8; acc: 0.3
Batch: 100; loss: 1.81; acc: 0.39
Batch: 120; loss: 1.74; acc: 0.39
Batch: 140; loss: 1.97; acc: 0.23
Batch: 160; loss: 1.92; acc: 0.3
Batch: 180; loss: 1.99; acc: 0.28
Batch: 200; loss: 1.76; acc: 0.36
Batch: 220; loss: 1.87; acc: 0.31
Batch: 240; loss: 1.93; acc: 0.3
Batch: 260; loss: 1.83; acc: 0.28
Batch: 280; loss: 1.85; acc: 0.36
Batch: 300; loss: 1.83; acc: 0.34
Batch: 320; loss: 1.88; acc: 0.36
Batch: 340; loss: 1.83; acc: 0.36
Batch: 360; loss: 1.78; acc: 0.33
Batch: 380; loss: 1.56; acc: 0.41
Batch: 400; loss: 1.79; acc: 0.33
Batch: 420; loss: 1.82; acc: 0.31
Batch: 440; loss: 1.9; acc: 0.3
Batch: 460; loss: 1.8; acc: 0.44
Batch: 480; loss: 1.74; acc: 0.34
Batch: 500; loss: 1.9; acc: 0.34
Batch: 520; loss: 1.79; acc: 0.36
Batch: 540; loss: 1.6; acc: 0.42
Batch: 560; loss: 1.84; acc: 0.28
Batch: 580; loss: 2.05; acc: 0.23
Batch: 600; loss: 1.66; acc: 0.39
Batch: 620; loss: 1.71; acc: 0.44
Batch: 640; loss: 1.72; acc: 0.41
Batch: 660; loss: 1.85; acc: 0.34
Batch: 680; loss: 1.75; acc: 0.41
Batch: 700; loss: 1.88; acc: 0.33
Batch: 720; loss: 1.84; acc: 0.33
Batch: 740; loss: 1.75; acc: 0.36
Batch: 760; loss: 1.84; acc: 0.33
Batch: 780; loss: 1.68; acc: 0.52
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.28
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.55
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7802243088461032; val_accuracy: 0.3622611464968153 

The current subspace-distance is: 3.437041232245974e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.84; acc: 0.41
Batch: 20; loss: 1.88; acc: 0.38
Batch: 40; loss: 1.94; acc: 0.23
Batch: 60; loss: 1.78; acc: 0.38
Batch: 80; loss: 1.93; acc: 0.28
Batch: 100; loss: 2.0; acc: 0.27
Batch: 120; loss: 1.75; acc: 0.36
Batch: 140; loss: 2.08; acc: 0.28
Batch: 160; loss: 1.68; acc: 0.39
Batch: 180; loss: 1.8; acc: 0.38
Batch: 200; loss: 1.59; acc: 0.45
Batch: 220; loss: 1.87; acc: 0.42
Batch: 240; loss: 1.82; acc: 0.36
Batch: 260; loss: 1.88; acc: 0.38
Batch: 280; loss: 1.83; acc: 0.42
Batch: 300; loss: 1.78; acc: 0.25
Batch: 320; loss: 1.82; acc: 0.38
Batch: 340; loss: 1.78; acc: 0.33
Batch: 360; loss: 1.99; acc: 0.28
Batch: 380; loss: 1.85; acc: 0.34
Batch: 400; loss: 1.84; acc: 0.31
Batch: 420; loss: 1.72; acc: 0.39
Batch: 440; loss: 1.63; acc: 0.44
Batch: 460; loss: 1.84; acc: 0.31
Batch: 480; loss: 1.61; acc: 0.45
Batch: 500; loss: 1.81; acc: 0.39
Batch: 520; loss: 1.63; acc: 0.38
Batch: 540; loss: 1.74; acc: 0.27
Batch: 560; loss: 1.8; acc: 0.31
Batch: 580; loss: 1.76; acc: 0.39
Batch: 600; loss: 1.7; acc: 0.42
Batch: 620; loss: 1.76; acc: 0.31
Batch: 640; loss: 1.88; acc: 0.3
Batch: 660; loss: 1.84; acc: 0.31
Batch: 680; loss: 1.81; acc: 0.34
Batch: 700; loss: 1.71; acc: 0.39
Batch: 720; loss: 1.77; acc: 0.41
Batch: 740; loss: 1.87; acc: 0.36
Batch: 760; loss: 1.82; acc: 0.33
Batch: 780; loss: 1.92; acc: 0.27
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.02; acc: 0.28
Batch: 40; loss: 1.52; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.56
Batch: 80; loss: 1.68; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.68; acc: 0.38
Val Epoch over. val_loss: 1.7803330398668908; val_accuracy: 0.36375398089171973 

The current subspace-distance is: 3.905201447196305e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.78; acc: 0.36
Batch: 20; loss: 1.73; acc: 0.33
Batch: 40; loss: 1.88; acc: 0.33
Batch: 60; loss: 1.9; acc: 0.31
Batch: 80; loss: 1.97; acc: 0.28
Batch: 100; loss: 1.75; acc: 0.41
Batch: 120; loss: 1.75; acc: 0.3
Batch: 140; loss: 1.83; acc: 0.31
Batch: 160; loss: 1.74; acc: 0.31
Batch: 180; loss: 1.69; acc: 0.41
Batch: 200; loss: 1.76; acc: 0.39
Batch: 220; loss: 1.99; acc: 0.3
Batch: 240; loss: 1.71; acc: 0.42
Batch: 260; loss: 1.78; acc: 0.34
Batch: 280; loss: 1.91; acc: 0.38
Batch: 300; loss: 1.63; acc: 0.45
Batch: 320; loss: 1.86; acc: 0.36
Batch: 340; loss: 1.7; acc: 0.39
Batch: 360; loss: 1.79; acc: 0.38
Batch: 380; loss: 1.83; acc: 0.31
Batch: 400; loss: 1.69; acc: 0.34
Batch: 420; loss: 1.96; acc: 0.25
Batch: 440; loss: 1.97; acc: 0.27
Batch: 460; loss: 2.1; acc: 0.2
Batch: 480; loss: 1.64; acc: 0.55
Batch: 500; loss: 1.89; acc: 0.36
Batch: 520; loss: 1.76; acc: 0.48
Batch: 540; loss: 1.81; acc: 0.34
Batch: 560; loss: 1.89; acc: 0.42
Batch: 580; loss: 1.91; acc: 0.41
Batch: 600; loss: 1.77; acc: 0.42
Batch: 620; loss: 1.61; acc: 0.48
Batch: 640; loss: 1.71; acc: 0.39
Batch: 660; loss: 1.73; acc: 0.39
Batch: 680; loss: 1.76; acc: 0.38
Batch: 700; loss: 1.78; acc: 0.31
Batch: 720; loss: 1.86; acc: 0.3
Batch: 740; loss: 2.05; acc: 0.23
Batch: 760; loss: 1.85; acc: 0.33
Batch: 780; loss: 2.0; acc: 0.27
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.3
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.55
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.96; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7793780922130416; val_accuracy: 0.36106687898089174 

The current subspace-distance is: 4.268361590220593e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.78; acc: 0.41
Batch: 20; loss: 1.75; acc: 0.36
Batch: 40; loss: 1.95; acc: 0.33
Batch: 60; loss: 1.79; acc: 0.33
Batch: 80; loss: 1.91; acc: 0.28
Batch: 100; loss: 1.74; acc: 0.39
Batch: 120; loss: 1.89; acc: 0.33
Batch: 140; loss: 1.86; acc: 0.31
Batch: 160; loss: 1.68; acc: 0.41
Batch: 180; loss: 1.83; acc: 0.3
Batch: 200; loss: 2.05; acc: 0.31
Batch: 220; loss: 1.77; acc: 0.39
Batch: 240; loss: 1.85; acc: 0.38
Batch: 260; loss: 1.6; acc: 0.53
Batch: 280; loss: 1.7; acc: 0.47
Batch: 300; loss: 1.76; acc: 0.36
Batch: 320; loss: 1.86; acc: 0.38
Batch: 340; loss: 1.66; acc: 0.42
Batch: 360; loss: 1.81; acc: 0.33
Batch: 380; loss: 1.86; acc: 0.38
Batch: 400; loss: 1.85; acc: 0.34
Batch: 420; loss: 1.87; acc: 0.31
Batch: 440; loss: 2.01; acc: 0.28
Batch: 460; loss: 1.63; acc: 0.45
Batch: 480; loss: 1.76; acc: 0.34
Batch: 500; loss: 1.62; acc: 0.44
Batch: 520; loss: 1.89; acc: 0.36
Batch: 540; loss: 1.67; acc: 0.42
Batch: 560; loss: 1.56; acc: 0.45
Batch: 580; loss: 1.94; acc: 0.3
Batch: 600; loss: 1.76; acc: 0.41
Batch: 620; loss: 1.78; acc: 0.45
Batch: 640; loss: 1.71; acc: 0.38
Batch: 660; loss: 1.75; acc: 0.36
Batch: 680; loss: 1.58; acc: 0.48
Batch: 700; loss: 1.93; acc: 0.28
Batch: 720; loss: 1.77; acc: 0.39
Batch: 740; loss: 1.79; acc: 0.42
Batch: 760; loss: 1.91; acc: 0.3
Batch: 780; loss: 1.65; acc: 0.41
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.48
Batch: 60; loss: 1.55; acc: 0.56
Batch: 80; loss: 1.68; acc: 0.41
Batch: 100; loss: 1.94; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.33
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7815229171400617; val_accuracy: 0.36156449044585987 

The current subspace-distance is: 4.024110967293382e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.75; acc: 0.36
Batch: 20; loss: 1.75; acc: 0.33
Batch: 40; loss: 1.84; acc: 0.42
Batch: 60; loss: 1.67; acc: 0.41
Batch: 80; loss: 1.88; acc: 0.42
Batch: 100; loss: 2.08; acc: 0.22
Batch: 120; loss: 1.77; acc: 0.34
Batch: 140; loss: 1.8; acc: 0.34
Batch: 160; loss: 1.71; acc: 0.39
Batch: 180; loss: 1.83; acc: 0.41
Batch: 200; loss: 1.68; acc: 0.34
Batch: 220; loss: 1.83; acc: 0.36
Batch: 240; loss: 1.83; acc: 0.36
Batch: 260; loss: 1.82; acc: 0.3
Batch: 280; loss: 1.72; acc: 0.34
Batch: 300; loss: 1.75; acc: 0.34
Batch: 320; loss: 1.89; acc: 0.38
Batch: 340; loss: 1.69; acc: 0.36
Batch: 360; loss: 1.64; acc: 0.47
Batch: 380; loss: 1.68; acc: 0.5
Batch: 400; loss: 1.58; acc: 0.47
Batch: 420; loss: 1.86; acc: 0.27
Batch: 440; loss: 1.84; acc: 0.34
Batch: 460; loss: 1.91; acc: 0.36
Batch: 480; loss: 2.02; acc: 0.28
Batch: 500; loss: 1.69; acc: 0.45
Batch: 520; loss: 1.69; acc: 0.33
Batch: 540; loss: 1.7; acc: 0.38
Batch: 560; loss: 1.67; acc: 0.36
Batch: 580; loss: 1.69; acc: 0.39
Batch: 600; loss: 1.73; acc: 0.36
Batch: 620; loss: 1.76; acc: 0.41
Batch: 640; loss: 1.74; acc: 0.34
Batch: 660; loss: 1.74; acc: 0.34
Batch: 680; loss: 1.69; acc: 0.34
Batch: 700; loss: 1.74; acc: 0.39
Batch: 720; loss: 1.72; acc: 0.41
Batch: 740; loss: 1.72; acc: 0.42
Batch: 760; loss: 1.69; acc: 0.42
Batch: 780; loss: 1.55; acc: 0.41
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.28
Batch: 40; loss: 1.5; acc: 0.5
Batch: 60; loss: 1.54; acc: 0.53
Batch: 80; loss: 1.66; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.31
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7789507390587194; val_accuracy: 0.36315684713375795 

The current subspace-distance is: 4.393215567688458e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.89; acc: 0.23
Batch: 20; loss: 1.74; acc: 0.47
Batch: 40; loss: 1.73; acc: 0.33
Batch: 60; loss: 1.89; acc: 0.36
Batch: 80; loss: 1.8; acc: 0.31
Batch: 100; loss: 1.8; acc: 0.33
Batch: 120; loss: 1.92; acc: 0.3
Batch: 140; loss: 1.79; acc: 0.31
Batch: 160; loss: 1.91; acc: 0.25
Batch: 180; loss: 1.85; acc: 0.3
Batch: 200; loss: 1.85; acc: 0.33
Batch: 220; loss: 1.93; acc: 0.31
Batch: 240; loss: 1.93; acc: 0.38
Batch: 260; loss: 1.8; acc: 0.36
Batch: 280; loss: 1.9; acc: 0.33
Batch: 300; loss: 1.76; acc: 0.34
Batch: 320; loss: 1.83; acc: 0.34
Batch: 340; loss: 1.72; acc: 0.34
Batch: 360; loss: 1.94; acc: 0.27
Batch: 380; loss: 1.78; acc: 0.39
Batch: 400; loss: 1.63; acc: 0.48
Batch: 420; loss: 1.79; acc: 0.31
Batch: 440; loss: 1.85; acc: 0.42
Batch: 460; loss: 1.92; acc: 0.33
Batch: 480; loss: 1.64; acc: 0.42
Batch: 500; loss: 1.71; acc: 0.44
Batch: 520; loss: 1.7; acc: 0.41
Batch: 540; loss: 1.61; acc: 0.41
Batch: 560; loss: 1.74; acc: 0.31
Batch: 580; loss: 1.72; acc: 0.42
Batch: 600; loss: 1.79; acc: 0.33
Batch: 620; loss: 1.81; acc: 0.33
Batch: 640; loss: 1.71; acc: 0.44
Batch: 660; loss: 1.87; acc: 0.27
Batch: 680; loss: 1.83; acc: 0.27
Batch: 700; loss: 1.65; acc: 0.41
Batch: 720; loss: 1.82; acc: 0.36
Batch: 740; loss: 1.82; acc: 0.38
Batch: 760; loss: 1.69; acc: 0.39
Batch: 780; loss: 1.85; acc: 0.31
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.52; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.55
Batch: 80; loss: 1.67; acc: 0.36
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.77901708700095; val_accuracy: 0.36106687898089174 

The current subspace-distance is: 4.508579877438024e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.91; acc: 0.28
Batch: 20; loss: 1.87; acc: 0.28
Batch: 40; loss: 1.91; acc: 0.3
Batch: 60; loss: 1.78; acc: 0.34
Batch: 80; loss: 1.69; acc: 0.39
Batch: 100; loss: 1.55; acc: 0.48
Batch: 120; loss: 1.69; acc: 0.41
Batch: 140; loss: 1.86; acc: 0.33
Batch: 160; loss: 1.87; acc: 0.33
Batch: 180; loss: 1.88; acc: 0.28
Batch: 200; loss: 1.87; acc: 0.34
Batch: 220; loss: 1.86; acc: 0.34
Batch: 240; loss: 2.06; acc: 0.31
Batch: 260; loss: 1.8; acc: 0.27
Batch: 280; loss: 1.77; acc: 0.3
Batch: 300; loss: 1.76; acc: 0.36
Batch: 320; loss: 1.89; acc: 0.28
Batch: 340; loss: 2.0; acc: 0.28
Batch: 360; loss: 1.85; acc: 0.39
Batch: 380; loss: 1.79; acc: 0.39
Batch: 400; loss: 1.91; acc: 0.33
Batch: 420; loss: 1.69; acc: 0.36
Batch: 440; loss: 1.87; acc: 0.33
Batch: 460; loss: 1.88; acc: 0.36
Batch: 480; loss: 1.84; acc: 0.33
Batch: 500; loss: 1.74; acc: 0.39
Batch: 520; loss: 1.69; acc: 0.45
Batch: 540; loss: 1.88; acc: 0.34
Batch: 560; loss: 1.83; acc: 0.3
Batch: 580; loss: 1.82; acc: 0.34
Batch: 600; loss: 1.82; acc: 0.39
Batch: 620; loss: 2.03; acc: 0.31
Batch: 640; loss: 1.91; acc: 0.3
Batch: 660; loss: 1.92; acc: 0.23
Batch: 680; loss: 1.79; acc: 0.36
Batch: 700; loss: 1.78; acc: 0.34
Batch: 720; loss: 1.6; acc: 0.41
Batch: 740; loss: 1.81; acc: 0.34
Batch: 760; loss: 2.01; acc: 0.34
Batch: 780; loss: 1.84; acc: 0.36
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.68; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 2.0; acc: 0.36
Batch: 140; loss: 1.68; acc: 0.38
Val Epoch over. val_loss: 1.7805236198340253; val_accuracy: 0.36246019108280253 

The current subspace-distance is: 4.42781783931423e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.89; acc: 0.38
Batch: 20; loss: 1.55; acc: 0.47
Batch: 40; loss: 1.91; acc: 0.23
Batch: 60; loss: 1.77; acc: 0.28
Batch: 80; loss: 1.68; acc: 0.45
Batch: 100; loss: 1.88; acc: 0.25
Batch: 120; loss: 1.73; acc: 0.39
Batch: 140; loss: 1.92; acc: 0.2
Batch: 160; loss: 1.67; acc: 0.39
Batch: 180; loss: 1.98; acc: 0.33
Batch: 200; loss: 1.88; acc: 0.31
Batch: 220; loss: 1.78; acc: 0.31
Batch: 240; loss: 1.87; acc: 0.39
Batch: 260; loss: 1.75; acc: 0.39
Batch: 280; loss: 1.73; acc: 0.42
Batch: 300; loss: 2.04; acc: 0.3
Batch: 320; loss: 1.86; acc: 0.33
Batch: 340; loss: 1.81; acc: 0.34
Batch: 360; loss: 1.83; acc: 0.36
Batch: 380; loss: 1.73; acc: 0.45
Batch: 400; loss: 1.69; acc: 0.38
Batch: 420; loss: 1.65; acc: 0.41
Batch: 440; loss: 1.82; acc: 0.38
Batch: 460; loss: 1.81; acc: 0.41
Batch: 480; loss: 1.73; acc: 0.33
Batch: 500; loss: 1.77; acc: 0.39
Batch: 520; loss: 1.72; acc: 0.41
Batch: 540; loss: 1.84; acc: 0.38
Batch: 560; loss: 1.63; acc: 0.45
Batch: 580; loss: 1.95; acc: 0.34
Batch: 600; loss: 1.69; acc: 0.38
Batch: 620; loss: 1.85; acc: 0.36
Batch: 640; loss: 1.7; acc: 0.47
Batch: 660; loss: 1.65; acc: 0.47
Batch: 680; loss: 1.94; acc: 0.3
Batch: 700; loss: 1.78; acc: 0.38
Batch: 720; loss: 2.13; acc: 0.22
Batch: 740; loss: 1.64; acc: 0.39
Batch: 760; loss: 1.84; acc: 0.34
Batch: 780; loss: 1.85; acc: 0.28
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.28
Batch: 40; loss: 1.51; acc: 0.53
Batch: 60; loss: 1.55; acc: 0.56
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7794054184749628; val_accuracy: 0.3622611464968153 

The current subspace-distance is: 4.665162123274058e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.69; acc: 0.39
Batch: 20; loss: 1.77; acc: 0.41
Batch: 40; loss: 1.73; acc: 0.42
Batch: 60; loss: 1.93; acc: 0.33
Batch: 80; loss: 1.89; acc: 0.31
Batch: 100; loss: 1.71; acc: 0.39
Batch: 120; loss: 1.82; acc: 0.31
Batch: 140; loss: 1.89; acc: 0.31
Batch: 160; loss: 1.85; acc: 0.33
Batch: 180; loss: 1.93; acc: 0.3
Batch: 200; loss: 1.89; acc: 0.39
Batch: 220; loss: 1.64; acc: 0.44
Batch: 240; loss: 1.88; acc: 0.27
Batch: 260; loss: 1.7; acc: 0.36
Batch: 280; loss: 1.78; acc: 0.34
Batch: 300; loss: 1.78; acc: 0.38
Batch: 320; loss: 1.81; acc: 0.28
Batch: 340; loss: 1.82; acc: 0.27
Batch: 360; loss: 1.78; acc: 0.39
Batch: 380; loss: 1.86; acc: 0.36
Batch: 400; loss: 1.74; acc: 0.41
Batch: 420; loss: 1.81; acc: 0.31
Batch: 440; loss: 1.79; acc: 0.39
Batch: 460; loss: 1.77; acc: 0.42
Batch: 480; loss: 1.78; acc: 0.38
Batch: 500; loss: 1.62; acc: 0.42
Batch: 520; loss: 1.72; acc: 0.39
Batch: 540; loss: 1.93; acc: 0.34
Batch: 560; loss: 1.72; acc: 0.38
Batch: 580; loss: 1.76; acc: 0.31
Batch: 600; loss: 1.78; acc: 0.31
Batch: 620; loss: 1.81; acc: 0.36
Batch: 640; loss: 1.73; acc: 0.36
Batch: 660; loss: 1.86; acc: 0.33
Batch: 680; loss: 1.93; acc: 0.33
Batch: 700; loss: 1.8; acc: 0.36
Batch: 720; loss: 1.83; acc: 0.33
Batch: 740; loss: 1.88; acc: 0.33
Batch: 760; loss: 1.58; acc: 0.41
Batch: 780; loss: 1.82; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7786882371659491; val_accuracy: 0.36186305732484075 

The current subspace-distance is: 4.811333565157838e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.78; acc: 0.36
Batch: 20; loss: 1.7; acc: 0.41
Batch: 40; loss: 1.87; acc: 0.31
Batch: 60; loss: 1.91; acc: 0.34
Batch: 80; loss: 1.87; acc: 0.39
Batch: 100; loss: 1.82; acc: 0.39
Batch: 120; loss: 1.78; acc: 0.38
Batch: 140; loss: 1.8; acc: 0.36
Batch: 160; loss: 1.7; acc: 0.38
Batch: 180; loss: 1.8; acc: 0.34
Batch: 200; loss: 1.93; acc: 0.31
Batch: 220; loss: 1.69; acc: 0.41
Batch: 240; loss: 2.04; acc: 0.22
Batch: 260; loss: 1.79; acc: 0.38
Batch: 280; loss: 1.93; acc: 0.33
Batch: 300; loss: 1.74; acc: 0.36
Batch: 320; loss: 1.77; acc: 0.34
Batch: 340; loss: 1.77; acc: 0.36
Batch: 360; loss: 1.76; acc: 0.41
Batch: 380; loss: 2.16; acc: 0.28
Batch: 400; loss: 1.98; acc: 0.19
Batch: 420; loss: 1.83; acc: 0.38
Batch: 440; loss: 1.71; acc: 0.41
Batch: 460; loss: 1.74; acc: 0.36
Batch: 480; loss: 1.66; acc: 0.38
Batch: 500; loss: 1.76; acc: 0.33
Batch: 520; loss: 1.92; acc: 0.33
Batch: 540; loss: 1.96; acc: 0.28
Batch: 560; loss: 1.73; acc: 0.44
Batch: 580; loss: 1.74; acc: 0.38
Batch: 600; loss: 1.82; acc: 0.31
Batch: 620; loss: 1.7; acc: 0.48
Batch: 640; loss: 1.69; acc: 0.41
Batch: 660; loss: 1.66; acc: 0.36
Batch: 680; loss: 1.98; acc: 0.34
Batch: 700; loss: 1.9; acc: 0.23
Batch: 720; loss: 2.16; acc: 0.3
Batch: 740; loss: 1.85; acc: 0.28
Batch: 760; loss: 1.83; acc: 0.3
Batch: 780; loss: 1.7; acc: 0.44
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.36
Batch: 20; loss: 2.01; acc: 0.25
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.68; acc: 0.38
Val Epoch over. val_loss: 1.7789640305148569; val_accuracy: 0.3619625796178344 

The current subspace-distance is: 4.7088244173210114e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.79; acc: 0.39
Batch: 20; loss: 1.86; acc: 0.36
Batch: 40; loss: 1.92; acc: 0.31
Batch: 60; loss: 1.78; acc: 0.42
Batch: 80; loss: 1.86; acc: 0.27
Batch: 100; loss: 1.76; acc: 0.39
Batch: 120; loss: 1.86; acc: 0.33
Batch: 140; loss: 1.74; acc: 0.44
Batch: 160; loss: 1.76; acc: 0.41
Batch: 180; loss: 1.76; acc: 0.36
Batch: 200; loss: 1.83; acc: 0.36
Batch: 220; loss: 1.78; acc: 0.3
Batch: 240; loss: 1.68; acc: 0.42
Batch: 260; loss: 1.87; acc: 0.33
Batch: 280; loss: 1.74; acc: 0.38
Batch: 300; loss: 1.7; acc: 0.33
Batch: 320; loss: 1.7; acc: 0.39
Batch: 340; loss: 1.81; acc: 0.39
Batch: 360; loss: 1.84; acc: 0.23
Batch: 380; loss: 1.91; acc: 0.23
Batch: 400; loss: 1.84; acc: 0.36
Batch: 420; loss: 1.73; acc: 0.38
Batch: 440; loss: 1.8; acc: 0.44
Batch: 460; loss: 1.72; acc: 0.41
Batch: 480; loss: 1.77; acc: 0.42
Batch: 500; loss: 1.84; acc: 0.38
Batch: 520; loss: 1.81; acc: 0.33
Batch: 540; loss: 1.79; acc: 0.25
Batch: 560; loss: 1.78; acc: 0.34
Batch: 580; loss: 1.77; acc: 0.36
Batch: 600; loss: 1.56; acc: 0.45
Batch: 620; loss: 1.7; acc: 0.41
Batch: 640; loss: 1.77; acc: 0.38
Batch: 660; loss: 1.99; acc: 0.34
Batch: 680; loss: 1.62; acc: 0.42
Batch: 700; loss: 1.84; acc: 0.39
Batch: 720; loss: 1.86; acc: 0.28
Batch: 740; loss: 1.86; acc: 0.31
Batch: 760; loss: 1.82; acc: 0.33
Batch: 780; loss: 1.76; acc: 0.36
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.28
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.55
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7788332070514654; val_accuracy: 0.3629578025477707 

The current subspace-distance is: 4.714141323347576e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.78; acc: 0.25
Batch: 20; loss: 1.82; acc: 0.39
Batch: 40; loss: 1.86; acc: 0.33
Batch: 60; loss: 1.7; acc: 0.42
Batch: 80; loss: 1.73; acc: 0.42
Batch: 100; loss: 1.74; acc: 0.39
Batch: 120; loss: 1.72; acc: 0.34
Batch: 140; loss: 1.85; acc: 0.3
Batch: 160; loss: 1.86; acc: 0.31
Batch: 180; loss: 1.81; acc: 0.38
Batch: 200; loss: 1.91; acc: 0.36
Batch: 220; loss: 1.98; acc: 0.33
Batch: 240; loss: 1.91; acc: 0.3
Batch: 260; loss: 1.91; acc: 0.38
Batch: 280; loss: 1.82; acc: 0.34
Batch: 300; loss: 1.82; acc: 0.33
Batch: 320; loss: 1.84; acc: 0.28
Batch: 340; loss: 1.67; acc: 0.36
Batch: 360; loss: 1.92; acc: 0.3
Batch: 380; loss: 1.87; acc: 0.34
Batch: 400; loss: 2.08; acc: 0.2
Batch: 420; loss: 1.87; acc: 0.31
Batch: 440; loss: 1.67; acc: 0.39
Batch: 460; loss: 2.04; acc: 0.28
Batch: 480; loss: 1.73; acc: 0.41
Batch: 500; loss: 1.9; acc: 0.36
Batch: 520; loss: 1.75; acc: 0.33
Batch: 540; loss: 1.73; acc: 0.38
Batch: 560; loss: 1.74; acc: 0.39
Batch: 580; loss: 1.96; acc: 0.31
Batch: 600; loss: 1.85; acc: 0.31
Batch: 620; loss: 1.66; acc: 0.42
Batch: 640; loss: 1.83; acc: 0.39
Batch: 660; loss: 1.78; acc: 0.38
Batch: 680; loss: 1.77; acc: 0.39
Batch: 700; loss: 1.88; acc: 0.28
Batch: 720; loss: 1.97; acc: 0.25
Batch: 740; loss: 1.62; acc: 0.47
Batch: 760; loss: 1.86; acc: 0.3
Batch: 780; loss: 1.64; acc: 0.42
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.28
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.55
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.66; acc: 0.38
Val Epoch over. val_loss: 1.778936004183095; val_accuracy: 0.3625597133757962 

The current subspace-distance is: 4.798215377377346e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.87; acc: 0.31
Batch: 20; loss: 1.82; acc: 0.34
Batch: 40; loss: 1.79; acc: 0.31
Batch: 60; loss: 1.78; acc: 0.42
Batch: 80; loss: 1.82; acc: 0.39
Batch: 100; loss: 1.71; acc: 0.39
Batch: 120; loss: 1.74; acc: 0.36
Batch: 140; loss: 1.73; acc: 0.42
Batch: 160; loss: 1.84; acc: 0.33
Batch: 180; loss: 1.67; acc: 0.41
Batch: 200; loss: 1.88; acc: 0.31
Batch: 220; loss: 1.91; acc: 0.34
Batch: 240; loss: 1.78; acc: 0.39
Batch: 260; loss: 1.81; acc: 0.38
Batch: 280; loss: 1.78; acc: 0.36
Batch: 300; loss: 1.72; acc: 0.42
Batch: 320; loss: 2.03; acc: 0.31
Batch: 340; loss: 1.8; acc: 0.39
Batch: 360; loss: 1.69; acc: 0.39
Batch: 380; loss: 1.78; acc: 0.36
Batch: 400; loss: 1.76; acc: 0.45
Batch: 420; loss: 1.86; acc: 0.33
Batch: 440; loss: 1.72; acc: 0.42
Batch: 460; loss: 2.06; acc: 0.27
Batch: 480; loss: 1.76; acc: 0.41
Batch: 500; loss: 1.81; acc: 0.3
Batch: 520; loss: 1.87; acc: 0.23
Batch: 540; loss: 1.88; acc: 0.31
Batch: 560; loss: 2.02; acc: 0.23
Batch: 580; loss: 1.88; acc: 0.28
Batch: 600; loss: 1.87; acc: 0.31
Batch: 620; loss: 1.82; acc: 0.31
Batch: 640; loss: 1.63; acc: 0.44
Batch: 660; loss: 1.82; acc: 0.38
Batch: 680; loss: 1.73; acc: 0.33
Batch: 700; loss: 1.65; acc: 0.47
Batch: 720; loss: 1.81; acc: 0.34
Batch: 740; loss: 1.83; acc: 0.39
Batch: 760; loss: 1.77; acc: 0.38
Batch: 780; loss: 1.89; acc: 0.31
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 2.02; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.53
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7788759492764807; val_accuracy: 0.3629578025477707 

The current subspace-distance is: 4.852148413192481e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.85; acc: 0.38
Batch: 20; loss: 2.03; acc: 0.19
Batch: 40; loss: 1.64; acc: 0.45
Batch: 60; loss: 1.76; acc: 0.39
Batch: 80; loss: 2.02; acc: 0.31
Batch: 100; loss: 1.58; acc: 0.42
Batch: 120; loss: 1.88; acc: 0.25
Batch: 140; loss: 1.74; acc: 0.41
Batch: 160; loss: 1.93; acc: 0.31
Batch: 180; loss: 1.96; acc: 0.36
Batch: 200; loss: 1.79; acc: 0.36
Batch: 220; loss: 1.82; acc: 0.36
Batch: 240; loss: 1.8; acc: 0.33
Batch: 260; loss: 1.64; acc: 0.45
Batch: 280; loss: 1.83; acc: 0.33
Batch: 300; loss: 1.75; acc: 0.44
Batch: 320; loss: 1.68; acc: 0.41
Batch: 340; loss: 1.85; acc: 0.33
Batch: 360; loss: 1.7; acc: 0.39
Batch: 380; loss: 1.72; acc: 0.44
Batch: 400; loss: 1.72; acc: 0.34
Batch: 420; loss: 1.93; acc: 0.25
Batch: 440; loss: 1.77; acc: 0.33
Batch: 460; loss: 1.77; acc: 0.42
Batch: 480; loss: 1.8; acc: 0.36
Batch: 500; loss: 1.86; acc: 0.28
Batch: 520; loss: 1.61; acc: 0.42
Batch: 540; loss: 1.77; acc: 0.34
Batch: 560; loss: 1.98; acc: 0.33
Batch: 580; loss: 1.95; acc: 0.3
Batch: 600; loss: 1.84; acc: 0.36
Batch: 620; loss: 1.97; acc: 0.31
Batch: 640; loss: 1.88; acc: 0.33
Batch: 660; loss: 1.71; acc: 0.42
Batch: 680; loss: 1.91; acc: 0.34
Batch: 700; loss: 1.88; acc: 0.31
Batch: 720; loss: 1.84; acc: 0.31
Batch: 740; loss: 1.61; acc: 0.34
Batch: 760; loss: 1.94; acc: 0.38
Batch: 780; loss: 1.74; acc: 0.39
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 2.02; acc: 0.28
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.66; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.66; acc: 0.38
Val Epoch over. val_loss: 1.778225911650688; val_accuracy: 0.3640525477707006 

The current subspace-distance is: 4.585046190186404e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.03; acc: 0.27
Batch: 20; loss: 1.86; acc: 0.33
Batch: 40; loss: 1.67; acc: 0.41
Batch: 60; loss: 1.83; acc: 0.38
Batch: 80; loss: 1.84; acc: 0.25
Batch: 100; loss: 1.83; acc: 0.36
Batch: 120; loss: 1.88; acc: 0.31
Batch: 140; loss: 1.76; acc: 0.36
Batch: 160; loss: 1.75; acc: 0.39
Batch: 180; loss: 1.93; acc: 0.27
Batch: 200; loss: 1.75; acc: 0.38
Batch: 220; loss: 1.7; acc: 0.45
Batch: 240; loss: 1.88; acc: 0.31
Batch: 260; loss: 1.79; acc: 0.42
Batch: 280; loss: 1.77; acc: 0.31
Batch: 300; loss: 1.76; acc: 0.38
Batch: 320; loss: 1.81; acc: 0.41
Batch: 340; loss: 1.85; acc: 0.38
Batch: 360; loss: 1.77; acc: 0.38
Batch: 380; loss: 1.91; acc: 0.27
Batch: 400; loss: 1.85; acc: 0.34
Batch: 420; loss: 1.84; acc: 0.27
Batch: 440; loss: 1.74; acc: 0.42
Batch: 460; loss: 1.91; acc: 0.33
Batch: 480; loss: 1.71; acc: 0.38
Batch: 500; loss: 1.77; acc: 0.39
Batch: 520; loss: 1.71; acc: 0.41
Batch: 540; loss: 1.87; acc: 0.28
Batch: 560; loss: 2.0; acc: 0.27
Batch: 580; loss: 1.62; acc: 0.45
Batch: 600; loss: 1.71; acc: 0.39
Batch: 620; loss: 1.71; acc: 0.44
Batch: 640; loss: 1.83; acc: 0.3
Batch: 660; loss: 1.84; acc: 0.33
Batch: 680; loss: 1.83; acc: 0.36
Batch: 700; loss: 1.7; acc: 0.44
Batch: 720; loss: 1.61; acc: 0.41
Batch: 740; loss: 1.72; acc: 0.42
Batch: 760; loss: 1.91; acc: 0.23
Batch: 780; loss: 1.66; acc: 0.36
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.36
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7787867693384742; val_accuracy: 0.36285828025477707 

The current subspace-distance is: 4.80315247841645e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.79; acc: 0.41
Batch: 20; loss: 1.68; acc: 0.42
Batch: 40; loss: 1.93; acc: 0.25
Batch: 60; loss: 1.92; acc: 0.34
Batch: 80; loss: 1.7; acc: 0.44
Batch: 100; loss: 1.81; acc: 0.41
Batch: 120; loss: 1.88; acc: 0.34
Batch: 140; loss: 1.64; acc: 0.41
Batch: 160; loss: 1.7; acc: 0.41
Batch: 180; loss: 1.79; acc: 0.38
Batch: 200; loss: 1.77; acc: 0.33
Batch: 220; loss: 1.8; acc: 0.36
Batch: 240; loss: 1.57; acc: 0.48
Batch: 260; loss: 2.03; acc: 0.23
Batch: 280; loss: 1.85; acc: 0.38
Batch: 300; loss: 1.85; acc: 0.31
Batch: 320; loss: 1.78; acc: 0.31
Batch: 340; loss: 1.77; acc: 0.41
Batch: 360; loss: 1.87; acc: 0.31
Batch: 380; loss: 1.88; acc: 0.31
Batch: 400; loss: 1.8; acc: 0.36
Batch: 420; loss: 2.07; acc: 0.28
Batch: 440; loss: 1.76; acc: 0.31
Batch: 460; loss: 1.74; acc: 0.36
Batch: 480; loss: 1.9; acc: 0.34
Batch: 500; loss: 1.75; acc: 0.42
Batch: 520; loss: 1.89; acc: 0.33
Batch: 540; loss: 1.67; acc: 0.42
Batch: 560; loss: 1.69; acc: 0.44
Batch: 580; loss: 1.79; acc: 0.33
Batch: 600; loss: 1.87; acc: 0.23
Batch: 620; loss: 1.82; acc: 0.31
Batch: 640; loss: 1.82; acc: 0.36
Batch: 660; loss: 1.81; acc: 0.39
Batch: 680; loss: 1.64; acc: 0.39
Batch: 700; loss: 1.84; acc: 0.34
Batch: 720; loss: 1.81; acc: 0.36
Batch: 740; loss: 1.73; acc: 0.45
Batch: 760; loss: 1.63; acc: 0.41
Batch: 780; loss: 1.76; acc: 0.33
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7784235067428298; val_accuracy: 0.36285828025477707 

The current subspace-distance is: 5.064591459813528e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.77; acc: 0.39
Batch: 20; loss: 1.69; acc: 0.34
Batch: 40; loss: 1.78; acc: 0.33
Batch: 60; loss: 1.75; acc: 0.41
Batch: 80; loss: 2.04; acc: 0.3
Batch: 100; loss: 1.77; acc: 0.44
Batch: 120; loss: 1.74; acc: 0.42
Batch: 140; loss: 1.83; acc: 0.41
Batch: 160; loss: 1.83; acc: 0.39
Batch: 180; loss: 1.77; acc: 0.42
Batch: 200; loss: 1.77; acc: 0.34
Batch: 220; loss: 1.83; acc: 0.31
Batch: 240; loss: 1.88; acc: 0.33
Batch: 260; loss: 1.82; acc: 0.36
Batch: 280; loss: 1.62; acc: 0.39
Batch: 300; loss: 1.8; acc: 0.36
Batch: 320; loss: 1.66; acc: 0.39
Batch: 340; loss: 1.75; acc: 0.39
Batch: 360; loss: 1.57; acc: 0.47
Batch: 380; loss: 2.08; acc: 0.3
Batch: 400; loss: 1.74; acc: 0.39
Batch: 420; loss: 1.76; acc: 0.34
Batch: 440; loss: 1.75; acc: 0.47
Batch: 460; loss: 1.79; acc: 0.31
Batch: 480; loss: 1.65; acc: 0.45
Batch: 500; loss: 1.75; acc: 0.44
Batch: 520; loss: 1.81; acc: 0.36
Batch: 540; loss: 1.67; acc: 0.45
Batch: 560; loss: 1.88; acc: 0.28
Batch: 580; loss: 1.95; acc: 0.34
Batch: 600; loss: 1.72; acc: 0.36
Batch: 620; loss: 1.99; acc: 0.23
Batch: 640; loss: 1.71; acc: 0.39
Batch: 660; loss: 1.93; acc: 0.28
Batch: 680; loss: 1.9; acc: 0.31
Batch: 700; loss: 1.99; acc: 0.23
Batch: 720; loss: 1.75; acc: 0.42
Batch: 740; loss: 1.59; acc: 0.41
Batch: 760; loss: 1.81; acc: 0.28
Batch: 780; loss: 1.84; acc: 0.31
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.96; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.66; acc: 0.38
Val Epoch over. val_loss: 1.7783353450192008; val_accuracy: 0.36285828025477707 

The current subspace-distance is: 5.360350041883066e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.83; acc: 0.41
Batch: 20; loss: 1.8; acc: 0.3
Batch: 40; loss: 2.01; acc: 0.3
Batch: 60; loss: 2.01; acc: 0.3
Batch: 80; loss: 1.82; acc: 0.36
Batch: 100; loss: 1.89; acc: 0.3
Batch: 120; loss: 1.6; acc: 0.42
Batch: 140; loss: 1.95; acc: 0.36
Batch: 160; loss: 1.73; acc: 0.42
Batch: 180; loss: 1.62; acc: 0.44
Batch: 200; loss: 1.87; acc: 0.27
Batch: 220; loss: 1.91; acc: 0.27
Batch: 240; loss: 1.59; acc: 0.41
Batch: 260; loss: 1.79; acc: 0.42
Batch: 280; loss: 1.65; acc: 0.5
Batch: 300; loss: 1.58; acc: 0.5
Batch: 320; loss: 1.63; acc: 0.47
Batch: 340; loss: 1.99; acc: 0.28
Batch: 360; loss: 1.7; acc: 0.44
Batch: 380; loss: 1.92; acc: 0.27
Batch: 400; loss: 1.87; acc: 0.36
Batch: 420; loss: 1.66; acc: 0.34
Batch: 440; loss: 1.98; acc: 0.33
Batch: 460; loss: 1.9; acc: 0.3
Batch: 480; loss: 1.53; acc: 0.52
Batch: 500; loss: 1.84; acc: 0.31
Batch: 520; loss: 1.91; acc: 0.28
Batch: 540; loss: 1.77; acc: 0.47
Batch: 560; loss: 1.86; acc: 0.34
Batch: 580; loss: 1.61; acc: 0.47
Batch: 600; loss: 1.93; acc: 0.33
Batch: 620; loss: 1.8; acc: 0.36
Batch: 640; loss: 1.63; acc: 0.45
Batch: 660; loss: 1.75; acc: 0.33
Batch: 680; loss: 1.61; acc: 0.48
Batch: 700; loss: 1.67; acc: 0.38
Batch: 720; loss: 2.0; acc: 0.3
Batch: 740; loss: 1.75; acc: 0.36
Batch: 760; loss: 1.69; acc: 0.42
Batch: 780; loss: 1.79; acc: 0.39
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.778502803699226; val_accuracy: 0.3614649681528662 

The current subspace-distance is: 5.6223248975584283e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.86; acc: 0.3
Batch: 20; loss: 1.89; acc: 0.28
Batch: 40; loss: 1.53; acc: 0.48
Batch: 60; loss: 1.94; acc: 0.36
Batch: 80; loss: 2.01; acc: 0.23
Batch: 100; loss: 1.91; acc: 0.36
Batch: 120; loss: 1.79; acc: 0.36
Batch: 140; loss: 1.71; acc: 0.41
Batch: 160; loss: 2.0; acc: 0.25
Batch: 180; loss: 1.71; acc: 0.39
Batch: 200; loss: 2.02; acc: 0.33
Batch: 220; loss: 1.99; acc: 0.3
Batch: 240; loss: 1.8; acc: 0.33
Batch: 260; loss: 1.68; acc: 0.42
Batch: 280; loss: 1.81; acc: 0.36
Batch: 300; loss: 1.79; acc: 0.39
Batch: 320; loss: 1.77; acc: 0.38
Batch: 340; loss: 1.82; acc: 0.31
Batch: 360; loss: 1.82; acc: 0.36
Batch: 380; loss: 1.99; acc: 0.3
Batch: 400; loss: 1.55; acc: 0.42
Batch: 420; loss: 1.78; acc: 0.3
Batch: 440; loss: 1.94; acc: 0.31
Batch: 460; loss: 1.73; acc: 0.42
Batch: 480; loss: 2.02; acc: 0.31
Batch: 500; loss: 1.85; acc: 0.38
Batch: 520; loss: 1.73; acc: 0.36
Batch: 540; loss: 1.84; acc: 0.39
Batch: 560; loss: 1.85; acc: 0.36
Batch: 580; loss: 1.74; acc: 0.41
Batch: 600; loss: 1.68; acc: 0.38
Batch: 620; loss: 1.73; acc: 0.48
Batch: 640; loss: 1.7; acc: 0.39
Batch: 660; loss: 1.78; acc: 0.42
Batch: 680; loss: 1.9; acc: 0.31
Batch: 700; loss: 1.73; acc: 0.38
Batch: 720; loss: 1.9; acc: 0.31
Batch: 740; loss: 1.82; acc: 0.42
Batch: 760; loss: 1.63; acc: 0.45
Batch: 780; loss: 1.77; acc: 0.34
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.36
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.36
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7789748557813607; val_accuracy: 0.36285828025477707 

The current subspace-distance is: 5.627113569062203e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.58; acc: 0.52
Batch: 20; loss: 2.05; acc: 0.2
Batch: 40; loss: 1.84; acc: 0.27
Batch: 60; loss: 2.05; acc: 0.3
Batch: 80; loss: 1.82; acc: 0.38
Batch: 100; loss: 1.9; acc: 0.36
Batch: 120; loss: 2.0; acc: 0.22
Batch: 140; loss: 1.74; acc: 0.33
Batch: 160; loss: 1.77; acc: 0.3
Batch: 180; loss: 1.91; acc: 0.33
Batch: 200; loss: 1.7; acc: 0.36
Batch: 220; loss: 1.95; acc: 0.28
Batch: 240; loss: 1.75; acc: 0.31
Batch: 260; loss: 1.78; acc: 0.41
Batch: 280; loss: 1.7; acc: 0.39
Batch: 300; loss: 1.67; acc: 0.47
Batch: 320; loss: 1.76; acc: 0.42
Batch: 340; loss: 1.88; acc: 0.28
Batch: 360; loss: 1.75; acc: 0.36
Batch: 380; loss: 1.56; acc: 0.47
Batch: 400; loss: 1.95; acc: 0.3
Batch: 420; loss: 1.64; acc: 0.45
Batch: 440; loss: 1.76; acc: 0.36
Batch: 460; loss: 1.69; acc: 0.44
Batch: 480; loss: 1.78; acc: 0.41
Batch: 500; loss: 1.79; acc: 0.42
Batch: 520; loss: 1.73; acc: 0.42
Batch: 540; loss: 2.04; acc: 0.27
Batch: 560; loss: 1.78; acc: 0.38
Batch: 580; loss: 1.6; acc: 0.5
Batch: 600; loss: 1.72; acc: 0.44
Batch: 620; loss: 1.81; acc: 0.39
Batch: 640; loss: 1.9; acc: 0.34
Batch: 660; loss: 1.91; acc: 0.33
Batch: 680; loss: 1.94; acc: 0.22
Batch: 700; loss: 1.91; acc: 0.31
Batch: 720; loss: 1.94; acc: 0.33
Batch: 740; loss: 1.67; acc: 0.41
Batch: 760; loss: 1.63; acc: 0.48
Batch: 780; loss: 1.85; acc: 0.31
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.77858267468252; val_accuracy: 0.36236066878980894 

The current subspace-distance is: 5.9231064369669184e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.81; acc: 0.34
Batch: 20; loss: 1.87; acc: 0.27
Batch: 40; loss: 1.78; acc: 0.34
Batch: 60; loss: 1.8; acc: 0.34
Batch: 80; loss: 1.7; acc: 0.33
Batch: 100; loss: 1.83; acc: 0.34
Batch: 120; loss: 1.97; acc: 0.33
Batch: 140; loss: 1.91; acc: 0.27
Batch: 160; loss: 1.89; acc: 0.33
Batch: 180; loss: 1.84; acc: 0.28
Batch: 200; loss: 1.76; acc: 0.34
Batch: 220; loss: 1.8; acc: 0.44
Batch: 240; loss: 1.65; acc: 0.48
Batch: 260; loss: 1.95; acc: 0.3
Batch: 280; loss: 1.87; acc: 0.34
Batch: 300; loss: 1.81; acc: 0.38
Batch: 320; loss: 1.65; acc: 0.42
Batch: 340; loss: 1.93; acc: 0.36
Batch: 360; loss: 1.66; acc: 0.39
Batch: 380; loss: 1.91; acc: 0.34
Batch: 400; loss: 1.73; acc: 0.39
Batch: 420; loss: 1.86; acc: 0.33
Batch: 440; loss: 1.83; acc: 0.34
Batch: 460; loss: 1.96; acc: 0.33
Batch: 480; loss: 1.72; acc: 0.38
Batch: 500; loss: 1.86; acc: 0.33
Batch: 520; loss: 1.89; acc: 0.28
Batch: 540; loss: 1.77; acc: 0.39
Batch: 560; loss: 1.92; acc: 0.25
Batch: 580; loss: 1.96; acc: 0.31
Batch: 600; loss: 1.79; acc: 0.41
Batch: 620; loss: 1.73; acc: 0.36
Batch: 640; loss: 1.86; acc: 0.36
Batch: 660; loss: 1.83; acc: 0.34
Batch: 680; loss: 1.79; acc: 0.41
Batch: 700; loss: 2.05; acc: 0.33
Batch: 720; loss: 1.76; acc: 0.38
Batch: 740; loss: 1.73; acc: 0.38
Batch: 760; loss: 1.82; acc: 0.44
Batch: 780; loss: 1.72; acc: 0.39
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.778613950796188; val_accuracy: 0.3632563694267516 

The current subspace-distance is: 5.818208956043236e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.85; acc: 0.33
Batch: 20; loss: 1.59; acc: 0.41
Batch: 40; loss: 1.58; acc: 0.44
Batch: 60; loss: 1.76; acc: 0.33
Batch: 80; loss: 1.63; acc: 0.42
Batch: 100; loss: 1.83; acc: 0.3
Batch: 120; loss: 1.8; acc: 0.41
Batch: 140; loss: 1.8; acc: 0.31
Batch: 160; loss: 1.74; acc: 0.42
Batch: 180; loss: 1.65; acc: 0.36
Batch: 200; loss: 1.76; acc: 0.34
Batch: 220; loss: 1.82; acc: 0.34
Batch: 240; loss: 1.65; acc: 0.47
Batch: 260; loss: 1.86; acc: 0.39
Batch: 280; loss: 1.78; acc: 0.39
Batch: 300; loss: 1.83; acc: 0.41
Batch: 320; loss: 1.71; acc: 0.45
Batch: 340; loss: 1.82; acc: 0.25
Batch: 360; loss: 1.78; acc: 0.3
Batch: 380; loss: 1.58; acc: 0.44
Batch: 400; loss: 1.77; acc: 0.33
Batch: 420; loss: 1.75; acc: 0.42
Batch: 440; loss: 1.7; acc: 0.38
Batch: 460; loss: 2.02; acc: 0.31
Batch: 480; loss: 1.73; acc: 0.38
Batch: 500; loss: 1.83; acc: 0.34
Batch: 520; loss: 1.99; acc: 0.28
Batch: 540; loss: 1.81; acc: 0.36
Batch: 560; loss: 1.74; acc: 0.41
Batch: 580; loss: 1.84; acc: 0.36
Batch: 600; loss: 1.71; acc: 0.45
Batch: 620; loss: 2.0; acc: 0.3
Batch: 640; loss: 1.52; acc: 0.52
Batch: 660; loss: 1.9; acc: 0.28
Batch: 680; loss: 1.76; acc: 0.39
Batch: 700; loss: 1.67; acc: 0.45
Batch: 720; loss: 1.72; acc: 0.34
Batch: 740; loss: 1.96; acc: 0.27
Batch: 760; loss: 1.88; acc: 0.36
Batch: 780; loss: 1.76; acc: 0.41
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.75; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7787879037249619; val_accuracy: 0.36335589171974525 

The current subspace-distance is: 6.255377229535952e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.87; acc: 0.31
Batch: 20; loss: 1.84; acc: 0.25
Batch: 40; loss: 1.7; acc: 0.45
Batch: 60; loss: 1.88; acc: 0.42
Batch: 80; loss: 1.69; acc: 0.39
Batch: 100; loss: 1.9; acc: 0.31
Batch: 120; loss: 1.76; acc: 0.41
Batch: 140; loss: 1.7; acc: 0.47
Batch: 160; loss: 1.82; acc: 0.33
Batch: 180; loss: 1.8; acc: 0.38
Batch: 200; loss: 1.77; acc: 0.36
Batch: 220; loss: 1.84; acc: 0.36
Batch: 240; loss: 1.8; acc: 0.34
Batch: 260; loss: 1.66; acc: 0.39
Batch: 280; loss: 1.81; acc: 0.38
Batch: 300; loss: 1.78; acc: 0.44
Batch: 320; loss: 1.96; acc: 0.22
Batch: 340; loss: 1.89; acc: 0.34
Batch: 360; loss: 1.67; acc: 0.41
Batch: 380; loss: 1.76; acc: 0.38
Batch: 400; loss: 1.75; acc: 0.34
Batch: 420; loss: 1.8; acc: 0.36
Batch: 440; loss: 1.88; acc: 0.34
Batch: 460; loss: 1.82; acc: 0.39
Batch: 480; loss: 1.84; acc: 0.31
Batch: 500; loss: 1.86; acc: 0.34
Batch: 520; loss: 1.73; acc: 0.36
Batch: 540; loss: 1.9; acc: 0.3
Batch: 560; loss: 1.85; acc: 0.34
Batch: 580; loss: 1.94; acc: 0.28
Batch: 600; loss: 1.78; acc: 0.41
Batch: 620; loss: 1.75; acc: 0.42
Batch: 640; loss: 2.06; acc: 0.2
Batch: 660; loss: 1.72; acc: 0.33
Batch: 680; loss: 1.76; acc: 0.3
Batch: 700; loss: 1.7; acc: 0.38
Batch: 720; loss: 1.65; acc: 0.5
Batch: 740; loss: 1.78; acc: 0.34
Batch: 760; loss: 1.95; acc: 0.31
Batch: 780; loss: 1.67; acc: 0.41
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.33
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.778803435860166; val_accuracy: 0.3625597133757962 

The current subspace-distance is: 6.670750735793263e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.78; acc: 0.41
Batch: 20; loss: 1.64; acc: 0.47
Batch: 40; loss: 1.68; acc: 0.44
Batch: 60; loss: 1.85; acc: 0.41
Batch: 80; loss: 1.9; acc: 0.34
Batch: 100; loss: 1.89; acc: 0.36
Batch: 120; loss: 1.8; acc: 0.33
Batch: 140; loss: 1.7; acc: 0.41
Batch: 160; loss: 1.8; acc: 0.42
Batch: 180; loss: 1.91; acc: 0.36
Batch: 200; loss: 1.62; acc: 0.39
Batch: 220; loss: 1.87; acc: 0.3
Batch: 240; loss: 1.74; acc: 0.42
Batch: 260; loss: 1.55; acc: 0.48
Batch: 280; loss: 1.59; acc: 0.42
Batch: 300; loss: 1.86; acc: 0.38
Batch: 320; loss: 1.83; acc: 0.34
Batch: 340; loss: 2.02; acc: 0.28
Batch: 360; loss: 1.87; acc: 0.33
Batch: 380; loss: 1.82; acc: 0.38
Batch: 400; loss: 1.8; acc: 0.34
Batch: 420; loss: 2.0; acc: 0.27
Batch: 440; loss: 1.91; acc: 0.27
Batch: 460; loss: 1.75; acc: 0.42
Batch: 480; loss: 1.87; acc: 0.33
Batch: 500; loss: 1.73; acc: 0.33
Batch: 520; loss: 1.57; acc: 0.52
Batch: 540; loss: 1.62; acc: 0.39
Batch: 560; loss: 1.9; acc: 0.28
Batch: 580; loss: 1.6; acc: 0.5
Batch: 600; loss: 1.77; acc: 0.36
Batch: 620; loss: 1.79; acc: 0.34
Batch: 640; loss: 1.69; acc: 0.39
Batch: 660; loss: 1.69; acc: 0.52
Batch: 680; loss: 1.63; acc: 0.39
Batch: 700; loss: 1.8; acc: 0.33
Batch: 720; loss: 1.64; acc: 0.48
Batch: 740; loss: 1.63; acc: 0.44
Batch: 760; loss: 1.66; acc: 0.44
Batch: 780; loss: 1.98; acc: 0.27
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.52; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.68; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7791498694450232; val_accuracy: 0.3638535031847134 

The current subspace-distance is: 7.31807595002465e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.98; acc: 0.36
Batch: 20; loss: 1.94; acc: 0.3
Batch: 40; loss: 1.67; acc: 0.48
Batch: 60; loss: 1.74; acc: 0.33
Batch: 80; loss: 1.86; acc: 0.3
Batch: 100; loss: 1.76; acc: 0.34
Batch: 120; loss: 1.63; acc: 0.39
Batch: 140; loss: 1.63; acc: 0.36
Batch: 160; loss: 1.92; acc: 0.3
Batch: 180; loss: 1.77; acc: 0.34
Batch: 200; loss: 1.79; acc: 0.36
Batch: 220; loss: 1.7; acc: 0.33
Batch: 240; loss: 1.88; acc: 0.33
Batch: 260; loss: 1.83; acc: 0.3
Batch: 280; loss: 1.85; acc: 0.31
Batch: 300; loss: 1.8; acc: 0.44
Batch: 320; loss: 1.85; acc: 0.3
Batch: 340; loss: 1.81; acc: 0.33
Batch: 360; loss: 1.79; acc: 0.33
Batch: 380; loss: 1.68; acc: 0.41
Batch: 400; loss: 2.04; acc: 0.3
Batch: 420; loss: 1.97; acc: 0.28
Batch: 440; loss: 1.95; acc: 0.39
Batch: 460; loss: 1.77; acc: 0.41
Batch: 480; loss: 1.58; acc: 0.36
Batch: 500; loss: 1.68; acc: 0.38
Batch: 520; loss: 1.64; acc: 0.48
Batch: 540; loss: 1.82; acc: 0.42
Batch: 560; loss: 1.79; acc: 0.38
Batch: 580; loss: 1.89; acc: 0.31
Batch: 600; loss: 1.71; acc: 0.42
Batch: 620; loss: 1.7; acc: 0.44
Batch: 640; loss: 1.62; acc: 0.42
Batch: 660; loss: 1.8; acc: 0.38
Batch: 680; loss: 1.85; acc: 0.31
Batch: 700; loss: 1.74; acc: 0.41
Batch: 720; loss: 1.63; acc: 0.44
Batch: 740; loss: 1.97; acc: 0.33
Batch: 760; loss: 2.01; acc: 0.34
Batch: 780; loss: 1.8; acc: 0.31
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7787366718243642; val_accuracy: 0.3629578025477707 

The current subspace-distance is: 7.328855281230062e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.68; acc: 0.39
Batch: 20; loss: 1.88; acc: 0.28
Batch: 40; loss: 2.0; acc: 0.28
Batch: 60; loss: 1.8; acc: 0.34
Batch: 80; loss: 2.06; acc: 0.28
Batch: 100; loss: 1.65; acc: 0.41
Batch: 120; loss: 1.81; acc: 0.33
Batch: 140; loss: 1.8; acc: 0.31
Batch: 160; loss: 1.9; acc: 0.31
Batch: 180; loss: 1.54; acc: 0.47
Batch: 200; loss: 1.83; acc: 0.41
Batch: 220; loss: 1.95; acc: 0.27
Batch: 240; loss: 1.95; acc: 0.31
Batch: 260; loss: 1.7; acc: 0.38
Batch: 280; loss: 1.89; acc: 0.34
Batch: 300; loss: 1.73; acc: 0.31
Batch: 320; loss: 1.71; acc: 0.38
Batch: 340; loss: 1.85; acc: 0.27
Batch: 360; loss: 1.73; acc: 0.31
Batch: 380; loss: 1.64; acc: 0.39
Batch: 400; loss: 1.81; acc: 0.41
Batch: 420; loss: 1.59; acc: 0.42
Batch: 440; loss: 1.99; acc: 0.31
Batch: 460; loss: 1.7; acc: 0.41
Batch: 480; loss: 1.88; acc: 0.36
Batch: 500; loss: 1.83; acc: 0.34
Batch: 520; loss: 1.97; acc: 0.3
Batch: 540; loss: 1.84; acc: 0.28
Batch: 560; loss: 1.72; acc: 0.42
Batch: 580; loss: 1.76; acc: 0.41
Batch: 600; loss: 1.83; acc: 0.38
Batch: 620; loss: 1.78; acc: 0.34
Batch: 640; loss: 1.89; acc: 0.3
Batch: 660; loss: 1.91; acc: 0.3
Batch: 680; loss: 1.78; acc: 0.42
Batch: 700; loss: 1.52; acc: 0.48
Batch: 720; loss: 1.8; acc: 0.36
Batch: 740; loss: 1.69; acc: 0.42
Batch: 760; loss: 1.85; acc: 0.3
Batch: 780; loss: 1.92; acc: 0.3
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7786483673533058; val_accuracy: 0.36206210191082805 

The current subspace-distance is: 7.656195521121845e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.0; acc: 0.31
Batch: 20; loss: 1.7; acc: 0.38
Batch: 40; loss: 1.75; acc: 0.41
Batch: 60; loss: 1.72; acc: 0.36
Batch: 80; loss: 1.77; acc: 0.31
Batch: 100; loss: 1.81; acc: 0.31
Batch: 120; loss: 1.87; acc: 0.33
Batch: 140; loss: 1.7; acc: 0.39
Batch: 160; loss: 1.76; acc: 0.38
Batch: 180; loss: 1.73; acc: 0.36
Batch: 200; loss: 1.79; acc: 0.42
Batch: 220; loss: 1.77; acc: 0.45
Batch: 240; loss: 1.61; acc: 0.47
Batch: 260; loss: 1.73; acc: 0.41
Batch: 280; loss: 1.59; acc: 0.41
Batch: 300; loss: 1.74; acc: 0.39
Batch: 320; loss: 1.93; acc: 0.28
Batch: 340; loss: 1.93; acc: 0.31
Batch: 360; loss: 1.78; acc: 0.36
Batch: 380; loss: 1.85; acc: 0.34
Batch: 400; loss: 1.7; acc: 0.44
Batch: 420; loss: 1.77; acc: 0.38
Batch: 440; loss: 1.79; acc: 0.33
Batch: 460; loss: 1.62; acc: 0.45
Batch: 480; loss: 1.82; acc: 0.31
Batch: 500; loss: 1.9; acc: 0.3
Batch: 520; loss: 1.83; acc: 0.38
Batch: 540; loss: 1.82; acc: 0.34
Batch: 560; loss: 1.82; acc: 0.33
Batch: 580; loss: 1.7; acc: 0.34
Batch: 600; loss: 1.9; acc: 0.25
Batch: 620; loss: 1.8; acc: 0.39
Batch: 640; loss: 1.9; acc: 0.34
Batch: 660; loss: 1.85; acc: 0.41
Batch: 680; loss: 1.74; acc: 0.41
Batch: 700; loss: 1.79; acc: 0.41
Batch: 720; loss: 1.63; acc: 0.45
Batch: 740; loss: 1.74; acc: 0.36
Batch: 760; loss: 1.65; acc: 0.41
Batch: 780; loss: 1.81; acc: 0.31
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.55
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7785497516583486; val_accuracy: 0.361265923566879 

The current subspace-distance is: 7.666050805710256e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.81; acc: 0.44
Batch: 20; loss: 1.83; acc: 0.27
Batch: 40; loss: 1.68; acc: 0.41
Batch: 60; loss: 1.82; acc: 0.28
Batch: 80; loss: 1.65; acc: 0.45
Batch: 100; loss: 1.65; acc: 0.39
Batch: 120; loss: 1.83; acc: 0.39
Batch: 140; loss: 1.74; acc: 0.38
Batch: 160; loss: 1.97; acc: 0.27
Batch: 180; loss: 1.91; acc: 0.3
Batch: 200; loss: 1.83; acc: 0.36
Batch: 220; loss: 1.99; acc: 0.28
Batch: 240; loss: 1.71; acc: 0.38
Batch: 260; loss: 1.74; acc: 0.36
Batch: 280; loss: 1.83; acc: 0.34
Batch: 300; loss: 1.86; acc: 0.33
Batch: 320; loss: 1.9; acc: 0.33
Batch: 340; loss: 1.67; acc: 0.42
Batch: 360; loss: 1.85; acc: 0.27
Batch: 380; loss: 1.86; acc: 0.34
Batch: 400; loss: 1.72; acc: 0.44
Batch: 420; loss: 1.97; acc: 0.2
Batch: 440; loss: 1.83; acc: 0.36
Batch: 460; loss: 2.0; acc: 0.2
Batch: 480; loss: 1.77; acc: 0.31
Batch: 500; loss: 1.81; acc: 0.31
Batch: 520; loss: 1.86; acc: 0.34
Batch: 540; loss: 1.74; acc: 0.33
Batch: 560; loss: 1.74; acc: 0.41
Batch: 580; loss: 1.84; acc: 0.41
Batch: 600; loss: 1.77; acc: 0.36
Batch: 620; loss: 1.93; acc: 0.31
Batch: 640; loss: 1.72; acc: 0.38
Batch: 660; loss: 1.54; acc: 0.52
Batch: 680; loss: 1.81; acc: 0.41
Batch: 700; loss: 1.9; acc: 0.31
Batch: 720; loss: 1.81; acc: 0.39
Batch: 740; loss: 1.8; acc: 0.33
Batch: 760; loss: 1.86; acc: 0.25
Batch: 780; loss: 1.71; acc: 0.42
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7785557432539145; val_accuracy: 0.36236066878980894 

The current subspace-distance is: 7.543984247604385e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.0; acc: 0.3
Batch: 20; loss: 1.78; acc: 0.38
Batch: 40; loss: 1.87; acc: 0.39
Batch: 60; loss: 1.68; acc: 0.41
Batch: 80; loss: 1.83; acc: 0.38
Batch: 100; loss: 1.84; acc: 0.34
Batch: 120; loss: 1.9; acc: 0.3
Batch: 140; loss: 1.82; acc: 0.31
Batch: 160; loss: 1.61; acc: 0.39
Batch: 180; loss: 1.68; acc: 0.39
Batch: 200; loss: 1.72; acc: 0.39
Batch: 220; loss: 1.75; acc: 0.42
Batch: 240; loss: 1.86; acc: 0.36
Batch: 260; loss: 1.89; acc: 0.31
Batch: 280; loss: 1.83; acc: 0.3
Batch: 300; loss: 1.74; acc: 0.34
Batch: 320; loss: 1.79; acc: 0.33
Batch: 340; loss: 1.69; acc: 0.42
Batch: 360; loss: 1.68; acc: 0.39
Batch: 380; loss: 1.76; acc: 0.38
Batch: 400; loss: 1.82; acc: 0.34
Batch: 420; loss: 1.8; acc: 0.41
Batch: 440; loss: 1.84; acc: 0.3
Batch: 460; loss: 1.96; acc: 0.23
Batch: 480; loss: 1.81; acc: 0.3
Batch: 500; loss: 1.81; acc: 0.33
Batch: 520; loss: 1.75; acc: 0.42
Batch: 540; loss: 1.9; acc: 0.3
Batch: 560; loss: 1.71; acc: 0.42
Batch: 580; loss: 1.78; acc: 0.31
Batch: 600; loss: 1.97; acc: 0.41
Batch: 620; loss: 1.74; acc: 0.3
Batch: 640; loss: 1.78; acc: 0.34
Batch: 660; loss: 1.68; acc: 0.39
Batch: 680; loss: 1.94; acc: 0.28
Batch: 700; loss: 1.83; acc: 0.33
Batch: 720; loss: 1.82; acc: 0.39
Batch: 740; loss: 1.85; acc: 0.36
Batch: 760; loss: 1.98; acc: 0.3
Batch: 780; loss: 1.8; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7786118088254503; val_accuracy: 0.3614649681528662 

The current subspace-distance is: 7.50240869820118e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.84; acc: 0.31
Batch: 20; loss: 1.56; acc: 0.44
Batch: 40; loss: 1.85; acc: 0.33
Batch: 60; loss: 1.88; acc: 0.38
Batch: 80; loss: 1.87; acc: 0.39
Batch: 100; loss: 1.65; acc: 0.33
Batch: 120; loss: 1.59; acc: 0.44
Batch: 140; loss: 1.89; acc: 0.3
Batch: 160; loss: 1.8; acc: 0.36
Batch: 180; loss: 1.79; acc: 0.34
Batch: 200; loss: 1.72; acc: 0.47
Batch: 220; loss: 1.59; acc: 0.52
Batch: 240; loss: 1.64; acc: 0.39
Batch: 260; loss: 1.8; acc: 0.36
Batch: 280; loss: 1.78; acc: 0.36
Batch: 300; loss: 1.97; acc: 0.34
Batch: 320; loss: 1.72; acc: 0.36
Batch: 340; loss: 1.75; acc: 0.39
Batch: 360; loss: 1.6; acc: 0.48
Batch: 380; loss: 1.71; acc: 0.44
Batch: 400; loss: 1.78; acc: 0.34
Batch: 420; loss: 1.79; acc: 0.38
Batch: 440; loss: 2.11; acc: 0.25
Batch: 460; loss: 1.93; acc: 0.33
Batch: 480; loss: 1.74; acc: 0.36
Batch: 500; loss: 1.84; acc: 0.39
Batch: 520; loss: 1.69; acc: 0.47
Batch: 540; loss: 1.56; acc: 0.53
Batch: 560; loss: 1.89; acc: 0.31
Batch: 580; loss: 1.74; acc: 0.44
Batch: 600; loss: 2.02; acc: 0.22
Batch: 620; loss: 1.77; acc: 0.28
Batch: 640; loss: 1.89; acc: 0.34
Batch: 660; loss: 1.59; acc: 0.45
Batch: 680; loss: 1.84; acc: 0.34
Batch: 700; loss: 1.82; acc: 0.38
Batch: 720; loss: 1.86; acc: 0.33
Batch: 740; loss: 1.59; acc: 0.45
Batch: 760; loss: 1.69; acc: 0.36
Batch: 780; loss: 1.75; acc: 0.41
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7784911227074398; val_accuracy: 0.36315684713375795 

The current subspace-distance is: 7.873309368733317e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.09; acc: 0.25
Batch: 20; loss: 1.74; acc: 0.33
Batch: 40; loss: 1.64; acc: 0.41
Batch: 60; loss: 1.89; acc: 0.31
Batch: 80; loss: 2.12; acc: 0.23
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.71; acc: 0.45
Batch: 140; loss: 1.67; acc: 0.42
Batch: 160; loss: 1.92; acc: 0.31
Batch: 180; loss: 1.7; acc: 0.41
Batch: 200; loss: 1.68; acc: 0.38
Batch: 220; loss: 1.68; acc: 0.44
Batch: 240; loss: 1.91; acc: 0.3
Batch: 260; loss: 1.73; acc: 0.36
Batch: 280; loss: 1.91; acc: 0.36
Batch: 300; loss: 1.86; acc: 0.36
Batch: 320; loss: 1.87; acc: 0.34
Batch: 340; loss: 1.55; acc: 0.42
Batch: 360; loss: 1.9; acc: 0.33
Batch: 380; loss: 1.68; acc: 0.36
Batch: 400; loss: 1.65; acc: 0.38
Batch: 420; loss: 1.94; acc: 0.33
Batch: 440; loss: 1.85; acc: 0.39
Batch: 460; loss: 1.93; acc: 0.25
Batch: 480; loss: 1.92; acc: 0.33
Batch: 500; loss: 1.78; acc: 0.34
Batch: 520; loss: 1.9; acc: 0.25
Batch: 540; loss: 1.82; acc: 0.3
Batch: 560; loss: 1.91; acc: 0.33
Batch: 580; loss: 1.9; acc: 0.33
Batch: 600; loss: 1.61; acc: 0.55
Batch: 620; loss: 1.94; acc: 0.3
Batch: 640; loss: 1.84; acc: 0.31
Batch: 660; loss: 1.82; acc: 0.28
Batch: 680; loss: 1.7; acc: 0.36
Batch: 700; loss: 1.67; acc: 0.39
Batch: 720; loss: 1.9; acc: 0.33
Batch: 740; loss: 1.82; acc: 0.34
Batch: 760; loss: 1.88; acc: 0.34
Batch: 780; loss: 1.9; acc: 0.33
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7785787787407068; val_accuracy: 0.36186305732484075 

The current subspace-distance is: 7.883700891397893e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.8; acc: 0.3
Batch: 20; loss: 1.71; acc: 0.38
Batch: 40; loss: 1.9; acc: 0.31
Batch: 60; loss: 1.56; acc: 0.48
Batch: 80; loss: 1.72; acc: 0.47
Batch: 100; loss: 1.97; acc: 0.27
Batch: 120; loss: 1.83; acc: 0.38
Batch: 140; loss: 1.85; acc: 0.3
Batch: 160; loss: 2.02; acc: 0.3
Batch: 180; loss: 1.82; acc: 0.33
Batch: 200; loss: 1.93; acc: 0.34
Batch: 220; loss: 1.81; acc: 0.34
Batch: 240; loss: 1.82; acc: 0.3
Batch: 260; loss: 1.93; acc: 0.3
Batch: 280; loss: 1.82; acc: 0.3
Batch: 300; loss: 1.63; acc: 0.42
Batch: 320; loss: 1.84; acc: 0.36
Batch: 340; loss: 1.82; acc: 0.36
Batch: 360; loss: 1.88; acc: 0.42
Batch: 380; loss: 1.81; acc: 0.41
Batch: 400; loss: 1.76; acc: 0.38
Batch: 420; loss: 1.81; acc: 0.42
Batch: 440; loss: 1.86; acc: 0.33
Batch: 460; loss: 1.76; acc: 0.41
Batch: 480; loss: 1.89; acc: 0.36
Batch: 500; loss: 1.78; acc: 0.38
Batch: 520; loss: 1.81; acc: 0.41
Batch: 540; loss: 1.79; acc: 0.34
Batch: 560; loss: 1.99; acc: 0.33
Batch: 580; loss: 1.82; acc: 0.42
Batch: 600; loss: 1.75; acc: 0.34
Batch: 620; loss: 1.75; acc: 0.34
Batch: 640; loss: 1.67; acc: 0.41
Batch: 660; loss: 1.68; acc: 0.39
Batch: 680; loss: 1.86; acc: 0.34
Batch: 700; loss: 1.79; acc: 0.33
Batch: 720; loss: 1.76; acc: 0.34
Batch: 740; loss: 1.67; acc: 0.45
Batch: 760; loss: 2.02; acc: 0.17
Batch: 780; loss: 1.86; acc: 0.34
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.98; acc: 0.36
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.778544892171386; val_accuracy: 0.3622611464968153 

The current subspace-distance is: 8.201676973840222e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.84; acc: 0.38
Batch: 20; loss: 1.9; acc: 0.36
Batch: 40; loss: 1.46; acc: 0.48
Batch: 60; loss: 1.94; acc: 0.31
Batch: 80; loss: 1.92; acc: 0.27
Batch: 100; loss: 1.76; acc: 0.41
Batch: 120; loss: 1.9; acc: 0.3
Batch: 140; loss: 1.78; acc: 0.36
Batch: 160; loss: 1.89; acc: 0.39
Batch: 180; loss: 1.84; acc: 0.31
Batch: 200; loss: 1.79; acc: 0.34
Batch: 220; loss: 1.82; acc: 0.34
Batch: 240; loss: 1.83; acc: 0.34
Batch: 260; loss: 1.62; acc: 0.42
Batch: 280; loss: 1.85; acc: 0.31
Batch: 300; loss: 1.8; acc: 0.45
Batch: 320; loss: 1.75; acc: 0.34
Batch: 340; loss: 1.85; acc: 0.38
Batch: 360; loss: 1.95; acc: 0.3
Batch: 380; loss: 1.85; acc: 0.33
Batch: 400; loss: 1.79; acc: 0.38
Batch: 420; loss: 1.78; acc: 0.42
Batch: 440; loss: 1.83; acc: 0.39
Batch: 460; loss: 1.85; acc: 0.31
Batch: 480; loss: 1.63; acc: 0.42
Batch: 500; loss: 1.7; acc: 0.41
Batch: 520; loss: 1.72; acc: 0.42
Batch: 540; loss: 1.84; acc: 0.3
Batch: 560; loss: 1.91; acc: 0.3
Batch: 580; loss: 1.74; acc: 0.42
Batch: 600; loss: 1.69; acc: 0.44
Batch: 620; loss: 2.05; acc: 0.22
Batch: 640; loss: 1.76; acc: 0.38
Batch: 660; loss: 1.77; acc: 0.34
Batch: 680; loss: 1.83; acc: 0.38
Batch: 700; loss: 1.77; acc: 0.31
Batch: 720; loss: 1.84; acc: 0.36
Batch: 740; loss: 1.94; acc: 0.27
Batch: 760; loss: 1.88; acc: 0.38
Batch: 780; loss: 1.76; acc: 0.38
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.7786430765868753; val_accuracy: 0.3613654458598726 

The current subspace-distance is: 8.364867971977219e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.89; acc: 0.34
Batch: 20; loss: 1.84; acc: 0.3
Batch: 40; loss: 2.0; acc: 0.27
Batch: 60; loss: 1.61; acc: 0.48
Batch: 80; loss: 1.81; acc: 0.33
Batch: 100; loss: 1.81; acc: 0.36
Batch: 120; loss: 1.6; acc: 0.42
Batch: 140; loss: 1.75; acc: 0.45
Batch: 160; loss: 1.69; acc: 0.47
Batch: 180; loss: 2.01; acc: 0.3
Batch: 200; loss: 1.72; acc: 0.38
Batch: 220; loss: 2.16; acc: 0.19
Batch: 240; loss: 1.9; acc: 0.28
Batch: 260; loss: 1.73; acc: 0.42
Batch: 280; loss: 1.81; acc: 0.38
Batch: 300; loss: 1.84; acc: 0.41
Batch: 320; loss: 1.95; acc: 0.36
Batch: 340; loss: 1.91; acc: 0.31
Batch: 360; loss: 1.8; acc: 0.33
Batch: 380; loss: 1.81; acc: 0.33
Batch: 400; loss: 1.82; acc: 0.34
Batch: 420; loss: 1.89; acc: 0.34
Batch: 440; loss: 1.67; acc: 0.52
Batch: 460; loss: 1.86; acc: 0.33
Batch: 480; loss: 1.87; acc: 0.33
Batch: 500; loss: 1.73; acc: 0.31
Batch: 520; loss: 1.83; acc: 0.34
Batch: 540; loss: 1.89; acc: 0.3
Batch: 560; loss: 1.69; acc: 0.38
Batch: 580; loss: 1.85; acc: 0.36
Batch: 600; loss: 1.87; acc: 0.33
Batch: 620; loss: 1.84; acc: 0.34
Batch: 640; loss: 1.95; acc: 0.28
Batch: 660; loss: 1.75; acc: 0.41
Batch: 680; loss: 1.67; acc: 0.53
Batch: 700; loss: 1.65; acc: 0.42
Batch: 720; loss: 1.77; acc: 0.3
Batch: 740; loss: 1.85; acc: 0.34
Batch: 760; loss: 1.69; acc: 0.38
Batch: 780; loss: 1.79; acc: 0.45
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.55; acc: 0.53
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.77871828322198; val_accuracy: 0.36216162420382164 

The current subspace-distance is: 9.041213343152776e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.74; acc: 0.42
Batch: 20; loss: 1.62; acc: 0.39
Batch: 40; loss: 1.69; acc: 0.34
Batch: 60; loss: 1.79; acc: 0.42
Batch: 80; loss: 1.94; acc: 0.34
Batch: 100; loss: 1.84; acc: 0.33
Batch: 120; loss: 1.86; acc: 0.23
Batch: 140; loss: 1.82; acc: 0.28
Batch: 160; loss: 1.9; acc: 0.28
Batch: 180; loss: 1.88; acc: 0.3
Batch: 200; loss: 1.8; acc: 0.34
Batch: 220; loss: 1.69; acc: 0.42
Batch: 240; loss: 1.84; acc: 0.25
Batch: 260; loss: 1.89; acc: 0.3
Batch: 280; loss: 1.73; acc: 0.38
Batch: 300; loss: 1.8; acc: 0.39
Batch: 320; loss: 1.75; acc: 0.36
Batch: 340; loss: 1.93; acc: 0.38
Batch: 360; loss: 1.65; acc: 0.42
Batch: 380; loss: 1.81; acc: 0.38
Batch: 400; loss: 1.75; acc: 0.36
Batch: 420; loss: 1.73; acc: 0.39
Batch: 440; loss: 1.64; acc: 0.38
Batch: 460; loss: 1.73; acc: 0.44
Batch: 480; loss: 1.94; acc: 0.27
Batch: 500; loss: 1.78; acc: 0.33
Batch: 520; loss: 1.87; acc: 0.38
Batch: 540; loss: 1.74; acc: 0.31
Batch: 560; loss: 1.82; acc: 0.33
Batch: 580; loss: 1.97; acc: 0.27
Batch: 600; loss: 1.69; acc: 0.39
Batch: 620; loss: 1.84; acc: 0.3
Batch: 640; loss: 1.82; acc: 0.41
Batch: 660; loss: 1.9; acc: 0.3
Batch: 680; loss: 1.82; acc: 0.33
Batch: 700; loss: 1.75; acc: 0.41
Batch: 720; loss: 2.11; acc: 0.34
Batch: 740; loss: 1.82; acc: 0.31
Batch: 760; loss: 1.85; acc: 0.36
Batch: 780; loss: 1.82; acc: 0.36
Train Epoch over. train_loss: 1.8; train_accuracy: 0.36 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 2.01; acc: 0.27
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.52
Batch: 80; loss: 1.67; acc: 0.38
Batch: 100; loss: 1.95; acc: 0.34
Batch: 120; loss: 1.99; acc: 0.34
Batch: 140; loss: 1.67; acc: 0.38
Val Epoch over. val_loss: 1.778611847549487; val_accuracy: 0.36176353503184716 

The current subspace-distance is: 9.299478551838547e-05 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_25_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 10631
elements in E: 2221300
fraction nonzero: 0.004785936163507856
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.32; acc: 0.08
Batch: 40; loss: 2.32; acc: 0.08
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.31; acc: 0.12
Batch: 100; loss: 2.32; acc: 0.06
Batch: 120; loss: 2.32; acc: 0.05
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.32; acc: 0.09
Batch: 200; loss: 2.31; acc: 0.06
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.31; acc: 0.08
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.31; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.28; acc: 0.08
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.28; acc: 0.19
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.03
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.31; acc: 0.06
Batch: 540; loss: 2.29; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.05
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.26; acc: 0.22
Batch: 680; loss: 2.29; acc: 0.06
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.28; acc: 0.08
Batch: 740; loss: 2.3; acc: 0.06
Batch: 760; loss: 2.28; acc: 0.08
Batch: 780; loss: 2.28; acc: 0.08
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.28; acc: 0.06
Batch: 20; loss: 2.27; acc: 0.06
Batch: 40; loss: 2.28; acc: 0.08
Batch: 60; loss: 2.27; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.03
Batch: 120; loss: 2.28; acc: 0.08
Batch: 140; loss: 2.27; acc: 0.09
Val Epoch over. val_loss: 2.278381419029965; val_accuracy: 0.09106289808917198 

The current subspace-distance is: 3.3837554838100914e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.08
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.28; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.03
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.28; acc: 0.09
Batch: 160; loss: 2.26; acc: 0.14
Batch: 180; loss: 2.27; acc: 0.06
Batch: 200; loss: 2.25; acc: 0.16
Batch: 220; loss: 2.26; acc: 0.16
Batch: 240; loss: 2.27; acc: 0.09
Batch: 260; loss: 2.26; acc: 0.08
Batch: 280; loss: 2.27; acc: 0.09
Batch: 300; loss: 2.26; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.05
Batch: 340; loss: 2.27; acc: 0.12
Batch: 360; loss: 2.27; acc: 0.14
Batch: 380; loss: 2.24; acc: 0.19
Batch: 400; loss: 2.26; acc: 0.17
Batch: 420; loss: 2.26; acc: 0.11
Batch: 440; loss: 2.23; acc: 0.22
Batch: 460; loss: 2.23; acc: 0.19
Batch: 480; loss: 2.26; acc: 0.14
Batch: 500; loss: 2.22; acc: 0.27
Batch: 520; loss: 2.19; acc: 0.28
Batch: 540; loss: 2.25; acc: 0.23
Batch: 560; loss: 2.23; acc: 0.23
Batch: 580; loss: 2.21; acc: 0.25
Batch: 600; loss: 2.23; acc: 0.23
Batch: 620; loss: 2.21; acc: 0.25
Batch: 640; loss: 2.23; acc: 0.19
Batch: 660; loss: 2.21; acc: 0.2
Batch: 680; loss: 2.26; acc: 0.14
Batch: 700; loss: 2.18; acc: 0.3
Batch: 720; loss: 2.17; acc: 0.23
Batch: 740; loss: 2.18; acc: 0.28
Batch: 760; loss: 2.14; acc: 0.27
Batch: 780; loss: 2.23; acc: 0.16
Train Epoch over. train_loss: 2.24; train_accuracy: 0.15 

Batch: 0; loss: 2.14; acc: 0.3
Batch: 20; loss: 2.1; acc: 0.41
Batch: 40; loss: 2.09; acc: 0.36
Batch: 60; loss: 2.1; acc: 0.38
Batch: 80; loss: 2.13; acc: 0.3
Batch: 100; loss: 2.16; acc: 0.3
Batch: 120; loss: 2.15; acc: 0.36
Batch: 140; loss: 2.15; acc: 0.3
Val Epoch over. val_loss: 2.1572714444178684; val_accuracy: 0.25865843949044587 

The current subspace-distance is: 6.865755040053045e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.16; acc: 0.2
Batch: 20; loss: 2.15; acc: 0.25
Batch: 40; loss: 2.11; acc: 0.27
Batch: 60; loss: 2.09; acc: 0.31
Batch: 80; loss: 2.1; acc: 0.31
Batch: 100; loss: 2.12; acc: 0.23
Batch: 120; loss: 2.15; acc: 0.25
Batch: 140; loss: 2.08; acc: 0.27
Batch: 160; loss: 2.1; acc: 0.23
Batch: 180; loss: 2.01; acc: 0.33
Batch: 200; loss: 1.94; acc: 0.28
Batch: 220; loss: 2.07; acc: 0.25
Batch: 240; loss: 2.01; acc: 0.36
Batch: 260; loss: 1.96; acc: 0.36
Batch: 280; loss: 1.85; acc: 0.47
Batch: 300; loss: 1.79; acc: 0.41
Batch: 320; loss: 1.93; acc: 0.38
Batch: 340; loss: 1.9; acc: 0.33
Batch: 360; loss: 1.86; acc: 0.33
Batch: 380; loss: 1.84; acc: 0.44
Batch: 400; loss: 1.66; acc: 0.44
Batch: 420; loss: 1.71; acc: 0.47
Batch: 440; loss: 1.78; acc: 0.42
Batch: 460; loss: 1.83; acc: 0.3
Batch: 480; loss: 1.87; acc: 0.33
Batch: 500; loss: 1.71; acc: 0.52
Batch: 520; loss: 1.62; acc: 0.47
Batch: 540; loss: 1.59; acc: 0.44
Batch: 560; loss: 1.65; acc: 0.44
Batch: 580; loss: 1.67; acc: 0.45
Batch: 600; loss: 1.73; acc: 0.41
Batch: 620; loss: 1.83; acc: 0.36
Batch: 640; loss: 1.85; acc: 0.44
Batch: 660; loss: 1.81; acc: 0.42
Batch: 680; loss: 1.57; acc: 0.48
Batch: 700; loss: 1.61; acc: 0.5
Batch: 720; loss: 1.45; acc: 0.48
Batch: 740; loss: 1.54; acc: 0.41
Batch: 760; loss: 1.71; acc: 0.34
Batch: 780; loss: 1.58; acc: 0.44
Train Epoch over. train_loss: 1.84; train_accuracy: 0.38 

Batch: 0; loss: 1.64; acc: 0.41
Batch: 20; loss: 1.51; acc: 0.39
Batch: 40; loss: 1.1; acc: 0.66
Batch: 60; loss: 1.49; acc: 0.55
Batch: 80; loss: 1.39; acc: 0.62
Batch: 100; loss: 1.59; acc: 0.45
Batch: 120; loss: 1.64; acc: 0.45
Batch: 140; loss: 1.36; acc: 0.56
Val Epoch over. val_loss: 1.5983811237250165; val_accuracy: 0.46875 

The current subspace-distance is: 1.4072016710997559e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.31; acc: 0.58
Batch: 20; loss: 1.91; acc: 0.36
Batch: 40; loss: 1.54; acc: 0.53
Batch: 60; loss: 1.47; acc: 0.48
Batch: 80; loss: 1.67; acc: 0.5
Batch: 100; loss: 1.36; acc: 0.44
Batch: 120; loss: 1.57; acc: 0.38
Batch: 140; loss: 1.42; acc: 0.56
Batch: 160; loss: 1.69; acc: 0.48
Batch: 180; loss: 1.44; acc: 0.53
Batch: 200; loss: 1.62; acc: 0.47
Batch: 220; loss: 1.45; acc: 0.58
Batch: 240; loss: 1.59; acc: 0.42
Batch: 260; loss: 1.33; acc: 0.53
Batch: 280; loss: 1.57; acc: 0.47
Batch: 300; loss: 1.41; acc: 0.5
Batch: 320; loss: 1.44; acc: 0.55
Batch: 340; loss: 1.77; acc: 0.41
Batch: 360; loss: 1.37; acc: 0.5
Batch: 380; loss: 1.68; acc: 0.38
Batch: 400; loss: 1.83; acc: 0.44
Batch: 420; loss: 1.84; acc: 0.33
Batch: 440; loss: 1.35; acc: 0.47
Batch: 460; loss: 1.65; acc: 0.53
Batch: 480; loss: 1.39; acc: 0.52
Batch: 500; loss: 1.43; acc: 0.52
Batch: 520; loss: 1.35; acc: 0.58
Batch: 540; loss: 1.5; acc: 0.52
Batch: 560; loss: 1.87; acc: 0.39
Batch: 580; loss: 1.6; acc: 0.42
Batch: 600; loss: 1.53; acc: 0.52
Batch: 620; loss: 1.52; acc: 0.58
Batch: 640; loss: 1.52; acc: 0.44
Batch: 660; loss: 1.82; acc: 0.34
Batch: 680; loss: 1.65; acc: 0.41
Batch: 700; loss: 1.4; acc: 0.5
Batch: 720; loss: 1.48; acc: 0.53
Batch: 740; loss: 1.48; acc: 0.5
Batch: 760; loss: 1.6; acc: 0.5
Batch: 780; loss: 1.48; acc: 0.5
Train Epoch over. train_loss: 1.56; train_accuracy: 0.47 

Batch: 0; loss: 1.73; acc: 0.42
Batch: 20; loss: 1.59; acc: 0.41
Batch: 40; loss: 1.03; acc: 0.64
Batch: 60; loss: 1.37; acc: 0.59
Batch: 80; loss: 1.25; acc: 0.58
Batch: 100; loss: 1.68; acc: 0.44
Batch: 120; loss: 1.68; acc: 0.48
Batch: 140; loss: 1.23; acc: 0.53
Val Epoch over. val_loss: 1.5388339735140466; val_accuracy: 0.45790207006369427 

The current subspace-distance is: 1.9363158571650274e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.67; acc: 0.44
Batch: 20; loss: 1.58; acc: 0.53
Batch: 40; loss: 1.44; acc: 0.48
Batch: 60; loss: 1.32; acc: 0.61
Batch: 80; loss: 1.76; acc: 0.39
Batch: 100; loss: 1.49; acc: 0.52
Batch: 120; loss: 1.76; acc: 0.36
Batch: 140; loss: 1.38; acc: 0.5
Batch: 160; loss: 1.3; acc: 0.52
Batch: 180; loss: 1.37; acc: 0.56
Batch: 200; loss: 1.42; acc: 0.44
Batch: 220; loss: 1.65; acc: 0.38
Batch: 240; loss: 1.39; acc: 0.52
Batch: 260; loss: 1.64; acc: 0.47
Batch: 280; loss: 1.51; acc: 0.53
Batch: 300; loss: 1.44; acc: 0.47
Batch: 320; loss: 1.5; acc: 0.45
Batch: 340; loss: 1.52; acc: 0.5
Batch: 360; loss: 1.7; acc: 0.42
Batch: 380; loss: 1.38; acc: 0.52
Batch: 400; loss: 1.36; acc: 0.62
Batch: 420; loss: 1.47; acc: 0.56
Batch: 440; loss: 1.61; acc: 0.47
Batch: 460; loss: 1.47; acc: 0.5
Batch: 480; loss: 1.55; acc: 0.53
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.33; acc: 0.61
Batch: 540; loss: 1.41; acc: 0.61
Batch: 560; loss: 1.54; acc: 0.47
Batch: 580; loss: 1.61; acc: 0.56
Batch: 600; loss: 1.42; acc: 0.52
Batch: 620; loss: 1.46; acc: 0.41
Batch: 640; loss: 1.58; acc: 0.56
Batch: 660; loss: 1.87; acc: 0.41
Batch: 680; loss: 1.41; acc: 0.55
Batch: 700; loss: 1.66; acc: 0.48
Batch: 720; loss: 1.7; acc: 0.45
Batch: 740; loss: 1.86; acc: 0.36
Batch: 760; loss: 1.29; acc: 0.58
Batch: 780; loss: 1.76; acc: 0.41
Train Epoch over. train_loss: 1.52; train_accuracy: 0.48 

Batch: 0; loss: 1.69; acc: 0.41
Batch: 20; loss: 1.62; acc: 0.41
Batch: 40; loss: 0.97; acc: 0.67
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.19; acc: 0.58
Batch: 100; loss: 1.64; acc: 0.5
Batch: 120; loss: 1.62; acc: 0.52
Batch: 140; loss: 1.12; acc: 0.72
Val Epoch over. val_loss: 1.5059748329934042; val_accuracy: 0.4864649681528662 

The current subspace-distance is: 2.414924165350385e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.52; acc: 0.47
Batch: 20; loss: 1.56; acc: 0.38
Batch: 40; loss: 1.72; acc: 0.36
Batch: 60; loss: 1.29; acc: 0.56
Batch: 80; loss: 1.81; acc: 0.34
Batch: 100; loss: 1.5; acc: 0.45
Batch: 120; loss: 1.74; acc: 0.39
Batch: 140; loss: 1.47; acc: 0.58
Batch: 160; loss: 1.46; acc: 0.53
Batch: 180; loss: 1.54; acc: 0.47
Batch: 200; loss: 1.47; acc: 0.5
Batch: 220; loss: 1.67; acc: 0.45
Batch: 240; loss: 1.59; acc: 0.45
Batch: 260; loss: 1.48; acc: 0.52
Batch: 280; loss: 1.49; acc: 0.52
Batch: 300; loss: 1.65; acc: 0.48
Batch: 320; loss: 1.79; acc: 0.38
Batch: 340; loss: 1.51; acc: 0.47
Batch: 360; loss: 1.39; acc: 0.5
Batch: 380; loss: 1.47; acc: 0.58
Batch: 400; loss: 1.61; acc: 0.41
Batch: 420; loss: 1.44; acc: 0.61
Batch: 440; loss: 1.55; acc: 0.45
Batch: 460; loss: 1.32; acc: 0.58
Batch: 480; loss: 1.62; acc: 0.47
Batch: 500; loss: 1.44; acc: 0.56
Batch: 520; loss: 1.4; acc: 0.52
Batch: 540; loss: 1.69; acc: 0.48
Batch: 560; loss: 1.56; acc: 0.47
Batch: 580; loss: 1.37; acc: 0.5
Batch: 600; loss: 1.52; acc: 0.48
Batch: 620; loss: 1.67; acc: 0.48
Batch: 640; loss: 1.39; acc: 0.55
Batch: 660; loss: 1.38; acc: 0.52
Batch: 680; loss: 1.34; acc: 0.56
Batch: 700; loss: 1.71; acc: 0.44
Batch: 720; loss: 1.34; acc: 0.52
Batch: 740; loss: 1.45; acc: 0.5
Batch: 760; loss: 1.39; acc: 0.56
Batch: 780; loss: 1.4; acc: 0.48
Train Epoch over. train_loss: 1.52; train_accuracy: 0.49 

Batch: 0; loss: 1.7; acc: 0.42
Batch: 20; loss: 1.52; acc: 0.48
Batch: 40; loss: 0.99; acc: 0.67
Batch: 60; loss: 1.32; acc: 0.59
Batch: 80; loss: 1.21; acc: 0.58
Batch: 100; loss: 1.58; acc: 0.53
Batch: 120; loss: 1.66; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.62
Val Epoch over. val_loss: 1.5049243478258705; val_accuracy: 0.4853702229299363 

The current subspace-distance is: 2.6710858946898952e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.48; acc: 0.47
Batch: 40; loss: 1.66; acc: 0.38
Batch: 60; loss: 1.38; acc: 0.55
Batch: 80; loss: 1.45; acc: 0.53
Batch: 100; loss: 1.53; acc: 0.52
Batch: 120; loss: 1.61; acc: 0.45
Batch: 140; loss: 1.4; acc: 0.59
Batch: 160; loss: 1.34; acc: 0.53
Batch: 180; loss: 1.36; acc: 0.56
Batch: 200; loss: 1.62; acc: 0.44
Batch: 220; loss: 1.72; acc: 0.36
Batch: 240; loss: 1.46; acc: 0.39
Batch: 260; loss: 1.51; acc: 0.45
Batch: 280; loss: 1.37; acc: 0.52
Batch: 300; loss: 1.46; acc: 0.52
Batch: 320; loss: 1.56; acc: 0.48
Batch: 340; loss: 1.5; acc: 0.42
Batch: 360; loss: 1.49; acc: 0.48
Batch: 380; loss: 1.46; acc: 0.53
Batch: 400; loss: 1.46; acc: 0.52
Batch: 420; loss: 1.4; acc: 0.53
Batch: 440; loss: 1.2; acc: 0.67
Batch: 460; loss: 1.64; acc: 0.48
Batch: 480; loss: 1.61; acc: 0.48
Batch: 500; loss: 1.9; acc: 0.42
Batch: 520; loss: 1.36; acc: 0.52
Batch: 540; loss: 1.58; acc: 0.44
Batch: 560; loss: 1.6; acc: 0.42
Batch: 580; loss: 1.65; acc: 0.42
Batch: 600; loss: 1.58; acc: 0.48
Batch: 620; loss: 1.6; acc: 0.45
Batch: 640; loss: 1.52; acc: 0.5
Batch: 660; loss: 1.54; acc: 0.47
Batch: 680; loss: 1.48; acc: 0.52
Batch: 700; loss: 1.4; acc: 0.55
Batch: 720; loss: 1.47; acc: 0.5
Batch: 740; loss: 1.65; acc: 0.48
Batch: 760; loss: 1.34; acc: 0.53
Batch: 780; loss: 1.48; acc: 0.48
Train Epoch over. train_loss: 1.51; train_accuracy: 0.48 

Batch: 0; loss: 1.64; acc: 0.39
Batch: 20; loss: 1.5; acc: 0.48
Batch: 40; loss: 0.94; acc: 0.67
Batch: 60; loss: 1.38; acc: 0.56
Batch: 80; loss: 1.2; acc: 0.61
Batch: 100; loss: 1.42; acc: 0.5
Batch: 120; loss: 1.66; acc: 0.48
Batch: 140; loss: 1.07; acc: 0.67
Val Epoch over. val_loss: 1.4920064822124068; val_accuracy: 0.5035828025477707 

The current subspace-distance is: 3.206663313903846e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.56; acc: 0.48
Batch: 20; loss: 1.46; acc: 0.61
Batch: 40; loss: 1.54; acc: 0.48
Batch: 60; loss: 1.4; acc: 0.5
Batch: 80; loss: 1.48; acc: 0.44
Batch: 100; loss: 1.38; acc: 0.52
Batch: 120; loss: 1.49; acc: 0.45
Batch: 140; loss: 1.41; acc: 0.5
Batch: 160; loss: 1.41; acc: 0.47
Batch: 180; loss: 1.7; acc: 0.44
Batch: 200; loss: 1.35; acc: 0.52
Batch: 220; loss: 1.35; acc: 0.53
Batch: 240; loss: 1.64; acc: 0.39
Batch: 260; loss: 1.47; acc: 0.48
Batch: 280; loss: 1.43; acc: 0.52
Batch: 300; loss: 1.48; acc: 0.5
Batch: 320; loss: 1.52; acc: 0.39
Batch: 340; loss: 1.51; acc: 0.48
Batch: 360; loss: 1.33; acc: 0.58
Batch: 380; loss: 1.51; acc: 0.48
Batch: 400; loss: 1.34; acc: 0.55
Batch: 420; loss: 1.32; acc: 0.59
Batch: 440; loss: 1.48; acc: 0.5
Batch: 460; loss: 1.47; acc: 0.45
Batch: 480; loss: 1.36; acc: 0.52
Batch: 500; loss: 1.96; acc: 0.36
Batch: 520; loss: 1.51; acc: 0.5
Batch: 540; loss: 1.48; acc: 0.52
Batch: 560; loss: 1.42; acc: 0.53
Batch: 580; loss: 1.39; acc: 0.53
Batch: 600; loss: 1.19; acc: 0.62
Batch: 620; loss: 1.15; acc: 0.56
Batch: 640; loss: 1.41; acc: 0.59
Batch: 660; loss: 1.6; acc: 0.56
Batch: 680; loss: 1.46; acc: 0.34
Batch: 700; loss: 1.6; acc: 0.53
Batch: 720; loss: 1.39; acc: 0.48
Batch: 740; loss: 1.42; acc: 0.5
Batch: 760; loss: 1.43; acc: 0.55
Batch: 780; loss: 1.26; acc: 0.56
Train Epoch over. train_loss: 1.45; train_accuracy: 0.51 

Batch: 0; loss: 1.52; acc: 0.42
Batch: 20; loss: 1.49; acc: 0.5
Batch: 40; loss: 0.93; acc: 0.7
Batch: 60; loss: 1.37; acc: 0.56
Batch: 80; loss: 1.05; acc: 0.64
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.61; acc: 0.52
Batch: 140; loss: 0.99; acc: 0.66
Val Epoch over. val_loss: 1.3925149881156387; val_accuracy: 0.5338375796178344 

The current subspace-distance is: 3.4850367228500545e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.38; acc: 0.59
Batch: 40; loss: 1.64; acc: 0.41
Batch: 60; loss: 1.66; acc: 0.41
Batch: 80; loss: 1.58; acc: 0.56
Batch: 100; loss: 1.49; acc: 0.47
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 1.32; acc: 0.53
Batch: 160; loss: 1.45; acc: 0.52
Batch: 180; loss: 1.52; acc: 0.47
Batch: 200; loss: 1.7; acc: 0.41
Batch: 220; loss: 1.37; acc: 0.56
Batch: 240; loss: 1.33; acc: 0.48
Batch: 260; loss: 1.52; acc: 0.58
Batch: 280; loss: 1.5; acc: 0.48
Batch: 300; loss: 1.16; acc: 0.59
Batch: 320; loss: 1.59; acc: 0.5
Batch: 340; loss: 1.5; acc: 0.52
Batch: 360; loss: 1.71; acc: 0.44
Batch: 380; loss: 1.16; acc: 0.66
Batch: 400; loss: 1.42; acc: 0.5
Batch: 420; loss: 1.36; acc: 0.53
Batch: 440; loss: 1.48; acc: 0.55
Batch: 460; loss: 1.24; acc: 0.66
Batch: 480; loss: 1.35; acc: 0.56
Batch: 500; loss: 1.43; acc: 0.53
Batch: 520; loss: 1.33; acc: 0.56
Batch: 540; loss: 1.43; acc: 0.53
Batch: 560; loss: 1.5; acc: 0.44
Batch: 580; loss: 1.29; acc: 0.55
Batch: 600; loss: 1.49; acc: 0.52
Batch: 620; loss: 1.27; acc: 0.55
Batch: 640; loss: 1.37; acc: 0.55
Batch: 660; loss: 1.25; acc: 0.5
Batch: 680; loss: 1.68; acc: 0.39
Batch: 700; loss: 1.29; acc: 0.53
Batch: 720; loss: 1.34; acc: 0.58
Batch: 740; loss: 1.39; acc: 0.53
Batch: 760; loss: 1.28; acc: 0.62
Batch: 780; loss: 1.32; acc: 0.59
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.4; acc: 0.48
Batch: 20; loss: 1.5; acc: 0.47
Batch: 40; loss: 0.98; acc: 0.72
Batch: 60; loss: 1.39; acc: 0.55
Batch: 80; loss: 1.06; acc: 0.61
Batch: 100; loss: 1.41; acc: 0.55
Batch: 120; loss: 1.5; acc: 0.58
Batch: 140; loss: 0.98; acc: 0.66
Val Epoch over. val_loss: 1.3772160342544506; val_accuracy: 0.5402070063694268 

The current subspace-distance is: 3.727290823007934e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.47; acc: 0.52
Batch: 20; loss: 1.36; acc: 0.48
Batch: 40; loss: 1.43; acc: 0.55
Batch: 60; loss: 1.31; acc: 0.52
Batch: 80; loss: 1.58; acc: 0.34
Batch: 100; loss: 1.19; acc: 0.61
Batch: 120; loss: 1.55; acc: 0.58
Batch: 140; loss: 1.32; acc: 0.5
Batch: 160; loss: 1.53; acc: 0.53
Batch: 180; loss: 1.54; acc: 0.5
Batch: 200; loss: 1.27; acc: 0.56
Batch: 220; loss: 1.38; acc: 0.55
Batch: 240; loss: 1.6; acc: 0.55
Batch: 260; loss: 1.43; acc: 0.52
Batch: 280; loss: 1.37; acc: 0.58
Batch: 300; loss: 1.21; acc: 0.5
Batch: 320; loss: 1.7; acc: 0.41
Batch: 340; loss: 1.49; acc: 0.58
Batch: 360; loss: 1.36; acc: 0.52
Batch: 380; loss: 1.27; acc: 0.52
Batch: 400; loss: 1.38; acc: 0.52
Batch: 420; loss: 1.33; acc: 0.53
Batch: 440; loss: 1.45; acc: 0.5
Batch: 460; loss: 1.43; acc: 0.52
Batch: 480; loss: 1.41; acc: 0.55
Batch: 500; loss: 1.4; acc: 0.52
Batch: 520; loss: 1.52; acc: 0.48
Batch: 540; loss: 1.33; acc: 0.53
Batch: 560; loss: 1.37; acc: 0.58
Batch: 580; loss: 1.75; acc: 0.39
Batch: 600; loss: 1.39; acc: 0.56
Batch: 620; loss: 1.38; acc: 0.52
Batch: 640; loss: 1.38; acc: 0.52
Batch: 660; loss: 1.43; acc: 0.5
Batch: 680; loss: 1.35; acc: 0.48
Batch: 700; loss: 1.36; acc: 0.45
Batch: 720; loss: 1.32; acc: 0.58
Batch: 740; loss: 1.31; acc: 0.5
Batch: 760; loss: 1.36; acc: 0.5
Batch: 780; loss: 1.47; acc: 0.52
Train Epoch over. train_loss: 1.39; train_accuracy: 0.53 

Batch: 0; loss: 1.26; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.45
Batch: 40; loss: 0.91; acc: 0.72
Batch: 60; loss: 1.36; acc: 0.53
Batch: 80; loss: 1.09; acc: 0.62
Batch: 100; loss: 1.39; acc: 0.5
Batch: 120; loss: 1.46; acc: 0.55
Batch: 140; loss: 1.0; acc: 0.64
Val Epoch over. val_loss: 1.3578014309239235; val_accuracy: 0.5429936305732485 

The current subspace-distance is: 4.220215487293899e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.57; acc: 0.48
Batch: 20; loss: 1.31; acc: 0.56
Batch: 40; loss: 1.22; acc: 0.59
Batch: 60; loss: 1.24; acc: 0.55
Batch: 80; loss: 1.39; acc: 0.55
Batch: 100; loss: 1.46; acc: 0.48
Batch: 120; loss: 1.34; acc: 0.53
Batch: 140; loss: 1.31; acc: 0.55
Batch: 160; loss: 1.53; acc: 0.41
Batch: 180; loss: 1.5; acc: 0.55
Batch: 200; loss: 1.24; acc: 0.52
Batch: 220; loss: 1.33; acc: 0.53
Batch: 240; loss: 1.17; acc: 0.56
Batch: 260; loss: 1.26; acc: 0.66
Batch: 280; loss: 1.49; acc: 0.59
Batch: 300; loss: 1.67; acc: 0.44
Batch: 320; loss: 1.46; acc: 0.44
Batch: 340; loss: 1.37; acc: 0.58
Batch: 360; loss: 1.45; acc: 0.53
Batch: 380; loss: 1.21; acc: 0.56
Batch: 400; loss: 1.32; acc: 0.58
Batch: 420; loss: 1.65; acc: 0.48
Batch: 440; loss: 1.37; acc: 0.58
Batch: 460; loss: 1.57; acc: 0.42
Batch: 480; loss: 1.41; acc: 0.52
Batch: 500; loss: 1.45; acc: 0.42
Batch: 520; loss: 1.52; acc: 0.48
Batch: 540; loss: 1.24; acc: 0.58
Batch: 560; loss: 1.42; acc: 0.56
Batch: 580; loss: 1.15; acc: 0.56
Batch: 600; loss: 1.26; acc: 0.56
Batch: 620; loss: 1.38; acc: 0.45
Batch: 640; loss: 1.2; acc: 0.59
Batch: 660; loss: 1.52; acc: 0.5
Batch: 680; loss: 1.3; acc: 0.53
Batch: 700; loss: 1.31; acc: 0.64
Batch: 720; loss: 1.38; acc: 0.56
Batch: 740; loss: 1.55; acc: 0.45
Batch: 760; loss: 1.33; acc: 0.58
Batch: 780; loss: 1.58; acc: 0.52
Train Epoch over. train_loss: 1.38; train_accuracy: 0.53 

Batch: 0; loss: 1.27; acc: 0.48
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 0.92; acc: 0.7
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.06; acc: 0.62
Batch: 100; loss: 1.39; acc: 0.5
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.02; acc: 0.64
Val Epoch over. val_loss: 1.3443884750840012; val_accuracy: 0.5476711783439491 

The current subspace-distance is: 4.3592339352471754e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.38; acc: 0.48
Batch: 20; loss: 1.46; acc: 0.55
Batch: 40; loss: 1.69; acc: 0.39
Batch: 60; loss: 1.43; acc: 0.48
Batch: 80; loss: 1.34; acc: 0.48
Batch: 100; loss: 1.32; acc: 0.58
Batch: 120; loss: 1.4; acc: 0.5
Batch: 140; loss: 1.33; acc: 0.5
Batch: 160; loss: 1.48; acc: 0.55
Batch: 180; loss: 1.19; acc: 0.61
Batch: 200; loss: 1.49; acc: 0.42
Batch: 220; loss: 1.35; acc: 0.53
Batch: 240; loss: 1.46; acc: 0.55
Batch: 260; loss: 1.45; acc: 0.48
Batch: 280; loss: 1.34; acc: 0.53
Batch: 300; loss: 1.25; acc: 0.52
Batch: 320; loss: 1.44; acc: 0.52
Batch: 340; loss: 1.58; acc: 0.47
Batch: 360; loss: 1.56; acc: 0.48
Batch: 380; loss: 1.6; acc: 0.47
Batch: 400; loss: 1.43; acc: 0.5
Batch: 420; loss: 1.75; acc: 0.41
Batch: 440; loss: 1.19; acc: 0.66
Batch: 460; loss: 1.46; acc: 0.44
Batch: 480; loss: 1.3; acc: 0.52
Batch: 500; loss: 1.28; acc: 0.53
Batch: 520; loss: 1.63; acc: 0.44
Batch: 540; loss: 1.37; acc: 0.48
Batch: 560; loss: 1.45; acc: 0.48
Batch: 580; loss: 1.24; acc: 0.58
Batch: 600; loss: 1.3; acc: 0.64
Batch: 620; loss: 1.31; acc: 0.55
Batch: 640; loss: 1.37; acc: 0.52
Batch: 660; loss: 1.22; acc: 0.61
Batch: 680; loss: 1.4; acc: 0.58
Batch: 700; loss: 1.15; acc: 0.62
Batch: 720; loss: 1.26; acc: 0.53
Batch: 740; loss: 1.65; acc: 0.41
Batch: 760; loss: 1.42; acc: 0.47
Batch: 780; loss: 1.2; acc: 0.61
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.29; acc: 0.5
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 0.9; acc: 0.72
Batch: 60; loss: 1.34; acc: 0.61
Batch: 80; loss: 1.03; acc: 0.61
Batch: 100; loss: 1.42; acc: 0.53
Batch: 120; loss: 1.43; acc: 0.55
Batch: 140; loss: 1.0; acc: 0.64
Val Epoch over. val_loss: 1.333998659234138; val_accuracy: 0.5519506369426752 

The current subspace-distance is: 4.7189267206704244e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.45; acc: 0.48
Batch: 20; loss: 1.29; acc: 0.59
Batch: 40; loss: 1.25; acc: 0.67
Batch: 60; loss: 1.33; acc: 0.55
Batch: 80; loss: 1.32; acc: 0.48
Batch: 100; loss: 1.06; acc: 0.66
Batch: 120; loss: 1.37; acc: 0.55
Batch: 140; loss: 1.12; acc: 0.56
Batch: 160; loss: 1.52; acc: 0.5
Batch: 180; loss: 1.58; acc: 0.48
Batch: 200; loss: 0.94; acc: 0.7
Batch: 220; loss: 1.48; acc: 0.45
Batch: 240; loss: 1.38; acc: 0.52
Batch: 260; loss: 1.49; acc: 0.53
Batch: 280; loss: 1.5; acc: 0.53
Batch: 300; loss: 1.41; acc: 0.48
Batch: 320; loss: 1.17; acc: 0.61
Batch: 340; loss: 1.44; acc: 0.52
Batch: 360; loss: 1.23; acc: 0.56
Batch: 380; loss: 1.29; acc: 0.61
Batch: 400; loss: 1.42; acc: 0.55
Batch: 420; loss: 1.31; acc: 0.61
Batch: 440; loss: 1.34; acc: 0.52
Batch: 460; loss: 1.26; acc: 0.62
Batch: 480; loss: 1.62; acc: 0.45
Batch: 500; loss: 1.54; acc: 0.5
Batch: 520; loss: 1.48; acc: 0.55
Batch: 540; loss: 1.4; acc: 0.52
Batch: 560; loss: 1.34; acc: 0.61
Batch: 580; loss: 1.04; acc: 0.67
Batch: 600; loss: 1.43; acc: 0.53
Batch: 620; loss: 1.36; acc: 0.52
Batch: 640; loss: 1.3; acc: 0.55
Batch: 660; loss: 1.52; acc: 0.53
Batch: 680; loss: 1.35; acc: 0.52
Batch: 700; loss: 1.34; acc: 0.5
Batch: 720; loss: 1.52; acc: 0.47
Batch: 740; loss: 1.55; acc: 0.52
Batch: 760; loss: 1.51; acc: 0.53
Batch: 780; loss: 1.5; acc: 0.45
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.27; acc: 0.55
Batch: 20; loss: 1.42; acc: 0.5
Batch: 40; loss: 0.91; acc: 0.75
Batch: 60; loss: 1.33; acc: 0.59
Batch: 80; loss: 1.03; acc: 0.58
Batch: 100; loss: 1.39; acc: 0.53
Batch: 120; loss: 1.42; acc: 0.48
Batch: 140; loss: 1.01; acc: 0.66
Val Epoch over. val_loss: 1.3328502390794694; val_accuracy: 0.5519506369426752 

The current subspace-distance is: 4.8357793275499716e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.33; acc: 0.55
Batch: 20; loss: 1.24; acc: 0.53
Batch: 40; loss: 1.41; acc: 0.44
Batch: 60; loss: 1.31; acc: 0.55
Batch: 80; loss: 1.41; acc: 0.48
Batch: 100; loss: 1.08; acc: 0.64
Batch: 120; loss: 1.36; acc: 0.56
Batch: 140; loss: 1.6; acc: 0.45
Batch: 160; loss: 1.58; acc: 0.55
Batch: 180; loss: 1.3; acc: 0.58
Batch: 200; loss: 1.35; acc: 0.58
Batch: 220; loss: 1.1; acc: 0.62
Batch: 240; loss: 1.26; acc: 0.56
Batch: 260; loss: 1.41; acc: 0.53
Batch: 280; loss: 1.24; acc: 0.61
Batch: 300; loss: 1.33; acc: 0.53
Batch: 320; loss: 1.08; acc: 0.67
Batch: 340; loss: 1.31; acc: 0.5
Batch: 360; loss: 1.26; acc: 0.58
Batch: 380; loss: 1.23; acc: 0.55
Batch: 400; loss: 1.53; acc: 0.52
Batch: 420; loss: 1.29; acc: 0.52
Batch: 440; loss: 1.5; acc: 0.55
Batch: 460; loss: 1.43; acc: 0.55
Batch: 480; loss: 1.28; acc: 0.59
Batch: 500; loss: 1.2; acc: 0.52
Batch: 520; loss: 1.35; acc: 0.56
Batch: 540; loss: 1.06; acc: 0.66
Batch: 560; loss: 1.31; acc: 0.55
Batch: 580; loss: 1.38; acc: 0.55
Batch: 600; loss: 1.36; acc: 0.52
Batch: 620; loss: 1.25; acc: 0.55
Batch: 640; loss: 1.06; acc: 0.67
Batch: 660; loss: 1.01; acc: 0.67
Batch: 680; loss: 1.73; acc: 0.44
Batch: 700; loss: 1.5; acc: 0.47
Batch: 720; loss: 1.17; acc: 0.62
Batch: 740; loss: 1.3; acc: 0.5
Batch: 760; loss: 1.46; acc: 0.52
Batch: 780; loss: 1.51; acc: 0.53
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.29; acc: 0.5
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 0.92; acc: 0.75
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.05; acc: 0.61
Batch: 100; loss: 1.39; acc: 0.53
Batch: 120; loss: 1.41; acc: 0.47
Batch: 140; loss: 1.0; acc: 0.67
Val Epoch over. val_loss: 1.336351885537433; val_accuracy: 0.5529458598726115 

The current subspace-distance is: 4.9681122618494555e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.2; acc: 0.56
Batch: 20; loss: 1.24; acc: 0.58
Batch: 40; loss: 1.54; acc: 0.47
Batch: 60; loss: 1.48; acc: 0.52
Batch: 80; loss: 1.43; acc: 0.41
Batch: 100; loss: 1.42; acc: 0.58
Batch: 120; loss: 1.09; acc: 0.66
Batch: 140; loss: 1.42; acc: 0.53
Batch: 160; loss: 1.37; acc: 0.59
Batch: 180; loss: 1.42; acc: 0.53
Batch: 200; loss: 1.31; acc: 0.58
Batch: 220; loss: 1.6; acc: 0.47
Batch: 240; loss: 1.25; acc: 0.42
Batch: 260; loss: 1.14; acc: 0.59
Batch: 280; loss: 1.51; acc: 0.5
Batch: 300; loss: 1.18; acc: 0.59
Batch: 320; loss: 1.33; acc: 0.58
Batch: 340; loss: 1.29; acc: 0.58
Batch: 360; loss: 1.34; acc: 0.52
Batch: 380; loss: 1.17; acc: 0.59
Batch: 400; loss: 1.31; acc: 0.59
Batch: 420; loss: 1.35; acc: 0.53
Batch: 440; loss: 1.5; acc: 0.48
Batch: 460; loss: 1.31; acc: 0.55
Batch: 480; loss: 1.56; acc: 0.44
Batch: 500; loss: 1.18; acc: 0.66
Batch: 520; loss: 1.57; acc: 0.48
Batch: 540; loss: 1.35; acc: 0.5
Batch: 560; loss: 1.16; acc: 0.59
Batch: 580; loss: 1.57; acc: 0.39
Batch: 600; loss: 1.39; acc: 0.5
Batch: 620; loss: 1.28; acc: 0.58
Batch: 640; loss: 1.32; acc: 0.55
Batch: 660; loss: 1.12; acc: 0.58
Batch: 680; loss: 1.57; acc: 0.52
Batch: 700; loss: 1.48; acc: 0.48
Batch: 720; loss: 1.3; acc: 0.55
Batch: 740; loss: 1.33; acc: 0.61
Batch: 760; loss: 1.37; acc: 0.58
Batch: 780; loss: 1.22; acc: 0.58
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.25; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.48
Batch: 40; loss: 0.89; acc: 0.73
Batch: 60; loss: 1.33; acc: 0.59
Batch: 80; loss: 1.02; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.59
Batch: 120; loss: 1.39; acc: 0.52
Batch: 140; loss: 0.98; acc: 0.67
Val Epoch over. val_loss: 1.3296747841652792; val_accuracy: 0.555234872611465 

The current subspace-distance is: 5.2836094255326316e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.19; acc: 0.55
Batch: 20; loss: 1.5; acc: 0.52
Batch: 40; loss: 1.27; acc: 0.58
Batch: 60; loss: 1.38; acc: 0.55
Batch: 80; loss: 1.27; acc: 0.56
Batch: 100; loss: 1.15; acc: 0.66
Batch: 120; loss: 1.47; acc: 0.52
Batch: 140; loss: 1.5; acc: 0.45
Batch: 160; loss: 1.43; acc: 0.41
Batch: 180; loss: 1.31; acc: 0.55
Batch: 200; loss: 1.28; acc: 0.56
Batch: 220; loss: 1.28; acc: 0.64
Batch: 240; loss: 1.23; acc: 0.58
Batch: 260; loss: 1.32; acc: 0.53
Batch: 280; loss: 1.44; acc: 0.53
Batch: 300; loss: 1.48; acc: 0.52
Batch: 320; loss: 1.52; acc: 0.42
Batch: 340; loss: 1.56; acc: 0.45
Batch: 360; loss: 1.2; acc: 0.58
Batch: 380; loss: 1.44; acc: 0.53
Batch: 400; loss: 1.18; acc: 0.61
Batch: 420; loss: 1.07; acc: 0.69
Batch: 440; loss: 1.59; acc: 0.52
Batch: 460; loss: 1.57; acc: 0.41
Batch: 480; loss: 1.37; acc: 0.59
Batch: 500; loss: 1.42; acc: 0.56
Batch: 520; loss: 1.48; acc: 0.5
Batch: 540; loss: 1.03; acc: 0.66
Batch: 560; loss: 1.26; acc: 0.56
Batch: 580; loss: 1.53; acc: 0.52
Batch: 600; loss: 1.51; acc: 0.52
Batch: 620; loss: 1.29; acc: 0.56
Batch: 640; loss: 1.29; acc: 0.55
Batch: 660; loss: 1.33; acc: 0.58
Batch: 680; loss: 1.38; acc: 0.59
Batch: 700; loss: 1.56; acc: 0.44
Batch: 720; loss: 1.61; acc: 0.48
Batch: 740; loss: 1.24; acc: 0.67
Batch: 760; loss: 1.36; acc: 0.52
Batch: 780; loss: 1.41; acc: 0.44
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.27; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.52
Batch: 40; loss: 0.89; acc: 0.73
Batch: 60; loss: 1.34; acc: 0.53
Batch: 80; loss: 1.02; acc: 0.56
Batch: 100; loss: 1.39; acc: 0.58
Batch: 120; loss: 1.38; acc: 0.55
Batch: 140; loss: 0.99; acc: 0.66
Val Epoch over. val_loss: 1.3286067217018953; val_accuracy: 0.5572253184713376 

The current subspace-distance is: 5.392295497586019e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.15; acc: 0.62
Batch: 20; loss: 1.34; acc: 0.53
Batch: 40; loss: 1.35; acc: 0.59
Batch: 60; loss: 1.38; acc: 0.47
Batch: 80; loss: 1.37; acc: 0.48
Batch: 100; loss: 1.74; acc: 0.28
Batch: 120; loss: 1.24; acc: 0.53
Batch: 140; loss: 1.45; acc: 0.62
Batch: 160; loss: 1.24; acc: 0.53
Batch: 180; loss: 1.59; acc: 0.5
Batch: 200; loss: 1.13; acc: 0.62
Batch: 220; loss: 1.6; acc: 0.45
Batch: 240; loss: 1.29; acc: 0.55
Batch: 260; loss: 1.32; acc: 0.59
Batch: 280; loss: 1.36; acc: 0.56
Batch: 300; loss: 1.29; acc: 0.56
Batch: 320; loss: 1.21; acc: 0.58
Batch: 340; loss: 1.46; acc: 0.52
Batch: 360; loss: 1.59; acc: 0.45
Batch: 380; loss: 1.47; acc: 0.55
Batch: 400; loss: 1.29; acc: 0.5
Batch: 420; loss: 1.16; acc: 0.64
Batch: 440; loss: 1.16; acc: 0.59
Batch: 460; loss: 1.43; acc: 0.45
Batch: 480; loss: 1.19; acc: 0.59
Batch: 500; loss: 1.24; acc: 0.61
Batch: 520; loss: 1.41; acc: 0.48
Batch: 540; loss: 1.32; acc: 0.61
Batch: 560; loss: 1.23; acc: 0.61
Batch: 580; loss: 1.29; acc: 0.53
Batch: 600; loss: 1.28; acc: 0.59
Batch: 620; loss: 1.34; acc: 0.55
Batch: 640; loss: 1.53; acc: 0.48
Batch: 660; loss: 1.27; acc: 0.58
Batch: 680; loss: 1.51; acc: 0.47
Batch: 700; loss: 1.4; acc: 0.52
Batch: 720; loss: 1.38; acc: 0.47
Batch: 740; loss: 1.28; acc: 0.55
Batch: 760; loss: 1.39; acc: 0.59
Batch: 780; loss: 1.35; acc: 0.61
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.26; acc: 0.55
Batch: 20; loss: 1.41; acc: 0.53
Batch: 40; loss: 0.9; acc: 0.75
Batch: 60; loss: 1.35; acc: 0.59
Batch: 80; loss: 1.04; acc: 0.61
Batch: 100; loss: 1.38; acc: 0.56
Batch: 120; loss: 1.39; acc: 0.5
Batch: 140; loss: 0.98; acc: 0.67
Val Epoch over. val_loss: 1.3301391905280435; val_accuracy: 0.5571257961783439 

The current subspace-distance is: 5.500421320903115e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.64; acc: 0.47
Batch: 20; loss: 1.31; acc: 0.52
Batch: 40; loss: 1.68; acc: 0.42
Batch: 60; loss: 1.5; acc: 0.45
Batch: 80; loss: 1.26; acc: 0.59
Batch: 100; loss: 1.27; acc: 0.56
Batch: 120; loss: 1.26; acc: 0.61
Batch: 140; loss: 1.39; acc: 0.5
Batch: 160; loss: 1.39; acc: 0.52
Batch: 180; loss: 1.26; acc: 0.48
Batch: 200; loss: 1.44; acc: 0.55
Batch: 220; loss: 1.13; acc: 0.62
Batch: 240; loss: 1.49; acc: 0.48
Batch: 260; loss: 1.34; acc: 0.56
Batch: 280; loss: 1.46; acc: 0.45
Batch: 300; loss: 1.26; acc: 0.58
Batch: 320; loss: 1.5; acc: 0.38
Batch: 340; loss: 1.35; acc: 0.53
Batch: 360; loss: 1.15; acc: 0.55
Batch: 380; loss: 1.52; acc: 0.45
Batch: 400; loss: 1.31; acc: 0.59
Batch: 420; loss: 1.61; acc: 0.47
Batch: 440; loss: 1.19; acc: 0.66
Batch: 460; loss: 1.55; acc: 0.47
Batch: 480; loss: 1.32; acc: 0.42
Batch: 500; loss: 1.35; acc: 0.55
Batch: 520; loss: 1.23; acc: 0.62
Batch: 540; loss: 1.49; acc: 0.42
Batch: 560; loss: 1.67; acc: 0.55
Batch: 580; loss: 1.64; acc: 0.44
Batch: 600; loss: 1.34; acc: 0.52
Batch: 620; loss: 1.4; acc: 0.58
Batch: 640; loss: 1.19; acc: 0.55
Batch: 660; loss: 1.17; acc: 0.62
Batch: 680; loss: 1.29; acc: 0.56
Batch: 700; loss: 1.23; acc: 0.59
Batch: 720; loss: 1.36; acc: 0.53
Batch: 740; loss: 1.4; acc: 0.53
Batch: 760; loss: 1.16; acc: 0.66
Batch: 780; loss: 1.24; acc: 0.62
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.26; acc: 0.5
Batch: 20; loss: 1.41; acc: 0.52
Batch: 40; loss: 0.88; acc: 0.75
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.02; acc: 0.58
Batch: 100; loss: 1.39; acc: 0.58
Batch: 120; loss: 1.37; acc: 0.56
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.329921986646713; val_accuracy: 0.5567277070063694 

The current subspace-distance is: 5.545884414459579e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.47; acc: 0.52
Batch: 20; loss: 1.02; acc: 0.66
Batch: 40; loss: 1.54; acc: 0.45
Batch: 60; loss: 1.39; acc: 0.52
Batch: 80; loss: 1.29; acc: 0.45
Batch: 100; loss: 1.33; acc: 0.56
Batch: 120; loss: 1.27; acc: 0.59
Batch: 140; loss: 1.44; acc: 0.53
Batch: 160; loss: 1.17; acc: 0.61
Batch: 180; loss: 1.34; acc: 0.55
Batch: 200; loss: 1.49; acc: 0.5
Batch: 220; loss: 1.55; acc: 0.5
Batch: 240; loss: 1.42; acc: 0.45
Batch: 260; loss: 1.34; acc: 0.58
Batch: 280; loss: 1.31; acc: 0.59
Batch: 300; loss: 1.31; acc: 0.52
Batch: 320; loss: 1.43; acc: 0.5
Batch: 340; loss: 1.32; acc: 0.52
Batch: 360; loss: 1.27; acc: 0.59
Batch: 380; loss: 1.52; acc: 0.52
Batch: 400; loss: 1.34; acc: 0.55
Batch: 420; loss: 1.21; acc: 0.61
Batch: 440; loss: 1.32; acc: 0.55
Batch: 460; loss: 1.28; acc: 0.53
Batch: 480; loss: 1.12; acc: 0.62
Batch: 500; loss: 1.28; acc: 0.52
Batch: 520; loss: 1.48; acc: 0.48
Batch: 540; loss: 1.29; acc: 0.52
Batch: 560; loss: 1.28; acc: 0.53
Batch: 580; loss: 1.5; acc: 0.47
Batch: 600; loss: 1.33; acc: 0.52
Batch: 620; loss: 1.35; acc: 0.53
Batch: 640; loss: 1.37; acc: 0.53
Batch: 660; loss: 1.43; acc: 0.56
Batch: 680; loss: 1.26; acc: 0.55
Batch: 700; loss: 1.28; acc: 0.53
Batch: 720; loss: 1.36; acc: 0.56
Batch: 740; loss: 1.48; acc: 0.53
Batch: 760; loss: 1.34; acc: 0.56
Batch: 780; loss: 1.4; acc: 0.58
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.24; acc: 0.53
Batch: 20; loss: 1.41; acc: 0.5
Batch: 40; loss: 0.87; acc: 0.77
Batch: 60; loss: 1.36; acc: 0.56
Batch: 80; loss: 1.04; acc: 0.53
Batch: 100; loss: 1.36; acc: 0.58
Batch: 120; loss: 1.36; acc: 0.55
Batch: 140; loss: 0.97; acc: 0.67
Val Epoch over. val_loss: 1.3353891429627778; val_accuracy: 0.5558320063694268 

The current subspace-distance is: 5.812079689349048e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.28; acc: 0.55
Batch: 20; loss: 1.12; acc: 0.69
Batch: 40; loss: 1.21; acc: 0.58
Batch: 60; loss: 1.56; acc: 0.45
Batch: 80; loss: 1.36; acc: 0.64
Batch: 100; loss: 1.63; acc: 0.39
Batch: 120; loss: 1.22; acc: 0.56
Batch: 140; loss: 1.39; acc: 0.55
Batch: 160; loss: 1.54; acc: 0.44
Batch: 180; loss: 1.18; acc: 0.61
Batch: 200; loss: 1.33; acc: 0.53
Batch: 220; loss: 1.41; acc: 0.5
Batch: 240; loss: 1.48; acc: 0.5
Batch: 260; loss: 1.3; acc: 0.66
Batch: 280; loss: 1.22; acc: 0.62
Batch: 300; loss: 1.35; acc: 0.52
Batch: 320; loss: 1.37; acc: 0.47
Batch: 340; loss: 1.41; acc: 0.5
Batch: 360; loss: 1.58; acc: 0.42
Batch: 380; loss: 1.27; acc: 0.61
Batch: 400; loss: 1.53; acc: 0.47
Batch: 420; loss: 1.13; acc: 0.66
Batch: 440; loss: 1.35; acc: 0.53
Batch: 460; loss: 1.64; acc: 0.41
Batch: 480; loss: 1.55; acc: 0.48
Batch: 500; loss: 1.46; acc: 0.53
Batch: 520; loss: 1.26; acc: 0.66
Batch: 540; loss: 1.16; acc: 0.56
Batch: 560; loss: 1.28; acc: 0.62
Batch: 580; loss: 1.3; acc: 0.48
Batch: 600; loss: 1.27; acc: 0.59
Batch: 620; loss: 1.27; acc: 0.58
Batch: 640; loss: 1.56; acc: 0.45
Batch: 660; loss: 1.43; acc: 0.45
Batch: 680; loss: 1.37; acc: 0.42
Batch: 700; loss: 1.41; acc: 0.52
Batch: 720; loss: 1.51; acc: 0.58
Batch: 740; loss: 1.52; acc: 0.47
Batch: 760; loss: 1.29; acc: 0.56
Batch: 780; loss: 1.51; acc: 0.45
Train Epoch over. train_loss: 1.37; train_accuracy: 0.53 

Batch: 0; loss: 1.27; acc: 0.48
Batch: 20; loss: 1.41; acc: 0.5
Batch: 40; loss: 0.89; acc: 0.77
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.02; acc: 0.56
Batch: 100; loss: 1.38; acc: 0.58
Batch: 120; loss: 1.38; acc: 0.53
Batch: 140; loss: 0.96; acc: 0.66
Val Epoch over. val_loss: 1.325374251338327; val_accuracy: 0.5618033439490446 

The current subspace-distance is: 6.195394962560385e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.41; acc: 0.56
Batch: 20; loss: 1.47; acc: 0.56
Batch: 40; loss: 1.45; acc: 0.48
Batch: 60; loss: 1.33; acc: 0.52
Batch: 80; loss: 1.29; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.5
Batch: 120; loss: 1.43; acc: 0.44
Batch: 140; loss: 1.35; acc: 0.48
Batch: 160; loss: 1.22; acc: 0.58
Batch: 180; loss: 1.51; acc: 0.5
Batch: 200; loss: 1.27; acc: 0.56
Batch: 220; loss: 1.33; acc: 0.62
Batch: 240; loss: 1.4; acc: 0.53
Batch: 260; loss: 1.41; acc: 0.52
Batch: 280; loss: 1.36; acc: 0.56
Batch: 300; loss: 1.36; acc: 0.55
Batch: 320; loss: 1.43; acc: 0.59
Batch: 340; loss: 1.24; acc: 0.58
Batch: 360; loss: 1.31; acc: 0.55
Batch: 380; loss: 1.48; acc: 0.45
Batch: 400; loss: 1.57; acc: 0.42
Batch: 420; loss: 1.36; acc: 0.5
Batch: 440; loss: 1.33; acc: 0.55
Batch: 460; loss: 1.34; acc: 0.53
Batch: 480; loss: 1.21; acc: 0.5
Batch: 500; loss: 1.47; acc: 0.44
Batch: 520; loss: 1.39; acc: 0.48
Batch: 540; loss: 1.35; acc: 0.53
Batch: 560; loss: 1.4; acc: 0.55
Batch: 580; loss: 1.44; acc: 0.53
Batch: 600; loss: 1.4; acc: 0.61
Batch: 620; loss: 1.27; acc: 0.55
Batch: 640; loss: 1.37; acc: 0.52
Batch: 660; loss: 1.35; acc: 0.45
Batch: 680; loss: 1.5; acc: 0.55
Batch: 700; loss: 1.22; acc: 0.59
Batch: 720; loss: 1.06; acc: 0.73
Batch: 740; loss: 1.35; acc: 0.52
Batch: 760; loss: 1.22; acc: 0.62
Batch: 780; loss: 1.46; acc: 0.5
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.53
Batch: 20; loss: 1.42; acc: 0.5
Batch: 40; loss: 0.9; acc: 0.73
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.03; acc: 0.58
Batch: 100; loss: 1.38; acc: 0.58
Batch: 120; loss: 1.37; acc: 0.52
Batch: 140; loss: 0.96; acc: 0.64
Val Epoch over. val_loss: 1.3246408773076004; val_accuracy: 0.5616042993630573 

The current subspace-distance is: 6.045895497663878e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.32; acc: 0.53
Batch: 20; loss: 1.44; acc: 0.45
Batch: 40; loss: 1.17; acc: 0.62
Batch: 60; loss: 1.29; acc: 0.56
Batch: 80; loss: 1.39; acc: 0.52
Batch: 100; loss: 1.45; acc: 0.53
Batch: 120; loss: 1.29; acc: 0.59
Batch: 140; loss: 1.68; acc: 0.47
Batch: 160; loss: 1.37; acc: 0.53
Batch: 180; loss: 1.25; acc: 0.61
Batch: 200; loss: 1.4; acc: 0.56
Batch: 220; loss: 1.32; acc: 0.52
Batch: 240; loss: 1.31; acc: 0.56
Batch: 260; loss: 1.28; acc: 0.55
Batch: 280; loss: 1.64; acc: 0.47
Batch: 300; loss: 1.25; acc: 0.56
Batch: 320; loss: 1.33; acc: 0.56
Batch: 340; loss: 1.23; acc: 0.64
Batch: 360; loss: 1.21; acc: 0.59
Batch: 380; loss: 1.3; acc: 0.56
Batch: 400; loss: 1.13; acc: 0.64
Batch: 420; loss: 1.4; acc: 0.53
Batch: 440; loss: 1.05; acc: 0.67
Batch: 460; loss: 1.39; acc: 0.48
Batch: 480; loss: 1.43; acc: 0.5
Batch: 500; loss: 1.23; acc: 0.53
Batch: 520; loss: 1.5; acc: 0.52
Batch: 540; loss: 1.55; acc: 0.44
Batch: 560; loss: 1.08; acc: 0.66
Batch: 580; loss: 1.38; acc: 0.5
Batch: 600; loss: 1.3; acc: 0.52
Batch: 620; loss: 1.33; acc: 0.56
Batch: 640; loss: 1.81; acc: 0.36
Batch: 660; loss: 1.47; acc: 0.42
Batch: 680; loss: 1.21; acc: 0.61
Batch: 700; loss: 1.37; acc: 0.52
Batch: 720; loss: 1.23; acc: 0.55
Batch: 740; loss: 1.31; acc: 0.53
Batch: 760; loss: 1.52; acc: 0.48
Batch: 780; loss: 1.4; acc: 0.53
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.52
Batch: 20; loss: 1.39; acc: 0.52
Batch: 40; loss: 0.9; acc: 0.73
Batch: 60; loss: 1.34; acc: 0.59
Batch: 80; loss: 1.02; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.56
Batch: 120; loss: 1.36; acc: 0.55
Batch: 140; loss: 0.94; acc: 0.64
Val Epoch over. val_loss: 1.3246435876105243; val_accuracy: 0.5638933121019108 

The current subspace-distance is: 6.168046820675954e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.47; acc: 0.48
Batch: 20; loss: 1.31; acc: 0.59
Batch: 40; loss: 1.62; acc: 0.48
Batch: 60; loss: 1.31; acc: 0.53
Batch: 80; loss: 1.42; acc: 0.53
Batch: 100; loss: 1.3; acc: 0.58
Batch: 120; loss: 1.53; acc: 0.5
Batch: 140; loss: 1.37; acc: 0.62
Batch: 160; loss: 1.35; acc: 0.5
Batch: 180; loss: 1.52; acc: 0.55
Batch: 200; loss: 1.51; acc: 0.55
Batch: 220; loss: 1.6; acc: 0.52
Batch: 240; loss: 1.19; acc: 0.61
Batch: 260; loss: 1.31; acc: 0.55
Batch: 280; loss: 1.42; acc: 0.5
Batch: 300; loss: 1.54; acc: 0.44
Batch: 320; loss: 1.3; acc: 0.61
Batch: 340; loss: 1.49; acc: 0.53
Batch: 360; loss: 1.41; acc: 0.52
Batch: 380; loss: 1.34; acc: 0.5
Batch: 400; loss: 1.19; acc: 0.56
Batch: 420; loss: 1.3; acc: 0.53
Batch: 440; loss: 1.39; acc: 0.55
Batch: 460; loss: 1.33; acc: 0.52
Batch: 480; loss: 1.35; acc: 0.53
Batch: 500; loss: 1.44; acc: 0.53
Batch: 520; loss: 1.43; acc: 0.53
Batch: 540; loss: 1.61; acc: 0.45
Batch: 560; loss: 1.39; acc: 0.52
Batch: 580; loss: 1.05; acc: 0.66
Batch: 600; loss: 1.23; acc: 0.53
Batch: 620; loss: 1.22; acc: 0.64
Batch: 640; loss: 1.49; acc: 0.59
Batch: 660; loss: 1.31; acc: 0.53
Batch: 680; loss: 1.56; acc: 0.45
Batch: 700; loss: 1.21; acc: 0.48
Batch: 720; loss: 1.42; acc: 0.52
Batch: 740; loss: 1.39; acc: 0.53
Batch: 760; loss: 1.33; acc: 0.58
Batch: 780; loss: 1.56; acc: 0.42
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

Batch: 0; loss: 1.25; acc: 0.5
Batch: 20; loss: 1.4; acc: 0.52
Batch: 40; loss: 0.9; acc: 0.73
Batch: 60; loss: 1.34; acc: 0.59
Batch: 80; loss: 1.01; acc: 0.59
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.35; acc: 0.53
Batch: 140; loss: 0.94; acc: 0.66
Val Epoch over. val_loss: 1.3226193462967113; val_accuracy: 0.5646894904458599 

The current subspace-distance is: 6.350217154249549e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.3; acc: 0.56
Batch: 20; loss: 1.45; acc: 0.47
Batch: 40; loss: 1.36; acc: 0.47
Batch: 60; loss: 1.44; acc: 0.48
Batch: 80; loss: 1.06; acc: 0.59
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.43; acc: 0.5
Batch: 140; loss: 1.41; acc: 0.56
Batch: 160; loss: 1.37; acc: 0.52
Batch: 180; loss: 1.66; acc: 0.45
Batch: 200; loss: 1.47; acc: 0.52
Batch: 220; loss: 1.53; acc: 0.45
Batch: 240; loss: 1.45; acc: 0.58
Batch: 260; loss: 1.37; acc: 0.55
Batch: 280; loss: 1.61; acc: 0.42
Batch: 300; loss: 1.42; acc: 0.5
Batch: 320; loss: 1.24; acc: 0.58
Batch: 340; loss: 1.49; acc: 0.5
Batch: 360; loss: 1.28; acc: 0.52
Batch: 380; loss: 1.37; acc: 0.52
Batch: 400; loss: 1.31; acc: 0.55
Batch: 420; loss: 1.45; acc: 0.48
Batch: 440; loss: 1.5; acc: 0.47
Batch: 460; loss: 1.31; acc: 0.61
Batch: 480; loss: 1.2; acc: 0.59
Batch: 500; loss: 1.28; acc: 0.56
Batch: 520; loss: 1.39; acc: 0.47
Batch: 540; loss: 1.55; acc: 0.47
Batch: 560; loss: 1.33; acc: 0.52
Batch: 580; loss: 1.34; acc: 0.53
Batch: 600; loss: 1.41; acc: 0.53
Batch: 620; loss: 1.3; acc: 0.58
Batch: 640; loss: 1.4; acc: 0.58
Batch: 660; loss: 1.2; acc: 0.61
Batch: 680; loss: 1.49; acc: 0.48
Batch: 700; loss: 1.35; acc: 0.53
Batch: 720; loss: 1.43; acc: 0.61
Batch: 740; loss: 1.18; acc: 0.55
Batch: 760; loss: 1.42; acc: 0.55
Batch: 780; loss: 1.32; acc: 0.55
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.47
Batch: 20; loss: 1.41; acc: 0.53
Batch: 40; loss: 0.9; acc: 0.75
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.01; acc: 0.61
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.35; acc: 0.52
Batch: 140; loss: 0.93; acc: 0.67
Val Epoch over. val_loss: 1.3225417015658822; val_accuracy: 0.5620023885350318 

The current subspace-distance is: 6.397338438546285e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.48; acc: 0.44
Batch: 20; loss: 1.14; acc: 0.66
Batch: 40; loss: 1.33; acc: 0.5
Batch: 60; loss: 1.32; acc: 0.59
Batch: 80; loss: 1.44; acc: 0.47
Batch: 100; loss: 1.51; acc: 0.45
Batch: 120; loss: 1.46; acc: 0.55
Batch: 140; loss: 1.5; acc: 0.45
Batch: 160; loss: 1.29; acc: 0.52
Batch: 180; loss: 1.39; acc: 0.5
Batch: 200; loss: 1.54; acc: 0.41
Batch: 220; loss: 1.64; acc: 0.39
Batch: 240; loss: 1.51; acc: 0.42
Batch: 260; loss: 1.39; acc: 0.53
Batch: 280; loss: 1.32; acc: 0.56
Batch: 300; loss: 1.46; acc: 0.47
Batch: 320; loss: 1.46; acc: 0.55
Batch: 340; loss: 1.25; acc: 0.52
Batch: 360; loss: 1.42; acc: 0.59
Batch: 380; loss: 1.95; acc: 0.47
Batch: 400; loss: 1.51; acc: 0.52
Batch: 420; loss: 1.41; acc: 0.53
Batch: 440; loss: 1.42; acc: 0.55
Batch: 460; loss: 1.4; acc: 0.55
Batch: 480; loss: 1.19; acc: 0.62
Batch: 500; loss: 1.48; acc: 0.48
Batch: 520; loss: 1.18; acc: 0.64
Batch: 540; loss: 1.54; acc: 0.44
Batch: 560; loss: 1.34; acc: 0.59
Batch: 580; loss: 1.12; acc: 0.64
Batch: 600; loss: 1.11; acc: 0.58
Batch: 620; loss: 1.36; acc: 0.45
Batch: 640; loss: 1.29; acc: 0.56
Batch: 660; loss: 1.32; acc: 0.61
Batch: 680; loss: 1.41; acc: 0.58
Batch: 700; loss: 1.4; acc: 0.55
Batch: 720; loss: 1.29; acc: 0.61
Batch: 740; loss: 1.33; acc: 0.55
Batch: 760; loss: 1.26; acc: 0.5
Batch: 780; loss: 1.32; acc: 0.55
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.5
Batch: 20; loss: 1.39; acc: 0.53
Batch: 40; loss: 0.9; acc: 0.77
Batch: 60; loss: 1.37; acc: 0.56
Batch: 80; loss: 1.0; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.58
Batch: 120; loss: 1.35; acc: 0.53
Batch: 140; loss: 0.92; acc: 0.67
Val Epoch over. val_loss: 1.3215372790196898; val_accuracy: 0.5630971337579618 

The current subspace-distance is: 6.507508805952966e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.65; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.53
Batch: 40; loss: 1.21; acc: 0.58
Batch: 60; loss: 1.32; acc: 0.62
Batch: 80; loss: 1.65; acc: 0.41
Batch: 100; loss: 1.36; acc: 0.5
Batch: 120; loss: 1.64; acc: 0.47
Batch: 140; loss: 1.33; acc: 0.53
Batch: 160; loss: 1.41; acc: 0.53
Batch: 180; loss: 1.2; acc: 0.56
Batch: 200; loss: 1.33; acc: 0.45
Batch: 220; loss: 1.37; acc: 0.47
Batch: 240; loss: 1.46; acc: 0.52
Batch: 260; loss: 1.51; acc: 0.48
Batch: 280; loss: 1.33; acc: 0.61
Batch: 300; loss: 1.53; acc: 0.58
Batch: 320; loss: 1.37; acc: 0.52
Batch: 340; loss: 1.35; acc: 0.55
Batch: 360; loss: 1.38; acc: 0.55
Batch: 380; loss: 1.43; acc: 0.55
Batch: 400; loss: 1.2; acc: 0.58
Batch: 420; loss: 1.34; acc: 0.55
Batch: 440; loss: 1.29; acc: 0.53
Batch: 460; loss: 1.53; acc: 0.52
Batch: 480; loss: 1.49; acc: 0.53
Batch: 500; loss: 1.4; acc: 0.5
Batch: 520; loss: 1.56; acc: 0.42
Batch: 540; loss: 1.4; acc: 0.53
Batch: 560; loss: 1.39; acc: 0.53
Batch: 580; loss: 1.21; acc: 0.56
Batch: 600; loss: 1.28; acc: 0.62
Batch: 620; loss: 1.29; acc: 0.64
Batch: 640; loss: 1.33; acc: 0.56
Batch: 660; loss: 1.32; acc: 0.58
Batch: 680; loss: 1.2; acc: 0.66
Batch: 700; loss: 1.36; acc: 0.5
Batch: 720; loss: 1.21; acc: 0.58
Batch: 740; loss: 1.57; acc: 0.42
Batch: 760; loss: 1.24; acc: 0.58
Batch: 780; loss: 1.27; acc: 0.58
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

Batch: 0; loss: 1.25; acc: 0.47
Batch: 20; loss: 1.38; acc: 0.53
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 1.36; acc: 0.58
Batch: 80; loss: 1.0; acc: 0.61
Batch: 100; loss: 1.33; acc: 0.55
Batch: 120; loss: 1.33; acc: 0.55
Batch: 140; loss: 0.9; acc: 0.67
Val Epoch over. val_loss: 1.3190662431868778; val_accuracy: 0.5659832802547771 

The current subspace-distance is: 6.926064088474959e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.31; acc: 0.66
Batch: 20; loss: 1.59; acc: 0.41
Batch: 40; loss: 1.38; acc: 0.52
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.24; acc: 0.66
Batch: 100; loss: 1.46; acc: 0.5
Batch: 120; loss: 1.46; acc: 0.48
Batch: 140; loss: 1.44; acc: 0.52
Batch: 160; loss: 1.3; acc: 0.59
Batch: 180; loss: 1.2; acc: 0.58
Batch: 200; loss: 1.56; acc: 0.39
Batch: 220; loss: 1.29; acc: 0.56
Batch: 240; loss: 1.34; acc: 0.52
Batch: 260; loss: 1.12; acc: 0.58
Batch: 280; loss: 1.49; acc: 0.48
Batch: 300; loss: 1.52; acc: 0.48
Batch: 320; loss: 1.64; acc: 0.44
Batch: 340; loss: 1.37; acc: 0.55
Batch: 360; loss: 1.51; acc: 0.52
Batch: 380; loss: 1.43; acc: 0.52
Batch: 400; loss: 1.46; acc: 0.56
Batch: 420; loss: 1.44; acc: 0.53
Batch: 440; loss: 1.29; acc: 0.62
Batch: 460; loss: 1.85; acc: 0.34
Batch: 480; loss: 1.46; acc: 0.5
Batch: 500; loss: 1.2; acc: 0.59
Batch: 520; loss: 1.75; acc: 0.44
Batch: 540; loss: 1.23; acc: 0.56
Batch: 560; loss: 1.43; acc: 0.5
Batch: 580; loss: 1.36; acc: 0.5
Batch: 600; loss: 1.26; acc: 0.58
Batch: 620; loss: 1.36; acc: 0.55
Batch: 640; loss: 1.68; acc: 0.42
Batch: 660; loss: 1.47; acc: 0.47
Batch: 680; loss: 1.37; acc: 0.55
Batch: 700; loss: 1.29; acc: 0.64
Batch: 720; loss: 1.6; acc: 0.48
Batch: 740; loss: 1.22; acc: 0.55
Batch: 760; loss: 1.35; acc: 0.61
Batch: 780; loss: 1.39; acc: 0.48
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.52
Batch: 40; loss: 0.87; acc: 0.72
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.99; acc: 0.62
Batch: 100; loss: 1.34; acc: 0.58
Batch: 120; loss: 1.33; acc: 0.55
Batch: 140; loss: 0.89; acc: 0.67
Val Epoch over. val_loss: 1.316929183568165; val_accuracy: 0.5677746815286624 

The current subspace-distance is: 6.932638643775135e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.3; acc: 0.64
Batch: 20; loss: 1.57; acc: 0.56
Batch: 40; loss: 1.34; acc: 0.53
Batch: 60; loss: 1.38; acc: 0.5
Batch: 80; loss: 1.15; acc: 0.59
Batch: 100; loss: 1.28; acc: 0.58
Batch: 120; loss: 1.47; acc: 0.39
Batch: 140; loss: 1.4; acc: 0.56
Batch: 160; loss: 1.44; acc: 0.47
Batch: 180; loss: 1.32; acc: 0.55
Batch: 200; loss: 1.13; acc: 0.61
Batch: 220; loss: 1.44; acc: 0.56
Batch: 240; loss: 1.01; acc: 0.64
Batch: 260; loss: 1.35; acc: 0.5
Batch: 280; loss: 1.06; acc: 0.67
Batch: 300; loss: 1.31; acc: 0.56
Batch: 320; loss: 1.67; acc: 0.45
Batch: 340; loss: 1.3; acc: 0.52
Batch: 360; loss: 1.46; acc: 0.53
Batch: 380; loss: 1.36; acc: 0.53
Batch: 400; loss: 1.47; acc: 0.47
Batch: 420; loss: 1.52; acc: 0.53
Batch: 440; loss: 1.25; acc: 0.61
Batch: 460; loss: 1.53; acc: 0.47
Batch: 480; loss: 1.24; acc: 0.61
Batch: 500; loss: 1.29; acc: 0.56
Batch: 520; loss: 1.34; acc: 0.62
Batch: 540; loss: 1.19; acc: 0.58
Batch: 560; loss: 1.5; acc: 0.52
Batch: 580; loss: 1.52; acc: 0.55
Batch: 600; loss: 1.17; acc: 0.67
Batch: 620; loss: 1.27; acc: 0.62
Batch: 640; loss: 1.29; acc: 0.67
Batch: 660; loss: 1.07; acc: 0.7
Batch: 680; loss: 1.11; acc: 0.62
Batch: 700; loss: 1.09; acc: 0.66
Batch: 720; loss: 1.27; acc: 0.64
Batch: 740; loss: 1.41; acc: 0.53
Batch: 760; loss: 1.21; acc: 0.59
Batch: 780; loss: 1.29; acc: 0.56
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.47
Batch: 20; loss: 1.41; acc: 0.52
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.99; acc: 0.64
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.32; acc: 0.53
Batch: 140; loss: 0.88; acc: 0.7
Val Epoch over. val_loss: 1.3156251246762123; val_accuracy: 0.5665804140127388 

The current subspace-distance is: 7.025958620943129e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.22; acc: 0.62
Batch: 20; loss: 1.36; acc: 0.52
Batch: 40; loss: 1.58; acc: 0.48
Batch: 60; loss: 1.57; acc: 0.53
Batch: 80; loss: 1.5; acc: 0.47
Batch: 100; loss: 1.24; acc: 0.59
Batch: 120; loss: 1.41; acc: 0.48
Batch: 140; loss: 1.17; acc: 0.69
Batch: 160; loss: 1.51; acc: 0.48
Batch: 180; loss: 1.34; acc: 0.52
Batch: 200; loss: 1.49; acc: 0.47
Batch: 220; loss: 1.33; acc: 0.55
Batch: 240; loss: 1.2; acc: 0.58
Batch: 260; loss: 1.31; acc: 0.58
Batch: 280; loss: 1.32; acc: 0.5
Batch: 300; loss: 1.46; acc: 0.47
Batch: 320; loss: 1.22; acc: 0.55
Batch: 340; loss: 1.38; acc: 0.56
Batch: 360; loss: 1.53; acc: 0.53
Batch: 380; loss: 1.36; acc: 0.53
Batch: 400; loss: 1.16; acc: 0.61
Batch: 420; loss: 1.4; acc: 0.5
Batch: 440; loss: 1.49; acc: 0.44
Batch: 460; loss: 1.16; acc: 0.62
Batch: 480; loss: 1.57; acc: 0.58
Batch: 500; loss: 1.26; acc: 0.56
Batch: 520; loss: 1.26; acc: 0.59
Batch: 540; loss: 1.0; acc: 0.66
Batch: 560; loss: 1.49; acc: 0.47
Batch: 580; loss: 1.38; acc: 0.53
Batch: 600; loss: 1.47; acc: 0.45
Batch: 620; loss: 1.25; acc: 0.61
Batch: 640; loss: 1.25; acc: 0.59
Batch: 660; loss: 1.31; acc: 0.53
Batch: 680; loss: 1.21; acc: 0.5
Batch: 700; loss: 1.5; acc: 0.48
Batch: 720; loss: 1.42; acc: 0.5
Batch: 740; loss: 1.25; acc: 0.59
Batch: 760; loss: 1.54; acc: 0.41
Batch: 780; loss: 1.34; acc: 0.61
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.27; acc: 0.5
Batch: 20; loss: 1.43; acc: 0.53
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 1.35; acc: 0.62
Batch: 80; loss: 0.98; acc: 0.62
Batch: 100; loss: 1.34; acc: 0.52
Batch: 120; loss: 1.31; acc: 0.55
Batch: 140; loss: 0.88; acc: 0.69
Val Epoch over. val_loss: 1.315239703199666; val_accuracy: 0.5652866242038217 

The current subspace-distance is: 7.171286415541545e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.64; acc: 0.5
Batch: 20; loss: 1.44; acc: 0.53
Batch: 40; loss: 1.49; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.52
Batch: 80; loss: 1.32; acc: 0.55
Batch: 100; loss: 1.35; acc: 0.53
Batch: 120; loss: 1.32; acc: 0.56
Batch: 140; loss: 1.29; acc: 0.58
Batch: 160; loss: 1.54; acc: 0.45
Batch: 180; loss: 1.26; acc: 0.59
Batch: 200; loss: 1.23; acc: 0.53
Batch: 220; loss: 1.39; acc: 0.55
Batch: 240; loss: 1.39; acc: 0.52
Batch: 260; loss: 1.27; acc: 0.61
Batch: 280; loss: 1.27; acc: 0.55
Batch: 300; loss: 1.7; acc: 0.44
Batch: 320; loss: 1.26; acc: 0.61
Batch: 340; loss: 1.38; acc: 0.58
Batch: 360; loss: 1.32; acc: 0.58
Batch: 380; loss: 1.38; acc: 0.58
Batch: 400; loss: 1.21; acc: 0.61
Batch: 420; loss: 1.26; acc: 0.55
Batch: 440; loss: 1.23; acc: 0.58
Batch: 460; loss: 1.23; acc: 0.59
Batch: 480; loss: 1.18; acc: 0.61
Batch: 500; loss: 1.16; acc: 0.58
Batch: 520; loss: 1.39; acc: 0.56
Batch: 540; loss: 1.35; acc: 0.52
Batch: 560; loss: 1.44; acc: 0.44
Batch: 580; loss: 1.29; acc: 0.58
Batch: 600; loss: 1.09; acc: 0.59
Batch: 620; loss: 1.23; acc: 0.56
Batch: 640; loss: 1.44; acc: 0.5
Batch: 660; loss: 1.33; acc: 0.55
Batch: 680; loss: 1.52; acc: 0.52
Batch: 700; loss: 1.36; acc: 0.55
Batch: 720; loss: 1.49; acc: 0.52
Batch: 740; loss: 1.12; acc: 0.67
Batch: 760; loss: 1.47; acc: 0.53
Batch: 780; loss: 1.4; acc: 0.45
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.27; acc: 0.48
Batch: 20; loss: 1.39; acc: 0.52
Batch: 40; loss: 0.85; acc: 0.72
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.99; acc: 0.67
Batch: 100; loss: 1.34; acc: 0.52
Batch: 120; loss: 1.31; acc: 0.55
Batch: 140; loss: 0.85; acc: 0.7
Val Epoch over. val_loss: 1.31465960460104; val_accuracy: 0.5683718152866242 

The current subspace-distance is: 7.181335968198255e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.6; acc: 0.48
Batch: 20; loss: 1.29; acc: 0.59
Batch: 40; loss: 1.4; acc: 0.55
Batch: 60; loss: 1.59; acc: 0.45
Batch: 80; loss: 1.19; acc: 0.56
Batch: 100; loss: 1.46; acc: 0.52
Batch: 120; loss: 1.61; acc: 0.53
Batch: 140; loss: 1.37; acc: 0.55
Batch: 160; loss: 1.42; acc: 0.44
Batch: 180; loss: 1.3; acc: 0.61
Batch: 200; loss: 1.3; acc: 0.59
Batch: 220; loss: 1.5; acc: 0.42
Batch: 240; loss: 1.01; acc: 0.69
Batch: 260; loss: 1.4; acc: 0.45
Batch: 280; loss: 1.29; acc: 0.59
Batch: 300; loss: 1.51; acc: 0.55
Batch: 320; loss: 1.24; acc: 0.64
Batch: 340; loss: 1.35; acc: 0.56
Batch: 360; loss: 1.3; acc: 0.53
Batch: 380; loss: 1.28; acc: 0.52
Batch: 400; loss: 1.31; acc: 0.55
Batch: 420; loss: 1.43; acc: 0.45
Batch: 440; loss: 1.28; acc: 0.55
Batch: 460; loss: 1.29; acc: 0.55
Batch: 480; loss: 1.24; acc: 0.61
Batch: 500; loss: 1.43; acc: 0.48
Batch: 520; loss: 1.62; acc: 0.52
Batch: 540; loss: 1.09; acc: 0.69
Batch: 560; loss: 1.07; acc: 0.69
Batch: 580; loss: 1.32; acc: 0.53
Batch: 600; loss: 1.28; acc: 0.56
Batch: 620; loss: 1.47; acc: 0.45
Batch: 640; loss: 1.26; acc: 0.56
Batch: 660; loss: 1.37; acc: 0.52
Batch: 680; loss: 1.61; acc: 0.47
Batch: 700; loss: 1.25; acc: 0.59
Batch: 720; loss: 1.32; acc: 0.56
Batch: 740; loss: 1.29; acc: 0.59
Batch: 760; loss: 1.37; acc: 0.58
Batch: 780; loss: 1.34; acc: 0.56
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.27; acc: 0.47
Batch: 20; loss: 1.41; acc: 0.52
Batch: 40; loss: 0.87; acc: 0.7
Batch: 60; loss: 1.37; acc: 0.61
Batch: 80; loss: 0.98; acc: 0.69
Batch: 100; loss: 1.34; acc: 0.5
Batch: 120; loss: 1.31; acc: 0.55
Batch: 140; loss: 0.86; acc: 0.72
Val Epoch over. val_loss: 1.311293710568908; val_accuracy: 0.5698646496815286 

The current subspace-distance is: 7.160771201597527e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.4; acc: 0.62
Batch: 20; loss: 1.55; acc: 0.56
Batch: 40; loss: 1.4; acc: 0.52
Batch: 60; loss: 1.23; acc: 0.56
Batch: 80; loss: 1.29; acc: 0.62
Batch: 100; loss: 1.55; acc: 0.5
Batch: 120; loss: 1.43; acc: 0.48
Batch: 140; loss: 1.31; acc: 0.52
Batch: 160; loss: 1.49; acc: 0.5
Batch: 180; loss: 1.36; acc: 0.5
Batch: 200; loss: 1.39; acc: 0.47
Batch: 220; loss: 1.24; acc: 0.58
Batch: 240; loss: 1.51; acc: 0.47
Batch: 260; loss: 1.4; acc: 0.53
Batch: 280; loss: 1.17; acc: 0.59
Batch: 300; loss: 1.3; acc: 0.52
Batch: 320; loss: 1.32; acc: 0.61
Batch: 340; loss: 1.37; acc: 0.58
Batch: 360; loss: 1.21; acc: 0.55
Batch: 380; loss: 1.51; acc: 0.55
Batch: 400; loss: 1.4; acc: 0.52
Batch: 420; loss: 1.67; acc: 0.5
Batch: 440; loss: 1.31; acc: 0.62
Batch: 460; loss: 1.54; acc: 0.52
Batch: 480; loss: 1.27; acc: 0.52
Batch: 500; loss: 1.33; acc: 0.48
Batch: 520; loss: 1.21; acc: 0.58
Batch: 540; loss: 1.25; acc: 0.56
Batch: 560; loss: 1.6; acc: 0.42
Batch: 580; loss: 1.56; acc: 0.39
Batch: 600; loss: 1.45; acc: 0.52
Batch: 620; loss: 1.24; acc: 0.58
Batch: 640; loss: 1.5; acc: 0.55
Batch: 660; loss: 1.34; acc: 0.45
Batch: 680; loss: 1.56; acc: 0.47
Batch: 700; loss: 1.47; acc: 0.61
Batch: 720; loss: 1.21; acc: 0.61
Batch: 740; loss: 1.21; acc: 0.56
Batch: 760; loss: 1.19; acc: 0.56
Batch: 780; loss: 1.36; acc: 0.56
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.26; acc: 0.47
Batch: 20; loss: 1.39; acc: 0.52
Batch: 40; loss: 0.86; acc: 0.7
Batch: 60; loss: 1.36; acc: 0.62
Batch: 80; loss: 0.98; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.31; acc: 0.55
Batch: 140; loss: 0.86; acc: 0.7
Val Epoch over. val_loss: 1.3103412925058109; val_accuracy: 0.5731488853503185 

The current subspace-distance is: 7.360117160715163e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.52; acc: 0.45
Batch: 20; loss: 1.2; acc: 0.61
Batch: 40; loss: 1.4; acc: 0.52
Batch: 60; loss: 1.23; acc: 0.52
Batch: 80; loss: 1.35; acc: 0.56
Batch: 100; loss: 1.24; acc: 0.64
Batch: 120; loss: 1.16; acc: 0.61
Batch: 140; loss: 1.44; acc: 0.53
Batch: 160; loss: 1.23; acc: 0.64
Batch: 180; loss: 1.36; acc: 0.52
Batch: 200; loss: 1.59; acc: 0.47
Batch: 220; loss: 1.31; acc: 0.55
Batch: 240; loss: 1.28; acc: 0.56
Batch: 260; loss: 1.4; acc: 0.55
Batch: 280; loss: 1.42; acc: 0.55
Batch: 300; loss: 1.36; acc: 0.59
Batch: 320; loss: 0.94; acc: 0.69
Batch: 340; loss: 1.41; acc: 0.58
Batch: 360; loss: 1.44; acc: 0.56
Batch: 380; loss: 1.25; acc: 0.58
Batch: 400; loss: 1.42; acc: 0.48
Batch: 420; loss: 1.27; acc: 0.55
Batch: 440; loss: 1.53; acc: 0.47
Batch: 460; loss: 1.37; acc: 0.61
Batch: 480; loss: 1.23; acc: 0.58
Batch: 500; loss: 1.4; acc: 0.5
Batch: 520; loss: 1.19; acc: 0.59
Batch: 540; loss: 1.39; acc: 0.58
Batch: 560; loss: 1.34; acc: 0.56
Batch: 580; loss: 1.23; acc: 0.62
Batch: 600; loss: 1.33; acc: 0.53
Batch: 620; loss: 1.49; acc: 0.48
Batch: 640; loss: 1.25; acc: 0.56
Batch: 660; loss: 1.26; acc: 0.53
Batch: 680; loss: 1.4; acc: 0.5
Batch: 700; loss: 1.31; acc: 0.5
Batch: 720; loss: 1.61; acc: 0.44
Batch: 740; loss: 1.28; acc: 0.66
Batch: 760; loss: 1.59; acc: 0.52
Batch: 780; loss: 1.39; acc: 0.5
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.27; acc: 0.47
Batch: 20; loss: 1.4; acc: 0.52
Batch: 40; loss: 0.86; acc: 0.7
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.98; acc: 0.66
Batch: 100; loss: 1.34; acc: 0.48
Batch: 120; loss: 1.31; acc: 0.53
Batch: 140; loss: 0.85; acc: 0.7
Val Epoch over. val_loss: 1.3109118084239353; val_accuracy: 0.5696656050955414 

The current subspace-distance is: 7.544810068793595e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.53; acc: 0.44
Batch: 20; loss: 1.43; acc: 0.58
Batch: 40; loss: 1.38; acc: 0.56
Batch: 60; loss: 1.53; acc: 0.44
Batch: 80; loss: 1.65; acc: 0.45
Batch: 100; loss: 1.54; acc: 0.5
Batch: 120; loss: 1.44; acc: 0.52
Batch: 140; loss: 1.6; acc: 0.44
Batch: 160; loss: 1.7; acc: 0.52
Batch: 180; loss: 1.21; acc: 0.62
Batch: 200; loss: 1.46; acc: 0.56
Batch: 220; loss: 1.38; acc: 0.53
Batch: 240; loss: 1.23; acc: 0.58
Batch: 260; loss: 1.35; acc: 0.58
Batch: 280; loss: 1.46; acc: 0.41
Batch: 300; loss: 1.19; acc: 0.61
Batch: 320; loss: 1.3; acc: 0.62
Batch: 340; loss: 1.21; acc: 0.55
Batch: 360; loss: 1.15; acc: 0.62
Batch: 380; loss: 1.48; acc: 0.48
Batch: 400; loss: 1.1; acc: 0.77
Batch: 420; loss: 1.41; acc: 0.48
Batch: 440; loss: 1.42; acc: 0.48
Batch: 460; loss: 1.6; acc: 0.41
Batch: 480; loss: 1.37; acc: 0.53
Batch: 500; loss: 1.3; acc: 0.5
Batch: 520; loss: 1.43; acc: 0.53
Batch: 540; loss: 1.32; acc: 0.58
Batch: 560; loss: 1.52; acc: 0.45
Batch: 580; loss: 1.4; acc: 0.59
Batch: 600; loss: 1.23; acc: 0.59
Batch: 620; loss: 1.11; acc: 0.56
Batch: 640; loss: 1.25; acc: 0.59
Batch: 660; loss: 1.32; acc: 0.53
Batch: 680; loss: 1.33; acc: 0.5
Batch: 700; loss: 1.17; acc: 0.58
Batch: 720; loss: 1.47; acc: 0.48
Batch: 740; loss: 1.18; acc: 0.62
Batch: 760; loss: 1.45; acc: 0.47
Batch: 780; loss: 1.41; acc: 0.45
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.27; acc: 0.47
Batch: 20; loss: 1.4; acc: 0.52
Batch: 40; loss: 0.86; acc: 0.72
Batch: 60; loss: 1.37; acc: 0.62
Batch: 80; loss: 0.99; acc: 0.69
Batch: 100; loss: 1.34; acc: 0.52
Batch: 120; loss: 1.32; acc: 0.55
Batch: 140; loss: 0.85; acc: 0.72
Val Epoch over. val_loss: 1.311516959955738; val_accuracy: 0.5711584394904459 

The current subspace-distance is: 7.576421194244176e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.17; acc: 0.62
Batch: 20; loss: 1.46; acc: 0.5
Batch: 40; loss: 1.18; acc: 0.61
Batch: 60; loss: 1.33; acc: 0.53
Batch: 80; loss: 1.47; acc: 0.56
Batch: 100; loss: 1.29; acc: 0.61
Batch: 120; loss: 1.59; acc: 0.44
Batch: 140; loss: 1.15; acc: 0.56
Batch: 160; loss: 1.22; acc: 0.58
Batch: 180; loss: 1.31; acc: 0.61
Batch: 200; loss: 1.31; acc: 0.62
Batch: 220; loss: 1.46; acc: 0.53
Batch: 240; loss: 1.43; acc: 0.59
Batch: 260; loss: 1.37; acc: 0.48
Batch: 280; loss: 1.28; acc: 0.53
Batch: 300; loss: 1.37; acc: 0.47
Batch: 320; loss: 1.17; acc: 0.59
Batch: 340; loss: 1.33; acc: 0.58
Batch: 360; loss: 1.3; acc: 0.59
Batch: 380; loss: 1.13; acc: 0.66
Batch: 400; loss: 1.37; acc: 0.55
Batch: 420; loss: 1.43; acc: 0.42
Batch: 440; loss: 1.22; acc: 0.62
Batch: 460; loss: 1.43; acc: 0.5
Batch: 480; loss: 1.46; acc: 0.59
Batch: 500; loss: 1.41; acc: 0.56
Batch: 520; loss: 1.63; acc: 0.31
Batch: 540; loss: 1.51; acc: 0.48
Batch: 560; loss: 1.36; acc: 0.55
Batch: 580; loss: 1.37; acc: 0.5
Batch: 600; loss: 1.57; acc: 0.42
Batch: 620; loss: 1.25; acc: 0.56
Batch: 640; loss: 1.33; acc: 0.53
Batch: 660; loss: 1.46; acc: 0.56
Batch: 680; loss: 1.56; acc: 0.47
Batch: 700; loss: 1.44; acc: 0.53
Batch: 720; loss: 1.49; acc: 0.5
Batch: 740; loss: 1.59; acc: 0.45
Batch: 760; loss: 1.24; acc: 0.61
Batch: 780; loss: 1.35; acc: 0.53
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.27; acc: 0.48
Batch: 20; loss: 1.41; acc: 0.48
Batch: 40; loss: 0.87; acc: 0.72
Batch: 60; loss: 1.37; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.34; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.56
Batch: 140; loss: 0.86; acc: 0.72
Val Epoch over. val_loss: 1.3090737575937987; val_accuracy: 0.5723527070063694 

The current subspace-distance is: 7.770309457555413e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.27; acc: 0.5
Batch: 20; loss: 1.23; acc: 0.58
Batch: 40; loss: 1.3; acc: 0.55
Batch: 60; loss: 1.45; acc: 0.48
Batch: 80; loss: 1.25; acc: 0.59
Batch: 100; loss: 1.29; acc: 0.56
Batch: 120; loss: 1.66; acc: 0.44
Batch: 140; loss: 1.31; acc: 0.55
Batch: 160; loss: 1.3; acc: 0.62
Batch: 180; loss: 1.47; acc: 0.47
Batch: 200; loss: 1.35; acc: 0.58
Batch: 220; loss: 1.45; acc: 0.5
Batch: 240; loss: 1.27; acc: 0.55
Batch: 260; loss: 1.33; acc: 0.59
Batch: 280; loss: 1.45; acc: 0.41
Batch: 300; loss: 1.51; acc: 0.5
Batch: 320; loss: 1.07; acc: 0.67
Batch: 340; loss: 1.63; acc: 0.48
Batch: 360; loss: 1.44; acc: 0.53
Batch: 380; loss: 1.41; acc: 0.47
Batch: 400; loss: 1.1; acc: 0.64
Batch: 420; loss: 1.38; acc: 0.58
Batch: 440; loss: 1.29; acc: 0.47
Batch: 460; loss: 1.42; acc: 0.61
Batch: 480; loss: 1.25; acc: 0.55
Batch: 500; loss: 1.28; acc: 0.55
Batch: 520; loss: 1.53; acc: 0.53
Batch: 540; loss: 1.47; acc: 0.55
Batch: 560; loss: 1.32; acc: 0.58
Batch: 580; loss: 1.25; acc: 0.56
Batch: 600; loss: 1.32; acc: 0.55
Batch: 620; loss: 1.21; acc: 0.59
Batch: 640; loss: 1.25; acc: 0.62
Batch: 660; loss: 1.39; acc: 0.59
Batch: 680; loss: 1.49; acc: 0.47
Batch: 700; loss: 1.51; acc: 0.53
Batch: 720; loss: 1.24; acc: 0.61
Batch: 740; loss: 1.43; acc: 0.61
Batch: 760; loss: 1.38; acc: 0.53
Batch: 780; loss: 1.28; acc: 0.61
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.27; acc: 0.5
Batch: 20; loss: 1.4; acc: 0.48
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.97; acc: 0.69
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.59
Batch: 140; loss: 0.85; acc: 0.72
Val Epoch over. val_loss: 1.3077594288595162; val_accuracy: 0.5728503184713376 

The current subspace-distance is: 8.0828984209802e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.55; acc: 0.52
Batch: 20; loss: 1.1; acc: 0.59
Batch: 40; loss: 0.92; acc: 0.78
Batch: 60; loss: 1.53; acc: 0.53
Batch: 80; loss: 1.27; acc: 0.59
Batch: 100; loss: 1.24; acc: 0.55
Batch: 120; loss: 1.53; acc: 0.53
Batch: 140; loss: 1.29; acc: 0.55
Batch: 160; loss: 1.33; acc: 0.55
Batch: 180; loss: 1.26; acc: 0.58
Batch: 200; loss: 1.52; acc: 0.52
Batch: 220; loss: 1.54; acc: 0.52
Batch: 240; loss: 1.5; acc: 0.52
Batch: 260; loss: 1.32; acc: 0.55
Batch: 280; loss: 1.39; acc: 0.52
Batch: 300; loss: 1.62; acc: 0.44
Batch: 320; loss: 1.07; acc: 0.66
Batch: 340; loss: 1.34; acc: 0.56
Batch: 360; loss: 1.38; acc: 0.52
Batch: 380; loss: 1.32; acc: 0.53
Batch: 400; loss: 1.13; acc: 0.62
Batch: 420; loss: 1.52; acc: 0.42
Batch: 440; loss: 1.23; acc: 0.59
Batch: 460; loss: 1.31; acc: 0.59
Batch: 480; loss: 1.43; acc: 0.52
Batch: 500; loss: 1.1; acc: 0.67
Batch: 520; loss: 1.43; acc: 0.5
Batch: 540; loss: 1.46; acc: 0.56
Batch: 560; loss: 1.58; acc: 0.53
Batch: 580; loss: 1.4; acc: 0.55
Batch: 600; loss: 1.15; acc: 0.66
Batch: 620; loss: 1.52; acc: 0.48
Batch: 640; loss: 1.06; acc: 0.67
Batch: 660; loss: 1.42; acc: 0.52
Batch: 680; loss: 1.31; acc: 0.59
Batch: 700; loss: 1.51; acc: 0.52
Batch: 720; loss: 1.45; acc: 0.56
Batch: 740; loss: 1.4; acc: 0.52
Batch: 760; loss: 1.27; acc: 0.61
Batch: 780; loss: 1.37; acc: 0.56
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 1.27; acc: 0.45
Batch: 20; loss: 1.4; acc: 0.48
Batch: 40; loss: 0.85; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.98; acc: 0.69
Batch: 100; loss: 1.32; acc: 0.52
Batch: 120; loss: 1.31; acc: 0.58
Batch: 140; loss: 0.84; acc: 0.73
Val Epoch over. val_loss: 1.3090270586833832; val_accuracy: 0.5722531847133758 

The current subspace-distance is: 8.140093996189535e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.68; acc: 0.48
Batch: 20; loss: 1.33; acc: 0.55
Batch: 40; loss: 1.03; acc: 0.72
Batch: 60; loss: 1.63; acc: 0.47
Batch: 80; loss: 1.28; acc: 0.52
Batch: 100; loss: 1.35; acc: 0.53
Batch: 120; loss: 1.45; acc: 0.52
Batch: 140; loss: 1.43; acc: 0.55
Batch: 160; loss: 1.13; acc: 0.64
Batch: 180; loss: 1.29; acc: 0.59
Batch: 200; loss: 1.44; acc: 0.56
Batch: 220; loss: 1.27; acc: 0.56
Batch: 240; loss: 1.29; acc: 0.52
Batch: 260; loss: 1.36; acc: 0.55
Batch: 280; loss: 1.27; acc: 0.58
Batch: 300; loss: 1.53; acc: 0.45
Batch: 320; loss: 1.48; acc: 0.53
Batch: 340; loss: 1.13; acc: 0.64
Batch: 360; loss: 1.28; acc: 0.59
Batch: 380; loss: 1.43; acc: 0.52
Batch: 400; loss: 1.29; acc: 0.5
Batch: 420; loss: 1.56; acc: 0.5
Batch: 440; loss: 1.17; acc: 0.53
Batch: 460; loss: 1.56; acc: 0.48
Batch: 480; loss: 1.18; acc: 0.67
Batch: 500; loss: 1.55; acc: 0.48
Batch: 520; loss: 1.43; acc: 0.45
Batch: 540; loss: 1.39; acc: 0.53
Batch: 560; loss: 1.56; acc: 0.55
Batch: 580; loss: 1.16; acc: 0.66
Batch: 600; loss: 1.57; acc: 0.55
Batch: 620; loss: 1.29; acc: 0.59
Batch: 640; loss: 1.39; acc: 0.55
Batch: 660; loss: 1.47; acc: 0.53
Batch: 680; loss: 1.25; acc: 0.61
Batch: 700; loss: 1.47; acc: 0.47
Batch: 720; loss: 1.18; acc: 0.61
Batch: 740; loss: 1.28; acc: 0.58
Batch: 760; loss: 1.47; acc: 0.45
Batch: 780; loss: 1.14; acc: 0.61
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.5
Batch: 20; loss: 1.4; acc: 0.52
Batch: 40; loss: 0.86; acc: 0.7
Batch: 60; loss: 1.37; acc: 0.61
Batch: 80; loss: 0.98; acc: 0.69
Batch: 100; loss: 1.33; acc: 0.53
Batch: 120; loss: 1.32; acc: 0.53
Batch: 140; loss: 0.85; acc: 0.73
Val Epoch over. val_loss: 1.308797299861908; val_accuracy: 0.5730493630573248 

The current subspace-distance is: 8.350985444849357e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.3; acc: 0.5
Batch: 20; loss: 1.34; acc: 0.56
Batch: 40; loss: 1.3; acc: 0.5
Batch: 60; loss: 1.38; acc: 0.55
Batch: 80; loss: 1.35; acc: 0.64
Batch: 100; loss: 1.51; acc: 0.5
Batch: 120; loss: 1.22; acc: 0.58
Batch: 140; loss: 1.18; acc: 0.62
Batch: 160; loss: 1.54; acc: 0.47
Batch: 180; loss: 1.56; acc: 0.47
Batch: 200; loss: 1.23; acc: 0.56
Batch: 220; loss: 1.5; acc: 0.5
Batch: 240; loss: 1.35; acc: 0.5
Batch: 260; loss: 1.18; acc: 0.69
Batch: 280; loss: 1.25; acc: 0.58
Batch: 300; loss: 1.47; acc: 0.48
Batch: 320; loss: 1.25; acc: 0.56
Batch: 340; loss: 1.49; acc: 0.53
Batch: 360; loss: 1.24; acc: 0.59
Batch: 380; loss: 1.27; acc: 0.53
Batch: 400; loss: 1.1; acc: 0.61
Batch: 420; loss: 1.56; acc: 0.45
Batch: 440; loss: 1.47; acc: 0.59
Batch: 460; loss: 1.23; acc: 0.61
Batch: 480; loss: 1.52; acc: 0.52
Batch: 500; loss: 1.09; acc: 0.67
Batch: 520; loss: 1.29; acc: 0.61
Batch: 540; loss: 1.24; acc: 0.69
Batch: 560; loss: 1.5; acc: 0.48
Batch: 580; loss: 1.31; acc: 0.56
Batch: 600; loss: 1.31; acc: 0.58
Batch: 620; loss: 1.32; acc: 0.66
Batch: 640; loss: 1.33; acc: 0.58
Batch: 660; loss: 1.28; acc: 0.55
Batch: 680; loss: 1.34; acc: 0.53
Batch: 700; loss: 1.35; acc: 0.52
Batch: 720; loss: 1.37; acc: 0.61
Batch: 740; loss: 1.34; acc: 0.58
Batch: 760; loss: 1.17; acc: 0.61
Batch: 780; loss: 1.22; acc: 0.58
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.47
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.98; acc: 0.69
Batch: 100; loss: 1.33; acc: 0.52
Batch: 120; loss: 1.32; acc: 0.55
Batch: 140; loss: 0.85; acc: 0.75
Val Epoch over. val_loss: 1.3069641946986983; val_accuracy: 0.5710589171974523 

The current subspace-distance is: 8.252502448158339e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.08; acc: 0.62
Batch: 20; loss: 1.42; acc: 0.53
Batch: 40; loss: 1.28; acc: 0.56
Batch: 60; loss: 1.24; acc: 0.62
Batch: 80; loss: 1.44; acc: 0.45
Batch: 100; loss: 1.22; acc: 0.59
Batch: 120; loss: 1.27; acc: 0.64
Batch: 140; loss: 1.29; acc: 0.55
Batch: 160; loss: 1.61; acc: 0.39
Batch: 180; loss: 1.5; acc: 0.48
Batch: 200; loss: 1.5; acc: 0.52
Batch: 220; loss: 1.03; acc: 0.69
Batch: 240; loss: 1.37; acc: 0.58
Batch: 260; loss: 1.38; acc: 0.5
Batch: 280; loss: 1.72; acc: 0.41
Batch: 300; loss: 1.41; acc: 0.53
Batch: 320; loss: 1.56; acc: 0.41
Batch: 340; loss: 1.22; acc: 0.61
Batch: 360; loss: 1.33; acc: 0.53
Batch: 380; loss: 1.25; acc: 0.55
Batch: 400; loss: 1.64; acc: 0.48
Batch: 420; loss: 1.53; acc: 0.53
Batch: 440; loss: 1.42; acc: 0.52
Batch: 460; loss: 1.17; acc: 0.59
Batch: 480; loss: 1.41; acc: 0.59
Batch: 500; loss: 1.43; acc: 0.5
Batch: 520; loss: 1.19; acc: 0.59
Batch: 540; loss: 1.39; acc: 0.61
Batch: 560; loss: 1.37; acc: 0.62
Batch: 580; loss: 1.28; acc: 0.53
Batch: 600; loss: 1.23; acc: 0.59
Batch: 620; loss: 1.31; acc: 0.55
Batch: 640; loss: 1.26; acc: 0.52
Batch: 660; loss: 1.39; acc: 0.52
Batch: 680; loss: 1.19; acc: 0.67
Batch: 700; loss: 1.23; acc: 0.58
Batch: 720; loss: 1.14; acc: 0.64
Batch: 740; loss: 1.33; acc: 0.53
Batch: 760; loss: 1.42; acc: 0.48
Batch: 780; loss: 1.34; acc: 0.58
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.5
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.37; acc: 0.59
Batch: 80; loss: 0.98; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.52
Batch: 120; loss: 1.33; acc: 0.58
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 1.306492666909649; val_accuracy: 0.5728503184713376 

The current subspace-distance is: 8.297299063997343e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.47; acc: 0.5
Batch: 20; loss: 1.54; acc: 0.56
Batch: 40; loss: 1.41; acc: 0.48
Batch: 60; loss: 1.31; acc: 0.55
Batch: 80; loss: 1.53; acc: 0.5
Batch: 100; loss: 1.05; acc: 0.64
Batch: 120; loss: 1.11; acc: 0.61
Batch: 140; loss: 1.23; acc: 0.61
Batch: 160; loss: 1.56; acc: 0.52
Batch: 180; loss: 1.35; acc: 0.52
Batch: 200; loss: 1.39; acc: 0.5
Batch: 220; loss: 1.41; acc: 0.48
Batch: 240; loss: 1.38; acc: 0.53
Batch: 260; loss: 1.38; acc: 0.47
Batch: 280; loss: 1.36; acc: 0.52
Batch: 300; loss: 1.57; acc: 0.56
Batch: 320; loss: 1.73; acc: 0.45
Batch: 340; loss: 1.46; acc: 0.5
Batch: 360; loss: 1.4; acc: 0.53
Batch: 380; loss: 1.17; acc: 0.59
Batch: 400; loss: 1.41; acc: 0.52
Batch: 420; loss: 1.24; acc: 0.58
Batch: 440; loss: 1.38; acc: 0.58
Batch: 460; loss: 1.52; acc: 0.53
Batch: 480; loss: 1.32; acc: 0.5
Batch: 500; loss: 1.01; acc: 0.66
Batch: 520; loss: 1.64; acc: 0.47
Batch: 540; loss: 1.08; acc: 0.66
Batch: 560; loss: 1.14; acc: 0.67
Batch: 580; loss: 1.21; acc: 0.66
Batch: 600; loss: 1.61; acc: 0.52
Batch: 620; loss: 1.11; acc: 0.62
Batch: 640; loss: 1.15; acc: 0.61
Batch: 660; loss: 1.39; acc: 0.52
Batch: 680; loss: 1.35; acc: 0.55
Batch: 700; loss: 1.21; acc: 0.58
Batch: 720; loss: 1.19; acc: 0.58
Batch: 740; loss: 1.41; acc: 0.55
Batch: 760; loss: 1.31; acc: 0.59
Batch: 780; loss: 1.3; acc: 0.56
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.52
Batch: 120; loss: 1.33; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.77
Val Epoch over. val_loss: 1.3060663308307623; val_accuracy: 0.5721536624203821 

The current subspace-distance is: 8.55094549478963e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.22; acc: 0.52
Batch: 60; loss: 1.27; acc: 0.59
Batch: 80; loss: 1.35; acc: 0.58
Batch: 100; loss: 1.48; acc: 0.5
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 1.29; acc: 0.56
Batch: 160; loss: 1.14; acc: 0.67
Batch: 180; loss: 1.27; acc: 0.56
Batch: 200; loss: 1.18; acc: 0.59
Batch: 220; loss: 1.25; acc: 0.59
Batch: 240; loss: 1.52; acc: 0.42
Batch: 260; loss: 1.25; acc: 0.59
Batch: 280; loss: 1.35; acc: 0.5
Batch: 300; loss: 1.22; acc: 0.59
Batch: 320; loss: 1.31; acc: 0.52
Batch: 340; loss: 1.71; acc: 0.41
Batch: 360; loss: 1.28; acc: 0.61
Batch: 380; loss: 1.17; acc: 0.66
Batch: 400; loss: 1.43; acc: 0.58
Batch: 420; loss: 1.34; acc: 0.59
Batch: 440; loss: 1.3; acc: 0.59
Batch: 460; loss: 1.18; acc: 0.64
Batch: 480; loss: 1.32; acc: 0.52
Batch: 500; loss: 1.52; acc: 0.53
Batch: 520; loss: 1.01; acc: 0.69
Batch: 540; loss: 1.24; acc: 0.58
Batch: 560; loss: 1.64; acc: 0.42
Batch: 580; loss: 1.42; acc: 0.5
Batch: 600; loss: 1.22; acc: 0.59
Batch: 620; loss: 1.43; acc: 0.55
Batch: 640; loss: 1.4; acc: 0.5
Batch: 660; loss: 1.4; acc: 0.58
Batch: 680; loss: 1.19; acc: 0.58
Batch: 700; loss: 1.36; acc: 0.5
Batch: 720; loss: 1.16; acc: 0.61
Batch: 740; loss: 1.32; acc: 0.5
Batch: 760; loss: 1.44; acc: 0.52
Batch: 780; loss: 1.26; acc: 0.53
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.97; acc: 0.69
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 1.305613442970689; val_accuracy: 0.5732484076433121 

The current subspace-distance is: 8.467448060400784e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.44; acc: 0.55
Batch: 20; loss: 1.38; acc: 0.56
Batch: 40; loss: 1.19; acc: 0.7
Batch: 60; loss: 1.32; acc: 0.59
Batch: 80; loss: 1.5; acc: 0.55
Batch: 100; loss: 1.27; acc: 0.56
Batch: 120; loss: 1.38; acc: 0.53
Batch: 140; loss: 1.35; acc: 0.59
Batch: 160; loss: 1.09; acc: 0.67
Batch: 180; loss: 1.24; acc: 0.52
Batch: 200; loss: 1.74; acc: 0.42
Batch: 220; loss: 1.45; acc: 0.47
Batch: 240; loss: 1.27; acc: 0.48
Batch: 260; loss: 1.59; acc: 0.48
Batch: 280; loss: 1.27; acc: 0.56
Batch: 300; loss: 1.3; acc: 0.62
Batch: 320; loss: 1.24; acc: 0.5
Batch: 340; loss: 1.27; acc: 0.62
Batch: 360; loss: 1.41; acc: 0.5
Batch: 380; loss: 1.5; acc: 0.5
Batch: 400; loss: 1.24; acc: 0.53
Batch: 420; loss: 1.33; acc: 0.52
Batch: 440; loss: 1.32; acc: 0.56
Batch: 460; loss: 1.52; acc: 0.5
Batch: 480; loss: 1.28; acc: 0.56
Batch: 500; loss: 1.21; acc: 0.53
Batch: 520; loss: 1.4; acc: 0.53
Batch: 540; loss: 1.2; acc: 0.56
Batch: 560; loss: 1.56; acc: 0.47
Batch: 580; loss: 1.36; acc: 0.53
Batch: 600; loss: 1.32; acc: 0.62
Batch: 620; loss: 1.42; acc: 0.45
Batch: 640; loss: 1.52; acc: 0.5
Batch: 660; loss: 1.18; acc: 0.64
Batch: 680; loss: 1.45; acc: 0.55
Batch: 700; loss: 1.49; acc: 0.5
Batch: 720; loss: 1.21; acc: 0.53
Batch: 740; loss: 1.57; acc: 0.44
Batch: 760; loss: 1.5; acc: 0.55
Batch: 780; loss: 1.01; acc: 0.69
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.47
Batch: 20; loss: 1.41; acc: 0.48
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.58
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 1.305937248050787; val_accuracy: 0.5715565286624203 

The current subspace-distance is: 8.51254299050197e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.28; acc: 0.62
Batch: 20; loss: 1.3; acc: 0.58
Batch: 40; loss: 1.49; acc: 0.52
Batch: 60; loss: 1.48; acc: 0.45
Batch: 80; loss: 1.26; acc: 0.59
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.37; acc: 0.56
Batch: 140; loss: 1.28; acc: 0.58
Batch: 160; loss: 1.2; acc: 0.64
Batch: 180; loss: 1.24; acc: 0.67
Batch: 200; loss: 1.64; acc: 0.52
Batch: 220; loss: 1.38; acc: 0.59
Batch: 240; loss: 1.26; acc: 0.59
Batch: 260; loss: 1.44; acc: 0.58
Batch: 280; loss: 1.48; acc: 0.48
Batch: 300; loss: 1.42; acc: 0.48
Batch: 320; loss: 1.52; acc: 0.47
Batch: 340; loss: 1.25; acc: 0.64
Batch: 360; loss: 1.34; acc: 0.55
Batch: 380; loss: 1.1; acc: 0.69
Batch: 400; loss: 1.58; acc: 0.42
Batch: 420; loss: 1.24; acc: 0.55
Batch: 440; loss: 1.22; acc: 0.59
Batch: 460; loss: 1.41; acc: 0.56
Batch: 480; loss: 1.23; acc: 0.55
Batch: 500; loss: 1.2; acc: 0.58
Batch: 520; loss: 1.1; acc: 0.64
Batch: 540; loss: 1.41; acc: 0.52
Batch: 560; loss: 1.31; acc: 0.56
Batch: 580; loss: 1.43; acc: 0.53
Batch: 600; loss: 1.41; acc: 0.55
Batch: 620; loss: 1.41; acc: 0.53
Batch: 640; loss: 1.55; acc: 0.5
Batch: 660; loss: 1.6; acc: 0.48
Batch: 680; loss: 1.49; acc: 0.5
Batch: 700; loss: 1.6; acc: 0.52
Batch: 720; loss: 1.42; acc: 0.56
Batch: 740; loss: 1.43; acc: 0.44
Batch: 760; loss: 1.27; acc: 0.56
Batch: 780; loss: 1.2; acc: 0.61
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.48
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.52
Batch: 120; loss: 1.33; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 1.3056602428673179; val_accuracy: 0.5727507961783439 

The current subspace-distance is: 8.733371214475483e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.58
Batch: 20; loss: 1.11; acc: 0.64
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 1.38; acc: 0.53
Batch: 100; loss: 1.53; acc: 0.45
Batch: 120; loss: 1.36; acc: 0.58
Batch: 140; loss: 1.07; acc: 0.7
Batch: 160; loss: 1.28; acc: 0.58
Batch: 180; loss: 1.32; acc: 0.61
Batch: 200; loss: 1.17; acc: 0.59
Batch: 220; loss: 1.46; acc: 0.44
Batch: 240; loss: 1.13; acc: 0.67
Batch: 260; loss: 1.65; acc: 0.55
Batch: 280; loss: 1.16; acc: 0.59
Batch: 300; loss: 1.6; acc: 0.45
Batch: 320; loss: 1.27; acc: 0.58
Batch: 340; loss: 1.46; acc: 0.52
Batch: 360; loss: 1.15; acc: 0.64
Batch: 380; loss: 1.4; acc: 0.53
Batch: 400; loss: 1.44; acc: 0.52
Batch: 420; loss: 1.39; acc: 0.55
Batch: 440; loss: 1.33; acc: 0.5
Batch: 460; loss: 1.4; acc: 0.56
Batch: 480; loss: 1.25; acc: 0.58
Batch: 500; loss: 1.57; acc: 0.47
Batch: 520; loss: 1.45; acc: 0.45
Batch: 540; loss: 1.31; acc: 0.69
Batch: 560; loss: 1.27; acc: 0.59
Batch: 580; loss: 1.36; acc: 0.48
Batch: 600; loss: 1.54; acc: 0.45
Batch: 620; loss: 1.33; acc: 0.53
Batch: 640; loss: 1.39; acc: 0.61
Batch: 660; loss: 1.38; acc: 0.59
Batch: 680; loss: 1.42; acc: 0.53
Batch: 700; loss: 1.41; acc: 0.56
Batch: 720; loss: 1.32; acc: 0.55
Batch: 740; loss: 1.33; acc: 0.56
Batch: 760; loss: 1.41; acc: 0.42
Batch: 780; loss: 1.54; acc: 0.44
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.48
Batch: 40; loss: 0.85; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 0.97; acc: 0.72
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.61
Batch: 140; loss: 0.84; acc: 0.77
Val Epoch over. val_loss: 1.3050861480129752; val_accuracy: 0.5740445859872612 

The current subspace-distance is: 8.675998833496124e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.56; acc: 0.5
Batch: 20; loss: 1.28; acc: 0.52
Batch: 40; loss: 1.14; acc: 0.67
Batch: 60; loss: 1.35; acc: 0.56
Batch: 80; loss: 1.24; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.48
Batch: 120; loss: 1.11; acc: 0.62
Batch: 140; loss: 1.42; acc: 0.48
Batch: 160; loss: 1.29; acc: 0.59
Batch: 180; loss: 1.31; acc: 0.48
Batch: 200; loss: 1.22; acc: 0.59
Batch: 220; loss: 1.46; acc: 0.58
Batch: 240; loss: 1.38; acc: 0.56
Batch: 260; loss: 1.44; acc: 0.55
Batch: 280; loss: 1.52; acc: 0.48
Batch: 300; loss: 1.37; acc: 0.55
Batch: 320; loss: 1.29; acc: 0.53
Batch: 340; loss: 1.34; acc: 0.56
Batch: 360; loss: 1.46; acc: 0.56
Batch: 380; loss: 1.16; acc: 0.61
Batch: 400; loss: 1.39; acc: 0.56
Batch: 420; loss: 1.69; acc: 0.44
Batch: 440; loss: 1.18; acc: 0.64
Batch: 460; loss: 1.34; acc: 0.55
Batch: 480; loss: 1.29; acc: 0.56
Batch: 500; loss: 1.42; acc: 0.5
Batch: 520; loss: 1.49; acc: 0.53
Batch: 540; loss: 1.13; acc: 0.61
Batch: 560; loss: 1.65; acc: 0.5
Batch: 580; loss: 1.48; acc: 0.53
Batch: 600; loss: 1.21; acc: 0.58
Batch: 620; loss: 1.22; acc: 0.59
Batch: 640; loss: 1.53; acc: 0.36
Batch: 660; loss: 1.26; acc: 0.66
Batch: 680; loss: 1.39; acc: 0.52
Batch: 700; loss: 1.23; acc: 0.59
Batch: 720; loss: 1.54; acc: 0.58
Batch: 740; loss: 1.28; acc: 0.61
Batch: 760; loss: 1.47; acc: 0.53
Batch: 780; loss: 1.41; acc: 0.56
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.28; acc: 0.5
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.85; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.72
Batch: 100; loss: 1.32; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.77
Val Epoch over. val_loss: 1.3051615566205068; val_accuracy: 0.574343152866242 

The current subspace-distance is: 8.823531970847398e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.67; acc: 0.52
Batch: 20; loss: 1.3; acc: 0.58
Batch: 40; loss: 1.52; acc: 0.45
Batch: 60; loss: 1.36; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.53
Batch: 100; loss: 1.38; acc: 0.48
Batch: 120; loss: 1.34; acc: 0.52
Batch: 140; loss: 1.43; acc: 0.5
Batch: 160; loss: 1.63; acc: 0.45
Batch: 180; loss: 1.22; acc: 0.55
Batch: 200; loss: 1.36; acc: 0.48
Batch: 220; loss: 1.16; acc: 0.61
Batch: 240; loss: 1.33; acc: 0.58
Batch: 260; loss: 1.39; acc: 0.59
Batch: 280; loss: 1.36; acc: 0.44
Batch: 300; loss: 1.56; acc: 0.47
Batch: 320; loss: 1.31; acc: 0.59
Batch: 340; loss: 1.2; acc: 0.55
Batch: 360; loss: 1.41; acc: 0.56
Batch: 380; loss: 1.32; acc: 0.61
Batch: 400; loss: 1.46; acc: 0.52
Batch: 420; loss: 1.4; acc: 0.52
Batch: 440; loss: 1.07; acc: 0.66
Batch: 460; loss: 1.49; acc: 0.55
Batch: 480; loss: 1.2; acc: 0.55
Batch: 500; loss: 1.53; acc: 0.48
Batch: 520; loss: 1.39; acc: 0.59
Batch: 540; loss: 1.32; acc: 0.61
Batch: 560; loss: 1.62; acc: 0.59
Batch: 580; loss: 1.35; acc: 0.55
Batch: 600; loss: 1.02; acc: 0.64
Batch: 620; loss: 1.35; acc: 0.56
Batch: 640; loss: 1.22; acc: 0.58
Batch: 660; loss: 1.17; acc: 0.55
Batch: 680; loss: 1.37; acc: 0.52
Batch: 700; loss: 1.2; acc: 0.58
Batch: 720; loss: 1.46; acc: 0.53
Batch: 740; loss: 1.33; acc: 0.62
Batch: 760; loss: 1.23; acc: 0.59
Batch: 780; loss: 1.37; acc: 0.58
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.29; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.5
Batch: 120; loss: 1.33; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 1.3054044557984468; val_accuracy: 0.5736464968152867 

The current subspace-distance is: 9.039113501785323e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.4; acc: 0.53
Batch: 20; loss: 1.57; acc: 0.45
Batch: 40; loss: 1.15; acc: 0.67
Batch: 60; loss: 1.45; acc: 0.58
Batch: 80; loss: 1.3; acc: 0.59
Batch: 100; loss: 1.2; acc: 0.67
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 1.34; acc: 0.55
Batch: 160; loss: 1.4; acc: 0.53
Batch: 180; loss: 1.42; acc: 0.47
Batch: 200; loss: 1.51; acc: 0.44
Batch: 220; loss: 1.35; acc: 0.5
Batch: 240; loss: 1.4; acc: 0.48
Batch: 260; loss: 1.12; acc: 0.62
Batch: 280; loss: 1.47; acc: 0.45
Batch: 300; loss: 1.43; acc: 0.5
Batch: 320; loss: 1.52; acc: 0.42
Batch: 340; loss: 1.46; acc: 0.45
Batch: 360; loss: 1.15; acc: 0.61
Batch: 380; loss: 1.13; acc: 0.67
Batch: 400; loss: 1.22; acc: 0.69
Batch: 420; loss: 1.45; acc: 0.41
Batch: 440; loss: 1.4; acc: 0.58
Batch: 460; loss: 1.43; acc: 0.53
Batch: 480; loss: 1.08; acc: 0.66
Batch: 500; loss: 1.23; acc: 0.56
Batch: 520; loss: 1.35; acc: 0.53
Batch: 540; loss: 1.39; acc: 0.5
Batch: 560; loss: 1.56; acc: 0.48
Batch: 580; loss: 1.35; acc: 0.58
Batch: 600; loss: 1.45; acc: 0.52
Batch: 620; loss: 1.51; acc: 0.53
Batch: 640; loss: 1.4; acc: 0.52
Batch: 660; loss: 1.26; acc: 0.55
Batch: 680; loss: 1.54; acc: 0.5
Batch: 700; loss: 1.26; acc: 0.56
Batch: 720; loss: 1.25; acc: 0.56
Batch: 740; loss: 1.66; acc: 0.42
Batch: 760; loss: 1.21; acc: 0.56
Batch: 780; loss: 1.16; acc: 0.61
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.29; acc: 0.5
Batch: 20; loss: 1.4; acc: 0.48
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.48
Batch: 120; loss: 1.33; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.77
Val Epoch over. val_loss: 1.3049711812833311; val_accuracy: 0.5734474522292994 

The current subspace-distance is: 9.207291441271082e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.43; acc: 0.5
Batch: 20; loss: 1.63; acc: 0.48
Batch: 40; loss: 1.21; acc: 0.56
Batch: 60; loss: 1.39; acc: 0.59
Batch: 80; loss: 1.36; acc: 0.53
Batch: 100; loss: 1.28; acc: 0.53
Batch: 120; loss: 1.43; acc: 0.44
Batch: 140; loss: 1.52; acc: 0.44
Batch: 160; loss: 0.98; acc: 0.7
Batch: 180; loss: 1.59; acc: 0.44
Batch: 200; loss: 1.45; acc: 0.47
Batch: 220; loss: 1.68; acc: 0.5
Batch: 240; loss: 1.48; acc: 0.5
Batch: 260; loss: 1.54; acc: 0.48
Batch: 280; loss: 1.47; acc: 0.52
Batch: 300; loss: 1.49; acc: 0.53
Batch: 320; loss: 1.27; acc: 0.61
Batch: 340; loss: 1.37; acc: 0.52
Batch: 360; loss: 1.15; acc: 0.58
Batch: 380; loss: 1.43; acc: 0.56
Batch: 400; loss: 1.41; acc: 0.55
Batch: 420; loss: 1.26; acc: 0.56
Batch: 440; loss: 1.25; acc: 0.5
Batch: 460; loss: 1.17; acc: 0.59
Batch: 480; loss: 1.4; acc: 0.48
Batch: 500; loss: 1.37; acc: 0.62
Batch: 520; loss: 1.43; acc: 0.56
Batch: 540; loss: 1.47; acc: 0.45
Batch: 560; loss: 0.94; acc: 0.8
Batch: 580; loss: 1.43; acc: 0.61
Batch: 600; loss: 1.42; acc: 0.48
Batch: 620; loss: 1.32; acc: 0.58
Batch: 640; loss: 1.49; acc: 0.59
Batch: 660; loss: 1.56; acc: 0.47
Batch: 680; loss: 1.51; acc: 0.52
Batch: 700; loss: 1.31; acc: 0.64
Batch: 720; loss: 1.7; acc: 0.38
Batch: 740; loss: 1.42; acc: 0.55
Batch: 760; loss: 1.41; acc: 0.5
Batch: 780; loss: 1.26; acc: 0.64
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.29; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.7
Batch: 100; loss: 1.33; acc: 0.48
Batch: 120; loss: 1.33; acc: 0.59
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 1.3055254182997782; val_accuracy: 0.5739450636942676 

The current subspace-distance is: 9.315904753748327e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.29; acc: 0.56
Batch: 20; loss: 1.07; acc: 0.66
Batch: 40; loss: 1.3; acc: 0.53
Batch: 60; loss: 1.37; acc: 0.59
Batch: 80; loss: 1.57; acc: 0.42
Batch: 100; loss: 1.3; acc: 0.55
Batch: 120; loss: 1.44; acc: 0.5
Batch: 140; loss: 1.57; acc: 0.47
Batch: 160; loss: 1.35; acc: 0.55
Batch: 180; loss: 1.37; acc: 0.62
Batch: 200; loss: 1.23; acc: 0.56
Batch: 220; loss: 1.57; acc: 0.39
Batch: 240; loss: 1.5; acc: 0.48
Batch: 260; loss: 1.42; acc: 0.5
Batch: 280; loss: 1.23; acc: 0.52
Batch: 300; loss: 1.47; acc: 0.52
Batch: 320; loss: 1.32; acc: 0.48
Batch: 340; loss: 1.56; acc: 0.45
Batch: 360; loss: 1.36; acc: 0.56
Batch: 380; loss: 1.63; acc: 0.45
Batch: 400; loss: 1.43; acc: 0.55
Batch: 420; loss: 1.59; acc: 0.48
Batch: 440; loss: 1.17; acc: 0.59
Batch: 460; loss: 1.41; acc: 0.56
Batch: 480; loss: 1.37; acc: 0.56
Batch: 500; loss: 1.59; acc: 0.45
Batch: 520; loss: 1.47; acc: 0.55
Batch: 540; loss: 1.5; acc: 0.53
Batch: 560; loss: 1.24; acc: 0.61
Batch: 580; loss: 1.56; acc: 0.42
Batch: 600; loss: 1.4; acc: 0.48
Batch: 620; loss: 1.12; acc: 0.58
Batch: 640; loss: 1.57; acc: 0.45
Batch: 660; loss: 1.3; acc: 0.59
Batch: 680; loss: 1.39; acc: 0.59
Batch: 700; loss: 1.35; acc: 0.53
Batch: 720; loss: 1.34; acc: 0.53
Batch: 740; loss: 1.33; acc: 0.61
Batch: 760; loss: 1.36; acc: 0.52
Batch: 780; loss: 1.27; acc: 0.53
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.29; acc: 0.5
Batch: 20; loss: 1.39; acc: 0.5
Batch: 40; loss: 0.85; acc: 0.75
Batch: 60; loss: 1.36; acc: 0.59
Batch: 80; loss: 0.97; acc: 0.72
Batch: 100; loss: 1.32; acc: 0.5
Batch: 120; loss: 1.32; acc: 0.61
Batch: 140; loss: 0.84; acc: 0.77
Val Epoch over. val_loss: 1.3047272870495061; val_accuracy: 0.5746417197452229 

The current subspace-distance is: 9.19308586162515e-05 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 15953
elements in E: 3331950
fraction nonzero: 0.004787886973093834
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.32; acc: 0.08
Batch: 40; loss: 2.32; acc: 0.08
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.31; acc: 0.12
Batch: 100; loss: 2.32; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.29; acc: 0.09
Batch: 180; loss: 2.31; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.06
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.29; acc: 0.12
Batch: 280; loss: 2.29; acc: 0.08
Batch: 300; loss: 2.27; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.27; acc: 0.17
Batch: 360; loss: 2.27; acc: 0.08
Batch: 380; loss: 2.28; acc: 0.12
Batch: 400; loss: 2.28; acc: 0.16
Batch: 420; loss: 2.26; acc: 0.23
Batch: 440; loss: 2.27; acc: 0.23
Batch: 460; loss: 2.28; acc: 0.12
Batch: 480; loss: 2.27; acc: 0.27
Batch: 500; loss: 2.28; acc: 0.17
Batch: 520; loss: 2.26; acc: 0.22
Batch: 540; loss: 2.25; acc: 0.28
Batch: 560; loss: 2.25; acc: 0.23
Batch: 580; loss: 2.24; acc: 0.34
Batch: 600; loss: 2.24; acc: 0.33
Batch: 620; loss: 2.23; acc: 0.34
Batch: 640; loss: 2.23; acc: 0.28
Batch: 660; loss: 2.19; acc: 0.45
Batch: 680; loss: 2.23; acc: 0.17
Batch: 700; loss: 2.21; acc: 0.19
Batch: 720; loss: 2.19; acc: 0.39
Batch: 740; loss: 2.21; acc: 0.22
Batch: 760; loss: 2.13; acc: 0.3
Batch: 780; loss: 2.14; acc: 0.28
Train Epoch over. train_loss: 2.26; train_accuracy: 0.18 

Batch: 0; loss: 2.12; acc: 0.36
Batch: 20; loss: 2.06; acc: 0.31
Batch: 40; loss: 1.98; acc: 0.56
Batch: 60; loss: 2.05; acc: 0.39
Batch: 80; loss: 2.06; acc: 0.39
Batch: 100; loss: 2.07; acc: 0.39
Batch: 120; loss: 2.11; acc: 0.3
Batch: 140; loss: 2.07; acc: 0.31
Val Epoch over. val_loss: 2.103599402555235; val_accuracy: 0.3315087579617834 

The current subspace-distance is: 5.1494753279257566e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.18; acc: 0.22
Batch: 20; loss: 2.09; acc: 0.41
Batch: 40; loss: 2.11; acc: 0.3
Batch: 60; loss: 2.05; acc: 0.33
Batch: 80; loss: 1.89; acc: 0.44
Batch: 100; loss: 1.9; acc: 0.41
Batch: 120; loss: 1.88; acc: 0.42
Batch: 140; loss: 1.82; acc: 0.39
Batch: 160; loss: 1.7; acc: 0.44
Batch: 180; loss: 1.59; acc: 0.47
Batch: 200; loss: 1.42; acc: 0.5
Batch: 220; loss: 1.43; acc: 0.55
Batch: 240; loss: 1.62; acc: 0.41
Batch: 260; loss: 1.4; acc: 0.52
Batch: 280; loss: 1.19; acc: 0.67
Batch: 300; loss: 1.24; acc: 0.64
Batch: 320; loss: 1.17; acc: 0.59
Batch: 340; loss: 1.33; acc: 0.58
Batch: 360; loss: 1.3; acc: 0.52
Batch: 380; loss: 1.11; acc: 0.64
Batch: 400; loss: 1.27; acc: 0.55
Batch: 420; loss: 1.12; acc: 0.59
Batch: 440; loss: 1.32; acc: 0.61
Batch: 460; loss: 1.36; acc: 0.64
Batch: 480; loss: 1.37; acc: 0.56
Batch: 500; loss: 1.16; acc: 0.64
Batch: 520; loss: 1.01; acc: 0.67
Batch: 540; loss: 1.15; acc: 0.62
Batch: 560; loss: 1.05; acc: 0.73
Batch: 580; loss: 1.23; acc: 0.59
Batch: 600; loss: 1.07; acc: 0.66
Batch: 620; loss: 1.19; acc: 0.62
Batch: 640; loss: 1.34; acc: 0.58
Batch: 660; loss: 1.25; acc: 0.61
Batch: 680; loss: 1.12; acc: 0.67
Batch: 700; loss: 1.05; acc: 0.64
Batch: 720; loss: 1.25; acc: 0.55
Batch: 740; loss: 1.08; acc: 0.58
Batch: 760; loss: 1.13; acc: 0.61
Batch: 780; loss: 1.05; acc: 0.59
Train Epoch over. train_loss: 1.37; train_accuracy: 0.55 

Batch: 0; loss: 1.0; acc: 0.64
Batch: 20; loss: 1.14; acc: 0.62
Batch: 40; loss: 0.66; acc: 0.72
Batch: 60; loss: 0.99; acc: 0.66
Batch: 80; loss: 1.07; acc: 0.64
Batch: 100; loss: 1.15; acc: 0.64
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 1.19; acc: 0.59
Val Epoch over. val_loss: 1.1310428536621628; val_accuracy: 0.6215167197452229 

The current subspace-distance is: 1.6563062672503293e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.12; acc: 0.66
Batch: 40; loss: 1.05; acc: 0.62
Batch: 60; loss: 1.16; acc: 0.58
Batch: 80; loss: 1.22; acc: 0.61
Batch: 100; loss: 0.87; acc: 0.75
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 1.17; acc: 0.61
Batch: 160; loss: 1.08; acc: 0.64
Batch: 180; loss: 1.17; acc: 0.61
Batch: 200; loss: 1.03; acc: 0.7
Batch: 220; loss: 0.97; acc: 0.62
Batch: 240; loss: 0.97; acc: 0.72
Batch: 260; loss: 1.14; acc: 0.7
Batch: 280; loss: 1.06; acc: 0.7
Batch: 300; loss: 1.02; acc: 0.67
Batch: 320; loss: 1.08; acc: 0.64
Batch: 340; loss: 1.13; acc: 0.66
Batch: 360; loss: 1.23; acc: 0.67
Batch: 380; loss: 1.34; acc: 0.5
Batch: 400; loss: 0.89; acc: 0.75
Batch: 420; loss: 0.9; acc: 0.67
Batch: 440; loss: 0.93; acc: 0.7
Batch: 460; loss: 1.1; acc: 0.64
Batch: 480; loss: 1.17; acc: 0.61
Batch: 500; loss: 1.0; acc: 0.62
Batch: 520; loss: 1.04; acc: 0.62
Batch: 540; loss: 1.02; acc: 0.64
Batch: 560; loss: 0.95; acc: 0.69
Batch: 580; loss: 0.98; acc: 0.64
Batch: 600; loss: 1.12; acc: 0.64
Batch: 620; loss: 1.15; acc: 0.64
Batch: 640; loss: 1.42; acc: 0.58
Batch: 660; loss: 1.21; acc: 0.59
Batch: 680; loss: 1.11; acc: 0.59
Batch: 700; loss: 0.89; acc: 0.7
Batch: 720; loss: 1.13; acc: 0.62
Batch: 740; loss: 1.05; acc: 0.72
Batch: 760; loss: 0.92; acc: 0.72
Batch: 780; loss: 1.23; acc: 0.66
Train Epoch over. train_loss: 1.1; train_accuracy: 0.64 

Batch: 0; loss: 1.06; acc: 0.62
Batch: 20; loss: 1.38; acc: 0.56
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.89; acc: 0.67
Batch: 80; loss: 0.97; acc: 0.72
Batch: 100; loss: 1.02; acc: 0.75
Batch: 120; loss: 1.33; acc: 0.56
Batch: 140; loss: 1.12; acc: 0.56
Val Epoch over. val_loss: 1.0701174542402765; val_accuracy: 0.6522691082802548 

The current subspace-distance is: 2.3219630747917108e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.84
Batch: 20; loss: 0.95; acc: 0.72
Batch: 40; loss: 0.95; acc: 0.64
Batch: 60; loss: 1.26; acc: 0.53
Batch: 80; loss: 0.98; acc: 0.67
Batch: 100; loss: 0.99; acc: 0.62
Batch: 120; loss: 1.28; acc: 0.66
Batch: 140; loss: 0.91; acc: 0.66
Batch: 160; loss: 0.94; acc: 0.75
Batch: 180; loss: 1.02; acc: 0.62
Batch: 200; loss: 1.19; acc: 0.61
Batch: 220; loss: 1.17; acc: 0.67
Batch: 240; loss: 1.17; acc: 0.61
Batch: 260; loss: 0.99; acc: 0.64
Batch: 280; loss: 1.23; acc: 0.62
Batch: 300; loss: 1.03; acc: 0.62
Batch: 320; loss: 0.89; acc: 0.73
Batch: 340; loss: 0.99; acc: 0.7
Batch: 360; loss: 0.93; acc: 0.64
Batch: 380; loss: 1.05; acc: 0.69
Batch: 400; loss: 1.05; acc: 0.66
Batch: 420; loss: 1.37; acc: 0.53
Batch: 440; loss: 0.92; acc: 0.7
Batch: 460; loss: 1.16; acc: 0.58
Batch: 480; loss: 0.84; acc: 0.73
Batch: 500; loss: 1.05; acc: 0.67
Batch: 520; loss: 0.82; acc: 0.69
Batch: 540; loss: 0.96; acc: 0.66
Batch: 560; loss: 1.28; acc: 0.64
Batch: 580; loss: 1.01; acc: 0.69
Batch: 600; loss: 1.16; acc: 0.67
Batch: 620; loss: 0.85; acc: 0.8
Batch: 640; loss: 1.21; acc: 0.59
Batch: 660; loss: 1.47; acc: 0.61
Batch: 680; loss: 1.27; acc: 0.67
Batch: 700; loss: 0.91; acc: 0.7
Batch: 720; loss: 1.14; acc: 0.59
Batch: 740; loss: 1.21; acc: 0.67
Batch: 760; loss: 0.98; acc: 0.7
Batch: 780; loss: 1.06; acc: 0.66
Train Epoch over. train_loss: 1.08; train_accuracy: 0.65 

Batch: 0; loss: 1.15; acc: 0.56
Batch: 20; loss: 1.21; acc: 0.61
Batch: 40; loss: 0.69; acc: 0.8
Batch: 60; loss: 1.05; acc: 0.7
Batch: 80; loss: 1.08; acc: 0.62
Batch: 100; loss: 1.14; acc: 0.66
Batch: 120; loss: 1.31; acc: 0.52
Batch: 140; loss: 1.27; acc: 0.53
Val Epoch over. val_loss: 1.1213395147566583; val_accuracy: 0.6271894904458599 

The current subspace-distance is: 2.7091053198091686e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.13; acc: 0.64
Batch: 20; loss: 1.11; acc: 0.58
Batch: 40; loss: 0.99; acc: 0.69
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.67
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.93; acc: 0.69
Batch: 160; loss: 1.07; acc: 0.67
Batch: 180; loss: 0.77; acc: 0.7
Batch: 200; loss: 1.02; acc: 0.62
Batch: 220; loss: 1.31; acc: 0.62
Batch: 240; loss: 1.04; acc: 0.67
Batch: 260; loss: 1.26; acc: 0.59
Batch: 280; loss: 1.01; acc: 0.64
Batch: 300; loss: 1.15; acc: 0.66
Batch: 320; loss: 1.15; acc: 0.64
Batch: 340; loss: 0.9; acc: 0.69
Batch: 360; loss: 1.15; acc: 0.61
Batch: 380; loss: 1.02; acc: 0.72
Batch: 400; loss: 0.82; acc: 0.73
Batch: 420; loss: 1.06; acc: 0.73
Batch: 440; loss: 0.99; acc: 0.69
Batch: 460; loss: 0.9; acc: 0.75
Batch: 480; loss: 1.18; acc: 0.64
Batch: 500; loss: 1.21; acc: 0.64
Batch: 520; loss: 0.83; acc: 0.75
Batch: 540; loss: 1.16; acc: 0.66
Batch: 560; loss: 1.34; acc: 0.64
Batch: 580; loss: 1.38; acc: 0.62
Batch: 600; loss: 1.08; acc: 0.61
Batch: 620; loss: 0.98; acc: 0.67
Batch: 640; loss: 1.26; acc: 0.59
Batch: 660; loss: 1.05; acc: 0.64
Batch: 680; loss: 0.95; acc: 0.64
Batch: 700; loss: 1.14; acc: 0.62
Batch: 720; loss: 1.22; acc: 0.69
Batch: 740; loss: 1.08; acc: 0.64
Batch: 760; loss: 0.93; acc: 0.72
Batch: 780; loss: 1.15; acc: 0.58
Train Epoch over. train_loss: 1.08; train_accuracy: 0.65 

Batch: 0; loss: 1.15; acc: 0.67
Batch: 20; loss: 1.46; acc: 0.55
Batch: 40; loss: 0.61; acc: 0.84
Batch: 60; loss: 0.94; acc: 0.7
Batch: 80; loss: 0.94; acc: 0.7
Batch: 100; loss: 1.12; acc: 0.72
Batch: 120; loss: 1.31; acc: 0.58
Batch: 140; loss: 1.03; acc: 0.61
Val Epoch over. val_loss: 1.058838701551887; val_accuracy: 0.6611265923566879 

The current subspace-distance is: 3.100826870650053e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.26; acc: 0.64
Batch: 20; loss: 1.01; acc: 0.66
Batch: 40; loss: 1.34; acc: 0.55
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 1.12; acc: 0.58
Batch: 100; loss: 1.18; acc: 0.58
Batch: 120; loss: 0.84; acc: 0.7
Batch: 140; loss: 0.67; acc: 0.83
Batch: 160; loss: 1.23; acc: 0.62
Batch: 180; loss: 1.1; acc: 0.64
Batch: 200; loss: 1.07; acc: 0.67
Batch: 220; loss: 1.0; acc: 0.62
Batch: 240; loss: 1.03; acc: 0.67
Batch: 260; loss: 0.93; acc: 0.7
Batch: 280; loss: 0.98; acc: 0.7
Batch: 300; loss: 1.2; acc: 0.64
Batch: 320; loss: 1.06; acc: 0.59
Batch: 340; loss: 0.94; acc: 0.72
Batch: 360; loss: 1.13; acc: 0.64
Batch: 380; loss: 1.15; acc: 0.62
Batch: 400; loss: 1.03; acc: 0.64
Batch: 420; loss: 1.04; acc: 0.62
Batch: 440; loss: 1.13; acc: 0.67
Batch: 460; loss: 0.87; acc: 0.72
Batch: 480; loss: 1.21; acc: 0.67
Batch: 500; loss: 0.99; acc: 0.64
Batch: 520; loss: 0.85; acc: 0.73
Batch: 540; loss: 1.3; acc: 0.59
Batch: 560; loss: 1.26; acc: 0.67
Batch: 580; loss: 1.1; acc: 0.72
Batch: 600; loss: 0.86; acc: 0.75
Batch: 620; loss: 1.39; acc: 0.64
Batch: 640; loss: 0.87; acc: 0.73
Batch: 660; loss: 0.88; acc: 0.69
Batch: 680; loss: 1.07; acc: 0.59
Batch: 700; loss: 1.32; acc: 0.59
Batch: 720; loss: 0.99; acc: 0.66
Batch: 740; loss: 1.15; acc: 0.62
Batch: 760; loss: 0.96; acc: 0.7
Batch: 780; loss: 1.12; acc: 0.66
Train Epoch over. train_loss: 1.06; train_accuracy: 0.66 

Batch: 0; loss: 1.08; acc: 0.67
Batch: 20; loss: 1.32; acc: 0.59
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 0.95; acc: 0.72
Batch: 80; loss: 1.07; acc: 0.69
Batch: 100; loss: 1.2; acc: 0.64
Batch: 120; loss: 1.2; acc: 0.52
Batch: 140; loss: 1.12; acc: 0.61
Val Epoch over. val_loss: 1.0602993122331656; val_accuracy: 0.648984872611465 

The current subspace-distance is: 3.5527140425983816e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.53
Batch: 20; loss: 0.94; acc: 0.66
Batch: 40; loss: 1.23; acc: 0.64
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 1.26; acc: 0.56
Batch: 100; loss: 1.03; acc: 0.62
Batch: 120; loss: 1.12; acc: 0.59
Batch: 140; loss: 1.0; acc: 0.72
Batch: 160; loss: 1.33; acc: 0.64
Batch: 180; loss: 1.2; acc: 0.58
Batch: 200; loss: 1.0; acc: 0.61
Batch: 220; loss: 1.02; acc: 0.72
Batch: 240; loss: 1.1; acc: 0.59
Batch: 260; loss: 1.05; acc: 0.61
Batch: 280; loss: 0.98; acc: 0.64
Batch: 300; loss: 1.14; acc: 0.72
Batch: 320; loss: 1.23; acc: 0.62
Batch: 340; loss: 1.03; acc: 0.58
Batch: 360; loss: 1.19; acc: 0.56
Batch: 380; loss: 1.34; acc: 0.58
Batch: 400; loss: 1.3; acc: 0.62
Batch: 420; loss: 0.74; acc: 0.78
Batch: 440; loss: 0.79; acc: 0.73
Batch: 460; loss: 1.23; acc: 0.56
Batch: 480; loss: 1.14; acc: 0.67
Batch: 500; loss: 1.17; acc: 0.66
Batch: 520; loss: 0.84; acc: 0.75
Batch: 540; loss: 1.23; acc: 0.56
Batch: 560; loss: 1.14; acc: 0.62
Batch: 580; loss: 1.12; acc: 0.55
Batch: 600; loss: 0.95; acc: 0.72
Batch: 620; loss: 1.29; acc: 0.59
Batch: 640; loss: 1.05; acc: 0.66
Batch: 660; loss: 1.14; acc: 0.61
Batch: 680; loss: 1.04; acc: 0.67
Batch: 700; loss: 0.88; acc: 0.72
Batch: 720; loss: 0.98; acc: 0.66
Batch: 740; loss: 1.03; acc: 0.66
Batch: 760; loss: 0.72; acc: 0.72
Batch: 780; loss: 0.95; acc: 0.69
Train Epoch over. train_loss: 1.03; train_accuracy: 0.66 

Batch: 0; loss: 1.04; acc: 0.62
Batch: 20; loss: 1.25; acc: 0.55
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.82; acc: 0.75
Batch: 100; loss: 1.02; acc: 0.64
Batch: 120; loss: 1.12; acc: 0.62
Batch: 140; loss: 0.76; acc: 0.69
Val Epoch over. val_loss: 0.946446981969153; val_accuracy: 0.6884952229299363 

The current subspace-distance is: 3.988695243606344e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.15; acc: 0.64
Batch: 20; loss: 1.14; acc: 0.69
Batch: 40; loss: 1.06; acc: 0.69
Batch: 60; loss: 1.05; acc: 0.67
Batch: 80; loss: 1.06; acc: 0.62
Batch: 100; loss: 0.85; acc: 0.75
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.9; acc: 0.67
Batch: 160; loss: 0.74; acc: 0.75
Batch: 180; loss: 1.3; acc: 0.59
Batch: 200; loss: 0.84; acc: 0.81
Batch: 220; loss: 1.1; acc: 0.56
Batch: 240; loss: 0.82; acc: 0.72
Batch: 260; loss: 1.08; acc: 0.64
Batch: 280; loss: 0.78; acc: 0.77
Batch: 300; loss: 1.04; acc: 0.66
Batch: 320; loss: 1.08; acc: 0.72
Batch: 340; loss: 1.05; acc: 0.72
Batch: 360; loss: 1.04; acc: 0.67
Batch: 380; loss: 0.93; acc: 0.69
Batch: 400; loss: 1.07; acc: 0.66
Batch: 420; loss: 0.95; acc: 0.67
Batch: 440; loss: 0.98; acc: 0.78
Batch: 460; loss: 1.3; acc: 0.62
Batch: 480; loss: 0.94; acc: 0.64
Batch: 500; loss: 1.51; acc: 0.5
Batch: 520; loss: 0.88; acc: 0.7
Batch: 540; loss: 0.95; acc: 0.7
Batch: 560; loss: 0.85; acc: 0.75
Batch: 580; loss: 1.14; acc: 0.69
Batch: 600; loss: 1.1; acc: 0.66
Batch: 620; loss: 0.86; acc: 0.69
Batch: 640; loss: 1.11; acc: 0.59
Batch: 660; loss: 0.93; acc: 0.62
Batch: 680; loss: 0.76; acc: 0.73
Batch: 700; loss: 0.83; acc: 0.77
Batch: 720; loss: 0.85; acc: 0.7
Batch: 740; loss: 1.08; acc: 0.61
Batch: 760; loss: 1.08; acc: 0.66
Batch: 780; loss: 1.04; acc: 0.64
Train Epoch over. train_loss: 1.0; train_accuracy: 0.67 

Batch: 0; loss: 0.98; acc: 0.59
Batch: 20; loss: 1.37; acc: 0.5
Batch: 40; loss: 0.58; acc: 0.8
Batch: 60; loss: 0.79; acc: 0.7
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 1.22; acc: 0.61
Batch: 140; loss: 0.72; acc: 0.75
Val Epoch over. val_loss: 0.9341912899807001; val_accuracy: 0.689390923566879 

The current subspace-distance is: 4.311104567022994e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.99; acc: 0.69
Batch: 20; loss: 0.88; acc: 0.7
Batch: 40; loss: 1.17; acc: 0.59
Batch: 60; loss: 1.19; acc: 0.58
Batch: 80; loss: 1.09; acc: 0.64
Batch: 100; loss: 1.04; acc: 0.64
Batch: 120; loss: 1.16; acc: 0.66
Batch: 140; loss: 1.03; acc: 0.75
Batch: 160; loss: 1.03; acc: 0.69
Batch: 180; loss: 0.79; acc: 0.75
Batch: 200; loss: 0.91; acc: 0.7
Batch: 220; loss: 0.78; acc: 0.7
Batch: 240; loss: 1.1; acc: 0.69
Batch: 260; loss: 1.08; acc: 0.75
Batch: 280; loss: 0.75; acc: 0.72
Batch: 300; loss: 0.84; acc: 0.67
Batch: 320; loss: 0.83; acc: 0.75
Batch: 340; loss: 0.86; acc: 0.72
Batch: 360; loss: 1.16; acc: 0.59
Batch: 380; loss: 1.08; acc: 0.66
Batch: 400; loss: 1.04; acc: 0.59
Batch: 420; loss: 0.81; acc: 0.75
Batch: 440; loss: 1.26; acc: 0.61
Batch: 460; loss: 0.96; acc: 0.59
Batch: 480; loss: 0.85; acc: 0.69
Batch: 500; loss: 0.96; acc: 0.73
Batch: 520; loss: 1.13; acc: 0.62
Batch: 540; loss: 1.29; acc: 0.58
Batch: 560; loss: 1.19; acc: 0.61
Batch: 580; loss: 1.11; acc: 0.66
Batch: 600; loss: 1.04; acc: 0.69
Batch: 620; loss: 0.96; acc: 0.64
Batch: 640; loss: 1.04; acc: 0.7
Batch: 660; loss: 0.84; acc: 0.73
Batch: 680; loss: 1.01; acc: 0.69
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 1.1; acc: 0.56
Batch: 740; loss: 1.15; acc: 0.56
Batch: 760; loss: 0.79; acc: 0.75
Batch: 780; loss: 1.03; acc: 0.69
Train Epoch over. train_loss: 1.0; train_accuracy: 0.67 

Batch: 0; loss: 0.93; acc: 0.64
Batch: 20; loss: 1.16; acc: 0.55
Batch: 40; loss: 0.61; acc: 0.81
Batch: 60; loss: 0.79; acc: 0.73
Batch: 80; loss: 0.84; acc: 0.75
Batch: 100; loss: 0.97; acc: 0.7
Batch: 120; loss: 1.08; acc: 0.58
Batch: 140; loss: 0.67; acc: 0.77
Val Epoch over. val_loss: 0.9295842089470784; val_accuracy: 0.68640525477707 

The current subspace-distance is: 4.5667606173083186e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.91; acc: 0.67
Batch: 20; loss: 1.03; acc: 0.62
Batch: 40; loss: 1.11; acc: 0.64
Batch: 60; loss: 1.0; acc: 0.67
Batch: 80; loss: 0.98; acc: 0.61
Batch: 100; loss: 0.88; acc: 0.69
Batch: 120; loss: 1.03; acc: 0.72
Batch: 140; loss: 1.19; acc: 0.62
Batch: 160; loss: 0.93; acc: 0.64
Batch: 180; loss: 1.07; acc: 0.75
Batch: 200; loss: 1.06; acc: 0.64
Batch: 220; loss: 0.97; acc: 0.69
Batch: 240; loss: 1.15; acc: 0.59
Batch: 260; loss: 0.96; acc: 0.62
Batch: 280; loss: 0.69; acc: 0.73
Batch: 300; loss: 0.83; acc: 0.75
Batch: 320; loss: 1.31; acc: 0.61
Batch: 340; loss: 1.01; acc: 0.64
Batch: 360; loss: 1.17; acc: 0.62
Batch: 380; loss: 0.79; acc: 0.73
Batch: 400; loss: 0.83; acc: 0.7
Batch: 420; loss: 0.99; acc: 0.7
Batch: 440; loss: 1.04; acc: 0.7
Batch: 460; loss: 0.83; acc: 0.66
Batch: 480; loss: 1.16; acc: 0.66
Batch: 500; loss: 0.79; acc: 0.77
Batch: 520; loss: 1.05; acc: 0.62
Batch: 540; loss: 0.94; acc: 0.62
Batch: 560; loss: 1.0; acc: 0.7
Batch: 580; loss: 1.0; acc: 0.67
Batch: 600; loss: 0.96; acc: 0.67
Batch: 620; loss: 0.92; acc: 0.7
Batch: 640; loss: 0.92; acc: 0.66
Batch: 660; loss: 1.1; acc: 0.67
Batch: 680; loss: 0.83; acc: 0.77
Batch: 700; loss: 0.94; acc: 0.7
Batch: 720; loss: 0.87; acc: 0.69
Batch: 740; loss: 1.12; acc: 0.72
Batch: 760; loss: 0.93; acc: 0.62
Batch: 780; loss: 0.65; acc: 0.8
Train Epoch over. train_loss: 0.98; train_accuracy: 0.67 

Batch: 0; loss: 1.16; acc: 0.62
Batch: 20; loss: 1.35; acc: 0.52
Batch: 40; loss: 0.81; acc: 0.73
Batch: 60; loss: 1.01; acc: 0.66
Batch: 80; loss: 0.95; acc: 0.77
Batch: 100; loss: 1.12; acc: 0.62
Batch: 120; loss: 1.27; acc: 0.64
Batch: 140; loss: 0.9; acc: 0.64
Val Epoch over. val_loss: 1.1453690999632429; val_accuracy: 0.6217157643312102 

The current subspace-distance is: 4.884826557827182e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.58; acc: 0.55
Batch: 20; loss: 0.92; acc: 0.7
Batch: 40; loss: 1.03; acc: 0.59
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 1.1; acc: 0.7
Batch: 100; loss: 1.13; acc: 0.66
Batch: 120; loss: 0.8; acc: 0.73
Batch: 140; loss: 0.76; acc: 0.77
Batch: 160; loss: 1.23; acc: 0.61
Batch: 180; loss: 0.82; acc: 0.75
Batch: 200; loss: 0.9; acc: 0.7
Batch: 220; loss: 0.68; acc: 0.78
Batch: 240; loss: 1.28; acc: 0.66
Batch: 260; loss: 0.94; acc: 0.77
Batch: 280; loss: 1.05; acc: 0.67
Batch: 300; loss: 0.95; acc: 0.66
Batch: 320; loss: 1.08; acc: 0.61
Batch: 340; loss: 1.0; acc: 0.69
Batch: 360; loss: 0.87; acc: 0.7
Batch: 380; loss: 0.91; acc: 0.67
Batch: 400; loss: 0.75; acc: 0.72
Batch: 420; loss: 1.14; acc: 0.59
Batch: 440; loss: 0.73; acc: 0.73
Batch: 460; loss: 1.13; acc: 0.62
Batch: 480; loss: 0.81; acc: 0.75
Batch: 500; loss: 0.92; acc: 0.7
Batch: 520; loss: 0.64; acc: 0.81
Batch: 540; loss: 0.71; acc: 0.73
Batch: 560; loss: 0.73; acc: 0.7
Batch: 580; loss: 0.89; acc: 0.7
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 0.78; acc: 0.75
Batch: 640; loss: 0.96; acc: 0.61
Batch: 660; loss: 1.03; acc: 0.67
Batch: 680; loss: 0.97; acc: 0.69
Batch: 700; loss: 1.27; acc: 0.61
Batch: 720; loss: 0.86; acc: 0.67
Batch: 740; loss: 0.79; acc: 0.78
Batch: 760; loss: 1.07; acc: 0.64
Batch: 780; loss: 1.02; acc: 0.66
Train Epoch over. train_loss: 0.91; train_accuracy: 0.7 

Batch: 0; loss: 0.92; acc: 0.67
Batch: 20; loss: 1.09; acc: 0.59
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.78; acc: 0.8
Batch: 80; loss: 0.72; acc: 0.73
Batch: 100; loss: 0.87; acc: 0.77
Batch: 120; loss: 0.94; acc: 0.66
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.8498059750362567; val_accuracy: 0.7182523885350318 

The current subspace-distance is: 5.343015072867274e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.88; acc: 0.69
Batch: 20; loss: 0.87; acc: 0.69
Batch: 40; loss: 0.93; acc: 0.67
Batch: 60; loss: 0.66; acc: 0.77
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.71; acc: 0.78
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.89; acc: 0.7
Batch: 160; loss: 0.69; acc: 0.73
Batch: 180; loss: 0.98; acc: 0.66
Batch: 200; loss: 0.84; acc: 0.69
Batch: 220; loss: 1.36; acc: 0.61
Batch: 240; loss: 0.79; acc: 0.7
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 1.08; acc: 0.69
Batch: 300; loss: 0.55; acc: 0.84
Batch: 320; loss: 1.11; acc: 0.67
Batch: 340; loss: 0.78; acc: 0.75
Batch: 360; loss: 0.99; acc: 0.66
Batch: 380; loss: 0.98; acc: 0.66
Batch: 400; loss: 0.8; acc: 0.73
Batch: 420; loss: 1.29; acc: 0.53
Batch: 440; loss: 0.85; acc: 0.72
Batch: 460; loss: 1.16; acc: 0.66
Batch: 480; loss: 1.07; acc: 0.61
Batch: 500; loss: 0.96; acc: 0.67
Batch: 520; loss: 0.98; acc: 0.62
Batch: 540; loss: 0.82; acc: 0.73
Batch: 560; loss: 1.21; acc: 0.62
Batch: 580; loss: 1.14; acc: 0.58
Batch: 600; loss: 0.77; acc: 0.72
Batch: 620; loss: 1.07; acc: 0.69
Batch: 640; loss: 1.0; acc: 0.75
Batch: 660; loss: 0.77; acc: 0.72
Batch: 680; loss: 0.81; acc: 0.67
Batch: 700; loss: 0.97; acc: 0.69
Batch: 720; loss: 0.81; acc: 0.73
Batch: 740; loss: 0.92; acc: 0.69
Batch: 760; loss: 0.78; acc: 0.72
Batch: 780; loss: 0.83; acc: 0.67
Train Epoch over. train_loss: 0.88; train_accuracy: 0.71 

Batch: 0; loss: 1.0; acc: 0.64
Batch: 20; loss: 1.2; acc: 0.55
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.77; acc: 0.75
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.54; acc: 0.8
Val Epoch over. val_loss: 0.8425136540725733; val_accuracy: 0.7238256369426752 

The current subspace-distance is: 5.720926492358558e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.07; acc: 0.66
Batch: 20; loss: 0.89; acc: 0.69
Batch: 40; loss: 0.85; acc: 0.7
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.85; acc: 0.67
Batch: 100; loss: 0.76; acc: 0.75
Batch: 120; loss: 0.81; acc: 0.67
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.92; acc: 0.7
Batch: 180; loss: 0.97; acc: 0.67
Batch: 200; loss: 0.97; acc: 0.69
Batch: 220; loss: 0.99; acc: 0.72
Batch: 240; loss: 0.88; acc: 0.64
Batch: 260; loss: 0.69; acc: 0.78
Batch: 280; loss: 1.01; acc: 0.62
Batch: 300; loss: 0.82; acc: 0.67
Batch: 320; loss: 0.64; acc: 0.84
Batch: 340; loss: 0.78; acc: 0.77
Batch: 360; loss: 0.72; acc: 0.78
Batch: 380; loss: 0.8; acc: 0.75
Batch: 400; loss: 0.73; acc: 0.75
Batch: 420; loss: 0.86; acc: 0.64
Batch: 440; loss: 0.7; acc: 0.7
Batch: 460; loss: 0.91; acc: 0.73
Batch: 480; loss: 1.01; acc: 0.61
Batch: 500; loss: 0.67; acc: 0.69
Batch: 520; loss: 0.89; acc: 0.75
Batch: 540; loss: 0.8; acc: 0.75
Batch: 560; loss: 0.82; acc: 0.73
Batch: 580; loss: 0.62; acc: 0.86
Batch: 600; loss: 0.99; acc: 0.73
Batch: 620; loss: 0.87; acc: 0.7
Batch: 640; loss: 0.81; acc: 0.75
Batch: 660; loss: 0.93; acc: 0.69
Batch: 680; loss: 0.92; acc: 0.69
Batch: 700; loss: 0.64; acc: 0.8
Batch: 720; loss: 1.09; acc: 0.55
Batch: 740; loss: 0.78; acc: 0.77
Batch: 760; loss: 1.09; acc: 0.64
Batch: 780; loss: 1.15; acc: 0.61
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 1.0; acc: 0.62
Batch: 20; loss: 1.09; acc: 0.61
Batch: 40; loss: 0.43; acc: 0.91
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.81; acc: 0.75
Batch: 100; loss: 0.9; acc: 0.73
Batch: 120; loss: 0.91; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.8110520746677544; val_accuracy: 0.7315883757961783 

The current subspace-distance is: 6.125828804215416e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.74; acc: 0.72
Batch: 20; loss: 0.72; acc: 0.7
Batch: 40; loss: 0.66; acc: 0.72
Batch: 60; loss: 0.84; acc: 0.7
Batch: 80; loss: 0.94; acc: 0.72
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 0.79; acc: 0.66
Batch: 140; loss: 0.86; acc: 0.73
Batch: 160; loss: 0.92; acc: 0.69
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.84; acc: 0.7
Batch: 220; loss: 0.72; acc: 0.69
Batch: 240; loss: 0.81; acc: 0.77
Batch: 260; loss: 0.73; acc: 0.73
Batch: 280; loss: 0.91; acc: 0.7
Batch: 300; loss: 0.74; acc: 0.73
Batch: 320; loss: 0.68; acc: 0.8
Batch: 340; loss: 1.0; acc: 0.64
Batch: 360; loss: 0.63; acc: 0.77
Batch: 380; loss: 0.83; acc: 0.72
Batch: 400; loss: 0.58; acc: 0.75
Batch: 420; loss: 0.97; acc: 0.7
Batch: 440; loss: 0.9; acc: 0.73
Batch: 460; loss: 0.93; acc: 0.73
Batch: 480; loss: 0.91; acc: 0.75
Batch: 500; loss: 0.79; acc: 0.72
Batch: 520; loss: 0.91; acc: 0.69
Batch: 540; loss: 0.69; acc: 0.75
Batch: 560; loss: 0.81; acc: 0.77
Batch: 580; loss: 0.85; acc: 0.78
Batch: 600; loss: 0.77; acc: 0.73
Batch: 620; loss: 0.76; acc: 0.81
Batch: 640; loss: 0.7; acc: 0.8
Batch: 660; loss: 0.72; acc: 0.75
Batch: 680; loss: 0.95; acc: 0.73
Batch: 700; loss: 1.0; acc: 0.64
Batch: 720; loss: 0.85; acc: 0.67
Batch: 740; loss: 0.79; acc: 0.73
Batch: 760; loss: 0.64; acc: 0.77
Batch: 780; loss: 0.94; acc: 0.64
Train Epoch over. train_loss: 0.84; train_accuracy: 0.72 

Batch: 0; loss: 1.0; acc: 0.64
Batch: 20; loss: 1.09; acc: 0.66
Batch: 40; loss: 0.44; acc: 0.91
Batch: 60; loss: 0.76; acc: 0.72
Batch: 80; loss: 0.79; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 0.97; acc: 0.62
Batch: 140; loss: 0.5; acc: 0.81
Val Epoch over. val_loss: 0.8105245293325679; val_accuracy: 0.7269108280254777 

The current subspace-distance is: 6.384452717611566e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.76; acc: 0.69
Batch: 40; loss: 0.74; acc: 0.8
Batch: 60; loss: 0.61; acc: 0.73
Batch: 80; loss: 0.68; acc: 0.77
Batch: 100; loss: 0.88; acc: 0.7
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.8; acc: 0.72
Batch: 160; loss: 1.05; acc: 0.72
Batch: 180; loss: 0.67; acc: 0.77
Batch: 200; loss: 0.7; acc: 0.8
Batch: 220; loss: 1.04; acc: 0.66
Batch: 240; loss: 0.96; acc: 0.75
Batch: 260; loss: 0.65; acc: 0.78
Batch: 280; loss: 0.78; acc: 0.7
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.76; acc: 0.75
Batch: 340; loss: 0.82; acc: 0.77
Batch: 360; loss: 0.68; acc: 0.67
Batch: 380; loss: 0.68; acc: 0.75
Batch: 400; loss: 0.83; acc: 0.72
Batch: 420; loss: 0.88; acc: 0.73
Batch: 440; loss: 0.99; acc: 0.67
Batch: 460; loss: 0.99; acc: 0.7
Batch: 480; loss: 0.81; acc: 0.75
Batch: 500; loss: 0.87; acc: 0.73
Batch: 520; loss: 0.83; acc: 0.66
Batch: 540; loss: 0.79; acc: 0.77
Batch: 560; loss: 0.71; acc: 0.7
Batch: 580; loss: 0.75; acc: 0.72
Batch: 600; loss: 1.13; acc: 0.64
Batch: 620; loss: 0.79; acc: 0.73
Batch: 640; loss: 0.8; acc: 0.72
Batch: 660; loss: 0.75; acc: 0.84
Batch: 680; loss: 1.23; acc: 0.62
Batch: 700; loss: 0.98; acc: 0.7
Batch: 720; loss: 0.73; acc: 0.77
Batch: 740; loss: 0.84; acc: 0.75
Batch: 760; loss: 0.86; acc: 0.77
Batch: 780; loss: 0.86; acc: 0.7
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 1.04; acc: 0.62
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.74; acc: 0.78
Batch: 100; loss: 0.9; acc: 0.77
Batch: 120; loss: 0.9; acc: 0.67
Batch: 140; loss: 0.44; acc: 0.88
Val Epoch over. val_loss: 0.78376290467894; val_accuracy: 0.7449243630573248 

The current subspace-distance is: 6.579612090718001e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.72; acc: 0.72
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.58; acc: 0.78
Batch: 100; loss: 0.63; acc: 0.77
Batch: 120; loss: 0.81; acc: 0.67
Batch: 140; loss: 0.97; acc: 0.66
Batch: 160; loss: 0.85; acc: 0.69
Batch: 180; loss: 0.95; acc: 0.62
Batch: 200; loss: 0.69; acc: 0.77
Batch: 220; loss: 0.94; acc: 0.7
Batch: 240; loss: 0.69; acc: 0.77
Batch: 260; loss: 0.68; acc: 0.78
Batch: 280; loss: 0.99; acc: 0.64
Batch: 300; loss: 0.85; acc: 0.72
Batch: 320; loss: 0.8; acc: 0.67
Batch: 340; loss: 1.02; acc: 0.69
Batch: 360; loss: 0.64; acc: 0.8
Batch: 380; loss: 0.81; acc: 0.67
Batch: 400; loss: 0.71; acc: 0.8
Batch: 420; loss: 0.59; acc: 0.8
Batch: 440; loss: 1.13; acc: 0.69
Batch: 460; loss: 0.91; acc: 0.69
Batch: 480; loss: 0.85; acc: 0.66
Batch: 500; loss: 0.91; acc: 0.72
Batch: 520; loss: 1.04; acc: 0.64
Batch: 540; loss: 0.6; acc: 0.83
Batch: 560; loss: 0.68; acc: 0.78
Batch: 580; loss: 1.06; acc: 0.62
Batch: 600; loss: 1.05; acc: 0.64
Batch: 620; loss: 0.72; acc: 0.78
Batch: 640; loss: 0.99; acc: 0.75
Batch: 660; loss: 1.06; acc: 0.66
Batch: 680; loss: 0.9; acc: 0.75
Batch: 700; loss: 0.77; acc: 0.73
Batch: 720; loss: 1.19; acc: 0.67
Batch: 740; loss: 0.85; acc: 0.8
Batch: 760; loss: 0.76; acc: 0.67
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.9; acc: 0.69
Batch: 20; loss: 1.02; acc: 0.59
Batch: 40; loss: 0.44; acc: 0.84
Batch: 60; loss: 0.77; acc: 0.72
Batch: 80; loss: 0.74; acc: 0.78
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 0.95; acc: 0.64
Batch: 140; loss: 0.49; acc: 0.81
Val Epoch over. val_loss: 0.7933984989193594; val_accuracy: 0.7383558917197452 

The current subspace-distance is: 6.90222586854361e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.62; acc: 0.75
Batch: 40; loss: 1.11; acc: 0.58
Batch: 60; loss: 0.75; acc: 0.7
Batch: 80; loss: 0.96; acc: 0.73
Batch: 100; loss: 0.88; acc: 0.75
Batch: 120; loss: 0.85; acc: 0.72
Batch: 140; loss: 0.86; acc: 0.77
Batch: 160; loss: 1.07; acc: 0.64
Batch: 180; loss: 1.06; acc: 0.67
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.84; acc: 0.67
Batch: 240; loss: 1.02; acc: 0.72
Batch: 260; loss: 0.74; acc: 0.78
Batch: 280; loss: 0.72; acc: 0.77
Batch: 300; loss: 0.62; acc: 0.8
Batch: 320; loss: 0.8; acc: 0.73
Batch: 340; loss: 0.83; acc: 0.73
Batch: 360; loss: 0.66; acc: 0.81
Batch: 380; loss: 0.77; acc: 0.7
Batch: 400; loss: 0.92; acc: 0.66
Batch: 420; loss: 0.92; acc: 0.66
Batch: 440; loss: 0.85; acc: 0.73
Batch: 460; loss: 1.11; acc: 0.61
Batch: 480; loss: 0.71; acc: 0.78
Batch: 500; loss: 0.89; acc: 0.81
Batch: 520; loss: 0.66; acc: 0.7
Batch: 540; loss: 0.77; acc: 0.78
Batch: 560; loss: 0.63; acc: 0.78
Batch: 580; loss: 0.84; acc: 0.66
Batch: 600; loss: 0.79; acc: 0.72
Batch: 620; loss: 0.73; acc: 0.8
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 1.02; acc: 0.7
Batch: 680; loss: 0.96; acc: 0.67
Batch: 700; loss: 0.72; acc: 0.73
Batch: 720; loss: 0.63; acc: 0.8
Batch: 740; loss: 0.92; acc: 0.66
Batch: 760; loss: 0.68; acc: 0.83
Batch: 780; loss: 0.83; acc: 0.7
Train Epoch over. train_loss: 0.83; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.69
Batch: 20; loss: 1.0; acc: 0.62
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.73; acc: 0.75
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.8
Batch: 120; loss: 0.91; acc: 0.67
Batch: 140; loss: 0.42; acc: 0.88
Val Epoch over. val_loss: 0.7837808680762152; val_accuracy: 0.7485071656050956 

The current subspace-distance is: 7.141559035517275e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.9; acc: 0.73
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 1.02; acc: 0.62
Batch: 60; loss: 1.37; acc: 0.66
Batch: 80; loss: 0.98; acc: 0.7
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 1.09; acc: 0.69
Batch: 160; loss: 0.72; acc: 0.73
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.78; acc: 0.75
Batch: 240; loss: 0.87; acc: 0.73
Batch: 260; loss: 0.86; acc: 0.7
Batch: 280; loss: 0.69; acc: 0.75
Batch: 300; loss: 0.8; acc: 0.7
Batch: 320; loss: 0.76; acc: 0.77
Batch: 340; loss: 0.61; acc: 0.8
Batch: 360; loss: 0.59; acc: 0.83
Batch: 380; loss: 0.89; acc: 0.73
Batch: 400; loss: 0.68; acc: 0.81
Batch: 420; loss: 0.92; acc: 0.7
Batch: 440; loss: 0.75; acc: 0.7
Batch: 460; loss: 1.15; acc: 0.61
Batch: 480; loss: 0.82; acc: 0.77
Batch: 500; loss: 0.99; acc: 0.69
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.86; acc: 0.7
Batch: 560; loss: 0.8; acc: 0.62
Batch: 580; loss: 0.92; acc: 0.72
Batch: 600; loss: 0.78; acc: 0.72
Batch: 620; loss: 0.79; acc: 0.64
Batch: 640; loss: 0.66; acc: 0.78
Batch: 660; loss: 0.72; acc: 0.75
Batch: 680; loss: 0.7; acc: 0.75
Batch: 700; loss: 0.92; acc: 0.75
Batch: 720; loss: 0.82; acc: 0.69
Batch: 740; loss: 1.18; acc: 0.67
Batch: 760; loss: 0.63; acc: 0.81
Batch: 780; loss: 0.78; acc: 0.77
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.94; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.72; acc: 0.73
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.75
Batch: 120; loss: 0.93; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7964283404456582; val_accuracy: 0.7410429936305732 

The current subspace-distance is: 7.201163680292666e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.96; acc: 0.66
Batch: 60; loss: 0.67; acc: 0.83
Batch: 80; loss: 0.95; acc: 0.64
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 1.01; acc: 0.61
Batch: 160; loss: 1.12; acc: 0.62
Batch: 180; loss: 0.65; acc: 0.8
Batch: 200; loss: 0.94; acc: 0.73
Batch: 220; loss: 0.77; acc: 0.73
Batch: 240; loss: 1.13; acc: 0.62
Batch: 260; loss: 0.62; acc: 0.77
Batch: 280; loss: 0.65; acc: 0.84
Batch: 300; loss: 0.78; acc: 0.77
Batch: 320; loss: 0.92; acc: 0.75
Batch: 340; loss: 0.83; acc: 0.73
Batch: 360; loss: 0.65; acc: 0.83
Batch: 380; loss: 0.84; acc: 0.69
Batch: 400; loss: 0.94; acc: 0.77
Batch: 420; loss: 0.91; acc: 0.69
Batch: 440; loss: 0.98; acc: 0.7
Batch: 460; loss: 0.64; acc: 0.78
Batch: 480; loss: 0.67; acc: 0.73
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 1.01; acc: 0.69
Batch: 540; loss: 0.56; acc: 0.78
Batch: 560; loss: 0.84; acc: 0.72
Batch: 580; loss: 0.98; acc: 0.62
Batch: 600; loss: 0.72; acc: 0.75
Batch: 620; loss: 0.88; acc: 0.77
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 0.84; acc: 0.73
Batch: 680; loss: 0.61; acc: 0.78
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.87; acc: 0.69
Batch: 740; loss: 0.84; acc: 0.67
Batch: 760; loss: 0.87; acc: 0.7
Batch: 780; loss: 0.79; acc: 0.72
Train Epoch over. train_loss: 0.83; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.67
Batch: 20; loss: 1.02; acc: 0.64
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.72; acc: 0.75
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.72
Batch: 120; loss: 0.93; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.7926062028499166; val_accuracy: 0.7433320063694268 

The current subspace-distance is: 7.545098196715117e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.82; acc: 0.72
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.97; acc: 0.66
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.74; acc: 0.72
Batch: 100; loss: 0.98; acc: 0.66
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.98; acc: 0.69
Batch: 160; loss: 1.0; acc: 0.75
Batch: 180; loss: 0.76; acc: 0.78
Batch: 200; loss: 0.65; acc: 0.69
Batch: 220; loss: 0.75; acc: 0.75
Batch: 240; loss: 0.85; acc: 0.7
Batch: 260; loss: 1.0; acc: 0.7
Batch: 280; loss: 0.59; acc: 0.83
Batch: 300; loss: 0.77; acc: 0.77
Batch: 320; loss: 0.89; acc: 0.75
Batch: 340; loss: 0.64; acc: 0.77
Batch: 360; loss: 0.85; acc: 0.69
Batch: 380; loss: 0.64; acc: 0.77
Batch: 400; loss: 0.71; acc: 0.78
Batch: 420; loss: 0.7; acc: 0.75
Batch: 440; loss: 0.8; acc: 0.73
Batch: 460; loss: 0.75; acc: 0.78
Batch: 480; loss: 1.08; acc: 0.64
Batch: 500; loss: 1.21; acc: 0.62
Batch: 520; loss: 0.87; acc: 0.73
Batch: 540; loss: 0.82; acc: 0.72
Batch: 560; loss: 0.81; acc: 0.7
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 0.8; acc: 0.7
Batch: 620; loss: 0.75; acc: 0.72
Batch: 640; loss: 0.97; acc: 0.72
Batch: 660; loss: 0.96; acc: 0.66
Batch: 680; loss: 0.87; acc: 0.67
Batch: 700; loss: 0.85; acc: 0.67
Batch: 720; loss: 0.92; acc: 0.78
Batch: 740; loss: 1.0; acc: 0.69
Batch: 760; loss: 0.84; acc: 0.72
Batch: 780; loss: 0.93; acc: 0.64
Train Epoch over. train_loss: 0.83; train_accuracy: 0.73 

Batch: 0; loss: 1.08; acc: 0.67
Batch: 20; loss: 1.13; acc: 0.61
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.93; acc: 0.78
Batch: 120; loss: 1.02; acc: 0.64
Batch: 140; loss: 0.48; acc: 0.84
Val Epoch over. val_loss: 0.8197174131110975; val_accuracy: 0.7385549363057324 

The current subspace-distance is: 7.589607412228361e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 0.92; acc: 0.67
Batch: 40; loss: 0.8; acc: 0.77
Batch: 60; loss: 1.05; acc: 0.69
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 0.81; acc: 0.73
Batch: 120; loss: 1.14; acc: 0.58
Batch: 140; loss: 1.12; acc: 0.69
Batch: 160; loss: 0.66; acc: 0.81
Batch: 180; loss: 1.02; acc: 0.69
Batch: 200; loss: 0.78; acc: 0.75
Batch: 220; loss: 0.84; acc: 0.72
Batch: 240; loss: 0.94; acc: 0.67
Batch: 260; loss: 0.86; acc: 0.73
Batch: 280; loss: 0.87; acc: 0.67
Batch: 300; loss: 0.83; acc: 0.72
Batch: 320; loss: 0.77; acc: 0.81
Batch: 340; loss: 0.83; acc: 0.8
Batch: 360; loss: 0.83; acc: 0.72
Batch: 380; loss: 0.71; acc: 0.77
Batch: 400; loss: 0.83; acc: 0.7
Batch: 420; loss: 1.0; acc: 0.58
Batch: 440; loss: 0.81; acc: 0.78
Batch: 460; loss: 0.76; acc: 0.75
Batch: 480; loss: 0.81; acc: 0.62
Batch: 500; loss: 0.72; acc: 0.78
Batch: 520; loss: 0.75; acc: 0.75
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.81; acc: 0.73
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 0.97; acc: 0.66
Batch: 620; loss: 0.68; acc: 0.72
Batch: 640; loss: 0.89; acc: 0.73
Batch: 660; loss: 0.83; acc: 0.69
Batch: 680; loss: 0.92; acc: 0.67
Batch: 700; loss: 0.62; acc: 0.75
Batch: 720; loss: 0.73; acc: 0.77
Batch: 740; loss: 0.98; acc: 0.7
Batch: 760; loss: 0.66; acc: 0.88
Batch: 780; loss: 0.96; acc: 0.66
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.98; acc: 0.64
Batch: 20; loss: 0.98; acc: 0.61
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.8; acc: 0.77
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.94; acc: 0.66
Batch: 140; loss: 0.45; acc: 0.83
Val Epoch over. val_loss: 0.7766718775223774; val_accuracy: 0.7476114649681529 

The current subspace-distance is: 7.739043940091506e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.09; acc: 0.59
Batch: 20; loss: 0.68; acc: 0.78
Batch: 40; loss: 0.98; acc: 0.75
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 0.8; acc: 0.75
Batch: 100; loss: 0.89; acc: 0.7
Batch: 120; loss: 0.84; acc: 0.7
Batch: 140; loss: 1.16; acc: 0.62
Batch: 160; loss: 0.82; acc: 0.77
Batch: 180; loss: 0.75; acc: 0.72
Batch: 200; loss: 0.69; acc: 0.7
Batch: 220; loss: 1.09; acc: 0.72
Batch: 240; loss: 0.82; acc: 0.75
Batch: 260; loss: 0.85; acc: 0.7
Batch: 280; loss: 1.19; acc: 0.61
Batch: 300; loss: 0.9; acc: 0.77
Batch: 320; loss: 0.91; acc: 0.7
Batch: 340; loss: 1.04; acc: 0.66
Batch: 360; loss: 0.95; acc: 0.73
Batch: 380; loss: 0.53; acc: 0.81
Batch: 400; loss: 0.7; acc: 0.77
Batch: 420; loss: 0.68; acc: 0.77
Batch: 440; loss: 0.68; acc: 0.78
Batch: 460; loss: 1.0; acc: 0.64
Batch: 480; loss: 0.84; acc: 0.7
Batch: 500; loss: 1.05; acc: 0.62
Batch: 520; loss: 0.78; acc: 0.78
Batch: 540; loss: 0.89; acc: 0.72
Batch: 560; loss: 0.9; acc: 0.69
Batch: 580; loss: 0.68; acc: 0.7
Batch: 600; loss: 0.82; acc: 0.75
Batch: 620; loss: 1.14; acc: 0.66
Batch: 640; loss: 0.7; acc: 0.78
Batch: 660; loss: 1.07; acc: 0.7
Batch: 680; loss: 0.83; acc: 0.69
Batch: 700; loss: 0.83; acc: 0.77
Batch: 720; loss: 0.62; acc: 0.83
Batch: 740; loss: 0.99; acc: 0.66
Batch: 760; loss: 0.82; acc: 0.73
Batch: 780; loss: 0.85; acc: 0.64
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.99; acc: 0.61
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.71; acc: 0.73
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 0.98; acc: 0.64
Batch: 140; loss: 0.48; acc: 0.81
Val Epoch over. val_loss: 0.7853643827757258; val_accuracy: 0.7430334394904459 

The current subspace-distance is: 7.820613973308355e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.11; acc: 0.75
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 1.03; acc: 0.58
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 1.04; acc: 0.78
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 1.07; acc: 0.61
Batch: 160; loss: 0.89; acc: 0.73
Batch: 180; loss: 1.01; acc: 0.73
Batch: 200; loss: 0.85; acc: 0.67
Batch: 220; loss: 0.65; acc: 0.81
Batch: 240; loss: 0.7; acc: 0.7
Batch: 260; loss: 0.7; acc: 0.81
Batch: 280; loss: 0.7; acc: 0.75
Batch: 300; loss: 1.01; acc: 0.61
Batch: 320; loss: 0.9; acc: 0.73
Batch: 340; loss: 1.04; acc: 0.73
Batch: 360; loss: 0.84; acc: 0.75
Batch: 380; loss: 0.74; acc: 0.73
Batch: 400; loss: 0.71; acc: 0.75
Batch: 420; loss: 0.57; acc: 0.78
Batch: 440; loss: 1.14; acc: 0.61
Batch: 460; loss: 0.71; acc: 0.73
Batch: 480; loss: 0.74; acc: 0.73
Batch: 500; loss: 1.02; acc: 0.69
Batch: 520; loss: 0.95; acc: 0.72
Batch: 540; loss: 0.81; acc: 0.77
Batch: 560; loss: 0.7; acc: 0.72
Batch: 580; loss: 0.57; acc: 0.84
Batch: 600; loss: 0.71; acc: 0.75
Batch: 620; loss: 0.74; acc: 0.78
Batch: 640; loss: 0.74; acc: 0.77
Batch: 660; loss: 0.81; acc: 0.73
Batch: 680; loss: 0.94; acc: 0.72
Batch: 700; loss: 0.65; acc: 0.78
Batch: 720; loss: 0.81; acc: 0.72
Batch: 740; loss: 0.67; acc: 0.73
Batch: 760; loss: 0.89; acc: 0.7
Batch: 780; loss: 0.89; acc: 0.73
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 1.02; acc: 0.62
Batch: 20; loss: 1.0; acc: 0.64
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.73; acc: 0.75
Batch: 80; loss: 0.85; acc: 0.8
Batch: 100; loss: 0.9; acc: 0.81
Batch: 120; loss: 0.98; acc: 0.7
Batch: 140; loss: 0.48; acc: 0.8
Val Epoch over. val_loss: 0.7957012719789128; val_accuracy: 0.7431329617834395 

The current subspace-distance is: 8.013148908503354e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.9; acc: 0.72
Batch: 20; loss: 0.66; acc: 0.8
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.88; acc: 0.67
Batch: 80; loss: 0.92; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.78
Batch: 120; loss: 0.97; acc: 0.69
Batch: 140; loss: 0.79; acc: 0.7
Batch: 160; loss: 0.82; acc: 0.72
Batch: 180; loss: 1.22; acc: 0.66
Batch: 200; loss: 0.83; acc: 0.67
Batch: 220; loss: 0.96; acc: 0.77
Batch: 240; loss: 0.99; acc: 0.66
Batch: 260; loss: 0.85; acc: 0.72
Batch: 280; loss: 1.01; acc: 0.7
Batch: 300; loss: 0.77; acc: 0.77
Batch: 320; loss: 0.76; acc: 0.73
Batch: 340; loss: 0.53; acc: 0.8
Batch: 360; loss: 1.21; acc: 0.67
Batch: 380; loss: 0.78; acc: 0.77
Batch: 400; loss: 0.97; acc: 0.75
Batch: 420; loss: 0.86; acc: 0.77
Batch: 440; loss: 0.78; acc: 0.83
Batch: 460; loss: 0.67; acc: 0.81
Batch: 480; loss: 0.59; acc: 0.8
Batch: 500; loss: 0.66; acc: 0.78
Batch: 520; loss: 0.89; acc: 0.78
Batch: 540; loss: 0.68; acc: 0.72
Batch: 560; loss: 0.74; acc: 0.72
Batch: 580; loss: 0.88; acc: 0.72
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 0.85; acc: 0.73
Batch: 640; loss: 0.77; acc: 0.7
Batch: 660; loss: 0.61; acc: 0.81
Batch: 680; loss: 0.84; acc: 0.67
Batch: 700; loss: 0.92; acc: 0.72
Batch: 720; loss: 0.84; acc: 0.75
Batch: 740; loss: 0.85; acc: 0.78
Batch: 760; loss: 0.64; acc: 0.75
Batch: 780; loss: 0.75; acc: 0.78
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 1.03; acc: 0.66
Batch: 20; loss: 1.06; acc: 0.59
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.79; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.8
Batch: 120; loss: 0.98; acc: 0.62
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7898983651665366; val_accuracy: 0.7446257961783439 

The current subspace-distance is: 8.059586980380118e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.1; acc: 0.66
Batch: 20; loss: 0.52; acc: 0.89
Batch: 40; loss: 0.69; acc: 0.72
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.95; acc: 0.77
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.91; acc: 0.67
Batch: 160; loss: 0.87; acc: 0.77
Batch: 180; loss: 0.72; acc: 0.8
Batch: 200; loss: 1.19; acc: 0.61
Batch: 220; loss: 1.14; acc: 0.7
Batch: 240; loss: 1.52; acc: 0.62
Batch: 260; loss: 0.88; acc: 0.66
Batch: 280; loss: 0.91; acc: 0.66
Batch: 300; loss: 0.83; acc: 0.72
Batch: 320; loss: 0.78; acc: 0.7
Batch: 340; loss: 0.88; acc: 0.72
Batch: 360; loss: 0.92; acc: 0.7
Batch: 380; loss: 1.28; acc: 0.72
Batch: 400; loss: 0.67; acc: 0.75
Batch: 420; loss: 0.73; acc: 0.73
Batch: 440; loss: 0.81; acc: 0.72
Batch: 460; loss: 0.89; acc: 0.7
Batch: 480; loss: 0.75; acc: 0.73
Batch: 500; loss: 0.98; acc: 0.73
Batch: 520; loss: 0.93; acc: 0.7
Batch: 540; loss: 0.79; acc: 0.73
Batch: 560; loss: 1.1; acc: 0.73
Batch: 580; loss: 0.72; acc: 0.8
Batch: 600; loss: 0.91; acc: 0.75
Batch: 620; loss: 0.87; acc: 0.69
Batch: 640; loss: 0.85; acc: 0.73
Batch: 660; loss: 0.68; acc: 0.8
Batch: 680; loss: 0.78; acc: 0.75
Batch: 700; loss: 0.7; acc: 0.72
Batch: 720; loss: 1.1; acc: 0.67
Batch: 740; loss: 0.98; acc: 0.66
Batch: 760; loss: 0.8; acc: 0.72
Batch: 780; loss: 0.68; acc: 0.81
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.98; acc: 0.66
Batch: 20; loss: 1.0; acc: 0.67
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.73; acc: 0.75
Batch: 80; loss: 0.83; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.81
Batch: 120; loss: 0.94; acc: 0.64
Batch: 140; loss: 0.46; acc: 0.88
Val Epoch over. val_loss: 0.7891474349103915; val_accuracy: 0.7448248407643312 

The current subspace-distance is: 8.317493484355509e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 0.97; acc: 0.72
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.72; acc: 0.78
Batch: 80; loss: 0.97; acc: 0.67
Batch: 100; loss: 0.99; acc: 0.66
Batch: 120; loss: 1.18; acc: 0.59
Batch: 140; loss: 0.87; acc: 0.75
Batch: 160; loss: 0.79; acc: 0.78
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.89; acc: 0.69
Batch: 220; loss: 0.97; acc: 0.66
Batch: 240; loss: 0.71; acc: 0.84
Batch: 260; loss: 0.97; acc: 0.67
Batch: 280; loss: 0.67; acc: 0.81
Batch: 300; loss: 0.87; acc: 0.75
Batch: 320; loss: 0.88; acc: 0.7
Batch: 340; loss: 0.76; acc: 0.83
Batch: 360; loss: 0.95; acc: 0.69
Batch: 380; loss: 0.74; acc: 0.77
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 0.9; acc: 0.8
Batch: 440; loss: 0.66; acc: 0.78
Batch: 460; loss: 0.85; acc: 0.67
Batch: 480; loss: 0.88; acc: 0.72
Batch: 500; loss: 0.8; acc: 0.8
Batch: 520; loss: 0.87; acc: 0.73
Batch: 540; loss: 0.79; acc: 0.73
Batch: 560; loss: 0.65; acc: 0.77
Batch: 580; loss: 0.56; acc: 0.78
Batch: 600; loss: 0.85; acc: 0.73
Batch: 620; loss: 0.76; acc: 0.8
Batch: 640; loss: 0.8; acc: 0.7
Batch: 660; loss: 0.77; acc: 0.75
Batch: 680; loss: 0.61; acc: 0.8
Batch: 700; loss: 0.67; acc: 0.78
Batch: 720; loss: 0.8; acc: 0.77
Batch: 740; loss: 1.12; acc: 0.67
Batch: 760; loss: 0.92; acc: 0.77
Batch: 780; loss: 0.69; acc: 0.75
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 1.0; acc: 0.62
Batch: 20; loss: 1.01; acc: 0.62
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.83; acc: 0.77
Batch: 100; loss: 0.89; acc: 0.83
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7824598140777297; val_accuracy: 0.7455214968152867 

The current subspace-distance is: 8.43209563754499e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 1.0; acc: 0.7
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.89; acc: 0.7
Batch: 80; loss: 0.64; acc: 0.77
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.78; acc: 0.77
Batch: 160; loss: 0.93; acc: 0.69
Batch: 180; loss: 0.8; acc: 0.69
Batch: 200; loss: 0.77; acc: 0.78
Batch: 220; loss: 0.81; acc: 0.77
Batch: 240; loss: 1.02; acc: 0.59
Batch: 260; loss: 0.76; acc: 0.69
Batch: 280; loss: 1.0; acc: 0.72
Batch: 300; loss: 0.84; acc: 0.72
Batch: 320; loss: 1.03; acc: 0.77
Batch: 340; loss: 0.68; acc: 0.77
Batch: 360; loss: 0.88; acc: 0.69
Batch: 380; loss: 0.84; acc: 0.78
Batch: 400; loss: 1.07; acc: 0.66
Batch: 420; loss: 0.77; acc: 0.7
Batch: 440; loss: 0.81; acc: 0.72
Batch: 460; loss: 1.12; acc: 0.67
Batch: 480; loss: 0.67; acc: 0.8
Batch: 500; loss: 0.9; acc: 0.67
Batch: 520; loss: 1.1; acc: 0.69
Batch: 540; loss: 0.76; acc: 0.7
Batch: 560; loss: 0.85; acc: 0.7
Batch: 580; loss: 0.96; acc: 0.73
Batch: 600; loss: 0.72; acc: 0.75
Batch: 620; loss: 1.1; acc: 0.7
Batch: 640; loss: 0.93; acc: 0.7
Batch: 660; loss: 1.18; acc: 0.64
Batch: 680; loss: 0.62; acc: 0.84
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.96; acc: 0.72
Batch: 740; loss: 0.71; acc: 0.75
Batch: 760; loss: 0.74; acc: 0.75
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.97; acc: 0.66
Batch: 20; loss: 1.02; acc: 0.61
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.89; acc: 0.78
Batch: 120; loss: 0.95; acc: 0.64
Batch: 140; loss: 0.47; acc: 0.81
Val Epoch over. val_loss: 0.7773035986787954; val_accuracy: 0.7469148089171974 

The current subspace-distance is: 8.540682756574824e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.8; acc: 0.78
Batch: 20; loss: 0.79; acc: 0.7
Batch: 40; loss: 0.77; acc: 0.7
Batch: 60; loss: 0.94; acc: 0.62
Batch: 80; loss: 0.77; acc: 0.8
Batch: 100; loss: 0.83; acc: 0.72
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.99; acc: 0.59
Batch: 160; loss: 0.77; acc: 0.81
Batch: 180; loss: 0.7; acc: 0.8
Batch: 200; loss: 1.12; acc: 0.64
Batch: 220; loss: 0.76; acc: 0.69
Batch: 240; loss: 0.7; acc: 0.75
Batch: 260; loss: 0.75; acc: 0.72
Batch: 280; loss: 0.65; acc: 0.77
Batch: 300; loss: 0.93; acc: 0.78
Batch: 320; loss: 1.16; acc: 0.62
Batch: 340; loss: 0.73; acc: 0.77
Batch: 360; loss: 0.59; acc: 0.84
Batch: 380; loss: 1.06; acc: 0.7
Batch: 400; loss: 0.99; acc: 0.72
Batch: 420; loss: 0.64; acc: 0.73
Batch: 440; loss: 0.88; acc: 0.72
Batch: 460; loss: 0.94; acc: 0.77
Batch: 480; loss: 0.9; acc: 0.69
Batch: 500; loss: 0.71; acc: 0.7
Batch: 520; loss: 0.68; acc: 0.78
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 1.18; acc: 0.67
Batch: 580; loss: 0.77; acc: 0.69
Batch: 600; loss: 0.77; acc: 0.7
Batch: 620; loss: 0.71; acc: 0.81
Batch: 640; loss: 0.93; acc: 0.77
Batch: 660; loss: 0.81; acc: 0.67
Batch: 680; loss: 0.52; acc: 0.88
Batch: 700; loss: 0.81; acc: 0.75
Batch: 720; loss: 0.54; acc: 0.83
Batch: 740; loss: 0.97; acc: 0.61
Batch: 760; loss: 0.76; acc: 0.77
Batch: 780; loss: 0.58; acc: 0.84
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.99; acc: 0.66
Batch: 20; loss: 1.04; acc: 0.59
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.89; acc: 0.8
Batch: 120; loss: 0.97; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.780103312176504; val_accuracy: 0.747312898089172 

The current subspace-distance is: 8.941979467635974e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.7; acc: 0.78
Batch: 20; loss: 0.92; acc: 0.72
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 0.86; acc: 0.72
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 0.69; acc: 0.73
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 1.06; acc: 0.7
Batch: 160; loss: 0.91; acc: 0.67
Batch: 180; loss: 0.66; acc: 0.78
Batch: 200; loss: 0.84; acc: 0.75
Batch: 220; loss: 0.65; acc: 0.81
Batch: 240; loss: 0.64; acc: 0.73
Batch: 260; loss: 0.65; acc: 0.78
Batch: 280; loss: 0.91; acc: 0.7
Batch: 300; loss: 0.82; acc: 0.75
Batch: 320; loss: 0.8; acc: 0.73
Batch: 340; loss: 0.6; acc: 0.77
Batch: 360; loss: 0.84; acc: 0.78
Batch: 380; loss: 0.73; acc: 0.73
Batch: 400; loss: 0.57; acc: 0.84
Batch: 420; loss: 0.69; acc: 0.73
Batch: 440; loss: 0.84; acc: 0.75
Batch: 460; loss: 0.83; acc: 0.75
Batch: 480; loss: 0.89; acc: 0.72
Batch: 500; loss: 0.62; acc: 0.78
Batch: 520; loss: 0.67; acc: 0.81
Batch: 540; loss: 0.72; acc: 0.77
Batch: 560; loss: 1.05; acc: 0.69
Batch: 580; loss: 0.7; acc: 0.8
Batch: 600; loss: 0.95; acc: 0.67
Batch: 620; loss: 0.77; acc: 0.73
Batch: 640; loss: 0.6; acc: 0.78
Batch: 660; loss: 0.75; acc: 0.77
Batch: 680; loss: 0.63; acc: 0.78
Batch: 700; loss: 0.99; acc: 0.7
Batch: 720; loss: 0.76; acc: 0.77
Batch: 740; loss: 0.54; acc: 0.78
Batch: 760; loss: 1.11; acc: 0.69
Batch: 780; loss: 1.21; acc: 0.62
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 1.02; acc: 0.64
Batch: 20; loss: 1.05; acc: 0.62
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.75
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.89; acc: 0.77
Batch: 120; loss: 1.0; acc: 0.64
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.7859957590224637; val_accuracy: 0.7444267515923567 

The current subspace-distance is: 9.061467426363379e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.22; acc: 0.69
Batch: 20; loss: 0.9; acc: 0.64
Batch: 40; loss: 0.83; acc: 0.78
Batch: 60; loss: 0.84; acc: 0.75
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 1.01; acc: 0.69
Batch: 120; loss: 1.02; acc: 0.67
Batch: 140; loss: 0.79; acc: 0.67
Batch: 160; loss: 0.72; acc: 0.73
Batch: 180; loss: 0.69; acc: 0.77
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.8; acc: 0.78
Batch: 240; loss: 0.81; acc: 0.72
Batch: 260; loss: 0.8; acc: 0.7
Batch: 280; loss: 1.05; acc: 0.7
Batch: 300; loss: 0.84; acc: 0.73
Batch: 320; loss: 0.78; acc: 0.7
Batch: 340; loss: 1.06; acc: 0.66
Batch: 360; loss: 0.69; acc: 0.75
Batch: 380; loss: 0.7; acc: 0.8
Batch: 400; loss: 0.72; acc: 0.75
Batch: 420; loss: 0.82; acc: 0.73
Batch: 440; loss: 0.66; acc: 0.73
Batch: 460; loss: 0.77; acc: 0.7
Batch: 480; loss: 0.76; acc: 0.69
Batch: 500; loss: 0.55; acc: 0.88
Batch: 520; loss: 0.85; acc: 0.67
Batch: 540; loss: 0.71; acc: 0.75
Batch: 560; loss: 1.02; acc: 0.66
Batch: 580; loss: 0.82; acc: 0.7
Batch: 600; loss: 0.84; acc: 0.8
Batch: 620; loss: 0.91; acc: 0.72
Batch: 640; loss: 1.06; acc: 0.64
Batch: 660; loss: 0.78; acc: 0.77
Batch: 680; loss: 0.89; acc: 0.7
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 1.04; acc: 0.69
Batch: 740; loss: 0.46; acc: 0.81
Batch: 760; loss: 0.81; acc: 0.8
Batch: 780; loss: 0.89; acc: 0.77
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.64
Batch: 20; loss: 1.02; acc: 0.62
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 0.89; acc: 0.77
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.7831290871094746; val_accuracy: 0.7426353503184714 

The current subspace-distance is: 9.0268105850555e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.06; acc: 0.7
Batch: 20; loss: 0.66; acc: 0.72
Batch: 40; loss: 0.79; acc: 0.75
Batch: 60; loss: 1.39; acc: 0.59
Batch: 80; loss: 0.92; acc: 0.67
Batch: 100; loss: 0.75; acc: 0.75
Batch: 120; loss: 0.84; acc: 0.69
Batch: 140; loss: 0.89; acc: 0.69
Batch: 160; loss: 1.01; acc: 0.64
Batch: 180; loss: 0.66; acc: 0.83
Batch: 200; loss: 0.67; acc: 0.77
Batch: 220; loss: 0.93; acc: 0.78
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.9; acc: 0.72
Batch: 280; loss: 0.86; acc: 0.73
Batch: 300; loss: 0.81; acc: 0.77
Batch: 320; loss: 0.86; acc: 0.7
Batch: 340; loss: 0.74; acc: 0.69
Batch: 360; loss: 0.68; acc: 0.77
Batch: 380; loss: 1.03; acc: 0.59
Batch: 400; loss: 0.72; acc: 0.77
Batch: 420; loss: 1.03; acc: 0.67
Batch: 440; loss: 0.81; acc: 0.73
Batch: 460; loss: 0.79; acc: 0.75
Batch: 480; loss: 0.75; acc: 0.8
Batch: 500; loss: 0.95; acc: 0.73
Batch: 520; loss: 0.78; acc: 0.67
Batch: 540; loss: 0.8; acc: 0.8
Batch: 560; loss: 0.55; acc: 0.83
Batch: 580; loss: 0.99; acc: 0.7
Batch: 600; loss: 0.76; acc: 0.7
Batch: 620; loss: 0.59; acc: 0.88
Batch: 640; loss: 1.06; acc: 0.64
Batch: 660; loss: 0.9; acc: 0.77
Batch: 680; loss: 0.85; acc: 0.75
Batch: 700; loss: 0.7; acc: 0.73
Batch: 720; loss: 0.96; acc: 0.66
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.96; acc: 0.66
Batch: 780; loss: 0.78; acc: 0.67
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.66
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.81
Val Epoch over. val_loss: 0.7741186260038121; val_accuracy: 0.75109474522293 

The current subspace-distance is: 8.984326268546283e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.7; acc: 0.8
Batch: 20; loss: 0.85; acc: 0.78
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.84; acc: 0.73
Batch: 100; loss: 1.1; acc: 0.69
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 1.0; acc: 0.67
Batch: 180; loss: 1.07; acc: 0.69
Batch: 200; loss: 0.58; acc: 0.75
Batch: 220; loss: 0.71; acc: 0.73
Batch: 240; loss: 1.0; acc: 0.73
Batch: 260; loss: 0.67; acc: 0.83
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.96; acc: 0.73
Batch: 320; loss: 0.93; acc: 0.69
Batch: 340; loss: 0.96; acc: 0.69
Batch: 360; loss: 0.59; acc: 0.78
Batch: 380; loss: 0.79; acc: 0.75
Batch: 400; loss: 0.69; acc: 0.77
Batch: 420; loss: 0.9; acc: 0.69
Batch: 440; loss: 0.7; acc: 0.75
Batch: 460; loss: 0.87; acc: 0.75
Batch: 480; loss: 0.92; acc: 0.7
Batch: 500; loss: 0.62; acc: 0.75
Batch: 520; loss: 0.58; acc: 0.81
Batch: 540; loss: 0.71; acc: 0.66
Batch: 560; loss: 0.78; acc: 0.77
Batch: 580; loss: 0.72; acc: 0.73
Batch: 600; loss: 0.73; acc: 0.73
Batch: 620; loss: 0.81; acc: 0.8
Batch: 640; loss: 0.83; acc: 0.67
Batch: 660; loss: 0.72; acc: 0.78
Batch: 680; loss: 0.82; acc: 0.69
Batch: 700; loss: 1.03; acc: 0.73
Batch: 720; loss: 0.81; acc: 0.72
Batch: 740; loss: 0.74; acc: 0.8
Batch: 760; loss: 0.77; acc: 0.77
Batch: 780; loss: 0.95; acc: 0.61
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.94; acc: 0.7
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7729969884559607; val_accuracy: 0.7502985668789809 

The current subspace-distance is: 9.087474609259516e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.9; acc: 0.67
Batch: 20; loss: 0.83; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.7
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.74; acc: 0.73
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.73
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.74; acc: 0.73
Batch: 180; loss: 0.62; acc: 0.78
Batch: 200; loss: 1.22; acc: 0.64
Batch: 220; loss: 0.73; acc: 0.73
Batch: 240; loss: 0.73; acc: 0.78
Batch: 260; loss: 0.62; acc: 0.8
Batch: 280; loss: 0.84; acc: 0.69
Batch: 300; loss: 0.77; acc: 0.75
Batch: 320; loss: 0.79; acc: 0.8
Batch: 340; loss: 1.07; acc: 0.67
Batch: 360; loss: 1.14; acc: 0.72
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 1.0; acc: 0.66
Batch: 420; loss: 0.89; acc: 0.75
Batch: 440; loss: 1.0; acc: 0.72
Batch: 460; loss: 0.78; acc: 0.81
Batch: 480; loss: 0.74; acc: 0.77
Batch: 500; loss: 1.04; acc: 0.62
Batch: 520; loss: 0.85; acc: 0.75
Batch: 540; loss: 0.73; acc: 0.77
Batch: 560; loss: 0.85; acc: 0.72
Batch: 580; loss: 0.74; acc: 0.77
Batch: 600; loss: 0.97; acc: 0.66
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.6; acc: 0.75
Batch: 660; loss: 0.8; acc: 0.8
Batch: 680; loss: 0.75; acc: 0.8
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 0.84; acc: 0.72
Batch: 740; loss: 0.81; acc: 0.75
Batch: 760; loss: 0.94; acc: 0.72
Batch: 780; loss: 0.88; acc: 0.73
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 1.01; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.7761778635963513; val_accuracy: 0.7490047770700637 

The current subspace-distance is: 9.233009768649936e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.99; acc: 0.7
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.92; acc: 0.72
Batch: 60; loss: 1.28; acc: 0.58
Batch: 80; loss: 0.84; acc: 0.72
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 0.79; acc: 0.7
Batch: 140; loss: 0.85; acc: 0.75
Batch: 160; loss: 1.01; acc: 0.73
Batch: 180; loss: 0.72; acc: 0.81
Batch: 200; loss: 0.91; acc: 0.75
Batch: 220; loss: 0.76; acc: 0.75
Batch: 240; loss: 0.91; acc: 0.72
Batch: 260; loss: 0.91; acc: 0.72
Batch: 280; loss: 0.96; acc: 0.67
Batch: 300; loss: 0.94; acc: 0.69
Batch: 320; loss: 0.82; acc: 0.75
Batch: 340; loss: 0.9; acc: 0.72
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 1.11; acc: 0.75
Batch: 400; loss: 0.74; acc: 0.77
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 1.0; acc: 0.64
Batch: 460; loss: 0.9; acc: 0.72
Batch: 480; loss: 0.68; acc: 0.81
Batch: 500; loss: 0.83; acc: 0.7
Batch: 520; loss: 0.81; acc: 0.67
Batch: 540; loss: 0.71; acc: 0.73
Batch: 560; loss: 1.03; acc: 0.69
Batch: 580; loss: 0.87; acc: 0.75
Batch: 600; loss: 0.6; acc: 0.81
Batch: 620; loss: 0.79; acc: 0.73
Batch: 640; loss: 1.1; acc: 0.69
Batch: 660; loss: 0.79; acc: 0.73
Batch: 680; loss: 0.87; acc: 0.73
Batch: 700; loss: 0.76; acc: 0.86
Batch: 720; loss: 1.07; acc: 0.67
Batch: 740; loss: 0.96; acc: 0.69
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.83; acc: 0.73
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 1.01; acc: 0.62
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.78
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.7753249664974821; val_accuracy: 0.74890525477707 

The current subspace-distance is: 9.42597325774841e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.79; acc: 0.67
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.7; acc: 0.73
Batch: 80; loss: 0.71; acc: 0.73
Batch: 100; loss: 1.32; acc: 0.62
Batch: 120; loss: 0.75; acc: 0.69
Batch: 140; loss: 0.64; acc: 0.83
Batch: 160; loss: 0.73; acc: 0.8
Batch: 180; loss: 0.96; acc: 0.66
Batch: 200; loss: 0.72; acc: 0.78
Batch: 220; loss: 0.6; acc: 0.78
Batch: 240; loss: 0.7; acc: 0.8
Batch: 260; loss: 1.05; acc: 0.64
Batch: 280; loss: 0.75; acc: 0.69
Batch: 300; loss: 0.86; acc: 0.78
Batch: 320; loss: 0.84; acc: 0.73
Batch: 340; loss: 1.01; acc: 0.7
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.73; acc: 0.72
Batch: 400; loss: 0.72; acc: 0.81
Batch: 420; loss: 0.44; acc: 0.83
Batch: 440; loss: 0.8; acc: 0.77
Batch: 460; loss: 0.91; acc: 0.73
Batch: 480; loss: 0.81; acc: 0.75
Batch: 500; loss: 0.91; acc: 0.72
Batch: 520; loss: 0.87; acc: 0.75
Batch: 540; loss: 0.96; acc: 0.77
Batch: 560; loss: 0.69; acc: 0.75
Batch: 580; loss: 0.59; acc: 0.81
Batch: 600; loss: 1.08; acc: 0.62
Batch: 620; loss: 0.74; acc: 0.72
Batch: 640; loss: 0.81; acc: 0.75
Batch: 660; loss: 0.94; acc: 0.7
Batch: 680; loss: 0.85; acc: 0.72
Batch: 700; loss: 0.95; acc: 0.72
Batch: 720; loss: 1.09; acc: 0.58
Batch: 740; loss: 1.22; acc: 0.67
Batch: 760; loss: 0.55; acc: 0.83
Batch: 780; loss: 0.66; acc: 0.78
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.774523836791895; val_accuracy: 0.75109474522293 

The current subspace-distance is: 9.398250404046848e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 0.85; acc: 0.75
Batch: 60; loss: 0.76; acc: 0.81
Batch: 80; loss: 0.99; acc: 0.7
Batch: 100; loss: 0.93; acc: 0.72
Batch: 120; loss: 1.17; acc: 0.62
Batch: 140; loss: 0.9; acc: 0.72
Batch: 160; loss: 0.82; acc: 0.75
Batch: 180; loss: 1.34; acc: 0.62
Batch: 200; loss: 0.8; acc: 0.75
Batch: 220; loss: 1.01; acc: 0.66
Batch: 240; loss: 0.75; acc: 0.72
Batch: 260; loss: 0.85; acc: 0.7
Batch: 280; loss: 1.02; acc: 0.67
Batch: 300; loss: 1.05; acc: 0.69
Batch: 320; loss: 0.71; acc: 0.8
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.67; acc: 0.81
Batch: 380; loss: 0.67; acc: 0.75
Batch: 400; loss: 0.83; acc: 0.75
Batch: 420; loss: 0.79; acc: 0.75
Batch: 440; loss: 1.21; acc: 0.7
Batch: 460; loss: 1.46; acc: 0.59
Batch: 480; loss: 0.98; acc: 0.64
Batch: 500; loss: 0.75; acc: 0.8
Batch: 520; loss: 0.91; acc: 0.66
Batch: 540; loss: 0.91; acc: 0.61
Batch: 560; loss: 0.63; acc: 0.77
Batch: 580; loss: 0.77; acc: 0.73
Batch: 600; loss: 0.82; acc: 0.77
Batch: 620; loss: 0.98; acc: 0.72
Batch: 640; loss: 0.79; acc: 0.73
Batch: 660; loss: 0.85; acc: 0.72
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 1.01; acc: 0.67
Batch: 720; loss: 0.65; acc: 0.77
Batch: 740; loss: 0.82; acc: 0.75
Batch: 760; loss: 0.75; acc: 0.77
Batch: 780; loss: 0.79; acc: 0.73
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.94; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.86
Val Epoch over. val_loss: 0.7739242958794733; val_accuracy: 0.75109474522293 

The current subspace-distance is: 9.464233880862594e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.03; acc: 0.69
Batch: 20; loss: 0.69; acc: 0.78
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.91; acc: 0.72
Batch: 80; loss: 0.72; acc: 0.73
Batch: 100; loss: 0.61; acc: 0.84
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.73; acc: 0.75
Batch: 160; loss: 0.87; acc: 0.75
Batch: 180; loss: 0.54; acc: 0.83
Batch: 200; loss: 0.77; acc: 0.78
Batch: 220; loss: 0.93; acc: 0.75
Batch: 240; loss: 0.62; acc: 0.81
Batch: 260; loss: 0.7; acc: 0.8
Batch: 280; loss: 1.22; acc: 0.56
Batch: 300; loss: 0.92; acc: 0.73
Batch: 320; loss: 0.65; acc: 0.81
Batch: 340; loss: 0.62; acc: 0.8
Batch: 360; loss: 0.64; acc: 0.75
Batch: 380; loss: 0.69; acc: 0.77
Batch: 400; loss: 0.68; acc: 0.77
Batch: 420; loss: 0.86; acc: 0.72
Batch: 440; loss: 0.88; acc: 0.7
Batch: 460; loss: 1.02; acc: 0.69
Batch: 480; loss: 0.88; acc: 0.66
Batch: 500; loss: 0.56; acc: 0.8
Batch: 520; loss: 0.93; acc: 0.67
Batch: 540; loss: 1.01; acc: 0.73
Batch: 560; loss: 1.1; acc: 0.59
Batch: 580; loss: 0.8; acc: 0.72
Batch: 600; loss: 0.69; acc: 0.78
Batch: 620; loss: 1.05; acc: 0.72
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.91; acc: 0.73
Batch: 680; loss: 0.52; acc: 0.81
Batch: 700; loss: 0.91; acc: 0.61
Batch: 720; loss: 0.65; acc: 0.75
Batch: 740; loss: 0.97; acc: 0.7
Batch: 760; loss: 0.69; acc: 0.75
Batch: 780; loss: 0.65; acc: 0.78
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 1.0; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.88; acc: 0.78
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.775386585741286; val_accuracy: 0.7499004777070064 

The current subspace-distance is: 9.539204620523378e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.98; acc: 0.73
Batch: 20; loss: 0.73; acc: 0.75
Batch: 40; loss: 0.67; acc: 0.77
Batch: 60; loss: 1.02; acc: 0.62
Batch: 80; loss: 0.67; acc: 0.81
Batch: 100; loss: 0.89; acc: 0.69
Batch: 120; loss: 0.71; acc: 0.86
Batch: 140; loss: 0.89; acc: 0.73
Batch: 160; loss: 0.9; acc: 0.77
Batch: 180; loss: 0.89; acc: 0.69
Batch: 200; loss: 0.83; acc: 0.75
Batch: 220; loss: 0.84; acc: 0.75
Batch: 240; loss: 0.81; acc: 0.7
Batch: 260; loss: 0.76; acc: 0.7
Batch: 280; loss: 1.01; acc: 0.69
Batch: 300; loss: 1.13; acc: 0.64
Batch: 320; loss: 0.98; acc: 0.64
Batch: 340; loss: 0.82; acc: 0.69
Batch: 360; loss: 0.91; acc: 0.67
Batch: 380; loss: 0.68; acc: 0.77
Batch: 400; loss: 0.71; acc: 0.75
Batch: 420; loss: 0.99; acc: 0.72
Batch: 440; loss: 0.73; acc: 0.75
Batch: 460; loss: 0.95; acc: 0.7
Batch: 480; loss: 0.97; acc: 0.67
Batch: 500; loss: 0.84; acc: 0.8
Batch: 520; loss: 1.06; acc: 0.66
Batch: 540; loss: 0.75; acc: 0.72
Batch: 560; loss: 0.73; acc: 0.77
Batch: 580; loss: 0.93; acc: 0.67
Batch: 600; loss: 0.77; acc: 0.73
Batch: 620; loss: 0.72; acc: 0.77
Batch: 640; loss: 0.88; acc: 0.73
Batch: 660; loss: 0.86; acc: 0.75
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.57; acc: 0.78
Batch: 720; loss: 0.75; acc: 0.7
Batch: 740; loss: 0.81; acc: 0.69
Batch: 760; loss: 1.03; acc: 0.7
Batch: 780; loss: 0.72; acc: 0.78
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 1.0; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.78
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.775913339511604; val_accuracy: 0.7476114649681529 

The current subspace-distance is: 9.731221507536247e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.95; acc: 0.69
Batch: 20; loss: 1.02; acc: 0.66
Batch: 40; loss: 0.98; acc: 0.73
Batch: 60; loss: 0.91; acc: 0.7
Batch: 80; loss: 0.83; acc: 0.72
Batch: 100; loss: 0.98; acc: 0.73
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.69; acc: 0.81
Batch: 160; loss: 0.69; acc: 0.77
Batch: 180; loss: 1.06; acc: 0.67
Batch: 200; loss: 0.64; acc: 0.81
Batch: 220; loss: 0.84; acc: 0.66
Batch: 240; loss: 0.88; acc: 0.62
Batch: 260; loss: 0.75; acc: 0.78
Batch: 280; loss: 0.68; acc: 0.75
Batch: 300; loss: 0.78; acc: 0.77
Batch: 320; loss: 0.82; acc: 0.72
Batch: 340; loss: 0.88; acc: 0.67
Batch: 360; loss: 0.91; acc: 0.75
Batch: 380; loss: 0.8; acc: 0.75
Batch: 400; loss: 0.58; acc: 0.83
Batch: 420; loss: 0.9; acc: 0.77
Batch: 440; loss: 0.8; acc: 0.72
Batch: 460; loss: 0.63; acc: 0.81
Batch: 480; loss: 0.94; acc: 0.62
Batch: 500; loss: 0.82; acc: 0.69
Batch: 520; loss: 0.68; acc: 0.77
Batch: 540; loss: 0.86; acc: 0.72
Batch: 560; loss: 0.97; acc: 0.7
Batch: 580; loss: 0.85; acc: 0.72
Batch: 600; loss: 0.91; acc: 0.67
Batch: 620; loss: 0.84; acc: 0.73
Batch: 640; loss: 0.58; acc: 0.83
Batch: 660; loss: 0.74; acc: 0.78
Batch: 680; loss: 0.81; acc: 0.78
Batch: 700; loss: 0.64; acc: 0.78
Batch: 720; loss: 0.53; acc: 0.8
Batch: 740; loss: 0.76; acc: 0.7
Batch: 760; loss: 0.59; acc: 0.78
Batch: 780; loss: 0.79; acc: 0.8
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.7729218047895249; val_accuracy: 0.7488057324840764 

The current subspace-distance is: 9.84663565759547e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 0.8; acc: 0.77
Batch: 40; loss: 0.74; acc: 0.75
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 1.06; acc: 0.73
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 0.68; acc: 0.72
Batch: 140; loss: 0.64; acc: 0.8
Batch: 160; loss: 0.68; acc: 0.78
Batch: 180; loss: 0.65; acc: 0.81
Batch: 200; loss: 0.74; acc: 0.72
Batch: 220; loss: 0.63; acc: 0.75
Batch: 240; loss: 0.89; acc: 0.7
Batch: 260; loss: 1.15; acc: 0.67
Batch: 280; loss: 1.19; acc: 0.66
Batch: 300; loss: 0.9; acc: 0.75
Batch: 320; loss: 0.71; acc: 0.77
Batch: 340; loss: 0.76; acc: 0.73
Batch: 360; loss: 1.0; acc: 0.67
Batch: 380; loss: 0.77; acc: 0.77
Batch: 400; loss: 0.79; acc: 0.69
Batch: 420; loss: 0.99; acc: 0.64
Batch: 440; loss: 0.72; acc: 0.72
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.71; acc: 0.77
Batch: 500; loss: 0.89; acc: 0.58
Batch: 520; loss: 0.65; acc: 0.77
Batch: 540; loss: 0.74; acc: 0.72
Batch: 560; loss: 1.12; acc: 0.64
Batch: 580; loss: 1.04; acc: 0.73
Batch: 600; loss: 0.84; acc: 0.69
Batch: 620; loss: 0.7; acc: 0.78
Batch: 640; loss: 0.73; acc: 0.78
Batch: 660; loss: 0.8; acc: 0.77
Batch: 680; loss: 0.73; acc: 0.8
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.64; acc: 0.8
Batch: 740; loss: 1.02; acc: 0.62
Batch: 760; loss: 0.85; acc: 0.73
Batch: 780; loss: 0.74; acc: 0.77
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.67
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.71; acc: 0.75
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7752548006309825; val_accuracy: 0.7499004777070064 

The current subspace-distance is: 9.960243187379092e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.07; acc: 0.69
Batch: 20; loss: 0.98; acc: 0.73
Batch: 40; loss: 1.21; acc: 0.62
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.89; acc: 0.67
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.67; acc: 0.73
Batch: 140; loss: 0.92; acc: 0.67
Batch: 160; loss: 0.85; acc: 0.72
Batch: 180; loss: 0.65; acc: 0.78
Batch: 200; loss: 0.74; acc: 0.75
Batch: 220; loss: 0.96; acc: 0.64
Batch: 240; loss: 0.88; acc: 0.73
Batch: 260; loss: 0.75; acc: 0.73
Batch: 280; loss: 0.81; acc: 0.77
Batch: 300; loss: 0.73; acc: 0.75
Batch: 320; loss: 0.88; acc: 0.7
Batch: 340; loss: 0.85; acc: 0.67
Batch: 360; loss: 0.71; acc: 0.84
Batch: 380; loss: 0.76; acc: 0.75
Batch: 400; loss: 0.94; acc: 0.67
Batch: 420; loss: 0.69; acc: 0.75
Batch: 440; loss: 0.99; acc: 0.64
Batch: 460; loss: 0.93; acc: 0.7
Batch: 480; loss: 0.78; acc: 0.75
Batch: 500; loss: 0.74; acc: 0.77
Batch: 520; loss: 0.73; acc: 0.72
Batch: 540; loss: 0.62; acc: 0.81
Batch: 560; loss: 0.97; acc: 0.69
Batch: 580; loss: 0.95; acc: 0.66
Batch: 600; loss: 1.17; acc: 0.69
Batch: 620; loss: 0.89; acc: 0.73
Batch: 640; loss: 0.68; acc: 0.77
Batch: 660; loss: 0.89; acc: 0.69
Batch: 680; loss: 0.9; acc: 0.77
Batch: 700; loss: 0.8; acc: 0.72
Batch: 720; loss: 0.75; acc: 0.73
Batch: 740; loss: 0.79; acc: 0.73
Batch: 760; loss: 1.02; acc: 0.62
Batch: 780; loss: 0.97; acc: 0.66
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7730496637760453; val_accuracy: 0.7512937898089171 

The current subspace-distance is: 0.00010025982192019 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.97; acc: 0.75
Batch: 20; loss: 0.93; acc: 0.69
Batch: 40; loss: 0.61; acc: 0.77
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.6; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.8
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.68; acc: 0.81
Batch: 160; loss: 0.66; acc: 0.78
Batch: 180; loss: 0.69; acc: 0.77
Batch: 200; loss: 0.67; acc: 0.78
Batch: 220; loss: 0.62; acc: 0.77
Batch: 240; loss: 0.98; acc: 0.75
Batch: 260; loss: 0.69; acc: 0.83
Batch: 280; loss: 0.78; acc: 0.75
Batch: 300; loss: 0.76; acc: 0.8
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.96; acc: 0.75
Batch: 360; loss: 0.91; acc: 0.7
Batch: 380; loss: 0.84; acc: 0.72
Batch: 400; loss: 0.74; acc: 0.83
Batch: 420; loss: 0.8; acc: 0.75
Batch: 440; loss: 0.79; acc: 0.78
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.99; acc: 0.73
Batch: 500; loss: 0.73; acc: 0.75
Batch: 520; loss: 0.76; acc: 0.75
Batch: 540; loss: 0.67; acc: 0.8
Batch: 560; loss: 0.82; acc: 0.73
Batch: 580; loss: 0.86; acc: 0.7
Batch: 600; loss: 0.66; acc: 0.77
Batch: 620; loss: 0.99; acc: 0.7
Batch: 640; loss: 0.87; acc: 0.75
Batch: 660; loss: 0.74; acc: 0.69
Batch: 680; loss: 0.79; acc: 0.67
Batch: 700; loss: 0.67; acc: 0.73
Batch: 720; loss: 0.74; acc: 0.69
Batch: 740; loss: 0.86; acc: 0.67
Batch: 760; loss: 0.82; acc: 0.7
Batch: 780; loss: 0.93; acc: 0.64
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.67
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7724459055502704; val_accuracy: 0.7513933121019108 

The current subspace-distance is: 0.00010197798110311851 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.95; acc: 0.69
Batch: 20; loss: 0.77; acc: 0.78
Batch: 40; loss: 0.58; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.88
Batch: 80; loss: 1.08; acc: 0.61
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.74; acc: 0.7
Batch: 140; loss: 0.72; acc: 0.75
Batch: 160; loss: 0.94; acc: 0.69
Batch: 180; loss: 0.75; acc: 0.73
Batch: 200; loss: 1.03; acc: 0.66
Batch: 220; loss: 0.93; acc: 0.7
Batch: 240; loss: 0.76; acc: 0.72
Batch: 260; loss: 1.09; acc: 0.66
Batch: 280; loss: 0.74; acc: 0.77
Batch: 300; loss: 0.83; acc: 0.72
Batch: 320; loss: 0.8; acc: 0.7
Batch: 340; loss: 0.7; acc: 0.86
Batch: 360; loss: 1.08; acc: 0.64
Batch: 380; loss: 0.75; acc: 0.73
Batch: 400; loss: 0.66; acc: 0.75
Batch: 420; loss: 0.72; acc: 0.77
Batch: 440; loss: 0.74; acc: 0.72
Batch: 460; loss: 0.87; acc: 0.7
Batch: 480; loss: 0.72; acc: 0.78
Batch: 500; loss: 0.69; acc: 0.72
Batch: 520; loss: 0.81; acc: 0.73
Batch: 540; loss: 0.66; acc: 0.8
Batch: 560; loss: 1.27; acc: 0.69
Batch: 580; loss: 0.75; acc: 0.78
Batch: 600; loss: 0.65; acc: 0.75
Batch: 620; loss: 0.85; acc: 0.75
Batch: 640; loss: 0.66; acc: 0.75
Batch: 660; loss: 0.75; acc: 0.78
Batch: 680; loss: 1.1; acc: 0.69
Batch: 700; loss: 0.92; acc: 0.67
Batch: 720; loss: 0.87; acc: 0.75
Batch: 740; loss: 0.68; acc: 0.73
Batch: 760; loss: 0.84; acc: 0.67
Batch: 780; loss: 0.6; acc: 0.78
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.96; acc: 0.67
Batch: 20; loss: 1.01; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.77; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.66
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7742369586874724; val_accuracy: 0.7512937898089171 

The current subspace-distance is: 0.00010497364564798772 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.97; acc: 0.66
Batch: 20; loss: 0.86; acc: 0.7
Batch: 40; loss: 1.05; acc: 0.62
Batch: 60; loss: 1.02; acc: 0.67
Batch: 80; loss: 0.96; acc: 0.67
Batch: 100; loss: 0.9; acc: 0.7
Batch: 120; loss: 1.11; acc: 0.69
Batch: 140; loss: 0.8; acc: 0.72
Batch: 160; loss: 0.65; acc: 0.77
Batch: 180; loss: 0.8; acc: 0.73
Batch: 200; loss: 1.27; acc: 0.64
Batch: 220; loss: 0.61; acc: 0.81
Batch: 240; loss: 0.85; acc: 0.75
Batch: 260; loss: 0.93; acc: 0.62
Batch: 280; loss: 0.62; acc: 0.77
Batch: 300; loss: 0.68; acc: 0.81
Batch: 320; loss: 0.86; acc: 0.75
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.84; acc: 0.7
Batch: 380; loss: 0.72; acc: 0.77
Batch: 400; loss: 1.09; acc: 0.67
Batch: 420; loss: 0.73; acc: 0.73
Batch: 440; loss: 0.76; acc: 0.78
Batch: 460; loss: 0.79; acc: 0.72
Batch: 480; loss: 0.78; acc: 0.75
Batch: 500; loss: 0.64; acc: 0.77
Batch: 520; loss: 0.66; acc: 0.84
Batch: 540; loss: 0.86; acc: 0.67
Batch: 560; loss: 0.83; acc: 0.75
Batch: 580; loss: 0.87; acc: 0.77
Batch: 600; loss: 1.07; acc: 0.73
Batch: 620; loss: 0.94; acc: 0.67
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 1.15; acc: 0.69
Batch: 680; loss: 0.94; acc: 0.7
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.76; acc: 0.75
Batch: 740; loss: 0.72; acc: 0.72
Batch: 760; loss: 0.97; acc: 0.67
Batch: 780; loss: 0.74; acc: 0.77
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.66
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7742179681541054; val_accuracy: 0.7487062101910829 

The current subspace-distance is: 0.00010659070539986715 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.99; acc: 0.66
Batch: 20; loss: 0.7; acc: 0.77
Batch: 40; loss: 0.97; acc: 0.66
Batch: 60; loss: 0.83; acc: 0.7
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 0.78; acc: 0.73
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.95; acc: 0.73
Batch: 160; loss: 0.72; acc: 0.81
Batch: 180; loss: 0.72; acc: 0.78
Batch: 200; loss: 0.75; acc: 0.78
Batch: 220; loss: 0.85; acc: 0.72
Batch: 240; loss: 0.93; acc: 0.77
Batch: 260; loss: 0.58; acc: 0.88
Batch: 280; loss: 0.67; acc: 0.73
Batch: 300; loss: 0.7; acc: 0.77
Batch: 320; loss: 0.63; acc: 0.81
Batch: 340; loss: 0.8; acc: 0.75
Batch: 360; loss: 0.69; acc: 0.78
Batch: 380; loss: 0.62; acc: 0.8
Batch: 400; loss: 0.9; acc: 0.69
Batch: 420; loss: 0.73; acc: 0.7
Batch: 440; loss: 1.06; acc: 0.73
Batch: 460; loss: 0.88; acc: 0.66
Batch: 480; loss: 0.82; acc: 0.69
Batch: 500; loss: 0.91; acc: 0.75
Batch: 520; loss: 0.87; acc: 0.75
Batch: 540; loss: 0.65; acc: 0.8
Batch: 560; loss: 0.57; acc: 0.83
Batch: 580; loss: 0.75; acc: 0.78
Batch: 600; loss: 0.9; acc: 0.67
Batch: 620; loss: 0.58; acc: 0.81
Batch: 640; loss: 1.0; acc: 0.72
Batch: 660; loss: 0.91; acc: 0.73
Batch: 680; loss: 0.91; acc: 0.69
Batch: 700; loss: 1.13; acc: 0.73
Batch: 720; loss: 0.85; acc: 0.73
Batch: 740; loss: 0.67; acc: 0.8
Batch: 760; loss: 0.77; acc: 0.7
Batch: 780; loss: 0.84; acc: 0.69
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7723998632400658; val_accuracy: 0.7533837579617835 

The current subspace-distance is: 0.00010797837603604421 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.95; acc: 0.69
Batch: 20; loss: 0.74; acc: 0.78
Batch: 40; loss: 0.66; acc: 0.77
Batch: 60; loss: 0.81; acc: 0.7
Batch: 80; loss: 1.05; acc: 0.62
Batch: 100; loss: 1.07; acc: 0.56
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.72; acc: 0.8
Batch: 160; loss: 1.05; acc: 0.67
Batch: 180; loss: 0.77; acc: 0.73
Batch: 200; loss: 1.06; acc: 0.7
Batch: 220; loss: 1.07; acc: 0.61
Batch: 240; loss: 0.77; acc: 0.7
Batch: 260; loss: 0.85; acc: 0.7
Batch: 280; loss: 1.11; acc: 0.66
Batch: 300; loss: 0.92; acc: 0.7
Batch: 320; loss: 0.93; acc: 0.73
Batch: 340; loss: 0.74; acc: 0.77
Batch: 360; loss: 1.26; acc: 0.69
Batch: 380; loss: 0.59; acc: 0.78
Batch: 400; loss: 0.87; acc: 0.72
Batch: 420; loss: 1.06; acc: 0.56
Batch: 440; loss: 0.98; acc: 0.78
Batch: 460; loss: 0.88; acc: 0.7
Batch: 480; loss: 0.88; acc: 0.77
Batch: 500; loss: 1.06; acc: 0.69
Batch: 520; loss: 1.06; acc: 0.67
Batch: 540; loss: 0.53; acc: 0.86
Batch: 560; loss: 0.64; acc: 0.84
Batch: 580; loss: 1.22; acc: 0.67
Batch: 600; loss: 0.77; acc: 0.78
Batch: 620; loss: 0.72; acc: 0.83
Batch: 640; loss: 1.1; acc: 0.64
Batch: 660; loss: 1.13; acc: 0.72
Batch: 680; loss: 0.86; acc: 0.78
Batch: 700; loss: 0.86; acc: 0.73
Batch: 720; loss: 1.08; acc: 0.67
Batch: 740; loss: 0.8; acc: 0.75
Batch: 760; loss: 0.92; acc: 0.73
Batch: 780; loss: 0.92; acc: 0.69
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.95; acc: 0.64
Batch: 20; loss: 1.0; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7733724346965741; val_accuracy: 0.7523885350318471 

The current subspace-distance is: 0.00010974748147418723 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.73; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.75
Batch: 40; loss: 0.89; acc: 0.7
Batch: 60; loss: 0.8; acc: 0.77
Batch: 80; loss: 0.77; acc: 0.84
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.77; acc: 0.8
Batch: 160; loss: 1.05; acc: 0.64
Batch: 180; loss: 0.74; acc: 0.8
Batch: 200; loss: 0.96; acc: 0.69
Batch: 220; loss: 0.69; acc: 0.8
Batch: 240; loss: 0.86; acc: 0.72
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 0.82; acc: 0.78
Batch: 300; loss: 0.75; acc: 0.72
Batch: 320; loss: 1.01; acc: 0.75
Batch: 340; loss: 0.57; acc: 0.75
Batch: 360; loss: 0.8; acc: 0.75
Batch: 380; loss: 0.73; acc: 0.73
Batch: 400; loss: 0.97; acc: 0.62
Batch: 420; loss: 0.74; acc: 0.77
Batch: 440; loss: 0.77; acc: 0.77
Batch: 460; loss: 0.77; acc: 0.72
Batch: 480; loss: 0.65; acc: 0.78
Batch: 500; loss: 1.12; acc: 0.7
Batch: 520; loss: 0.85; acc: 0.75
Batch: 540; loss: 1.08; acc: 0.73
Batch: 560; loss: 0.94; acc: 0.69
Batch: 580; loss: 0.77; acc: 0.78
Batch: 600; loss: 0.81; acc: 0.73
Batch: 620; loss: 0.78; acc: 0.77
Batch: 640; loss: 0.63; acc: 0.81
Batch: 660; loss: 0.68; acc: 0.73
Batch: 680; loss: 0.78; acc: 0.73
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 1.1; acc: 0.69
Batch: 740; loss: 0.89; acc: 0.7
Batch: 760; loss: 1.06; acc: 0.64
Batch: 780; loss: 0.78; acc: 0.75
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.94; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.77; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.7723332210710854; val_accuracy: 0.7517914012738853 

The current subspace-distance is: 0.00011139112029923126 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.77; acc: 0.83
Batch: 20; loss: 0.92; acc: 0.72
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.9; acc: 0.72
Batch: 80; loss: 0.72; acc: 0.75
Batch: 100; loss: 0.72; acc: 0.73
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 1.1; acc: 0.66
Batch: 160; loss: 0.93; acc: 0.73
Batch: 180; loss: 1.24; acc: 0.64
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 1.27; acc: 0.66
Batch: 240; loss: 0.84; acc: 0.7
Batch: 260; loss: 0.54; acc: 0.8
Batch: 280; loss: 0.72; acc: 0.84
Batch: 300; loss: 0.66; acc: 0.78
Batch: 320; loss: 0.89; acc: 0.72
Batch: 340; loss: 0.93; acc: 0.72
Batch: 360; loss: 0.9; acc: 0.67
Batch: 380; loss: 0.64; acc: 0.78
Batch: 400; loss: 0.65; acc: 0.75
Batch: 420; loss: 1.01; acc: 0.7
Batch: 440; loss: 0.71; acc: 0.73
Batch: 460; loss: 1.1; acc: 0.66
Batch: 480; loss: 0.76; acc: 0.75
Batch: 500; loss: 0.8; acc: 0.72
Batch: 520; loss: 0.81; acc: 0.69
Batch: 540; loss: 1.01; acc: 0.7
Batch: 560; loss: 0.94; acc: 0.72
Batch: 580; loss: 0.59; acc: 0.78
Batch: 600; loss: 0.9; acc: 0.72
Batch: 620; loss: 1.14; acc: 0.61
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.84; acc: 0.72
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 1.05; acc: 0.69
Batch: 720; loss: 1.08; acc: 0.61
Batch: 740; loss: 1.09; acc: 0.58
Batch: 760; loss: 0.96; acc: 0.72
Batch: 780; loss: 0.7; acc: 0.77
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.64
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.7723681273733735; val_accuracy: 0.7511942675159236 

The current subspace-distance is: 0.00011287343659205362 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.76; acc: 0.73
Batch: 20; loss: 0.86; acc: 0.73
Batch: 40; loss: 1.17; acc: 0.66
Batch: 60; loss: 0.99; acc: 0.7
Batch: 80; loss: 0.85; acc: 0.77
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.97; acc: 0.69
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.81; acc: 0.69
Batch: 200; loss: 0.69; acc: 0.77
Batch: 220; loss: 1.02; acc: 0.64
Batch: 240; loss: 0.88; acc: 0.75
Batch: 260; loss: 0.78; acc: 0.81
Batch: 280; loss: 0.95; acc: 0.67
Batch: 300; loss: 0.98; acc: 0.66
Batch: 320; loss: 1.02; acc: 0.64
Batch: 340; loss: 0.94; acc: 0.69
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 0.85; acc: 0.72
Batch: 400; loss: 0.98; acc: 0.69
Batch: 420; loss: 0.81; acc: 0.7
Batch: 440; loss: 0.6; acc: 0.86
Batch: 460; loss: 0.98; acc: 0.73
Batch: 480; loss: 0.59; acc: 0.78
Batch: 500; loss: 0.61; acc: 0.83
Batch: 520; loss: 0.73; acc: 0.77
Batch: 540; loss: 0.8; acc: 0.83
Batch: 560; loss: 0.73; acc: 0.78
Batch: 580; loss: 1.23; acc: 0.61
Batch: 600; loss: 1.12; acc: 0.7
Batch: 620; loss: 0.76; acc: 0.78
Batch: 640; loss: 0.87; acc: 0.7
Batch: 660; loss: 0.92; acc: 0.7
Batch: 680; loss: 0.79; acc: 0.73
Batch: 700; loss: 0.54; acc: 0.8
Batch: 720; loss: 1.13; acc: 0.59
Batch: 740; loss: 1.02; acc: 0.67
Batch: 760; loss: 0.55; acc: 0.83
Batch: 780; loss: 0.72; acc: 0.72
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.94; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.77; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.95; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.7719525740404797; val_accuracy: 0.7513933121019108 

The current subspace-distance is: 0.00011420415830798447 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.07; acc: 0.64
Batch: 20; loss: 0.81; acc: 0.77
Batch: 40; loss: 0.77; acc: 0.78
Batch: 60; loss: 0.88; acc: 0.7
Batch: 80; loss: 0.91; acc: 0.69
Batch: 100; loss: 0.94; acc: 0.75
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.97; acc: 0.67
Batch: 160; loss: 0.66; acc: 0.8
Batch: 180; loss: 0.73; acc: 0.73
Batch: 200; loss: 0.84; acc: 0.73
Batch: 220; loss: 0.84; acc: 0.72
Batch: 240; loss: 1.14; acc: 0.66
Batch: 260; loss: 1.06; acc: 0.69
Batch: 280; loss: 0.6; acc: 0.78
Batch: 300; loss: 0.81; acc: 0.73
Batch: 320; loss: 0.86; acc: 0.78
Batch: 340; loss: 0.97; acc: 0.73
Batch: 360; loss: 0.81; acc: 0.67
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.78; acc: 0.7
Batch: 420; loss: 0.89; acc: 0.78
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.8; acc: 0.75
Batch: 480; loss: 0.97; acc: 0.81
Batch: 500; loss: 0.86; acc: 0.7
Batch: 520; loss: 0.76; acc: 0.7
Batch: 540; loss: 0.97; acc: 0.69
Batch: 560; loss: 0.72; acc: 0.78
Batch: 580; loss: 0.74; acc: 0.75
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 1.02; acc: 0.66
Batch: 640; loss: 0.73; acc: 0.83
Batch: 660; loss: 0.89; acc: 0.72
Batch: 680; loss: 0.64; acc: 0.75
Batch: 700; loss: 0.85; acc: 0.7
Batch: 720; loss: 0.85; acc: 0.72
Batch: 740; loss: 0.62; acc: 0.75
Batch: 760; loss: 0.66; acc: 0.81
Batch: 780; loss: 1.13; acc: 0.64
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.95; acc: 0.67
Batch: 20; loss: 0.99; acc: 0.64
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.7724376389175464; val_accuracy: 0.7505971337579618 

The current subspace-distance is: 0.00011484157585073262 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_75_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 20859
elements in E: 4442600
fraction nonzero: 0.004695223517759871
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.32; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.31; acc: 0.05
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.32; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.31; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.03
Batch: 220; loss: 2.29; acc: 0.06
Batch: 240; loss: 2.29; acc: 0.09
Batch: 260; loss: 2.28; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.26; acc: 0.16
Batch: 320; loss: 2.29; acc: 0.05
Batch: 340; loss: 2.27; acc: 0.16
Batch: 360; loss: 2.27; acc: 0.17
Batch: 380; loss: 2.27; acc: 0.19
Batch: 400; loss: 2.27; acc: 0.11
Batch: 420; loss: 2.27; acc: 0.14
Batch: 440; loss: 2.27; acc: 0.17
Batch: 460; loss: 2.26; acc: 0.22
Batch: 480; loss: 2.27; acc: 0.17
Batch: 500; loss: 2.27; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.14
Batch: 540; loss: 2.24; acc: 0.25
Batch: 560; loss: 2.25; acc: 0.27
Batch: 580; loss: 2.26; acc: 0.17
Batch: 600; loss: 2.24; acc: 0.25
Batch: 620; loss: 2.22; acc: 0.28
Batch: 640; loss: 2.26; acc: 0.14
Batch: 660; loss: 2.2; acc: 0.31
Batch: 680; loss: 2.23; acc: 0.22
Batch: 700; loss: 2.2; acc: 0.22
Batch: 720; loss: 2.14; acc: 0.31
Batch: 740; loss: 2.17; acc: 0.23
Batch: 760; loss: 2.13; acc: 0.34
Batch: 780; loss: 2.11; acc: 0.31
Train Epoch over. train_loss: 2.26; train_accuracy: 0.17 

Batch: 0; loss: 2.12; acc: 0.34
Batch: 20; loss: 2.02; acc: 0.44
Batch: 40; loss: 2.02; acc: 0.42
Batch: 60; loss: 2.06; acc: 0.34
Batch: 80; loss: 2.06; acc: 0.34
Batch: 100; loss: 2.08; acc: 0.33
Batch: 120; loss: 2.09; acc: 0.36
Batch: 140; loss: 2.06; acc: 0.33
Val Epoch over. val_loss: 2.0916040945964256; val_accuracy: 0.3115047770700637 

The current subspace-distance is: 5.168418738321634e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.16; acc: 0.19
Batch: 20; loss: 2.05; acc: 0.38
Batch: 40; loss: 2.08; acc: 0.28
Batch: 60; loss: 2.01; acc: 0.31
Batch: 80; loss: 1.83; acc: 0.41
Batch: 100; loss: 1.76; acc: 0.38
Batch: 120; loss: 1.7; acc: 0.45
Batch: 140; loss: 1.66; acc: 0.38
Batch: 160; loss: 1.39; acc: 0.52
Batch: 180; loss: 1.49; acc: 0.45
Batch: 200; loss: 1.17; acc: 0.61
Batch: 220; loss: 1.27; acc: 0.52
Batch: 240; loss: 1.51; acc: 0.41
Batch: 260; loss: 1.23; acc: 0.62
Batch: 280; loss: 1.23; acc: 0.58
Batch: 300; loss: 1.02; acc: 0.61
Batch: 320; loss: 1.0; acc: 0.62
Batch: 340; loss: 1.15; acc: 0.66
Batch: 360; loss: 1.22; acc: 0.61
Batch: 380; loss: 0.84; acc: 0.67
Batch: 400; loss: 1.07; acc: 0.56
Batch: 420; loss: 0.82; acc: 0.73
Batch: 440; loss: 1.13; acc: 0.67
Batch: 460; loss: 0.9; acc: 0.72
Batch: 480; loss: 1.14; acc: 0.62
Batch: 500; loss: 1.29; acc: 0.58
Batch: 520; loss: 0.82; acc: 0.7
Batch: 540; loss: 1.18; acc: 0.64
Batch: 560; loss: 1.14; acc: 0.7
Batch: 580; loss: 0.97; acc: 0.72
Batch: 600; loss: 0.99; acc: 0.69
Batch: 620; loss: 0.81; acc: 0.77
Batch: 640; loss: 0.94; acc: 0.72
Batch: 660; loss: 1.1; acc: 0.64
Batch: 680; loss: 1.08; acc: 0.66
Batch: 700; loss: 1.1; acc: 0.67
Batch: 720; loss: 1.08; acc: 0.62
Batch: 740; loss: 0.99; acc: 0.61
Batch: 760; loss: 1.16; acc: 0.66
Batch: 780; loss: 1.01; acc: 0.66
Train Epoch over. train_loss: 1.22; train_accuracy: 0.6 

Batch: 0; loss: 1.19; acc: 0.58
Batch: 20; loss: 1.07; acc: 0.58
Batch: 40; loss: 0.86; acc: 0.7
Batch: 60; loss: 1.24; acc: 0.59
Batch: 80; loss: 1.15; acc: 0.62
Batch: 100; loss: 1.31; acc: 0.58
Batch: 120; loss: 1.31; acc: 0.55
Batch: 140; loss: 0.91; acc: 0.64
Val Epoch over. val_loss: 1.162707919148123; val_accuracy: 0.6101711783439491 

The current subspace-distance is: 1.690877616056241e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.12; acc: 0.56
Batch: 20; loss: 0.96; acc: 0.67
Batch: 40; loss: 0.86; acc: 0.77
Batch: 60; loss: 0.99; acc: 0.69
Batch: 80; loss: 0.85; acc: 0.73
Batch: 100; loss: 0.96; acc: 0.64
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 1.04; acc: 0.64
Batch: 160; loss: 1.01; acc: 0.62
Batch: 180; loss: 1.22; acc: 0.62
Batch: 200; loss: 0.91; acc: 0.75
Batch: 220; loss: 0.9; acc: 0.77
Batch: 240; loss: 0.99; acc: 0.69
Batch: 260; loss: 1.03; acc: 0.67
Batch: 280; loss: 0.72; acc: 0.75
Batch: 300; loss: 0.73; acc: 0.8
Batch: 320; loss: 0.89; acc: 0.66
Batch: 340; loss: 1.11; acc: 0.67
Batch: 360; loss: 1.0; acc: 0.67
Batch: 380; loss: 0.99; acc: 0.69
Batch: 400; loss: 0.78; acc: 0.7
Batch: 420; loss: 1.06; acc: 0.67
Batch: 440; loss: 0.75; acc: 0.73
Batch: 460; loss: 1.08; acc: 0.64
Batch: 480; loss: 1.03; acc: 0.66
Batch: 500; loss: 1.02; acc: 0.62
Batch: 520; loss: 0.76; acc: 0.7
Batch: 540; loss: 0.64; acc: 0.8
Batch: 560; loss: 0.79; acc: 0.67
Batch: 580; loss: 0.77; acc: 0.77
Batch: 600; loss: 1.05; acc: 0.62
Batch: 620; loss: 1.01; acc: 0.67
Batch: 640; loss: 0.9; acc: 0.75
Batch: 660; loss: 1.08; acc: 0.62
Batch: 680; loss: 0.86; acc: 0.67
Batch: 700; loss: 0.69; acc: 0.8
Batch: 720; loss: 0.79; acc: 0.72
Batch: 740; loss: 0.83; acc: 0.73
Batch: 760; loss: 0.67; acc: 0.78
Batch: 780; loss: 1.01; acc: 0.64
Train Epoch over. train_loss: 0.91; train_accuracy: 0.7 

Batch: 0; loss: 1.17; acc: 0.62
Batch: 20; loss: 1.14; acc: 0.53
Batch: 40; loss: 0.67; acc: 0.75
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 1.03; acc: 0.64
Batch: 100; loss: 1.06; acc: 0.64
Batch: 120; loss: 0.99; acc: 0.66
Batch: 140; loss: 0.91; acc: 0.62
Val Epoch over. val_loss: 1.0801124018468675; val_accuracy: 0.6490843949044586 

The current subspace-distance is: 2.5368508431711234e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.77
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.93; acc: 0.7
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.88; acc: 0.69
Batch: 100; loss: 0.81; acc: 0.7
Batch: 120; loss: 0.83; acc: 0.72
Batch: 140; loss: 0.89; acc: 0.75
Batch: 160; loss: 0.87; acc: 0.77
Batch: 180; loss: 0.72; acc: 0.77
Batch: 200; loss: 0.99; acc: 0.7
Batch: 220; loss: 0.79; acc: 0.67
Batch: 240; loss: 0.74; acc: 0.81
Batch: 260; loss: 0.88; acc: 0.75
Batch: 280; loss: 1.02; acc: 0.73
Batch: 300; loss: 0.7; acc: 0.75
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 0.87; acc: 0.7
Batch: 360; loss: 0.77; acc: 0.72
Batch: 380; loss: 0.88; acc: 0.77
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 1.09; acc: 0.72
Batch: 440; loss: 0.82; acc: 0.69
Batch: 460; loss: 0.84; acc: 0.69
Batch: 480; loss: 0.83; acc: 0.72
Batch: 500; loss: 0.71; acc: 0.77
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.85; acc: 0.77
Batch: 560; loss: 1.04; acc: 0.67
Batch: 580; loss: 0.99; acc: 0.61
Batch: 600; loss: 0.71; acc: 0.72
Batch: 620; loss: 0.94; acc: 0.78
Batch: 640; loss: 1.05; acc: 0.69
Batch: 660; loss: 1.07; acc: 0.58
Batch: 680; loss: 0.96; acc: 0.69
Batch: 700; loss: 1.0; acc: 0.77
Batch: 720; loss: 0.93; acc: 0.7
Batch: 740; loss: 0.94; acc: 0.7
Batch: 760; loss: 0.8; acc: 0.75
Batch: 780; loss: 0.57; acc: 0.86
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.8; acc: 0.7
Batch: 20; loss: 0.82; acc: 0.67
Batch: 40; loss: 0.72; acc: 0.73
Batch: 60; loss: 0.95; acc: 0.67
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.88; acc: 0.69
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.75; acc: 0.73
Val Epoch over. val_loss: 0.9047440149981505; val_accuracy: 0.6906847133757962 

The current subspace-distance is: 2.7744290491682477e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.13; acc: 0.56
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.87; acc: 0.78
Batch: 60; loss: 0.61; acc: 0.77
Batch: 80; loss: 0.65; acc: 0.81
Batch: 100; loss: 1.06; acc: 0.64
Batch: 120; loss: 1.03; acc: 0.61
Batch: 140; loss: 0.82; acc: 0.73
Batch: 160; loss: 0.83; acc: 0.8
Batch: 180; loss: 0.6; acc: 0.73
Batch: 200; loss: 0.73; acc: 0.75
Batch: 220; loss: 0.91; acc: 0.73
Batch: 240; loss: 0.83; acc: 0.77
Batch: 260; loss: 0.86; acc: 0.7
Batch: 280; loss: 0.99; acc: 0.66
Batch: 300; loss: 0.99; acc: 0.59
Batch: 320; loss: 0.86; acc: 0.72
Batch: 340; loss: 0.75; acc: 0.73
Batch: 360; loss: 1.03; acc: 0.66
Batch: 380; loss: 0.63; acc: 0.75
Batch: 400; loss: 0.66; acc: 0.78
Batch: 420; loss: 0.71; acc: 0.77
Batch: 440; loss: 0.95; acc: 0.72
Batch: 460; loss: 0.62; acc: 0.8
Batch: 480; loss: 1.0; acc: 0.69
Batch: 500; loss: 0.71; acc: 0.77
Batch: 520; loss: 0.78; acc: 0.7
Batch: 540; loss: 0.73; acc: 0.73
Batch: 560; loss: 0.69; acc: 0.8
Batch: 580; loss: 0.81; acc: 0.83
Batch: 600; loss: 0.95; acc: 0.72
Batch: 620; loss: 0.76; acc: 0.72
Batch: 640; loss: 0.85; acc: 0.72
Batch: 660; loss: 1.29; acc: 0.59
Batch: 680; loss: 0.73; acc: 0.77
Batch: 700; loss: 0.92; acc: 0.73
Batch: 720; loss: 1.15; acc: 0.61
Batch: 740; loss: 0.74; acc: 0.7
Batch: 760; loss: 0.77; acc: 0.75
Batch: 780; loss: 0.84; acc: 0.64
Train Epoch over. train_loss: 0.82; train_accuracy: 0.73 

Batch: 0; loss: 1.15; acc: 0.64
Batch: 20; loss: 1.03; acc: 0.62
Batch: 40; loss: 0.95; acc: 0.72
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 0.88; acc: 0.73
Batch: 100; loss: 0.89; acc: 0.61
Batch: 120; loss: 1.07; acc: 0.67
Batch: 140; loss: 0.62; acc: 0.75
Val Epoch over. val_loss: 0.9879925776818755; val_accuracy: 0.6830214968152867 

The current subspace-distance is: 3.131559060420841e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.66
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.95; acc: 0.75
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.96; acc: 0.61
Batch: 100; loss: 0.86; acc: 0.75
Batch: 120; loss: 0.74; acc: 0.67
Batch: 140; loss: 0.69; acc: 0.77
Batch: 160; loss: 0.78; acc: 0.77
Batch: 180; loss: 0.94; acc: 0.72
Batch: 200; loss: 0.82; acc: 0.77
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.78; acc: 0.73
Batch: 260; loss: 0.69; acc: 0.78
Batch: 280; loss: 0.6; acc: 0.84
Batch: 300; loss: 0.78; acc: 0.75
Batch: 320; loss: 0.71; acc: 0.78
Batch: 340; loss: 0.67; acc: 0.77
Batch: 360; loss: 0.87; acc: 0.69
Batch: 380; loss: 0.71; acc: 0.73
Batch: 400; loss: 0.74; acc: 0.75
Batch: 420; loss: 0.79; acc: 0.72
Batch: 440; loss: 0.93; acc: 0.75
Batch: 460; loss: 0.91; acc: 0.7
Batch: 480; loss: 0.81; acc: 0.73
Batch: 500; loss: 0.69; acc: 0.75
Batch: 520; loss: 0.69; acc: 0.77
Batch: 540; loss: 0.96; acc: 0.66
Batch: 560; loss: 1.07; acc: 0.7
Batch: 580; loss: 1.0; acc: 0.75
Batch: 600; loss: 0.78; acc: 0.73
Batch: 620; loss: 0.7; acc: 0.81
Batch: 640; loss: 0.66; acc: 0.78
Batch: 660; loss: 0.75; acc: 0.72
Batch: 680; loss: 0.93; acc: 0.73
Batch: 700; loss: 0.73; acc: 0.72
Batch: 720; loss: 0.89; acc: 0.7
Batch: 740; loss: 1.25; acc: 0.67
Batch: 760; loss: 0.52; acc: 0.81
Batch: 780; loss: 0.64; acc: 0.75
Train Epoch over. train_loss: 0.8; train_accuracy: 0.74 

Batch: 0; loss: 0.94; acc: 0.67
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.86; acc: 0.7
Batch: 60; loss: 0.9; acc: 0.72
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.73
Batch: 120; loss: 1.06; acc: 0.53
Batch: 140; loss: 0.55; acc: 0.81
Val Epoch over. val_loss: 0.827934525005377; val_accuracy: 0.7302945859872612 

The current subspace-distance is: 3.488478978397325e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.07; acc: 0.7
Batch: 20; loss: 0.82; acc: 0.78
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.93; acc: 0.62
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.95; acc: 0.8
Batch: 140; loss: 0.82; acc: 0.8
Batch: 160; loss: 0.93; acc: 0.77
Batch: 180; loss: 1.12; acc: 0.69
Batch: 200; loss: 0.67; acc: 0.77
Batch: 220; loss: 0.71; acc: 0.73
Batch: 240; loss: 0.77; acc: 0.72
Batch: 260; loss: 0.54; acc: 0.84
Batch: 280; loss: 0.95; acc: 0.73
Batch: 300; loss: 0.75; acc: 0.78
Batch: 320; loss: 0.96; acc: 0.69
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.82; acc: 0.7
Batch: 380; loss: 0.8; acc: 0.73
Batch: 400; loss: 0.85; acc: 0.69
Batch: 420; loss: 0.64; acc: 0.81
Batch: 440; loss: 0.55; acc: 0.8
Batch: 460; loss: 0.68; acc: 0.78
Batch: 480; loss: 0.97; acc: 0.66
Batch: 500; loss: 0.64; acc: 0.81
Batch: 520; loss: 0.55; acc: 0.86
Batch: 540; loss: 0.83; acc: 0.66
Batch: 560; loss: 0.95; acc: 0.67
Batch: 580; loss: 0.66; acc: 0.78
Batch: 600; loss: 0.95; acc: 0.64
Batch: 620; loss: 1.19; acc: 0.62
Batch: 640; loss: 0.79; acc: 0.77
Batch: 660; loss: 0.73; acc: 0.75
Batch: 680; loss: 0.88; acc: 0.67
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.69; acc: 0.83
Batch: 740; loss: 0.78; acc: 0.72
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.8; acc: 0.69
Train Epoch over. train_loss: 0.79; train_accuracy: 0.74 

Batch: 0; loss: 0.87; acc: 0.69
Batch: 20; loss: 0.7; acc: 0.73
Batch: 40; loss: 0.65; acc: 0.77
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.53; acc: 0.8
Batch: 120; loss: 0.81; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.83
Val Epoch over. val_loss: 0.7266532962868928; val_accuracy: 0.7546775477707006 

The current subspace-distance is: 3.67494321835693e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.02; acc: 0.66
Batch: 20; loss: 1.08; acc: 0.61
Batch: 40; loss: 0.69; acc: 0.73
Batch: 60; loss: 0.97; acc: 0.66
Batch: 80; loss: 0.88; acc: 0.7
Batch: 100; loss: 0.72; acc: 0.78
Batch: 120; loss: 0.64; acc: 0.75
Batch: 140; loss: 0.77; acc: 0.81
Batch: 160; loss: 0.72; acc: 0.78
Batch: 180; loss: 1.12; acc: 0.67
Batch: 200; loss: 0.59; acc: 0.84
Batch: 220; loss: 0.7; acc: 0.75
Batch: 240; loss: 0.75; acc: 0.73
Batch: 260; loss: 0.78; acc: 0.78
Batch: 280; loss: 0.86; acc: 0.66
Batch: 300; loss: 0.67; acc: 0.78
Batch: 320; loss: 0.8; acc: 0.64
Batch: 340; loss: 0.86; acc: 0.77
Batch: 360; loss: 0.79; acc: 0.8
Batch: 380; loss: 0.75; acc: 0.77
Batch: 400; loss: 0.69; acc: 0.8
Batch: 420; loss: 0.77; acc: 0.72
Batch: 440; loss: 0.75; acc: 0.77
Batch: 460; loss: 0.94; acc: 0.66
Batch: 480; loss: 0.68; acc: 0.81
Batch: 500; loss: 0.82; acc: 0.67
Batch: 520; loss: 0.89; acc: 0.75
Batch: 540; loss: 0.8; acc: 0.75
Batch: 560; loss: 0.68; acc: 0.77
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.77; acc: 0.78
Batch: 620; loss: 0.59; acc: 0.81
Batch: 640; loss: 0.77; acc: 0.77
Batch: 660; loss: 0.83; acc: 0.72
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.93; acc: 0.69
Batch: 720; loss: 0.82; acc: 0.73
Batch: 740; loss: 0.87; acc: 0.7
Batch: 760; loss: 1.02; acc: 0.59
Batch: 780; loss: 0.72; acc: 0.78
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

Batch: 0; loss: 0.91; acc: 0.67
Batch: 20; loss: 0.87; acc: 0.7
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.77
Batch: 120; loss: 1.12; acc: 0.64
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.789414352861939; val_accuracy: 0.7432324840764332 

The current subspace-distance is: 3.985657895100303e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.85; acc: 0.67
Batch: 20; loss: 0.62; acc: 0.83
Batch: 40; loss: 0.87; acc: 0.72
Batch: 60; loss: 0.81; acc: 0.69
Batch: 80; loss: 0.79; acc: 0.75
Batch: 100; loss: 0.83; acc: 0.66
Batch: 120; loss: 0.84; acc: 0.81
Batch: 140; loss: 0.84; acc: 0.78
Batch: 160; loss: 0.51; acc: 0.81
Batch: 180; loss: 0.64; acc: 0.81
Batch: 200; loss: 0.57; acc: 0.81
Batch: 220; loss: 0.69; acc: 0.7
Batch: 240; loss: 0.69; acc: 0.75
Batch: 260; loss: 0.59; acc: 0.8
Batch: 280; loss: 0.67; acc: 0.78
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.84; acc: 0.72
Batch: 340; loss: 0.78; acc: 0.75
Batch: 360; loss: 0.94; acc: 0.7
Batch: 380; loss: 0.8; acc: 0.78
Batch: 400; loss: 0.9; acc: 0.69
Batch: 420; loss: 0.7; acc: 0.81
Batch: 440; loss: 0.83; acc: 0.67
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.67; acc: 0.77
Batch: 500; loss: 0.76; acc: 0.78
Batch: 520; loss: 1.01; acc: 0.73
Batch: 540; loss: 1.06; acc: 0.69
Batch: 560; loss: 0.94; acc: 0.7
Batch: 580; loss: 0.66; acc: 0.77
Batch: 600; loss: 0.65; acc: 0.81
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.58; acc: 0.8
Batch: 660; loss: 0.67; acc: 0.78
Batch: 680; loss: 0.73; acc: 0.77
Batch: 700; loss: 0.67; acc: 0.77
Batch: 720; loss: 0.85; acc: 0.69
Batch: 740; loss: 0.76; acc: 0.73
Batch: 760; loss: 0.69; acc: 0.81
Batch: 780; loss: 0.73; acc: 0.81
Train Epoch over. train_loss: 0.75; train_accuracy: 0.76 

Batch: 0; loss: 1.09; acc: 0.61
Batch: 20; loss: 0.74; acc: 0.73
Batch: 40; loss: 0.96; acc: 0.64
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.6; acc: 0.8
Batch: 100; loss: 0.78; acc: 0.7
Batch: 120; loss: 1.18; acc: 0.58
Batch: 140; loss: 0.62; acc: 0.83
Val Epoch over. val_loss: 0.8890182503089783; val_accuracy: 0.7043192675159236 

The current subspace-distance is: 4.47055499535054e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.03; acc: 0.7
Batch: 20; loss: 0.94; acc: 0.67
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.77; acc: 0.67
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 0.88; acc: 0.72
Batch: 120; loss: 0.93; acc: 0.69
Batch: 140; loss: 0.97; acc: 0.72
Batch: 160; loss: 0.74; acc: 0.72
Batch: 180; loss: 0.91; acc: 0.73
Batch: 200; loss: 0.74; acc: 0.75
Batch: 220; loss: 0.59; acc: 0.75
Batch: 240; loss: 0.98; acc: 0.67
Batch: 260; loss: 0.64; acc: 0.83
Batch: 280; loss: 0.55; acc: 0.83
Batch: 300; loss: 0.48; acc: 0.81
Batch: 320; loss: 0.92; acc: 0.69
Batch: 340; loss: 0.74; acc: 0.77
Batch: 360; loss: 0.85; acc: 0.69
Batch: 380; loss: 0.54; acc: 0.88
Batch: 400; loss: 0.69; acc: 0.77
Batch: 420; loss: 0.71; acc: 0.72
Batch: 440; loss: 0.68; acc: 0.78
Batch: 460; loss: 0.78; acc: 0.7
Batch: 480; loss: 0.96; acc: 0.67
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.67; acc: 0.78
Batch: 540; loss: 0.8; acc: 0.73
Batch: 560; loss: 0.63; acc: 0.84
Batch: 580; loss: 0.92; acc: 0.64
Batch: 600; loss: 0.89; acc: 0.78
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.89; acc: 0.72
Batch: 660; loss: 0.85; acc: 0.77
Batch: 680; loss: 0.83; acc: 0.72
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.83; acc: 0.72
Batch: 740; loss: 0.78; acc: 0.72
Batch: 760; loss: 0.83; acc: 0.73
Batch: 780; loss: 0.78; acc: 0.77
Train Epoch over. train_loss: 0.74; train_accuracy: 0.76 

Batch: 0; loss: 0.88; acc: 0.67
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.64; acc: 0.78
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.48; acc: 0.83
Val Epoch over. val_loss: 0.715016053740386; val_accuracy: 0.7611464968152867 

The current subspace-distance is: 4.8815763875609264e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.13; acc: 0.67
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.7; acc: 0.75
Batch: 100; loss: 0.59; acc: 0.81
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.71; acc: 0.83
Batch: 160; loss: 0.9; acc: 0.72
Batch: 180; loss: 0.68; acc: 0.8
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.7; acc: 0.8
Batch: 240; loss: 0.92; acc: 0.69
Batch: 260; loss: 0.67; acc: 0.78
Batch: 280; loss: 0.76; acc: 0.75
Batch: 300; loss: 0.94; acc: 0.67
Batch: 320; loss: 0.88; acc: 0.69
Batch: 340; loss: 0.93; acc: 0.72
Batch: 360; loss: 0.62; acc: 0.81
Batch: 380; loss: 0.98; acc: 0.77
Batch: 400; loss: 0.84; acc: 0.78
Batch: 420; loss: 1.0; acc: 0.72
Batch: 440; loss: 0.7; acc: 0.75
Batch: 460; loss: 0.88; acc: 0.73
Batch: 480; loss: 0.72; acc: 0.73
Batch: 500; loss: 0.68; acc: 0.75
Batch: 520; loss: 0.63; acc: 0.83
Batch: 540; loss: 0.55; acc: 0.8
Batch: 560; loss: 0.48; acc: 0.78
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.73; acc: 0.73
Batch: 640; loss: 0.82; acc: 0.77
Batch: 660; loss: 0.96; acc: 0.78
Batch: 680; loss: 0.83; acc: 0.72
Batch: 700; loss: 0.94; acc: 0.78
Batch: 720; loss: 0.78; acc: 0.78
Batch: 740; loss: 0.82; acc: 0.64
Batch: 760; loss: 0.78; acc: 0.72
Batch: 780; loss: 0.89; acc: 0.67
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

Batch: 0; loss: 0.9; acc: 0.67
Batch: 20; loss: 0.6; acc: 0.84
Batch: 40; loss: 0.63; acc: 0.77
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.75
Batch: 120; loss: 0.76; acc: 0.72
Batch: 140; loss: 0.39; acc: 0.91
Val Epoch over. val_loss: 0.6697843302587035; val_accuracy: 0.7844347133757962 

The current subspace-distance is: 5.2189243433531374e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.8
Batch: 20; loss: 1.07; acc: 0.75
Batch: 40; loss: 0.91; acc: 0.67
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.73; acc: 0.77
Batch: 120; loss: 0.86; acc: 0.67
Batch: 140; loss: 0.67; acc: 0.77
Batch: 160; loss: 0.71; acc: 0.73
Batch: 180; loss: 0.62; acc: 0.78
Batch: 200; loss: 0.76; acc: 0.83
Batch: 220; loss: 0.71; acc: 0.8
Batch: 240; loss: 0.79; acc: 0.69
Batch: 260; loss: 0.87; acc: 0.69
Batch: 280; loss: 0.73; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.77
Batch: 320; loss: 0.95; acc: 0.73
Batch: 340; loss: 0.75; acc: 0.7
Batch: 360; loss: 0.85; acc: 0.77
Batch: 380; loss: 0.7; acc: 0.75
Batch: 400; loss: 0.65; acc: 0.78
Batch: 420; loss: 0.78; acc: 0.78
Batch: 440; loss: 0.66; acc: 0.75
Batch: 460; loss: 0.87; acc: 0.69
Batch: 480; loss: 0.79; acc: 0.78
Batch: 500; loss: 1.02; acc: 0.77
Batch: 520; loss: 0.79; acc: 0.77
Batch: 540; loss: 0.89; acc: 0.77
Batch: 560; loss: 1.03; acc: 0.69
Batch: 580; loss: 0.81; acc: 0.77
Batch: 600; loss: 0.68; acc: 0.83
Batch: 620; loss: 0.73; acc: 0.78
Batch: 640; loss: 0.82; acc: 0.77
Batch: 660; loss: 0.62; acc: 0.84
Batch: 680; loss: 0.85; acc: 0.77
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.84; acc: 0.73
Batch: 760; loss: 0.76; acc: 0.8
Batch: 780; loss: 0.7; acc: 0.81
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

Batch: 0; loss: 0.87; acc: 0.67
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.6; acc: 0.8
Batch: 60; loss: 0.49; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.75
Batch: 120; loss: 0.83; acc: 0.69
Batch: 140; loss: 0.43; acc: 0.91
Val Epoch over. val_loss: 0.6782159946716515; val_accuracy: 0.7808519108280255 

The current subspace-distance is: 5.381636947277002e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.91; acc: 0.75
Batch: 20; loss: 0.71; acc: 0.73
Batch: 40; loss: 0.79; acc: 0.8
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.77; acc: 0.78
Batch: 120; loss: 0.55; acc: 0.8
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.7; acc: 0.78
Batch: 180; loss: 0.74; acc: 0.77
Batch: 200; loss: 0.7; acc: 0.75
Batch: 220; loss: 0.94; acc: 0.75
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.73; acc: 0.73
Batch: 280; loss: 0.77; acc: 0.75
Batch: 300; loss: 0.59; acc: 0.8
Batch: 320; loss: 0.72; acc: 0.78
Batch: 340; loss: 0.78; acc: 0.73
Batch: 360; loss: 0.72; acc: 0.77
Batch: 380; loss: 0.85; acc: 0.77
Batch: 400; loss: 0.74; acc: 0.78
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.74; acc: 0.75
Batch: 460; loss: 0.8; acc: 0.72
Batch: 480; loss: 0.96; acc: 0.67
Batch: 500; loss: 0.72; acc: 0.75
Batch: 520; loss: 0.69; acc: 0.84
Batch: 540; loss: 0.68; acc: 0.77
Batch: 560; loss: 0.82; acc: 0.78
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.73; acc: 0.81
Batch: 620; loss: 0.56; acc: 0.83
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.67; acc: 0.78
Batch: 680; loss: 0.94; acc: 0.72
Batch: 700; loss: 0.67; acc: 0.81
Batch: 720; loss: 0.96; acc: 0.77
Batch: 740; loss: 0.85; acc: 0.75
Batch: 760; loss: 0.86; acc: 0.7
Batch: 780; loss: 0.84; acc: 0.7
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

Batch: 0; loss: 0.82; acc: 0.7
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.59; acc: 0.78
Batch: 60; loss: 0.53; acc: 0.78
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.36; acc: 0.94
Val Epoch over. val_loss: 0.6674922049804858; val_accuracy: 0.7834394904458599 

The current subspace-distance is: 5.6413635320495814e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.75; acc: 0.81
Batch: 40; loss: 0.52; acc: 0.8
Batch: 60; loss: 0.77; acc: 0.67
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.7; acc: 0.8
Batch: 120; loss: 0.58; acc: 0.78
Batch: 140; loss: 0.77; acc: 0.72
Batch: 160; loss: 0.8; acc: 0.73
Batch: 180; loss: 0.61; acc: 0.83
Batch: 200; loss: 0.74; acc: 0.75
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.73; acc: 0.73
Batch: 260; loss: 0.59; acc: 0.83
Batch: 280; loss: 0.65; acc: 0.81
Batch: 300; loss: 0.68; acc: 0.8
Batch: 320; loss: 0.68; acc: 0.77
Batch: 340; loss: 0.94; acc: 0.66
Batch: 360; loss: 0.64; acc: 0.78
Batch: 380; loss: 0.56; acc: 0.88
Batch: 400; loss: 0.58; acc: 0.73
Batch: 420; loss: 0.77; acc: 0.8
Batch: 440; loss: 0.67; acc: 0.81
Batch: 460; loss: 0.79; acc: 0.78
Batch: 480; loss: 0.99; acc: 0.77
Batch: 500; loss: 0.58; acc: 0.86
Batch: 520; loss: 0.8; acc: 0.75
Batch: 540; loss: 0.59; acc: 0.84
Batch: 560; loss: 0.56; acc: 0.81
Batch: 580; loss: 0.58; acc: 0.77
Batch: 600; loss: 0.92; acc: 0.72
Batch: 620; loss: 0.89; acc: 0.77
Batch: 640; loss: 0.63; acc: 0.83
Batch: 660; loss: 0.8; acc: 0.77
Batch: 680; loss: 1.11; acc: 0.64
Batch: 700; loss: 0.8; acc: 0.67
Batch: 720; loss: 0.59; acc: 0.77
Batch: 740; loss: 0.7; acc: 0.75
Batch: 760; loss: 0.63; acc: 0.77
Batch: 780; loss: 0.89; acc: 0.8
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

Batch: 0; loss: 0.88; acc: 0.69
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.57; acc: 0.77
Batch: 80; loss: 0.45; acc: 0.92
Batch: 100; loss: 0.61; acc: 0.78
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.39; acc: 0.84
Val Epoch over. val_loss: 0.672008440467962; val_accuracy: 0.7878184713375797 

The current subspace-distance is: 5.9514393797144294e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.61; acc: 0.77
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.74; acc: 0.78
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.7; acc: 0.83
Batch: 160; loss: 1.02; acc: 0.69
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.68; acc: 0.75
Batch: 220; loss: 0.9; acc: 0.69
Batch: 240; loss: 0.75; acc: 0.8
Batch: 260; loss: 0.79; acc: 0.75
Batch: 280; loss: 0.72; acc: 0.77
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.65; acc: 0.81
Batch: 340; loss: 0.59; acc: 0.81
Batch: 360; loss: 0.73; acc: 0.73
Batch: 380; loss: 0.68; acc: 0.73
Batch: 400; loss: 0.6; acc: 0.84
Batch: 420; loss: 0.8; acc: 0.72
Batch: 440; loss: 0.56; acc: 0.84
Batch: 460; loss: 0.73; acc: 0.77
Batch: 480; loss: 0.72; acc: 0.75
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.7; acc: 0.77
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.67; acc: 0.81
Batch: 640; loss: 0.79; acc: 0.77
Batch: 660; loss: 0.72; acc: 0.75
Batch: 680; loss: 0.93; acc: 0.69
Batch: 700; loss: 0.91; acc: 0.72
Batch: 720; loss: 0.74; acc: 0.8
Batch: 740; loss: 0.54; acc: 0.88
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.89; acc: 0.72
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.88; acc: 0.69
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.52; acc: 0.77
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.57; acc: 0.75
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.37; acc: 0.89
Val Epoch over. val_loss: 0.673951541921895; val_accuracy: 0.7880175159235668 

The current subspace-distance is: 6.334877252811566e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.88
Batch: 40; loss: 0.68; acc: 0.75
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.66; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.75
Batch: 120; loss: 0.8; acc: 0.73
Batch: 140; loss: 0.92; acc: 0.75
Batch: 160; loss: 0.66; acc: 0.75
Batch: 180; loss: 0.7; acc: 0.75
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.99; acc: 0.7
Batch: 240; loss: 0.73; acc: 0.78
Batch: 260; loss: 0.68; acc: 0.81
Batch: 280; loss: 0.83; acc: 0.75
Batch: 300; loss: 0.88; acc: 0.69
Batch: 320; loss: 0.75; acc: 0.77
Batch: 340; loss: 1.09; acc: 0.66
Batch: 360; loss: 0.74; acc: 0.77
Batch: 380; loss: 0.71; acc: 0.78
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.92; acc: 0.7
Batch: 460; loss: 1.12; acc: 0.67
Batch: 480; loss: 0.57; acc: 0.8
Batch: 500; loss: 0.92; acc: 0.77
Batch: 520; loss: 0.88; acc: 0.72
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.65; acc: 0.81
Batch: 580; loss: 0.64; acc: 0.77
Batch: 600; loss: 1.02; acc: 0.73
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.8; acc: 0.73
Batch: 660; loss: 0.86; acc: 0.77
Batch: 680; loss: 0.62; acc: 0.8
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.6; acc: 0.81
Batch: 740; loss: 1.0; acc: 0.73
Batch: 760; loss: 0.69; acc: 0.78
Batch: 780; loss: 0.62; acc: 0.83
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.84; acc: 0.7
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.5; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.77
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.38; acc: 0.91
Val Epoch over. val_loss: 0.6476333168851343; val_accuracy: 0.7953821656050956 

The current subspace-distance is: 6.550472608068958e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.65; acc: 0.78
Batch: 60; loss: 0.77; acc: 0.75
Batch: 80; loss: 0.68; acc: 0.78
Batch: 100; loss: 0.82; acc: 0.72
Batch: 120; loss: 0.65; acc: 0.75
Batch: 140; loss: 0.84; acc: 0.7
Batch: 160; loss: 1.02; acc: 0.73
Batch: 180; loss: 0.86; acc: 0.75
Batch: 200; loss: 0.61; acc: 0.83
Batch: 220; loss: 0.62; acc: 0.75
Batch: 240; loss: 0.85; acc: 0.75
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.48; acc: 0.8
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.74; acc: 0.72
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.8; acc: 0.77
Batch: 400; loss: 0.71; acc: 0.75
Batch: 420; loss: 0.64; acc: 0.77
Batch: 440; loss: 0.48; acc: 0.84
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.59; acc: 0.83
Batch: 500; loss: 0.87; acc: 0.78
Batch: 520; loss: 0.54; acc: 0.83
Batch: 540; loss: 0.53; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.66; acc: 0.81
Batch: 600; loss: 0.58; acc: 0.77
Batch: 620; loss: 0.54; acc: 0.8
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.59; acc: 0.8
Batch: 680; loss: 0.96; acc: 0.72
Batch: 700; loss: 0.65; acc: 0.78
Batch: 720; loss: 0.53; acc: 0.81
Batch: 740; loss: 0.81; acc: 0.78
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.77; acc: 0.8
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.83; acc: 0.73
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.54; acc: 0.77
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.77
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.38; acc: 0.91
Val Epoch over. val_loss: 0.653966730187653; val_accuracy: 0.7911027070063694 

The current subspace-distance is: 6.944020424271002e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.16; acc: 0.64
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.9; acc: 0.75
Batch: 60; loss: 1.01; acc: 0.72
Batch: 80; loss: 0.63; acc: 0.77
Batch: 100; loss: 0.42; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.75
Batch: 140; loss: 0.84; acc: 0.69
Batch: 160; loss: 0.73; acc: 0.72
Batch: 180; loss: 0.66; acc: 0.8
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.63; acc: 0.8
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.76; acc: 0.78
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.69; acc: 0.78
Batch: 340; loss: 0.6; acc: 0.81
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.74; acc: 0.8
Batch: 400; loss: 0.77; acc: 0.78
Batch: 420; loss: 1.11; acc: 0.61
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.91; acc: 0.69
Batch: 480; loss: 0.63; acc: 0.77
Batch: 500; loss: 0.86; acc: 0.77
Batch: 520; loss: 0.59; acc: 0.78
Batch: 540; loss: 0.69; acc: 0.72
Batch: 560; loss: 0.9; acc: 0.75
Batch: 580; loss: 0.79; acc: 0.72
Batch: 600; loss: 0.69; acc: 0.84
Batch: 620; loss: 0.57; acc: 0.88
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.61; acc: 0.83
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.63; acc: 0.77
Batch: 740; loss: 1.19; acc: 0.64
Batch: 760; loss: 0.66; acc: 0.78
Batch: 780; loss: 0.56; acc: 0.83
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.69; acc: 0.75
Batch: 40; loss: 0.53; acc: 0.77
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.81
Batch: 100; loss: 0.59; acc: 0.75
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.38; acc: 0.92
Val Epoch over. val_loss: 0.6665502282654404; val_accuracy: 0.7899084394904459 

The current subspace-distance is: 7.011365960352123e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.68; acc: 0.75
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.77; acc: 0.73
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.69; acc: 0.73
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.7; acc: 0.72
Batch: 140; loss: 0.78; acc: 0.78
Batch: 160; loss: 0.58; acc: 0.81
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.85; acc: 0.7
Batch: 220; loss: 0.85; acc: 0.69
Batch: 240; loss: 0.77; acc: 0.7
Batch: 260; loss: 0.55; acc: 0.84
Batch: 280; loss: 0.54; acc: 0.8
Batch: 300; loss: 0.78; acc: 0.81
Batch: 320; loss: 0.78; acc: 0.78
Batch: 340; loss: 0.61; acc: 0.8
Batch: 360; loss: 0.65; acc: 0.81
Batch: 380; loss: 0.86; acc: 0.69
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.74; acc: 0.77
Batch: 440; loss: 0.68; acc: 0.7
Batch: 460; loss: 0.7; acc: 0.78
Batch: 480; loss: 0.98; acc: 0.72
Batch: 500; loss: 0.7; acc: 0.75
Batch: 520; loss: 0.81; acc: 0.69
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.68; acc: 0.78
Batch: 580; loss: 0.82; acc: 0.72
Batch: 600; loss: 0.46; acc: 0.84
Batch: 620; loss: 0.58; acc: 0.81
Batch: 640; loss: 0.71; acc: 0.83
Batch: 660; loss: 0.87; acc: 0.72
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.78; acc: 0.78
Batch: 720; loss: 0.58; acc: 0.78
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.78; acc: 0.73
Batch: 780; loss: 0.72; acc: 0.73
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.6; acc: 0.77
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.64; acc: 0.7
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.39; acc: 0.92
Val Epoch over. val_loss: 0.6874805259856449; val_accuracy: 0.7813495222929936 

The current subspace-distance is: 7.472273136954755e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.7; acc: 0.72
Batch: 60; loss: 0.66; acc: 0.86
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.84; acc: 0.72
Batch: 160; loss: 0.73; acc: 0.78
Batch: 180; loss: 0.69; acc: 0.75
Batch: 200; loss: 0.59; acc: 0.8
Batch: 220; loss: 1.06; acc: 0.67
Batch: 240; loss: 1.01; acc: 0.75
Batch: 260; loss: 0.68; acc: 0.78
Batch: 280; loss: 0.58; acc: 0.83
Batch: 300; loss: 0.72; acc: 0.77
Batch: 320; loss: 0.8; acc: 0.72
Batch: 340; loss: 0.67; acc: 0.78
Batch: 360; loss: 0.77; acc: 0.73
Batch: 380; loss: 0.66; acc: 0.77
Batch: 400; loss: 0.68; acc: 0.75
Batch: 420; loss: 0.57; acc: 0.81
Batch: 440; loss: 0.75; acc: 0.77
Batch: 460; loss: 0.99; acc: 0.69
Batch: 480; loss: 0.72; acc: 0.75
Batch: 500; loss: 0.78; acc: 0.8
Batch: 520; loss: 0.74; acc: 0.75
Batch: 540; loss: 0.82; acc: 0.72
Batch: 560; loss: 0.66; acc: 0.8
Batch: 580; loss: 0.51; acc: 0.88
Batch: 600; loss: 0.78; acc: 0.78
Batch: 620; loss: 0.76; acc: 0.72
Batch: 640; loss: 0.8; acc: 0.78
Batch: 660; loss: 0.62; acc: 0.78
Batch: 680; loss: 0.66; acc: 0.77
Batch: 700; loss: 0.65; acc: 0.8
Batch: 720; loss: 0.87; acc: 0.8
Batch: 740; loss: 0.99; acc: 0.72
Batch: 760; loss: 0.73; acc: 0.78
Batch: 780; loss: 0.74; acc: 0.77
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.81; acc: 0.73
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.55; acc: 0.78
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.67; acc: 0.73
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.37; acc: 0.92
Val Epoch over. val_loss: 0.6544594690678226; val_accuracy: 0.7939888535031847 

The current subspace-distance is: 7.442010974045843e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 1.06; acc: 0.73
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 0.77; acc: 0.69
Batch: 160; loss: 0.66; acc: 0.8
Batch: 180; loss: 0.74; acc: 0.78
Batch: 200; loss: 0.9; acc: 0.69
Batch: 220; loss: 0.88; acc: 0.75
Batch: 240; loss: 0.74; acc: 0.81
Batch: 260; loss: 0.72; acc: 0.75
Batch: 280; loss: 0.74; acc: 0.84
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.52; acc: 0.88
Batch: 360; loss: 0.55; acc: 0.8
Batch: 380; loss: 0.48; acc: 0.88
Batch: 400; loss: 0.83; acc: 0.75
Batch: 420; loss: 0.82; acc: 0.78
Batch: 440; loss: 0.71; acc: 0.78
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.78; acc: 0.8
Batch: 500; loss: 0.64; acc: 0.73
Batch: 520; loss: 0.77; acc: 0.8
Batch: 540; loss: 0.69; acc: 0.75
Batch: 560; loss: 0.81; acc: 0.72
Batch: 580; loss: 0.74; acc: 0.77
Batch: 600; loss: 0.71; acc: 0.78
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.7; acc: 0.73
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.77
Batch: 720; loss: 0.53; acc: 0.81
Batch: 740; loss: 0.81; acc: 0.73
Batch: 760; loss: 0.74; acc: 0.77
Batch: 780; loss: 0.86; acc: 0.66
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.78; acc: 0.73
Batch: 20; loss: 0.57; acc: 0.81
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.56; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.63; acc: 0.77
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.95
Val Epoch over. val_loss: 0.6429540306139904; val_accuracy: 0.7989649681528662 

The current subspace-distance is: 7.649449253221974e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.88; acc: 0.78
Batch: 20; loss: 0.74; acc: 0.72
Batch: 40; loss: 0.79; acc: 0.73
Batch: 60; loss: 0.64; acc: 0.75
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.62; acc: 0.83
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 1.19; acc: 0.67
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.64; acc: 0.81
Batch: 220; loss: 0.66; acc: 0.78
Batch: 240; loss: 0.71; acc: 0.75
Batch: 260; loss: 0.62; acc: 0.73
Batch: 280; loss: 0.81; acc: 0.78
Batch: 300; loss: 0.76; acc: 0.69
Batch: 320; loss: 1.02; acc: 0.72
Batch: 340; loss: 0.66; acc: 0.8
Batch: 360; loss: 0.63; acc: 0.83
Batch: 380; loss: 0.57; acc: 0.8
Batch: 400; loss: 0.53; acc: 0.81
Batch: 420; loss: 0.64; acc: 0.81
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.98; acc: 0.73
Batch: 480; loss: 0.78; acc: 0.8
Batch: 500; loss: 0.56; acc: 0.81
Batch: 520; loss: 0.7; acc: 0.8
Batch: 540; loss: 0.85; acc: 0.7
Batch: 560; loss: 0.73; acc: 0.78
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 0.56; acc: 0.86
Batch: 620; loss: 0.71; acc: 0.81
Batch: 640; loss: 0.71; acc: 0.81
Batch: 660; loss: 0.85; acc: 0.72
Batch: 680; loss: 0.66; acc: 0.83
Batch: 700; loss: 0.78; acc: 0.7
Batch: 720; loss: 0.72; acc: 0.81
Batch: 740; loss: 0.75; acc: 0.77
Batch: 760; loss: 0.54; acc: 0.78
Batch: 780; loss: 0.83; acc: 0.77
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.57; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.64; acc: 0.75
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.6433441359905681; val_accuracy: 0.7977707006369427 

The current subspace-distance is: 8.023993723327294e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.83; acc: 0.73
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.79; acc: 0.67
Batch: 100; loss: 0.8; acc: 0.73
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.75; acc: 0.77
Batch: 160; loss: 0.69; acc: 0.77
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.61; acc: 0.73
Batch: 220; loss: 0.71; acc: 0.78
Batch: 240; loss: 0.5; acc: 0.88
Batch: 260; loss: 0.58; acc: 0.75
Batch: 280; loss: 0.54; acc: 0.81
Batch: 300; loss: 0.74; acc: 0.73
Batch: 320; loss: 0.83; acc: 0.75
Batch: 340; loss: 0.74; acc: 0.77
Batch: 360; loss: 1.06; acc: 0.67
Batch: 380; loss: 0.64; acc: 0.8
Batch: 400; loss: 0.49; acc: 0.81
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.81; acc: 0.73
Batch: 460; loss: 0.7; acc: 0.75
Batch: 480; loss: 0.55; acc: 0.83
Batch: 500; loss: 0.79; acc: 0.78
Batch: 520; loss: 0.71; acc: 0.78
Batch: 540; loss: 0.78; acc: 0.84
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.64; acc: 0.81
Batch: 620; loss: 0.52; acc: 0.81
Batch: 640; loss: 0.81; acc: 0.8
Batch: 660; loss: 0.61; acc: 0.86
Batch: 680; loss: 0.61; acc: 0.8
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 1.0; acc: 0.66
Batch: 740; loss: 0.65; acc: 0.86
Batch: 760; loss: 0.66; acc: 0.75
Batch: 780; loss: 0.82; acc: 0.8
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 0.57; acc: 0.81
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.77
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.6415028508491577; val_accuracy: 0.8001592356687898 

The current subspace-distance is: 8.280295878648758e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.6; acc: 0.75
Batch: 40; loss: 0.61; acc: 0.86
Batch: 60; loss: 0.63; acc: 0.8
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.7
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.62; acc: 0.78
Batch: 180; loss: 0.94; acc: 0.73
Batch: 200; loss: 0.91; acc: 0.75
Batch: 220; loss: 0.65; acc: 0.78
Batch: 240; loss: 0.84; acc: 0.77
Batch: 260; loss: 0.61; acc: 0.83
Batch: 280; loss: 0.82; acc: 0.7
Batch: 300; loss: 0.63; acc: 0.81
Batch: 320; loss: 0.64; acc: 0.83
Batch: 340; loss: 0.82; acc: 0.78
Batch: 360; loss: 0.71; acc: 0.78
Batch: 380; loss: 0.54; acc: 0.8
Batch: 400; loss: 0.61; acc: 0.84
Batch: 420; loss: 0.66; acc: 0.8
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.73; acc: 0.77
Batch: 480; loss: 0.72; acc: 0.77
Batch: 500; loss: 0.52; acc: 0.83
Batch: 520; loss: 0.64; acc: 0.78
Batch: 540; loss: 0.87; acc: 0.75
Batch: 560; loss: 0.66; acc: 0.73
Batch: 580; loss: 0.72; acc: 0.72
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.69; acc: 0.78
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.73; acc: 0.77
Batch: 700; loss: 0.62; acc: 0.78
Batch: 720; loss: 0.88; acc: 0.75
Batch: 740; loss: 0.66; acc: 0.8
Batch: 760; loss: 0.72; acc: 0.77
Batch: 780; loss: 1.04; acc: 0.67
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.32; acc: 0.91
Val Epoch over. val_loss: 0.6422580387561944; val_accuracy: 0.7976711783439491 

The current subspace-distance is: 8.504917059326544e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.94; acc: 0.73
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.62; acc: 0.73
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.82; acc: 0.73
Batch: 160; loss: 0.68; acc: 0.78
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.69; acc: 0.73
Batch: 220; loss: 0.85; acc: 0.8
Batch: 240; loss: 0.98; acc: 0.64
Batch: 260; loss: 0.75; acc: 0.78
Batch: 280; loss: 0.9; acc: 0.73
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.68; acc: 0.73
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.64; acc: 0.88
Batch: 380; loss: 1.27; acc: 0.69
Batch: 400; loss: 0.53; acc: 0.88
Batch: 420; loss: 0.68; acc: 0.77
Batch: 440; loss: 0.58; acc: 0.83
Batch: 460; loss: 0.9; acc: 0.7
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.79; acc: 0.8
Batch: 520; loss: 0.73; acc: 0.75
Batch: 540; loss: 0.72; acc: 0.77
Batch: 560; loss: 0.94; acc: 0.72
Batch: 580; loss: 0.59; acc: 0.81
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.66; acc: 0.73
Batch: 660; loss: 0.81; acc: 0.72
Batch: 680; loss: 0.87; acc: 0.73
Batch: 700; loss: 0.72; acc: 0.73
Batch: 720; loss: 0.74; acc: 0.75
Batch: 740; loss: 0.88; acc: 0.75
Batch: 760; loss: 0.67; acc: 0.8
Batch: 780; loss: 0.74; acc: 0.73
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.78; acc: 0.77
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.66; acc: 0.77
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6448283288509223; val_accuracy: 0.7988654458598726 

The current subspace-distance is: 8.575705578550696e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.85; acc: 0.77
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.83; acc: 0.69
Batch: 60; loss: 0.64; acc: 0.77
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.71; acc: 0.73
Batch: 160; loss: 1.0; acc: 0.66
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.77; acc: 0.7
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.71; acc: 0.8
Batch: 260; loss: 0.88; acc: 0.77
Batch: 280; loss: 0.64; acc: 0.81
Batch: 300; loss: 0.8; acc: 0.78
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.99; acc: 0.75
Batch: 380; loss: 0.67; acc: 0.8
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.78; acc: 0.73
Batch: 440; loss: 0.87; acc: 0.77
Batch: 460; loss: 0.71; acc: 0.73
Batch: 480; loss: 0.39; acc: 0.92
Batch: 500; loss: 0.84; acc: 0.75
Batch: 520; loss: 0.53; acc: 0.91
Batch: 540; loss: 0.71; acc: 0.78
Batch: 560; loss: 0.67; acc: 0.8
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.62; acc: 0.81
Batch: 620; loss: 0.78; acc: 0.77
Batch: 640; loss: 0.65; acc: 0.83
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.72; acc: 0.73
Batch: 740; loss: 0.86; acc: 0.72
Batch: 760; loss: 0.52; acc: 0.83
Batch: 780; loss: 0.54; acc: 0.81
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.6395229942100064; val_accuracy: 0.8019506369426752 

The current subspace-distance is: 8.518371760146692e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.94; acc: 0.69
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.65; acc: 0.73
Batch: 140; loss: 0.63; acc: 0.81
Batch: 160; loss: 0.53; acc: 0.89
Batch: 180; loss: 0.85; acc: 0.77
Batch: 200; loss: 0.79; acc: 0.75
Batch: 220; loss: 0.71; acc: 0.73
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.64; acc: 0.75
Batch: 280; loss: 0.81; acc: 0.81
Batch: 300; loss: 0.75; acc: 0.8
Batch: 320; loss: 0.73; acc: 0.77
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.66; acc: 0.8
Batch: 380; loss: 0.52; acc: 0.88
Batch: 400; loss: 0.97; acc: 0.69
Batch: 420; loss: 0.89; acc: 0.75
Batch: 440; loss: 0.83; acc: 0.67
Batch: 460; loss: 0.86; acc: 0.77
Batch: 480; loss: 0.87; acc: 0.73
Batch: 500; loss: 0.59; acc: 0.81
Batch: 520; loss: 0.67; acc: 0.73
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.66; acc: 0.77
Batch: 580; loss: 0.83; acc: 0.72
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.58; acc: 0.83
Batch: 640; loss: 0.8; acc: 0.72
Batch: 660; loss: 0.79; acc: 0.73
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.85; acc: 0.78
Batch: 720; loss: 0.76; acc: 0.8
Batch: 740; loss: 0.61; acc: 0.8
Batch: 760; loss: 0.72; acc: 0.73
Batch: 780; loss: 0.44; acc: 0.8
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.61; acc: 0.77
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.77
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.6410701195145868; val_accuracy: 0.7982683121019108 

The current subspace-distance is: 8.647284266771749e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.89; acc: 0.75
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.83; acc: 0.77
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.71; acc: 0.75
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.77; acc: 0.8
Batch: 160; loss: 0.7; acc: 0.81
Batch: 180; loss: 0.7; acc: 0.75
Batch: 200; loss: 0.52; acc: 0.83
Batch: 220; loss: 0.66; acc: 0.81
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.88; acc: 0.73
Batch: 280; loss: 0.62; acc: 0.77
Batch: 300; loss: 0.71; acc: 0.81
Batch: 320; loss: 0.99; acc: 0.73
Batch: 340; loss: 0.62; acc: 0.78
Batch: 360; loss: 0.62; acc: 0.81
Batch: 380; loss: 0.93; acc: 0.72
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.64; acc: 0.86
Batch: 460; loss: 0.7; acc: 0.81
Batch: 480; loss: 0.89; acc: 0.73
Batch: 500; loss: 0.68; acc: 0.78
Batch: 520; loss: 0.74; acc: 0.75
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.93; acc: 0.66
Batch: 580; loss: 0.81; acc: 0.78
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.65; acc: 0.8
Batch: 660; loss: 0.41; acc: 0.83
Batch: 680; loss: 0.56; acc: 0.8
Batch: 700; loss: 0.55; acc: 0.78
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.96; acc: 0.73
Batch: 760; loss: 0.62; acc: 0.77
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.64; acc: 0.75
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.32; acc: 0.89
Val Epoch over. val_loss: 0.6389370920361986; val_accuracy: 0.7981687898089171 

The current subspace-distance is: 8.873374463291839e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.63; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.77; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.74; acc: 0.83
Batch: 100; loss: 0.74; acc: 0.73
Batch: 120; loss: 0.53; acc: 0.78
Batch: 140; loss: 0.71; acc: 0.81
Batch: 160; loss: 0.94; acc: 0.64
Batch: 180; loss: 0.8; acc: 0.73
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 0.62; acc: 0.84
Batch: 240; loss: 0.54; acc: 0.81
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.93; acc: 0.8
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.69; acc: 0.78
Batch: 340; loss: 0.71; acc: 0.86
Batch: 360; loss: 0.66; acc: 0.77
Batch: 380; loss: 0.68; acc: 0.78
Batch: 400; loss: 0.53; acc: 0.8
Batch: 420; loss: 0.63; acc: 0.8
Batch: 440; loss: 0.56; acc: 0.8
Batch: 460; loss: 0.62; acc: 0.78
Batch: 480; loss: 0.62; acc: 0.81
Batch: 500; loss: 0.61; acc: 0.78
Batch: 520; loss: 0.64; acc: 0.75
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.94; acc: 0.78
Batch: 580; loss: 0.68; acc: 0.8
Batch: 600; loss: 0.72; acc: 0.7
Batch: 620; loss: 0.58; acc: 0.8
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.46; acc: 0.81
Batch: 680; loss: 0.67; acc: 0.81
Batch: 700; loss: 0.85; acc: 0.78
Batch: 720; loss: 0.71; acc: 0.78
Batch: 740; loss: 0.69; acc: 0.75
Batch: 760; loss: 0.68; acc: 0.78
Batch: 780; loss: 1.03; acc: 0.67
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.6374371114430154; val_accuracy: 0.8022492038216561 

The current subspace-distance is: 9.259558282792568e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.86; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.73; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.81
Batch: 80; loss: 0.65; acc: 0.77
Batch: 100; loss: 0.7; acc: 0.75
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.51; acc: 0.84
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.85; acc: 0.77
Batch: 240; loss: 0.62; acc: 0.77
Batch: 260; loss: 0.53; acc: 0.88
Batch: 280; loss: 0.78; acc: 0.78
Batch: 300; loss: 1.03; acc: 0.73
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.74; acc: 0.78
Batch: 360; loss: 0.74; acc: 0.73
Batch: 380; loss: 0.58; acc: 0.81
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.89; acc: 0.7
Batch: 440; loss: 0.76; acc: 0.78
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.74; acc: 0.75
Batch: 500; loss: 0.53; acc: 0.8
Batch: 520; loss: 0.74; acc: 0.69
Batch: 540; loss: 0.64; acc: 0.78
Batch: 560; loss: 0.82; acc: 0.73
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.72; acc: 0.78
Batch: 640; loss: 0.59; acc: 0.8
Batch: 660; loss: 0.74; acc: 0.83
Batch: 680; loss: 0.76; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.83
Batch: 720; loss: 0.88; acc: 0.73
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.62; acc: 0.84
Batch: 780; loss: 0.66; acc: 0.78
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.72
Batch: 20; loss: 0.66; acc: 0.73
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.66; acc: 0.75
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.6438144646632443; val_accuracy: 0.7954816878980892 

The current subspace-distance is: 9.401904389960691e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.95; acc: 0.77
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.67; acc: 0.77
Batch: 60; loss: 1.02; acc: 0.66
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.67; acc: 0.78
Batch: 120; loss: 1.04; acc: 0.72
Batch: 140; loss: 0.79; acc: 0.73
Batch: 160; loss: 0.8; acc: 0.78
Batch: 180; loss: 0.71; acc: 0.83
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.97; acc: 0.72
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.64; acc: 0.72
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.85; acc: 0.81
Batch: 320; loss: 0.77; acc: 0.78
Batch: 340; loss: 0.65; acc: 0.8
Batch: 360; loss: 0.62; acc: 0.78
Batch: 380; loss: 0.81; acc: 0.72
Batch: 400; loss: 0.58; acc: 0.86
Batch: 420; loss: 0.65; acc: 0.78
Batch: 440; loss: 0.73; acc: 0.78
Batch: 460; loss: 0.54; acc: 0.81
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.76; acc: 0.77
Batch: 520; loss: 0.86; acc: 0.78
Batch: 540; loss: 0.87; acc: 0.7
Batch: 560; loss: 0.67; acc: 0.8
Batch: 580; loss: 0.81; acc: 0.77
Batch: 600; loss: 0.66; acc: 0.81
Batch: 620; loss: 0.73; acc: 0.73
Batch: 640; loss: 0.83; acc: 0.72
Batch: 660; loss: 0.62; acc: 0.77
Batch: 680; loss: 0.78; acc: 0.72
Batch: 700; loss: 0.57; acc: 0.8
Batch: 720; loss: 0.77; acc: 0.78
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.81; acc: 0.78
Batch: 780; loss: 0.72; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.6335499263872766; val_accuracy: 0.8000597133757962 

The current subspace-distance is: 9.425514144822955e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.69; acc: 0.78
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.7; acc: 0.7
Batch: 160; loss: 0.74; acc: 0.84
Batch: 180; loss: 0.56; acc: 0.77
Batch: 200; loss: 0.69; acc: 0.78
Batch: 220; loss: 0.45; acc: 0.83
Batch: 240; loss: 0.71; acc: 0.78
Batch: 260; loss: 0.89; acc: 0.78
Batch: 280; loss: 0.72; acc: 0.72
Batch: 300; loss: 0.75; acc: 0.75
Batch: 320; loss: 0.77; acc: 0.72
Batch: 340; loss: 0.66; acc: 0.86
Batch: 360; loss: 0.51; acc: 0.81
Batch: 380; loss: 0.69; acc: 0.78
Batch: 400; loss: 0.53; acc: 0.81
Batch: 420; loss: 0.85; acc: 0.73
Batch: 440; loss: 0.57; acc: 0.86
Batch: 460; loss: 0.64; acc: 0.81
Batch: 480; loss: 0.77; acc: 0.77
Batch: 500; loss: 0.63; acc: 0.84
Batch: 520; loss: 0.56; acc: 0.83
Batch: 540; loss: 0.69; acc: 0.77
Batch: 560; loss: 0.85; acc: 0.67
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.83
Batch: 620; loss: 0.65; acc: 0.83
Batch: 640; loss: 0.79; acc: 0.69
Batch: 660; loss: 0.6; acc: 0.75
Batch: 680; loss: 0.65; acc: 0.84
Batch: 700; loss: 0.82; acc: 0.75
Batch: 720; loss: 0.77; acc: 0.77
Batch: 740; loss: 0.69; acc: 0.77
Batch: 760; loss: 0.75; acc: 0.75
Batch: 780; loss: 0.83; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.6324523256462851; val_accuracy: 0.8007563694267515 

The current subspace-distance is: 9.476546983933076e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.67; acc: 0.8
Batch: 40; loss: 0.64; acc: 0.83
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.76; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.72
Batch: 120; loss: 0.85; acc: 0.7
Batch: 140; loss: 0.7; acc: 0.73
Batch: 160; loss: 0.6; acc: 0.83
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.89; acc: 0.73
Batch: 220; loss: 0.69; acc: 0.75
Batch: 240; loss: 0.72; acc: 0.73
Batch: 260; loss: 0.82; acc: 0.75
Batch: 280; loss: 0.75; acc: 0.75
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.55; acc: 0.81
Batch: 340; loss: 0.73; acc: 0.8
Batch: 360; loss: 0.94; acc: 0.67
Batch: 380; loss: 0.75; acc: 0.7
Batch: 400; loss: 0.67; acc: 0.73
Batch: 420; loss: 0.58; acc: 0.86
Batch: 440; loss: 0.74; acc: 0.72
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.7; acc: 0.73
Batch: 500; loss: 0.58; acc: 0.78
Batch: 520; loss: 0.9; acc: 0.77
Batch: 540; loss: 0.79; acc: 0.77
Batch: 560; loss: 0.69; acc: 0.78
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.9; acc: 0.72
Batch: 620; loss: 0.84; acc: 0.78
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.73; acc: 0.72
Batch: 680; loss: 0.59; acc: 0.88
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.82; acc: 0.73
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.69; acc: 0.78
Batch: 780; loss: 0.59; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.6328290858466155; val_accuracy: 0.8001592356687898 

The current subspace-distance is: 9.627789404476061e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.9; acc: 0.78
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.89; acc: 0.7
Batch: 60; loss: 1.08; acc: 0.73
Batch: 80; loss: 0.8; acc: 0.72
Batch: 100; loss: 1.15; acc: 0.69
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 1.07; acc: 0.75
Batch: 180; loss: 0.6; acc: 0.8
Batch: 200; loss: 0.71; acc: 0.78
Batch: 220; loss: 0.68; acc: 0.73
Batch: 240; loss: 0.59; acc: 0.83
Batch: 260; loss: 0.62; acc: 0.78
Batch: 280; loss: 0.85; acc: 0.73
Batch: 300; loss: 0.7; acc: 0.77
Batch: 320; loss: 0.76; acc: 0.78
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.67; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.55; acc: 0.83
Batch: 440; loss: 0.67; acc: 0.83
Batch: 460; loss: 0.91; acc: 0.66
Batch: 480; loss: 0.65; acc: 0.75
Batch: 500; loss: 0.8; acc: 0.8
Batch: 520; loss: 0.65; acc: 0.75
Batch: 540; loss: 0.62; acc: 0.81
Batch: 560; loss: 0.83; acc: 0.75
Batch: 580; loss: 0.83; acc: 0.8
Batch: 600; loss: 0.55; acc: 0.88
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.65; acc: 0.8
Batch: 660; loss: 0.81; acc: 0.75
Batch: 680; loss: 0.78; acc: 0.78
Batch: 700; loss: 0.55; acc: 0.81
Batch: 720; loss: 0.79; acc: 0.77
Batch: 740; loss: 0.81; acc: 0.81
Batch: 760; loss: 0.63; acc: 0.78
Batch: 780; loss: 0.6; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.61; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.6314012933119088; val_accuracy: 0.8007563694267515 

The current subspace-distance is: 0.00010137054050574079 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.67; acc: 0.81
Batch: 20; loss: 0.93; acc: 0.7
Batch: 40; loss: 0.58; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.66; acc: 0.75
Batch: 100; loss: 0.94; acc: 0.73
Batch: 120; loss: 0.68; acc: 0.73
Batch: 140; loss: 0.68; acc: 0.77
Batch: 160; loss: 0.61; acc: 0.77
Batch: 180; loss: 0.78; acc: 0.77
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 0.69; acc: 0.72
Batch: 240; loss: 0.56; acc: 0.81
Batch: 260; loss: 0.8; acc: 0.8
Batch: 280; loss: 0.56; acc: 0.84
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.68; acc: 0.77
Batch: 340; loss: 0.73; acc: 0.77
Batch: 360; loss: 0.43; acc: 0.91
Batch: 380; loss: 0.52; acc: 0.8
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.52; acc: 0.81
Batch: 440; loss: 0.72; acc: 0.78
Batch: 460; loss: 0.66; acc: 0.8
Batch: 480; loss: 0.77; acc: 0.7
Batch: 500; loss: 0.88; acc: 0.72
Batch: 520; loss: 0.82; acc: 0.69
Batch: 540; loss: 0.69; acc: 0.77
Batch: 560; loss: 0.76; acc: 0.81
Batch: 580; loss: 0.65; acc: 0.75
Batch: 600; loss: 0.75; acc: 0.81
Batch: 620; loss: 0.53; acc: 0.89
Batch: 640; loss: 0.64; acc: 0.78
Batch: 660; loss: 0.71; acc: 0.8
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.66; acc: 0.77
Batch: 720; loss: 0.66; acc: 0.83
Batch: 740; loss: 0.85; acc: 0.7
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.45; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.77
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.3; acc: 0.89
Val Epoch over. val_loss: 0.6318824690808157; val_accuracy: 0.7988654458598726 

The current subspace-distance is: 9.96959424810484e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.71; acc: 0.77
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.83
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 0.6; acc: 0.83
Batch: 160; loss: 0.78; acc: 0.8
Batch: 180; loss: 0.9; acc: 0.72
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.82; acc: 0.72
Batch: 240; loss: 0.85; acc: 0.77
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.89; acc: 0.73
Batch: 300; loss: 0.86; acc: 0.75
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.94; acc: 0.73
Batch: 360; loss: 0.58; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.87; acc: 0.75
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 1.01; acc: 0.7
Batch: 460; loss: 0.88; acc: 0.7
Batch: 480; loss: 0.72; acc: 0.73
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.82; acc: 0.73
Batch: 540; loss: 0.61; acc: 0.75
Batch: 560; loss: 0.69; acc: 0.77
Batch: 580; loss: 0.73; acc: 0.75
Batch: 600; loss: 0.77; acc: 0.7
Batch: 620; loss: 0.63; acc: 0.8
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.68; acc: 0.75
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 0.41; acc: 0.92
Batch: 740; loss: 0.76; acc: 0.75
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.63; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.75
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6308137915886132; val_accuracy: 0.798765923566879 

The current subspace-distance is: 0.00010215963993687183 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.7; acc: 0.75
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.69; acc: 0.8
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.88; acc: 0.75
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 0.67; acc: 0.77
Batch: 280; loss: 0.8; acc: 0.72
Batch: 300; loss: 1.05; acc: 0.69
Batch: 320; loss: 0.58; acc: 0.83
Batch: 340; loss: 0.62; acc: 0.81
Batch: 360; loss: 0.75; acc: 0.75
Batch: 380; loss: 0.67; acc: 0.77
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.68; acc: 0.75
Batch: 440; loss: 0.82; acc: 0.69
Batch: 460; loss: 0.8; acc: 0.72
Batch: 480; loss: 0.59; acc: 0.8
Batch: 500; loss: 0.54; acc: 0.78
Batch: 520; loss: 0.75; acc: 0.77
Batch: 540; loss: 0.93; acc: 0.73
Batch: 560; loss: 0.88; acc: 0.7
Batch: 580; loss: 0.7; acc: 0.78
Batch: 600; loss: 0.51; acc: 0.84
Batch: 620; loss: 1.0; acc: 0.62
Batch: 640; loss: 0.61; acc: 0.86
Batch: 660; loss: 0.86; acc: 0.73
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 1.01; acc: 0.69
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.56; acc: 0.8
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.64; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.74; acc: 0.73
Batch: 20; loss: 0.61; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.92
Val Epoch over. val_loss: 0.6333220091405188; val_accuracy: 0.7996616242038217 

The current subspace-distance is: 0.00010526228288654238 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.7; acc: 0.75
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 1.04; acc: 0.73
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.69; acc: 0.72
Batch: 160; loss: 0.63; acc: 0.78
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.71; acc: 0.78
Batch: 220; loss: 0.92; acc: 0.75
Batch: 240; loss: 0.67; acc: 0.7
Batch: 260; loss: 0.89; acc: 0.7
Batch: 280; loss: 1.04; acc: 0.66
Batch: 300; loss: 0.8; acc: 0.75
Batch: 320; loss: 0.65; acc: 0.8
Batch: 340; loss: 0.8; acc: 0.78
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.66; acc: 0.77
Batch: 420; loss: 0.72; acc: 0.67
Batch: 440; loss: 0.62; acc: 0.81
Batch: 460; loss: 0.73; acc: 0.78
Batch: 480; loss: 0.65; acc: 0.83
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.86; acc: 0.73
Batch: 540; loss: 0.67; acc: 0.78
Batch: 560; loss: 0.66; acc: 0.8
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.83; acc: 0.77
Batch: 640; loss: 0.8; acc: 0.8
Batch: 660; loss: 0.55; acc: 0.8
Batch: 680; loss: 0.47; acc: 0.8
Batch: 700; loss: 0.58; acc: 0.83
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.64; acc: 0.8
Batch: 760; loss: 0.69; acc: 0.77
Batch: 780; loss: 0.59; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.62; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6335657374684218; val_accuracy: 0.8004578025477707 

The current subspace-distance is: 0.00010825112258316949 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 1.09; acc: 0.72
Batch: 100; loss: 0.74; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.72
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.75; acc: 0.8
Batch: 180; loss: 0.67; acc: 0.72
Batch: 200; loss: 0.58; acc: 0.86
Batch: 220; loss: 0.71; acc: 0.77
Batch: 240; loss: 0.73; acc: 0.78
Batch: 260; loss: 0.57; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.85; acc: 0.81
Batch: 340; loss: 0.65; acc: 0.78
Batch: 360; loss: 0.7; acc: 0.83
Batch: 380; loss: 0.55; acc: 0.84
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.75; acc: 0.72
Batch: 440; loss: 0.61; acc: 0.8
Batch: 460; loss: 0.66; acc: 0.81
Batch: 480; loss: 0.76; acc: 0.73
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.75; acc: 0.8
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.67; acc: 0.78
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.55; acc: 0.78
Batch: 620; loss: 0.75; acc: 0.8
Batch: 640; loss: 0.46; acc: 0.78
Batch: 660; loss: 0.7; acc: 0.77
Batch: 680; loss: 0.7; acc: 0.8
Batch: 700; loss: 0.64; acc: 0.77
Batch: 720; loss: 0.78; acc: 0.73
Batch: 740; loss: 0.63; acc: 0.8
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.94; acc: 0.7
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6314171215720997; val_accuracy: 0.8003582802547771 

The current subspace-distance is: 0.00011128383630421013 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.64; acc: 0.84
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.87; acc: 0.7
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.76; acc: 0.73
Batch: 180; loss: 0.62; acc: 0.81
Batch: 200; loss: 0.85; acc: 0.72
Batch: 220; loss: 0.54; acc: 0.81
Batch: 240; loss: 0.56; acc: 0.81
Batch: 260; loss: 0.96; acc: 0.7
Batch: 280; loss: 0.74; acc: 0.72
Batch: 300; loss: 0.76; acc: 0.73
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.57; acc: 0.81
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.69; acc: 0.72
Batch: 420; loss: 0.53; acc: 0.77
Batch: 440; loss: 0.79; acc: 0.77
Batch: 460; loss: 0.43; acc: 0.83
Batch: 480; loss: 0.67; acc: 0.77
Batch: 500; loss: 0.72; acc: 0.8
Batch: 520; loss: 0.51; acc: 0.88
Batch: 540; loss: 0.75; acc: 0.75
Batch: 560; loss: 0.67; acc: 0.88
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.63; acc: 0.83
Batch: 620; loss: 0.66; acc: 0.8
Batch: 640; loss: 0.67; acc: 0.75
Batch: 660; loss: 0.55; acc: 0.81
Batch: 680; loss: 0.71; acc: 0.77
Batch: 700; loss: 0.68; acc: 0.78
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.89; acc: 0.77
Batch: 760; loss: 0.63; acc: 0.77
Batch: 780; loss: 0.53; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.77
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.88
Val Epoch over. val_loss: 0.6337083145311684; val_accuracy: 0.796875 

The current subspace-distance is: 0.00011320186604280025 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.81; acc: 0.78
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.67; acc: 0.83
Batch: 80; loss: 0.7; acc: 0.81
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.53; acc: 0.77
Batch: 160; loss: 0.61; acc: 0.78
Batch: 180; loss: 0.51; acc: 0.86
Batch: 200; loss: 0.82; acc: 0.77
Batch: 220; loss: 0.78; acc: 0.77
Batch: 240; loss: 0.79; acc: 0.75
Batch: 260; loss: 0.65; acc: 0.75
Batch: 280; loss: 0.77; acc: 0.73
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.8; acc: 0.77
Batch: 340; loss: 0.6; acc: 0.78
Batch: 360; loss: 0.72; acc: 0.75
Batch: 380; loss: 0.53; acc: 0.8
Batch: 400; loss: 0.7; acc: 0.78
Batch: 420; loss: 0.75; acc: 0.78
Batch: 440; loss: 0.74; acc: 0.77
Batch: 460; loss: 0.63; acc: 0.81
Batch: 480; loss: 0.59; acc: 0.78
Batch: 500; loss: 0.59; acc: 0.81
Batch: 520; loss: 0.72; acc: 0.75
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.52; acc: 0.84
Batch: 580; loss: 0.82; acc: 0.7
Batch: 600; loss: 0.71; acc: 0.8
Batch: 620; loss: 0.79; acc: 0.81
Batch: 640; loss: 0.73; acc: 0.78
Batch: 660; loss: 0.73; acc: 0.75
Batch: 680; loss: 0.42; acc: 0.92
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.78; acc: 0.78
Batch: 740; loss: 0.79; acc: 0.78
Batch: 760; loss: 0.89; acc: 0.7
Batch: 780; loss: 0.69; acc: 0.75
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6308131160060312; val_accuracy: 0.7994625796178344 

The current subspace-distance is: 0.00011219729640288278 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.66; acc: 0.81
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.65; acc: 0.77
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.69; acc: 0.81
Batch: 100; loss: 0.71; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.75; acc: 0.72
Batch: 240; loss: 0.95; acc: 0.73
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.68; acc: 0.73
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.82; acc: 0.7
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.81; acc: 0.73
Batch: 420; loss: 0.63; acc: 0.77
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.66; acc: 0.78
Batch: 480; loss: 0.87; acc: 0.67
Batch: 500; loss: 0.69; acc: 0.75
Batch: 520; loss: 0.49; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.79; acc: 0.75
Batch: 580; loss: 0.64; acc: 0.8
Batch: 600; loss: 0.53; acc: 0.75
Batch: 620; loss: 0.81; acc: 0.78
Batch: 640; loss: 0.88; acc: 0.75
Batch: 660; loss: 0.7; acc: 0.73
Batch: 680; loss: 0.72; acc: 0.83
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.8; acc: 0.78
Batch: 740; loss: 0.65; acc: 0.83
Batch: 760; loss: 0.7; acc: 0.8
Batch: 780; loss: 0.57; acc: 0.78
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.6314595191721704; val_accuracy: 0.7991640127388535 

The current subspace-distance is: 0.00011337910109432414 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.77; acc: 0.72
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.78; acc: 0.78
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.62; acc: 0.78
Batch: 160; loss: 0.79; acc: 0.77
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 1.04; acc: 0.61
Batch: 220; loss: 0.68; acc: 0.73
Batch: 240; loss: 0.57; acc: 0.84
Batch: 260; loss: 0.62; acc: 0.83
Batch: 280; loss: 0.85; acc: 0.7
Batch: 300; loss: 0.7; acc: 0.8
Batch: 320; loss: 0.69; acc: 0.78
Batch: 340; loss: 0.76; acc: 0.78
Batch: 360; loss: 0.87; acc: 0.75
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.73; acc: 0.78
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.73; acc: 0.75
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.63; acc: 0.8
Batch: 520; loss: 0.69; acc: 0.73
Batch: 540; loss: 0.8; acc: 0.75
Batch: 560; loss: 0.87; acc: 0.75
Batch: 580; loss: 0.59; acc: 0.8
Batch: 600; loss: 0.6; acc: 0.81
Batch: 620; loss: 0.83; acc: 0.72
Batch: 640; loss: 0.61; acc: 0.8
Batch: 660; loss: 0.58; acc: 0.88
Batch: 680; loss: 0.81; acc: 0.7
Batch: 700; loss: 0.73; acc: 0.84
Batch: 720; loss: 0.4; acc: 0.81
Batch: 740; loss: 0.74; acc: 0.75
Batch: 760; loss: 0.86; acc: 0.69
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.6298053210518163; val_accuracy: 0.801453025477707 

The current subspace-distance is: 0.00011889371671713889 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.9; acc: 0.73
Batch: 40; loss: 0.76; acc: 0.75
Batch: 60; loss: 0.63; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.67
Batch: 100; loss: 1.0; acc: 0.64
Batch: 120; loss: 0.86; acc: 0.72
Batch: 140; loss: 0.66; acc: 0.77
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.64; acc: 0.8
Batch: 200; loss: 0.99; acc: 0.7
Batch: 220; loss: 0.6; acc: 0.81
Batch: 240; loss: 0.59; acc: 0.77
Batch: 260; loss: 0.72; acc: 0.8
Batch: 280; loss: 0.76; acc: 0.78
Batch: 300; loss: 0.59; acc: 0.78
Batch: 320; loss: 0.87; acc: 0.66
Batch: 340; loss: 0.69; acc: 0.75
Batch: 360; loss: 0.59; acc: 0.8
Batch: 380; loss: 0.59; acc: 0.86
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.64; acc: 0.81
Batch: 460; loss: 0.73; acc: 0.81
Batch: 480; loss: 0.58; acc: 0.83
Batch: 500; loss: 0.93; acc: 0.7
Batch: 520; loss: 0.46; acc: 0.81
Batch: 540; loss: 0.65; acc: 0.78
Batch: 560; loss: 0.85; acc: 0.69
Batch: 580; loss: 0.57; acc: 0.8
Batch: 600; loss: 0.76; acc: 0.78
Batch: 620; loss: 0.85; acc: 0.75
Batch: 640; loss: 0.9; acc: 0.73
Batch: 660; loss: 0.74; acc: 0.78
Batch: 680; loss: 0.74; acc: 0.81
Batch: 700; loss: 0.65; acc: 0.8
Batch: 720; loss: 0.56; acc: 0.83
Batch: 740; loss: 0.65; acc: 0.72
Batch: 760; loss: 0.66; acc: 0.78
Batch: 780; loss: 0.64; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6303238203381277; val_accuracy: 0.7994625796178344 

The current subspace-distance is: 0.00012081493332516402 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.66; acc: 0.81
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.53; acc: 0.77
Batch: 160; loss: 0.65; acc: 0.86
Batch: 180; loss: 0.68; acc: 0.8
Batch: 200; loss: 0.55; acc: 0.81
Batch: 220; loss: 0.68; acc: 0.84
Batch: 240; loss: 0.68; acc: 0.84
Batch: 260; loss: 0.81; acc: 0.75
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.92; acc: 0.72
Batch: 320; loss: 0.63; acc: 0.77
Batch: 340; loss: 0.66; acc: 0.84
Batch: 360; loss: 0.6; acc: 0.8
Batch: 380; loss: 0.65; acc: 0.81
Batch: 400; loss: 0.83; acc: 0.8
Batch: 420; loss: 0.64; acc: 0.77
Batch: 440; loss: 0.63; acc: 0.77
Batch: 460; loss: 0.94; acc: 0.78
Batch: 480; loss: 0.56; acc: 0.81
Batch: 500; loss: 0.95; acc: 0.73
Batch: 520; loss: 0.83; acc: 0.7
Batch: 540; loss: 0.69; acc: 0.8
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.62; acc: 0.78
Batch: 620; loss: 0.81; acc: 0.77
Batch: 640; loss: 0.73; acc: 0.75
Batch: 660; loss: 0.86; acc: 0.73
Batch: 680; loss: 0.62; acc: 0.78
Batch: 700; loss: 0.98; acc: 0.7
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 0.77; acc: 0.73
Batch: 780; loss: 0.8; acc: 0.73
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.58; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.92
Val Epoch over. val_loss: 0.6301266387769371; val_accuracy: 0.8007563694267515 

The current subspace-distance is: 0.00012001508730463684 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.65; acc: 0.72
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.89; acc: 0.75
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 0.79; acc: 0.75
Batch: 140; loss: 0.51; acc: 0.81
Batch: 160; loss: 0.63; acc: 0.75
Batch: 180; loss: 0.59; acc: 0.8
Batch: 200; loss: 0.87; acc: 0.73
Batch: 220; loss: 0.88; acc: 0.67
Batch: 240; loss: 0.79; acc: 0.75
Batch: 260; loss: 0.74; acc: 0.75
Batch: 280; loss: 0.69; acc: 0.78
Batch: 300; loss: 0.56; acc: 0.78
Batch: 320; loss: 1.09; acc: 0.66
Batch: 340; loss: 0.84; acc: 0.84
Batch: 360; loss: 0.85; acc: 0.75
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.63; acc: 0.78
Batch: 420; loss: 0.9; acc: 0.64
Batch: 440; loss: 0.85; acc: 0.75
Batch: 460; loss: 0.63; acc: 0.88
Batch: 480; loss: 0.87; acc: 0.66
Batch: 500; loss: 0.66; acc: 0.77
Batch: 520; loss: 0.76; acc: 0.73
Batch: 540; loss: 0.58; acc: 0.8
Batch: 560; loss: 1.03; acc: 0.67
Batch: 580; loss: 0.93; acc: 0.78
Batch: 600; loss: 0.81; acc: 0.73
Batch: 620; loss: 0.65; acc: 0.81
Batch: 640; loss: 0.94; acc: 0.69
Batch: 660; loss: 0.57; acc: 0.84
Batch: 680; loss: 0.81; acc: 0.73
Batch: 700; loss: 0.59; acc: 0.84
Batch: 720; loss: 0.78; acc: 0.77
Batch: 740; loss: 0.66; acc: 0.81
Batch: 760; loss: 0.85; acc: 0.73
Batch: 780; loss: 0.72; acc: 0.77
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.6295829344137459; val_accuracy: 0.8024482484076433 

The current subspace-distance is: 0.00011960526171606034 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.68; acc: 0.86
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.94; acc: 0.73
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.65; acc: 0.75
Batch: 220; loss: 0.74; acc: 0.75
Batch: 240; loss: 0.67; acc: 0.8
Batch: 260; loss: 0.6; acc: 0.83
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.72; acc: 0.83
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.61; acc: 0.81
Batch: 380; loss: 0.8; acc: 0.75
Batch: 400; loss: 0.96; acc: 0.73
Batch: 420; loss: 0.66; acc: 0.77
Batch: 440; loss: 0.56; acc: 0.86
Batch: 460; loss: 0.62; acc: 0.73
Batch: 480; loss: 0.56; acc: 0.84
Batch: 500; loss: 0.87; acc: 0.77
Batch: 520; loss: 0.6; acc: 0.83
Batch: 540; loss: 1.04; acc: 0.69
Batch: 560; loss: 0.72; acc: 0.78
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.77; acc: 0.78
Batch: 640; loss: 0.65; acc: 0.73
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.74; acc: 0.81
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.86; acc: 0.78
Batch: 740; loss: 0.73; acc: 0.77
Batch: 760; loss: 0.69; acc: 0.73
Batch: 780; loss: 0.62; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.6299644684905459; val_accuracy: 0.8019506369426752 

The current subspace-distance is: 0.00011859368532896042 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.86
Batch: 20; loss: 0.83; acc: 0.7
Batch: 40; loss: 0.55; acc: 0.81
Batch: 60; loss: 0.68; acc: 0.72
Batch: 80; loss: 0.53; acc: 0.78
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.82; acc: 0.75
Batch: 160; loss: 0.91; acc: 0.73
Batch: 180; loss: 0.87; acc: 0.72
Batch: 200; loss: 0.8; acc: 0.73
Batch: 220; loss: 0.9; acc: 0.73
Batch: 240; loss: 0.64; acc: 0.84
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.69; acc: 0.75
Batch: 300; loss: 0.59; acc: 0.83
Batch: 320; loss: 0.74; acc: 0.77
Batch: 340; loss: 0.83; acc: 0.77
Batch: 360; loss: 0.65; acc: 0.8
Batch: 380; loss: 0.74; acc: 0.8
Batch: 400; loss: 0.72; acc: 0.72
Batch: 420; loss: 0.95; acc: 0.73
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.7; acc: 0.8
Batch: 480; loss: 0.69; acc: 0.78
Batch: 500; loss: 0.54; acc: 0.78
Batch: 520; loss: 0.77; acc: 0.77
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.62; acc: 0.78
Batch: 580; loss: 0.48; acc: 0.8
Batch: 600; loss: 0.61; acc: 0.8
Batch: 620; loss: 0.91; acc: 0.7
Batch: 640; loss: 0.6; acc: 0.78
Batch: 660; loss: 0.79; acc: 0.78
Batch: 680; loss: 0.6; acc: 0.86
Batch: 700; loss: 0.71; acc: 0.72
Batch: 720; loss: 0.73; acc: 0.73
Batch: 740; loss: 0.82; acc: 0.73
Batch: 760; loss: 0.77; acc: 0.73
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.62; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.77
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6305169033206952; val_accuracy: 0.8005573248407644 

The current subspace-distance is: 0.00012363215500954539 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.66; acc: 0.77
Batch: 20; loss: 0.96; acc: 0.69
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.73
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.88; acc: 0.7
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.68; acc: 0.77
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.85; acc: 0.73
Batch: 240; loss: 0.6; acc: 0.77
Batch: 260; loss: 0.64; acc: 0.75
Batch: 280; loss: 0.79; acc: 0.7
Batch: 300; loss: 0.79; acc: 0.8
Batch: 320; loss: 0.75; acc: 0.75
Batch: 340; loss: 0.62; acc: 0.77
Batch: 360; loss: 0.65; acc: 0.78
Batch: 380; loss: 0.59; acc: 0.8
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.62; acc: 0.8
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.62; acc: 0.8
Batch: 500; loss: 0.57; acc: 0.78
Batch: 520; loss: 0.88; acc: 0.72
Batch: 540; loss: 0.63; acc: 0.78
Batch: 560; loss: 0.63; acc: 0.8
Batch: 580; loss: 0.86; acc: 0.73
Batch: 600; loss: 0.95; acc: 0.77
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.58; acc: 0.84
Batch: 660; loss: 0.59; acc: 0.8
Batch: 680; loss: 0.64; acc: 0.83
Batch: 700; loss: 0.55; acc: 0.86
Batch: 720; loss: 0.93; acc: 0.69
Batch: 740; loss: 0.84; acc: 0.73
Batch: 760; loss: 0.74; acc: 0.78
Batch: 780; loss: 0.54; acc: 0.83
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.6; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.6317463676640942; val_accuracy: 0.8016520700636943 

The current subspace-distance is: 0.00012493261601775885 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.34; acc: 0.94
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.98; acc: 0.75
Batch: 100; loss: 0.65; acc: 0.75
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.71; acc: 0.8
Batch: 160; loss: 0.61; acc: 0.83
Batch: 180; loss: 0.65; acc: 0.8
Batch: 200; loss: 0.85; acc: 0.73
Batch: 220; loss: 0.57; acc: 0.81
Batch: 240; loss: 0.67; acc: 0.78
Batch: 260; loss: 1.11; acc: 0.7
Batch: 280; loss: 0.86; acc: 0.8
Batch: 300; loss: 0.92; acc: 0.69
Batch: 320; loss: 0.8; acc: 0.77
Batch: 340; loss: 1.03; acc: 0.64
Batch: 360; loss: 0.71; acc: 0.77
Batch: 380; loss: 0.62; acc: 0.81
Batch: 400; loss: 0.69; acc: 0.83
Batch: 420; loss: 0.83; acc: 0.77
Batch: 440; loss: 0.5; acc: 0.89
Batch: 460; loss: 0.6; acc: 0.81
Batch: 480; loss: 0.76; acc: 0.77
Batch: 500; loss: 0.85; acc: 0.75
Batch: 520; loss: 0.76; acc: 0.8
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.6; acc: 0.83
Batch: 580; loss: 0.62; acc: 0.75
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.96; acc: 0.73
Batch: 640; loss: 0.87; acc: 0.75
Batch: 660; loss: 0.6; acc: 0.77
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.56; acc: 0.81
Batch: 720; loss: 0.74; acc: 0.8
Batch: 740; loss: 0.65; acc: 0.77
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.8; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.6297186959511155; val_accuracy: 0.8007563694267515 

The current subspace-distance is: 0.00012555030116345733 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 26290
elements in E: 5553250
fraction nonzero: 0.004734164678341511
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.06
Batch: 180; loss: 2.31; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.28; acc: 0.09
Batch: 260; loss: 2.28; acc: 0.16
Batch: 280; loss: 2.27; acc: 0.23
Batch: 300; loss: 2.26; acc: 0.27
Batch: 320; loss: 2.28; acc: 0.12
Batch: 340; loss: 2.26; acc: 0.36
Batch: 360; loss: 2.26; acc: 0.22
Batch: 380; loss: 2.27; acc: 0.23
Batch: 400; loss: 2.27; acc: 0.3
Batch: 420; loss: 2.26; acc: 0.2
Batch: 440; loss: 2.25; acc: 0.3
Batch: 460; loss: 2.25; acc: 0.36
Batch: 480; loss: 2.22; acc: 0.36
Batch: 500; loss: 2.22; acc: 0.3
Batch: 520; loss: 2.2; acc: 0.34
Batch: 540; loss: 2.19; acc: 0.38
Batch: 560; loss: 2.15; acc: 0.36
Batch: 580; loss: 2.17; acc: 0.31
Batch: 600; loss: 2.03; acc: 0.39
Batch: 620; loss: 2.01; acc: 0.42
Batch: 640; loss: 1.94; acc: 0.38
Batch: 660; loss: 1.81; acc: 0.42
Batch: 680; loss: 1.76; acc: 0.38
Batch: 700; loss: 1.7; acc: 0.41
Batch: 720; loss: 1.32; acc: 0.61
Batch: 740; loss: 1.39; acc: 0.45
Batch: 760; loss: 1.06; acc: 0.72
Batch: 780; loss: 1.11; acc: 0.59
Train Epoch over. train_loss: 2.1; train_accuracy: 0.27 

Batch: 0; loss: 1.09; acc: 0.64
Batch: 20; loss: 1.03; acc: 0.67
Batch: 40; loss: 0.9; acc: 0.73
Batch: 60; loss: 0.96; acc: 0.64
Batch: 80; loss: 1.0; acc: 0.62
Batch: 100; loss: 1.0; acc: 0.64
Batch: 120; loss: 0.97; acc: 0.69
Batch: 140; loss: 0.94; acc: 0.67
Val Epoch over. val_loss: 1.118565880189276; val_accuracy: 0.6171377388535032 

The current subspace-distance is: 8.93970991455717e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.94; acc: 0.67
Batch: 20; loss: 0.99; acc: 0.62
Batch: 40; loss: 1.24; acc: 0.56
Batch: 60; loss: 0.81; acc: 0.7
Batch: 80; loss: 0.92; acc: 0.66
Batch: 100; loss: 0.99; acc: 0.55
Batch: 120; loss: 0.9; acc: 0.69
Batch: 140; loss: 1.2; acc: 0.59
Batch: 160; loss: 0.73; acc: 0.78
Batch: 180; loss: 1.15; acc: 0.67
Batch: 200; loss: 0.83; acc: 0.72
Batch: 220; loss: 0.81; acc: 0.77
Batch: 240; loss: 1.25; acc: 0.66
Batch: 260; loss: 1.13; acc: 0.61
Batch: 280; loss: 0.83; acc: 0.72
Batch: 300; loss: 0.73; acc: 0.73
Batch: 320; loss: 0.96; acc: 0.67
Batch: 340; loss: 0.68; acc: 0.77
Batch: 360; loss: 0.99; acc: 0.64
Batch: 380; loss: 0.93; acc: 0.67
Batch: 400; loss: 0.73; acc: 0.78
Batch: 420; loss: 0.62; acc: 0.81
Batch: 440; loss: 0.82; acc: 0.72
Batch: 460; loss: 0.98; acc: 0.69
Batch: 480; loss: 0.9; acc: 0.7
Batch: 500; loss: 0.85; acc: 0.77
Batch: 520; loss: 0.92; acc: 0.77
Batch: 540; loss: 0.71; acc: 0.75
Batch: 560; loss: 1.16; acc: 0.58
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 0.84; acc: 0.72
Batch: 620; loss: 0.92; acc: 0.7
Batch: 640; loss: 0.83; acc: 0.78
Batch: 660; loss: 0.84; acc: 0.73
Batch: 680; loss: 0.88; acc: 0.7
Batch: 700; loss: 0.89; acc: 0.69
Batch: 720; loss: 1.02; acc: 0.66
Batch: 740; loss: 0.67; acc: 0.78
Batch: 760; loss: 0.88; acc: 0.7
Batch: 780; loss: 0.95; acc: 0.61
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.87; acc: 0.67
Batch: 20; loss: 0.8; acc: 0.77
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.75; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.86; acc: 0.73
Batch: 140; loss: 0.28; acc: 0.95
Val Epoch over. val_loss: 0.7066853547551829; val_accuracy: 0.7696058917197452 

The current subspace-distance is: 1.935111140483059e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.7
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.76; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.77
Batch: 80; loss: 0.69; acc: 0.77
Batch: 100; loss: 0.78; acc: 0.73
Batch: 120; loss: 0.76; acc: 0.69
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.62; acc: 0.78
Batch: 180; loss: 0.78; acc: 0.7
Batch: 200; loss: 0.77; acc: 0.78
Batch: 220; loss: 0.72; acc: 0.83
Batch: 240; loss: 0.72; acc: 0.77
Batch: 260; loss: 0.68; acc: 0.77
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.58; acc: 0.73
Batch: 320; loss: 0.61; acc: 0.78
Batch: 340; loss: 0.68; acc: 0.78
Batch: 360; loss: 0.58; acc: 0.81
Batch: 380; loss: 0.81; acc: 0.78
Batch: 400; loss: 0.69; acc: 0.73
Batch: 420; loss: 0.66; acc: 0.81
Batch: 440; loss: 0.63; acc: 0.78
Batch: 460; loss: 0.85; acc: 0.69
Batch: 480; loss: 0.75; acc: 0.72
Batch: 500; loss: 0.86; acc: 0.8
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.7; acc: 0.77
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.78; acc: 0.75
Batch: 620; loss: 0.51; acc: 0.81
Batch: 640; loss: 0.67; acc: 0.75
Batch: 660; loss: 0.96; acc: 0.69
Batch: 680; loss: 0.75; acc: 0.7
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.63; acc: 0.78
Batch: 740; loss: 0.76; acc: 0.75
Batch: 760; loss: 0.61; acc: 0.78
Batch: 780; loss: 0.61; acc: 0.81
Train Epoch over. train_loss: 0.73; train_accuracy: 0.76 

Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.99; acc: 0.66
Batch: 40; loss: 0.57; acc: 0.78
Batch: 60; loss: 0.79; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.36; acc: 0.89
Val Epoch over. val_loss: 0.7782949940034538; val_accuracy: 0.7495023885350318 

The current subspace-distance is: 2.580446016509086e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.86; acc: 0.75
Batch: 40; loss: 0.73; acc: 0.75
Batch: 60; loss: 0.66; acc: 0.72
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.54; acc: 0.8
Batch: 200; loss: 0.86; acc: 0.7
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.62; acc: 0.86
Batch: 260; loss: 0.55; acc: 0.81
Batch: 280; loss: 1.07; acc: 0.73
Batch: 300; loss: 0.63; acc: 0.81
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.92; acc: 0.75
Batch: 360; loss: 0.48; acc: 0.8
Batch: 380; loss: 0.64; acc: 0.8
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.52; acc: 0.78
Batch: 440; loss: 0.67; acc: 0.81
Batch: 460; loss: 0.75; acc: 0.69
Batch: 480; loss: 0.7; acc: 0.8
Batch: 500; loss: 0.55; acc: 0.84
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.71; acc: 0.75
Batch: 560; loss: 0.76; acc: 0.75
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.84; acc: 0.73
Batch: 640; loss: 0.82; acc: 0.78
Batch: 660; loss: 0.8; acc: 0.73
Batch: 680; loss: 0.56; acc: 0.84
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.67; acc: 0.75
Batch: 740; loss: 0.61; acc: 0.8
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.53; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 0.85; acc: 0.7
Batch: 20; loss: 0.97; acc: 0.67
Batch: 40; loss: 0.64; acc: 0.75
Batch: 60; loss: 1.12; acc: 0.7
Batch: 80; loss: 0.69; acc: 0.75
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.98; acc: 0.72
Batch: 140; loss: 0.44; acc: 0.84
Val Epoch over. val_loss: 0.8405412980325663; val_accuracy: 0.7159633757961783 

The current subspace-distance is: 3.0840052204439417e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.24; acc: 0.67
Batch: 20; loss: 0.53; acc: 0.81
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.63; acc: 0.83
Batch: 100; loss: 0.76; acc: 0.75
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.61; acc: 0.81
Batch: 160; loss: 0.63; acc: 0.78
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.78; acc: 0.75
Batch: 240; loss: 0.64; acc: 0.77
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.62; acc: 0.8
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.62; acc: 0.77
Batch: 340; loss: 0.66; acc: 0.8
Batch: 360; loss: 0.59; acc: 0.77
Batch: 380; loss: 0.69; acc: 0.8
Batch: 400; loss: 0.56; acc: 0.84
Batch: 420; loss: 0.56; acc: 0.78
Batch: 440; loss: 1.13; acc: 0.62
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.68; acc: 0.84
Batch: 500; loss: 0.63; acc: 0.8
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.5; acc: 0.8
Batch: 560; loss: 0.75; acc: 0.75
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 0.54; acc: 0.77
Batch: 620; loss: 0.58; acc: 0.83
Batch: 640; loss: 0.77; acc: 0.78
Batch: 660; loss: 0.83; acc: 0.8
Batch: 680; loss: 0.84; acc: 0.77
Batch: 700; loss: 0.66; acc: 0.77
Batch: 720; loss: 1.0; acc: 0.66
Batch: 740; loss: 0.47; acc: 0.83
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.72; acc: 0.72
Train Epoch over. train_loss: 0.65; train_accuracy: 0.79 

Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 1.27; acc: 0.64
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.6; acc: 0.78
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 1.08; acc: 0.72
Batch: 140; loss: 0.45; acc: 0.84
Val Epoch over. val_loss: 0.7712970546856048; val_accuracy: 0.7584593949044586 

The current subspace-distance is: 3.8195586967049167e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.75
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.83; acc: 0.72
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.68; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.72
Batch: 120; loss: 0.88; acc: 0.73
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.67; acc: 0.81
Batch: 180; loss: 0.57; acc: 0.81
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.53; acc: 0.84
Batch: 240; loss: 0.64; acc: 0.78
Batch: 260; loss: 0.62; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.77; acc: 0.77
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.54; acc: 0.78
Batch: 380; loss: 0.48; acc: 0.91
Batch: 400; loss: 0.63; acc: 0.83
Batch: 420; loss: 0.85; acc: 0.84
Batch: 440; loss: 0.7; acc: 0.83
Batch: 460; loss: 0.57; acc: 0.83
Batch: 480; loss: 0.69; acc: 0.72
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.53; acc: 0.88
Batch: 540; loss: 0.92; acc: 0.69
Batch: 560; loss: 0.84; acc: 0.81
Batch: 580; loss: 0.9; acc: 0.72
Batch: 600; loss: 0.53; acc: 0.83
Batch: 620; loss: 0.7; acc: 0.77
Batch: 640; loss: 0.76; acc: 0.77
Batch: 660; loss: 0.66; acc: 0.78
Batch: 680; loss: 0.62; acc: 0.78
Batch: 700; loss: 0.67; acc: 0.77
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.73; acc: 0.77
Batch: 760; loss: 0.66; acc: 0.83
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.62; train_accuracy: 0.81 

Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.77; acc: 0.69
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.9; acc: 0.69
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.5631904724487073; val_accuracy: 0.8229498407643312 

The current subspace-distance is: 4.176617585471831e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.81
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.44; acc: 0.83
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.61; acc: 0.84
Batch: 160; loss: 0.57; acc: 0.84
Batch: 180; loss: 0.82; acc: 0.75
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.67; acc: 0.77
Batch: 240; loss: 0.75; acc: 0.73
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.53; acc: 0.84
Batch: 300; loss: 0.59; acc: 0.83
Batch: 320; loss: 0.69; acc: 0.81
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.73; acc: 0.75
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.78; acc: 0.73
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.82; acc: 0.77
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.88; acc: 0.73
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.64; acc: 0.77
Batch: 560; loss: 0.63; acc: 0.77
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.44; acc: 0.84
Batch: 620; loss: 0.62; acc: 0.8
Batch: 640; loss: 0.51; acc: 0.8
Batch: 660; loss: 0.62; acc: 0.78
Batch: 680; loss: 0.72; acc: 0.78
Batch: 700; loss: 0.72; acc: 0.8
Batch: 720; loss: 0.5; acc: 0.84
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.62; acc: 0.86
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.89
Val Epoch over. val_loss: 0.5192356562348688; val_accuracy: 0.8434514331210191 

The current subspace-distance is: 4.54670334875118e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.08; acc: 0.66
Batch: 20; loss: 0.83; acc: 0.72
Batch: 40; loss: 0.54; acc: 0.86
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.77
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.77; acc: 0.72
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.61; acc: 0.78
Batch: 240; loss: 0.52; acc: 0.8
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.57; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.81
Batch: 320; loss: 0.59; acc: 0.8
Batch: 340; loss: 0.61; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.81
Batch: 380; loss: 0.78; acc: 0.77
Batch: 400; loss: 0.66; acc: 0.77
Batch: 420; loss: 0.61; acc: 0.75
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.78; acc: 0.73
Batch: 480; loss: 0.47; acc: 0.84
Batch: 500; loss: 0.69; acc: 0.77
Batch: 520; loss: 0.63; acc: 0.78
Batch: 540; loss: 0.87; acc: 0.77
Batch: 560; loss: 0.59; acc: 0.73
Batch: 580; loss: 0.52; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.84
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.52; acc: 0.8
Batch: 660; loss: 0.62; acc: 0.86
Batch: 680; loss: 0.59; acc: 0.89
Batch: 700; loss: 0.54; acc: 0.75
Batch: 720; loss: 0.44; acc: 0.83
Batch: 740; loss: 0.48; acc: 0.83
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.74; acc: 0.78
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

Batch: 0; loss: 0.65; acc: 0.75
Batch: 20; loss: 0.85; acc: 0.7
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.51; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.84; acc: 0.7
Batch: 140; loss: 0.44; acc: 0.83
Val Epoch over. val_loss: 0.7800804456328131; val_accuracy: 0.7573646496815286 

The current subspace-distance is: 4.807053483091295e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.01; acc: 0.73
Batch: 20; loss: 0.74; acc: 0.8
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.57; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.75; acc: 0.8
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.81
Batch: 200; loss: 0.66; acc: 0.75
Batch: 220; loss: 0.54; acc: 0.86
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.44; acc: 0.83
Batch: 280; loss: 0.63; acc: 0.81
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.73; acc: 0.69
Batch: 340; loss: 0.75; acc: 0.81
Batch: 360; loss: 0.5; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.67; acc: 0.8
Batch: 420; loss: 0.94; acc: 0.8
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.59; acc: 0.8
Batch: 480; loss: 0.47; acc: 0.83
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.76; acc: 0.77
Batch: 540; loss: 0.83; acc: 0.78
Batch: 560; loss: 0.76; acc: 0.75
Batch: 580; loss: 0.57; acc: 0.8
Batch: 600; loss: 0.43; acc: 0.83
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.6; acc: 0.8
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.68; acc: 0.8
Batch: 740; loss: 0.57; acc: 0.81
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.55; acc: 0.88
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.43; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.77
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.5169748910673105; val_accuracy: 0.8407643312101911 

The current subspace-distance is: 5.1468821766320616e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.86; acc: 0.67
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.66; acc: 0.81
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.88; acc: 0.7
Batch: 200; loss: 0.57; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.55; acc: 0.83
Batch: 320; loss: 0.82; acc: 0.84
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.78; acc: 0.81
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.57; acc: 0.83
Batch: 420; loss: 0.51; acc: 0.81
Batch: 440; loss: 0.77; acc: 0.75
Batch: 460; loss: 0.33; acc: 0.94
Batch: 480; loss: 0.83; acc: 0.75
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 1.01; acc: 0.7
Batch: 540; loss: 0.48; acc: 0.78
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.91; acc: 0.7
Batch: 600; loss: 0.5; acc: 0.83
Batch: 620; loss: 0.53; acc: 0.86
Batch: 640; loss: 0.54; acc: 0.81
Batch: 660; loss: 0.7; acc: 0.83
Batch: 680; loss: 0.84; acc: 0.77
Batch: 700; loss: 0.51; acc: 0.81
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.8; acc: 0.78
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.82; acc: 0.7
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.67; acc: 0.77
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.86; acc: 0.72
Batch: 140; loss: 0.38; acc: 0.81
Val Epoch over. val_loss: 0.6074257979916918; val_accuracy: 0.8124004777070064 

The current subspace-distance is: 5.417860666057095e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.93; acc: 0.75
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.67; acc: 0.86
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.83
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.8
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.47; acc: 0.91
Batch: 280; loss: 0.64; acc: 0.86
Batch: 300; loss: 0.66; acc: 0.86
Batch: 320; loss: 0.72; acc: 0.8
Batch: 340; loss: 0.68; acc: 0.77
Batch: 360; loss: 0.52; acc: 0.86
Batch: 380; loss: 0.5; acc: 0.86
Batch: 400; loss: 0.6; acc: 0.81
Batch: 420; loss: 0.99; acc: 0.67
Batch: 440; loss: 0.53; acc: 0.81
Batch: 460; loss: 0.56; acc: 0.83
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.58; acc: 0.78
Batch: 600; loss: 0.56; acc: 0.84
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.63; acc: 0.83
Batch: 680; loss: 0.57; acc: 0.84
Batch: 700; loss: 0.83; acc: 0.75
Batch: 720; loss: 0.69; acc: 0.81
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.61; acc: 0.73
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.72
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.507459648143334; val_accuracy: 0.8440485668789809 

The current subspace-distance is: 5.6499484344385564e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.52; acc: 0.86
Batch: 100; loss: 0.6; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.49; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.64; acc: 0.81
Batch: 220; loss: 0.66; acc: 0.8
Batch: 240; loss: 0.66; acc: 0.75
Batch: 260; loss: 0.57; acc: 0.84
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.62; acc: 0.81
Batch: 340; loss: 0.6; acc: 0.81
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.67; acc: 0.83
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.62; acc: 0.81
Batch: 440; loss: 0.41; acc: 0.84
Batch: 460; loss: 0.66; acc: 0.86
Batch: 480; loss: 0.55; acc: 0.86
Batch: 500; loss: 0.66; acc: 0.84
Batch: 520; loss: 0.65; acc: 0.78
Batch: 540; loss: 0.55; acc: 0.84
Batch: 560; loss: 0.95; acc: 0.73
Batch: 580; loss: 0.75; acc: 0.8
Batch: 600; loss: 0.42; acc: 0.83
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.58; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.5; acc: 0.83
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.66; acc: 0.73
Batch: 760; loss: 0.58; acc: 0.81
Batch: 780; loss: 0.52; acc: 0.86
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.31; acc: 0.86
Val Epoch over. val_loss: 0.5106836891003476; val_accuracy: 0.8407643312101911 

The current subspace-distance is: 6.065192792448215e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.66; acc: 0.84
Batch: 20; loss: 0.77; acc: 0.81
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.51; acc: 0.78
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.57; acc: 0.86
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.91
Batch: 280; loss: 0.67; acc: 0.75
Batch: 300; loss: 0.37; acc: 0.86
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.49; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.65; acc: 0.78
Batch: 480; loss: 0.61; acc: 0.77
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.67; acc: 0.78
Batch: 540; loss: 0.59; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.48; acc: 0.81
Batch: 640; loss: 0.7; acc: 0.78
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.55; acc: 0.83
Batch: 700; loss: 0.33; acc: 0.94
Batch: 720; loss: 0.68; acc: 0.8
Batch: 740; loss: 0.65; acc: 0.8
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.71; acc: 0.81
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.51; acc: 0.8
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.32; acc: 0.89
Val Epoch over. val_loss: 0.5276590003898949; val_accuracy: 0.839968152866242 

The current subspace-distance is: 6.39629943179898e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.68; acc: 0.83
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.75
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.89; acc: 0.77
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.58; acc: 0.78
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.65; acc: 0.81
Batch: 260; loss: 0.47; acc: 0.81
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.64; acc: 0.84
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.57; acc: 0.77
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.55; acc: 0.86
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.75; acc: 0.78
Batch: 440; loss: 0.44; acc: 0.81
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.47; acc: 0.83
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.69; acc: 0.77
Batch: 540; loss: 0.46; acc: 0.83
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.56; acc: 0.81
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.59; acc: 0.84
Batch: 660; loss: 0.58; acc: 0.84
Batch: 680; loss: 0.7; acc: 0.75
Batch: 700; loss: 0.7; acc: 0.8
Batch: 720; loss: 0.53; acc: 0.81
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.55; acc: 0.78
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.3; acc: 0.86
Val Epoch over. val_loss: 0.5038718067726512; val_accuracy: 0.84484474522293 

The current subspace-distance is: 6.68689317535609e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.64; acc: 0.75
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.79; acc: 0.73
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.69; acc: 0.8
Batch: 220; loss: 0.55; acc: 0.78
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.54; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.55; acc: 0.86
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.64; acc: 0.78
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.56; acc: 0.84
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.48; acc: 0.89
Batch: 520; loss: 0.52; acc: 0.88
Batch: 540; loss: 0.5; acc: 0.81
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.62; acc: 0.81
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.67; acc: 0.81
Batch: 700; loss: 0.75; acc: 0.83
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.67; acc: 0.7
Batch: 780; loss: 0.61; acc: 0.78
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.7
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.49973928411105634; val_accuracy: 0.8487261146496815 

The current subspace-distance is: 6.891277007525787e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.59; acc: 0.8
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.54; acc: 0.78
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.61; acc: 0.78
Batch: 300; loss: 0.59; acc: 0.81
Batch: 320; loss: 0.67; acc: 0.75
Batch: 340; loss: 0.54; acc: 0.83
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.62; acc: 0.78
Batch: 460; loss: 0.87; acc: 0.77
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.63; acc: 0.83
Batch: 520; loss: 0.63; acc: 0.86
Batch: 540; loss: 0.43; acc: 0.84
Batch: 560; loss: 0.64; acc: 0.86
Batch: 580; loss: 0.67; acc: 0.78
Batch: 600; loss: 0.71; acc: 0.8
Batch: 620; loss: 0.48; acc: 0.8
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.56; acc: 0.83
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.51; acc: 0.78
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.4961424605671767; val_accuracy: 0.846437101910828 

The current subspace-distance is: 6.986773223616183e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.86
Batch: 40; loss: 0.71; acc: 0.75
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.53; acc: 0.88
Batch: 140; loss: 0.68; acc: 0.81
Batch: 160; loss: 0.55; acc: 0.8
Batch: 180; loss: 0.82; acc: 0.73
Batch: 200; loss: 0.53; acc: 0.88
Batch: 220; loss: 0.59; acc: 0.8
Batch: 240; loss: 0.72; acc: 0.81
Batch: 260; loss: 0.58; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.68; acc: 0.83
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.84
Batch: 400; loss: 0.56; acc: 0.86
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.83
Batch: 460; loss: 0.75; acc: 0.8
Batch: 480; loss: 0.45; acc: 0.81
Batch: 500; loss: 0.61; acc: 0.75
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.53; acc: 0.81
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.36; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.84
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.68; acc: 0.78
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.44; acc: 0.83
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.6; acc: 0.81
Batch: 780; loss: 0.46; acc: 0.81
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.4896409083988256; val_accuracy: 0.8522093949044586 

The current subspace-distance is: 7.283285958692431e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.69; acc: 0.78
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 0.53; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.83
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.73; acc: 0.83
Batch: 320; loss: 0.81; acc: 0.73
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.93; acc: 0.77
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.62; acc: 0.83
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.67; acc: 0.8
Batch: 560; loss: 0.59; acc: 0.78
Batch: 580; loss: 0.59; acc: 0.81
Batch: 600; loss: 0.69; acc: 0.8
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.63; acc: 0.77
Batch: 740; loss: 0.76; acc: 0.78
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.53; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.48025936220481896; val_accuracy: 0.8506170382165605 

The current subspace-distance is: 7.452225690940395e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.49; acc: 0.91
Batch: 80; loss: 0.63; acc: 0.81
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.55; acc: 0.81
Batch: 160; loss: 0.38; acc: 0.84
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.6; acc: 0.81
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.8
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.61; acc: 0.83
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.76; acc: 0.69
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.51; acc: 0.89
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.62; acc: 0.78
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.66; acc: 0.84
Batch: 580; loss: 0.65; acc: 0.8
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.6; acc: 0.84
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.59; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.47; acc: 0.84
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.27; acc: 0.88
Val Epoch over. val_loss: 0.4903503346025564; val_accuracy: 0.846437101910828 

The current subspace-distance is: 7.604670099681243e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.83
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.61; acc: 0.78
Batch: 160; loss: 0.57; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.72; acc: 0.81
Batch: 260; loss: 0.67; acc: 0.86
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.67; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.44; acc: 0.91
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.33; acc: 0.84
Batch: 400; loss: 0.53; acc: 0.83
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.72; acc: 0.84
Batch: 460; loss: 0.7; acc: 0.8
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.59; acc: 0.81
Batch: 540; loss: 0.51; acc: 0.8
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.57; acc: 0.84
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.56; acc: 0.81
Batch: 720; loss: 0.6; acc: 0.78
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.76; acc: 0.73
Batch: 780; loss: 0.67; acc: 0.72
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.48; acc: 0.8
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.79; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.5441362612946018; val_accuracy: 0.824343152866242 

The current subspace-distance is: 7.743593596387655e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.74; acc: 0.81
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.63; acc: 0.81
Batch: 160; loss: 0.58; acc: 0.81
Batch: 180; loss: 0.6; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.62; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.48; acc: 0.89
Batch: 340; loss: 0.63; acc: 0.81
Batch: 360; loss: 0.61; acc: 0.73
Batch: 380; loss: 0.67; acc: 0.78
Batch: 400; loss: 0.57; acc: 0.83
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.5; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.81
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.66; acc: 0.83
Batch: 580; loss: 0.55; acc: 0.75
Batch: 600; loss: 0.6; acc: 0.78
Batch: 620; loss: 0.36; acc: 0.84
Batch: 640; loss: 0.53; acc: 0.83
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.81
Batch: 780; loss: 0.55; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.27; acc: 0.92
Val Epoch over. val_loss: 0.48541659050306696; val_accuracy: 0.8481289808917197 

The current subspace-distance is: 8.010524470591918e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.57; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.6; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.8; acc: 0.77
Batch: 160; loss: 0.62; acc: 0.86
Batch: 180; loss: 0.46; acc: 0.78
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.62; acc: 0.78
Batch: 240; loss: 0.79; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.67; acc: 0.81
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.62; acc: 0.83
Batch: 360; loss: 0.62; acc: 0.81
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.81
Batch: 460; loss: 0.75; acc: 0.77
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.57; acc: 0.8
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.62; acc: 0.81
Batch: 580; loss: 0.6; acc: 0.84
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.52; acc: 0.86
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.61; acc: 0.81
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.78; acc: 0.8
Batch: 760; loss: 0.51; acc: 0.8
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.8
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.7
Batch: 140; loss: 0.26; acc: 0.94
Val Epoch over. val_loss: 0.48132418793667653; val_accuracy: 0.8508160828025477 

The current subspace-distance is: 8.115886157611385e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.74; acc: 0.84
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 0.58; acc: 0.77
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.72; acc: 0.8
Batch: 220; loss: 0.51; acc: 0.8
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.49; acc: 0.89
Batch: 280; loss: 0.58; acc: 0.83
Batch: 300; loss: 0.96; acc: 0.75
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.61; acc: 0.8
Batch: 380; loss: 0.5; acc: 0.81
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.52; acc: 0.88
Batch: 440; loss: 0.75; acc: 0.8
Batch: 460; loss: 0.7; acc: 0.77
Batch: 480; loss: 0.51; acc: 0.8
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.7; acc: 0.81
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.57; acc: 0.86
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.61; acc: 0.78
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.81
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.7; acc: 0.77
Batch: 740; loss: 0.63; acc: 0.77
Batch: 760; loss: 0.66; acc: 0.83
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.4731957901530205; val_accuracy: 0.8541003184713376 

The current subspace-distance is: 8.256105502368882e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.6; acc: 0.78
Batch: 180; loss: 0.66; acc: 0.75
Batch: 200; loss: 0.6; acc: 0.89
Batch: 220; loss: 0.7; acc: 0.78
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.76; acc: 0.78
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.57; acc: 0.88
Batch: 360; loss: 0.67; acc: 0.8
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.66; acc: 0.77
Batch: 420; loss: 0.53; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.55; acc: 0.83
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.54; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.54; acc: 0.83
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.57; acc: 0.8
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.73; acc: 0.7
Batch: 720; loss: 0.88; acc: 0.77
Batch: 740; loss: 0.4; acc: 0.83
Batch: 760; loss: 0.61; acc: 0.77
Batch: 780; loss: 0.6; acc: 0.8
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.4739677233585886; val_accuracy: 0.853702229299363 

The current subspace-distance is: 8.507896563969553e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.65; acc: 0.8
Batch: 160; loss: 0.54; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.81
Batch: 200; loss: 0.71; acc: 0.8
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.76; acc: 0.78
Batch: 260; loss: 0.55; acc: 0.83
Batch: 280; loss: 0.71; acc: 0.8
Batch: 300; loss: 0.52; acc: 0.88
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.96; acc: 0.75
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.7; acc: 0.8
Batch: 440; loss: 0.58; acc: 0.84
Batch: 460; loss: 0.59; acc: 0.81
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.6; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.54; acc: 0.8
Batch: 680; loss: 0.55; acc: 0.86
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.69; acc: 0.8
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 0.61; acc: 0.78
Batch: 780; loss: 0.49; acc: 0.91
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.47704370519158185; val_accuracy: 0.8532046178343949 

The current subspace-distance is: 8.600205183029175e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.61; acc: 0.81
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.81
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.35; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.58; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.78
Batch: 240; loss: 0.7; acc: 0.83
Batch: 260; loss: 0.81; acc: 0.73
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.71; acc: 0.83
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.62; acc: 0.84
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 0.59; acc: 0.84
Batch: 460; loss: 0.39; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.55; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.8
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.58; acc: 0.84
Batch: 740; loss: 0.84; acc: 0.77
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4721504762578922; val_accuracy: 0.8553941082802548 

The current subspace-distance is: 8.759502088651061e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.51; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.84
Batch: 200; loss: 0.61; acc: 0.77
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.78; acc: 0.77
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.62; acc: 0.77
Batch: 340; loss: 0.51; acc: 0.81
Batch: 360; loss: 0.5; acc: 0.8
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.77; acc: 0.8
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.51; acc: 0.8
Batch: 460; loss: 1.05; acc: 0.78
Batch: 480; loss: 0.69; acc: 0.78
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.65; acc: 0.86
Batch: 540; loss: 0.41; acc: 0.83
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.6; acc: 0.78
Batch: 600; loss: 0.52; acc: 0.86
Batch: 620; loss: 0.52; acc: 0.83
Batch: 640; loss: 0.76; acc: 0.77
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.65; acc: 0.8
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.54; acc: 0.83
Batch: 780; loss: 0.23; acc: 0.97
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.47196179286689516; val_accuracy: 0.8545979299363057 

The current subspace-distance is: 8.874720515450463e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.79; acc: 0.78
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.52; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.5; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.8
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.84
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.68; acc: 0.8
Batch: 280; loss: 0.69; acc: 0.84
Batch: 300; loss: 0.51; acc: 0.8
Batch: 320; loss: 1.09; acc: 0.7
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.62; acc: 0.83
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.7; acc: 0.8
Batch: 500; loss: 0.55; acc: 0.84
Batch: 520; loss: 0.42; acc: 0.81
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.79; acc: 0.7
Batch: 580; loss: 0.72; acc: 0.83
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.84
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.61; acc: 0.84
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.4776459143135198; val_accuracy: 0.8516122611464968 

The current subspace-distance is: 9.119308379013091e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.74; acc: 0.81
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.66; acc: 0.81
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.73; acc: 0.83
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.51; acc: 0.78
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.49; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.59; acc: 0.86
Batch: 440; loss: 0.49; acc: 0.81
Batch: 460; loss: 0.4; acc: 0.83
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.58; acc: 0.8
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.69; acc: 0.75
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.6; acc: 0.77
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.66; acc: 0.77
Batch: 780; loss: 0.71; acc: 0.77
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.4771281904096057; val_accuracy: 0.8532046178343949 

The current subspace-distance is: 9.315412899013609e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.84; acc: 0.75
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.62; acc: 0.77
Batch: 140; loss: 0.54; acc: 0.8
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.7; acc: 0.86
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.54; acc: 0.81
Batch: 300; loss: 0.64; acc: 0.8
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.69; acc: 0.77
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.49; acc: 0.83
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.62; acc: 0.83
Batch: 580; loss: 0.64; acc: 0.83
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.74; acc: 0.78
Batch: 640; loss: 0.67; acc: 0.81
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.59; acc: 0.81
Batch: 740; loss: 0.51; acc: 0.89
Batch: 760; loss: 0.77; acc: 0.81
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4793486907413811; val_accuracy: 0.8492237261146497 

The current subspace-distance is: 9.506961214356124e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.74; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.71; acc: 0.83
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.91
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.52; acc: 0.83
Batch: 260; loss: 0.81; acc: 0.75
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.65; acc: 0.8
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.61; acc: 0.78
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.55; acc: 0.8
Batch: 440; loss: 0.57; acc: 0.8
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.86
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.57; acc: 0.8
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.8; acc: 0.78
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.56; acc: 0.84
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.62; acc: 0.75
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.73; acc: 0.8
Batch: 780; loss: 0.48; acc: 0.8
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.47002995166049644; val_accuracy: 0.8544984076433121 

The current subspace-distance is: 9.634286107029766e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.91
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.64; acc: 0.78
Batch: 100; loss: 0.51; acc: 0.81
Batch: 120; loss: 0.63; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.84
Batch: 160; loss: 0.53; acc: 0.86
Batch: 180; loss: 0.6; acc: 0.81
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.58; acc: 0.84
Batch: 280; loss: 0.45; acc: 0.8
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.53; acc: 0.81
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.53; acc: 0.89
Batch: 380; loss: 0.68; acc: 0.84
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.69; acc: 0.83
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.76; acc: 0.78
Batch: 500; loss: 0.59; acc: 0.8
Batch: 520; loss: 0.65; acc: 0.8
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.81
Batch: 620; loss: 0.6; acc: 0.81
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.72; acc: 0.83
Batch: 720; loss: 0.67; acc: 0.81
Batch: 740; loss: 0.41; acc: 0.83
Batch: 760; loss: 0.51; acc: 0.84
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.4701120200430512; val_accuracy: 0.8541998407643312 

The current subspace-distance is: 9.777913510333747e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.57; acc: 0.78
Batch: 20; loss: 0.71; acc: 0.8
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.55; acc: 0.81
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 1.08; acc: 0.75
Batch: 220; loss: 0.62; acc: 0.8
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.43; acc: 0.83
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.89; acc: 0.7
Batch: 380; loss: 0.45; acc: 0.83
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.5; acc: 0.81
Batch: 440; loss: 0.68; acc: 0.81
Batch: 460; loss: 0.59; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.96; acc: 0.77
Batch: 540; loss: 0.64; acc: 0.88
Batch: 560; loss: 0.7; acc: 0.75
Batch: 580; loss: 0.7; acc: 0.81
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.63; acc: 0.83
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.58; acc: 0.84
Batch: 700; loss: 0.52; acc: 0.83
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 0.41; acc: 0.91
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4723800348628099; val_accuracy: 0.8519108280254777 

The current subspace-distance is: 0.00010019644832937047 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.77; acc: 0.72
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.72; acc: 0.81
Batch: 60; loss: 0.75; acc: 0.72
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.77
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.9; acc: 0.77
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.52; acc: 0.81
Batch: 220; loss: 0.58; acc: 0.8
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.67; acc: 0.8
Batch: 280; loss: 1.0; acc: 0.72
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.81
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.69; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.48; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.63; acc: 0.83
Batch: 500; loss: 0.56; acc: 0.81
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.63; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.77
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.77; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.65; acc: 0.81
Batch: 740; loss: 0.51; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.57; acc: 0.8
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.47157903063069484; val_accuracy: 0.8533041401273885 

The current subspace-distance is: 0.00010155759810004383 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.64; acc: 0.84
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.83
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.78; acc: 0.7
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.83
Batch: 220; loss: 0.61; acc: 0.8
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.55; acc: 0.8
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.56; acc: 0.8
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.68; acc: 0.81
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.45; acc: 0.91
Batch: 540; loss: 0.74; acc: 0.81
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.53; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.78
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.78; acc: 0.75
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.6; acc: 0.78
Batch: 720; loss: 0.84; acc: 0.78
Batch: 740; loss: 0.55; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.47120378489137454; val_accuracy: 0.8524084394904459 

The current subspace-distance is: 0.00010201623081229627 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.95; acc: 0.7
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.63; acc: 0.81
Batch: 180; loss: 0.72; acc: 0.72
Batch: 200; loss: 0.49; acc: 0.86
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.65; acc: 0.81
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.68; acc: 0.78
Batch: 360; loss: 0.6; acc: 0.81
Batch: 380; loss: 0.52; acc: 0.83
Batch: 400; loss: 0.65; acc: 0.77
Batch: 420; loss: 0.55; acc: 0.81
Batch: 440; loss: 0.77; acc: 0.77
Batch: 460; loss: 0.8; acc: 0.78
Batch: 480; loss: 0.44; acc: 0.89
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.66; acc: 0.8
Batch: 540; loss: 0.5; acc: 0.78
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.81
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.65; acc: 0.81
Batch: 720; loss: 0.35; acc: 0.94
Batch: 740; loss: 0.75; acc: 0.75
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.46907931585220775; val_accuracy: 0.855593152866242 

The current subspace-distance is: 0.00010331957309972495 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.55; acc: 0.84
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.81
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.5; acc: 0.89
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.63; acc: 0.86
Batch: 220; loss: 0.61; acc: 0.84
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.55; acc: 0.81
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.82; acc: 0.78
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.56; acc: 0.81
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.81
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.59; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.72; acc: 0.78
Batch: 540; loss: 0.74; acc: 0.83
Batch: 560; loss: 0.64; acc: 0.77
Batch: 580; loss: 0.53; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.73; acc: 0.78
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.65; acc: 0.78
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.73
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4733175508155944; val_accuracy: 0.8527070063694268 

The current subspace-distance is: 0.00010628077143337578 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.68; acc: 0.78
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.71; acc: 0.8
Batch: 160; loss: 0.42; acc: 0.83
Batch: 180; loss: 0.55; acc: 0.8
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.51; acc: 0.83
Batch: 260; loss: 0.47; acc: 0.81
Batch: 280; loss: 0.89; acc: 0.78
Batch: 300; loss: 0.84; acc: 0.75
Batch: 320; loss: 0.56; acc: 0.81
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.59; acc: 0.8
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.71; acc: 0.83
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.57; acc: 0.8
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.56; acc: 0.81
Batch: 560; loss: 0.59; acc: 0.77
Batch: 580; loss: 0.61; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.69; acc: 0.8
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.73
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.47161999297369817; val_accuracy: 0.8536027070063694 

The current subspace-distance is: 0.00010684437438612804 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.89; acc: 0.78
Batch: 100; loss: 0.79; acc: 0.72
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.69; acc: 0.78
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.47; acc: 0.8
Batch: 220; loss: 0.46; acc: 0.83
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.83
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.67; acc: 0.8
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.66; acc: 0.78
Batch: 440; loss: 0.53; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.75; acc: 0.78
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.55; acc: 0.8
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.81
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.67; acc: 0.81
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.53; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.61; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.4703652146420661; val_accuracy: 0.854796974522293 

The current subspace-distance is: 0.00010790899250423536 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.6; acc: 0.78
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.56; acc: 0.78
Batch: 80; loss: 0.72; acc: 0.75
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.54; acc: 0.83
Batch: 200; loss: 0.42; acc: 0.83
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.77; acc: 0.77
Batch: 280; loss: 0.7; acc: 0.81
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.61; acc: 0.83
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.61; acc: 0.83
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.73; acc: 0.75
Batch: 420; loss: 0.56; acc: 0.84
Batch: 440; loss: 0.78; acc: 0.75
Batch: 460; loss: 0.44; acc: 0.8
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.65; acc: 0.86
Batch: 580; loss: 0.68; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.26; acc: 0.95
Batch: 680; loss: 0.66; acc: 0.78
Batch: 700; loss: 0.52; acc: 0.81
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.81; acc: 0.64
Batch: 760; loss: 0.61; acc: 0.81
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.47118910297656513; val_accuracy: 0.8550955414012739 

The current subspace-distance is: 0.00010944464156636968 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.56; acc: 0.84
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.55; acc: 0.8
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.55; acc: 0.8
Batch: 220; loss: 0.74; acc: 0.8
Batch: 240; loss: 0.75; acc: 0.8
Batch: 260; loss: 0.36; acc: 0.84
Batch: 280; loss: 0.49; acc: 0.81
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.48; acc: 0.8
Batch: 360; loss: 0.69; acc: 0.84
Batch: 380; loss: 0.38; acc: 0.84
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.76; acc: 0.78
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.63; acc: 0.72
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.58; acc: 0.81
Batch: 600; loss: 0.49; acc: 0.91
Batch: 620; loss: 0.6; acc: 0.77
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.94
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.51; acc: 0.84
Batch: 740; loss: 0.66; acc: 0.78
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4689340630819084; val_accuracy: 0.8551950636942676 

The current subspace-distance is: 0.00011091361375292763 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.64; acc: 0.77
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 0.31; acc: 0.86
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.52; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.55; acc: 0.8
Batch: 240; loss: 0.61; acc: 0.86
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.47; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.81
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.54; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.81
Batch: 400; loss: 0.5; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.88
Batch: 480; loss: 0.89; acc: 0.77
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.75; acc: 0.73
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.39; acc: 0.83
Batch: 620; loss: 0.64; acc: 0.78
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.59; acc: 0.84
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4693764466199146; val_accuracy: 0.8538017515923567 

The current subspace-distance is: 0.00011210054799448699 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.59; acc: 0.78
Batch: 160; loss: 0.55; acc: 0.81
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.78; acc: 0.73
Batch: 220; loss: 0.64; acc: 0.78
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.56; acc: 0.78
Batch: 280; loss: 0.48; acc: 0.83
Batch: 300; loss: 0.42; acc: 0.8
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.5; acc: 0.83
Batch: 360; loss: 0.7; acc: 0.83
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.71; acc: 0.8
Batch: 440; loss: 0.56; acc: 0.8
Batch: 460; loss: 0.59; acc: 0.88
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.7; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.46; acc: 0.81
Batch: 660; loss: 0.33; acc: 0.84
Batch: 680; loss: 0.63; acc: 0.81
Batch: 700; loss: 0.56; acc: 0.81
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.64; acc: 0.77
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.469708713376598; val_accuracy: 0.8536027070063694 

The current subspace-distance is: 0.00011478579108370468 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.91
Batch: 20; loss: 0.68; acc: 0.73
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.57; acc: 0.78
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.68; acc: 0.84
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.68; acc: 0.77
Batch: 260; loss: 0.64; acc: 0.78
Batch: 280; loss: 0.5; acc: 0.86
Batch: 300; loss: 0.44; acc: 0.89
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.78
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.71; acc: 0.78
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.51; acc: 0.8
Batch: 460; loss: 0.61; acc: 0.75
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.64; acc: 0.75
Batch: 560; loss: 0.62; acc: 0.77
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.73; acc: 0.8
Batch: 620; loss: 0.62; acc: 0.8
Batch: 640; loss: 0.69; acc: 0.78
Batch: 660; loss: 0.7; acc: 0.8
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.73; acc: 0.81
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.77; acc: 0.75
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.46928207429161495; val_accuracy: 0.8550955414012739 

The current subspace-distance is: 0.00011574992095120251 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.64; acc: 0.77
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.92
Batch: 220; loss: 0.67; acc: 0.77
Batch: 240; loss: 0.62; acc: 0.86
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.87; acc: 0.78
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.44; acc: 0.81
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.47; acc: 0.84
Batch: 420; loss: 0.46; acc: 0.86
Batch: 440; loss: 0.6; acc: 0.81
Batch: 460; loss: 0.8; acc: 0.77
Batch: 480; loss: 0.51; acc: 0.88
Batch: 500; loss: 0.81; acc: 0.75
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.57; acc: 0.81
Batch: 600; loss: 0.46; acc: 0.83
Batch: 620; loss: 0.33; acc: 0.84
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.86
Batch: 680; loss: 0.64; acc: 0.8
Batch: 700; loss: 0.77; acc: 0.77
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.54; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.81
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.469068577952066; val_accuracy: 0.8549960191082803 

The current subspace-distance is: 0.00011681218165904284 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.78
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.33; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.75
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.5; acc: 0.83
Batch: 160; loss: 0.64; acc: 0.8
Batch: 180; loss: 0.52; acc: 0.86
Batch: 200; loss: 0.73; acc: 0.75
Batch: 220; loss: 0.68; acc: 0.83
Batch: 240; loss: 0.53; acc: 0.84
Batch: 260; loss: 0.59; acc: 0.86
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.8; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.43; acc: 0.81
Batch: 420; loss: 0.66; acc: 0.81
Batch: 440; loss: 0.69; acc: 0.81
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.63; acc: 0.81
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.58; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.83
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.86; acc: 0.77
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.55; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.88
Batch: 680; loss: 0.64; acc: 0.81
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.66; acc: 0.8
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.69; acc: 0.81
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.468608650954286; val_accuracy: 0.8554936305732485 

The current subspace-distance is: 0.00011806652037193999 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.69; acc: 0.77
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.56; acc: 0.86
Batch: 220; loss: 0.58; acc: 0.86
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.5; acc: 0.78
Batch: 320; loss: 0.58; acc: 0.83
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.44; acc: 0.84
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.53; acc: 0.8
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.75; acc: 0.73
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.61; acc: 0.88
Batch: 560; loss: 0.75; acc: 0.73
Batch: 580; loss: 0.52; acc: 0.78
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.83
Batch: 680; loss: 0.7; acc: 0.75
Batch: 700; loss: 0.57; acc: 0.84
Batch: 720; loss: 0.61; acc: 0.78
Batch: 740; loss: 0.46; acc: 0.84
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.46878395618716623; val_accuracy: 0.854796974522293 

The current subspace-distance is: 0.00011852127499878407 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.82; acc: 0.77
Batch: 160; loss: 0.68; acc: 0.78
Batch: 180; loss: 0.84; acc: 0.8
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.81; acc: 0.73
Batch: 240; loss: 0.52; acc: 0.84
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.45; acc: 0.89
Batch: 340; loss: 0.74; acc: 0.77
Batch: 360; loss: 0.58; acc: 0.81
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.7; acc: 0.81
Batch: 440; loss: 0.44; acc: 0.83
Batch: 460; loss: 0.74; acc: 0.78
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.83
Batch: 520; loss: 0.65; acc: 0.77
Batch: 540; loss: 0.83; acc: 0.77
Batch: 560; loss: 0.55; acc: 0.81
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.57; acc: 0.83
Batch: 620; loss: 0.55; acc: 0.81
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.79; acc: 0.75
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.65; acc: 0.78
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.54; acc: 0.81
Batch: 760; loss: 0.55; acc: 0.83
Batch: 780; loss: 0.25; acc: 0.98
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.46885637573565647; val_accuracy: 0.8556926751592356 

The current subspace-distance is: 0.00011929164611501619 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.61; acc: 0.78
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.74; acc: 0.8
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.73; acc: 0.8
Batch: 200; loss: 0.43; acc: 0.8
Batch: 220; loss: 0.72; acc: 0.7
Batch: 240; loss: 0.46; acc: 0.81
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.68; acc: 0.78
Batch: 340; loss: 0.45; acc: 0.91
Batch: 360; loss: 0.45; acc: 0.84
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.54; acc: 0.78
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.6; acc: 0.86
Batch: 480; loss: 0.46; acc: 0.83
Batch: 500; loss: 0.56; acc: 0.83
Batch: 520; loss: 0.59; acc: 0.86
Batch: 540; loss: 0.56; acc: 0.75
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.72; acc: 0.8
Batch: 600; loss: 0.6; acc: 0.77
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.83
Batch: 680; loss: 0.68; acc: 0.81
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.54; acc: 0.81
Batch: 740; loss: 0.72; acc: 0.81
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.46825596153925936; val_accuracy: 0.8562898089171974 

The current subspace-distance is: 0.00011974353401456028 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.62; acc: 0.81
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.67; acc: 0.83
Batch: 340; loss: 0.84; acc: 0.75
Batch: 360; loss: 0.52; acc: 0.8
Batch: 380; loss: 0.55; acc: 0.8
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.57; acc: 0.84
Batch: 440; loss: 0.28; acc: 0.89
Batch: 460; loss: 0.56; acc: 0.78
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.67; acc: 0.88
Batch: 520; loss: 0.56; acc: 0.81
Batch: 540; loss: 0.56; acc: 0.81
Batch: 560; loss: 0.5; acc: 0.81
Batch: 580; loss: 0.37; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.89
Batch: 620; loss: 0.6; acc: 0.81
Batch: 640; loss: 0.65; acc: 0.77
Batch: 660; loss: 0.53; acc: 0.8
Batch: 680; loss: 0.35; acc: 0.84
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.95
Batch: 780; loss: 0.68; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.46851832253538117; val_accuracy: 0.855593152866242 

The current subspace-distance is: 0.00012152887211414054 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_125_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 31568
elements in E: 6663900
fraction nonzero: 0.004737165923858401
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.28; acc: 0.09
Batch: 180; loss: 2.31; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.06
Batch: 220; loss: 2.28; acc: 0.16
Batch: 240; loss: 2.28; acc: 0.11
Batch: 260; loss: 2.27; acc: 0.12
Batch: 280; loss: 2.28; acc: 0.11
Batch: 300; loss: 2.25; acc: 0.22
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.26; acc: 0.19
Batch: 360; loss: 2.24; acc: 0.19
Batch: 380; loss: 2.25; acc: 0.16
Batch: 400; loss: 2.25; acc: 0.12
Batch: 420; loss: 2.23; acc: 0.22
Batch: 440; loss: 2.22; acc: 0.28
Batch: 460; loss: 2.21; acc: 0.2
Batch: 480; loss: 2.2; acc: 0.31
Batch: 500; loss: 2.21; acc: 0.23
Batch: 520; loss: 2.17; acc: 0.34
Batch: 540; loss: 2.08; acc: 0.42
Batch: 560; loss: 2.07; acc: 0.44
Batch: 580; loss: 2.03; acc: 0.36
Batch: 600; loss: 1.92; acc: 0.39
Batch: 620; loss: 1.79; acc: 0.5
Batch: 640; loss: 1.71; acc: 0.53
Batch: 660; loss: 1.52; acc: 0.53
Batch: 680; loss: 1.44; acc: 0.55
Batch: 700; loss: 1.41; acc: 0.53
Batch: 720; loss: 1.07; acc: 0.75
Batch: 740; loss: 1.14; acc: 0.62
Batch: 760; loss: 0.95; acc: 0.67
Batch: 780; loss: 0.83; acc: 0.7
Train Epoch over. train_loss: 2.03; train_accuracy: 0.27 

Batch: 0; loss: 1.26; acc: 0.52
Batch: 20; loss: 1.22; acc: 0.58
Batch: 40; loss: 0.88; acc: 0.67
Batch: 60; loss: 1.16; acc: 0.64
Batch: 80; loss: 0.94; acc: 0.64
Batch: 100; loss: 1.2; acc: 0.62
Batch: 120; loss: 1.11; acc: 0.53
Batch: 140; loss: 0.93; acc: 0.64
Val Epoch over. val_loss: 1.1402197635857163; val_accuracy: 0.6134554140127388 

The current subspace-distance is: 8.910090400604531e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.15; acc: 0.58
Batch: 20; loss: 0.88; acc: 0.67
Batch: 40; loss: 1.2; acc: 0.58
Batch: 60; loss: 0.8; acc: 0.69
Batch: 80; loss: 1.04; acc: 0.7
Batch: 100; loss: 0.78; acc: 0.7
Batch: 120; loss: 0.92; acc: 0.67
Batch: 140; loss: 1.07; acc: 0.64
Batch: 160; loss: 1.02; acc: 0.64
Batch: 180; loss: 0.98; acc: 0.67
Batch: 200; loss: 1.06; acc: 0.69
Batch: 220; loss: 0.86; acc: 0.7
Batch: 240; loss: 1.06; acc: 0.7
Batch: 260; loss: 1.07; acc: 0.67
Batch: 280; loss: 0.72; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.73
Batch: 320; loss: 0.77; acc: 0.77
Batch: 340; loss: 0.88; acc: 0.73
Batch: 360; loss: 1.04; acc: 0.67
Batch: 380; loss: 0.88; acc: 0.66
Batch: 400; loss: 0.73; acc: 0.78
Batch: 420; loss: 0.62; acc: 0.78
Batch: 440; loss: 0.74; acc: 0.8
Batch: 460; loss: 0.95; acc: 0.69
Batch: 480; loss: 0.93; acc: 0.73
Batch: 500; loss: 1.0; acc: 0.67
Batch: 520; loss: 0.72; acc: 0.7
Batch: 540; loss: 0.78; acc: 0.72
Batch: 560; loss: 0.85; acc: 0.78
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.77; acc: 0.75
Batch: 620; loss: 0.96; acc: 0.75
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.76; acc: 0.75
Batch: 700; loss: 0.78; acc: 0.72
Batch: 720; loss: 0.92; acc: 0.66
Batch: 740; loss: 0.82; acc: 0.73
Batch: 760; loss: 0.93; acc: 0.69
Batch: 780; loss: 0.71; acc: 0.75
Train Epoch over. train_loss: 0.8; train_accuracy: 0.74 

Batch: 0; loss: 1.07; acc: 0.66
Batch: 20; loss: 0.92; acc: 0.66
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 1.15; acc: 0.61
Batch: 120; loss: 1.16; acc: 0.61
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7586306994128379; val_accuracy: 0.7576632165605095 

The current subspace-distance is: 1.8565669961390086e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.69
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 0.6; acc: 0.77
Batch: 60; loss: 0.69; acc: 0.75
Batch: 80; loss: 0.81; acc: 0.73
Batch: 100; loss: 0.74; acc: 0.72
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.6; acc: 0.78
Batch: 160; loss: 0.64; acc: 0.81
Batch: 180; loss: 0.64; acc: 0.84
Batch: 200; loss: 0.57; acc: 0.83
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.55; acc: 0.75
Batch: 260; loss: 0.71; acc: 0.75
Batch: 280; loss: 0.52; acc: 0.8
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.58; acc: 0.81
Batch: 340; loss: 0.68; acc: 0.73
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.69; acc: 0.78
Batch: 400; loss: 0.53; acc: 0.8
Batch: 420; loss: 0.65; acc: 0.7
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.85; acc: 0.7
Batch: 500; loss: 0.66; acc: 0.77
Batch: 520; loss: 0.57; acc: 0.8
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.72; acc: 0.75
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.63; acc: 0.78
Batch: 620; loss: 0.68; acc: 0.73
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.93; acc: 0.73
Batch: 680; loss: 0.59; acc: 0.78
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.7; acc: 0.75
Batch: 740; loss: 0.88; acc: 0.75
Batch: 760; loss: 0.74; acc: 0.8
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.66; train_accuracy: 0.78 

Batch: 0; loss: 0.9; acc: 0.75
Batch: 20; loss: 0.76; acc: 0.73
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.94
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.44; acc: 0.83
Val Epoch over. val_loss: 0.6526488063821367; val_accuracy: 0.7849323248407644 

The current subspace-distance is: 2.7030760975321755e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.78
Batch: 20; loss: 0.66; acc: 0.8
Batch: 40; loss: 0.41; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.77; acc: 0.75
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.54; acc: 0.75
Batch: 180; loss: 0.54; acc: 0.84
Batch: 200; loss: 0.82; acc: 0.75
Batch: 220; loss: 0.59; acc: 0.84
Batch: 240; loss: 0.7; acc: 0.75
Batch: 260; loss: 0.59; acc: 0.75
Batch: 280; loss: 1.05; acc: 0.78
Batch: 300; loss: 0.68; acc: 0.83
Batch: 320; loss: 0.69; acc: 0.8
Batch: 340; loss: 0.77; acc: 0.77
Batch: 360; loss: 0.53; acc: 0.8
Batch: 380; loss: 0.67; acc: 0.8
Batch: 400; loss: 0.66; acc: 0.83
Batch: 420; loss: 0.56; acc: 0.75
Batch: 440; loss: 0.54; acc: 0.81
Batch: 460; loss: 0.84; acc: 0.67
Batch: 480; loss: 0.43; acc: 0.83
Batch: 500; loss: 0.5; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.56; acc: 0.8
Batch: 560; loss: 0.91; acc: 0.72
Batch: 580; loss: 0.57; acc: 0.78
Batch: 600; loss: 0.6; acc: 0.77
Batch: 620; loss: 0.87; acc: 0.77
Batch: 640; loss: 0.92; acc: 0.69
Batch: 660; loss: 0.81; acc: 0.75
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.65; acc: 0.83
Batch: 740; loss: 0.61; acc: 0.8
Batch: 760; loss: 0.54; acc: 0.83
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.65; train_accuracy: 0.79 

Batch: 0; loss: 1.07; acc: 0.72
Batch: 20; loss: 0.87; acc: 0.72
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.89; acc: 0.69
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 0.93; acc: 0.61
Batch: 140; loss: 0.57; acc: 0.75
Val Epoch over. val_loss: 0.7403265188454063; val_accuracy: 0.7569665605095541 

The current subspace-distance is: 3.279290103819221e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.98; acc: 0.73
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.67; acc: 0.77
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.51; acc: 0.78
Batch: 100; loss: 0.98; acc: 0.7
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.43; acc: 0.91
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.76; acc: 0.8
Batch: 240; loss: 0.73; acc: 0.78
Batch: 260; loss: 0.61; acc: 0.8
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.72; acc: 0.72
Batch: 320; loss: 0.59; acc: 0.78
Batch: 340; loss: 0.52; acc: 0.8
Batch: 360; loss: 0.67; acc: 0.81
Batch: 380; loss: 0.48; acc: 0.81
Batch: 400; loss: 0.61; acc: 0.75
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.93; acc: 0.69
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.55; acc: 0.86
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.94; acc: 0.83
Batch: 580; loss: 0.61; acc: 0.8
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.97; acc: 0.77
Batch: 660; loss: 0.79; acc: 0.75
Batch: 680; loss: 0.85; acc: 0.72
Batch: 700; loss: 0.67; acc: 0.83
Batch: 720; loss: 0.88; acc: 0.7
Batch: 740; loss: 0.9; acc: 0.69
Batch: 760; loss: 0.54; acc: 0.75
Batch: 780; loss: 0.56; acc: 0.8
Train Epoch over. train_loss: 0.63; train_accuracy: 0.8 

Batch: 0; loss: 1.1; acc: 0.55
Batch: 20; loss: 1.17; acc: 0.56
Batch: 40; loss: 0.49; acc: 0.8
Batch: 60; loss: 0.8; acc: 0.78
Batch: 80; loss: 0.64; acc: 0.73
Batch: 100; loss: 1.41; acc: 0.61
Batch: 120; loss: 1.18; acc: 0.67
Batch: 140; loss: 0.46; acc: 0.78
Val Epoch over. val_loss: 0.8340590949271135; val_accuracy: 0.713077229299363 

The current subspace-distance is: 3.680841109598987e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.23; acc: 0.62
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 1.05; acc: 0.72
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.69; acc: 0.81
Batch: 180; loss: 0.71; acc: 0.73
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.69; acc: 0.75
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.82; acc: 0.77
Batch: 320; loss: 0.61; acc: 0.78
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.65; acc: 0.81
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.6; acc: 0.84
Batch: 420; loss: 0.75; acc: 0.77
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 1.18; acc: 0.69
Batch: 560; loss: 0.65; acc: 0.8
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.45; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.76; acc: 0.75
Batch: 700; loss: 0.59; acc: 0.78
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.67; acc: 0.88
Batch: 760; loss: 0.42; acc: 0.83
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.61; train_accuracy: 0.81 

Batch: 0; loss: 0.79; acc: 0.7
Batch: 20; loss: 0.75; acc: 0.75
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.74; acc: 0.75
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.41; acc: 0.86
Val Epoch over. val_loss: 0.5658202024212309; val_accuracy: 0.8222531847133758 

The current subspace-distance is: 4.33998393418733e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.84; acc: 0.75
Batch: 20; loss: 0.57; acc: 0.81
Batch: 40; loss: 0.61; acc: 0.81
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.67; acc: 0.75
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.68; acc: 0.77
Batch: 180; loss: 0.78; acc: 0.84
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.74; acc: 0.77
Batch: 240; loss: 0.86; acc: 0.66
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.52; acc: 0.81
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.68; acc: 0.81
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.66; acc: 0.78
Batch: 380; loss: 0.61; acc: 0.84
Batch: 400; loss: 0.92; acc: 0.66
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.51; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.67; acc: 0.84
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.59; acc: 0.75
Batch: 560; loss: 0.52; acc: 0.77
Batch: 580; loss: 0.49; acc: 0.81
Batch: 600; loss: 0.89; acc: 0.72
Batch: 620; loss: 0.87; acc: 0.75
Batch: 640; loss: 0.63; acc: 0.81
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.54; acc: 0.89
Batch: 700; loss: 0.5; acc: 0.88
Batch: 720; loss: 0.72; acc: 0.77
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.6; acc: 0.75
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.8; acc: 0.72
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.61; acc: 0.77
Batch: 140; loss: 0.32; acc: 0.89
Val Epoch over. val_loss: 0.5739696595319517; val_accuracy: 0.8202627388535032 

The current subspace-distance is: 4.599063322530128e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.02; acc: 0.73
Batch: 20; loss: 0.67; acc: 0.83
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.81
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.69; acc: 0.83
Batch: 200; loss: 0.5; acc: 0.83
Batch: 220; loss: 0.73; acc: 0.83
Batch: 240; loss: 0.5; acc: 0.81
Batch: 260; loss: 0.56; acc: 0.88
Batch: 280; loss: 0.77; acc: 0.75
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.84
Batch: 340; loss: 0.62; acc: 0.8
Batch: 360; loss: 0.6; acc: 0.77
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.8; acc: 0.8
Batch: 420; loss: 0.6; acc: 0.8
Batch: 440; loss: 0.86; acc: 0.75
Batch: 460; loss: 0.73; acc: 0.75
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.67; acc: 0.8
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.52; acc: 0.83
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.72; acc: 0.8
Batch: 600; loss: 0.46; acc: 0.8
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.81
Batch: 660; loss: 0.56; acc: 0.83
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.66; acc: 0.78
Batch: 720; loss: 0.84; acc: 0.72
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.46; acc: 0.84
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.82; acc: 0.69
Batch: 20; loss: 1.02; acc: 0.67
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.56; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.76; acc: 0.78
Batch: 120; loss: 1.02; acc: 0.67
Batch: 140; loss: 0.42; acc: 0.83
Val Epoch over. val_loss: 0.6868664107884571; val_accuracy: 0.7838375796178344 

The current subspace-distance is: 4.901776264887303e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.73
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.71; acc: 0.81
Batch: 60; loss: 0.49; acc: 0.8
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.63; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.8
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.75
Batch: 240; loss: 0.57; acc: 0.8
Batch: 260; loss: 0.52; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.6; acc: 0.8
Batch: 360; loss: 0.64; acc: 0.81
Batch: 380; loss: 0.58; acc: 0.78
Batch: 400; loss: 0.7; acc: 0.73
Batch: 420; loss: 0.63; acc: 0.81
Batch: 440; loss: 0.6; acc: 0.78
Batch: 460; loss: 0.61; acc: 0.77
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.57; acc: 0.75
Batch: 540; loss: 0.63; acc: 0.84
Batch: 560; loss: 0.61; acc: 0.81
Batch: 580; loss: 0.55; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.8
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.5; acc: 0.81
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.39; acc: 0.86
Batch: 720; loss: 0.65; acc: 0.88
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.39; acc: 0.83
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.95
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.474793534369985; val_accuracy: 0.8516122611464968 

The current subspace-distance is: 5.1440438255667686e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.83; acc: 0.72
Batch: 60; loss: 0.58; acc: 0.78
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.81
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.5; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.83
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.55; acc: 0.84
Batch: 240; loss: 0.91; acc: 0.8
Batch: 260; loss: 0.46; acc: 0.83
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.68; acc: 0.75
Batch: 340; loss: 0.83; acc: 0.81
Batch: 360; loss: 0.84; acc: 0.75
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.45; acc: 0.81
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.43; acc: 0.81
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.71; acc: 0.77
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.67; acc: 0.8
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.64; acc: 0.78
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.59; acc: 0.81
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.62; acc: 0.73
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.62; acc: 0.78
Batch: 740; loss: 0.48; acc: 0.8
Batch: 760; loss: 0.58; acc: 0.77
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.63; acc: 0.75
Batch: 20; loss: 0.9; acc: 0.7
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.6; acc: 0.77
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.8; acc: 0.75
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.5762136117288261; val_accuracy: 0.8088176751592356 

The current subspace-distance is: 5.529224290512502e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.97; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.83
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.51; acc: 0.8
Batch: 280; loss: 0.76; acc: 0.75
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.58; acc: 0.81
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.44; acc: 0.81
Batch: 420; loss: 1.09; acc: 0.7
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.54; acc: 0.81
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.44; acc: 0.84
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 0.69; acc: 0.88
Batch: 680; loss: 0.43; acc: 0.8
Batch: 700; loss: 0.6; acc: 0.86
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.83
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.8
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.77
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.42418566222783105; val_accuracy: 0.8681329617834395 

The current subspace-distance is: 5.8586098020896316e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.57; acc: 0.83
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.58; acc: 0.8
Batch: 340; loss: 0.66; acc: 0.8
Batch: 360; loss: 0.6; acc: 0.77
Batch: 380; loss: 0.54; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.63; acc: 0.84
Batch: 440; loss: 0.61; acc: 0.84
Batch: 460; loss: 0.58; acc: 0.81
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.66; acc: 0.83
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.46; acc: 0.84
Batch: 560; loss: 0.67; acc: 0.73
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.46; acc: 0.81
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.56; acc: 0.83
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.52; acc: 0.78
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4490706840897821; val_accuracy: 0.8638535031847133 

The current subspace-distance is: 6.150058470666409e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.3; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.84
Batch: 180; loss: 0.4; acc: 0.84
Batch: 200; loss: 0.48; acc: 0.8
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.61; acc: 0.86
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.61; acc: 0.88
Batch: 420; loss: 0.37; acc: 0.92
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.65; acc: 0.81
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.51; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.5; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.83
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.59; acc: 0.81
Batch: 760; loss: 0.74; acc: 0.73
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.62; acc: 0.75
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4906134122306374; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 6.449742068070918e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.54; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.55; acc: 0.78
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.55; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.6; acc: 0.8
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.56; acc: 0.78
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.62; acc: 0.83
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.62; acc: 0.88
Batch: 480; loss: 0.61; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.52; acc: 0.81
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.66; acc: 0.8
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.54; acc: 0.8
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.48; acc: 0.83
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.54; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.45485198858437265; val_accuracy: 0.8594745222929936 

The current subspace-distance is: 6.764126010239124e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.81
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.64; acc: 0.8
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.48; acc: 0.81
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.57; acc: 0.77
Batch: 440; loss: 0.34; acc: 0.84
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.92
Batch: 540; loss: 0.55; acc: 0.81
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.6; acc: 0.86
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.58; acc: 0.81
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.7; acc: 0.8
Batch: 700; loss: 0.72; acc: 0.78
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.97
Val Epoch over. val_loss: 0.44399679789117946; val_accuracy: 0.8618630573248408 

The current subspace-distance is: 6.975258293095976e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.8
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.75; acc: 0.8
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.56; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.44; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.84
Batch: 460; loss: 0.78; acc: 0.75
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.59; acc: 0.84
Batch: 520; loss: 0.66; acc: 0.8
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.68; acc: 0.78
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.57; acc: 0.8
Batch: 680; loss: 0.46; acc: 0.81
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.72; acc: 0.75
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.18; acc: 0.97
Val Epoch over. val_loss: 0.4348604200751918; val_accuracy: 0.8676353503184714 

The current subspace-distance is: 7.146961434045807e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.61; acc: 0.84
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.61; acc: 0.81
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.83
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.49; acc: 0.88
Batch: 280; loss: 0.48; acc: 0.83
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.55; acc: 0.8
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.33; acc: 0.94
Batch: 460; loss: 0.62; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.44; acc: 0.83
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.79; acc: 0.8
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.45; acc: 0.81
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.43698122276432194; val_accuracy: 0.8654458598726115 

The current subspace-distance is: 7.446473318850622e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.97; acc: 0.69
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.69; acc: 0.78
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.47; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.86
Batch: 300; loss: 0.44; acc: 0.91
Batch: 320; loss: 0.79; acc: 0.78
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.6; acc: 0.83
Batch: 440; loss: 0.41; acc: 0.84
Batch: 460; loss: 0.87; acc: 0.7
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.56; acc: 0.77
Batch: 520; loss: 0.48; acc: 0.88
Batch: 540; loss: 0.5; acc: 0.81
Batch: 560; loss: 0.46; acc: 0.83
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.62; acc: 0.81
Batch: 620; loss: 0.46; acc: 0.8
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.51; acc: 0.84
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.92; acc: 0.78
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.42358498816277573; val_accuracy: 0.871218152866242 

The current subspace-distance is: 7.80866394052282e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.63; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.84
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.56; acc: 0.84
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.62; acc: 0.81
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.54; acc: 0.83
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.65; acc: 0.83
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.49; acc: 0.78
Batch: 540; loss: 0.32; acc: 0.84
Batch: 560; loss: 0.34; acc: 0.94
Batch: 580; loss: 0.63; acc: 0.84
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.4; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.53; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.83
Batch: 720; loss: 0.59; acc: 0.81
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.4163317388030374; val_accuracy: 0.8735071656050956 

The current subspace-distance is: 8.025988790905103e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.89
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.61; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.53; acc: 0.8
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.46; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.69; acc: 0.75
Batch: 480; loss: 0.75; acc: 0.7
Batch: 500; loss: 0.52; acc: 0.86
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.46; acc: 0.91
Batch: 700; loss: 0.55; acc: 0.78
Batch: 720; loss: 0.43; acc: 0.89
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.85 

Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.4464049166554858; val_accuracy: 0.8649482484076433 

The current subspace-distance is: 8.144398452714086e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.48; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.86
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.47; acc: 0.91
Batch: 200; loss: 0.63; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.61; acc: 0.8
Batch: 260; loss: 0.49; acc: 0.8
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.92
Batch: 400; loss: 0.58; acc: 0.77
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.57; acc: 0.88
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.59; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.57; acc: 0.86
Batch: 700; loss: 0.52; acc: 0.83
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.57; acc: 0.78
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.4135384581461074; val_accuracy: 0.8756966560509554 

The current subspace-distance is: 8.417935896432027e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.58; acc: 0.8
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.56; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.85; acc: 0.83
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.8
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.4; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.68; acc: 0.78
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.75; acc: 0.81
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.92
Batch: 540; loss: 0.75; acc: 0.78
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.65; acc: 0.83
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.78; acc: 0.81
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.64; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4158320524700128; val_accuracy: 0.8729100318471338 

The current subspace-distance is: 8.712941780686378e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.8
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.52; acc: 0.86
Batch: 260; loss: 0.47; acc: 0.88
Batch: 280; loss: 0.56; acc: 0.83
Batch: 300; loss: 0.59; acc: 0.84
Batch: 320; loss: 0.55; acc: 0.84
Batch: 340; loss: 0.49; acc: 0.81
Batch: 360; loss: 0.8; acc: 0.78
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.6; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.6; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.51; acc: 0.83
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.72; acc: 0.81
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.5; acc: 0.81
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.41474187554447517; val_accuracy: 0.8747014331210191 

The current subspace-distance is: 8.754881127970293e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.53; acc: 0.81
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.7; acc: 0.77
Batch: 200; loss: 0.58; acc: 0.88
Batch: 220; loss: 0.65; acc: 0.83
Batch: 240; loss: 0.63; acc: 0.8
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.6; acc: 0.75
Batch: 300; loss: 0.37; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.81
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.5; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.64; acc: 0.83
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.4272156181229148; val_accuracy: 0.8689291401273885 

The current subspace-distance is: 9.075767593458295e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.89; acc: 0.78
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.81
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.48; acc: 0.81
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 1.18; acc: 0.67
Batch: 260; loss: 0.34; acc: 0.81
Batch: 280; loss: 0.61; acc: 0.84
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.46; acc: 0.81
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.85; acc: 0.78
Batch: 400; loss: 0.4; acc: 0.84
Batch: 420; loss: 0.66; acc: 0.75
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.83
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.55; acc: 0.78
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.46; acc: 0.81
Batch: 560; loss: 0.57; acc: 0.83
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.52; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.84
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.78; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4091960520596261; val_accuracy: 0.8763933121019108 

The current subspace-distance is: 9.42429542192258e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.83; acc: 0.73
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.64; acc: 0.8
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.66; acc: 0.83
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.42; acc: 0.81
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.49; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.52; acc: 0.81
Batch: 740; loss: 0.7; acc: 0.81
Batch: 760; loss: 0.49; acc: 0.83
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.63; acc: 0.8
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4116185484987915; val_accuracy: 0.8754976114649682 

The current subspace-distance is: 9.516843419987708e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.64; acc: 0.84
Batch: 420; loss: 0.61; acc: 0.81
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.76; acc: 0.72
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.87; acc: 0.75
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.7; acc: 0.75
Batch: 640; loss: 0.78; acc: 0.78
Batch: 660; loss: 0.57; acc: 0.81
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.92
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4163295697824211; val_accuracy: 0.873109076433121 

The current subspace-distance is: 9.702194074634463e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.81
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.52; acc: 0.86
Batch: 180; loss: 0.52; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.59; acc: 0.83
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.71; acc: 0.86
Batch: 400; loss: 0.27; acc: 0.97
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.6; acc: 0.84
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.73; acc: 0.73
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.83
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.33; acc: 0.94
Batch: 740; loss: 0.53; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.41972668877073155; val_accuracy: 0.871218152866242 

The current subspace-distance is: 9.961952309822664e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.83
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.53; acc: 0.81
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.67; acc: 0.8
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.56; acc: 0.84
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.63; acc: 0.83
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.54; acc: 0.78
Batch: 580; loss: 0.36; acc: 0.94
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.94
Batch: 640; loss: 0.47; acc: 0.89
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.84
Batch: 700; loss: 0.62; acc: 0.84
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.61; acc: 0.81
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.8
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4191264914479225; val_accuracy: 0.8720143312101911 

The current subspace-distance is: 0.00010232601198367774 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.46; acc: 0.77
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.66; acc: 0.81
Batch: 300; loss: 0.59; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.43; acc: 0.83
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.61; acc: 0.89
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.84
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.54; acc: 0.88
Batch: 560; loss: 0.6; acc: 0.83
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.54; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.66; acc: 0.84
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.8
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.53; acc: 0.81
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.4197226294856163; val_accuracy: 0.8717157643312102 

The current subspace-distance is: 0.00010339730215491727 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.39; acc: 0.83
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.56; acc: 0.86
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.64; acc: 0.83
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.58; acc: 0.81
Batch: 280; loss: 0.3; acc: 0.88
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.49; acc: 0.78
Batch: 340; loss: 0.38; acc: 0.81
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.86; acc: 0.84
Batch: 440; loss: 0.65; acc: 0.83
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.5; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.63; acc: 0.78
Batch: 540; loss: 0.61; acc: 0.83
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.66; acc: 0.83
Batch: 600; loss: 0.44; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.52; acc: 0.81
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.77
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4059660063142989; val_accuracy: 0.8764928343949044 

The current subspace-distance is: 0.00010378401930211112 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.75; acc: 0.78
Batch: 180; loss: 0.44; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.81
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.83
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.56; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.81
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.63; acc: 0.86
Batch: 440; loss: 0.35; acc: 0.84
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.55; acc: 0.83
Batch: 500; loss: 0.42; acc: 0.83
Batch: 520; loss: 0.42; acc: 0.83
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.44; acc: 0.8
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.5; acc: 0.88
Batch: 640; loss: 0.5; acc: 0.84
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.81
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.48; acc: 0.75
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.407550845176551; val_accuracy: 0.8759952229299363 

The current subspace-distance is: 0.00010620692046359181 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.78
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.52; acc: 0.86
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.51; acc: 0.81
Batch: 460; loss: 0.69; acc: 0.83
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.79; acc: 0.78
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.5; acc: 0.8
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.59; acc: 0.86
Batch: 700; loss: 0.49; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.41015698784475874; val_accuracy: 0.8763933121019108 

The current subspace-distance is: 0.00010625678260112181 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.58; acc: 0.77
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.84; acc: 0.75
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.55; acc: 0.81
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.81; acc: 0.78
Batch: 280; loss: 0.58; acc: 0.86
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.54; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.91
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.8
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.58; acc: 0.83
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.63; acc: 0.83
Batch: 680; loss: 0.61; acc: 0.81
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.68; acc: 0.78
Batch: 740; loss: 0.6; acc: 0.83
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.47; acc: 0.81
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.41179205069116726; val_accuracy: 0.8758957006369427 

The current subspace-distance is: 0.00010832305997610092 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.51; acc: 0.84
Batch: 200; loss: 0.49; acc: 0.8
Batch: 220; loss: 0.49; acc: 0.83
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.48; acc: 0.8
Batch: 480; loss: 0.63; acc: 0.78
Batch: 500; loss: 0.5; acc: 0.8
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.58; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.68; acc: 0.77
Batch: 680; loss: 0.5; acc: 0.83
Batch: 700; loss: 0.55; acc: 0.78
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4078008207925566; val_accuracy: 0.8747014331210191 

The current subspace-distance is: 0.00011043401900678873 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.54; acc: 0.89
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.64; acc: 0.83
Batch: 180; loss: 0.68; acc: 0.83
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.63; acc: 0.84
Batch: 260; loss: 0.43; acc: 0.8
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.46; acc: 0.8
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.73; acc: 0.78
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.58; acc: 0.75
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.46; acc: 0.81
Batch: 700; loss: 0.56; acc: 0.8
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.40540089372806487; val_accuracy: 0.8764928343949044 

The current subspace-distance is: 0.00011093826469732448 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.72; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.41; acc: 0.91
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.56; acc: 0.8
Batch: 300; loss: 0.63; acc: 0.78
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.46; acc: 0.83
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.54; acc: 0.88
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.53; acc: 0.81
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.69; acc: 0.83
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.58; acc: 0.8
Batch: 760; loss: 0.55; acc: 0.84
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.84
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4089244557603909; val_accuracy: 0.8755971337579618 

The current subspace-distance is: 0.00011307279055472463 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.95
Batch: 260; loss: 0.62; acc: 0.86
Batch: 280; loss: 0.84; acc: 0.75
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.65; acc: 0.77
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.34; acc: 0.83
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.78
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.62; acc: 0.77
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.53; acc: 0.83
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.59; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.406970306851302; val_accuracy: 0.87609474522293 

The current subspace-distance is: 0.00011501296830829233 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.56; acc: 0.86
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.9; acc: 0.78
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.52; acc: 0.78
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.63; acc: 0.8
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.62; acc: 0.84
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.81
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.46; acc: 0.8
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.56; acc: 0.8
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.83
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4053709761352296; val_accuracy: 0.8783837579617835 

The current subspace-distance is: 0.00011681754403980449 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.81
Batch: 260; loss: 0.49; acc: 0.83
Batch: 280; loss: 0.73; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.53; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.8
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.58; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.4; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.59; acc: 0.81
Batch: 760; loss: 0.53; acc: 0.8
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4066389575126065; val_accuracy: 0.8761942675159236 

The current subspace-distance is: 0.00011850094597321004 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.76; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.62; acc: 0.83
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.57; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.51; acc: 0.83
Batch: 440; loss: 0.75; acc: 0.83
Batch: 460; loss: 0.57; acc: 0.75
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.61; acc: 0.8
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.71; acc: 0.77
Batch: 640; loss: 0.6; acc: 0.88
Batch: 660; loss: 0.63; acc: 0.77
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4053605631658226; val_accuracy: 0.8770899681528662 

The current subspace-distance is: 0.00012097429862478748 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.61; acc: 0.83
Batch: 260; loss: 0.34; acc: 0.83
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.45; acc: 0.81
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.69; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.64; acc: 0.78
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.6; acc: 0.86
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4049077989758959; val_accuracy: 0.8766918789808917 

The current subspace-distance is: 0.00012265308760106564 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.46; acc: 0.8
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.68; acc: 0.73
Batch: 220; loss: 0.52; acc: 0.81
Batch: 240; loss: 0.59; acc: 0.8
Batch: 260; loss: 0.53; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.65; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.88
Batch: 460; loss: 0.58; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.46; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.62; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.51; acc: 0.89
Batch: 640; loss: 0.44; acc: 0.81
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.63; acc: 0.83
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.37; acc: 0.84
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.40573883986776804; val_accuracy: 0.8763933121019108 

The current subspace-distance is: 0.0001238731201738119 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.89
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.75; acc: 0.81
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.56; acc: 0.84
Batch: 280; loss: 0.51; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.3; acc: 0.95
Batch: 380; loss: 0.57; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.57; acc: 0.83
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.55; acc: 0.77
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.56; acc: 0.78
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.55; acc: 0.81
Batch: 660; loss: 0.71; acc: 0.8
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.46; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.88
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4049534261891037; val_accuracy: 0.8767914012738853 

The current subspace-distance is: 0.0001252119691343978 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.53; acc: 0.78
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.72; acc: 0.8
Batch: 260; loss: 0.51; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.57; acc: 0.78
Batch: 320; loss: 0.52; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.3; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.64; acc: 0.84
Batch: 460; loss: 0.75; acc: 0.8
Batch: 480; loss: 0.37; acc: 0.81
Batch: 500; loss: 0.65; acc: 0.84
Batch: 520; loss: 0.5; acc: 0.8
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.83
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.67; acc: 0.8
Batch: 660; loss: 0.44; acc: 0.83
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.43; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4053154354737063; val_accuracy: 0.8775875796178344 

The current subspace-distance is: 0.00012633719597943127 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.8
Batch: 80; loss: 0.67; acc: 0.83
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.54; acc: 0.8
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.4; acc: 0.84
Batch: 260; loss: 0.55; acc: 0.78
Batch: 280; loss: 0.5; acc: 0.8
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.7; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.76; acc: 0.84
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.51; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.86
Batch: 480; loss: 0.61; acc: 0.8
Batch: 500; loss: 0.59; acc: 0.78
Batch: 520; loss: 0.71; acc: 0.8
Batch: 540; loss: 0.46; acc: 0.81
Batch: 560; loss: 0.58; acc: 0.8
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.38; acc: 0.84
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.64; acc: 0.8
Batch: 740; loss: 0.35; acc: 0.84
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.62; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.40480377183408495; val_accuracy: 0.8772890127388535 

The current subspace-distance is: 0.00012798779061995447 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.77; acc: 0.81
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.56; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.52; acc: 0.8
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.68; acc: 0.83
Batch: 520; loss: 0.45; acc: 0.89
Batch: 540; loss: 0.75; acc: 0.78
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.52; acc: 0.84
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.52; acc: 0.81
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4047586987162851; val_accuracy: 0.8769904458598726 

The current subspace-distance is: 0.00012971310934517533 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.83
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.61; acc: 0.8
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.69; acc: 0.81
Batch: 240; loss: 0.52; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.55; acc: 0.81
Batch: 300; loss: 0.34; acc: 0.83
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.62; acc: 0.8
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.81
Batch: 440; loss: 0.29; acc: 0.95
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.83
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.68; acc: 0.81
Batch: 560; loss: 0.53; acc: 0.8
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.8
Batch: 620; loss: 0.65; acc: 0.78
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.86
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.27; acc: 0.95
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.40431088166441886; val_accuracy: 0.877687101910828 

The current subspace-distance is: 0.0001300454168813303 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.61; acc: 0.81
Batch: 340; loss: 0.5; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.57; acc: 0.81
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.61; acc: 0.83
Batch: 600; loss: 0.67; acc: 0.83
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.72; acc: 0.75
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4048619086670268; val_accuracy: 0.8766918789808917 

The current subspace-distance is: 0.00012999222963117063 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.81
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.77; acc: 0.81
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.59; acc: 0.84
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.54; acc: 0.88
Batch: 280; loss: 0.54; acc: 0.81
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.45; acc: 0.92
Batch: 340; loss: 0.54; acc: 0.83
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.81
Batch: 420; loss: 0.7; acc: 0.86
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.55; acc: 0.73
Batch: 520; loss: 0.51; acc: 0.83
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.54; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.43; acc: 0.81
Batch: 720; loss: 0.55; acc: 0.8
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.79; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4055191445502506; val_accuracy: 0.8764928343949044 

The current subspace-distance is: 0.0001308806095039472 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_150_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 36612
elements in E: 7774550
fraction nonzero: 0.004709211465615373
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.08
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.28; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.29; acc: 0.06
Batch: 220; loss: 2.27; acc: 0.12
Batch: 240; loss: 2.26; acc: 0.17
Batch: 260; loss: 2.26; acc: 0.14
Batch: 280; loss: 2.26; acc: 0.27
Batch: 300; loss: 2.23; acc: 0.34
Batch: 320; loss: 2.25; acc: 0.27
Batch: 340; loss: 2.21; acc: 0.34
Batch: 360; loss: 2.22; acc: 0.36
Batch: 380; loss: 2.21; acc: 0.28
Batch: 400; loss: 2.15; acc: 0.36
Batch: 420; loss: 2.16; acc: 0.34
Batch: 440; loss: 2.09; acc: 0.44
Batch: 460; loss: 2.1; acc: 0.36
Batch: 480; loss: 1.98; acc: 0.41
Batch: 500; loss: 1.89; acc: 0.44
Batch: 520; loss: 1.71; acc: 0.61
Batch: 540; loss: 1.5; acc: 0.59
Batch: 560; loss: 1.38; acc: 0.61
Batch: 580; loss: 1.28; acc: 0.59
Batch: 600; loss: 1.07; acc: 0.61
Batch: 620; loss: 1.11; acc: 0.62
Batch: 640; loss: 1.18; acc: 0.58
Batch: 660; loss: 1.1; acc: 0.62
Batch: 680; loss: 1.06; acc: 0.56
Batch: 700; loss: 1.24; acc: 0.64
Batch: 720; loss: 0.75; acc: 0.73
Batch: 740; loss: 0.82; acc: 0.75
Batch: 760; loss: 0.75; acc: 0.8
Batch: 780; loss: 0.87; acc: 0.72
Train Epoch over. train_loss: 1.84; train_accuracy: 0.36 

Batch: 0; loss: 0.81; acc: 0.75
Batch: 20; loss: 0.86; acc: 0.62
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.6; acc: 0.77
Batch: 80; loss: 0.64; acc: 0.78
Batch: 100; loss: 0.64; acc: 0.81
Batch: 120; loss: 0.94; acc: 0.67
Batch: 140; loss: 0.59; acc: 0.8
Val Epoch over. val_loss: 0.7631244211439874; val_accuracy: 0.758359872611465 

The current subspace-distance is: 1.0727735570981167e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.98; acc: 0.72
Batch: 40; loss: 1.18; acc: 0.61
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.98; acc: 0.66
Batch: 100; loss: 0.8; acc: 0.72
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.94; acc: 0.73
Batch: 160; loss: 0.72; acc: 0.8
Batch: 180; loss: 0.95; acc: 0.7
Batch: 200; loss: 0.85; acc: 0.72
Batch: 220; loss: 0.87; acc: 0.72
Batch: 240; loss: 0.99; acc: 0.62
Batch: 260; loss: 0.83; acc: 0.7
Batch: 280; loss: 0.73; acc: 0.8
Batch: 300; loss: 0.63; acc: 0.77
Batch: 320; loss: 0.66; acc: 0.77
Batch: 340; loss: 0.78; acc: 0.72
Batch: 360; loss: 0.86; acc: 0.73
Batch: 380; loss: 0.87; acc: 0.75
Batch: 400; loss: 0.53; acc: 0.83
Batch: 420; loss: 0.7; acc: 0.78
Batch: 440; loss: 0.65; acc: 0.77
Batch: 460; loss: 0.68; acc: 0.73
Batch: 480; loss: 0.81; acc: 0.75
Batch: 500; loss: 0.88; acc: 0.72
Batch: 520; loss: 0.67; acc: 0.78
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.82; acc: 0.75
Batch: 580; loss: 0.73; acc: 0.8
Batch: 600; loss: 0.63; acc: 0.8
Batch: 620; loss: 0.66; acc: 0.83
Batch: 640; loss: 0.58; acc: 0.78
Batch: 660; loss: 0.87; acc: 0.7
Batch: 680; loss: 0.81; acc: 0.75
Batch: 700; loss: 0.73; acc: 0.73
Batch: 720; loss: 0.88; acc: 0.72
Batch: 740; loss: 0.56; acc: 0.78
Batch: 760; loss: 0.78; acc: 0.72
Batch: 780; loss: 0.77; acc: 0.8
Train Epoch over. train_loss: 0.7; train_accuracy: 0.77 

Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.78
Batch: 40; loss: 0.4; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.82; acc: 0.75
Batch: 140; loss: 0.62; acc: 0.77
Val Epoch over. val_loss: 0.6481442028170179; val_accuracy: 0.7883160828025477 

The current subspace-distance is: 2.0068780941073783e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.67; acc: 0.77
Batch: 40; loss: 0.72; acc: 0.81
Batch: 60; loss: 0.9; acc: 0.73
Batch: 80; loss: 0.64; acc: 0.77
Batch: 100; loss: 0.6; acc: 0.75
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.89
Batch: 160; loss: 0.72; acc: 0.81
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.6; acc: 0.8
Batch: 220; loss: 0.76; acc: 0.78
Batch: 240; loss: 0.53; acc: 0.8
Batch: 260; loss: 0.68; acc: 0.72
Batch: 280; loss: 0.42; acc: 0.81
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.75; acc: 0.7
Batch: 340; loss: 0.76; acc: 0.77
Batch: 360; loss: 0.58; acc: 0.77
Batch: 380; loss: 0.74; acc: 0.73
Batch: 400; loss: 0.51; acc: 0.8
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.64; acc: 0.75
Batch: 480; loss: 0.63; acc: 0.8
Batch: 500; loss: 0.65; acc: 0.84
Batch: 520; loss: 0.84; acc: 0.7
Batch: 540; loss: 0.59; acc: 0.83
Batch: 560; loss: 0.55; acc: 0.86
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.7; acc: 0.81
Batch: 620; loss: 0.57; acc: 0.81
Batch: 640; loss: 0.55; acc: 0.84
Batch: 660; loss: 1.0; acc: 0.64
Batch: 680; loss: 0.62; acc: 0.77
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.55; acc: 0.73
Batch: 740; loss: 0.85; acc: 0.81
Batch: 760; loss: 0.49; acc: 0.78
Batch: 780; loss: 0.66; acc: 0.84
Train Epoch over. train_loss: 0.62; train_accuracy: 0.8 

Batch: 0; loss: 0.6; acc: 0.75
Batch: 20; loss: 0.59; acc: 0.77
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.73; acc: 0.75
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.45; acc: 0.86
Val Epoch over. val_loss: 0.5957537356075967; val_accuracy: 0.8082205414012739 

The current subspace-distance is: 2.7213078283239156e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.62; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.52; acc: 0.81
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.54; acc: 0.88
Batch: 200; loss: 0.7; acc: 0.75
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.7; acc: 0.8
Batch: 280; loss: 0.77; acc: 0.81
Batch: 300; loss: 0.48; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.63; acc: 0.77
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.7; acc: 0.75
Batch: 400; loss: 0.72; acc: 0.78
Batch: 420; loss: 0.64; acc: 0.73
Batch: 440; loss: 0.41; acc: 0.84
Batch: 460; loss: 0.83; acc: 0.72
Batch: 480; loss: 0.69; acc: 0.83
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.77; acc: 0.75
Batch: 560; loss: 0.81; acc: 0.75
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.73; acc: 0.8
Batch: 640; loss: 0.67; acc: 0.84
Batch: 660; loss: 0.8; acc: 0.73
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.71; acc: 0.83
Batch: 740; loss: 0.61; acc: 0.8
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.58; train_accuracy: 0.81 

Batch: 0; loss: 1.23; acc: 0.56
Batch: 20; loss: 1.12; acc: 0.59
Batch: 40; loss: 0.83; acc: 0.75
Batch: 60; loss: 1.5; acc: 0.64
Batch: 80; loss: 1.18; acc: 0.7
Batch: 100; loss: 1.4; acc: 0.69
Batch: 120; loss: 1.39; acc: 0.64
Batch: 140; loss: 1.11; acc: 0.66
Val Epoch over. val_loss: 1.2272975209412302; val_accuracy: 0.6282842356687898 

The current subspace-distance is: 3.271187233622186e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.46; acc: 0.56
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.78; acc: 0.73
Batch: 120; loss: 0.67; acc: 0.73
Batch: 140; loss: 0.51; acc: 0.8
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.86; acc: 0.77
Batch: 240; loss: 0.56; acc: 0.78
Batch: 260; loss: 0.59; acc: 0.81
Batch: 280; loss: 0.6; acc: 0.8
Batch: 300; loss: 0.55; acc: 0.73
Batch: 320; loss: 0.68; acc: 0.75
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.49; acc: 0.81
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.6; acc: 0.78
Batch: 460; loss: 0.43; acc: 0.83
Batch: 480; loss: 0.82; acc: 0.81
Batch: 500; loss: 0.64; acc: 0.83
Batch: 520; loss: 0.34; acc: 0.84
Batch: 540; loss: 0.6; acc: 0.78
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.69; acc: 0.81
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.85; acc: 0.8
Batch: 660; loss: 0.85; acc: 0.75
Batch: 680; loss: 0.55; acc: 0.83
Batch: 700; loss: 0.55; acc: 0.78
Batch: 720; loss: 1.08; acc: 0.64
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.6; acc: 0.78
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.75
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.87; acc: 0.78
Batch: 120; loss: 0.93; acc: 0.72
Batch: 140; loss: 0.48; acc: 0.84
Val Epoch over. val_loss: 0.5822160224056547; val_accuracy: 0.8070262738853503 

The current subspace-distance is: 3.826788815786131e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.75
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.82; acc: 0.78
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.56; acc: 0.78
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.61; acc: 0.86
Batch: 180; loss: 0.79; acc: 0.78
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.65; acc: 0.84
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.64; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.52; acc: 0.81
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 1.05; acc: 0.7
Batch: 560; loss: 0.62; acc: 0.86
Batch: 580; loss: 0.53; acc: 0.83
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.51; acc: 0.81
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.53; acc: 0.83
Batch: 700; loss: 0.7; acc: 0.8
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.47; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.67; acc: 0.77
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.77; acc: 0.84
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.5191959444504635; val_accuracy: 0.8350915605095541 

The current subspace-distance is: 4.233993968227878e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.77
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.54; acc: 0.86
Batch: 160; loss: 0.68; acc: 0.81
Batch: 180; loss: 0.79; acc: 0.77
Batch: 200; loss: 0.52; acc: 0.83
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.6; acc: 0.77
Batch: 260; loss: 0.39; acc: 0.83
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.65; acc: 0.81
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.63; acc: 0.73
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.52; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.58; acc: 0.78
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.71; acc: 0.78
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.55; acc: 0.77
Batch: 560; loss: 0.57; acc: 0.86
Batch: 580; loss: 0.58; acc: 0.83
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.64; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.58; acc: 0.83
Batch: 680; loss: 0.48; acc: 0.91
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.54; acc: 0.81
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.81
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.69; acc: 0.78
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.62; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.47722694467587073; val_accuracy: 0.8528065286624203 

The current subspace-distance is: 4.680897473008372e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.78
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.84
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.67; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.89
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.61; acc: 0.86
Batch: 460; loss: 0.62; acc: 0.83
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.78
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.52; acc: 0.81
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.91; acc: 0.72
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.7; acc: 0.81
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.51; acc: 0.84
Val Epoch over. val_loss: 0.6316300534708484; val_accuracy: 0.801453025477707 

The current subspace-distance is: 5.097109897178598e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.49; acc: 0.8
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.61; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.49; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.49; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.79; acc: 0.75
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.81
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.72; acc: 0.73
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.67; acc: 0.83
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.56; acc: 0.86
Batch: 520; loss: 0.73; acc: 0.83
Batch: 540; loss: 0.72; acc: 0.77
Batch: 560; loss: 0.86; acc: 0.75
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.94
Batch: 640; loss: 0.59; acc: 0.84
Batch: 660; loss: 0.5; acc: 0.81
Batch: 680; loss: 0.54; acc: 0.86
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.55; acc: 0.8
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.42; acc: 0.83
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.67; acc: 0.86
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.35; acc: 0.89
Val Epoch over. val_loss: 0.46455785736536526; val_accuracy: 0.8607683121019108 

The current subspace-distance is: 5.401071030064486e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.7; acc: 0.8
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.71; acc: 0.75
Batch: 180; loss: 0.77; acc: 0.78
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.62; acc: 0.77
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.6; acc: 0.84
Batch: 340; loss: 0.74; acc: 0.84
Batch: 360; loss: 0.71; acc: 0.78
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.49; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.69; acc: 0.78
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.59; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.8
Batch: 600; loss: 0.55; acc: 0.88
Batch: 620; loss: 0.45; acc: 0.92
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.66; acc: 0.81
Batch: 680; loss: 0.65; acc: 0.8
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.8; acc: 0.72
Batch: 120; loss: 0.79; acc: 0.72
Batch: 140; loss: 0.53; acc: 0.8
Val Epoch over. val_loss: 0.5599173339688854; val_accuracy: 0.8229498407643312 

The current subspace-distance is: 5.7013618061318994e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.96; acc: 0.72
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.7; acc: 0.84
Batch: 200; loss: 0.34; acc: 0.86
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.49; acc: 0.91
Batch: 280; loss: 0.59; acc: 0.86
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.64; acc: 0.78
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.51; acc: 0.89
Batch: 420; loss: 0.74; acc: 0.78
Batch: 440; loss: 0.49; acc: 0.83
Batch: 460; loss: 0.59; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.83
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.46; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.52; acc: 0.83
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.59; acc: 0.84
Batch: 660; loss: 0.58; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 0.51; acc: 0.81
Batch: 740; loss: 0.41; acc: 0.83
Batch: 760; loss: 0.45; acc: 0.81
Batch: 780; loss: 0.69; acc: 0.77
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.4384063037147947; val_accuracy: 0.8641520700636943 

The current subspace-distance is: 6.084157575969584e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.55; acc: 0.78
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.5; acc: 0.88
Batch: 380; loss: 0.52; acc: 0.8
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.63; acc: 0.86
Batch: 440; loss: 0.53; acc: 0.81
Batch: 460; loss: 0.6; acc: 0.81
Batch: 480; loss: 0.48; acc: 0.81
Batch: 500; loss: 0.71; acc: 0.8
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.67; acc: 0.78
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.53; acc: 0.86
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.48; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.68; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.37; acc: 0.89
Val Epoch over. val_loss: 0.45478224934666023; val_accuracy: 0.8599721337579618 

The current subspace-distance is: 6.397701508831233e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.25; acc: 0.88
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.48; acc: 0.81
Batch: 260; loss: 0.54; acc: 0.92
Batch: 280; loss: 0.54; acc: 0.83
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.65; acc: 0.86
Batch: 480; loss: 0.77; acc: 0.83
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.6; acc: 0.83
Batch: 540; loss: 0.68; acc: 0.78
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.61; acc: 0.84
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.57; acc: 0.8
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.72; acc: 0.83
Batch: 740; loss: 0.44; acc: 0.95
Batch: 760; loss: 0.57; acc: 0.86
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.44501428624057465; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 6.685645348625258e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.71; acc: 0.81
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.58; acc: 0.84
Batch: 100; loss: 0.53; acc: 0.81
Batch: 120; loss: 0.44; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.43; acc: 0.81
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.48; acc: 0.83
Batch: 440; loss: 0.68; acc: 0.81
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.59; acc: 0.83
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.83
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.86
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.56; acc: 0.8
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.43391006549072875; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 7.057520997477695e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.6; acc: 0.83
Batch: 240; loss: 0.51; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.53; acc: 0.8
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.89
Batch: 540; loss: 0.48; acc: 0.83
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.41; acc: 0.84
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.87; acc: 0.78
Batch: 700; loss: 0.64; acc: 0.81
Batch: 720; loss: 0.44; acc: 0.89
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.55; acc: 0.81
Batch: 780; loss: 0.6; acc: 0.81
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.4316153506374663; val_accuracy: 0.8670382165605095 

The current subspace-distance is: 7.290373469004408e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.95
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.73; acc: 0.8
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.86; acc: 0.77
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.62; acc: 0.78
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.6; acc: 0.77
Batch: 600; loss: 0.52; acc: 0.8
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.81; acc: 0.81
Batch: 740; loss: 0.67; acc: 0.8
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.34; acc: 0.94
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.66; acc: 0.77
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.4294696086721056; val_accuracy: 0.8692277070063694 

The current subspace-distance is: 7.534721225965768e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.67; acc: 0.83
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.57; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.61; acc: 0.8
Batch: 260; loss: 0.53; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.56; acc: 0.83
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.28; acc: 0.89
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.84
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.7; acc: 0.81
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.43; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.86
Batch: 120; loss: 0.84; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.4094412923333751; val_accuracy: 0.8763933121019108 

The current subspace-distance is: 7.774728874210268e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.66; acc: 0.81
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.63; acc: 0.75
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.88
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.52; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.51; acc: 0.89
Batch: 280; loss: 0.44; acc: 0.83
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.56; acc: 0.84
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.82; acc: 0.75
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.65; acc: 0.7
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.57; acc: 0.83
Batch: 580; loss: 0.67; acc: 0.8
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.88
Batch: 720; loss: 0.58; acc: 0.8
Batch: 740; loss: 0.82; acc: 0.78
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.4160260359288021; val_accuracy: 0.8717157643312102 

The current subspace-distance is: 8.050725591601804e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.54; acc: 0.81
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.91
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.61; acc: 0.84
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.37; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.51; acc: 0.8
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.54; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.22; acc: 0.95
Val Epoch over. val_loss: 0.40400662220967043; val_accuracy: 0.8772890127388535 

The current subspace-distance is: 8.323879592353478e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.52; acc: 0.81
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.6; acc: 0.81
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.57; acc: 0.77
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.7; acc: 0.81
Batch: 480; loss: 0.63; acc: 0.81
Batch: 500; loss: 0.57; acc: 0.84
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.48; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.95
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.62; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.75
Batch: 140; loss: 0.24; acc: 0.94
Val Epoch over. val_loss: 0.42026441425654537; val_accuracy: 0.8713176751592356 

The current subspace-distance is: 8.592916128691286e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.58; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.92
Batch: 440; loss: 0.4; acc: 0.84
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.54; acc: 0.75
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.8
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.59; acc: 0.83
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.54; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.390518525935662; val_accuracy: 0.880672770700637 

The current subspace-distance is: 8.895181235857308e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.47; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.62; acc: 0.78
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.5; acc: 0.84
Batch: 380; loss: 0.31; acc: 0.86
Batch: 400; loss: 0.38; acc: 0.84
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.66; acc: 0.84
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.73; acc: 0.8
Batch: 560; loss: 0.69; acc: 0.8
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.55; acc: 0.78
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.84
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.8
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.64; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.87; acc: 0.77
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.40335108382496865; val_accuracy: 0.8749004777070064 

The current subspace-distance is: 9.107559162657708e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.57; acc: 0.8
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.51; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.86
Batch: 440; loss: 0.53; acc: 0.81
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.82; acc: 0.8
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.44; acc: 0.83
Batch: 660; loss: 0.47; acc: 0.81
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.38877586621767396; val_accuracy: 0.8816679936305732 

The current subspace-distance is: 9.376229718327522e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.78
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.66; acc: 0.78
Batch: 200; loss: 0.65; acc: 0.84
Batch: 220; loss: 0.54; acc: 0.8
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.56; acc: 0.88
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.46; acc: 0.91
Batch: 320; loss: 0.55; acc: 0.86
Batch: 340; loss: 0.54; acc: 0.88
Batch: 360; loss: 0.58; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.52; acc: 0.84
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.83
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.83
Batch: 780; loss: 0.53; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.88; acc: 0.75
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3981859648398533; val_accuracy: 0.8754976114649682 

The current subspace-distance is: 9.529567614663392e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.5; acc: 0.8
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.58; acc: 0.8
Batch: 160; loss: 0.51; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.86
Batch: 200; loss: 0.71; acc: 0.84
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.9; acc: 0.8
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.69; acc: 0.8
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 1.13; acc: 0.75
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.62; acc: 0.83
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.51; acc: 0.84
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.8
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.39438603984512344; val_accuracy: 0.8791799363057324 

The current subspace-distance is: 9.822969150263816e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.84
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.52; acc: 0.77
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.62; acc: 0.83
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.54; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.35; acc: 0.84
Batch: 760; loss: 0.49; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.8
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.91
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.39532658277423516; val_accuracy: 0.8782842356687898 

The current subspace-distance is: 0.00010086939437314868 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.81
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.83
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.56; acc: 0.83
Batch: 420; loss: 0.5; acc: 0.81
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.8
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.61; acc: 0.83
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.61; acc: 0.78
Batch: 660; loss: 0.64; acc: 0.8
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.64; acc: 0.81
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.89; acc: 0.75
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.39256020350630877; val_accuracy: 0.879578025477707 

The current subspace-distance is: 0.0001036459143506363 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.44; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.54; acc: 0.81
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.5; acc: 0.83
Batch: 320; loss: 0.76; acc: 0.81
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.46; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.68; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.67; acc: 0.81
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.83
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.39795786199296357; val_accuracy: 0.8773885350318471 

The current subspace-distance is: 0.00010601523536024615 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.4; acc: 0.83
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.42; acc: 0.83
Batch: 280; loss: 0.46; acc: 0.84
Batch: 300; loss: 0.51; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.52; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.18; acc: 0.98
Batch: 480; loss: 0.43; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.76; acc: 0.81
Batch: 580; loss: 0.53; acc: 0.8
Batch: 600; loss: 0.72; acc: 0.81
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.6; acc: 0.8
Batch: 740; loss: 0.44; acc: 0.83
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.7; acc: 0.8
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.8
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38755044018387036; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 0.00010677355021471158 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.69; acc: 0.84
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.94
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.62; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.47; acc: 0.83
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 0.24; acc: 0.94
Val Epoch over. val_loss: 0.40759457633563667; val_accuracy: 0.8722133757961783 

The current subspace-distance is: 0.00010865717922570184 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.66; acc: 0.81
Batch: 180; loss: 0.41; acc: 0.84
Batch: 200; loss: 0.2; acc: 0.89
Batch: 220; loss: 0.82; acc: 0.78
Batch: 240; loss: 0.36; acc: 0.94
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.58; acc: 0.81
Batch: 600; loss: 0.65; acc: 0.75
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.55; acc: 0.88
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.84
Batch: 720; loss: 0.56; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.39; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38734436272435885; val_accuracy: 0.8810708598726115 

The current subspace-distance is: 0.00010968906281050295 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.5; acc: 0.88
Batch: 180; loss: 0.52; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.57; acc: 0.8
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.62; acc: 0.78
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.45; acc: 0.81
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.57; acc: 0.83
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.44; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.94
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.61; acc: 0.88
Batch: 720; loss: 0.57; acc: 0.84
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.56; acc: 0.81
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.3875694162431796; val_accuracy: 0.8804737261146497 

The current subspace-distance is: 0.00011114071094198152 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.38; acc: 0.81
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.76; acc: 0.8
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.75; acc: 0.81
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.54; acc: 0.86
Batch: 460; loss: 0.6; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.96; acc: 0.8
Batch: 540; loss: 0.58; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.84
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.83
Batch: 620; loss: 0.65; acc: 0.83
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.95
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38694645891523666; val_accuracy: 0.881468949044586 

The current subspace-distance is: 0.00011428697325754911 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.66; acc: 0.83
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.58; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.64; acc: 0.86
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.54; acc: 0.78
Batch: 300; loss: 0.29; acc: 0.86
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.49; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.77
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.88
Batch: 580; loss: 0.61; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.89; acc: 0.81
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.51; acc: 0.8
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.48; acc: 0.83
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.38647507173810036; val_accuracy: 0.8831608280254777 

The current subspace-distance is: 0.00011618435382843018 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.83
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.49; acc: 0.77
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.45; acc: 0.83
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.92
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.5; acc: 0.8
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.86
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.83
Batch: 600; loss: 0.42; acc: 0.84
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.65; acc: 0.86
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.37; acc: 0.81
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.75
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.38605547368906107; val_accuracy: 0.8820660828025477 

The current subspace-distance is: 0.00011865915439557284 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.92
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.56; acc: 0.86
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.83
Batch: 460; loss: 0.88; acc: 0.7
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.62; acc: 0.78
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.57; acc: 0.86
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.71; acc: 0.81
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.3887469414977511; val_accuracy: 0.8810708598726115 

The current subspace-distance is: 0.00012031232472509146 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.35; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.53; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.65; acc: 0.8
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.5; acc: 0.81
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.42; acc: 0.91
Batch: 540; loss: 0.52; acc: 0.86
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.53; acc: 0.83
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.64; acc: 0.86
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.6; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.26; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.3873928135652451; val_accuracy: 0.8796775477707006 

The current subspace-distance is: 0.00012171400885563344 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.75; acc: 0.78
Batch: 300; loss: 0.41; acc: 0.81
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.52; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.3909166084163508; val_accuracy: 0.8815684713375797 

The current subspace-distance is: 0.00012211005378048867 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.49; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.82; acc: 0.8
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.53; acc: 0.86
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.57; acc: 0.8
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.86
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.63; acc: 0.83
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.83
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.63; acc: 0.8
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.38526484389214; val_accuracy: 0.8824641719745223 

The current subspace-distance is: 0.00012430739297997206 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.96; acc: 0.73
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.83
Batch: 220; loss: 0.42; acc: 0.83
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.45; acc: 0.89
Batch: 280; loss: 0.68; acc: 0.84
Batch: 300; loss: 0.54; acc: 0.83
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.63; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.78
Batch: 440; loss: 0.65; acc: 0.84
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.88
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.8
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38727806309226215; val_accuracy: 0.8794785031847133 

The current subspace-distance is: 0.00012594145664479584 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.91
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.3; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.62; acc: 0.83
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.81
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.86
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.52; acc: 0.83
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.83
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38562856951526775; val_accuracy: 0.8816679936305732 

The current subspace-distance is: 0.00012632885773200542 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.84
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.45; acc: 0.81
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.43; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.46; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.38522684104313515; val_accuracy: 0.882265127388535 

The current subspace-distance is: 0.0001274188980460167 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.68; acc: 0.84
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.49; acc: 0.8
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.68; acc: 0.8
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.43; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.73; acc: 0.75
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.95
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.58; acc: 0.84
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3848189170573168; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 0.00012900264118798077 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.58; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.42; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.83
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.6; acc: 0.84
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.32; acc: 0.84
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3857037173999343; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 0.00012981865438632667 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.97
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.42; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.65; acc: 0.8
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.65; acc: 0.83
Batch: 520; loss: 0.53; acc: 0.83
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.6; acc: 0.77
Batch: 660; loss: 0.46; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3848496423974918; val_accuracy: 0.881468949044586 

The current subspace-distance is: 0.00013255138765089214 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.24; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.34; acc: 0.86
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.72; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.61; acc: 0.83
Batch: 500; loss: 0.4; acc: 0.83
Batch: 520; loss: 0.45; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38460547249218463; val_accuracy: 0.8826632165605095 

The current subspace-distance is: 0.0001349873055005446 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.86; acc: 0.8
Batch: 180; loss: 0.56; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.38; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.94
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.46; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.73; acc: 0.78
Batch: 520; loss: 0.5; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.55; acc: 0.81
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.38518338360983856; val_accuracy: 0.8823646496815286 

The current subspace-distance is: 0.0001357935689156875 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.31; acc: 0.84
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.67; acc: 0.84
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.64; acc: 0.84
Batch: 200; loss: 0.43; acc: 0.8
Batch: 220; loss: 0.79; acc: 0.83
Batch: 240; loss: 0.39; acc: 0.83
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.39; acc: 0.86
Batch: 320; loss: 0.48; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.49; acc: 0.81
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.81
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.59; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.83
Batch: 700; loss: 0.6; acc: 0.77
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.84
Batch: 760; loss: 0.32; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.38479169443914085; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 0.00013734666572418064 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.5; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.12; acc: 1.0
Batch: 140; loss: 0.71; acc: 0.81
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.56; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.45; acc: 0.81
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.52; acc: 0.86
Batch: 360; loss: 0.45; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.55; acc: 0.84
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.81
Batch: 580; loss: 0.79; acc: 0.81
Batch: 600; loss: 0.77; acc: 0.81
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.5; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3855035912933623; val_accuracy: 0.8816679936305732 

The current subspace-distance is: 0.0001392754929838702 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.51; acc: 0.86
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.95
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.91
Batch: 340; loss: 0.69; acc: 0.8
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.67; acc: 0.81
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.39; acc: 0.92
Batch: 500; loss: 0.5; acc: 0.83
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.46; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.81
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.46; acc: 0.8
Batch: 640; loss: 0.52; acc: 0.81
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.65; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.84
Batch: 780; loss: 0.73; acc: 0.83
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3848362947060804; val_accuracy: 0.8819665605095541 

The current subspace-distance is: 0.00014098525571171194 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_175_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 42223
elements in E: 8885200
fraction nonzero: 0.004752059604735966
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.28; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.05
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.27; acc: 0.19
Batch: 260; loss: 2.27; acc: 0.17
Batch: 280; loss: 2.26; acc: 0.2
Batch: 300; loss: 2.24; acc: 0.33
Batch: 320; loss: 2.26; acc: 0.22
Batch: 340; loss: 2.25; acc: 0.23
Batch: 360; loss: 2.23; acc: 0.39
Batch: 380; loss: 2.21; acc: 0.33
Batch: 400; loss: 2.22; acc: 0.22
Batch: 420; loss: 2.18; acc: 0.36
Batch: 440; loss: 2.11; acc: 0.42
Batch: 460; loss: 2.08; acc: 0.38
Batch: 480; loss: 2.06; acc: 0.28
Batch: 500; loss: 2.0; acc: 0.3
Batch: 520; loss: 1.84; acc: 0.36
Batch: 540; loss: 1.65; acc: 0.44
Batch: 560; loss: 1.4; acc: 0.61
Batch: 580; loss: 1.41; acc: 0.53
Batch: 600; loss: 1.14; acc: 0.7
Batch: 620; loss: 1.09; acc: 0.69
Batch: 640; loss: 1.08; acc: 0.66
Batch: 660; loss: 0.97; acc: 0.69
Batch: 680; loss: 1.49; acc: 0.53
Batch: 700; loss: 1.09; acc: 0.62
Batch: 720; loss: 0.56; acc: 0.86
Batch: 740; loss: 0.98; acc: 0.7
Batch: 760; loss: 0.77; acc: 0.73
Batch: 780; loss: 0.8; acc: 0.7
Train Epoch over. train_loss: 1.86; train_accuracy: 0.36 

Batch: 0; loss: 0.91; acc: 0.7
Batch: 20; loss: 0.82; acc: 0.7
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.85; acc: 0.75
Batch: 80; loss: 0.68; acc: 0.81
Batch: 100; loss: 0.62; acc: 0.83
Batch: 120; loss: 0.9; acc: 0.69
Batch: 140; loss: 0.52; acc: 0.83
Val Epoch over. val_loss: 0.7900443880041693; val_accuracy: 0.7390525477707006 

The current subspace-distance is: 1.0099961400555912e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.95; acc: 0.73
Batch: 20; loss: 0.77; acc: 0.77
Batch: 40; loss: 1.23; acc: 0.69
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.89; acc: 0.69
Batch: 160; loss: 0.71; acc: 0.77
Batch: 180; loss: 0.78; acc: 0.81
Batch: 200; loss: 0.66; acc: 0.8
Batch: 220; loss: 0.72; acc: 0.84
Batch: 240; loss: 0.93; acc: 0.67
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.79; acc: 0.83
Batch: 300; loss: 0.63; acc: 0.78
Batch: 320; loss: 0.49; acc: 0.8
Batch: 340; loss: 0.6; acc: 0.81
Batch: 360; loss: 0.8; acc: 0.78
Batch: 380; loss: 0.52; acc: 0.81
Batch: 400; loss: 0.57; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.59; acc: 0.86
Batch: 460; loss: 0.62; acc: 0.73
Batch: 480; loss: 0.84; acc: 0.8
Batch: 500; loss: 0.71; acc: 0.75
Batch: 520; loss: 0.67; acc: 0.84
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.55; acc: 0.86
Batch: 580; loss: 0.63; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.59; acc: 0.83
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.51; acc: 0.89
Batch: 700; loss: 0.65; acc: 0.75
Batch: 720; loss: 0.67; acc: 0.77
Batch: 740; loss: 0.58; acc: 0.78
Batch: 760; loss: 0.59; acc: 0.84
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.64; train_accuracy: 0.8 

Batch: 0; loss: 0.64; acc: 0.72
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.58; acc: 0.86
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.31; acc: 0.88
Val Epoch over. val_loss: 0.49384198048312195; val_accuracy: 0.8423566878980892 

The current subspace-distance is: 1.961696398211643e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.78
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.63; acc: 0.75
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.61; acc: 0.81
Batch: 200; loss: 0.56; acc: 0.84
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.5; acc: 0.78
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.64; acc: 0.78
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.81
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.5; acc: 0.83
Batch: 520; loss: 0.59; acc: 0.83
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.6; acc: 0.83
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.76; acc: 0.8
Batch: 680; loss: 0.64; acc: 0.78
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.8; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.93; acc: 0.69
Batch: 20; loss: 0.79; acc: 0.7
Batch: 40; loss: 0.56; acc: 0.78
Batch: 60; loss: 0.88; acc: 0.72
Batch: 80; loss: 0.9; acc: 0.73
Batch: 100; loss: 0.78; acc: 0.8
Batch: 120; loss: 0.89; acc: 0.75
Batch: 140; loss: 0.38; acc: 0.86
Val Epoch over. val_loss: 0.83082201108811; val_accuracy: 0.7508957006369427 

The current subspace-distance is: 2.6479270673007704e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.68; acc: 0.78
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.8
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.8
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.52; acc: 0.77
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.81
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.45; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.65; acc: 0.78
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.51; acc: 0.78
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.84
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.55; acc: 0.86
Batch: 640; loss: 0.63; acc: 0.89
Batch: 660; loss: 0.55; acc: 0.8
Batch: 680; loss: 0.54; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

Batch: 0; loss: 0.93; acc: 0.72
Batch: 20; loss: 0.86; acc: 0.75
Batch: 40; loss: 0.61; acc: 0.77
Batch: 60; loss: 1.14; acc: 0.69
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.52; acc: 0.77
Val Epoch over. val_loss: 0.7761828639325062; val_accuracy: 0.7538813694267515 

The current subspace-distance is: 3.261934034526348e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.99; acc: 0.69
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.29; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.54; acc: 0.8
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.56; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.83
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.61; acc: 0.83
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.84
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.5; acc: 0.83
Batch: 660; loss: 0.53; acc: 0.88
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.76; acc: 0.77
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.83
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.48185888431064644; val_accuracy: 0.8425557324840764 

The current subspace-distance is: 3.825106250587851e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.74; acc: 0.75
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.65; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.83
Batch: 180; loss: 0.5; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.88
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.73; acc: 0.75
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.89
Batch: 740; loss: 0.55; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.56; acc: 0.84
Batch: 20; loss: 0.63; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.74; acc: 0.81
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.26; acc: 0.89
Val Epoch over. val_loss: 0.5283824947609264; val_accuracy: 0.8344944267515924 

The current subspace-distance is: 4.2909494368359447e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.69
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.89
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.47; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.53; acc: 0.89
Batch: 320; loss: 0.45; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.45; acc: 0.81
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.51; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.83
Batch: 480; loss: 0.57; acc: 0.8
Batch: 500; loss: 0.5; acc: 0.83
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.84
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.25; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.92
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.48; acc: 0.78
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3708061216410938; val_accuracy: 0.882265127388535 

The current subspace-distance is: 4.777331560035236e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.56; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.67; acc: 0.77
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.51; acc: 0.8
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.49; acc: 0.88
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.54; acc: 0.81
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.8; acc: 0.78
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.4580531478355265; val_accuracy: 0.8560907643312102 

The current subspace-distance is: 5.1082693971693516e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.47; acc: 0.8
Batch: 340; loss: 0.42; acc: 0.81
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.68; acc: 0.7
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.49; acc: 0.8
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.38; acc: 0.83
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35469202189498644; val_accuracy: 0.89171974522293 

The current subspace-distance is: 5.5165808589663357e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.83; acc: 0.77
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.65; acc: 0.77
Batch: 340; loss: 0.71; acc: 0.86
Batch: 360; loss: 0.91; acc: 0.77
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.57; acc: 0.78
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.51; acc: 0.89
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.5; acc: 0.88
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.65; acc: 0.78
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.65; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.53; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.3950156522974087; val_accuracy: 0.8789808917197452 

The current subspace-distance is: 5.8943442127201706e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.86
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.59; acc: 0.84
Batch: 340; loss: 0.4; acc: 0.83
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.81
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.49; acc: 0.83
Batch: 660; loss: 0.36; acc: 0.84
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.55; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.81
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.339503258205713; val_accuracy: 0.897093949044586 

The current subspace-distance is: 6.212687731022015e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.84
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.95
Batch: 360; loss: 0.51; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.92
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.61; acc: 0.81
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.81
Batch: 640; loss: 0.42; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3486131308896906; val_accuracy: 0.8947054140127388 

The current subspace-distance is: 6.492207467090338e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.5; acc: 0.8
Batch: 240; loss: 0.36; acc: 0.84
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.59; acc: 0.84
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.48; acc: 0.88
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.5; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.6; acc: 0.83
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.48; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.51; acc: 0.89
Batch: 780; loss: 0.51; acc: 0.84
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3361761884135046; val_accuracy: 0.8991839171974523 

The current subspace-distance is: 6.76703784847632e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.14; acc: 1.0
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.53; acc: 0.86
Batch: 460; loss: 0.56; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.84
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.25; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.46; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3160168664755335; val_accuracy: 0.9028662420382165 

The current subspace-distance is: 7.009568071225658e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.45; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.86
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.29; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.47; acc: 0.81
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.81
Batch: 720; loss: 0.46; acc: 0.89
Batch: 740; loss: 0.43; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.51; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.33009179524934973; val_accuracy: 0.8987858280254777 

The current subspace-distance is: 7.348658982664347e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.57; acc: 0.86
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.83
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.22; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.8
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.64; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.83
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.8
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.6; acc: 0.83
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.97
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3716173512730629; val_accuracy: 0.8844546178343949 

The current subspace-distance is: 7.706833275733516e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.66; acc: 0.78
Batch: 180; loss: 0.33; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.83
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.49; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.83
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.81
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.29; acc: 0.86
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.54; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.321994059262382; val_accuracy: 0.901671974522293 

The current subspace-distance is: 7.902814832050353e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.5; acc: 0.81
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.89
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.86
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.51; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.5; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.57; acc: 0.83
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.6; acc: 0.78
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.44; acc: 0.81
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.77; acc: 0.81
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.33656143081510903; val_accuracy: 0.896297770700637 

The current subspace-distance is: 8.13583392300643e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.51; acc: 0.8
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.21; acc: 0.97
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.55; acc: 0.77
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.2; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.09; acc: 1.0
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.33693264842413034; val_accuracy: 0.8967953821656051 

The current subspace-distance is: 8.314002479892224e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.57; acc: 0.83
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.49; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.31978369371336735; val_accuracy: 0.9029657643312102 

The current subspace-distance is: 8.582041482441127e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.84
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.92
Batch: 680; loss: 0.55; acc: 0.86
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.30839395698658223; val_accuracy: 0.9060509554140127 

The current subspace-distance is: 8.787088154349476e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.51; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3116975146683918; val_accuracy: 0.9046576433121019 

The current subspace-distance is: 8.984186570160091e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.65; acc: 0.81
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.55; acc: 0.86
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.45; acc: 0.8
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.61; acc: 0.84
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.31937636712649065; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 9.209488052874804e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.78
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.89
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.58; acc: 0.83
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.37; acc: 0.83
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.83
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.5; acc: 0.83
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.30676452155895295; val_accuracy: 0.9064490445859873 

The current subspace-distance is: 9.444356692256406e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.49; acc: 0.81
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.86
Batch: 200; loss: 0.53; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.57; acc: 0.88
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.86; acc: 0.75
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.83
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.84
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.62; acc: 0.91
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.31596373586328164; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 9.67568121268414e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.57; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.58; acc: 0.81
Batch: 360; loss: 0.53; acc: 0.81
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.48; acc: 0.83
Batch: 480; loss: 0.32; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.78
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.31151244609029427; val_accuracy: 0.9075437898089171 

The current subspace-distance is: 9.880265861283988e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.55; acc: 0.8
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.62; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.49; acc: 0.81
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.44; acc: 0.81
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.86
Batch: 660; loss: 0.62; acc: 0.81
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.67; acc: 0.84
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3093526764375389; val_accuracy: 0.9068471337579618 

The current subspace-distance is: 0.00010125119297299534 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.5; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.43; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.57; acc: 0.81
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.39; acc: 0.83
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3145243652212392; val_accuracy: 0.9042595541401274 

The current subspace-distance is: 0.00010336792911402881 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.98
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.64; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.64; acc: 0.81
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3096701041053814; val_accuracy: 0.9071457006369427 

The current subspace-distance is: 0.00010527172707952559 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.98
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.4; acc: 0.83
Batch: 320; loss: 0.29; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.48; acc: 0.91
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.51; acc: 0.8
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.58; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.51; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.31680904072561084; val_accuracy: 0.9029657643312102 

The current subspace-distance is: 0.00010761436715256423 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.83
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.54; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.83
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.56; acc: 0.86
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.30582970703483386; val_accuracy: 0.9054538216560509 

The current subspace-distance is: 0.00010873053543036804 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.51; acc: 0.83
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.44; acc: 0.83
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.30818102333196407; val_accuracy: 0.9052547770700637 

The current subspace-distance is: 0.00011062213889090344 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.47; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.67; acc: 0.83
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.83
Batch: 600; loss: 0.42; acc: 0.81
Batch: 620; loss: 0.43; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.30595814999026855; val_accuracy: 0.9057523885350318 

The current subspace-distance is: 0.00011211805394850671 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.53; acc: 0.89
Batch: 60; loss: 0.73; acc: 0.81
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.74; acc: 0.83
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.47; acc: 0.89
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.51; acc: 0.88
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.89
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.72; acc: 0.78
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3076445561400644; val_accuracy: 0.9040605095541401 

The current subspace-distance is: 0.00011302671919111162 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.52; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3061215674896149; val_accuracy: 0.9067476114649682 

The current subspace-distance is: 0.00011485295544844121 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.61; acc: 0.8
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.56; acc: 0.86
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.63; acc: 0.78
Batch: 460; loss: 0.67; acc: 0.8
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3041413159696919; val_accuracy: 0.908140923566879 

The current subspace-distance is: 0.00011694058775901794 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.83
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.46; acc: 0.81
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.51; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.83
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3090708356374388; val_accuracy: 0.90515525477707 

The current subspace-distance is: 0.00011859474761877209 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.72; acc: 0.84
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.44; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.86
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3072211404040361; val_accuracy: 0.9049562101910829 

The current subspace-distance is: 0.00012025164323858917 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.72; acc: 0.73
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.47; acc: 0.81
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.43; acc: 0.83
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.88
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3049935986092136; val_accuracy: 0.9072452229299363 

The current subspace-distance is: 0.00012092500401195139 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.76; acc: 0.83
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.53; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3061452243643202; val_accuracy: 0.9067476114649682 

The current subspace-distance is: 0.0001239584817085415 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.86
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.59; acc: 0.86
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.38; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.83
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3052563280056996; val_accuracy: 0.9060509554140127 

The current subspace-distance is: 0.00012610724661499262 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.83
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3060948790353575; val_accuracy: 0.9053542993630573 

The current subspace-distance is: 0.00012761734251398593 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.64; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.48; acc: 0.91
Batch: 360; loss: 0.69; acc: 0.81
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.53; acc: 0.78
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3061660951964415; val_accuracy: 0.9052547770700637 

The current subspace-distance is: 0.0001282662124140188 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.83
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.53; acc: 0.83
Batch: 200; loss: 0.63; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.47; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.5; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.81
Batch: 380; loss: 0.6; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.5; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.48; acc: 0.91
Batch: 660; loss: 0.68; acc: 0.83
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.47; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.30619229433263184; val_accuracy: 0.9056528662420382 

The current subspace-distance is: 0.000129285515868105 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.84
Batch: 440; loss: 0.47; acc: 0.89
Batch: 460; loss: 0.67; acc: 0.81
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3044538467553011; val_accuracy: 0.908140923566879 

The current subspace-distance is: 0.00013193309132475406 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.84
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.92
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.89
Batch: 600; loss: 0.54; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3048735274725659; val_accuracy: 0.9077428343949044 

The current subspace-distance is: 0.00013281266728881747 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.66; acc: 0.81
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.63; acc: 0.83
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.5; acc: 0.84
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.83
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.83
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.55; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.83
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3053198564489176; val_accuracy: 0.9072452229299363 

The current subspace-distance is: 0.000134894551592879 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.53; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.92
Batch: 180; loss: 0.5; acc: 0.8
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.52; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.48; acc: 0.83
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3044515660708877; val_accuracy: 0.9069466560509554 

The current subspace-distance is: 0.00013633350317832083 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.81
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.11; acc: 1.0
Batch: 500; loss: 0.44; acc: 0.8
Batch: 520; loss: 0.53; acc: 0.8
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.62; acc: 0.83
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.30471483262101556; val_accuracy: 0.9074442675159236 

The current subspace-distance is: 0.00013683660654351115 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.43; acc: 0.81
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.43; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.21; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.52; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.305153926846328; val_accuracy: 0.9072452229299363 

The current subspace-distance is: 0.00013847986701875925 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 44376
elements in E: 9329460
fraction nonzero: 0.004756545394910316
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.26; acc: 0.2
Batch: 260; loss: 2.25; acc: 0.23
Batch: 280; loss: 2.26; acc: 0.27
Batch: 300; loss: 2.22; acc: 0.36
Batch: 320; loss: 2.23; acc: 0.19
Batch: 340; loss: 2.24; acc: 0.06
Batch: 360; loss: 2.15; acc: 0.34
Batch: 380; loss: 2.12; acc: 0.36
Batch: 400; loss: 2.13; acc: 0.23
Batch: 420; loss: 1.99; acc: 0.42
Batch: 440; loss: 1.77; acc: 0.58
Batch: 460; loss: 1.61; acc: 0.56
Batch: 480; loss: 1.37; acc: 0.58
Batch: 500; loss: 1.06; acc: 0.58
Batch: 520; loss: 0.79; acc: 0.73
Batch: 540; loss: 0.91; acc: 0.73
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.86; acc: 0.73
Batch: 600; loss: 0.63; acc: 0.84
Batch: 620; loss: 0.71; acc: 0.77
Batch: 640; loss: 0.96; acc: 0.69
Batch: 660; loss: 0.77; acc: 0.72
Batch: 680; loss: 1.02; acc: 0.64
Batch: 700; loss: 0.92; acc: 0.77
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.88; acc: 0.72
Batch: 760; loss: 0.68; acc: 0.78
Batch: 780; loss: 1.12; acc: 0.69
Train Epoch over. train_loss: 1.67; train_accuracy: 0.42 

Batch: 0; loss: 0.7; acc: 0.75
Batch: 20; loss: 0.96; acc: 0.7
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.72; acc: 0.75
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 1.14; acc: 0.62
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.6161143744637252; val_accuracy: 0.800656847133758 

The current subspace-distance is: 1.1525232366693672e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.75
Batch: 20; loss: 0.78; acc: 0.77
Batch: 40; loss: 0.97; acc: 0.72
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.96; acc: 0.72
Batch: 100; loss: 0.75; acc: 0.73
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.68; acc: 0.77
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.91; acc: 0.75
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.64; acc: 0.8
Batch: 240; loss: 0.86; acc: 0.81
Batch: 260; loss: 0.75; acc: 0.75
Batch: 280; loss: 0.72; acc: 0.75
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.58; acc: 0.86
Batch: 340; loss: 0.64; acc: 0.8
Batch: 360; loss: 0.64; acc: 0.73
Batch: 380; loss: 0.65; acc: 0.81
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.49; acc: 0.88
Batch: 460; loss: 0.55; acc: 0.83
Batch: 480; loss: 0.69; acc: 0.78
Batch: 500; loss: 0.76; acc: 0.75
Batch: 520; loss: 0.67; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.65; acc: 0.81
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.75; acc: 0.77
Batch: 620; loss: 0.52; acc: 0.8
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.6; acc: 0.77
Batch: 700; loss: 0.45; acc: 0.83
Batch: 720; loss: 0.6; acc: 0.83
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.73; acc: 0.8
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

Batch: 0; loss: 0.68; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.75
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.64; acc: 0.8
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.4; acc: 0.83
Val Epoch over. val_loss: 0.6272160523826149; val_accuracy: 0.7916003184713376 

The current subspace-distance is: 2.0053037587786093e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.61; acc: 0.78
Batch: 200; loss: 0.63; acc: 0.86
Batch: 220; loss: 0.72; acc: 0.83
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.37; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.61; acc: 0.78
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.47; acc: 0.77
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.81
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.58; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.89
Batch: 520; loss: 0.53; acc: 0.77
Batch: 540; loss: 0.41; acc: 0.95
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.8
Batch: 660; loss: 0.85; acc: 0.7
Batch: 680; loss: 0.43; acc: 0.81
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.76; acc: 0.78
Batch: 740; loss: 0.85; acc: 0.73
Batch: 760; loss: 0.52; acc: 0.83
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.69; acc: 0.75
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 0.22; acc: 0.97
Val Epoch over. val_loss: 0.5348767387639185; val_accuracy: 0.8295183121019108 

The current subspace-distance is: 2.7305137336952612e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.65; acc: 0.84
Batch: 80; loss: 0.62; acc: 0.78
Batch: 100; loss: 0.79; acc: 0.72
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.8
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.71; acc: 0.83
Batch: 300; loss: 0.49; acc: 0.83
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.7; acc: 0.83
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.57; acc: 0.83
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.76; acc: 0.75
Batch: 480; loss: 0.63; acc: 0.81
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.92; acc: 0.73
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.62; acc: 0.81
Batch: 640; loss: 0.85; acc: 0.73
Batch: 660; loss: 0.63; acc: 0.83
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.53; acc: 0.84
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.92; acc: 0.69
Batch: 20; loss: 0.9; acc: 0.7
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 1.1; acc: 0.7
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.78; acc: 0.75
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.76; acc: 0.75
Val Epoch over. val_loss: 0.7299938184820163; val_accuracy: 0.7586584394904459 

The current subspace-distance is: 3.3218828320968896e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.08; acc: 0.61
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.69; acc: 0.75
Batch: 120; loss: 0.56; acc: 0.88
Batch: 140; loss: 0.62; acc: 0.8
Batch: 160; loss: 0.59; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.53; acc: 0.81
Batch: 300; loss: 0.81; acc: 0.8
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.45; acc: 0.89
Batch: 360; loss: 0.56; acc: 0.78
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.67; acc: 0.77
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.64; acc: 0.83
Batch: 500; loss: 0.63; acc: 0.78
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.8; acc: 0.75
Batch: 580; loss: 0.7; acc: 0.84
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.67; acc: 0.78
Batch: 680; loss: 0.57; acc: 0.81
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 1.19; acc: 0.66
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 1.11; acc: 0.62
Batch: 20; loss: 1.52; acc: 0.59
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.87; acc: 0.72
Batch: 80; loss: 1.02; acc: 0.72
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 1.29; acc: 0.66
Batch: 140; loss: 0.59; acc: 0.8
Val Epoch over. val_loss: 0.9353977257658721; val_accuracy: 0.7201433121019108 

The current subspace-distance is: 3.880261647282168e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.14; acc: 0.7
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 1.0; acc: 0.78
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.53; acc: 0.77
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.51; acc: 0.8
Batch: 180; loss: 0.51; acc: 0.81
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.57; acc: 0.83
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.55; acc: 0.86
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.89; acc: 0.73
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.74; acc: 0.81
Batch: 560; loss: 0.63; acc: 0.86
Batch: 580; loss: 0.51; acc: 0.88
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.64; acc: 0.83
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.42; acc: 0.81
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 1.14; acc: 0.64
Batch: 20; loss: 1.16; acc: 0.64
Batch: 40; loss: 0.51; acc: 0.78
Batch: 60; loss: 0.99; acc: 0.7
Batch: 80; loss: 0.68; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.8
Batch: 120; loss: 1.4; acc: 0.66
Batch: 140; loss: 1.01; acc: 0.72
Val Epoch over. val_loss: 0.922886432925607; val_accuracy: 0.7110867834394905 

The current subspace-distance is: 4.3097592424601316e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.69
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.49; acc: 0.8
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.58; acc: 0.84
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.51; acc: 0.84
Batch: 160; loss: 0.6; acc: 0.88
Batch: 180; loss: 0.59; acc: 0.73
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.66; acc: 0.75
Batch: 360; loss: 0.49; acc: 0.81
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.42; acc: 0.83
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.81
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.65; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.8
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.383472977834902; val_accuracy: 0.8771894904458599 

The current subspace-distance is: 4.715684553957544e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.7; acc: 0.83
Batch: 40; loss: 0.65; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.38; acc: 0.84
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.49; acc: 0.8
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.5; acc: 0.8
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.84; acc: 0.77
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.81; acc: 0.77
Batch: 520; loss: 0.47; acc: 0.81
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.15; acc: 0.98
Batch: 640; loss: 0.54; acc: 0.8
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.56; acc: 0.77
Batch: 740; loss: 0.51; acc: 0.83
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 2.27; acc: 0.48
Batch: 20; loss: 2.96; acc: 0.44
Batch: 40; loss: 1.38; acc: 0.61
Batch: 60; loss: 1.58; acc: 0.52
Batch: 80; loss: 2.3; acc: 0.5
Batch: 100; loss: 1.52; acc: 0.58
Batch: 120; loss: 2.6; acc: 0.47
Batch: 140; loss: 2.22; acc: 0.5
Val Epoch over. val_loss: 2.1061088218810453; val_accuracy: 0.5084593949044586 

The current subspace-distance is: 4.954127507517114e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.48; acc: 0.41
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.71; acc: 0.72
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.37; acc: 0.84
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.55; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.67; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.81
Batch: 400; loss: 0.73; acc: 0.78
Batch: 420; loss: 0.54; acc: 0.75
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.49; acc: 0.78
Batch: 540; loss: 0.83; acc: 0.73
Batch: 560; loss: 0.49; acc: 0.8
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.75; acc: 0.78
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.86
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.73; acc: 0.72
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.94; acc: 0.72
Batch: 140; loss: 0.32; acc: 0.89
Val Epoch over. val_loss: 0.4833859437780016; val_accuracy: 0.8457404458598726 

The current subspace-distance is: 5.268979293759912e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.71; acc: 0.75
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.63; acc: 0.75
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.47; acc: 0.8
Batch: 180; loss: 0.58; acc: 0.78
Batch: 200; loss: 0.24; acc: 0.86
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.56; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.65; acc: 0.8
Batch: 340; loss: 0.68; acc: 0.83
Batch: 360; loss: 0.64; acc: 0.83
Batch: 380; loss: 0.53; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.84
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.97
Batch: 520; loss: 0.68; acc: 0.81
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.55; acc: 0.81
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.55; acc: 0.81
Batch: 680; loss: 0.46; acc: 0.8
Batch: 700; loss: 0.34; acc: 0.81
Batch: 720; loss: 0.52; acc: 0.73
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.9; acc: 0.67
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.54; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.42834999379079053; val_accuracy: 0.8634554140127388 

The current subspace-distance is: 5.699713801732287e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.83
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.89
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.67; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.77
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.51; acc: 0.81
Batch: 660; loss: 0.59; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.83
Batch: 740; loss: 0.34; acc: 0.83
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.8; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3712298771378341; val_accuracy: 0.8873407643312102 

The current subspace-distance is: 6.04357774136588e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.44; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.83
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.55; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.47; acc: 0.83
Batch: 360; loss: 0.45; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.48; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.95
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.79; acc: 0.83
Batch: 580; loss: 0.42; acc: 0.92
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.81
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.77; acc: 0.84
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.58; acc: 0.8
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.86; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3768163883382348; val_accuracy: 0.8832603503184714 

The current subspace-distance is: 6.385830783983693e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.81
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.47; acc: 0.81
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.54; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.69; acc: 0.83
Batch: 480; loss: 0.35; acc: 0.83
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.83
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.48; acc: 0.86
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.68; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.78
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.39034893510827595; val_accuracy: 0.877687101910828 

The current subspace-distance is: 6.700758240185678e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.49; acc: 0.8
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.84
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.48; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.47; acc: 0.81
Batch: 460; loss: 0.55; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.81
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.57; acc: 0.86
Batch: 20; loss: 0.82; acc: 0.78
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.40959081295759053; val_accuracy: 0.8735071656050956 

The current subspace-distance is: 6.915340054547414e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.81
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.44; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.27; acc: 0.88
Batch: 460; loss: 0.38; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.86
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.46; acc: 0.8
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.62; acc: 0.84
Batch: 760; loss: 0.41; acc: 0.83
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.55; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.81
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3643073651488799; val_accuracy: 0.8872412420382165 

The current subspace-distance is: 7.175084465416148e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.94
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.22; acc: 0.97
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.64; acc: 0.83
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.57; acc: 0.81
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.66; acc: 0.81
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.65; acc: 0.83
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.5; acc: 0.83
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.8; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.362834060030758; val_accuracy: 0.8899283439490446 

The current subspace-distance is: 7.44275821489282e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.56; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.61; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.53; acc: 0.84
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.86
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.81
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.52; acc: 0.88
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.83
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.64; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.8
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.3726279807698195; val_accuracy: 0.8802746815286624 

The current subspace-distance is: 7.729024946456775e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.18; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.59; acc: 0.83
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.35; acc: 0.95
Batch: 320; loss: 0.61; acc: 0.83
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.93; acc: 0.8
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.69; acc: 0.81
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.64; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.84
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.45; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.57; acc: 0.81
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.58; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.62; acc: 0.77
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.39274154987874305; val_accuracy: 0.8773885350318471 

The current subspace-distance is: 7.977491623023525e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.58; acc: 0.86
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.49; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.34; acc: 0.84
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.92
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.44; acc: 0.83
Batch: 400; loss: 0.24; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.84
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.43; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.83
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.8
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.75
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.34581087999472954; val_accuracy: 0.88953025477707 

The current subspace-distance is: 8.21668072603643e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.43; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.86
Batch: 240; loss: 0.67; acc: 0.81
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.4; acc: 0.81
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.5; acc: 0.8
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.55; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.33; acc: 0.86
Batch: 700; loss: 0.22; acc: 0.89
Batch: 720; loss: 0.63; acc: 0.81
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3480290747751856; val_accuracy: 0.8893312101910829 

The current subspace-distance is: 8.406797860516235e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.92
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.45; acc: 0.81
Batch: 420; loss: 0.45; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.45; acc: 0.83
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.55; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.79; acc: 0.75
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.33855434004098744; val_accuracy: 0.8946058917197452 

The current subspace-distance is: 8.61302760313265e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.59; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.59; acc: 0.8
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.52; acc: 0.84
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.62; acc: 0.88
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.78; acc: 0.78
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.61; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3332936146361813; val_accuracy: 0.8990843949044586 

The current subspace-distance is: 8.746715320739895e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.6; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.84
Batch: 220; loss: 0.3; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.8
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.39; acc: 0.83
Batch: 320; loss: 0.51; acc: 0.88
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.37; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.86
Batch: 540; loss: 0.58; acc: 0.84
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.339160507604195; val_accuracy: 0.8960987261146497 

The current subspace-distance is: 8.913160854717717e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.64; acc: 0.84
Batch: 220; loss: 0.44; acc: 0.83
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.84
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.44; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.55; acc: 0.84
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.53; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.55; acc: 0.81
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.3396069551491813; val_accuracy: 0.894406847133758 

The current subspace-distance is: 9.107220830628648e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.81
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.92
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.73; acc: 0.81
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.53; acc: 0.83
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.96; acc: 0.77
Batch: 400; loss: 0.43; acc: 0.83
Batch: 420; loss: 0.55; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.84
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.38; acc: 0.84
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.32939291168834756; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 9.313413465861231e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.55; acc: 0.88
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.92
Batch: 140; loss: 0.37; acc: 0.84
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.57; acc: 0.84
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.8
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.56; acc: 0.84
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.3314122396764482; val_accuracy: 0.8973925159235668 

The current subspace-distance is: 9.5465307822451e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.47; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.83
Batch: 440; loss: 0.42; acc: 0.91
Batch: 460; loss: 0.66; acc: 0.81
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.49; acc: 0.83
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.82; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.34375794155962147; val_accuracy: 0.8924164012738853 

The current subspace-distance is: 9.674282046034932e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.39; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.49; acc: 0.8
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.84
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.63; acc: 0.8
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.49; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3592435144789659; val_accuracy: 0.8878383757961783 

The current subspace-distance is: 9.862392471404746e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.46; acc: 0.8
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.59; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.64; acc: 0.81
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.5; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.44; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.7; acc: 0.8
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3477393292887196; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 0.00010039849439635873 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.59; acc: 0.77
Batch: 20; loss: 0.52; acc: 0.78
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.81
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.81
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.58; acc: 0.84
Batch: 300; loss: 0.47; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.52; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.41; acc: 0.94
Batch: 620; loss: 0.56; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.77
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.81
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.33996883148600343; val_accuracy: 0.8905254777070064 

The current subspace-distance is: 0.0001018749171635136 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.94
Batch: 180; loss: 0.43; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.75; acc: 0.86
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.49; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.53; acc: 0.86
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 0.48; acc: 0.88
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.57; acc: 0.8
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.54; acc: 0.8
Batch: 700; loss: 0.37; acc: 0.81
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.32620038841940036; val_accuracy: 0.8969944267515924 

The current subspace-distance is: 0.00010366261994931847 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.52; acc: 0.89
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.83
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.47; acc: 0.8
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.48; acc: 0.8
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.92
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.57; acc: 0.78
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.33218591048079693; val_accuracy: 0.8969944267515924 

The current subspace-distance is: 0.00010512272274354473 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.84
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.7; acc: 0.75
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.86
Batch: 360; loss: 0.58; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.51; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.6; acc: 0.83
Batch: 540; loss: 0.5; acc: 0.89
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.62; acc: 0.83
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.32596121868415245; val_accuracy: 0.897093949044586 

The current subspace-distance is: 0.00010674463555915281 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.65; acc: 0.88
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.61; acc: 0.84
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.86
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.58; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.44; acc: 0.84
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.43; acc: 0.83
Batch: 580; loss: 0.66; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.51; acc: 0.83
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.57; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3273390631909203; val_accuracy: 0.8980891719745223 

The current subspace-distance is: 0.00010814096458489075 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.78
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.18; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.83
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.43; acc: 0.83
Batch: 540; loss: 0.54; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.94
Batch: 660; loss: 0.63; acc: 0.8
Batch: 680; loss: 0.37; acc: 0.94
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.81
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.32733063779439137; val_accuracy: 0.8971934713375797 

The current subspace-distance is: 0.00010963155364152044 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.81
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.39; acc: 0.92
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.65; acc: 0.78
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.89
Batch: 300; loss: 0.48; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.45; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.85; acc: 0.75
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.5; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3295094986108078; val_accuracy: 0.8980891719745223 

The current subspace-distance is: 0.00011202337918803096 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.47; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.38; acc: 0.84
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.37; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.79; acc: 0.75
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3311513461599684; val_accuracy: 0.8955015923566879 

The current subspace-distance is: 0.00011431166785769165 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.23; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.48; acc: 0.89
Batch: 280; loss: 0.71; acc: 0.81
Batch: 300; loss: 0.58; acc: 0.8
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.92
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.49; acc: 0.88
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.81
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3268702824594109; val_accuracy: 0.8975915605095541 

The current subspace-distance is: 0.00011652940884232521 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.33; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.63; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.56; acc: 0.78
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.84
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.49; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.84
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.32661149086086616; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 0.00011794080637628213 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.86
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.51; acc: 0.91
Batch: 280; loss: 0.7; acc: 0.84
Batch: 300; loss: 0.47; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.81
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3288525076476252; val_accuracy: 0.8981886942675159 

The current subspace-distance is: 0.00011875710333697498 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.65; acc: 0.83
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.83
Batch: 180; loss: 0.31; acc: 0.95
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.65; acc: 0.84
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.52; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.52; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.55; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.53; acc: 0.84
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.83; acc: 0.8
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.53; acc: 0.89
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.43; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.32430131045306565; val_accuracy: 0.897890127388535 

The current subspace-distance is: 0.00011978916882071644 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.83
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.59; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.42; acc: 0.83
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3258450811218684; val_accuracy: 0.8974920382165605 

The current subspace-distance is: 0.00012175889423815534 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.52; acc: 0.81
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.79; acc: 0.78
Batch: 220; loss: 0.69; acc: 0.81
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.1; acc: 1.0
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.55; acc: 0.81
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.6; acc: 0.78
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.83
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.78
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.32498735329432854; val_accuracy: 0.8974920382165605 

The current subspace-distance is: 0.00012274690379854292 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.81
Batch: 80; loss: 0.47; acc: 0.92
Batch: 100; loss: 0.7; acc: 0.84
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.76; acc: 0.81
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.43; acc: 0.81
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.86
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.32568720666466244; val_accuracy: 0.8979896496815286 

The current subspace-distance is: 0.00012460308789741248 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.47; acc: 0.88
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.54; acc: 0.84
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.83
Batch: 680; loss: 0.5; acc: 0.81
Batch: 700; loss: 0.66; acc: 0.83
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.32440825395143713; val_accuracy: 0.897093949044586 

The current subspace-distance is: 0.00012592534767463803 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.51; acc: 0.89
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.68; acc: 0.86
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.54; acc: 0.91
Batch: 360; loss: 0.64; acc: 0.83
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.45; acc: 0.94
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.88
Batch: 720; loss: 0.51; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.32422162015821526; val_accuracy: 0.8980891719745223 

The current subspace-distance is: 0.00012756316573359072 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.66; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.81
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.32427908821850066; val_accuracy: 0.8980891719745223 

The current subspace-distance is: 0.0001276069669984281 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.75; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.54; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.5; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.64; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.32483522328221875; val_accuracy: 0.8983877388535032 

The current subspace-distance is: 0.00012823488214053214 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.62; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.84
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.84
Batch: 400; loss: 0.59; acc: 0.83
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.6; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.72; acc: 0.75
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.3254699474971765; val_accuracy: 0.8977906050955414 

The current subspace-distance is: 0.000129947075038217 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.57; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.46; acc: 0.86
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.51; acc: 0.83
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.86
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.58; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3245677641432756; val_accuracy: 0.8976910828025477 

The current subspace-distance is: 0.00013193482300266623 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_210_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 46404
elements in E: 9773720
fraction nonzero: 0.004747833987468436
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.27; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.26; acc: 0.19
Batch: 240; loss: 2.25; acc: 0.23
Batch: 260; loss: 2.25; acc: 0.19
Batch: 280; loss: 2.23; acc: 0.38
Batch: 300; loss: 2.21; acc: 0.34
Batch: 320; loss: 2.22; acc: 0.27
Batch: 340; loss: 2.19; acc: 0.27
Batch: 360; loss: 2.14; acc: 0.5
Batch: 380; loss: 2.1; acc: 0.5
Batch: 400; loss: 2.0; acc: 0.36
Batch: 420; loss: 1.79; acc: 0.59
Batch: 440; loss: 1.53; acc: 0.53
Batch: 460; loss: 1.52; acc: 0.48
Batch: 480; loss: 1.2; acc: 0.62
Batch: 500; loss: 1.06; acc: 0.58
Batch: 520; loss: 0.96; acc: 0.66
Batch: 540; loss: 1.43; acc: 0.53
Batch: 560; loss: 0.73; acc: 0.75
Batch: 580; loss: 0.99; acc: 0.69
Batch: 600; loss: 0.81; acc: 0.73
Batch: 620; loss: 0.72; acc: 0.75
Batch: 640; loss: 0.95; acc: 0.7
Batch: 660; loss: 0.84; acc: 0.73
Batch: 680; loss: 0.99; acc: 0.73
Batch: 700; loss: 0.88; acc: 0.7
Batch: 720; loss: 0.75; acc: 0.73
Batch: 740; loss: 1.06; acc: 0.7
Batch: 760; loss: 0.57; acc: 0.78
Batch: 780; loss: 0.72; acc: 0.75
Train Epoch over. train_loss: 1.65; train_accuracy: 0.43 

Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.77
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.67; acc: 0.75
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 1.03; acc: 0.66
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.6219301795124248; val_accuracy: 0.8021496815286624 

The current subspace-distance is: 1.1319161785650067e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.77
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 1.07; acc: 0.67
Batch: 60; loss: 0.57; acc: 0.78
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.72; acc: 0.78
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.77; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.91
Batch: 220; loss: 0.72; acc: 0.8
Batch: 240; loss: 0.87; acc: 0.77
Batch: 260; loss: 0.76; acc: 0.78
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.57; acc: 0.75
Batch: 320; loss: 0.52; acc: 0.89
Batch: 340; loss: 0.69; acc: 0.81
Batch: 360; loss: 0.75; acc: 0.78
Batch: 380; loss: 0.56; acc: 0.83
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.84
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.68; acc: 0.83
Batch: 500; loss: 0.62; acc: 0.81
Batch: 520; loss: 0.69; acc: 0.77
Batch: 540; loss: 0.4; acc: 0.81
Batch: 560; loss: 0.75; acc: 0.75
Batch: 580; loss: 0.62; acc: 0.83
Batch: 600; loss: 0.6; acc: 0.83
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.78; acc: 0.75
Batch: 660; loss: 0.54; acc: 0.84
Batch: 680; loss: 0.68; acc: 0.78
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.71; acc: 0.77
Batch: 740; loss: 0.63; acc: 0.84
Batch: 760; loss: 0.61; acc: 0.81
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.87; acc: 0.77
Batch: 40; loss: 0.52; acc: 0.78
Batch: 60; loss: 0.89; acc: 0.72
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.72; acc: 0.77
Batch: 120; loss: 0.97; acc: 0.69
Batch: 140; loss: 0.66; acc: 0.69
Val Epoch over. val_loss: 0.7476094182889172; val_accuracy: 0.7580613057324841 

The current subspace-distance is: 2.018217674049083e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.02; acc: 0.69
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.65; acc: 0.75
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.45; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.78
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.6; acc: 0.83
Batch: 220; loss: 0.82; acc: 0.72
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.4; acc: 0.94
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.53; acc: 0.84
Batch: 480; loss: 0.52; acc: 0.78
Batch: 500; loss: 0.68; acc: 0.83
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.59; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.52; acc: 0.81
Batch: 660; loss: 0.78; acc: 0.81
Batch: 680; loss: 0.83; acc: 0.72
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.86; acc: 0.78
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.5110694647404799; val_accuracy: 0.8396695859872612 

The current subspace-distance is: 2.6805988454725593e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.47; acc: 0.81
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.83
Batch: 200; loss: 0.64; acc: 0.8
Batch: 220; loss: 0.43; acc: 0.83
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 1.11; acc: 0.78
Batch: 300; loss: 0.63; acc: 0.8
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.7; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.81
Batch: 460; loss: 0.69; acc: 0.75
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.86
Batch: 540; loss: 0.57; acc: 0.84
Batch: 560; loss: 0.83; acc: 0.77
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.95
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.7; acc: 0.8
Batch: 660; loss: 0.7; acc: 0.84
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.47; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 1.01; acc: 0.73
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.64; acc: 0.77
Batch: 60; loss: 1.08; acc: 0.67
Batch: 80; loss: 0.76; acc: 0.84
Batch: 100; loss: 0.95; acc: 0.77
Batch: 120; loss: 1.11; acc: 0.7
Batch: 140; loss: 0.91; acc: 0.67
Val Epoch over. val_loss: 0.9430220504854895; val_accuracy: 0.7100915605095541 

The current subspace-distance is: 3.205436223652214e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.18; acc: 0.66
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.68; acc: 0.84
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.65; acc: 0.75
Batch: 120; loss: 0.83; acc: 0.75
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.45; acc: 0.83
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.94
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.54; acc: 0.75
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.69; acc: 0.78
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.61; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.84
Batch: 600; loss: 0.46; acc: 0.84
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.51; acc: 0.81
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.62; acc: 0.78
Batch: 740; loss: 0.33; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 1.16; acc: 0.67
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 1.16; acc: 0.7
Batch: 80; loss: 0.96; acc: 0.78
Batch: 100; loss: 0.81; acc: 0.7
Batch: 120; loss: 1.25; acc: 0.69
Batch: 140; loss: 0.63; acc: 0.77
Val Epoch over. val_loss: 0.8093926204237968; val_accuracy: 0.7622412420382165 

The current subspace-distance is: 3.77291944460012e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.73
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.75; acc: 0.81
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.81
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.47; acc: 0.83
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.76; acc: 0.78
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.88
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.55; acc: 0.8
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.57; acc: 0.81
Batch: 600; loss: 0.39; acc: 0.94
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.84
Batch: 680; loss: 0.44; acc: 0.8
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.75; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.86
Val Epoch over. val_loss: 0.42360510919124456; val_accuracy: 0.8675358280254777 

The current subspace-distance is: 4.187255763099529e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.83
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.57; acc: 0.81
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.61; acc: 0.83
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.79; acc: 0.75
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.65; acc: 0.77
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.68; acc: 0.8
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.48; acc: 0.8
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.78; acc: 0.72
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.46; acc: 0.89
Batch: 620; loss: 0.63; acc: 0.81
Batch: 640; loss: 0.44; acc: 0.81
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.83
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.377280140141393; val_accuracy: 0.884952229299363 

The current subspace-distance is: 4.595003338181414e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.54; acc: 0.84
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.62; acc: 0.78
Batch: 300; loss: 0.55; acc: 0.77
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.63; acc: 0.83
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.57; acc: 0.84
Batch: 420; loss: 0.51; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.26; acc: 0.95
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.83
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.75
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.77; acc: 0.73
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.75; acc: 0.83
Batch: 140; loss: 0.52; acc: 0.83
Val Epoch over. val_loss: 0.5217661449484005; val_accuracy: 0.8363853503184714 

The current subspace-distance is: 4.9289490561932325e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.61; acc: 0.81
Batch: 160; loss: 0.27; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.81
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.64; acc: 0.83
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.59; acc: 0.84
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.83
Batch: 520; loss: 0.59; acc: 0.78
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.78
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.46; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.67; acc: 0.83
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4056723723840562; val_accuracy: 0.8763933121019108 

The current subspace-distance is: 5.386405609897338e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.69; acc: 0.78
Batch: 40; loss: 0.65; acc: 0.81
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.5; acc: 0.81
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.67; acc: 0.81
Batch: 260; loss: 0.51; acc: 0.81
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.56; acc: 0.86
Batch: 360; loss: 0.81; acc: 0.8
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.71; acc: 0.83
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.84
Batch: 600; loss: 0.51; acc: 0.89
Batch: 620; loss: 0.45; acc: 0.89
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.84
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.83
Batch: 760; loss: 0.56; acc: 0.8
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.28; acc: 0.92
Val Epoch over. val_loss: 0.4152557755446738; val_accuracy: 0.8690286624203821 

The current subspace-distance is: 5.7538643886800855e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.81; acc: 0.8
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.81
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.84
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.78; acc: 0.8
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.8
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.3549934877142025; val_accuracy: 0.8942078025477707 

The current subspace-distance is: 5.998280175845139e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.86
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.48; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.57; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.58; acc: 0.83
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.73; acc: 0.8
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.84
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3649550331341233; val_accuracy: 0.886046974522293 

The current subspace-distance is: 6.268644210649654e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.63; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.97
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.43; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.34000448085320223; val_accuracy: 0.8977906050955414 

The current subspace-distance is: 6.56836709822528e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.35; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.97
Batch: 760; loss: 0.4; acc: 0.83
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.37095871738567476; val_accuracy: 0.8810708598726115 

The current subspace-distance is: 6.8645465944428e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.83
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.54; acc: 0.8
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.5; acc: 0.84
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.35; acc: 0.84
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.3519599926035116; val_accuracy: 0.8916202229299363 

The current subspace-distance is: 7.223202555906028e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.49; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.83
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.47; acc: 0.83
Batch: 520; loss: 0.46; acc: 0.81
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.88
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.53; acc: 0.84
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.39; acc: 0.8
Batch: 680; loss: 0.41; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.4; acc: 0.81
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.36025424460601657; val_accuracy: 0.8859474522292994 

The current subspace-distance is: 7.494429155485705e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.59; acc: 0.84
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.25; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.54; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.86
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35039987218133206; val_accuracy: 0.8909235668789809 

The current subspace-distance is: 7.685973832849413e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.59; acc: 0.83
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.56; acc: 0.81
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.52; acc: 0.81
Batch: 600; loss: 0.49; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.2; acc: 0.88
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.86
Batch: 700; loss: 0.59; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.62; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.21; acc: 0.88
Val Epoch over. val_loss: 0.369050486167525; val_accuracy: 0.8846536624203821 

The current subspace-distance is: 7.926832040539011e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.35; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.55; acc: 0.89
Batch: 580; loss: 0.53; acc: 0.86
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.3323523365198427; val_accuracy: 0.8972929936305732 

The current subspace-distance is: 8.175916445907205e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.57; acc: 0.81
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.45; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.52; acc: 0.83
Batch: 480; loss: 0.43; acc: 0.84
Batch: 500; loss: 0.58; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.84
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.43; acc: 0.81
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3559032544778411; val_accuracy: 0.88953025477707 

The current subspace-distance is: 8.413326577283442e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.49; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.35; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.44; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.32472227276510496; val_accuracy: 0.8996815286624203 

The current subspace-distance is: 8.602156594861299e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.58; acc: 0.78
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.51; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.92
Batch: 460; loss: 0.55; acc: 0.8
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.59; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.86
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.36; acc: 0.84
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3303067361473278; val_accuracy: 0.8960987261146497 

The current subspace-distance is: 8.84277542354539e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.44; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.83
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3269376149223109; val_accuracy: 0.8986863057324841 

The current subspace-distance is: 9.057973511517048e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.48; acc: 0.81
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.88
Batch: 280; loss: 0.52; acc: 0.8
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.81
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.84
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.38; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.336305590714239; val_accuracy: 0.895203025477707 

The current subspace-distance is: 9.188349940814078e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.47; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.56; acc: 0.81
Batch: 240; loss: 0.77; acc: 0.84
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.79; acc: 0.83
Batch: 400; loss: 0.21; acc: 0.97
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.52; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3293538322779024; val_accuracy: 0.8979896496815286 

The current subspace-distance is: 9.346532897325233e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.83
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.83
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.58; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.55; acc: 0.78
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3221653481577612; val_accuracy: 0.8995820063694268 

The current subspace-distance is: 9.56548101385124e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.86
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.56; acc: 0.83
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.74; acc: 0.78
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.84
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.49; acc: 0.83
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31918444033640964; val_accuracy: 0.9021695859872612 

The current subspace-distance is: 9.701724047772586e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.38; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.63; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.3308941876147963; val_accuracy: 0.8964968152866242 

The current subspace-distance is: 9.885142935672775e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.68; acc: 0.8
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.54; acc: 0.8
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3315786155308508; val_accuracy: 0.8975915605095541 

The current subspace-distance is: 0.00010093390301335603 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.55; acc: 0.86
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.54; acc: 0.88
Batch: 300; loss: 0.5; acc: 0.8
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.81
Batch: 640; loss: 0.74; acc: 0.83
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3426149261130649; val_accuracy: 0.8914211783439491 

The current subspace-distance is: 0.00010313177335774526 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.95
Batch: 220; loss: 0.69; acc: 0.77
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.95
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.42; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31534085835620856; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 0.00010460160410730168 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.81
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.51; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.83
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.64; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.31862526937465; val_accuracy: 0.9000796178343949 

The current subspace-distance is: 0.00010589283192530274 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.23; acc: 0.97
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.52; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.65; acc: 0.84
Batch: 540; loss: 0.58; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.31738166520549993; val_accuracy: 0.9013734076433121 

The current subspace-distance is: 0.000107931176899001 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.86
Batch: 40; loss: 0.51; acc: 0.89
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.72; acc: 0.81
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.62; acc: 0.83
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.84
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.92
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.23; acc: 0.98
Batch: 720; loss: 0.46; acc: 0.81
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31763225950443064; val_accuracy: 0.9012738853503185 

The current subspace-distance is: 0.0001087906930479221 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.52; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.5; acc: 0.81
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3177818091716736; val_accuracy: 0.9021695859872612 

The current subspace-distance is: 0.0001106587951653637 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.55; acc: 0.8
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.53; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.5; acc: 0.84
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.73; acc: 0.84
Batch: 460; loss: 0.63; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.83
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.31988212228960294; val_accuracy: 0.9007762738853503 

The current subspace-distance is: 0.00011253908451180905 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.84
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.58; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.52; acc: 0.78
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.321897561050904; val_accuracy: 0.8994824840764332 

The current subspace-distance is: 0.00011385728430468589 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.59; acc: 0.83
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.66; acc: 0.86
Batch: 300; loss: 0.38; acc: 0.83
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.36; acc: 0.84
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31701036490452517; val_accuracy: 0.9001791401273885 

The current subspace-distance is: 0.0001152370241470635 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.84
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.98
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.89
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.31; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3153843248061314; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 0.00011650773376459256 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.59; acc: 0.8
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.98
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31692603705035655; val_accuracy: 0.9018710191082803 

The current subspace-distance is: 0.00011798490595538169 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.37; acc: 0.83
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.84
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.95
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31493335758235047; val_accuracy: 0.9019705414012739 

The current subspace-distance is: 0.00011954950605286285 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.5; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.31510929810773036; val_accuracy: 0.9019705414012739 

The current subspace-distance is: 0.00012141472689108923 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.86
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.58; acc: 0.88
Batch: 220; loss: 0.59; acc: 0.88
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.48; acc: 0.83
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.11; acc: 1.0
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.83
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3147228423767029; val_accuracy: 0.901671974522293 

The current subspace-distance is: 0.00012263402459211648 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.37; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.35; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.48; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.81
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.54; acc: 0.81
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.31619442482093335; val_accuracy: 0.9021695859872612 

The current subspace-distance is: 0.00012434361269697547 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.49; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.54; acc: 0.91
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.52; acc: 0.8
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3145554936520613; val_accuracy: 0.9020700636942676 

The current subspace-distance is: 0.00012592347047757357 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.15; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.54; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.97
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.69; acc: 0.86
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3148426023922908; val_accuracy: 0.9026671974522293 

The current subspace-distance is: 0.00012797162344213575 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.86
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.46; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.35; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.84
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.314114034697888; val_accuracy: 0.9009753184713376 

The current subspace-distance is: 0.00013095830217935145 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.49; acc: 0.86
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.6; acc: 0.84
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.45; acc: 0.81
Batch: 720; loss: 0.37; acc: 0.83
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3144019038244418; val_accuracy: 0.9020700636942676 

The current subspace-distance is: 0.00013246704475022852 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.44; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.88
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.37; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.4; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.62; acc: 0.8
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.31489028943002606; val_accuracy: 0.9018710191082803 

The current subspace-distance is: 0.00013416509318631142 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.48; acc: 0.81
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.42; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.84
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.71; acc: 0.83
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3157095941863242; val_accuracy: 0.9007762738853503 

The current subspace-distance is: 0.00013430777471512556 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_220_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 48738
elements in E: 10217980
fraction nonzero: 0.00476982730441829
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.05
Batch: 140; loss: 2.29; acc: 0.06
Batch: 160; loss: 2.26; acc: 0.25
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.27; acc: 0.25
Batch: 220; loss: 2.26; acc: 0.31
Batch: 240; loss: 2.24; acc: 0.31
Batch: 260; loss: 2.23; acc: 0.39
Batch: 280; loss: 2.22; acc: 0.42
Batch: 300; loss: 2.18; acc: 0.44
Batch: 320; loss: 2.2; acc: 0.39
Batch: 340; loss: 2.16; acc: 0.41
Batch: 360; loss: 2.09; acc: 0.48
Batch: 380; loss: 2.1; acc: 0.34
Batch: 400; loss: 2.06; acc: 0.31
Batch: 420; loss: 1.86; acc: 0.38
Batch: 440; loss: 1.69; acc: 0.58
Batch: 460; loss: 1.49; acc: 0.58
Batch: 480; loss: 1.2; acc: 0.61
Batch: 500; loss: 1.11; acc: 0.67
Batch: 520; loss: 0.77; acc: 0.73
Batch: 540; loss: 1.0; acc: 0.66
Batch: 560; loss: 0.87; acc: 0.78
Batch: 580; loss: 0.96; acc: 0.72
Batch: 600; loss: 0.79; acc: 0.75
Batch: 620; loss: 0.85; acc: 0.78
Batch: 640; loss: 0.97; acc: 0.58
Batch: 660; loss: 0.97; acc: 0.72
Batch: 680; loss: 1.12; acc: 0.67
Batch: 700; loss: 1.04; acc: 0.61
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.86; acc: 0.77
Batch: 760; loss: 0.63; acc: 0.81
Batch: 780; loss: 1.03; acc: 0.64
Train Epoch over. train_loss: 1.66; train_accuracy: 0.45 

Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.77; acc: 0.72
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.73; acc: 0.77
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.8; acc: 0.72
Batch: 140; loss: 0.48; acc: 0.81
Val Epoch over. val_loss: 0.6868137474272661; val_accuracy: 0.7752786624203821 

The current subspace-distance is: 1.1621050362009555e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.68; acc: 0.78
Batch: 20; loss: 0.76; acc: 0.8
Batch: 40; loss: 1.11; acc: 0.73
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.89; acc: 0.7
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.66; acc: 0.7
Batch: 160; loss: 0.72; acc: 0.75
Batch: 180; loss: 0.8; acc: 0.75
Batch: 200; loss: 0.59; acc: 0.75
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.75; acc: 0.75
Batch: 260; loss: 0.71; acc: 0.8
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.78
Batch: 320; loss: 0.45; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.86
Batch: 360; loss: 0.67; acc: 0.73
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.58; acc: 0.81
Batch: 480; loss: 0.58; acc: 0.89
Batch: 500; loss: 0.85; acc: 0.72
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.75; acc: 0.77
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.58; acc: 0.81
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.51; acc: 0.84
Batch: 740; loss: 0.56; acc: 0.83
Batch: 760; loss: 0.71; acc: 0.78
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.55; train_accuracy: 0.82 

Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.7; acc: 0.77
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.75; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.5133639161184336; val_accuracy: 0.8435509554140127 

The current subspace-distance is: 2.0992529243812896e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.78
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.6; acc: 0.77
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.5; acc: 0.8
Batch: 180; loss: 0.71; acc: 0.81
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.81
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.57; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.39; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.6; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.65; acc: 0.81
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.83
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.68; acc: 0.78
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.83; acc: 0.75
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.72; acc: 0.8
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.69; acc: 0.7
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4494469699206626; val_accuracy: 0.8588773885350318 

The current subspace-distance is: 2.6960542527376674e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.8
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.83
Batch: 440; loss: 0.36; acc: 0.84
Batch: 460; loss: 0.61; acc: 0.77
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.88
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.7; acc: 0.73
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.91
Batch: 620; loss: 0.59; acc: 0.83
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.62; acc: 0.81
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.47; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.67; acc: 0.73
Batch: 20; loss: 0.74; acc: 0.77
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 1.14; acc: 0.67
Batch: 80; loss: 0.5; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 0.82; acc: 0.78
Batch: 140; loss: 0.27; acc: 0.92
Val Epoch over. val_loss: 0.7081721865447463; val_accuracy: 0.7777667197452229 

The current subspace-distance is: 3.24571410601493e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.75
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.81
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.49; acc: 0.88
Batch: 300; loss: 0.48; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.47; acc: 0.8
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.84; acc: 0.8
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 1.03; acc: 0.77
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.85; acc: 0.7
Batch: 40; loss: 0.23; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.83
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.33; acc: 0.84
Batch: 120; loss: 0.97; acc: 0.7
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.5159912358993178; val_accuracy: 0.8304140127388535 

The current subspace-distance is: 3.8078880606917664e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.77
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.6; acc: 0.83
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.47; acc: 0.88
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.59; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.53; acc: 0.81
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.65; acc: 0.72
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.47; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.1; acc: 1.0
Val Epoch over. val_loss: 0.36515328821957493; val_accuracy: 0.8854498407643312 

The current subspace-distance is: 4.223344149067998e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.66; acc: 0.84
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.45; acc: 0.94
Batch: 180; loss: 0.67; acc: 0.83
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.78
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.64; acc: 0.78
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.68; acc: 0.81
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.54; acc: 0.84
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.48; acc: 0.81
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.40328773376858157; val_accuracy: 0.8740047770700637 

The current subspace-distance is: 4.6870511141605675e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.44; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.46; acc: 0.81
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.81
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.51; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.78; acc: 0.83
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.55; acc: 0.8
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.83; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.88
Batch: 120; loss: 1.1; acc: 0.73
Batch: 140; loss: 0.26; acc: 0.94
Val Epoch over. val_loss: 0.5208008637663665; val_accuracy: 0.841859076433121 

The current subspace-distance is: 5.134807724971324e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.4; acc: 0.84
Batch: 260; loss: 0.54; acc: 0.81
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.69; acc: 0.75
Batch: 420; loss: 0.69; acc: 0.83
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.88
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.45; acc: 0.81
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.81
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.329116468145779; val_accuracy: 0.8988853503184714 

The current subspace-distance is: 5.526029781321995e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.61; acc: 0.83
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.42; acc: 0.83
Batch: 240; loss: 0.54; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.89
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.51; acc: 0.92
Batch: 360; loss: 0.52; acc: 0.88
Batch: 380; loss: 0.41; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.4; acc: 0.81
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.46; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.43; acc: 0.83
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.79; acc: 0.83
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3467700620460662; val_accuracy: 0.890625 

The current subspace-distance is: 5.904875069973059e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.62; acc: 0.83
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.42; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.6; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.92
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.35354883427832534; val_accuracy: 0.8889331210191083 

The current subspace-distance is: 6.352891068672761e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.81
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.64; acc: 0.81
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.74; acc: 0.78
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.38729123410525595; val_accuracy: 0.8834593949044586 

The current subspace-distance is: 6.666735862381756e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.42; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.47; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3707104284482397; val_accuracy: 0.8863455414012739 

The current subspace-distance is: 7.050118438201025e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.27; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.25; acc: 0.97
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.75; acc: 0.72
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.72
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.36597536779513024; val_accuracy: 0.8857484076433121 

The current subspace-distance is: 7.287679909495637e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.62; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.86
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.31748042730199305; val_accuracy: 0.9021695859872612 

The current subspace-distance is: 7.471986464224756e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.84
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.56; acc: 0.88
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.81
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.46; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.71; acc: 0.8
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.30055751725082186; val_accuracy: 0.9058519108280255 

The current subspace-distance is: 7.720349094597623e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.77
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.6; acc: 0.86
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.68; acc: 0.83
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.3119793149174019; val_accuracy: 0.9014729299363057 

The current subspace-distance is: 7.883292710175738e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.83
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.84
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.56; acc: 0.86
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.83
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.73; acc: 0.81
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.28725374945599563; val_accuracy: 0.9130175159235668 

The current subspace-distance is: 8.18680418888107e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.46; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.47; acc: 0.81
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.38; acc: 0.84
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2858882839702497; val_accuracy: 0.9142117834394905 

The current subspace-distance is: 8.534041990060359e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.47; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.74; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.66; acc: 0.83
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3033929912100552; val_accuracy: 0.9059514331210191 

The current subspace-distance is: 8.693067502463236e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.68; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.52; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.51; acc: 0.81
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.27982710131034727; val_accuracy: 0.9150079617834395 

The current subspace-distance is: 8.96532874321565e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.97
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.45; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.28894854277657095; val_accuracy: 0.9117237261146497 

The current subspace-distance is: 9.1955327661708e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.86
Batch: 40; loss: 0.55; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.18; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.71; acc: 0.83
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2745425243428938; val_accuracy: 0.9159036624203821 

The current subspace-distance is: 9.46112340898253e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.14; acc: 0.98
Batch: 280; loss: 0.53; acc: 0.86
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.86
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.28256736686275263; val_accuracy: 0.912718949044586 

The current subspace-distance is: 9.668461279943585e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.67; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.84
Batch: 360; loss: 0.41; acc: 0.92
Batch: 380; loss: 0.68; acc: 0.77
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.65; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.28048100258419467; val_accuracy: 0.9140127388535032 

The current subspace-distance is: 9.854501695372164e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.97
Batch: 520; loss: 0.08; acc: 1.0
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.83
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.27443653644080374; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 0.00010065188689623028 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.57; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.83
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.52; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.57; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.27120043781058045; val_accuracy: 0.9183917197452229 

The current subspace-distance is: 0.0001027264806907624 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.91
Batch: 140; loss: 0.51; acc: 0.8
Batch: 160; loss: 0.4; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.34; acc: 0.83
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.23; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.89
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3109499451935671; val_accuracy: 0.9032643312101911 

The current subspace-distance is: 0.00010511169239180163 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.35; acc: 0.84
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.83
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.62; acc: 0.81
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.55; acc: 0.84
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.62; acc: 0.84
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.29285486282151973; val_accuracy: 0.910031847133758 

The current subspace-distance is: 0.00010645185102475807 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.81
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.97
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.56; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2811307711111512; val_accuracy: 0.9137141719745223 

The current subspace-distance is: 0.00010996296623488888 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.58; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.68; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2685880543557322; val_accuracy: 0.9175955414012739 

The current subspace-distance is: 0.00011096306116087362 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.19; acc: 0.98
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2695695964773749; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 0.0001128906587837264 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.73; acc: 0.83
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.5; acc: 0.88
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2689513740408572; val_accuracy: 0.9178941082802548 

The current subspace-distance is: 0.00011529874609550461 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.68; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.52; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.83
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.88
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.84
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.39; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.26913204101050736; val_accuracy: 0.919187898089172 

The current subspace-distance is: 0.00011764775990741327 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.4; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.75; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.83
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.27253125921176496; val_accuracy: 0.9161027070063694 

The current subspace-distance is: 0.0001189759059343487 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.26986238642767735; val_accuracy: 0.918093152866242 

The current subspace-distance is: 0.0001206895976793021 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.52; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.97
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.8
Batch: 760; loss: 0.64; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.27306617772693087; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 0.0001228482142323628 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.84
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.45; acc: 0.91
Batch: 280; loss: 0.59; acc: 0.77
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.35; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.86
Batch: 440; loss: 0.28; acc: 0.97
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2721529451857327; val_accuracy: 0.9156050955414012 

The current subspace-distance is: 0.00012584237265400589 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.98
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.42; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2672300333524965; val_accuracy: 0.9185907643312102 

The current subspace-distance is: 0.00012829907063860446 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.59; acc: 0.8
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.72; acc: 0.8
Batch: 300; loss: 0.44; acc: 0.83
Batch: 320; loss: 0.23; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.98
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.27201445006830677; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 0.00012920582958031446 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.55; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.88
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.6; acc: 0.86
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.38; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.28; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.26612236737540573; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 0.00012937966675963253 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.88
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.84
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2665434647944702; val_accuracy: 0.9184912420382165 

The current subspace-distance is: 0.0001307808270212263 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.57; acc: 0.81
Batch: 220; loss: 0.43; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.49; acc: 0.84
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2667663156464221; val_accuracy: 0.9189888535031847 

The current subspace-distance is: 0.00013222619600128382 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.09; acc: 1.0
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.29; acc: 0.97
Batch: 500; loss: 0.38; acc: 0.81
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.26761745269985715; val_accuracy: 0.918093152866242 

The current subspace-distance is: 0.00013345401384867728 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.95
Batch: 40; loss: 0.29; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.39; acc: 0.83
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.77; acc: 0.86
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.83; acc: 0.83
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.26711745688300226; val_accuracy: 0.9200835987261147 

The current subspace-distance is: 0.0001363517512800172 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.45; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.83
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.53; acc: 0.83
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2662789810235333; val_accuracy: 0.9187898089171974 

The current subspace-distance is: 0.0001387471129419282 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.47; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.97
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2660318880466519; val_accuracy: 0.9190883757961783 

The current subspace-distance is: 0.0001397866872139275 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.26628217181772185; val_accuracy: 0.9188893312101911 

The current subspace-distance is: 0.0001425205555278808 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.52; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.27; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.23; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.7; acc: 0.8
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2658623559459759; val_accuracy: 0.9192874203821656 

The current subspace-distance is: 0.0001440206542611122 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.52; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.47; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.47; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.57; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2684238887611468; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 0.0001455897290725261 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_230_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 50719
elements in E: 10662240
fraction nonzero: 0.004756880355347469
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.11
Batch: 160; loss: 2.27; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.09
Batch: 220; loss: 2.26; acc: 0.17
Batch: 240; loss: 2.25; acc: 0.14
Batch: 260; loss: 2.24; acc: 0.17
Batch: 280; loss: 2.22; acc: 0.36
Batch: 300; loss: 2.18; acc: 0.44
Batch: 320; loss: 2.2; acc: 0.31
Batch: 340; loss: 2.14; acc: 0.39
Batch: 360; loss: 2.07; acc: 0.56
Batch: 380; loss: 1.98; acc: 0.53
Batch: 400; loss: 1.78; acc: 0.45
Batch: 420; loss: 1.57; acc: 0.56
Batch: 440; loss: 1.17; acc: 0.69
Batch: 460; loss: 1.29; acc: 0.58
Batch: 480; loss: 1.0; acc: 0.62
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.57; acc: 0.81
Batch: 540; loss: 0.77; acc: 0.69
Batch: 560; loss: 0.62; acc: 0.77
Batch: 580; loss: 0.83; acc: 0.81
Batch: 600; loss: 0.44; acc: 0.84
Batch: 620; loss: 0.7; acc: 0.8
Batch: 640; loss: 0.69; acc: 0.73
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.85; acc: 0.81
Batch: 700; loss: 0.75; acc: 0.73
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.71; acc: 0.77
Batch: 760; loss: 0.5; acc: 0.77
Batch: 780; loss: 0.72; acc: 0.78
Train Epoch over. train_loss: 1.54; train_accuracy: 0.47 

Batch: 0; loss: 0.44; acc: 0.81
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.4883733424980929; val_accuracy: 0.8441480891719745 

The current subspace-distance is: 1.2145727851020638e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.85; acc: 0.8
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.72; acc: 0.78
Batch: 160; loss: 0.38; acc: 0.83
Batch: 180; loss: 0.71; acc: 0.75
Batch: 200; loss: 0.52; acc: 0.81
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.57; acc: 0.75
Batch: 260; loss: 0.78; acc: 0.83
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.94
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.56; acc: 0.86
Batch: 460; loss: 0.55; acc: 0.83
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.87; acc: 0.73
Batch: 520; loss: 0.58; acc: 0.78
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.58; acc: 0.8
Batch: 580; loss: 0.54; acc: 0.81
Batch: 600; loss: 0.61; acc: 0.83
Batch: 620; loss: 0.53; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.55; acc: 0.8
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.48; acc: 0.89
Batch: 760; loss: 0.67; acc: 0.8
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.3960268299338544; val_accuracy: 0.8741042993630573 

The current subspace-distance is: 2.124811362591572e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.68; acc: 0.8
Batch: 200; loss: 0.43; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.37; acc: 0.84
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.84
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.35; acc: 0.94
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.67; acc: 0.81
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.86; acc: 0.75
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.34460747137570835; val_accuracy: 0.8939092356687898 

The current subspace-distance is: 2.7848307581734844e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.81
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.37; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.56; acc: 0.84
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.59; acc: 0.86
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.43; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.52; acc: 0.77
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.7; acc: 0.75
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.5579359089587904; val_accuracy: 0.8245421974522293 

The current subspace-distance is: 3.33728312398307e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.92; acc: 0.7
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.68; acc: 0.83
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.4; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.84
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.48; acc: 0.81
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.83
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.47; acc: 0.83
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.53; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.51; acc: 0.78
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.75; acc: 0.7
Batch: 20; loss: 0.71; acc: 0.67
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.67; acc: 0.77
Batch: 100; loss: 0.58; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.18; acc: 0.89
Val Epoch over. val_loss: 0.5538939533719591; val_accuracy: 0.8169785031847133 

The current subspace-distance is: 3.865406688419171e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.81; acc: 0.69
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.86; acc: 0.8
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.41; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.83
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.99; acc: 0.75
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.41697776369797956; val_accuracy: 0.8703224522292994 

The current subspace-distance is: 4.3440129957161844e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.83
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.52; acc: 0.86
Batch: 180; loss: 0.66; acc: 0.86
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.54; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.43; acc: 0.78
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2783838297436192; val_accuracy: 0.9141122611464968 

The current subspace-distance is: 4.767440987052396e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.59; acc: 0.83
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.81
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.39; acc: 0.83
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.84; acc: 0.78
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.82; acc: 0.69
Batch: 140; loss: 0.22; acc: 0.89
Val Epoch over. val_loss: 0.5367895311136155; val_accuracy: 0.828125 

The current subspace-distance is: 5.094250445836224e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.78
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.88
Batch: 140; loss: 0.43; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.83
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.4; acc: 0.84
Batch: 420; loss: 0.61; acc: 0.86
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.57; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.51; acc: 0.84
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.81
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.43; acc: 0.8
Batch: 20; loss: 0.27; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.92
Val Epoch over. val_loss: 0.3816610172296026; val_accuracy: 0.8743033439490446 

The current subspace-distance is: 5.5286458518821746e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.83
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.25; acc: 0.88
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.94
Batch: 360; loss: 0.75; acc: 0.8
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.47; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.30666733587718314; val_accuracy: 0.9076433121019108 

The current subspace-distance is: 5.918960596318357e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.38; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.28433652082161537; val_accuracy: 0.9131170382165605 

The current subspace-distance is: 6.183954246807843e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.83
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2739490698904369; val_accuracy: 0.9145103503184714 

The current subspace-distance is: 6.469204527093098e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.97
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.83
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2659620382129007; val_accuracy: 0.9219745222929936 

The current subspace-distance is: 6.815289816586301e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.48; acc: 0.88
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.86
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.45; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.38; acc: 0.81
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2995068601741912; val_accuracy: 0.9065485668789809 

The current subspace-distance is: 7.093229214660823e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.88
Batch: 620; loss: 0.49; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.88
Batch: 780; loss: 0.53; acc: 0.84
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.29061523881877305; val_accuracy: 0.9084394904458599 

The current subspace-distance is: 7.401048060273752e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.88
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.88
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.83
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.86
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.86
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.84
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2743928584323567; val_accuracy: 0.9167993630573248 

The current subspace-distance is: 7.694117084611207e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.55; acc: 0.81
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.59; acc: 0.86
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.54; acc: 0.81
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.86
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2573977617463868; val_accuracy: 0.9200835987261147 

The current subspace-distance is: 8.045146387303248e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.81
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.91
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.2; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.46; acc: 0.89
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2714505820612239; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 8.321288623847067e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.37; acc: 0.83
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.86
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.86
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24583076823289227; val_accuracy: 0.924562101910828 

The current subspace-distance is: 8.570680802222341e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.21; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.25669270580646336; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 8.772792352829129e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.98
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.24005549125800466; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 9.01666862773709e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.51; acc: 0.81
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.45; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24435978408926612; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 9.200444037560374e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.84
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.84
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2455064732652561; val_accuracy: 0.9230692675159236 

The current subspace-distance is: 9.452613448956981e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.89
Batch: 180; loss: 0.63; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.43; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23734264716411094; val_accuracy: 0.9262539808917197 

The current subspace-distance is: 9.69381580944173e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.68; acc: 0.86
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.6; acc: 0.83
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.07; acc: 1.0
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.62; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.23686810198483194; val_accuracy: 0.9255573248407644 

The current subspace-distance is: 9.929329826263711e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.27; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.34; acc: 0.83
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23946155073821165; val_accuracy: 0.9255573248407644 

The current subspace-distance is: 0.0001007847095024772 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.43; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23665193107667243; val_accuracy: 0.9261544585987261 

The current subspace-distance is: 0.00010338272113585845 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.55; acc: 0.86
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.91
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.07; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2576538969993971; val_accuracy: 0.9187898089171974 

The current subspace-distance is: 0.00010471314453752711 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.59; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24026013592815704; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 0.00010618609667290002 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.56; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.43; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23811448294266013; val_accuracy: 0.926453025477707 

The current subspace-distance is: 0.00010826707148225978 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.58; acc: 0.86
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.83
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.98
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2333899509565086; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 0.00010971078154398128 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.38; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2332641479980414; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 0.00011161368456669152 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.86
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.51; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.44; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.86
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2341847723931264; val_accuracy: 0.9271496815286624 

The current subspace-distance is: 0.00011382896627765149 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.49; acc: 0.89
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.45; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.94
Batch: 640; loss: 0.5; acc: 0.83
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23131669481184072; val_accuracy: 0.9287420382165605 

The current subspace-distance is: 0.00011498122330522165 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.41; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.57; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.97
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23179333374663524; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 0.00011689194798236713 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.38; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.89
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23185587560485124; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 0.00011889611778315157 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.86
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.94
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23177754095975; val_accuracy: 0.927547770700637 

The current subspace-distance is: 0.00012072597746737301 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.89
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.95
Batch: 280; loss: 0.59; acc: 0.89
Batch: 300; loss: 0.49; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23441361000013958; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 0.00012192899885121733 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.48; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.45; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2318223462837517; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 0.0001231370260939002 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.23265133235769667; val_accuracy: 0.9272492038216561 

The current subspace-distance is: 0.00012421027349773794 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.86
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.35; acc: 0.84
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23125144008808074; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 0.00012619518383871764 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.84
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2319316065567694; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 0.00012813757348340005 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.24; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.86
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.88
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2309716631937179; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 0.00012992792471777648 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23125703291148897; val_accuracy: 0.928343949044586 

The current subspace-distance is: 0.0001306615595240146 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.58; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.57; acc: 0.86
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2310158764575697; val_accuracy: 0.929140127388535 

The current subspace-distance is: 0.0001315668341703713 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.35; acc: 0.94
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.54; acc: 0.84
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23057940066050572; val_accuracy: 0.9296377388535032 

The current subspace-distance is: 0.00013360702723730356 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.09; acc: 1.0
Batch: 160; loss: 0.68; acc: 0.75
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23017908025319408; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 0.00013581823441199958 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23071792555652607; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 0.00013749347999691963 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.38; acc: 0.83
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.39; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.58; acc: 0.89
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.83
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.23079271987080574; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 0.00013918713375460356 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.3; acc: 0.97
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23111325049191522; val_accuracy: 0.928343949044586 

The current subspace-distance is: 0.0001399059983668849 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_240_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 52537
elements in E: 11106500
fraction nonzero: 0.004730293071624724
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.27; acc: 0.27
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.27; acc: 0.19
Batch: 220; loss: 2.25; acc: 0.25
Batch: 240; loss: 2.25; acc: 0.28
Batch: 260; loss: 2.24; acc: 0.17
Batch: 280; loss: 2.21; acc: 0.33
Batch: 300; loss: 2.2; acc: 0.22
Batch: 320; loss: 2.2; acc: 0.2
Batch: 340; loss: 2.14; acc: 0.28
Batch: 360; loss: 2.04; acc: 0.45
Batch: 380; loss: 2.01; acc: 0.38
Batch: 400; loss: 1.81; acc: 0.45
Batch: 420; loss: 1.47; acc: 0.73
Batch: 440; loss: 1.24; acc: 0.69
Batch: 460; loss: 1.18; acc: 0.61
Batch: 480; loss: 1.15; acc: 0.64
Batch: 500; loss: 0.89; acc: 0.66
Batch: 520; loss: 0.86; acc: 0.73
Batch: 540; loss: 0.73; acc: 0.75
Batch: 560; loss: 0.79; acc: 0.83
Batch: 580; loss: 0.95; acc: 0.73
Batch: 600; loss: 0.65; acc: 0.73
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.74; acc: 0.8
Batch: 660; loss: 0.65; acc: 0.8
Batch: 680; loss: 1.26; acc: 0.55
Batch: 700; loss: 0.77; acc: 0.72
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.68; acc: 0.78
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.83; acc: 0.73
Train Epoch over. train_loss: 1.55; train_accuracy: 0.46 

Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.89; acc: 0.73
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.5068584022818098; val_accuracy: 0.8446457006369427 

The current subspace-distance is: 1.2671955119003542e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.77
Batch: 40; loss: 1.16; acc: 0.67
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.62; acc: 0.83
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.52; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.72; acc: 0.83
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.88
Batch: 260; loss: 0.59; acc: 0.86
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.64; acc: 0.81
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.62; acc: 0.81
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.55; acc: 0.75
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.57; acc: 0.78
Batch: 580; loss: 0.5; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.67; acc: 0.78
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.78
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.49; acc: 0.8
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.64; acc: 0.77
Batch: 780; loss: 0.5; acc: 0.81
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.3598347330928608; val_accuracy: 0.8936106687898089 

The current subspace-distance is: 2.1876088794670068e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.54; acc: 0.81
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.84
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.64; acc: 0.81
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.37; acc: 0.94
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.421417597657556; val_accuracy: 0.8765923566878981 

The current subspace-distance is: 2.863416557374876e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.84
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.87; acc: 0.8
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.41; acc: 0.84
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.83
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.47; acc: 0.83
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.54; acc: 0.88
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 1.01; acc: 0.75
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.64; acc: 0.8
Batch: 60; loss: 0.71; acc: 0.84
Batch: 80; loss: 0.53; acc: 0.75
Batch: 100; loss: 0.74; acc: 0.73
Batch: 120; loss: 0.86; acc: 0.78
Batch: 140; loss: 0.36; acc: 0.89
Val Epoch over. val_loss: 0.8236354533464286; val_accuracy: 0.7502985668789809 

The current subspace-distance is: 3.451888187555596e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.73
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.54; acc: 0.78
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.59; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.57; acc: 0.77
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.31; acc: 0.84
Batch: 400; loss: 0.44; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.43; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.5; acc: 0.84
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.68; acc: 0.72
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.41195582441843237; val_accuracy: 0.8736066878980892 

The current subspace-distance is: 4.036238897242583e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.74; acc: 0.84
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.52; acc: 0.86
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.98
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.81
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.45; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.88
Batch: 680; loss: 0.2; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.31; acc: 0.84
Batch: 740; loss: 0.56; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.45; acc: 0.77
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.36827194591046897; val_accuracy: 0.8834593949044586 

The current subspace-distance is: 4.535037078312598e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.86
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.44; acc: 0.83
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.46; acc: 0.8
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.97; acc: 0.67
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.42495207279730757; val_accuracy: 0.8675358280254777 

The current subspace-distance is: 4.970097870682366e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.81
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.41; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.46; acc: 0.83
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.46; acc: 0.8
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.84
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.46; acc: 0.84
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.6; acc: 0.75
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 1.15; acc: 0.75
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.4233871162127537; val_accuracy: 0.8681329617834395 

The current subspace-distance is: 5.470436008181423e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.98
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.53; acc: 0.84
Batch: 420; loss: 0.47; acc: 0.8
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.68; acc: 0.84
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.84
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.3193101601520921; val_accuracy: 0.9056528662420382 

The current subspace-distance is: 5.86065580137074e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.53; acc: 0.89
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.58; acc: 0.81
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.55; acc: 0.84
Batch: 340; loss: 0.52; acc: 0.89
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2929066311401926; val_accuracy: 0.9116242038216561 

The current subspace-distance is: 6.283942639129236e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.88
Batch: 120; loss: 0.08; acc: 1.0
Batch: 140; loss: 0.22; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.54; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.84
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.61; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.95
Batch: 640; loss: 0.4; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.94
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.84
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.86; acc: 0.72
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2959974541975434; val_accuracy: 0.9128184713375797 

The current subspace-distance is: 6.683119136141613e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.08; acc: 1.0
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.52; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.52; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.43; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.89; acc: 0.73
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.3007877477842152; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 7.066733087413013e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.41; acc: 0.84
Batch: 560; loss: 0.33; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.83
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2998087569881397; val_accuracy: 0.9097332802547771 

The current subspace-distance is: 7.327175262616947e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.46; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.84
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.98
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.92
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3087214530700711; val_accuracy: 0.904359076433121 

The current subspace-distance is: 7.664818986086175e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.83
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.44; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.69; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.28163783195292114; val_accuracy: 0.915406050955414 

The current subspace-distance is: 8.015405182959512e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.83
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.43; acc: 0.83
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.51; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.86
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.95
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.95
Val Epoch over. val_loss: 0.28064948797320866; val_accuracy: 0.9130175159235668 

The current subspace-distance is: 8.383306703763083e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.92
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.3110051009400635; val_accuracy: 0.9025676751592356 

The current subspace-distance is: 8.688927482580766e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.57; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.64; acc: 0.75
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.46; acc: 0.8
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.65; acc: 0.84
Batch: 760; loss: 0.08; acc: 1.0
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.92
Val Epoch over. val_loss: 0.32789551661272714; val_accuracy: 0.8999800955414012 

The current subspace-distance is: 9.016751573653892e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.06; acc: 1.0
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.86
Batch: 600; loss: 0.15; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.2907939587191791; val_accuracy: 0.9104299363057324 

The current subspace-distance is: 9.305381536250934e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.83
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.54; acc: 0.88
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.38; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.298296980488642; val_accuracy: 0.9086385350318471 

The current subspace-distance is: 9.709643200039864e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.84
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2683603478844758; val_accuracy: 0.9184912420382165 

The current subspace-distance is: 9.865824540611356e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.47; acc: 0.83
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.98
Batch: 460; loss: 0.63; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2674571903315699; val_accuracy: 0.9156050955414012 

The current subspace-distance is: 0.00010100970393978059 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.84
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.84
Batch: 120; loss: 0.19; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.84
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.27006900925070615; val_accuracy: 0.9167993630573248 

The current subspace-distance is: 0.00010149493027711287 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.56; acc: 0.88
Batch: 200; loss: 0.66; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.54; acc: 0.84
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.27162586722024684; val_accuracy: 0.9147093949044586 

The current subspace-distance is: 0.00010415938595542684 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.92
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.3; acc: 0.86
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.64; acc: 0.86
Batch: 260; loss: 0.17; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.58; acc: 0.84
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2708911305400217; val_accuracy: 0.9161027070063694 

The current subspace-distance is: 0.00010595859930617735 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.51; acc: 0.81
Batch: 280; loss: 0.17; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.4; acc: 0.91
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.26772629149305593; val_accuracy: 0.9175955414012739 

The current subspace-distance is: 0.00010809685772983357 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.49; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.34; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.56; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.84
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.26750531356046153; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 0.00011044058919651434 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.97
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.84
Batch: 580; loss: 0.49; acc: 0.83
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.91
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2849627693130332; val_accuracy: 0.9142117834394905 

The current subspace-distance is: 0.00011147930490551516 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.21; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.2712550919241966; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 0.00011276470468146726 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.89
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.79; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2646754987442949; val_accuracy: 0.9185907643312102 

The current subspace-distance is: 0.00011479725071694702 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.86
Batch: 180; loss: 0.17; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.25886680541714285; val_accuracy: 0.9200835987261147 

The current subspace-distance is: 0.00011675933637889102 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.44; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25761195706428996; val_accuracy: 0.9215764331210191 

The current subspace-distance is: 0.00011880373494932428 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25626252518053266; val_accuracy: 0.9217754777070064 

The current subspace-distance is: 0.00012003713345620781 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.35; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.45; acc: 0.83
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2558878928328016; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 0.00012191814312245697 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.97
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.43; acc: 0.91
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.72
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25770258685206154; val_accuracy: 0.92078025477707 

The current subspace-distance is: 0.00012428151967469603 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.62; acc: 0.77
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.58; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.49; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.67; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.45; acc: 0.81
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25455874339885015; val_accuracy: 0.92296974522293 

The current subspace-distance is: 0.00012717740901280195 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.84
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.56; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.46; acc: 0.92
Batch: 540; loss: 0.65; acc: 0.84
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2555830900788687; val_accuracy: 0.9222730891719745 

The current subspace-distance is: 0.00012861622963100672 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.05; acc: 1.0
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.41; acc: 0.91
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.17; acc: 0.98
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.86
Batch: 480; loss: 0.28; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.86
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.09; acc: 1.0
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.21; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25577278670137094; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 0.00013004841457586735 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.25625737412435234; val_accuracy: 0.9221735668789809 

The current subspace-distance is: 0.00013147441495675594 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.58; acc: 0.84
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2584624652080475; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 0.00013264316658023745 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.47; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2548116496556504; val_accuracy: 0.9227707006369427 

The current subspace-distance is: 0.0001351639220956713 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.59; acc: 0.86
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2550160874654153; val_accuracy: 0.9227707006369427 

The current subspace-distance is: 0.00013678541290573776 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.58; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2549918668380209; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 0.00013803945330437273 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.51; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.54; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2551337169945999; val_accuracy: 0.92296974522293 

The current subspace-distance is: 0.00014124336303211749 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.83
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.39; acc: 0.84
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.86
Batch: 440; loss: 0.52; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.97
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25380527655220336; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 0.00014408165588974953 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.59; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2534847911328647; val_accuracy: 0.92296974522293 

The current subspace-distance is: 0.00014606238983105868 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.46; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.52; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.48; acc: 0.81
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2538534918218661; val_accuracy: 0.9227707006369427 

The current subspace-distance is: 0.00014793289301451296 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.47; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.51; acc: 0.84
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25428803122726973; val_accuracy: 0.9225716560509554 

The current subspace-distance is: 0.00014871371968183666 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.84
Batch: 340; loss: 0.36; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.84
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.83
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25422432537006723; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 0.00015012681251391768 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.86
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.86
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25406181719747317; val_accuracy: 0.9228702229299363 

The current subspace-distance is: 0.0001513081369921565 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_250_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 54683
elements in E: 11550760
fraction nonzero: 0.004734147363463529
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.29; acc: 0.14
Batch: 200; loss: 2.28; acc: 0.19
Batch: 220; loss: 2.26; acc: 0.22
Batch: 240; loss: 2.24; acc: 0.33
Batch: 260; loss: 2.25; acc: 0.28
Batch: 280; loss: 2.21; acc: 0.45
Batch: 300; loss: 2.21; acc: 0.41
Batch: 320; loss: 2.22; acc: 0.38
Batch: 340; loss: 2.14; acc: 0.47
Batch: 360; loss: 2.13; acc: 0.47
Batch: 380; loss: 2.11; acc: 0.39
Batch: 400; loss: 2.01; acc: 0.44
Batch: 420; loss: 1.82; acc: 0.59
Batch: 440; loss: 1.6; acc: 0.58
Batch: 460; loss: 1.47; acc: 0.52
Batch: 480; loss: 1.0; acc: 0.72
Batch: 500; loss: 1.05; acc: 0.67
Batch: 520; loss: 0.61; acc: 0.83
Batch: 540; loss: 0.89; acc: 0.7
Batch: 560; loss: 0.63; acc: 0.83
Batch: 580; loss: 0.85; acc: 0.81
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.8; acc: 0.83
Batch: 640; loss: 0.66; acc: 0.77
Batch: 660; loss: 0.52; acc: 0.81
Batch: 680; loss: 0.77; acc: 0.72
Batch: 700; loss: 0.65; acc: 0.8
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.63; acc: 0.78
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.62; acc: 0.83
Train Epoch over. train_loss: 1.58; train_accuracy: 0.48 

Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.42714348615734443; val_accuracy: 0.8721138535031847 

The current subspace-distance is: 1.1791493307100609e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.8
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.64; acc: 0.78
Batch: 180; loss: 0.61; acc: 0.81
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.5; acc: 0.86
Batch: 240; loss: 0.75; acc: 0.78
Batch: 260; loss: 0.74; acc: 0.8
Batch: 280; loss: 0.49; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.56; acc: 0.83
Batch: 360; loss: 0.74; acc: 0.77
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.57; acc: 0.78
Batch: 520; loss: 0.42; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.49; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.88
Batch: 600; loss: 0.76; acc: 0.84
Batch: 620; loss: 0.55; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.56; acc: 0.8
Batch: 740; loss: 0.55; acc: 0.84
Batch: 760; loss: 0.59; acc: 0.84
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3817298566080203; val_accuracy: 0.8885350318471338 

The current subspace-distance is: 2.1559799279202707e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.71; acc: 0.77
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.84
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.84
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.43; acc: 0.83
Batch: 660; loss: 0.62; acc: 0.84
Batch: 680; loss: 0.41; acc: 0.81
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.56; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.68; acc: 0.88
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.35; acc: 0.88
Val Epoch over. val_loss: 0.5476977589783395; val_accuracy: 0.8293192675159236 

The current subspace-distance is: 2.8808701244997792e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.55; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.62; acc: 0.83
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.15; acc: 0.98
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.57; acc: 0.88
Batch: 660; loss: 0.52; acc: 0.8
Batch: 680; loss: 0.34; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.55; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.3509923633259193; val_accuracy: 0.8941082802547771 

The current subspace-distance is: 3.443947935011238e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.78
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.57; acc: 0.89
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.83
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.81
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.57; acc: 0.83
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.51; acc: 0.83
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.73; acc: 0.73
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.73
Batch: 140; loss: 0.19; acc: 0.91
Val Epoch over. val_loss: 0.42082240702999624; val_accuracy: 0.8684315286624203 

The current subspace-distance is: 3.963656126870774e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.86
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.45; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.86
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.69; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.371881780018852; val_accuracy: 0.8865445859872612 

The current subspace-distance is: 4.347030699136667e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.83
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.65; acc: 0.83
Batch: 380; loss: 0.41; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.81
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.86
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.81
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.29318054817664396; val_accuracy: 0.9144108280254777 

The current subspace-distance is: 4.701605575974099e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.81
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.21; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.6; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.48; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.51; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.92; acc: 0.72
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3472060242276283; val_accuracy: 0.894406847133758 

The current subspace-distance is: 5.0610691687325016e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.92
Batch: 140; loss: 0.42; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.55; acc: 0.81
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.88
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.44; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.45; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.89; acc: 0.77
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3036776896162777; val_accuracy: 0.9092356687898089 

The current subspace-distance is: 5.4546377214137465e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.54; acc: 0.8
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.56; acc: 0.84
Batch: 360; loss: 0.81; acc: 0.8
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.81
Batch: 500; loss: 0.08; acc: 1.0
Batch: 520; loss: 0.59; acc: 0.81
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.55; acc: 0.78
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.89
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.98
Val Epoch over. val_loss: 0.35257682235092874; val_accuracy: 0.8909235668789809 

The current subspace-distance is: 5.860280725755729e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.84
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.51; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2611923644876784; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 6.220274372026324e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.08; acc: 1.0
Batch: 420; loss: 0.47; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.42; acc: 0.83
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.29587902297164986; val_accuracy: 0.9128184713375797 

The current subspace-distance is: 6.519782618852332e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.94
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.97
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.57; acc: 0.81
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.63; acc: 0.84
Batch: 740; loss: 0.28; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3046791952127104; val_accuracy: 0.9151074840764332 

The current subspace-distance is: 6.805864541092888e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.97
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.84
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.84
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2703355254878284; val_accuracy: 0.9178941082802548 

The current subspace-distance is: 7.058565824991092e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.84
Batch: 440; loss: 0.21; acc: 0.89
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.41; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.2594048541964619; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 7.347523205680773e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.07; acc: 1.0
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.49; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2703435947038945; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 7.638237002538517e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.54; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.84
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.83
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.95
Val Epoch over. val_loss: 0.27121432429286324; val_accuracy: 0.9187898089171974 

The current subspace-distance is: 7.842008926672861e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.68; acc: 0.83
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.22; acc: 0.89
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.62; acc: 0.83
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.2856688130718128; val_accuracy: 0.9129179936305732 

The current subspace-distance is: 8.115728996926919e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.84
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.84
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.17; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2706574714582437; val_accuracy: 0.9179936305732485 

The current subspace-distance is: 8.461791003355756e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.43; acc: 0.8
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.88
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.98
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.27003697241852237; val_accuracy: 0.9192874203821656 

The current subspace-distance is: 8.661751780891791e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.44; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.24181541596438474; val_accuracy: 0.9266520700636943 

The current subspace-distance is: 8.839559450279921e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.59; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.24435682059710573; val_accuracy: 0.925656847133758 

The current subspace-distance is: 9.08594811335206e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.45; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.6; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.24416273414709005; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 9.328071610070765e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.84
Batch: 720; loss: 0.54; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.23812363999094932; val_accuracy: 0.9268511146496815 

The current subspace-distance is: 9.570446127327159e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.94
Batch: 240; loss: 0.75; acc: 0.8
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.97
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.67; acc: 0.83
Batch: 740; loss: 0.55; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.24441984919890478; val_accuracy: 0.926453025477707 

The current subspace-distance is: 9.845710155786946e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.24232863803293295; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 0.00010055413440568373 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.56; acc: 0.84
Batch: 480; loss: 0.37; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.91
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.25033909478669714; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 0.00010280262358719483 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.86
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.57; acc: 0.86
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.95
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2680016865918211; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 0.00010451138950884342 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.94
Batch: 360; loss: 0.58; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.43; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.41; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.6; acc: 0.83
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.92
Val Epoch over. val_loss: 0.2485714565226986; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 0.00010599291999824345 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.98
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.98
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26185974141784535; val_accuracy: 0.9212778662420382 

The current subspace-distance is: 0.00010746363113867119 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.55; acc: 0.86
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.23516357293838908; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 0.00010989796282956377 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.19; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.23508534318275132; val_accuracy: 0.9301353503184714 

The current subspace-distance is: 0.0001125080234487541 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.97
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.57; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.45; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.63; acc: 0.86
Batch: 540; loss: 0.49; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.23798562225642478; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 0.00011413647735025734 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.54; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.88
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.23725793605587284; val_accuracy: 0.9287420382165605 

The current subspace-distance is: 0.00011530979827512056 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.21; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.48; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.23572372666494862; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 0.00011713306594174355 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.51; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.23723281440651342; val_accuracy: 0.9287420382165605 

The current subspace-distance is: 0.00011831416486529633 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.39; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.51; acc: 0.83
Batch: 560; loss: 0.25; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2364761842189321; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 0.00012032571248710155 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.09; acc: 1.0
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.42; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.97
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.6; acc: 0.86
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2363677379337086; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 0.0001222736609634012 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.7; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.23423021685355788; val_accuracy: 0.929140127388535 

The current subspace-distance is: 0.00012381312262732536 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.66; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.56; acc: 0.83
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.23633290853375083; val_accuracy: 0.9300358280254777 

The current subspace-distance is: 0.00012568209785968065 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.46; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.23425505008951875; val_accuracy: 0.929140127388535 

The current subspace-distance is: 0.0001273230300284922 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.83
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.23415656992869013; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 0.00012861192226409912 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.23492521659773627; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 0.00013036116433795542 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.84
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.53; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.37; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.64; acc: 0.81
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.23476231228678848; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 0.0001314891123911366 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.97
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.07; acc: 1.0
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.91
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.5; acc: 0.86
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2345576432717454; val_accuracy: 0.9296377388535032 

The current subspace-distance is: 0.00013323873281478882 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.84
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.92
Batch: 300; loss: 0.4; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.97
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.235338950233095; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 0.00013483456859830767 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.86
Batch: 420; loss: 0.23; acc: 0.86
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.61; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2347910613485962; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 0.00013590237358585 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.58; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.52; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.45; acc: 0.86
Batch: 740; loss: 0.26; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.23371085135420416; val_accuracy: 0.9306329617834395 

The current subspace-distance is: 0.00013731460785493255 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.41; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.81
Batch: 620; loss: 0.13; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2331522975805079; val_accuracy: 0.9303343949044586 

The current subspace-distance is: 0.00013858065358363092 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.26; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.48; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.55; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.2347295298033459; val_accuracy: 0.929140127388535 

The current subspace-distance is: 0.0001401207991875708 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_260_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 57062
elements in E: 11995020
fraction nonzero: 0.004757140880131921
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.14
Batch: 160; loss: 2.26; acc: 0.28
Batch: 180; loss: 2.28; acc: 0.17
Batch: 200; loss: 2.26; acc: 0.22
Batch: 220; loss: 2.24; acc: 0.3
Batch: 240; loss: 2.21; acc: 0.39
Batch: 260; loss: 2.2; acc: 0.31
Batch: 280; loss: 2.17; acc: 0.36
Batch: 300; loss: 2.14; acc: 0.33
Batch: 320; loss: 2.15; acc: 0.28
Batch: 340; loss: 2.01; acc: 0.41
Batch: 360; loss: 1.92; acc: 0.44
Batch: 380; loss: 1.66; acc: 0.48
Batch: 400; loss: 1.39; acc: 0.56
Batch: 420; loss: 1.19; acc: 0.61
Batch: 440; loss: 0.99; acc: 0.7
Batch: 460; loss: 1.08; acc: 0.61
Batch: 480; loss: 0.91; acc: 0.7
Batch: 500; loss: 0.8; acc: 0.75
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 0.83; acc: 0.67
Batch: 560; loss: 0.62; acc: 0.84
Batch: 580; loss: 0.8; acc: 0.8
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.59; acc: 0.83
Batch: 640; loss: 0.89; acc: 0.75
Batch: 660; loss: 0.65; acc: 0.77
Batch: 680; loss: 1.46; acc: 0.59
Batch: 700; loss: 0.92; acc: 0.69
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 0.58; acc: 0.8
Batch: 780; loss: 0.69; acc: 0.75
Train Epoch over. train_loss: 1.49; train_accuracy: 0.5 

Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.63; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.77; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.4756010658801741; val_accuracy: 0.8541998407643312 

The current subspace-distance is: 1.2464502106013242e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.76; acc: 0.81
Batch: 40; loss: 0.71; acc: 0.8
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.62; acc: 0.8
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.59; acc: 0.83
Batch: 200; loss: 0.47; acc: 0.81
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.61; acc: 0.83
Batch: 260; loss: 0.79; acc: 0.81
Batch: 280; loss: 0.56; acc: 0.83
Batch: 300; loss: 0.63; acc: 0.77
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.79; acc: 0.73
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.49; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.72; acc: 0.77
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.72; acc: 0.72
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.67; acc: 0.77
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.89
Batch: 620; loss: 0.52; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.5; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.89
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.66; acc: 0.81
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.89
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.40516423396054346; val_accuracy: 0.8720143312101911 

The current subspace-distance is: 2.147384475392755e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.65; acc: 0.8
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.8
Batch: 360; loss: 0.54; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.63; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.87; acc: 0.73
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.51; acc: 0.81
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.55; acc: 0.78
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.43920759401123993; val_accuracy: 0.863953025477707 

The current subspace-distance is: 2.860734639398288e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.86
Batch: 200; loss: 0.5; acc: 0.88
Batch: 220; loss: 0.51; acc: 0.8
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.65; acc: 0.84
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.56; acc: 0.83
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.54; acc: 0.84
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.51; acc: 0.86
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.84
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.53; acc: 0.78
Batch: 560; loss: 0.59; acc: 0.77
Batch: 580; loss: 0.28; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.95
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.57; acc: 0.78
Batch: 680; loss: 0.31; acc: 0.95
Batch: 700; loss: 0.44; acc: 0.83
Batch: 720; loss: 0.71; acc: 0.81
Batch: 740; loss: 0.52; acc: 0.8
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.53; acc: 0.75
Batch: 20; loss: 0.64; acc: 0.77
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.86; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.83
Batch: 100; loss: 0.73; acc: 0.81
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.26; acc: 0.89
Val Epoch over. val_loss: 0.6598406531818354; val_accuracy: 0.8004578025477707 

The current subspace-distance is: 3.427822593948804e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.46; acc: 0.81
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.56; acc: 0.78
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.89; acc: 0.73
Batch: 460; loss: 0.19; acc: 0.98
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.76; acc: 0.81
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.67; acc: 0.84
Batch: 660; loss: 0.68; acc: 0.88
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 1.12; acc: 0.64
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 1.35; acc: 0.59
Batch: 20; loss: 1.85; acc: 0.52
Batch: 40; loss: 0.71; acc: 0.81
Batch: 60; loss: 1.18; acc: 0.7
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 1.06; acc: 0.66
Batch: 120; loss: 1.65; acc: 0.62
Batch: 140; loss: 0.91; acc: 0.7
Val Epoch over. val_loss: 1.100699244600952; val_accuracy: 0.695859872611465 

The current subspace-distance is: 3.9442536944989115e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.18; acc: 0.66
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.91; acc: 0.75
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.83
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.5; acc: 0.88
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.73; acc: 0.72
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.48; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.51; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.81
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.78
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3398257547123417; val_accuracy: 0.8967953821656051 

The current subspace-distance is: 4.3777334212791175e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.57; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.56; acc: 0.83
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.31; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.88
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.53; acc: 0.8
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.3631529604933064; val_accuracy: 0.8891321656050956 

The current subspace-distance is: 4.802962939720601e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.84
Batch: 20; loss: 0.73; acc: 0.73
Batch: 40; loss: 0.48; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.86
Batch: 180; loss: 0.61; acc: 0.83
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.37; acc: 0.84
Batch: 420; loss: 0.38; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.74; acc: 0.73
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.81
Batch: 120; loss: 1.13; acc: 0.7
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.5364752020805504; val_accuracy: 0.8322054140127388 

The current subspace-distance is: 5.269180837785825e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.83
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.77; acc: 0.81
Batch: 420; loss: 0.6; acc: 0.84
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.44; acc: 0.8
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.8
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.81
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.33950580376538503; val_accuracy: 0.8973925159235668 

The current subspace-distance is: 5.508664617082104e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.45; acc: 0.81
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.62; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.42; acc: 0.84
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.61; acc: 0.81
Batch: 20; loss: 0.58; acc: 0.75
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.78
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.44188765403191754; val_accuracy: 0.8662420382165605 

The current subspace-distance is: 5.830526788486168e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.23; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.84
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.6; acc: 0.77
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.49; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2724072886215653; val_accuracy: 0.9165007961783439 

The current subspace-distance is: 6.117765587987378e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.35; acc: 0.84
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.45; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.83
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.84
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.81
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.32311777817975185; val_accuracy: 0.9039609872611465 

The current subspace-distance is: 6.417303666239604e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.32; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.88
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.30412686357547525; val_accuracy: 0.9124203821656051 

The current subspace-distance is: 6.760490214219317e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.42; acc: 0.83
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.83
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.88
Batch: 680; loss: 0.56; acc: 0.83
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3028398847598938; val_accuracy: 0.9066480891719745 

The current subspace-distance is: 7.00680902809836e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.86
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2734464920440297; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 7.29809034965001e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.46; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.34; acc: 0.94
Batch: 460; loss: 0.59; acc: 0.81
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.59; acc: 0.83
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2824873833851829; val_accuracy: 0.9121218152866242 

The current subspace-distance is: 7.550197915406898e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.46; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.45; acc: 0.81
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.88
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.52; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2818759510376651; val_accuracy: 0.9141122611464968 

The current subspace-distance is: 7.786426431266591e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.8
Batch: 160; loss: 0.25; acc: 0.88
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.56; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.64; acc: 0.86
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.3323645623531311; val_accuracy: 0.8983877388535032 

The current subspace-distance is: 8.010752208065242e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.48; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.49; acc: 0.81
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.26245312027301; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 8.269201498478651e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.97
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.29279869771117617; val_accuracy: 0.9150079617834395 

The current subspace-distance is: 8.555375097785145e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.95
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.97
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.14; acc: 0.92
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2576175279156038; val_accuracy: 0.9234673566878981 

The current subspace-distance is: 8.664704364491627e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.83
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.56; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.55; acc: 0.86
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.08; acc: 1.0
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.54; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2596967491991581; val_accuracy: 0.92078025477707 

The current subspace-distance is: 8.911258191801608e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.43; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.25497471287277096; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 9.214516467181966e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.84
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.53; acc: 0.8
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25438522001740277; val_accuracy: 0.92296974522293 

The current subspace-distance is: 9.449789649806917e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.55; acc: 0.81
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.83
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.86
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.95
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.49; acc: 0.91
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2588337319814096; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 9.640852658776566e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.58; acc: 0.83
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2587134082605884; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 9.780325490282848e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.98
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.97
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25577441012119034; val_accuracy: 0.9231687898089171 

The current subspace-distance is: 9.927522478392348e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.88
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.52; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.98
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.51; acc: 0.83
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.84
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2765586071285852; val_accuracy: 0.9173964968152867 

The current subspace-distance is: 0.00010100275540025905 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2638195035563912; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 0.00010323656897526234 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.89
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.259250404728446; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 0.00010465722880326211 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.12; acc: 0.98
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25166583896442585; val_accuracy: 0.924562101910828 

The current subspace-distance is: 0.00010588406439637765 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2504506869490739; val_accuracy: 0.9234673566878981 

The current subspace-distance is: 0.00010779066360555589 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.55; acc: 0.78
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.47; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.36; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.36; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.98
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2502830113954605; val_accuracy: 0.9251592356687898 

The current subspace-distance is: 0.00010929647396551445 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.51; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.33; acc: 0.94
Batch: 740; loss: 0.5; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25074000212891845; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 0.00011128647747682407 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.88
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.53; acc: 0.81
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.86
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25208578595689907; val_accuracy: 0.9251592356687898 

The current subspace-distance is: 0.00011313729191897437 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.81
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.95
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.35; acc: 0.86
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.45; acc: 0.83
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.5; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.1; acc: 1.0
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.250051080183998; val_accuracy: 0.9262539808917197 

The current subspace-distance is: 0.00011612288653850555 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.97
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.53; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25441813801124596; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 0.00011833557073259726 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.13; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2525435124945109; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 0.00011987973266514018 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.42; acc: 0.83
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.98
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2515336128699172; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 0.00012175818847026676 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.3; acc: 0.84
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.84
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.55; acc: 0.8
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.250768845390742; val_accuracy: 0.9258558917197452 

The current subspace-distance is: 0.0001233279035659507 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.24969115478407805; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 0.0001254638482350856 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.09; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.52; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2500822231126059; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 0.00012712892203126103 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.37; acc: 0.84
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25008724012951944; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 0.0001282259327126667 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.83
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.86
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.83
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.86
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.52; acc: 0.83
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.98
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2500069518188003; val_accuracy: 0.9251592356687898 

The current subspace-distance is: 0.00012970066745765507 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.11; acc: 1.0
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.16; acc: 0.98
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24869326839021816; val_accuracy: 0.9272492038216561 

The current subspace-distance is: 0.0001310297375312075 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.84
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.95
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.25; acc: 0.88
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.83
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.84
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2488125544160035; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 0.00013215153012424707 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.51; acc: 0.8
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.84
Batch: 560; loss: 0.45; acc: 0.83
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.24889003926781333; val_accuracy: 0.925656847133758 

The current subspace-distance is: 0.00013352416863199323 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.54; acc: 0.8
Batch: 160; loss: 0.34; acc: 0.94
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.46; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.43; acc: 0.81
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2489925955843394; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 0.00013600298552773893 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.68; acc: 0.78
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2487542822862127; val_accuracy: 0.9260549363057324 

The current subspace-distance is: 0.00013682145799975842 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.54; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.24966630453516722; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 0.0001377354346914217 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_270_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 58909
elements in E: 12439280
fraction nonzero: 0.004735724254136896
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.06
Batch: 140; loss: 2.27; acc: 0.09
Batch: 160; loss: 2.26; acc: 0.2
Batch: 180; loss: 2.28; acc: 0.19
Batch: 200; loss: 2.26; acc: 0.16
Batch: 220; loss: 2.24; acc: 0.27
Batch: 240; loss: 2.18; acc: 0.44
Batch: 260; loss: 2.16; acc: 0.38
Batch: 280; loss: 2.1; acc: 0.38
Batch: 300; loss: 2.0; acc: 0.41
Batch: 320; loss: 1.92; acc: 0.41
Batch: 340; loss: 1.7; acc: 0.48
Batch: 360; loss: 1.4; acc: 0.62
Batch: 380; loss: 1.02; acc: 0.7
Batch: 400; loss: 0.9; acc: 0.73
Batch: 420; loss: 0.74; acc: 0.77
Batch: 440; loss: 0.59; acc: 0.81
Batch: 460; loss: 0.99; acc: 0.66
Batch: 480; loss: 0.53; acc: 0.89
Batch: 500; loss: 0.71; acc: 0.75
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.8; acc: 0.7
Batch: 560; loss: 0.57; acc: 0.83
Batch: 580; loss: 0.88; acc: 0.75
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.59; acc: 0.8
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.83; acc: 0.73
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.72; acc: 0.78
Batch: 760; loss: 0.67; acc: 0.78
Batch: 780; loss: 0.59; acc: 0.84
Train Epoch over. train_loss: 1.36; train_accuracy: 0.54 

Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.68; acc: 0.73
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 1.04; acc: 0.7
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.4814207997101887; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 1.3243951798358466e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.7
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.9; acc: 0.67
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.81
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.54; acc: 0.8
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.58; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.5; acc: 0.89
Batch: 260; loss: 0.68; acc: 0.81
Batch: 280; loss: 0.68; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.4; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.8
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.83
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.68; acc: 0.8
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.64; acc: 0.81
Batch: 580; loss: 0.42; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.63; acc: 0.78
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.34786277727051906; val_accuracy: 0.8921178343949044 

The current subspace-distance is: 2.1984329578117467e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.52; acc: 0.88
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.53; acc: 0.86
Batch: 620; loss: 0.45; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.59; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.8
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.61; acc: 0.86
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.32806506491960236; val_accuracy: 0.8969944267515924 

The current subspace-distance is: 2.877667975553777e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.86
Batch: 220; loss: 0.31; acc: 0.84
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.74; acc: 0.81
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.84
Batch: 560; loss: 0.46; acc: 0.81
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.56; acc: 0.83
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.8
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 1.22; acc: 0.7
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.52; acc: 0.75
Val Epoch over. val_loss: 0.5909551993297164; val_accuracy: 0.8108081210191083 

The current subspace-distance is: 3.4411586966598406e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.92; acc: 0.75
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.83
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.79; acc: 0.72
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.86; acc: 0.78
Batch: 140; loss: 0.24; acc: 0.88
Val Epoch over. val_loss: 0.38891449981149595; val_accuracy: 0.8727109872611465 

The current subspace-distance is: 3.945684511563741e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.66; acc: 0.83
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.53; acc: 0.81
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.83
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.30264339610269875; val_accuracy: 0.9069466560509554 

The current subspace-distance is: 4.404290302773006e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.34; acc: 0.94
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2718975402794446; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 4.8478930693818256e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.84
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.84
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.81
Batch: 380; loss: 0.33; acc: 0.94
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.47; acc: 0.83
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.48; acc: 0.81
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 1.01; acc: 0.73
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.82; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.95; acc: 0.75
Batch: 140; loss: 0.53; acc: 0.91
Val Epoch over. val_loss: 0.5607912895880687; val_accuracy: 0.8335987261146497 

The current subspace-distance is: 5.194518234930001e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.84
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.57; acc: 0.8
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.68; acc: 0.81
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.53; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.91
Val Epoch over. val_loss: 0.2824250763388956; val_accuracy: 0.9145103503184714 

The current subspace-distance is: 5.5045347835402936e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.34; acc: 0.95
Batch: 360; loss: 0.46; acc: 0.81
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.44; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.61; acc: 0.83
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.83
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.98
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.34182676188885025; val_accuracy: 0.894406847133758 

The current subspace-distance is: 5.830292502650991e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.38; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.88
Batch: 420; loss: 0.53; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.54; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.24523614612734243; val_accuracy: 0.9255573248407644 

The current subspace-distance is: 6.139654578873888e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 1.0
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.52; acc: 0.86
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.39; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.54; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.2897421853842249; val_accuracy: 0.9128184713375797 

The current subspace-distance is: 6.44162209937349e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.47; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.54; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.86
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.63; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.53; acc: 0.88
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2805575733636595; val_accuracy: 0.9132165605095541 

The current subspace-distance is: 6.69427536195144e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.98
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.34; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26388776487415766; val_accuracy: 0.9178941082802548 

The current subspace-distance is: 7.020112389000133e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.98
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26909642704543035; val_accuracy: 0.9141122611464968 

The current subspace-distance is: 7.270149944815785e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.47; acc: 0.86
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.71; acc: 0.84
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25883998185586016; val_accuracy: 0.9215764331210191 

The current subspace-distance is: 7.600997196277604e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.97
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.86
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.52; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.23696155523418622; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 7.88775141700171e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.84
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.84
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.43; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.56; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.24862738788887195; val_accuracy: 0.9231687898089171 

The current subspace-distance is: 8.131831418722868e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.36; acc: 0.84
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26646719137384633; val_accuracy: 0.9193869426751592 

The current subspace-distance is: 8.399212674703449e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.98
Batch: 400; loss: 0.34; acc: 0.95
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.98
Batch: 60; loss: 0.65; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2824677495867204; val_accuracy: 0.9151074840764332 

The current subspace-distance is: 8.65894544404e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.53; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22837792149489852; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 8.920850814320147e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.56; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.07; acc: 1.0
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.19; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.23308752975456273; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 9.131403203355148e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.97
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.41; acc: 0.83
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.11; acc: 0.98
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.22595353023546516; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 9.382898861076683e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.84
Batch: 340; loss: 0.53; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.86
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.4; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2228180670007399; val_accuracy: 0.9300358280254777 

The current subspace-distance is: 9.57757729338482e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.47; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.81
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.83; acc: 0.83
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22855252713249746; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 9.802870772546157e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.22460613530247833; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 0.00010025804658653215 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.11; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.83
Batch: 660; loss: 0.33; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2213282244647764; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 0.00010231494525214657 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.47; acc: 0.88
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.98
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.88
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.5; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.24387597952299056; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 0.00010429065150674433 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.86
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.2288591832776738; val_accuracy: 0.9303343949044586 

The current subspace-distance is: 0.00010699082486098632 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22158339588790182; val_accuracy: 0.9328224522292994 

The current subspace-distance is: 0.00010867821401916444 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.39; acc: 0.92
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.34; acc: 0.86
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.07; acc: 1.0
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2251831742039152; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 0.00011002750397892669 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.37; acc: 0.83
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.15; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.86
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21902134767763173; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 0.00011168025230290368 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.98
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.22021698111751278; val_accuracy: 0.9331210191082803 

The current subspace-distance is: 0.00011313655704725534 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.47; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21877756790750347; val_accuracy: 0.9327229299363057 

The current subspace-distance is: 0.00011495880607981235 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2226704090691296; val_accuracy: 0.9308320063694268 

The current subspace-distance is: 0.00011651300883386284 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.84
Batch: 620; loss: 0.38; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.5; acc: 0.91
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21942449985131338; val_accuracy: 0.9313296178343949 

The current subspace-distance is: 0.0001181681000161916 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.83
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2233872691252429; val_accuracy: 0.9311305732484076 

The current subspace-distance is: 0.00011942267883569002 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.54; acc: 0.84
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.84
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.98
Batch: 600; loss: 0.25; acc: 0.86
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21728102357429305; val_accuracy: 0.9333200636942676 

The current subspace-distance is: 0.00012126744695706293 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.47; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2177725601348148; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 0.00012276979396119714 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.98
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.84
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22307742365701183; val_accuracy: 0.9319267515923567 

The current subspace-distance is: 0.0001248105545528233 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.45; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.83
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21728432539162362; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 0.00012651283759623766 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.86
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.42; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21761308838227753; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 0.0001280284341191873 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.36; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21785987517351557; val_accuracy: 0.9334195859872612 

The current subspace-distance is: 0.00012895106920041144 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.42; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.89
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.66; acc: 0.81
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.55; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21724759962908022; val_accuracy: 0.9320262738853503 

The current subspace-distance is: 0.00013135244080331177 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.07; acc: 1.0
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.88
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.43; acc: 0.83
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2166852158298538; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 0.00013316851982381195 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.56; acc: 0.83
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.84
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2177264844630934; val_accuracy: 0.9326234076433121 

The current subspace-distance is: 0.00013403561024460942 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.5; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.54; acc: 0.89
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2162640509047326; val_accuracy: 0.9325238853503185 

The current subspace-distance is: 0.00013534113531932235 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.25; acc: 0.88
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21727535982800136; val_accuracy: 0.9327229299363057 

The current subspace-distance is: 0.00013707323523703963 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.95
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.44; acc: 0.86
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2164122574031353; val_accuracy: 0.9328224522292994 

The current subspace-distance is: 0.00013912208669353276 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.86
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.07; acc: 1.0
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.46; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2168481031278516; val_accuracy: 0.931827229299363 

The current subspace-distance is: 0.00014074327191337943 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_280_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 60978
elements in E: 12883540
fraction nonzero: 0.004733015925747116
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.05
Batch: 140; loss: 2.27; acc: 0.14
Batch: 160; loss: 2.25; acc: 0.3
Batch: 180; loss: 2.26; acc: 0.22
Batch: 200; loss: 2.24; acc: 0.27
Batch: 220; loss: 2.22; acc: 0.33
Batch: 240; loss: 2.18; acc: 0.48
Batch: 260; loss: 2.17; acc: 0.44
Batch: 280; loss: 2.09; acc: 0.45
Batch: 300; loss: 2.02; acc: 0.53
Batch: 320; loss: 1.94; acc: 0.45
Batch: 340; loss: 1.75; acc: 0.53
Batch: 360; loss: 1.51; acc: 0.61
Batch: 380; loss: 1.32; acc: 0.64
Batch: 400; loss: 1.06; acc: 0.66
Batch: 420; loss: 0.99; acc: 0.61
Batch: 440; loss: 0.81; acc: 0.72
Batch: 460; loss: 1.4; acc: 0.5
Batch: 480; loss: 0.71; acc: 0.78
Batch: 500; loss: 0.67; acc: 0.73
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.77; acc: 0.72
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.8; acc: 0.77
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.83; acc: 0.78
Batch: 640; loss: 0.73; acc: 0.75
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.8; acc: 0.75
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.56; acc: 0.81
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 1.41; train_accuracy: 0.54 

Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.74; acc: 0.73
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.81
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.88; acc: 0.73
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.45656219765449024; val_accuracy: 0.8541998407643312 

The current subspace-distance is: 1.2760108802467585e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.92; acc: 0.69
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.85; acc: 0.78
Batch: 100; loss: 0.63; acc: 0.81
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.83
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.77; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.91
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.52; acc: 0.89
Batch: 260; loss: 0.64; acc: 0.78
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.83
Batch: 320; loss: 0.38; acc: 0.95
Batch: 340; loss: 0.41; acc: 0.89
Batch: 360; loss: 0.5; acc: 0.81
Batch: 380; loss: 0.59; acc: 0.81
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.52; acc: 0.84
Batch: 460; loss: 0.39; acc: 0.81
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.71; acc: 0.77
Batch: 520; loss: 0.55; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.62; acc: 0.78
Batch: 580; loss: 0.49; acc: 0.86
Batch: 600; loss: 0.56; acc: 0.86
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.5; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.58; acc: 0.8
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.65; acc: 0.81
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.55; acc: 0.73
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.8
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.49; acc: 0.78
Val Epoch over. val_loss: 0.6055752551954263; val_accuracy: 0.7974721337579618 

The current subspace-distance is: 2.1746260244981386e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.8
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.91
Batch: 80; loss: 0.51; acc: 0.81
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.55; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.8
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.83
Batch: 460; loss: 0.32; acc: 0.86
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.53; acc: 0.81
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.6; acc: 0.84
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.69; acc: 0.8
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.55; acc: 0.89
Batch: 60; loss: 0.48; acc: 0.81
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.5782494198554641; val_accuracy: 0.817078025477707 

The current subspace-distance is: 2.8748438126058318e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.49; acc: 0.81
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.94
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.23; acc: 0.97
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.4083626678889724; val_accuracy: 0.8709195859872612 

The current subspace-distance is: 3.557742093107663e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.84
Batch: 240; loss: 0.38; acc: 0.83
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.83
Batch: 380; loss: 0.39; acc: 0.92
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.86
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.65; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.47; acc: 0.81
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.84
Batch: 720; loss: 0.93; acc: 0.73
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 1.06; acc: 0.7
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.69; acc: 0.81
Batch: 100; loss: 0.77; acc: 0.78
Batch: 120; loss: 0.97; acc: 0.77
Batch: 140; loss: 0.38; acc: 0.88
Val Epoch over. val_loss: 0.6912607734750031; val_accuracy: 0.8103105095541401 

The current subspace-distance is: 4.1036571928998455e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.78
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.82; acc: 0.8
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.84
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.86
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.63; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.4490803893489443; val_accuracy: 0.8532046178343949 

The current subspace-distance is: 4.6100420149741694e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.77
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.81
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.25959870855140077; val_accuracy: 0.917296974522293 

The current subspace-distance is: 5.09249912283849e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.34; acc: 0.83
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.43; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.65; acc: 0.75
Batch: 20; loss: 0.9; acc: 0.73
Batch: 40; loss: 0.25; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.81
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.6369079402203013; val_accuracy: 0.8095143312101911 

The current subspace-distance is: 5.4821401135995984e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.35; acc: 0.84
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.07; acc: 1.0
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.84
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.83
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.13; acc: 0.98
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.30943178589556625; val_accuracy: 0.8998805732484076 

The current subspace-distance is: 5.9833433624589816e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.39; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.53; acc: 0.83
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.52; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.94
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.36; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.18; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.2772502056352652; val_accuracy: 0.9132165605095541 

The current subspace-distance is: 6.343120912788436e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.09; acc: 1.0
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.52; acc: 0.88
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.48; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.24574964071155353; val_accuracy: 0.923765923566879 

The current subspace-distance is: 6.697861681459472e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.09; acc: 1.0
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.09; acc: 1.0
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.64; acc: 0.86
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2609694401739509; val_accuracy: 0.9215764331210191 

The current subspace-distance is: 7.029248081380501e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.47; acc: 0.81
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.42; acc: 0.92
Batch: 540; loss: 0.39; acc: 0.84
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2649111985970455; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 7.26558719179593e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.83
Batch: 480; loss: 0.38; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2635391677261158; val_accuracy: 0.9183917197452229 

The current subspace-distance is: 7.607239967910573e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.24549610860598314; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 7.86515956860967e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.88
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24092396149399933; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 8.150825306074694e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.34; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.98
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2607555164463201; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 8.441512909485027e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.46; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.55; acc: 0.88
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.69; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22372553715850138; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 8.771819557296112e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.48; acc: 0.91
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22824917562827943; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 9.003801824292168e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.97
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2225199448075264; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 9.259585931431502e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21207700916536296; val_accuracy: 0.9345143312101911 

The current subspace-distance is: 9.523866174276918e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.5; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.21112482078895448; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 9.798153041629121e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.98
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.49; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21338724895457553; val_accuracy: 0.9333200636942676 

The current subspace-distance is: 0.0001008011240628548 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.48; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21220797869809874; val_accuracy: 0.9345143312101911 

The current subspace-distance is: 0.00010288630437571555 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.97
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20990399641406005; val_accuracy: 0.9363057324840764 

The current subspace-distance is: 0.00010578668297966942 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20810170561834507; val_accuracy: 0.935609076433121 

The current subspace-distance is: 0.00010871253471123055 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.39; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.97
Batch: 720; loss: 0.4; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21395048836044445; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 0.00010973183816531673 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.98
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.232105586464238; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 0.00011226153583265841 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.05; acc: 1.0
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20602003926304496; val_accuracy: 0.9376990445859873 

The current subspace-distance is: 0.00011441681272117421 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.55; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.86
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2073550475346055; val_accuracy: 0.935609076433121 

The current subspace-distance is: 0.00011637152783805504 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.84
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2028612669581061; val_accuracy: 0.9382961783439491 

The current subspace-distance is: 0.00011783473019022495 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2022087551700841; val_accuracy: 0.9383957006369427 

The current subspace-distance is: 0.00011961613199673593 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.51; acc: 0.86
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.88
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.84
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20180904542564587; val_accuracy: 0.9375995222929936 

The current subspace-distance is: 0.00012185251398477703 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.45; acc: 0.83
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.53; acc: 0.88
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.07; acc: 1.0
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.11; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20325739273599758; val_accuracy: 0.93859474522293 

The current subspace-distance is: 0.0001240483543369919 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.84
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20193327531503263; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 0.00012613613216672093 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20108375242751114; val_accuracy: 0.9374004777070064 

The current subspace-distance is: 0.00012834776134695858 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.12; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.84
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20150028107462414; val_accuracy: 0.9375 

The current subspace-distance is: 0.00013002748892176896 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.29; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.74; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.45; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20054377311733879; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 0.00013219039828982204 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19947925803198177; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 0.00013408441736828536 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.95
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.8
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20541330972674546; val_accuracy: 0.9374004777070064 

The current subspace-distance is: 0.0001357666333205998 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.65; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19908459195096023; val_accuracy: 0.9387937898089171 

The current subspace-distance is: 0.00013752411177847534 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19928599618802403; val_accuracy: 0.9394904458598726 

The current subspace-distance is: 0.00013962449156679213 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.95
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.3; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19941395701496464; val_accuracy: 0.939390923566879 

The current subspace-distance is: 0.0001419304753653705 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.91
Batch: 640; loss: 0.57; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.46; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20039087571915548; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 0.00014386374095920473 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.56; acc: 0.88
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20011231886922934; val_accuracy: 0.9395899681528662 

The current subspace-distance is: 0.00014492614718619734 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.92
Batch: 260; loss: 0.42; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.1987422719882552; val_accuracy: 0.9380971337579618 

The current subspace-distance is: 0.00014725410437677056 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.45; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19910647198083295; val_accuracy: 0.9386942675159236 

The current subspace-distance is: 0.00014894033665768802 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.48; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.86
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19867557671609198; val_accuracy: 0.939390923566879 

The current subspace-distance is: 0.00015008235641289502 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.4; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.34; acc: 0.94
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19959599705068928; val_accuracy: 0.9388933121019108 

The current subspace-distance is: 0.0001515336916781962 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.15; acc: 0.98
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.44; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19953891786800068; val_accuracy: 0.9389928343949044 

The current subspace-distance is: 0.00015309546142816544 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_290_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 63553
elements in E: 13327800
fraction nonzero: 0.004768453908371975
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.12
Batch: 160; loss: 2.27; acc: 0.3
Batch: 180; loss: 2.28; acc: 0.14
Batch: 200; loss: 2.26; acc: 0.2
Batch: 220; loss: 2.25; acc: 0.3
Batch: 240; loss: 2.22; acc: 0.36
Batch: 260; loss: 2.23; acc: 0.23
Batch: 280; loss: 2.17; acc: 0.33
Batch: 300; loss: 2.17; acc: 0.31
Batch: 320; loss: 2.14; acc: 0.28
Batch: 340; loss: 2.0; acc: 0.38
Batch: 360; loss: 1.79; acc: 0.56
Batch: 380; loss: 1.59; acc: 0.58
Batch: 400; loss: 1.36; acc: 0.48
Batch: 420; loss: 1.19; acc: 0.55
Batch: 440; loss: 0.78; acc: 0.78
Batch: 460; loss: 0.84; acc: 0.75
Batch: 480; loss: 0.83; acc: 0.77
Batch: 500; loss: 0.71; acc: 0.77
Batch: 520; loss: 0.64; acc: 0.84
Batch: 540; loss: 0.74; acc: 0.73
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.75; acc: 0.8
Batch: 600; loss: 0.72; acc: 0.84
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.68; acc: 0.78
Batch: 660; loss: 0.51; acc: 0.83
Batch: 680; loss: 0.92; acc: 0.69
Batch: 700; loss: 0.91; acc: 0.69
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.92; acc: 0.75
Batch: 760; loss: 0.51; acc: 0.88
Batch: 780; loss: 0.82; acc: 0.7
Train Epoch over. train_loss: 1.48; train_accuracy: 0.49 

Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.85; acc: 0.67
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.87; acc: 0.73
Batch: 80; loss: 0.64; acc: 0.8
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.94; acc: 0.69
Batch: 140; loss: 0.7; acc: 0.72
Val Epoch over. val_loss: 0.6929369282190967; val_accuracy: 0.7588574840764332 

The current subspace-distance is: 1.2717330719169695e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.68; acc: 0.73
Batch: 20; loss: 0.65; acc: 0.83
Batch: 40; loss: 0.75; acc: 0.75
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.55; acc: 0.81
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.65; acc: 0.84
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.51; acc: 0.83
Batch: 240; loss: 1.09; acc: 0.72
Batch: 260; loss: 0.71; acc: 0.8
Batch: 280; loss: 0.56; acc: 0.83
Batch: 300; loss: 0.56; acc: 0.8
Batch: 320; loss: 0.61; acc: 0.86
Batch: 340; loss: 0.62; acc: 0.77
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.67; acc: 0.81
Batch: 480; loss: 0.45; acc: 0.91
Batch: 500; loss: 0.67; acc: 0.78
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.47; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.88
Batch: 620; loss: 0.63; acc: 0.84
Batch: 640; loss: 0.5; acc: 0.81
Batch: 660; loss: 0.45; acc: 0.81
Batch: 680; loss: 0.55; acc: 0.81
Batch: 700; loss: 0.38; acc: 0.84
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.48; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.22; acc: 0.89
Val Epoch over. val_loss: 0.3668139791887277; val_accuracy: 0.886046974522293 

The current subspace-distance is: 2.156951632059645e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.51; acc: 0.84
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.43; acc: 0.83
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.81
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.83
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.59; acc: 0.77
Batch: 680; loss: 0.47; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.7; acc: 0.83
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

Batch: 0; loss: 0.69; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.69
Batch: 40; loss: 0.43; acc: 0.81
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.66; acc: 0.83
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.38; acc: 0.88
Val Epoch over. val_loss: 0.5935229726467922; val_accuracy: 0.806827229299363 

The current subspace-distance is: 2.798414061544463e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.48; acc: 0.83
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.81
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.95
Batch: 460; loss: 0.59; acc: 0.77
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.65; acc: 0.73
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.5441607695286441; val_accuracy: 0.823546974522293 

The current subspace-distance is: 3.373426079633646e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 0.22; acc: 0.88
Batch: 40; loss: 0.62; acc: 0.84
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.81
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.59; acc: 0.81
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.13; acc: 1.0
Batch: 480; loss: 0.45; acc: 0.83
Batch: 500; loss: 0.53; acc: 0.88
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.6; acc: 0.8
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 1.05; acc: 0.66
Batch: 20; loss: 1.1; acc: 0.66
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.93; acc: 0.69
Batch: 80; loss: 0.86; acc: 0.77
Batch: 100; loss: 0.73; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.67
Batch: 140; loss: 0.35; acc: 0.89
Val Epoch over. val_loss: 0.7650259845196061; val_accuracy: 0.7647292993630573 

The current subspace-distance is: 3.868020576192066e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.81
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.59; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.5; acc: 0.86
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.88
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.47; acc: 0.8
Batch: 560; loss: 0.49; acc: 0.88
Batch: 580; loss: 0.57; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.98
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.47; acc: 0.78
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3782702402039698; val_accuracy: 0.8742038216560509 

The current subspace-distance is: 4.3489002564456314e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.25; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.42; acc: 0.8
Batch: 380; loss: 0.39; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.48; acc: 0.83
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.26129940901971926; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 4.7772336984053254e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.51; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.45; acc: 0.78
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.84
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.29; acc: 0.88
Batch: 760; loss: 0.49; acc: 0.8
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.40504039548764564; val_accuracy: 0.8717157643312102 

The current subspace-distance is: 5.268493259791285e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.86
Batch: 400; loss: 0.52; acc: 0.8
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.8
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.49; acc: 0.84
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.27067047988723036; val_accuracy: 0.9195859872611465 

The current subspace-distance is: 5.678300294675864e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.86; acc: 0.84
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.71; acc: 0.8
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.83
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.79; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.29920069076073397; val_accuracy: 0.9070461783439491 

The current subspace-distance is: 5.981635331409052e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.51; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.66; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.81
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.36; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.25536239417685064; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 6.297721120063215e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.45; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.55; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.62; acc: 0.86
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.24948685184405867; val_accuracy: 0.9230692675159236 

The current subspace-distance is: 6.647560803685337e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.56; acc: 0.88
Batch: 420; loss: 0.18; acc: 0.98
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.98
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2816410343738119; val_accuracy: 0.9140127388535032 

The current subspace-distance is: 6.976402073632926e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.26; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.08; acc: 1.0
Batch: 300; loss: 0.3; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.18; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.94
Val Epoch over. val_loss: 0.23945581153699547; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 7.300558354472741e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.57; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2464294431695513; val_accuracy: 0.9265525477707006 

The current subspace-distance is: 7.582893886137754e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.86
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.56; acc: 0.83
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.24316682998731637; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 7.909813575679436e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.83
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.88
Batch: 600; loss: 0.25; acc: 0.88
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2597186222767374; val_accuracy: 0.9233678343949044 

The current subspace-distance is: 8.20536952232942e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.46; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.88
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.45; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.24724401723427378; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 8.526822057319805e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.36; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.84
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2273601241836882; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 8.810009603621438e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.98
Batch: 140; loss: 0.28; acc: 0.86
Batch: 160; loss: 0.33; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.56; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.23085788701465176; val_accuracy: 0.9311305732484076 

The current subspace-distance is: 9.022407175507396e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.09; acc: 1.0
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.94
Val Epoch over. val_loss: 0.21928747648456295; val_accuracy: 0.9362062101910829 

The current subspace-distance is: 9.345958096673712e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.48; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.21562301301082987; val_accuracy: 0.9335191082802548 

The current subspace-distance is: 9.551842958899215e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.32; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.21496802418949498; val_accuracy: 0.9336186305732485 

The current subspace-distance is: 9.844717715168372e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.98
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.47; acc: 0.84
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.94
Val Epoch over. val_loss: 0.21356348214065954; val_accuracy: 0.934812898089172 

The current subspace-distance is: 0.00010050027049146593 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.32; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.61; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.91
Batch: 380; loss: 0.63; acc: 0.81
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.58; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.94
Val Epoch over. val_loss: 0.21676560329973318; val_accuracy: 0.9342157643312102 

The current subspace-distance is: 0.00010236335947411135 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.84
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.21602367953794777; val_accuracy: 0.9344148089171974 

The current subspace-distance is: 0.00010470792767591774 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.6; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.92
Val Epoch over. val_loss: 0.21658455300482976; val_accuracy: 0.9346138535031847 

The current subspace-distance is: 0.00010700956045184284 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.47; acc: 0.91
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.45; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.23181907789912193; val_accuracy: 0.9308320063694268 

The current subspace-distance is: 0.00010926672985078767 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.97
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.42; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.46; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.21670736699916754; val_accuracy: 0.9349124203821656 

The current subspace-distance is: 0.00011127193283755332 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.97
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.21663211305050334; val_accuracy: 0.9338176751592356 

The current subspace-distance is: 0.00011341091158101335 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.6; acc: 0.81
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.22; acc: 0.97
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.21055285962429016; val_accuracy: 0.9363057324840764 

The current subspace-distance is: 0.00011564385931706056 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2106939227954977; val_accuracy: 0.9361066878980892 

The current subspace-distance is: 0.00011767514661187306 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.84
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.51; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.61; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.34; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.21018085600274383; val_accuracy: 0.935609076433121 

The current subspace-distance is: 0.00011953053763136268 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.46; acc: 0.89
Batch: 740; loss: 0.43; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20870551578463262; val_accuracy: 0.9366042993630573 

The current subspace-distance is: 0.00012164167856099084 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.08; acc: 1.0
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.98
Batch: 380; loss: 0.11; acc: 1.0
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.89
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.92
Val Epoch over. val_loss: 0.2111158498153565; val_accuracy: 0.9353105095541401 

The current subspace-distance is: 0.00012361517292447388 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.98
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.49; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.20912925457688653; val_accuracy: 0.9361066878980892 

The current subspace-distance is: 0.0001261514116777107 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.2103261374601513; val_accuracy: 0.9374004777070064 

The current subspace-distance is: 0.00012764587881974876 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.97
Batch: 280; loss: 0.5; acc: 0.86
Batch: 300; loss: 0.2; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.2088759258911488; val_accuracy: 0.9355095541401274 

The current subspace-distance is: 0.00012959779996890575 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20905541099465577; val_accuracy: 0.9361066878980892 

The current subspace-distance is: 0.00013038740144111216 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.37; acc: 0.84
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.37; acc: 0.86
Batch: 460; loss: 0.1; acc: 1.0
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.2102537210200243; val_accuracy: 0.93640525477707 

The current subspace-distance is: 0.0001322951284237206 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.38; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20800998655094463; val_accuracy: 0.9366042993630573 

The current subspace-distance is: 0.00013384890917222947 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.20847953134661268; val_accuracy: 0.9369028662420382 

The current subspace-distance is: 0.0001359629532089457 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.64; acc: 0.86
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20800064774645363; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 0.00013747472257819027 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.41; acc: 0.83
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.92
Val Epoch over. val_loss: 0.20832488377382802; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 0.00013806424976792186 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.07; acc: 1.0
Batch: 360; loss: 0.14; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.44; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20858271118656846; val_accuracy: 0.9368033439490446 

The current subspace-distance is: 0.00013986858539283276 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.95
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.208191942471038; val_accuracy: 0.9369028662420382 

The current subspace-distance is: 0.0001413120626239106 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.53; acc: 0.81
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.65; acc: 0.83
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.88
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20754922622708; val_accuracy: 0.9367038216560509 

The current subspace-distance is: 0.0001427256065653637 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.84
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.57; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.86
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.20808660345757082; val_accuracy: 0.9367038216560509 

The current subspace-distance is: 0.00014378377818502486 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.21; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.95
Batch: 600; loss: 0.46; acc: 0.89
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.92
Val Epoch over. val_loss: 0.20827796969823775; val_accuracy: 0.9365047770700637 

The current subspace-distance is: 0.0001443703076802194 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.86
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.92
Val Epoch over. val_loss: 0.20857627329173362; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 0.00014598891721107066 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 73876
elements in E: 15549100
fraction nonzero: 0.004751143152979915
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.12
Batch: 160; loss: 2.24; acc: 0.33
Batch: 180; loss: 2.25; acc: 0.2
Batch: 200; loss: 2.21; acc: 0.25
Batch: 220; loss: 2.14; acc: 0.41
Batch: 240; loss: 2.03; acc: 0.47
Batch: 260; loss: 1.91; acc: 0.42
Batch: 280; loss: 1.6; acc: 0.58
Batch: 300; loss: 1.48; acc: 0.56
Batch: 320; loss: 1.17; acc: 0.58
Batch: 340; loss: 1.13; acc: 0.61
Batch: 360; loss: 0.79; acc: 0.81
Batch: 380; loss: 0.73; acc: 0.81
Batch: 400; loss: 0.73; acc: 0.75
Batch: 420; loss: 0.67; acc: 0.75
Batch: 440; loss: 0.48; acc: 0.84
Batch: 460; loss: 0.8; acc: 0.75
Batch: 480; loss: 0.53; acc: 0.8
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.35; acc: 0.84
Batch: 540; loss: 0.75; acc: 0.73
Batch: 560; loss: 0.43; acc: 0.88
Batch: 580; loss: 0.55; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.84
Batch: 640; loss: 0.5; acc: 0.81
Batch: 660; loss: 0.3; acc: 0.95
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.5; acc: 0.81
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.57; acc: 0.83
Train Epoch over. train_loss: 1.2; train_accuracy: 0.6 

Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3554450214193885; val_accuracy: 0.8937101910828026 

The current subspace-distance is: 1.3433314961730503e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.61; acc: 0.81
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.63; acc: 0.81
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.56; acc: 0.84
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.94
Batch: 260; loss: 0.71; acc: 0.8
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.51; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.29; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.53; acc: 0.83
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.65; acc: 0.83
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.86; acc: 0.75
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.64; acc: 0.78
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.96; acc: 0.73
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.5533301355732474; val_accuracy: 0.8141918789808917 

The current subspace-distance is: 2.1671989088645205e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.81
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.97
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.88
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.55; acc: 0.83
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.63; acc: 0.83
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.78
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.4748959290278945; val_accuracy: 0.8508160828025477 

The current subspace-distance is: 2.8746224415954202e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.61; acc: 0.84
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.81
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.9 

Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.56; acc: 0.78
Batch: 40; loss: 0.4; acc: 0.84
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.52; acc: 0.83
Val Epoch over. val_loss: 0.5961381624553613; val_accuracy: 0.8140923566878981 

The current subspace-distance is: 3.45245425705798e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.35; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.62; acc: 0.8
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4024235852015246; val_accuracy: 0.870421974522293 

The current subspace-distance is: 3.920498056686483e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.84
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.53; acc: 0.78
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 1.56; acc: 0.66
Batch: 20; loss: 1.43; acc: 0.55
Batch: 40; loss: 1.23; acc: 0.69
Batch: 60; loss: 1.94; acc: 0.66
Batch: 80; loss: 1.47; acc: 0.66
Batch: 100; loss: 1.23; acc: 0.78
Batch: 120; loss: 1.68; acc: 0.58
Batch: 140; loss: 1.53; acc: 0.61
Val Epoch over. val_loss: 1.3431878355657978; val_accuracy: 0.665406050955414 

The current subspace-distance is: 4.358930164016783e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.73; acc: 0.64
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.92
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.83
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.58; acc: 0.77
Batch: 380; loss: 0.38; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.06; acc: 1.0
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.24865837679926756; val_accuracy: 0.9222730891719745 

The current subspace-distance is: 4.782123141922057e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.52; acc: 0.86
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.6; acc: 0.78
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.98; acc: 0.73
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 1.15; acc: 0.75
Batch: 140; loss: 0.4; acc: 0.86
Val Epoch over. val_loss: 0.5639368311330012; val_accuracy: 0.8318073248407644 

The current subspace-distance is: 5.1720780902542174e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.86
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.2892804035715237; val_accuracy: 0.9133160828025477 

The current subspace-distance is: 5.546119064092636e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.65; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.97
Batch: 360; loss: 0.62; acc: 0.84
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.33188890945759547; val_accuracy: 0.8940087579617835 

The current subspace-distance is: 5.890453394385986e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.47; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.86
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.213592368563649; val_accuracy: 0.9358081210191083 

The current subspace-distance is: 6.188975385157391e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.98
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.89
Batch: 160; loss: 0.08; acc: 1.0
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.98
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.86
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.36; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22174531788488103; val_accuracy: 0.9340167197452229 

The current subspace-distance is: 6.509136437671259e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.97
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.37; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.92
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.2689341687282939; val_accuracy: 0.9153065286624203 

The current subspace-distance is: 6.799201219109818e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.94
Batch: 660; loss: 0.08; acc: 1.0
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2690143076952096; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 7.088866550475359e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2337350199224463; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 7.41397961974144e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21525623554446896; val_accuracy: 0.9363057324840764 

The current subspace-distance is: 7.719099812675267e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.83
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.44; acc: 0.91
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.23070007462979883; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 7.998920773388818e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.59; acc: 0.84
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.23111908192372627; val_accuracy: 0.9266520700636943 

The current subspace-distance is: 8.281458576675504e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.05; acc: 1.0
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19954583589818067; val_accuracy: 0.9408837579617835 

The current subspace-distance is: 8.562213770346716e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.13; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.11; acc: 1.0
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20849956042922227; val_accuracy: 0.9377985668789809 

The current subspace-distance is: 8.843037358019501e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.98
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.06; acc: 1.0
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.97
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19748880524354376; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 9.106851211981848e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.95
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.97
Batch: 400; loss: 0.08; acc: 1.0
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.201122722285948; val_accuracy: 0.9396894904458599 

The current subspace-distance is: 9.363477875012904e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.37; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19659026842682983; val_accuracy: 0.9410828025477707 

The current subspace-distance is: 9.590906120138243e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.52; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1998211878595079; val_accuracy: 0.9407842356687898 

The current subspace-distance is: 9.867265907814726e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.51; acc: 0.86
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.38; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.91
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.20640188875566623; val_accuracy: 0.9368033439490446 

The current subspace-distance is: 0.000100943427241873 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1983728904965197; val_accuracy: 0.9397890127388535 

The current subspace-distance is: 0.0001032368527376093 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.08; acc: 1.0
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.25; acc: 0.88
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.98
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.53; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20068520082125238; val_accuracy: 0.9405851910828026 

The current subspace-distance is: 0.0001056557593983598 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.89
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.22855935547097472; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 0.00010798490257002413 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.88
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.89
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2005985626938996; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 0.00010987342102453113 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.89
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22019062483101892; val_accuracy: 0.9335191082802548 

The current subspace-distance is: 0.00011113347864011303 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.84
Batch: 460; loss: 0.22; acc: 0.89
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.08; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1950791204810902; val_accuracy: 0.9407842356687898 

The current subspace-distance is: 0.00011304885265417397 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.1946790952496468; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 0.00011505393194966018 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.84
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19866266531074883; val_accuracy: 0.9396894904458599 

The current subspace-distance is: 0.00011725837248377502 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.05; acc: 1.0
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.2; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19427785611930926; val_accuracy: 0.9416799363057324 

The current subspace-distance is: 0.00011891733447555453 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.89
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19245115793339765; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 0.00012050636723870412 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.53; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19607594317406607; val_accuracy: 0.9403861464968153 

The current subspace-distance is: 0.00012184872321086004 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1935406412431009; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 0.00012329591845627874 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.59; acc: 0.84
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19769642736976314; val_accuracy: 0.940187101910828 

The current subspace-distance is: 0.0001252768561244011 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.41; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19237123818913843; val_accuracy: 0.942078025477707 

The current subspace-distance is: 0.00012772261106874794 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.46; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19490575225679738; val_accuracy: 0.9413813694267515 

The current subspace-distance is: 0.00012939404405187815 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1921129317088112; val_accuracy: 0.9413813694267515 

The current subspace-distance is: 0.00013105226389598101 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1922857482104924; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 0.00013230505282990634 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19274572086087458; val_accuracy: 0.9414808917197452 

The current subspace-distance is: 0.00013378451694734395 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.5; acc: 0.91
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19302957801587262; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 0.00013503796071745455 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19240177285139728; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 0.00013704493176192045 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19179135276253817; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 0.000138677962240763 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.52; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19300886025284505; val_accuracy: 0.9414808917197452 

The current subspace-distance is: 0.00014060722605790943 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.41; acc: 0.83
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.84
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19167551856226983; val_accuracy: 0.9422770700636943 

The current subspace-distance is: 0.00014236127026379108 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.08; acc: 1.0
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.49; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19270856550354867; val_accuracy: 0.9421775477707006 

The current subspace-distance is: 0.0001441292988602072 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19218577525228453; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 0.0001456896570743993 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_350_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 84558
elements in E: 17770400
fraction nonzero: 0.004758362220321433
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.08
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.08
Batch: 120; loss: 2.28; acc: 0.06
Batch: 140; loss: 2.26; acc: 0.12
Batch: 160; loss: 2.23; acc: 0.3
Batch: 180; loss: 2.23; acc: 0.23
Batch: 200; loss: 2.19; acc: 0.31
Batch: 220; loss: 2.14; acc: 0.39
Batch: 240; loss: 1.96; acc: 0.62
Batch: 260; loss: 1.85; acc: 0.33
Batch: 280; loss: 1.37; acc: 0.64
Batch: 300; loss: 1.24; acc: 0.61
Batch: 320; loss: 1.04; acc: 0.62
Batch: 340; loss: 1.23; acc: 0.62
Batch: 360; loss: 0.99; acc: 0.64
Batch: 380; loss: 0.72; acc: 0.73
Batch: 400; loss: 0.69; acc: 0.81
Batch: 420; loss: 0.64; acc: 0.78
Batch: 440; loss: 0.44; acc: 0.83
Batch: 460; loss: 0.68; acc: 0.77
Batch: 480; loss: 0.61; acc: 0.84
Batch: 500; loss: 0.52; acc: 0.83
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.63; acc: 0.73
Batch: 560; loss: 0.47; acc: 0.88
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.49; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.64; acc: 0.77
Batch: 700; loss: 0.71; acc: 0.81
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 1.19; train_accuracy: 0.6 

Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.57; acc: 0.77
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.86; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.36506299242662016; val_accuracy: 0.8863455414012739 

The current subspace-distance is: 1.4432807802222669e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.43; acc: 0.8
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.57; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.87; acc: 0.78
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.51; acc: 0.8
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.57; acc: 0.86
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.97
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.18; acc: 0.89
Val Epoch over. val_loss: 0.37042019720290115; val_accuracy: 0.8805732484076433 

The current subspace-distance is: 2.2827576685813256e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.83
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.6; acc: 0.86
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.09; acc: 1.0
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26179618492817425; val_accuracy: 0.9169984076433121 

The current subspace-distance is: 2.8980570277781226e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.86
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.38; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.23; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.3007164986649896; val_accuracy: 0.9019705414012739 

The current subspace-distance is: 3.495034252409823e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.88
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.48; acc: 0.88
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.38; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.58; acc: 0.78
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.82; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.4253462000162738; val_accuracy: 0.8668391719745223 

The current subspace-distance is: 4.00620156142395e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.5; acc: 0.91
Batch: 180; loss: 0.5; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.95
Batch: 420; loss: 0.44; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.84
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.88
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.17; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.51; acc: 0.89
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20479786059089528; val_accuracy: 0.939390923566879 

The current subspace-distance is: 4.389551395433955e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19333024451117606; val_accuracy: 0.943172770700637 

The current subspace-distance is: 4.79237423860468e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.42; acc: 0.81
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.94 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3629850504599559; val_accuracy: 0.8929140127388535 

The current subspace-distance is: 5.202888132771477e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.89
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.98
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.94
Val Epoch over. val_loss: 0.2472088132409533; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 5.6058117479551584e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.97
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.23; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2209430992555846; val_accuracy: 0.9339171974522293 

The current subspace-distance is: 5.9238805988570675e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.52; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18163090393801404; val_accuracy: 0.9455613057324841 

The current subspace-distance is: 6.236715853447095e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1971673789392611; val_accuracy: 0.9427746815286624 

The current subspace-distance is: 6.55249459668994e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18062979087328454; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 6.82720637996681e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.29; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.05; acc: 1.0
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.98
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.17925465659825665; val_accuracy: 0.9463574840764332 

The current subspace-distance is: 7.068740524118766e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.07; acc: 1.0
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.98
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.06; acc: 1.0
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18126370140891165; val_accuracy: 0.9481488853503185 

The current subspace-distance is: 7.333680696319789e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1893182406617198; val_accuracy: 0.9455613057324841 

The current subspace-distance is: 7.622836710652336e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1749177026283589; val_accuracy: 0.9465565286624203 

The current subspace-distance is: 7.884616206865758e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.07; acc: 1.0
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.21; acc: 0.88
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.91
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.41; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.39; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.97
Val Epoch over. val_loss: 0.17522163693882098; val_accuracy: 0.9479498407643312 

The current subspace-distance is: 8.174473623512313e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.07; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17779621723920677; val_accuracy: 0.948546974522293 

The current subspace-distance is: 8.442140824627131e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1758887791994271; val_accuracy: 0.9490445859872612 

The current subspace-distance is: 8.686881483299658e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16536380151274857; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 8.93234828254208e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.49; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.98
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16607075635414975; val_accuracy: 0.9511345541401274 

The current subspace-distance is: 9.173709258902818e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.12; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.91
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.91
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.17; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.163364256619458; val_accuracy: 0.9519307324840764 

The current subspace-distance is: 9.382647112943232e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16462979978247053; val_accuracy: 0.9525278662420382 

The current subspace-distance is: 9.578786557540298e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.56; acc: 0.89
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.33; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16606265923399835; val_accuracy: 0.9510350318471338 

The current subspace-distance is: 9.81635894277133e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.95
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16405745064187202; val_accuracy: 0.9522292993630573 

The current subspace-distance is: 9.977722947951406e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.37; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16714515240424; val_accuracy: 0.9511345541401274 

The current subspace-distance is: 0.00010143859981326386 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.05; acc: 1.0
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16892137800811963; val_accuracy: 0.9496417197452229 

The current subspace-distance is: 0.00010363657202105969 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.05; acc: 1.0
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16899522624103128; val_accuracy: 0.9506369426751592 

The current subspace-distance is: 0.00010542883683228865 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.84
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.12; acc: 0.94
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16330291767408894; val_accuracy: 0.9519307324840764 

The current subspace-distance is: 0.00010760028089862317 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1625423790400575; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 0.00010953381570288911 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16165247870383748; val_accuracy: 0.9537221337579618 

The current subspace-distance is: 0.00011136521061416715 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16419213625845636; val_accuracy: 0.9523288216560509 

The current subspace-distance is: 0.00011366992839612067 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.38; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.89
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.41; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1626969102746362; val_accuracy: 0.9527269108280255 

The current subspace-distance is: 0.00011484503920655698 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.88
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1605847755530078; val_accuracy: 0.9524283439490446 

The current subspace-distance is: 0.00011697925219777972 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.41; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.44; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16125634912947182; val_accuracy: 0.9535230891719745 

The current subspace-distance is: 0.00011917809024453163 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.05; acc: 1.0
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16429087320330796; val_accuracy: 0.9530254777070064 

The current subspace-distance is: 0.0001211856069858186 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16128036636076157; val_accuracy: 0.953125 

The current subspace-distance is: 0.0001231478963745758 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.07; acc: 1.0
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16130002424310727; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 0.00012502768367994577 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.49; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.91
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1615442476312446; val_accuracy: 0.9527269108280255 

The current subspace-distance is: 0.00012725884153041989 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.98
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.27; acc: 0.86
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16053228236877234; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 0.00012849066115450114 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.31; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.27; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.95
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16021276704350096; val_accuracy: 0.9536226114649682 

The current subspace-distance is: 0.00013074131857138127 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16059312668101045; val_accuracy: 0.9528264331210191 

The current subspace-distance is: 0.00013280403800308704 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.42; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16102773613136284; val_accuracy: 0.9533240445859873 

The current subspace-distance is: 0.00013472759746946394 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.08; acc: 1.0
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.89
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.98
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16054095956645195; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 0.00013637113443110138 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.34; acc: 0.92
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15976195303118154; val_accuracy: 0.9543192675159236 

The current subspace-distance is: 0.0001379852619720623 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.35; acc: 0.94
Batch: 520; loss: 0.07; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.31; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15991212626931015; val_accuracy: 0.9540207006369427 

The current subspace-distance is: 0.00013924826635047793 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.06; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.08; acc: 1.0
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16003246349134262; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 0.00014092502533458173 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15998257300371577; val_accuracy: 0.9538216560509554 

The current subspace-distance is: 0.0001418701431248337 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.89
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16094226110133397; val_accuracy: 0.9544187898089171 

The current subspace-distance is: 0.00014366128016263247 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 94812
elements in E: 19991700
fraction nonzero: 0.004742568165788803
Epoch 1 start
The current lr is: 1.0
/home/llang/thesis-intrinsic-dimension/logging_helper.py:44: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax1 = plt.subplots()
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.28; acc: 0.14
Batch: 120; loss: 2.26; acc: 0.17
Batch: 140; loss: 2.25; acc: 0.16
Batch: 160; loss: 2.2; acc: 0.38
Batch: 180; loss: 2.19; acc: 0.28
Batch: 200; loss: 2.08; acc: 0.41
Batch: 220; loss: 1.92; acc: 0.42
Batch: 240; loss: 1.56; acc: 0.67
Batch: 260; loss: 1.45; acc: 0.52
Batch: 280; loss: 0.98; acc: 0.66
Batch: 300; loss: 0.88; acc: 0.67
Batch: 320; loss: 0.65; acc: 0.75
Batch: 340; loss: 0.89; acc: 0.73
Batch: 360; loss: 0.53; acc: 0.8
Batch: 380; loss: 0.54; acc: 0.78
Batch: 400; loss: 0.63; acc: 0.78
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.57; acc: 0.78
Batch: 480; loss: 0.47; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.48; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.65; acc: 0.75
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 1.06; train_accuracy: 0.65 

Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.277561716094708; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 1.4585860299121123e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.69; acc: 0.81
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.54; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.47; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.52; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.54; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.33; acc: 0.84
Batch: 580; loss: 0.42; acc: 0.92
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.24498140631587642; val_accuracy: 0.926453025477707 

The current subspace-distance is: 2.3081172912498005e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.88
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.59; acc: 0.78
Batch: 680; loss: 0.52; acc: 0.86
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.2986830088553155; val_accuracy: 0.9069466560509554 

The current subspace-distance is: 2.9678483770112507e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.6; acc: 0.86
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.84
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.4044964458722218; val_accuracy: 0.8765923566878981 

The current subspace-distance is: 3.541588012012653e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.84
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.51; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.88
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.61; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.3527974035045144; val_accuracy: 0.8892316878980892 

The current subspace-distance is: 4.0391070797340944e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.17; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.07; acc: 1.0
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.53; acc: 0.78
Batch: 20; loss: 0.47; acc: 0.77
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.63; acc: 0.81
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 1.03; acc: 0.73
Batch: 140; loss: 0.29; acc: 0.86
Val Epoch over. val_loss: 0.5121928846855073; val_accuracy: 0.8321058917197452 

The current subspace-distance is: 4.49371145805344e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.73
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.44; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.95
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19724417812410433; val_accuracy: 0.9430732484076433 

The current subspace-distance is: 4.916498437523842e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.24; acc: 0.97
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.51; acc: 0.8
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.76; acc: 0.78
Batch: 100; loss: 0.42; acc: 0.8
Batch: 120; loss: 1.06; acc: 0.73
Batch: 140; loss: 0.23; acc: 0.86
Val Epoch over. val_loss: 0.5354211576235522; val_accuracy: 0.8362858280254777 

The current subspace-distance is: 5.314776717568748e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.8
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1867471665476158; val_accuracy: 0.9444665605095541 

The current subspace-distance is: 5.7070119510171935e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.47; acc: 0.91
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.5; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.06; acc: 1.0
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22805037750465096; val_accuracy: 0.932921974522293 

The current subspace-distance is: 6.052824392099865e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.28; acc: 0.86
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.44; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18361934547306627; val_accuracy: 0.9437699044585988 

The current subspace-distance is: 6.397913966793567e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.08; acc: 1.0
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.06; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.88
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.91
Batch: 400; loss: 0.07; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17218741238307042; val_accuracy: 0.949343152866242 

The current subspace-distance is: 6.736951763741672e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1807751160613291; val_accuracy: 0.9463574840764332 

The current subspace-distance is: 7.049300620565191e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18356929940118152; val_accuracy: 0.945859872611465 

The current subspace-distance is: 7.34180212020874e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.16393451758061245; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 7.632042252225801e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.43; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18596287838118092; val_accuracy: 0.9432722929936306 

The current subspace-distance is: 7.916965114418417e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.3; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.94
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.88
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18443571403622627; val_accuracy: 0.9443670382165605 

The current subspace-distance is: 8.209361840272322e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.98
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18710196148722794; val_accuracy: 0.943172770700637 

The current subspace-distance is: 8.480421092826873e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1574170798253102; val_accuracy: 0.9540207006369427 

The current subspace-distance is: 8.712907583685592e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.07; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17389999904260514; val_accuracy: 0.9500398089171974 

The current subspace-distance is: 8.961354615166783e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15143758625646306; val_accuracy: 0.9559116242038217 

The current subspace-distance is: 9.169012628262863e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15811633154939694; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 9.393133223056793e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15014454850535483; val_accuracy: 0.9559116242038217 

The current subspace-distance is: 9.635175229050219e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.48; acc: 0.89
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.3; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.05; acc: 1.0
Batch: 460; loss: 0.19; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.15; train_accuracy: 0.96 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15055508403831228; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 9.89594918792136e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.42; acc: 0.92
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1605359222621295; val_accuracy: 0.9506369426751592 

The current subspace-distance is: 0.00010150785965379328 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.5; acc: 0.89
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.06; acc: 1.0
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1498381679130208; val_accuracy: 0.9551154458598726 

The current subspace-distance is: 0.00010327839845558628 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.07; acc: 1.0
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.89
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1622116427607597; val_accuracy: 0.9513335987261147 

The current subspace-distance is: 0.00010563847899902612 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16091646156778003; val_accuracy: 0.9527269108280255 

The current subspace-distance is: 0.00010773306712508202 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.19; acc: 0.89
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1540123769052469; val_accuracy: 0.9536226114649682 

The current subspace-distance is: 0.00010961256339214742 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.96 

Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1563183580329464; val_accuracy: 0.95421974522293 

The current subspace-distance is: 0.00011155274842167273 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.94
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14911583096832987; val_accuracy: 0.9564092356687898 

The current subspace-distance is: 0.00011352139699738473 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.91
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.91
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14817870313384732; val_accuracy: 0.9559116242038217 

The current subspace-distance is: 0.0001152276890934445 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.89
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15021773952112835; val_accuracy: 0.9552149681528662 

The current subspace-distance is: 0.00011740018089767545 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14863876215401728; val_accuracy: 0.9561106687898089 

The current subspace-distance is: 0.00011938680108869448 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.92
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.24; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14884526341868815; val_accuracy: 0.9549164012738853 

The current subspace-distance is: 0.00012130215327488258 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.28; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14812158373226025; val_accuracy: 0.9559116242038217 

The current subspace-distance is: 0.00012331054313108325 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.09; acc: 1.0
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.89
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14898817084587304; val_accuracy: 0.9561106687898089 

The current subspace-distance is: 0.00012510348460637033 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.41; acc: 0.91
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.14983743597652502; val_accuracy: 0.9561106687898089 

The current subspace-distance is: 0.00012711129966191947 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.31; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14746227575715182; val_accuracy: 0.956906847133758 

The current subspace-distance is: 0.00012913667887914926 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.34; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.91
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1493958993607266; val_accuracy: 0.9559116242038217 

The current subspace-distance is: 0.00013119252980686724 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1473924601628522; val_accuracy: 0.9564092356687898 

The current subspace-distance is: 0.00013296707766130567 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14750806439169653; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 0.00013450677215587348 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.42; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.18; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14758795597086286; val_accuracy: 0.9568073248407644 

The current subspace-distance is: 0.00013631531328428537 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.92
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1476056653128308; val_accuracy: 0.9572054140127388 

The current subspace-distance is: 0.00013820709136780351 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.95
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14718501889117205; val_accuracy: 0.9557125796178344 

The current subspace-distance is: 0.00013948537525720894 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14709278808277884; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 0.00014088142779655755 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.05; acc: 1.0
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.13; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14828016243542835; val_accuracy: 0.9563097133757962 

The current subspace-distance is: 0.0001426384988008067 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.91
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.05; acc: 1.0
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1467794601799576; val_accuracy: 0.9563097133757962 

The current subspace-distance is: 0.00014419826038647443 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14786099367270802; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 0.00014609239588025957 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.35; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14718169543393858; val_accuracy: 0.9570063694267515 

The current subspace-distance is: 0.00014780300261918455 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_450_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 105803
elements in E: 22213000
fraction nonzero: 0.004763111691351911
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.27; acc: 0.14
Batch: 120; loss: 2.25; acc: 0.28
Batch: 140; loss: 2.22; acc: 0.28
Batch: 160; loss: 2.12; acc: 0.41
Batch: 180; loss: 2.02; acc: 0.38
Batch: 200; loss: 1.71; acc: 0.53
Batch: 220; loss: 1.31; acc: 0.61
Batch: 240; loss: 0.92; acc: 0.8
Batch: 260; loss: 1.36; acc: 0.56
Batch: 280; loss: 0.72; acc: 0.7
Batch: 300; loss: 0.65; acc: 0.75
Batch: 320; loss: 0.61; acc: 0.81
Batch: 340; loss: 0.93; acc: 0.73
Batch: 360; loss: 0.52; acc: 0.81
Batch: 380; loss: 0.5; acc: 0.86
Batch: 400; loss: 0.58; acc: 0.84
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.83
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.52; acc: 0.86
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.64; acc: 0.81
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.6; acc: 0.81
Batch: 700; loss: 0.37; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.48; acc: 0.83
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 1.0; train_accuracy: 0.67 

Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.31229253905783794; val_accuracy: 0.9065485668789809 

The current subspace-distance is: 1.4585364624508657e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.84
Batch: 180; loss: 0.57; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.51; acc: 0.89
Batch: 260; loss: 0.6; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.83
Batch: 320; loss: 0.33; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.54; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.53; acc: 0.77
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.81
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.43208236944903233; val_accuracy: 0.8718152866242038 

The current subspace-distance is: 2.3048212824505754e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.8
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.48; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.86
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.3965643036422456; val_accuracy: 0.8809713375796179 

The current subspace-distance is: 3.011490662174765e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.86
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.42; acc: 0.92
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.29552625034265456; val_accuracy: 0.9114251592356688 

The current subspace-distance is: 3.5891152947442606e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.07; acc: 1.0
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.8
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.85; acc: 0.66
Batch: 20; loss: 0.96; acc: 0.66
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 1.17; acc: 0.7
Batch: 80; loss: 1.07; acc: 0.72
Batch: 100; loss: 1.31; acc: 0.69
Batch: 120; loss: 1.26; acc: 0.67
Batch: 140; loss: 0.72; acc: 0.73
Val Epoch over. val_loss: 0.9032161558509633; val_accuracy: 0.7540804140127388 

The current subspace-distance is: 4.138510848861188e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.86
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.07; acc: 1.0
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2399593488236142; val_accuracy: 0.9235668789808917 

The current subspace-distance is: 4.630948751582764e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19098270895659544; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 5.13379491167143e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.94
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2042492587048157; val_accuracy: 0.9386942675159236 

The current subspace-distance is: 5.61747292522341e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.63; acc: 0.81
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.18449295940957253; val_accuracy: 0.9462579617834395 

The current subspace-distance is: 6.059632505639456e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.1; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.94
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.46; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.23; acc: 0.86
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19316723809880057; val_accuracy: 0.9455613057324841 

The current subspace-distance is: 6.432826921809465e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.43; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16143942923302862; val_accuracy: 0.9509355095541401 

The current subspace-distance is: 6.814028893131763e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.97
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17113752684490696; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 7.174042548285797e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.98
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1639439955258825; val_accuracy: 0.9503383757961783 

The current subspace-distance is: 7.488897244911641e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.89
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1754992723370054; val_accuracy: 0.9482484076433121 

The current subspace-distance is: 7.806679786881432e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.91
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.25; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.89
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16441931679939767; val_accuracy: 0.9515326433121019 

The current subspace-distance is: 8.10932251624763e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.18160902637584952; val_accuracy: 0.9438694267515924 

The current subspace-distance is: 8.411245653405786e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.1; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16520534631363146; val_accuracy: 0.9482484076433121 

The current subspace-distance is: 8.712056296644732e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.92
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.17683564971207053; val_accuracy: 0.9464570063694268 

The current subspace-distance is: 9.020594734465703e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.92
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.92
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.07; acc: 1.0
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.92
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.16517816785319595; val_accuracy: 0.9513335987261147 

The current subspace-distance is: 9.295353083871305e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.43; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1803487963784652; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 9.541670442558825e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.94
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.15416460574432544; val_accuracy: 0.9534235668789809 

The current subspace-distance is: 9.770760516403243e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.88
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.23; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.15570255409285522; val_accuracy: 0.9529259554140127 

The current subspace-distance is: 9.986521763494238e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.98
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.09; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.15123988415120512; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 0.0001022700234898366 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1493925431114473; val_accuracy: 0.9554140127388535 

The current subspace-distance is: 0.00010429730173200369 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.51; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.98
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.15100833866152036; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 0.00010644075518939644 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.88
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.98
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.09; acc: 0.94
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.91
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.14856288961733982; val_accuracy: 0.9539211783439491 

The current subspace-distance is: 0.00010873236897168681 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.06; acc: 1.0
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.15744514163037773; val_accuracy: 0.951234076433121 

The current subspace-distance is: 0.00011082210403401405 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.44; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.91
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16381007221758745; val_accuracy: 0.9518312101910829 

The current subspace-distance is: 0.00011317097232677042 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.02; acc: 0.98
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.41; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.92
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.16347683695661033; val_accuracy: 0.95203025477707 

The current subspace-distance is: 0.00011542563879629597 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1530263114032472; val_accuracy: 0.9545183121019108 

The current subspace-distance is: 0.00011777373583754525 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.05; acc: 1.0
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.91
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14703192073068802; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 0.00012016258551739156 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.03; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.97
Val Epoch over. val_loss: 0.1460813313342963; val_accuracy: 0.9562101910828026 

The current subspace-distance is: 0.00012279374641366303 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.27; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.09; acc: 1.0
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.98
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14420943263514785; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 0.00012514484114944935 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.27; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.06; acc: 1.0
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14525128072898857; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 0.00012713047908619046 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.14; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14643914831481922; val_accuracy: 0.9554140127388535 

The current subspace-distance is: 0.00012882564624305815 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.92
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14551105108230736; val_accuracy: 0.9563097133757962 

The current subspace-distance is: 0.00013060604396741837 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.92
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.14831722041319131; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 0.00013272666546981782 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.97
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14409838654812734; val_accuracy: 0.9554140127388535 

The current subspace-distance is: 0.00013420087634585798 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.39; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14566575365651185; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 0.00013618737284559757 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.44; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.15159566923501386; val_accuracy: 0.9544187898089171 

The current subspace-distance is: 0.0001379973691655323 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.41; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.21; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14409312463490068; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 0.00013970676809549332 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14526908479298756; val_accuracy: 0.9556130573248408 

The current subspace-distance is: 0.0001413279678672552 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.21; acc: 0.97
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14497613505857765; val_accuracy: 0.9557125796178344 

The current subspace-distance is: 0.00014300949987955391 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.52; acc: 0.92
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1452822973536458; val_accuracy: 0.9548168789808917 

The current subspace-distance is: 0.00014458635996561497 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.22; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.24; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.89
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1445310496885306; val_accuracy: 0.955812101910828 

The current subspace-distance is: 0.0001463685039198026 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14353581624710635; val_accuracy: 0.955812101910828 

The current subspace-distance is: 0.00014801112411078066 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.91
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1438699702073814; val_accuracy: 0.9562101910828026 

The current subspace-distance is: 0.00015029186033643782 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14341021974565119; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 0.0001518021890660748 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.08; acc: 0.95
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14399324371746391; val_accuracy: 0.9562101910828026 

The current subspace-distance is: 0.00015343402628786862 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.92
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.98
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.09; acc: 0.94
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.97
Val Epoch over. val_loss: 0.14440552702849838; val_accuracy: 0.9564092356687898 

The current subspace-distance is: 0.0001552818139316514 

plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
plots/subspace_training/lenet/2020-01-22 14:35:09/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
