model : reg_lenet_2
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 2
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : True
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 20:48:50
nonzero elements in E: 7154
elements in E: 988700
fraction nonzero: 0.007235764134722363
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.32; acc: 0.09
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.32; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.03
Batch: 200; loss: 2.31; acc: 0.12
Batch: 220; loss: 2.32; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.09
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.32; acc: 0.08
Batch: 300; loss: 2.31; acc: 0.05
Batch: 320; loss: 2.32; acc: 0.05
Batch: 340; loss: 2.3; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.16
Batch: 380; loss: 2.31; acc: 0.06
Batch: 400; loss: 2.31; acc: 0.11
Batch: 420; loss: 2.31; acc: 0.08
Batch: 440; loss: 2.3; acc: 0.06
Batch: 460; loss: 2.3; acc: 0.14
Batch: 480; loss: 2.32; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.16
Batch: 520; loss: 2.31; acc: 0.08
Batch: 540; loss: 2.3; acc: 0.14
Batch: 560; loss: 2.3; acc: 0.05
Batch: 580; loss: 2.31; acc: 0.12
Batch: 600; loss: 2.32; acc: 0.03
Batch: 620; loss: 2.31; acc: 0.16
Batch: 640; loss: 2.3; acc: 0.06
Batch: 660; loss: 2.31; acc: 0.09
Batch: 680; loss: 2.31; acc: 0.12
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.31; acc: 0.12
Batch: 740; loss: 2.31; acc: 0.08
Batch: 760; loss: 2.32; acc: 0.08
Batch: 780; loss: 2.31; acc: 0.12
Train Epoch over. train_loss: 2.31; train_accuracy: 0.1 

5.760252861364279e-06
3.2654440929036355e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.16
Batch: 80; loss: 2.31; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.17
Batch: 140; loss: 2.31; acc: 0.09
Val Epoch over. val_loss: 2.3059919670129276; val_accuracy: 0.11962579617834394 

The current subspace-distance is: 3.2654440929036355e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.11
Batch: 20; loss: 2.32; acc: 0.16
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.05
Batch: 120; loss: 2.31; acc: 0.09
Batch: 140; loss: 2.29; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.16
Batch: 200; loss: 2.3; acc: 0.16
Batch: 220; loss: 2.3; acc: 0.19
Batch: 240; loss: 2.31; acc: 0.14
Batch: 260; loss: 2.32; acc: 0.06
Batch: 280; loss: 2.31; acc: 0.08
Batch: 300; loss: 2.32; acc: 0.12
Batch: 320; loss: 2.31; acc: 0.14
Batch: 340; loss: 2.3; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.16
Batch: 380; loss: 2.29; acc: 0.2
Batch: 400; loss: 2.31; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.17
Batch: 440; loss: 2.32; acc: 0.14
Batch: 460; loss: 2.31; acc: 0.14
Batch: 480; loss: 2.29; acc: 0.25
Batch: 500; loss: 2.3; acc: 0.27
Batch: 520; loss: 2.29; acc: 0.22
Batch: 540; loss: 2.32; acc: 0.2
Batch: 560; loss: 2.31; acc: 0.19
Batch: 580; loss: 2.3; acc: 0.16
Batch: 600; loss: 2.31; acc: 0.16
Batch: 620; loss: 2.31; acc: 0.19
Batch: 640; loss: 2.3; acc: 0.16
Batch: 660; loss: 2.31; acc: 0.19
Batch: 680; loss: 2.31; acc: 0.17
Batch: 700; loss: 2.31; acc: 0.19
Batch: 720; loss: 2.3; acc: 0.19
Batch: 740; loss: 2.29; acc: 0.2
Batch: 760; loss: 2.29; acc: 0.28
Batch: 780; loss: 2.29; acc: 0.23
Train Epoch over. train_loss: 2.3; train_accuracy: 0.16 

6.347500402625883e-06
5.075681883681682e-07
Batch: 0; loss: 2.29; acc: 0.17
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.3; acc: 0.22
Batch: 60; loss: 2.3; acc: 0.19
Batch: 80; loss: 2.3; acc: 0.19
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.31; acc: 0.19
Val Epoch over. val_loss: 2.3034945323968388; val_accuracy: 0.17824442675159236 

The current subspace-distance is: 5.075681883681682e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.19
Batch: 20; loss: 2.28; acc: 0.3
Batch: 40; loss: 2.3; acc: 0.19
Batch: 60; loss: 2.3; acc: 0.22
Batch: 80; loss: 2.31; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.22
Batch: 160; loss: 2.3; acc: 0.27
Batch: 180; loss: 2.29; acc: 0.17
Batch: 200; loss: 2.3; acc: 0.17
Batch: 220; loss: 2.29; acc: 0.22
Batch: 240; loss: 2.31; acc: 0.14
Batch: 260; loss: 2.31; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.16
Batch: 320; loss: 2.31; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.28; acc: 0.25
Batch: 400; loss: 2.3; acc: 0.14
Batch: 420; loss: 2.29; acc: 0.23
Batch: 440; loss: 2.3; acc: 0.2
Batch: 460; loss: 2.3; acc: 0.14
Batch: 480; loss: 2.3; acc: 0.08
Batch: 500; loss: 2.31; acc: 0.08
Batch: 520; loss: 2.31; acc: 0.12
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.31; acc: 0.19
Batch: 600; loss: 2.31; acc: 0.11
Batch: 620; loss: 2.31; acc: 0.05
Batch: 640; loss: 2.31; acc: 0.06
Batch: 660; loss: 2.29; acc: 0.19
Batch: 680; loss: 2.31; acc: 0.08
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.3; acc: 0.11
Batch: 760; loss: 2.31; acc: 0.08
Batch: 780; loss: 2.31; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.14 

6.9056077336426824e-06
6.216304768713599e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.09
Val Epoch over. val_loss: 2.301523630786094; val_accuracy: 0.11355493630573249 

The current subspace-distance is: 6.216304768713599e-07 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.19
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.31; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.31; acc: 0.08
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.09
Batch: 260; loss: 2.31; acc: 0.16
Batch: 280; loss: 2.31; acc: 0.14
Batch: 300; loss: 2.3; acc: 0.16
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.22
Batch: 360; loss: 2.28; acc: 0.14
Batch: 380; loss: 2.3; acc: 0.17
Batch: 400; loss: 2.3; acc: 0.11
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.14
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.17
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.31; acc: 0.08
Batch: 540; loss: 2.29; acc: 0.17
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.16
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.3; acc: 0.14
Batch: 640; loss: 2.31; acc: 0.06
Batch: 660; loss: 2.31; acc: 0.05
Batch: 680; loss: 2.29; acc: 0.17
Batch: 700; loss: 2.3; acc: 0.08
Batch: 720; loss: 2.3; acc: 0.14
Batch: 740; loss: 2.29; acc: 0.08
Batch: 760; loss: 2.29; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.06
Train Epoch over. train_loss: 2.3; train_accuracy: 0.12 

7.408512374240672e-06
8.761754202168959e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Val Epoch over. val_loss: 2.2999794862832235; val_accuracy: 0.11405254777070063 

The current subspace-distance is: 8.761754202168959e-07 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.17
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.22
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.31; acc: 0.08
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.3; acc: 0.17
Batch: 240; loss: 2.31; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.16
Batch: 320; loss: 2.3; acc: 0.08
Batch: 340; loss: 2.29; acc: 0.19
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.09
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.29; acc: 0.17
Batch: 520; loss: 2.29; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.29; acc: 0.2
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.12
Batch: 660; loss: 2.29; acc: 0.09
Batch: 680; loss: 2.29; acc: 0.17
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.31; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.16
Batch: 760; loss: 2.31; acc: 0.05
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.13 

7.120013378880685e-06
1.1910371995327296e-06
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.11
Val Epoch over. val_loss: 2.2982707676614167; val_accuracy: 0.12549761146496816 

The current subspace-distance is: 1.1910371995327296e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.23
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.31; acc: 0.11
Batch: 180; loss: 2.3; acc: 0.14
Batch: 200; loss: 2.3; acc: 0.16
Batch: 220; loss: 2.3; acc: 0.19
Batch: 240; loss: 2.29; acc: 0.22
Batch: 260; loss: 2.3; acc: 0.16
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.3; acc: 0.16
Batch: 320; loss: 2.3; acc: 0.16
Batch: 340; loss: 2.3; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.14
Batch: 380; loss: 2.31; acc: 0.14
Batch: 400; loss: 2.3; acc: 0.16
Batch: 420; loss: 2.29; acc: 0.17
Batch: 440; loss: 2.31; acc: 0.11
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.12
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.3; acc: 0.11
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.16
Batch: 580; loss: 2.3; acc: 0.09
Batch: 600; loss: 2.29; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.2
Batch: 660; loss: 2.29; acc: 0.2
Batch: 680; loss: 2.3; acc: 0.12
Batch: 700; loss: 2.3; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.17
Batch: 740; loss: 2.29; acc: 0.16
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.3; acc: 0.09
Train Epoch over. train_loss: 2.3; train_accuracy: 0.15 

7.725102477706969e-06
1.3257782711662003e-06
Batch: 0; loss: 2.29; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.14
Val Epoch over. val_loss: 2.2957980632781982; val_accuracy: 0.1435111464968153 

The current subspace-distance is: 1.3257782711662003e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.28; acc: 0.23
Batch: 80; loss: 2.31; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.2
Batch: 120; loss: 2.29; acc: 0.19
Batch: 140; loss: 2.29; acc: 0.17
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.29; acc: 0.17
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.14
Batch: 300; loss: 2.29; acc: 0.2
Batch: 320; loss: 2.3; acc: 0.06
Batch: 340; loss: 2.31; acc: 0.09
Batch: 360; loss: 2.28; acc: 0.22
Batch: 380; loss: 2.3; acc: 0.11
Batch: 400; loss: 2.29; acc: 0.23
Batch: 420; loss: 2.28; acc: 0.22
Batch: 440; loss: 2.31; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.17
Batch: 480; loss: 2.3; acc: 0.14
Batch: 500; loss: 2.29; acc: 0.19
Batch: 520; loss: 2.29; acc: 0.16
Batch: 540; loss: 2.3; acc: 0.11
Batch: 560; loss: 2.3; acc: 0.14
Batch: 580; loss: 2.29; acc: 0.2
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.19
Batch: 640; loss: 2.28; acc: 0.2
Batch: 660; loss: 2.3; acc: 0.11
Batch: 680; loss: 2.3; acc: 0.09
Batch: 700; loss: 2.28; acc: 0.25
Batch: 720; loss: 2.3; acc: 0.17
Batch: 740; loss: 2.29; acc: 0.2
Batch: 760; loss: 2.29; acc: 0.17
Batch: 780; loss: 2.3; acc: 0.14
Train Epoch over. train_loss: 2.29; train_accuracy: 0.17 

8.337523468071595e-06
1.4478752063951106e-06
Batch: 0; loss: 2.29; acc: 0.23
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.28; acc: 0.22
Batch: 60; loss: 2.28; acc: 0.19
Batch: 80; loss: 2.29; acc: 0.2
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.2
Batch: 140; loss: 2.29; acc: 0.19
Val Epoch over. val_loss: 2.2912576350436846; val_accuracy: 0.1877985668789809 

The current subspace-distance is: 1.4478752063951106e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.3; acc: 0.17
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.29; acc: 0.2
Batch: 100; loss: 2.28; acc: 0.22
Batch: 120; loss: 2.29; acc: 0.22
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.17
Batch: 220; loss: 2.28; acc: 0.23
Batch: 240; loss: 2.29; acc: 0.17
Batch: 260; loss: 2.28; acc: 0.23
Batch: 280; loss: 2.29; acc: 0.22
Batch: 300; loss: 2.28; acc: 0.31
Batch: 320; loss: 2.3; acc: 0.14
Batch: 340; loss: 2.27; acc: 0.3
Batch: 360; loss: 2.29; acc: 0.2
Batch: 380; loss: 2.29; acc: 0.2
Batch: 400; loss: 2.27; acc: 0.34
Batch: 420; loss: 2.29; acc: 0.17
Batch: 440; loss: 2.29; acc: 0.2
Batch: 460; loss: 2.28; acc: 0.27
Batch: 480; loss: 2.29; acc: 0.31
Batch: 500; loss: 2.29; acc: 0.25
Batch: 520; loss: 2.28; acc: 0.25
Batch: 540; loss: 2.27; acc: 0.31
Batch: 560; loss: 2.3; acc: 0.2
Batch: 580; loss: 2.28; acc: 0.25
Batch: 600; loss: 2.29; acc: 0.22
Batch: 620; loss: 2.28; acc: 0.27
Batch: 640; loss: 2.27; acc: 0.28
Batch: 660; loss: 2.27; acc: 0.27
Batch: 680; loss: 2.29; acc: 0.17
Batch: 700; loss: 2.27; acc: 0.25
Batch: 720; loss: 2.27; acc: 0.3
Batch: 740; loss: 2.29; acc: 0.23
Batch: 760; loss: 2.28; acc: 0.25
Batch: 780; loss: 2.28; acc: 0.23
Train Epoch over. train_loss: 2.29; train_accuracy: 0.22 

8.064624125836417e-06
1.600719542693696e-06
Batch: 0; loss: 2.27; acc: 0.27
Batch: 20; loss: 2.29; acc: 0.23
Batch: 40; loss: 2.27; acc: 0.27
Batch: 60; loss: 2.27; acc: 0.31
Batch: 80; loss: 2.28; acc: 0.22
Batch: 100; loss: 2.29; acc: 0.19
Batch: 120; loss: 2.27; acc: 0.27
Batch: 140; loss: 2.28; acc: 0.23
Val Epoch over. val_loss: 2.2809805961171534; val_accuracy: 0.2262141719745223 

The current subspace-distance is: 1.600719542693696e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.2
Batch: 20; loss: 2.29; acc: 0.25
Batch: 40; loss: 2.29; acc: 0.22
Batch: 60; loss: 2.29; acc: 0.19
Batch: 80; loss: 2.28; acc: 0.22
Batch: 100; loss: 2.28; acc: 0.2
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.3
Batch: 160; loss: 2.28; acc: 0.19
Batch: 180; loss: 2.29; acc: 0.23
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.28; acc: 0.19
Batch: 260; loss: 2.27; acc: 0.2
Batch: 280; loss: 2.28; acc: 0.19
Batch: 300; loss: 2.28; acc: 0.22
Batch: 320; loss: 2.28; acc: 0.2
Batch: 340; loss: 2.27; acc: 0.19
Batch: 360; loss: 2.28; acc: 0.2
Batch: 380; loss: 2.27; acc: 0.22
Batch: 400; loss: 2.27; acc: 0.2
Batch: 420; loss: 2.3; acc: 0.11
Batch: 440; loss: 2.27; acc: 0.25
Batch: 460; loss: 2.27; acc: 0.22
Batch: 480; loss: 2.28; acc: 0.19
Batch: 500; loss: 2.28; acc: 0.16
Batch: 520; loss: 2.27; acc: 0.17
Batch: 540; loss: 2.27; acc: 0.16
Batch: 560; loss: 2.27; acc: 0.16
Batch: 580; loss: 2.27; acc: 0.17
Batch: 600; loss: 2.26; acc: 0.25
Batch: 620; loss: 2.25; acc: 0.28
Batch: 640; loss: 2.26; acc: 0.2
Batch: 660; loss: 2.26; acc: 0.2
Batch: 680; loss: 2.24; acc: 0.27
Batch: 700; loss: 2.26; acc: 0.2
Batch: 720; loss: 2.26; acc: 0.22
Batch: 740; loss: 2.27; acc: 0.22
Batch: 760; loss: 2.25; acc: 0.34
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.27; train_accuracy: 0.22 

1.1009708032361232e-05
2.5886458843160653e-06
Batch: 0; loss: 2.25; acc: 0.34
Batch: 20; loss: 2.28; acc: 0.23
Batch: 40; loss: 2.25; acc: 0.23
Batch: 60; loss: 2.25; acc: 0.33
Batch: 80; loss: 2.26; acc: 0.25
Batch: 100; loss: 2.28; acc: 0.17
Batch: 120; loss: 2.26; acc: 0.23
Batch: 140; loss: 2.25; acc: 0.22
Val Epoch over. val_loss: 2.2605875176229295; val_accuracy: 0.20979299363057324 

The current subspace-distance is: 2.5886458843160653e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 2.25; acc: 0.2
Batch: 20; loss: 2.27; acc: 0.16
Batch: 40; loss: 2.27; acc: 0.17
Batch: 60; loss: 2.24; acc: 0.3
Batch: 80; loss: 2.25; acc: 0.22
Batch: 100; loss: 2.25; acc: 0.23
Batch: 120; loss: 2.25; acc: 0.25
Batch: 140; loss: 2.27; acc: 0.16
Batch: 160; loss: 2.26; acc: 0.16
Batch: 180; loss: 2.25; acc: 0.16
Batch: 200; loss: 2.23; acc: 0.28
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.25; acc: 0.16
Batch: 260; loss: 2.26; acc: 0.16
Batch: 280; loss: 2.2; acc: 0.28
Batch: 300; loss: 2.26; acc: 0.27
Batch: 320; loss: 2.23; acc: 0.23
Batch: 340; loss: 2.24; acc: 0.2
Batch: 360; loss: 2.24; acc: 0.16
Batch: 380; loss: 2.25; acc: 0.19
Batch: 400; loss: 2.22; acc: 0.28
Batch: 420; loss: 2.21; acc: 0.27
Batch: 440; loss: 2.24; acc: 0.22
Batch: 460; loss: 2.21; acc: 0.31
Batch: 480; loss: 2.25; acc: 0.23
Batch: 500; loss: 2.24; acc: 0.23
Batch: 520; loss: 2.22; acc: 0.22
Batch: 540; loss: 2.2; acc: 0.27
Batch: 560; loss: 2.2; acc: 0.23
Batch: 580; loss: 2.24; acc: 0.28
Batch: 600; loss: 2.27; acc: 0.16
Batch: 620; loss: 2.19; acc: 0.38
Batch: 640; loss: 2.24; acc: 0.14
Batch: 660; loss: 2.14; acc: 0.38
Batch: 680; loss: 2.19; acc: 0.31
Batch: 700; loss: 2.22; acc: 0.22
Batch: 720; loss: 2.18; acc: 0.3
Batch: 740; loss: 2.24; acc: 0.2
Batch: 760; loss: 2.22; acc: 0.25
Batch: 780; loss: 2.16; acc: 0.27
Train Epoch over. train_loss: 2.23; train_accuracy: 0.23 

1.2425254681147635e-05
3.042453272428247e-06
Batch: 0; loss: 2.2; acc: 0.23
Batch: 20; loss: 2.26; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.27
Batch: 60; loss: 2.21; acc: 0.2
Batch: 80; loss: 2.18; acc: 0.27
Batch: 100; loss: 2.25; acc: 0.17
Batch: 120; loss: 2.25; acc: 0.2
Batch: 140; loss: 2.17; acc: 0.33
Val Epoch over. val_loss: 2.2002736869131683; val_accuracy: 0.2619426751592357 

The current subspace-distance is: 3.042453272428247e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.17; acc: 0.19
Batch: 20; loss: 2.18; acc: 0.25
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.21; acc: 0.34
Batch: 80; loss: 2.15; acc: 0.31
Batch: 100; loss: 2.17; acc: 0.39
Batch: 120; loss: 2.22; acc: 0.23
Batch: 140; loss: 2.18; acc: 0.22
Batch: 160; loss: 2.2; acc: 0.3
Batch: 180; loss: 2.2; acc: 0.28
Batch: 200; loss: 2.17; acc: 0.28
Batch: 220; loss: 2.21; acc: 0.25
Batch: 240; loss: 2.17; acc: 0.3
Batch: 260; loss: 2.13; acc: 0.38
Batch: 280; loss: 2.2; acc: 0.3
Batch: 300; loss: 2.18; acc: 0.31
Batch: 320; loss: 2.17; acc: 0.28
Batch: 340; loss: 2.22; acc: 0.2
Batch: 360; loss: 2.15; acc: 0.33
Batch: 380; loss: 2.17; acc: 0.3
Batch: 400; loss: 2.17; acc: 0.25
Batch: 420; loss: 2.19; acc: 0.31
Batch: 440; loss: 2.23; acc: 0.25
Batch: 460; loss: 2.18; acc: 0.27
Batch: 480; loss: 2.13; acc: 0.39
Batch: 500; loss: 2.13; acc: 0.31
Batch: 520; loss: 2.13; acc: 0.25
Batch: 540; loss: 2.21; acc: 0.23
Batch: 560; loss: 2.15; acc: 0.28
Batch: 580; loss: 2.21; acc: 0.2
Batch: 600; loss: 2.22; acc: 0.2
Batch: 620; loss: 2.21; acc: 0.17
Batch: 640; loss: 2.21; acc: 0.22
Batch: 660; loss: 2.15; acc: 0.27
Batch: 680; loss: 2.11; acc: 0.3
Batch: 700; loss: 2.15; acc: 0.23
Batch: 720; loss: 2.16; acc: 0.22
Batch: 740; loss: 2.21; acc: 0.25
Batch: 760; loss: 2.11; acc: 0.27
Batch: 780; loss: 2.19; acc: 0.27
Train Epoch over. train_loss: 2.18; train_accuracy: 0.27 

1.4733780517417472e-05
4.0537529457651544e-06
Batch: 0; loss: 2.16; acc: 0.23
Batch: 20; loss: 2.25; acc: 0.19
Batch: 40; loss: 2.14; acc: 0.23
Batch: 60; loss: 2.14; acc: 0.22
Batch: 80; loss: 2.12; acc: 0.27
Batch: 100; loss: 2.23; acc: 0.12
Batch: 120; loss: 2.23; acc: 0.2
Batch: 140; loss: 2.1; acc: 0.34
Val Epoch over. val_loss: 2.1641625295019455; val_accuracy: 0.26253980891719747 

The current subspace-distance is: 4.0537529457651544e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 2.19; acc: 0.23
Batch: 20; loss: 2.18; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.04; acc: 0.34
Batch: 80; loss: 2.19; acc: 0.22
Batch: 100; loss: 2.18; acc: 0.2
Batch: 120; loss: 2.17; acc: 0.22
Batch: 140; loss: 2.19; acc: 0.27
Batch: 160; loss: 2.1; acc: 0.33
Batch: 180; loss: 2.11; acc: 0.33
Batch: 200; loss: 2.13; acc: 0.28
Batch: 220; loss: 2.06; acc: 0.41
Batch: 240; loss: 2.23; acc: 0.25
Batch: 260; loss: 2.12; acc: 0.25
Batch: 280; loss: 2.16; acc: 0.23
Batch: 300; loss: 2.13; acc: 0.27
Batch: 320; loss: 2.13; acc: 0.25
Batch: 340; loss: 2.18; acc: 0.16
Batch: 360; loss: 2.16; acc: 0.3
Batch: 380; loss: 2.14; acc: 0.28
Batch: 400; loss: 2.03; acc: 0.33
Batch: 420; loss: 2.21; acc: 0.16
Batch: 440; loss: 2.14; acc: 0.27
Batch: 460; loss: 2.11; acc: 0.3
Batch: 480; loss: 2.2; acc: 0.25
Batch: 500; loss: 2.07; acc: 0.33
Batch: 520; loss: 2.11; acc: 0.23
Batch: 540; loss: 2.13; acc: 0.2
Batch: 560; loss: 2.18; acc: 0.22
Batch: 580; loss: 2.05; acc: 0.3
Batch: 600; loss: 2.08; acc: 0.33
Batch: 620; loss: 2.13; acc: 0.3
Batch: 640; loss: 2.15; acc: 0.17
Batch: 660; loss: 2.12; acc: 0.25
Batch: 680; loss: 2.19; acc: 0.19
Batch: 700; loss: 2.12; acc: 0.27
Batch: 720; loss: 2.07; acc: 0.27
Batch: 740; loss: 2.22; acc: 0.22
Batch: 760; loss: 2.17; acc: 0.25
Batch: 780; loss: 2.19; acc: 0.19
Train Epoch over. train_loss: 2.14; train_accuracy: 0.26 

1.5516980056418106e-05
4.254116902302485e-06
Batch: 0; loss: 2.1; acc: 0.2
Batch: 20; loss: 2.22; acc: 0.14
Batch: 40; loss: 2.06; acc: 0.25
Batch: 60; loss: 2.05; acc: 0.25
Batch: 80; loss: 2.05; acc: 0.25
Batch: 100; loss: 2.19; acc: 0.16
Batch: 120; loss: 2.18; acc: 0.2
Batch: 140; loss: 2.02; acc: 0.33
Val Epoch over. val_loss: 2.109871639567576; val_accuracy: 0.2483081210191083 

The current subspace-distance is: 4.254116902302485e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 2.16; acc: 0.23
Batch: 20; loss: 2.11; acc: 0.23
Batch: 40; loss: 2.0; acc: 0.33
Batch: 60; loss: 2.2; acc: 0.19
Batch: 80; loss: 2.17; acc: 0.2
Batch: 100; loss: 2.1; acc: 0.23
Batch: 120; loss: 2.05; acc: 0.28
Batch: 140; loss: 2.12; acc: 0.23
Batch: 160; loss: 2.17; acc: 0.16
Batch: 180; loss: 2.13; acc: 0.25
Batch: 200; loss: 2.09; acc: 0.23
Batch: 220; loss: 2.14; acc: 0.2
Batch: 240; loss: 2.07; acc: 0.2
Batch: 260; loss: 2.14; acc: 0.2
Batch: 280; loss: 2.1; acc: 0.3
Batch: 300; loss: 2.05; acc: 0.22
Batch: 320; loss: 2.11; acc: 0.22
Batch: 340; loss: 2.11; acc: 0.2
Batch: 360; loss: 2.15; acc: 0.16
Batch: 380; loss: 2.07; acc: 0.25
Batch: 400; loss: 2.08; acc: 0.23
Batch: 420; loss: 2.1; acc: 0.23
Batch: 440; loss: 2.1; acc: 0.25
Batch: 460; loss: 2.09; acc: 0.25
Batch: 480; loss: 2.09; acc: 0.25
Batch: 500; loss: 2.17; acc: 0.2
Batch: 520; loss: 2.04; acc: 0.31
Batch: 540; loss: 2.06; acc: 0.23
Batch: 560; loss: 2.1; acc: 0.17
Batch: 580; loss: 2.02; acc: 0.2
Batch: 600; loss: 2.01; acc: 0.33
Batch: 620; loss: 1.87; acc: 0.42
Batch: 640; loss: 2.07; acc: 0.22
Batch: 660; loss: 2.02; acc: 0.33
Batch: 680; loss: 2.02; acc: 0.23
Batch: 700; loss: 2.06; acc: 0.25
Batch: 720; loss: 2.02; acc: 0.3
Batch: 740; loss: 1.98; acc: 0.3
Batch: 760; loss: 2.05; acc: 0.23
Batch: 780; loss: 2.0; acc: 0.23
Train Epoch over. train_loss: 2.07; train_accuracy: 0.25 

1.6061385395005345e-05
4.398832970764488e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 2.15; acc: 0.19
Batch: 40; loss: 1.94; acc: 0.3
Batch: 60; loss: 1.91; acc: 0.31
Batch: 80; loss: 1.9; acc: 0.3
Batch: 100; loss: 2.13; acc: 0.19
Batch: 120; loss: 2.1; acc: 0.22
Batch: 140; loss: 1.89; acc: 0.33
Val Epoch over. val_loss: 2.0196395186102314; val_accuracy: 0.26025079617834396 

The current subspace-distance is: 4.398832970764488e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 2.01; acc: 0.27
Batch: 20; loss: 1.88; acc: 0.31
Batch: 40; loss: 1.9; acc: 0.33
Batch: 60; loss: 1.96; acc: 0.31
Batch: 80; loss: 2.05; acc: 0.12
Batch: 100; loss: 1.96; acc: 0.3
Batch: 120; loss: 1.94; acc: 0.34
Batch: 140; loss: 2.02; acc: 0.27
Batch: 160; loss: 2.13; acc: 0.2
Batch: 180; loss: 1.93; acc: 0.33
Batch: 200; loss: 2.06; acc: 0.22
Batch: 220; loss: 2.09; acc: 0.27
Batch: 240; loss: 2.0; acc: 0.27
Batch: 260; loss: 1.98; acc: 0.36
Batch: 280; loss: 2.05; acc: 0.23
Batch: 300; loss: 2.01; acc: 0.27
Batch: 320; loss: 1.91; acc: 0.3
Batch: 340; loss: 1.8; acc: 0.39
Batch: 360; loss: 1.79; acc: 0.38
Batch: 380; loss: 1.89; acc: 0.3
Batch: 400; loss: 1.96; acc: 0.3
Batch: 420; loss: 1.74; acc: 0.42
Batch: 440; loss: 1.84; acc: 0.42
Batch: 460; loss: 1.98; acc: 0.28
Batch: 480; loss: 1.84; acc: 0.34
Batch: 500; loss: 1.94; acc: 0.34
Batch: 520; loss: 1.87; acc: 0.31
Batch: 540; loss: 1.72; acc: 0.39
Batch: 560; loss: 1.77; acc: 0.42
Batch: 580; loss: 1.88; acc: 0.27
Batch: 600; loss: 1.81; acc: 0.38
Batch: 620; loss: 1.88; acc: 0.39
Batch: 640; loss: 1.84; acc: 0.3
Batch: 660; loss: 1.81; acc: 0.3
Batch: 680; loss: 1.89; acc: 0.36
Batch: 700; loss: 1.72; acc: 0.42
Batch: 720; loss: 1.92; acc: 0.31
Batch: 740; loss: 1.79; acc: 0.33
Batch: 760; loss: 1.85; acc: 0.33
Batch: 780; loss: 1.64; acc: 0.44
Train Epoch over. train_loss: 1.89; train_accuracy: 0.32 

1.803657505661249e-05
4.906215963274008e-06
Batch: 0; loss: 1.67; acc: 0.38
Batch: 20; loss: 2.01; acc: 0.22
Batch: 40; loss: 1.72; acc: 0.42
Batch: 60; loss: 1.69; acc: 0.33
Batch: 80; loss: 1.61; acc: 0.41
Batch: 100; loss: 1.84; acc: 0.39
Batch: 120; loss: 1.9; acc: 0.31
Batch: 140; loss: 1.68; acc: 0.34
Val Epoch over. val_loss: 1.778771527253898; val_accuracy: 0.34773089171974525 

The current subspace-distance is: 4.906215963274008e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 2.01; acc: 0.23
Batch: 20; loss: 1.79; acc: 0.34
Batch: 40; loss: 1.5; acc: 0.56
Batch: 60; loss: 1.77; acc: 0.3
Batch: 80; loss: 1.55; acc: 0.42
Batch: 100; loss: 1.67; acc: 0.44
Batch: 120; loss: 1.86; acc: 0.33
Batch: 140; loss: 1.68; acc: 0.42
Batch: 160; loss: 1.61; acc: 0.42
Batch: 180; loss: 1.64; acc: 0.48
Batch: 200; loss: 1.79; acc: 0.44
Batch: 220; loss: 1.85; acc: 0.34
Batch: 240; loss: 1.64; acc: 0.36
Batch: 260; loss: 1.86; acc: 0.27
Batch: 280; loss: 2.01; acc: 0.25
Batch: 300; loss: 1.77; acc: 0.36
Batch: 320; loss: 1.96; acc: 0.28
Batch: 340; loss: 1.63; acc: 0.42
Batch: 360; loss: 1.66; acc: 0.38
Batch: 380; loss: 1.78; acc: 0.33
Batch: 400; loss: 1.87; acc: 0.25
Batch: 420; loss: 1.73; acc: 0.41
Batch: 440; loss: 1.77; acc: 0.36
Batch: 460; loss: 1.46; acc: 0.5
Batch: 480; loss: 1.72; acc: 0.41
Batch: 500; loss: 1.68; acc: 0.42
Batch: 520; loss: 1.76; acc: 0.38
Batch: 540; loss: 1.9; acc: 0.33
Batch: 560; loss: 1.55; acc: 0.44
Batch: 580; loss: 1.71; acc: 0.41
Batch: 600; loss: 1.72; acc: 0.38
Batch: 620; loss: 1.91; acc: 0.28
Batch: 640; loss: 1.83; acc: 0.31
Batch: 660; loss: 1.8; acc: 0.36
Batch: 680; loss: 1.67; acc: 0.36
Batch: 700; loss: 1.69; acc: 0.38
Batch: 720; loss: 1.84; acc: 0.34
Batch: 740; loss: 1.71; acc: 0.33
Batch: 760; loss: 1.65; acc: 0.36
Batch: 780; loss: 1.92; acc: 0.33
Train Epoch over. train_loss: 1.73; train_accuracy: 0.39 

1.9927187167922966e-05
6.203264092619065e-06
Batch: 0; loss: 1.64; acc: 0.39
Batch: 20; loss: 1.87; acc: 0.31
Batch: 40; loss: 1.57; acc: 0.44
Batch: 60; loss: 1.75; acc: 0.44
Batch: 80; loss: 1.59; acc: 0.44
Batch: 100; loss: 1.69; acc: 0.45
Batch: 120; loss: 1.72; acc: 0.42
Batch: 140; loss: 1.63; acc: 0.41
Val Epoch over. val_loss: 1.6884451937523617; val_accuracy: 0.39599920382165604 

The current subspace-distance is: 6.203264092619065e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.8; acc: 0.27
Batch: 20; loss: 1.77; acc: 0.47
Batch: 40; loss: 1.95; acc: 0.33
Batch: 60; loss: 1.59; acc: 0.5
Batch: 80; loss: 1.67; acc: 0.41
Batch: 100; loss: 1.66; acc: 0.36
Batch: 120; loss: 1.75; acc: 0.39
Batch: 140; loss: 1.72; acc: 0.34
Batch: 160; loss: 1.92; acc: 0.3
Batch: 180; loss: 1.58; acc: 0.42
Batch: 200; loss: 1.93; acc: 0.38
Batch: 220; loss: 1.81; acc: 0.33
Batch: 240; loss: 1.5; acc: 0.5
Batch: 260; loss: 1.72; acc: 0.41
Batch: 280; loss: 1.67; acc: 0.41
Batch: 300; loss: 1.71; acc: 0.44
Batch: 320; loss: 1.79; acc: 0.33
Batch: 340; loss: 1.65; acc: 0.39
Batch: 360; loss: 2.0; acc: 0.33
Batch: 380; loss: 1.76; acc: 0.38
Batch: 400; loss: 1.71; acc: 0.48
Batch: 420; loss: 1.55; acc: 0.42
Batch: 440; loss: 1.61; acc: 0.41
Batch: 460; loss: 1.72; acc: 0.38
Batch: 480; loss: 1.66; acc: 0.39
Batch: 500; loss: 1.45; acc: 0.44
Batch: 520; loss: 1.74; acc: 0.41
Batch: 540; loss: 1.65; acc: 0.41
Batch: 560; loss: 1.62; acc: 0.48
Batch: 580; loss: 1.99; acc: 0.41
Batch: 600; loss: 1.59; acc: 0.48
Batch: 620; loss: 1.8; acc: 0.33
Batch: 640; loss: 1.6; acc: 0.42
Batch: 660; loss: 1.81; acc: 0.31
Batch: 680; loss: 1.95; acc: 0.28
Batch: 700; loss: 1.72; acc: 0.44
Batch: 720; loss: 1.54; acc: 0.48
Batch: 740; loss: 1.64; acc: 0.48
Batch: 760; loss: 1.73; acc: 0.42
Batch: 780; loss: 1.59; acc: 0.42
Train Epoch over. train_loss: 1.7; train_accuracy: 0.4 

1.813123162719421e-05
5.644765678880503e-06
Batch: 0; loss: 1.69; acc: 0.41
Batch: 20; loss: 1.92; acc: 0.33
Batch: 40; loss: 1.63; acc: 0.48
Batch: 60; loss: 1.78; acc: 0.39
Batch: 80; loss: 1.55; acc: 0.48
Batch: 100; loss: 1.75; acc: 0.39
Batch: 120; loss: 1.8; acc: 0.47
Batch: 140; loss: 1.59; acc: 0.42
Val Epoch over. val_loss: 1.6959301947028773; val_accuracy: 0.41391321656050956 

The current subspace-distance is: 5.644765678880503e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.55; acc: 0.48
Batch: 20; loss: 1.85; acc: 0.3
Batch: 40; loss: 1.66; acc: 0.45
Batch: 60; loss: 1.57; acc: 0.44
Batch: 80; loss: 1.72; acc: 0.41
Batch: 100; loss: 1.63; acc: 0.41
Batch: 120; loss: 1.66; acc: 0.41
Batch: 140; loss: 1.59; acc: 0.38
Batch: 160; loss: 1.87; acc: 0.3
Batch: 180; loss: 1.73; acc: 0.39
Batch: 200; loss: 1.7; acc: 0.33
Batch: 220; loss: 1.69; acc: 0.41
Batch: 240; loss: 1.61; acc: 0.45
Batch: 260; loss: 1.67; acc: 0.33
Batch: 280; loss: 1.58; acc: 0.45
Batch: 300; loss: 1.75; acc: 0.33
Batch: 320; loss: 1.58; acc: 0.48
Batch: 340; loss: 1.62; acc: 0.42
Batch: 360; loss: 1.58; acc: 0.5
Batch: 380; loss: 1.73; acc: 0.36
Batch: 400; loss: 1.83; acc: 0.33
Batch: 420; loss: 1.64; acc: 0.39
Batch: 440; loss: 1.63; acc: 0.48
Batch: 460; loss: 1.8; acc: 0.38
Batch: 480; loss: 1.65; acc: 0.33
Batch: 500; loss: 1.65; acc: 0.42
Batch: 520; loss: 1.59; acc: 0.41
Batch: 540; loss: 1.62; acc: 0.47
Batch: 560; loss: 1.63; acc: 0.47
Batch: 580; loss: 1.63; acc: 0.38
Batch: 600; loss: 1.52; acc: 0.47
Batch: 620; loss: 1.6; acc: 0.44
Batch: 640; loss: 1.71; acc: 0.47
Batch: 660; loss: 1.69; acc: 0.42
Batch: 680; loss: 1.73; acc: 0.38
Batch: 700; loss: 1.77; acc: 0.42
Batch: 720; loss: 1.56; acc: 0.42
Batch: 740; loss: 1.62; acc: 0.47
Batch: 760; loss: 1.81; acc: 0.31
Batch: 780; loss: 1.69; acc: 0.36
Train Epoch over. train_loss: 1.7; train_accuracy: 0.4 

2.299181869602762e-05
6.800146366003901e-06
Batch: 0; loss: 1.69; acc: 0.38
Batch: 20; loss: 1.92; acc: 0.3
Batch: 40; loss: 1.58; acc: 0.48
Batch: 60; loss: 1.79; acc: 0.38
Batch: 80; loss: 1.6; acc: 0.47
Batch: 100; loss: 1.72; acc: 0.34
Batch: 120; loss: 1.79; acc: 0.42
Batch: 140; loss: 1.59; acc: 0.42
Val Epoch over. val_loss: 1.6816043345032223; val_accuracy: 0.3955015923566879 

The current subspace-distance is: 6.800146366003901e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.56; acc: 0.5
Batch: 20; loss: 1.82; acc: 0.38
Batch: 40; loss: 1.73; acc: 0.38
Batch: 60; loss: 1.88; acc: 0.34
Batch: 80; loss: 1.67; acc: 0.42
Batch: 100; loss: 1.59; acc: 0.47
Batch: 120; loss: 1.89; acc: 0.31
Batch: 140; loss: 1.85; acc: 0.36
Batch: 160; loss: 1.53; acc: 0.45
Batch: 180; loss: 2.02; acc: 0.31
Batch: 200; loss: 1.76; acc: 0.36
Batch: 220; loss: 1.79; acc: 0.38
Batch: 240; loss: 1.52; acc: 0.58
Batch: 260; loss: 1.66; acc: 0.5
Batch: 280; loss: 1.79; acc: 0.36
Batch: 300; loss: 1.67; acc: 0.45
Batch: 320; loss: 1.76; acc: 0.39
Batch: 340; loss: 1.75; acc: 0.44
Batch: 360; loss: 1.73; acc: 0.41
Batch: 380; loss: 1.69; acc: 0.31
Batch: 400; loss: 1.69; acc: 0.39
Batch: 420; loss: 1.76; acc: 0.34
Batch: 440; loss: 1.62; acc: 0.38
Batch: 460; loss: 1.68; acc: 0.44
Batch: 480; loss: 1.74; acc: 0.39
Batch: 500; loss: 1.71; acc: 0.31
Batch: 520; loss: 1.64; acc: 0.42
Batch: 540; loss: 1.55; acc: 0.44
Batch: 560; loss: 1.59; acc: 0.5
Batch: 580; loss: 1.57; acc: 0.45
Batch: 600; loss: 1.49; acc: 0.47
Batch: 620; loss: 1.73; acc: 0.36
Batch: 640; loss: 1.55; acc: 0.42
Batch: 660; loss: 1.55; acc: 0.41
Batch: 680; loss: 1.55; acc: 0.47
Batch: 700; loss: 1.61; acc: 0.36
Batch: 720; loss: 1.74; acc: 0.36
Batch: 740; loss: 1.92; acc: 0.25
Batch: 760; loss: 1.55; acc: 0.5
Batch: 780; loss: 1.5; acc: 0.5
Train Epoch over. train_loss: 1.7; train_accuracy: 0.4 

1.903797783597838e-05
5.406319360190537e-06
Batch: 0; loss: 1.67; acc: 0.42
Batch: 20; loss: 1.9; acc: 0.31
Batch: 40; loss: 1.58; acc: 0.47
Batch: 60; loss: 1.76; acc: 0.36
Batch: 80; loss: 1.53; acc: 0.52
Batch: 100; loss: 1.73; acc: 0.34
Batch: 120; loss: 1.77; acc: 0.44
Batch: 140; loss: 1.55; acc: 0.48
Val Epoch over. val_loss: 1.6679420410447818; val_accuracy: 0.3991839171974522 

The current subspace-distance is: 5.406319360190537e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.57; acc: 0.48
Batch: 20; loss: 1.79; acc: 0.31
Batch: 40; loss: 1.89; acc: 0.31
Batch: 60; loss: 1.68; acc: 0.52
Batch: 80; loss: 1.48; acc: 0.53
Batch: 100; loss: 1.82; acc: 0.31
Batch: 120; loss: 1.69; acc: 0.39
Batch: 140; loss: 1.69; acc: 0.38
Batch: 160; loss: 1.74; acc: 0.36
Batch: 180; loss: 1.7; acc: 0.45
Batch: 200; loss: 1.86; acc: 0.31
Batch: 220; loss: 1.64; acc: 0.45
Batch: 240; loss: 1.63; acc: 0.41
Batch: 260; loss: 1.8; acc: 0.36
Batch: 280; loss: 1.78; acc: 0.41
Batch: 300; loss: 1.64; acc: 0.38
Batch: 320; loss: 1.77; acc: 0.31
Batch: 340; loss: 1.85; acc: 0.38
Batch: 360; loss: 1.71; acc: 0.39
Batch: 380; loss: 1.62; acc: 0.53
Batch: 400; loss: 1.92; acc: 0.42
Batch: 420; loss: 1.72; acc: 0.36
Batch: 440; loss: 1.81; acc: 0.31
Batch: 460; loss: 1.83; acc: 0.42
Batch: 480; loss: 1.6; acc: 0.48
Batch: 500; loss: 1.68; acc: 0.42
Batch: 520; loss: 1.76; acc: 0.27
Batch: 540; loss: 1.83; acc: 0.33
Batch: 560; loss: 1.64; acc: 0.39
Batch: 580; loss: 1.66; acc: 0.41
Batch: 600; loss: 1.68; acc: 0.45
Batch: 620; loss: 1.96; acc: 0.3
Batch: 640; loss: 1.84; acc: 0.3
Batch: 660; loss: 1.57; acc: 0.48
Batch: 680; loss: 1.78; acc: 0.31
Batch: 700; loss: 1.56; acc: 0.45
Batch: 720; loss: 1.75; acc: 0.38
Batch: 740; loss: 1.59; acc: 0.48
Batch: 760; loss: 1.7; acc: 0.38
Batch: 780; loss: 1.55; acc: 0.44
Train Epoch over. train_loss: 1.7; train_accuracy: 0.4 

1.9013790733879432e-05
5.553555638471153e-06
Batch: 0; loss: 1.66; acc: 0.39
Batch: 20; loss: 1.89; acc: 0.31
Batch: 40; loss: 1.57; acc: 0.44
Batch: 60; loss: 1.73; acc: 0.36
Batch: 80; loss: 1.49; acc: 0.47
Batch: 100; loss: 1.7; acc: 0.38
Batch: 120; loss: 1.68; acc: 0.48
Batch: 140; loss: 1.56; acc: 0.47
Val Epoch over. val_loss: 1.679117755525431; val_accuracy: 0.39440684713375795 

The current subspace-distance is: 5.553555638471153e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.72; acc: 0.36
Batch: 20; loss: 1.66; acc: 0.41
Batch: 40; loss: 1.64; acc: 0.41
Batch: 60; loss: 1.85; acc: 0.34
Batch: 80; loss: 1.69; acc: 0.38
Batch: 100; loss: 1.92; acc: 0.36
Batch: 120; loss: 1.68; acc: 0.45
Batch: 140; loss: 1.47; acc: 0.45
Batch: 160; loss: 1.65; acc: 0.36
Batch: 180; loss: 1.82; acc: 0.34
Batch: 200; loss: 1.65; acc: 0.39
Batch: 220; loss: 1.68; acc: 0.39
Batch: 240; loss: 1.63; acc: 0.44
Batch: 260; loss: 1.48; acc: 0.5
Batch: 280; loss: 1.82; acc: 0.33
Batch: 300; loss: 1.73; acc: 0.39
Batch: 320; loss: 1.63; acc: 0.42
Batch: 340; loss: 1.89; acc: 0.25
Batch: 360; loss: 1.78; acc: 0.36
Batch: 380; loss: 1.68; acc: 0.39
Batch: 400; loss: 1.88; acc: 0.28
Batch: 420; loss: 1.72; acc: 0.36
Batch: 440; loss: 1.71; acc: 0.31
Batch: 460; loss: 1.77; acc: 0.38
Batch: 480; loss: 1.68; acc: 0.41
Batch: 500; loss: 1.73; acc: 0.34
Batch: 520; loss: 1.61; acc: 0.55
Batch: 540; loss: 1.96; acc: 0.3
Batch: 560; loss: 1.69; acc: 0.28
Batch: 580; loss: 1.72; acc: 0.36
Batch: 600; loss: 1.83; acc: 0.31
Batch: 620; loss: 1.76; acc: 0.31
Batch: 640; loss: 1.79; acc: 0.36
Batch: 660; loss: 1.69; acc: 0.44
Batch: 680; loss: 1.49; acc: 0.5
Batch: 700; loss: 1.88; acc: 0.25
Batch: 720; loss: 1.66; acc: 0.41
Batch: 740; loss: 1.71; acc: 0.36
Batch: 760; loss: 1.83; acc: 0.31
Batch: 780; loss: 1.8; acc: 0.36
Train Epoch over. train_loss: 1.7; train_accuracy: 0.4 

2.157654489565175e-05
4.841188001591945e-06
Batch: 0; loss: 1.69; acc: 0.36
Batch: 20; loss: 1.87; acc: 0.34
Batch: 40; loss: 1.58; acc: 0.48
Batch: 60; loss: 1.72; acc: 0.41
Batch: 80; loss: 1.52; acc: 0.5
Batch: 100; loss: 1.69; acc: 0.39
Batch: 120; loss: 1.73; acc: 0.41
Batch: 140; loss: 1.54; acc: 0.47
Val Epoch over. val_loss: 1.663158482047403; val_accuracy: 0.4138136942675159 

The current subspace-distance is: 4.841188001591945e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.81; acc: 0.31
Batch: 20; loss: 1.57; acc: 0.48
Batch: 40; loss: 1.85; acc: 0.39
Batch: 60; loss: 1.76; acc: 0.41
Batch: 80; loss: 1.63; acc: 0.39
Batch: 100; loss: 1.85; acc: 0.31
Batch: 120; loss: 1.6; acc: 0.44
Batch: 140; loss: 1.82; acc: 0.31
Batch: 160; loss: 1.82; acc: 0.38
Batch: 180; loss: 1.74; acc: 0.45
Batch: 200; loss: 1.73; acc: 0.45
Batch: 220; loss: 1.78; acc: 0.42
Batch: 240; loss: 1.59; acc: 0.44
Batch: 260; loss: 1.68; acc: 0.44
Batch: 280; loss: 1.85; acc: 0.33
Batch: 300; loss: 1.61; acc: 0.41
Batch: 320; loss: 1.83; acc: 0.34
Batch: 340; loss: 1.56; acc: 0.48
Batch: 360; loss: 1.87; acc: 0.33
Batch: 380; loss: 1.8; acc: 0.33
Batch: 400; loss: 1.58; acc: 0.45
Batch: 420; loss: 1.65; acc: 0.38
Batch: 440; loss: 1.66; acc: 0.41
Batch: 460; loss: 1.64; acc: 0.39
Batch: 480; loss: 1.63; acc: 0.42
Batch: 500; loss: 1.66; acc: 0.38
Batch: 520; loss: 1.69; acc: 0.38
Batch: 540; loss: 1.61; acc: 0.47
Batch: 560; loss: 1.78; acc: 0.39
Batch: 580; loss: 1.86; acc: 0.28
Batch: 600; loss: 1.47; acc: 0.52
Batch: 620; loss: 1.77; acc: 0.34
Batch: 640; loss: 1.64; acc: 0.41
Batch: 660; loss: 1.71; acc: 0.39
Batch: 680; loss: 1.62; acc: 0.41
Batch: 700; loss: 1.63; acc: 0.34
Batch: 720; loss: 1.9; acc: 0.28
Batch: 740; loss: 1.49; acc: 0.47
Batch: 760; loss: 1.6; acc: 0.39
Batch: 780; loss: 1.59; acc: 0.41
Train Epoch over. train_loss: 1.69; train_accuracy: 0.4 

2.0657960703829303e-05
4.777540652867174e-06
Batch: 0; loss: 1.69; acc: 0.39
Batch: 20; loss: 1.92; acc: 0.27
Batch: 40; loss: 1.58; acc: 0.44
Batch: 60; loss: 1.73; acc: 0.38
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.72; acc: 0.36
Batch: 120; loss: 1.72; acc: 0.44
Batch: 140; loss: 1.54; acc: 0.48
Val Epoch over. val_loss: 1.6694348997371211; val_accuracy: 0.3956011146496815 

The current subspace-distance is: 4.777540652867174e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.72; acc: 0.42
Batch: 20; loss: 1.7; acc: 0.41
Batch: 40; loss: 1.72; acc: 0.41
Batch: 60; loss: 1.64; acc: 0.41
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.65; acc: 0.42
Batch: 120; loss: 1.78; acc: 0.33
Batch: 140; loss: 1.61; acc: 0.38
Batch: 160; loss: 1.83; acc: 0.34
Batch: 180; loss: 1.58; acc: 0.41
Batch: 200; loss: 1.66; acc: 0.41
Batch: 220; loss: 1.97; acc: 0.25
Batch: 240; loss: 1.6; acc: 0.44
Batch: 260; loss: 1.71; acc: 0.45
Batch: 280; loss: 1.62; acc: 0.48
Batch: 300; loss: 1.74; acc: 0.36
Batch: 320; loss: 1.62; acc: 0.36
Batch: 340; loss: 1.65; acc: 0.41
Batch: 360; loss: 1.6; acc: 0.45
Batch: 380; loss: 1.57; acc: 0.44
Batch: 400; loss: 1.44; acc: 0.48
Batch: 420; loss: 1.68; acc: 0.42
Batch: 440; loss: 1.66; acc: 0.31
Batch: 460; loss: 1.64; acc: 0.42
Batch: 480; loss: 1.65; acc: 0.36
Batch: 500; loss: 1.66; acc: 0.38
Batch: 520; loss: 1.53; acc: 0.5
Batch: 540; loss: 1.75; acc: 0.33
Batch: 560; loss: 1.82; acc: 0.41
Batch: 580; loss: 1.73; acc: 0.34
Batch: 600; loss: 1.73; acc: 0.36
Batch: 620; loss: 1.57; acc: 0.41
Batch: 640; loss: 1.79; acc: 0.33
Batch: 660; loss: 1.72; acc: 0.41
Batch: 680; loss: 1.92; acc: 0.3
Batch: 700; loss: 1.75; acc: 0.39
Batch: 720; loss: 1.76; acc: 0.38
Batch: 740; loss: 1.51; acc: 0.42
Batch: 760; loss: 1.73; acc: 0.36
Batch: 780; loss: 1.6; acc: 0.42
Train Epoch over. train_loss: 1.69; train_accuracy: 0.4 

2.283083631482441e-05
7.404905318253441e-06
Batch: 0; loss: 1.67; acc: 0.41
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.61; acc: 0.48
Batch: 60; loss: 1.72; acc: 0.41
Batch: 80; loss: 1.5; acc: 0.48
Batch: 100; loss: 1.7; acc: 0.41
Batch: 120; loss: 1.69; acc: 0.42
Batch: 140; loss: 1.51; acc: 0.47
Val Epoch over. val_loss: 1.6568926663915062; val_accuracy: 0.42147691082802546 

The current subspace-distance is: 7.404905318253441e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.55; acc: 0.52
Batch: 20; loss: 1.84; acc: 0.41
Batch: 40; loss: 1.64; acc: 0.38
Batch: 60; loss: 1.61; acc: 0.41
Batch: 80; loss: 1.72; acc: 0.36
Batch: 100; loss: 1.71; acc: 0.38
Batch: 120; loss: 1.64; acc: 0.45
Batch: 140; loss: 1.78; acc: 0.27
Batch: 160; loss: 2.01; acc: 0.33
Batch: 180; loss: 1.74; acc: 0.38
Batch: 200; loss: 1.67; acc: 0.39
Batch: 220; loss: 1.59; acc: 0.52
Batch: 240; loss: 1.58; acc: 0.42
Batch: 260; loss: 1.7; acc: 0.47
Batch: 280; loss: 1.83; acc: 0.39
Batch: 300; loss: 1.75; acc: 0.38
Batch: 320; loss: 1.67; acc: 0.41
Batch: 340; loss: 1.76; acc: 0.3
Batch: 360; loss: 1.82; acc: 0.39
Batch: 380; loss: 1.74; acc: 0.42
Batch: 400; loss: 1.71; acc: 0.41
Batch: 420; loss: 1.66; acc: 0.42
Batch: 440; loss: 1.83; acc: 0.44
Batch: 460; loss: 1.78; acc: 0.34
Batch: 480; loss: 1.82; acc: 0.34
Batch: 500; loss: 1.66; acc: 0.48
Batch: 520; loss: 1.68; acc: 0.42
Batch: 540; loss: 1.65; acc: 0.39
Batch: 560; loss: 1.59; acc: 0.44
Batch: 580; loss: 1.67; acc: 0.39
Batch: 600; loss: 1.58; acc: 0.5
Batch: 620; loss: 1.53; acc: 0.52
Batch: 640; loss: 1.79; acc: 0.38
Batch: 660; loss: 1.59; acc: 0.48
Batch: 680; loss: 1.56; acc: 0.5
Batch: 700; loss: 1.89; acc: 0.33
Batch: 720; loss: 1.91; acc: 0.3
Batch: 740; loss: 1.83; acc: 0.33
Batch: 760; loss: 1.67; acc: 0.47
Batch: 780; loss: 1.77; acc: 0.36
Train Epoch over. train_loss: 1.68; train_accuracy: 0.41 

1.9804290786851197e-05
5.839324330736417e-06
Batch: 0; loss: 1.67; acc: 0.41
Batch: 20; loss: 1.87; acc: 0.3
Batch: 40; loss: 1.58; acc: 0.47
Batch: 60; loss: 1.71; acc: 0.41
Batch: 80; loss: 1.5; acc: 0.47
Batch: 100; loss: 1.69; acc: 0.44
Batch: 120; loss: 1.71; acc: 0.41
Batch: 140; loss: 1.51; acc: 0.48
Val Epoch over. val_loss: 1.6490252245763304; val_accuracy: 0.41052945859872614 

The current subspace-distance is: 5.839324330736417e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.77; acc: 0.39
Batch: 20; loss: 1.51; acc: 0.45
Batch: 40; loss: 1.61; acc: 0.45
Batch: 60; loss: 1.61; acc: 0.45
Batch: 80; loss: 1.51; acc: 0.45
Batch: 100; loss: 1.58; acc: 0.39
Batch: 120; loss: 1.68; acc: 0.41
Batch: 140; loss: 1.65; acc: 0.55
Batch: 160; loss: 1.83; acc: 0.27
Batch: 180; loss: 1.76; acc: 0.39
Batch: 200; loss: 1.94; acc: 0.31
Batch: 220; loss: 1.72; acc: 0.41
Batch: 240; loss: 1.7; acc: 0.36
Batch: 260; loss: 1.61; acc: 0.41
Batch: 280; loss: 1.89; acc: 0.28
Batch: 300; loss: 1.76; acc: 0.39
Batch: 320; loss: 1.63; acc: 0.47
Batch: 340; loss: 1.64; acc: 0.42
Batch: 360; loss: 1.79; acc: 0.33
Batch: 380; loss: 2.11; acc: 0.27
Batch: 400; loss: 1.88; acc: 0.3
Batch: 420; loss: 1.54; acc: 0.5
Batch: 440; loss: 1.72; acc: 0.45
Batch: 460; loss: 1.66; acc: 0.44
Batch: 480; loss: 1.61; acc: 0.48
Batch: 500; loss: 1.7; acc: 0.42
Batch: 520; loss: 1.52; acc: 0.48
Batch: 540; loss: 1.53; acc: 0.48
Batch: 560; loss: 1.76; acc: 0.34
Batch: 580; loss: 1.58; acc: 0.48
Batch: 600; loss: 1.7; acc: 0.38
Batch: 620; loss: 1.72; acc: 0.36
Batch: 640; loss: 1.96; acc: 0.28
Batch: 660; loss: 1.53; acc: 0.47
Batch: 680; loss: 1.68; acc: 0.42
Batch: 700; loss: 1.56; acc: 0.52
Batch: 720; loss: 1.65; acc: 0.38
Batch: 740; loss: 1.76; acc: 0.39
Batch: 760; loss: 1.64; acc: 0.44
Batch: 780; loss: 1.76; acc: 0.44
Train Epoch over. train_loss: 1.68; train_accuracy: 0.4 

1.9110158973489888e-05
4.664233983930899e-06
Batch: 0; loss: 1.68; acc: 0.39
Batch: 20; loss: 1.88; acc: 0.42
Batch: 40; loss: 1.63; acc: 0.48
Batch: 60; loss: 1.7; acc: 0.42
Batch: 80; loss: 1.49; acc: 0.5
Batch: 100; loss: 1.69; acc: 0.39
Batch: 120; loss: 1.7; acc: 0.42
Batch: 140; loss: 1.5; acc: 0.45
Val Epoch over. val_loss: 1.6594358644667704; val_accuracy: 0.4267515923566879 

The current subspace-distance is: 4.664233983930899e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.77; acc: 0.36
Batch: 20; loss: 1.61; acc: 0.48
Batch: 40; loss: 1.77; acc: 0.45
Batch: 60; loss: 1.89; acc: 0.34
Batch: 80; loss: 1.42; acc: 0.53
Batch: 100; loss: 1.73; acc: 0.44
Batch: 120; loss: 1.56; acc: 0.45
Batch: 140; loss: 1.59; acc: 0.48
Batch: 160; loss: 1.79; acc: 0.44
Batch: 180; loss: 1.71; acc: 0.36
Batch: 200; loss: 1.73; acc: 0.38
Batch: 220; loss: 1.79; acc: 0.31
Batch: 240; loss: 1.59; acc: 0.45
Batch: 260; loss: 1.75; acc: 0.33
Batch: 280; loss: 1.54; acc: 0.48
Batch: 300; loss: 1.67; acc: 0.44
Batch: 320; loss: 1.65; acc: 0.42
Batch: 340; loss: 1.55; acc: 0.44
Batch: 360; loss: 1.93; acc: 0.31
Batch: 380; loss: 1.76; acc: 0.36
Batch: 400; loss: 1.82; acc: 0.34
Batch: 420; loss: 1.77; acc: 0.34
Batch: 440; loss: 1.78; acc: 0.31
Batch: 460; loss: 1.74; acc: 0.42
Batch: 480; loss: 1.53; acc: 0.45
Batch: 500; loss: 1.56; acc: 0.42
Batch: 520; loss: 1.7; acc: 0.33
Batch: 540; loss: 1.71; acc: 0.33
Batch: 560; loss: 1.48; acc: 0.47
Batch: 580; loss: 1.7; acc: 0.42
Batch: 600; loss: 1.64; acc: 0.44
Batch: 620; loss: 1.64; acc: 0.41
Batch: 640; loss: 1.6; acc: 0.47
Batch: 660; loss: 1.81; acc: 0.36
Batch: 680; loss: 1.78; acc: 0.34
Batch: 700; loss: 1.77; acc: 0.33
Batch: 720; loss: 1.7; acc: 0.3
Batch: 740; loss: 1.74; acc: 0.42
Batch: 760; loss: 1.77; acc: 0.38
Batch: 780; loss: 1.69; acc: 0.39
Train Epoch over. train_loss: 1.68; train_accuracy: 0.4 

1.736418744258117e-05
6.6558000071381684e-06
Batch: 0; loss: 1.68; acc: 0.39
Batch: 20; loss: 1.88; acc: 0.38
Batch: 40; loss: 1.65; acc: 0.48
Batch: 60; loss: 1.7; acc: 0.47
Batch: 80; loss: 1.5; acc: 0.48
Batch: 100; loss: 1.7; acc: 0.39
Batch: 120; loss: 1.71; acc: 0.41
Batch: 140; loss: 1.5; acc: 0.5
Val Epoch over. val_loss: 1.662331354845861; val_accuracy: 0.42983678343949044 

The current subspace-distance is: 6.6558000071381684e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.69; acc: 0.38
Batch: 20; loss: 1.7; acc: 0.34
Batch: 40; loss: 1.73; acc: 0.38
Batch: 60; loss: 1.83; acc: 0.33
Batch: 80; loss: 1.69; acc: 0.42
Batch: 100; loss: 1.77; acc: 0.44
Batch: 120; loss: 1.58; acc: 0.34
Batch: 140; loss: 1.78; acc: 0.34
Batch: 160; loss: 1.87; acc: 0.38
Batch: 180; loss: 1.67; acc: 0.39
Batch: 200; loss: 1.63; acc: 0.42
Batch: 220; loss: 1.65; acc: 0.41
Batch: 240; loss: 1.7; acc: 0.45
Batch: 260; loss: 1.48; acc: 0.52
Batch: 280; loss: 1.7; acc: 0.41
Batch: 300; loss: 1.69; acc: 0.39
Batch: 320; loss: 1.64; acc: 0.39
Batch: 340; loss: 1.75; acc: 0.44
Batch: 360; loss: 1.61; acc: 0.45
Batch: 380; loss: 1.62; acc: 0.48
Batch: 400; loss: 1.72; acc: 0.41
Batch: 420; loss: 1.76; acc: 0.33
Batch: 440; loss: 1.65; acc: 0.41
Batch: 460; loss: 1.5; acc: 0.5
Batch: 480; loss: 1.8; acc: 0.34
Batch: 500; loss: 1.76; acc: 0.42
Batch: 520; loss: 1.67; acc: 0.45
Batch: 540; loss: 1.75; acc: 0.33
Batch: 560; loss: 1.76; acc: 0.42
Batch: 580; loss: 1.54; acc: 0.48
Batch: 600; loss: 1.55; acc: 0.39
Batch: 620; loss: 1.74; acc: 0.39
Batch: 640; loss: 1.91; acc: 0.27
Batch: 660; loss: 1.64; acc: 0.47
Batch: 680; loss: 1.71; acc: 0.39
Batch: 700; loss: 1.54; acc: 0.41
Batch: 720; loss: 1.69; acc: 0.34
Batch: 740; loss: 1.58; acc: 0.41
Batch: 760; loss: 1.55; acc: 0.45
Batch: 780; loss: 1.82; acc: 0.3
Train Epoch over. train_loss: 1.68; train_accuracy: 0.41 

2.299905099789612e-05
5.937759397056652e-06
Batch: 0; loss: 1.67; acc: 0.41
Batch: 20; loss: 1.87; acc: 0.34
Batch: 40; loss: 1.58; acc: 0.45
Batch: 60; loss: 1.69; acc: 0.41
Batch: 80; loss: 1.47; acc: 0.5
Batch: 100; loss: 1.67; acc: 0.36
Batch: 120; loss: 1.72; acc: 0.48
Batch: 140; loss: 1.5; acc: 0.5
Val Epoch over. val_loss: 1.6563387251203987; val_accuracy: 0.40714570063694266 

The current subspace-distance is: 5.937759397056652e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.65; acc: 0.44
Batch: 20; loss: 1.72; acc: 0.39
Batch: 40; loss: 1.7; acc: 0.38
Batch: 60; loss: 1.72; acc: 0.42
Batch: 80; loss: 1.73; acc: 0.45
Batch: 100; loss: 1.87; acc: 0.28
Batch: 120; loss: 1.71; acc: 0.41
Batch: 140; loss: 1.75; acc: 0.39
Batch: 160; loss: 1.55; acc: 0.5
Batch: 180; loss: 1.64; acc: 0.39
Batch: 200; loss: 1.6; acc: 0.41
Batch: 220; loss: 1.65; acc: 0.41
Batch: 240; loss: 1.6; acc: 0.41
Batch: 260; loss: 1.51; acc: 0.41
Batch: 280; loss: 1.69; acc: 0.42
Batch: 300; loss: 1.61; acc: 0.38
Batch: 320; loss: 1.53; acc: 0.42
Batch: 340; loss: 1.54; acc: 0.45
Batch: 360; loss: 1.66; acc: 0.45
Batch: 380; loss: 1.59; acc: 0.41
Batch: 400; loss: 1.54; acc: 0.44
Batch: 420; loss: 1.5; acc: 0.55
Batch: 440; loss: 1.58; acc: 0.36
Batch: 460; loss: 1.59; acc: 0.42
Batch: 480; loss: 1.43; acc: 0.55
Batch: 500; loss: 1.75; acc: 0.42
Batch: 520; loss: 1.37; acc: 0.56
Batch: 540; loss: 1.72; acc: 0.42
Batch: 560; loss: 1.81; acc: 0.42
Batch: 580; loss: 1.62; acc: 0.48
Batch: 600; loss: 1.67; acc: 0.39
Batch: 620; loss: 1.73; acc: 0.42
Batch: 640; loss: 1.89; acc: 0.36
Batch: 660; loss: 1.64; acc: 0.47
Batch: 680; loss: 1.73; acc: 0.44
Batch: 700; loss: 1.72; acc: 0.38
Batch: 720; loss: 1.7; acc: 0.44
Batch: 740; loss: 1.85; acc: 0.28
Batch: 760; loss: 1.66; acc: 0.34
Batch: 780; loss: 1.75; acc: 0.36
Train Epoch over. train_loss: 1.67; train_accuracy: 0.41 

2.0067853256477974e-05
5.3984063015377615e-06
Batch: 0; loss: 1.65; acc: 0.45
Batch: 20; loss: 1.89; acc: 0.41
Batch: 40; loss: 1.61; acc: 0.47
Batch: 60; loss: 1.69; acc: 0.39
Batch: 80; loss: 1.45; acc: 0.58
Batch: 100; loss: 1.69; acc: 0.3
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.48; acc: 0.48
Val Epoch over. val_loss: 1.6301548306349736; val_accuracy: 0.4255573248407643 

The current subspace-distance is: 5.3984063015377615e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.66; acc: 0.38
Batch: 20; loss: 1.62; acc: 0.39
Batch: 40; loss: 1.75; acc: 0.42
Batch: 60; loss: 1.77; acc: 0.28
Batch: 80; loss: 1.75; acc: 0.33
Batch: 100; loss: 1.74; acc: 0.41
Batch: 120; loss: 1.58; acc: 0.42
Batch: 140; loss: 1.7; acc: 0.39
Batch: 160; loss: 1.63; acc: 0.34
Batch: 180; loss: 1.7; acc: 0.31
Batch: 200; loss: 1.7; acc: 0.42
Batch: 220; loss: 1.64; acc: 0.36
Batch: 240; loss: 1.8; acc: 0.31
Batch: 260; loss: 1.61; acc: 0.33
Batch: 280; loss: 1.42; acc: 0.52
Batch: 300; loss: 1.63; acc: 0.36
Batch: 320; loss: 1.59; acc: 0.42
Batch: 340; loss: 1.84; acc: 0.42
Batch: 360; loss: 1.64; acc: 0.38
Batch: 380; loss: 1.61; acc: 0.48
Batch: 400; loss: 1.71; acc: 0.34
Batch: 420; loss: 1.65; acc: 0.41
Batch: 440; loss: 1.72; acc: 0.42
Batch: 460; loss: 1.57; acc: 0.5
Batch: 480; loss: 1.67; acc: 0.36
Batch: 500; loss: 1.45; acc: 0.55
Batch: 520; loss: 1.76; acc: 0.31
Batch: 540; loss: 1.65; acc: 0.36
Batch: 560; loss: 1.45; acc: 0.47
Batch: 580; loss: 1.56; acc: 0.53
Batch: 600; loss: 1.56; acc: 0.44
Batch: 620; loss: 1.67; acc: 0.41
Batch: 640; loss: 1.6; acc: 0.42
Batch: 660; loss: 1.66; acc: 0.45
Batch: 680; loss: 1.71; acc: 0.47
Batch: 700; loss: 1.75; acc: 0.41
Batch: 720; loss: 1.76; acc: 0.33
Batch: 740; loss: 1.68; acc: 0.44
Batch: 760; loss: 1.72; acc: 0.41
Batch: 780; loss: 1.77; acc: 0.34
Train Epoch over. train_loss: 1.67; train_accuracy: 0.41 

1.9227292796131223e-05
5.091978891869076e-06
Batch: 0; loss: 1.66; acc: 0.41
Batch: 20; loss: 1.82; acc: 0.41
Batch: 40; loss: 1.63; acc: 0.52
Batch: 60; loss: 1.68; acc: 0.44
Batch: 80; loss: 1.49; acc: 0.53
Batch: 100; loss: 1.68; acc: 0.33
Batch: 120; loss: 1.73; acc: 0.47
Batch: 140; loss: 1.46; acc: 0.5
Val Epoch over. val_loss: 1.6304989886132015; val_accuracy: 0.4290406050955414 

The current subspace-distance is: 5.091978891869076e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.76; acc: 0.33
Batch: 20; loss: 1.69; acc: 0.41
Batch: 40; loss: 1.45; acc: 0.53
Batch: 60; loss: 1.54; acc: 0.47
Batch: 80; loss: 1.64; acc: 0.39
Batch: 100; loss: 1.51; acc: 0.5
Batch: 120; loss: 1.49; acc: 0.42
Batch: 140; loss: 1.84; acc: 0.3
Batch: 160; loss: 1.71; acc: 0.42
Batch: 180; loss: 1.69; acc: 0.39
Batch: 200; loss: 1.7; acc: 0.41
Batch: 220; loss: 1.7; acc: 0.38
Batch: 240; loss: 1.89; acc: 0.41
Batch: 260; loss: 1.66; acc: 0.44
Batch: 280; loss: 1.67; acc: 0.45
Batch: 300; loss: 1.64; acc: 0.39
Batch: 320; loss: 1.73; acc: 0.44
Batch: 340; loss: 1.9; acc: 0.34
Batch: 360; loss: 1.73; acc: 0.41
Batch: 380; loss: 1.96; acc: 0.3
Batch: 400; loss: 1.73; acc: 0.41
Batch: 420; loss: 1.72; acc: 0.41
Batch: 440; loss: 1.71; acc: 0.39
Batch: 460; loss: 1.75; acc: 0.34
Batch: 480; loss: 1.86; acc: 0.33
Batch: 500; loss: 1.61; acc: 0.45
Batch: 520; loss: 1.78; acc: 0.36
Batch: 540; loss: 1.69; acc: 0.45
Batch: 560; loss: 1.92; acc: 0.25
Batch: 580; loss: 1.42; acc: 0.58
Batch: 600; loss: 1.52; acc: 0.48
Batch: 620; loss: 1.75; acc: 0.33
Batch: 640; loss: 1.66; acc: 0.44
Batch: 660; loss: 1.61; acc: 0.41
Batch: 680; loss: 1.39; acc: 0.48
Batch: 700; loss: 1.86; acc: 0.28
Batch: 720; loss: 1.58; acc: 0.39
Batch: 740; loss: 1.58; acc: 0.47
Batch: 760; loss: 1.54; acc: 0.5
Batch: 780; loss: 1.62; acc: 0.48
Train Epoch over. train_loss: 1.66; train_accuracy: 0.41 

2.2995771360001527e-05
6.568612661794759e-06
Batch: 0; loss: 1.67; acc: 0.44
Batch: 20; loss: 1.83; acc: 0.39
Batch: 40; loss: 1.61; acc: 0.48
Batch: 60; loss: 1.71; acc: 0.41
Batch: 80; loss: 1.46; acc: 0.5
Batch: 100; loss: 1.69; acc: 0.34
Batch: 120; loss: 1.74; acc: 0.45
Batch: 140; loss: 1.47; acc: 0.48
Val Epoch over. val_loss: 1.648429091568965; val_accuracy: 0.4098328025477707 

The current subspace-distance is: 6.568612661794759e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.64; acc: 0.38
Batch: 20; loss: 1.59; acc: 0.47
Batch: 40; loss: 1.61; acc: 0.44
Batch: 60; loss: 1.82; acc: 0.34
Batch: 80; loss: 1.64; acc: 0.34
Batch: 100; loss: 1.75; acc: 0.36
Batch: 120; loss: 1.57; acc: 0.45
Batch: 140; loss: 1.63; acc: 0.45
Batch: 160; loss: 1.62; acc: 0.44
Batch: 180; loss: 1.6; acc: 0.42
Batch: 200; loss: 1.67; acc: 0.41
Batch: 220; loss: 1.69; acc: 0.36
Batch: 240; loss: 1.87; acc: 0.38
Batch: 260; loss: 1.72; acc: 0.48
Batch: 280; loss: 1.58; acc: 0.48
Batch: 300; loss: 1.65; acc: 0.44
Batch: 320; loss: 1.69; acc: 0.42
Batch: 340; loss: 1.6; acc: 0.45
Batch: 360; loss: 1.62; acc: 0.48
Batch: 380; loss: 1.81; acc: 0.33
Batch: 400; loss: 1.67; acc: 0.38
Batch: 420; loss: 1.86; acc: 0.34
Batch: 440; loss: 1.88; acc: 0.25
Batch: 460; loss: 1.7; acc: 0.38
Batch: 480; loss: 1.87; acc: 0.36
Batch: 500; loss: 1.61; acc: 0.31
Batch: 520; loss: 1.71; acc: 0.36
Batch: 540; loss: 1.48; acc: 0.61
Batch: 560; loss: 1.66; acc: 0.44
Batch: 580; loss: 1.76; acc: 0.38
Batch: 600; loss: 1.64; acc: 0.47
Batch: 620; loss: 1.76; acc: 0.44
Batch: 640; loss: 1.69; acc: 0.34
Batch: 660; loss: 1.59; acc: 0.45
Batch: 680; loss: 1.62; acc: 0.47
Batch: 700; loss: 1.66; acc: 0.33
Batch: 720; loss: 1.67; acc: 0.39
Batch: 740; loss: 1.55; acc: 0.48
Batch: 760; loss: 1.76; acc: 0.38
Batch: 780; loss: 1.75; acc: 0.44
Train Epoch over. train_loss: 1.66; train_accuracy: 0.41 

2.0849409338552505e-05
4.846890533372061e-06
Batch: 0; loss: 1.66; acc: 0.45
Batch: 20; loss: 1.83; acc: 0.36
Batch: 40; loss: 1.61; acc: 0.44
Batch: 60; loss: 1.7; acc: 0.39
Batch: 80; loss: 1.45; acc: 0.52
Batch: 100; loss: 1.7; acc: 0.33
Batch: 120; loss: 1.75; acc: 0.45
Batch: 140; loss: 1.46; acc: 0.5
Val Epoch over. val_loss: 1.6340971106936217; val_accuracy: 0.41709792993630573 

The current subspace-distance is: 4.846890533372061e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.72; acc: 0.36
Batch: 20; loss: 1.6; acc: 0.45
Batch: 40; loss: 1.63; acc: 0.44
Batch: 60; loss: 1.93; acc: 0.31
Batch: 80; loss: 1.66; acc: 0.38
Batch: 100; loss: 1.74; acc: 0.36
Batch: 120; loss: 1.57; acc: 0.38
Batch: 140; loss: 1.97; acc: 0.3
Batch: 160; loss: 1.68; acc: 0.38
Batch: 180; loss: 1.8; acc: 0.42
Batch: 200; loss: 1.65; acc: 0.45
Batch: 220; loss: 1.74; acc: 0.33
Batch: 240; loss: 1.43; acc: 0.56
Batch: 260; loss: 1.64; acc: 0.45
Batch: 280; loss: 1.57; acc: 0.44
Batch: 300; loss: 1.49; acc: 0.42
Batch: 320; loss: 1.91; acc: 0.3
Batch: 340; loss: 1.68; acc: 0.38
Batch: 360; loss: 1.68; acc: 0.38
Batch: 380; loss: 1.69; acc: 0.44
Batch: 400; loss: 1.53; acc: 0.48
Batch: 420; loss: 1.58; acc: 0.45
Batch: 440; loss: 1.71; acc: 0.41
Batch: 460; loss: 1.7; acc: 0.45
Batch: 480; loss: 1.76; acc: 0.36
Batch: 500; loss: 1.49; acc: 0.44
Batch: 520; loss: 1.48; acc: 0.48
Batch: 540; loss: 1.57; acc: 0.45
Batch: 560; loss: 1.78; acc: 0.38
Batch: 580; loss: 1.51; acc: 0.41
Batch: 600; loss: 1.48; acc: 0.55
Batch: 620; loss: 1.59; acc: 0.47
Batch: 640; loss: 1.83; acc: 0.36
Batch: 660; loss: 1.71; acc: 0.41
Batch: 680; loss: 1.67; acc: 0.45
Batch: 700; loss: 1.64; acc: 0.45
Batch: 720; loss: 1.7; acc: 0.36
Batch: 740; loss: 1.49; acc: 0.56
Batch: 760; loss: 1.69; acc: 0.42
Batch: 780; loss: 1.78; acc: 0.33
Train Epoch over. train_loss: 1.66; train_accuracy: 0.42 

2.1035351892351173e-05
6.3677721300337e-06
Batch: 0; loss: 1.65; acc: 0.44
Batch: 20; loss: 1.81; acc: 0.38
Batch: 40; loss: 1.62; acc: 0.48
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.46; acc: 0.53
Batch: 100; loss: 1.67; acc: 0.36
Batch: 120; loss: 1.74; acc: 0.45
Batch: 140; loss: 1.45; acc: 0.48
Val Epoch over. val_loss: 1.6309589549994012; val_accuracy: 0.4211783439490446 

The current subspace-distance is: 6.3677721300337e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.8; acc: 0.42
Batch: 20; loss: 1.6; acc: 0.36
Batch: 40; loss: 1.43; acc: 0.48
Batch: 60; loss: 1.62; acc: 0.44
Batch: 80; loss: 1.77; acc: 0.36
Batch: 100; loss: 1.57; acc: 0.48
Batch: 120; loss: 1.88; acc: 0.36
Batch: 140; loss: 1.63; acc: 0.36
Batch: 160; loss: 1.6; acc: 0.42
Batch: 180; loss: 1.73; acc: 0.39
Batch: 200; loss: 1.61; acc: 0.52
Batch: 220; loss: 1.66; acc: 0.42
Batch: 240; loss: 1.66; acc: 0.39
Batch: 260; loss: 1.59; acc: 0.36
Batch: 280; loss: 1.6; acc: 0.44
Batch: 300; loss: 1.73; acc: 0.36
Batch: 320; loss: 1.63; acc: 0.39
Batch: 340; loss: 1.72; acc: 0.36
Batch: 360; loss: 1.71; acc: 0.42
Batch: 380; loss: 1.76; acc: 0.36
Batch: 400; loss: 1.58; acc: 0.38
Batch: 420; loss: 1.71; acc: 0.38
Batch: 440; loss: 1.57; acc: 0.53
Batch: 460; loss: 1.7; acc: 0.38
Batch: 480; loss: 1.56; acc: 0.47
Batch: 500; loss: 1.64; acc: 0.39
Batch: 520; loss: 1.68; acc: 0.38
Batch: 540; loss: 1.66; acc: 0.38
Batch: 560; loss: 1.61; acc: 0.41
Batch: 580; loss: 1.58; acc: 0.44
Batch: 600; loss: 1.58; acc: 0.45
Batch: 620; loss: 1.43; acc: 0.5
Batch: 640; loss: 1.71; acc: 0.38
Batch: 660; loss: 1.85; acc: 0.36
Batch: 680; loss: 1.58; acc: 0.45
Batch: 700; loss: 1.58; acc: 0.38
Batch: 720; loss: 1.53; acc: 0.52
Batch: 740; loss: 1.68; acc: 0.36
Batch: 760; loss: 1.63; acc: 0.44
Batch: 780; loss: 1.74; acc: 0.39
Train Epoch over. train_loss: 1.65; train_accuracy: 0.42 

2.0741788830491714e-05
7.028450909274397e-06
Batch: 0; loss: 1.63; acc: 0.45
Batch: 20; loss: 1.8; acc: 0.41
Batch: 40; loss: 1.61; acc: 0.5
Batch: 60; loss: 1.7; acc: 0.45
Batch: 80; loss: 1.45; acc: 0.56
Batch: 100; loss: 1.66; acc: 0.34
Batch: 120; loss: 1.74; acc: 0.45
Batch: 140; loss: 1.45; acc: 0.47
Val Epoch over. val_loss: 1.621796576840103; val_accuracy: 0.4250597133757962 

The current subspace-distance is: 7.028450909274397e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.58; acc: 0.47
Batch: 20; loss: 1.49; acc: 0.5
Batch: 40; loss: 1.61; acc: 0.41
Batch: 60; loss: 1.79; acc: 0.3
Batch: 80; loss: 1.64; acc: 0.44
Batch: 100; loss: 1.57; acc: 0.45
Batch: 120; loss: 1.59; acc: 0.5
Batch: 140; loss: 1.67; acc: 0.47
Batch: 160; loss: 1.43; acc: 0.44
Batch: 180; loss: 1.55; acc: 0.45
Batch: 200; loss: 1.76; acc: 0.33
Batch: 220; loss: 1.68; acc: 0.41
Batch: 240; loss: 1.59; acc: 0.41
Batch: 260; loss: 1.8; acc: 0.38
Batch: 280; loss: 1.66; acc: 0.38
Batch: 300; loss: 1.73; acc: 0.42
Batch: 320; loss: 1.61; acc: 0.34
Batch: 340; loss: 1.6; acc: 0.42
Batch: 360; loss: 1.76; acc: 0.42
Batch: 380; loss: 1.91; acc: 0.34
Batch: 400; loss: 1.68; acc: 0.36
Batch: 420; loss: 1.69; acc: 0.45
Batch: 440; loss: 1.46; acc: 0.5
Batch: 460; loss: 1.63; acc: 0.45
Batch: 480; loss: 1.72; acc: 0.36
Batch: 500; loss: 1.78; acc: 0.34
Batch: 520; loss: 1.86; acc: 0.34
Batch: 540; loss: 1.63; acc: 0.44
Batch: 560; loss: 1.76; acc: 0.38
Batch: 580; loss: 1.59; acc: 0.42
Batch: 600; loss: 1.46; acc: 0.53
Batch: 620; loss: 1.66; acc: 0.42
Batch: 640; loss: 1.82; acc: 0.41
Batch: 660; loss: 1.69; acc: 0.39
Batch: 680; loss: 1.58; acc: 0.45
Batch: 700; loss: 1.81; acc: 0.36
Batch: 720; loss: 1.42; acc: 0.5
Batch: 740; loss: 1.75; acc: 0.39
Batch: 760; loss: 1.71; acc: 0.34
Batch: 780; loss: 1.76; acc: 0.34
Train Epoch over. train_loss: 1.65; train_accuracy: 0.42 

2.1894020392210223e-05
6.594097158085788e-06
Batch: 0; loss: 1.63; acc: 0.47
Batch: 20; loss: 1.82; acc: 0.44
Batch: 40; loss: 1.63; acc: 0.48
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.44; acc: 0.59
Batch: 100; loss: 1.65; acc: 0.34
Batch: 120; loss: 1.75; acc: 0.45
Batch: 140; loss: 1.45; acc: 0.47
Val Epoch over. val_loss: 1.6114138547022632; val_accuracy: 0.43670382165605093 

The current subspace-distance is: 6.594097158085788e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.55; acc: 0.48
Batch: 20; loss: 1.57; acc: 0.45
Batch: 40; loss: 1.59; acc: 0.48
Batch: 60; loss: 1.73; acc: 0.31
Batch: 80; loss: 1.51; acc: 0.42
Batch: 100; loss: 1.52; acc: 0.44
Batch: 120; loss: 1.57; acc: 0.38
Batch: 140; loss: 1.76; acc: 0.36
Batch: 160; loss: 1.64; acc: 0.5
Batch: 180; loss: 1.74; acc: 0.39
Batch: 200; loss: 1.47; acc: 0.5
Batch: 220; loss: 1.56; acc: 0.47
Batch: 240; loss: 1.56; acc: 0.44
Batch: 260; loss: 1.72; acc: 0.39
Batch: 280; loss: 1.73; acc: 0.36
Batch: 300; loss: 1.62; acc: 0.45
Batch: 320; loss: 1.77; acc: 0.33
Batch: 340; loss: 1.69; acc: 0.42
Batch: 360; loss: 1.89; acc: 0.31
Batch: 380; loss: 1.5; acc: 0.41
Batch: 400; loss: 1.55; acc: 0.38
Batch: 420; loss: 1.47; acc: 0.5
Batch: 440; loss: 1.76; acc: 0.3
Batch: 460; loss: 1.4; acc: 0.52
Batch: 480; loss: 1.56; acc: 0.47
Batch: 500; loss: 1.43; acc: 0.48
Batch: 520; loss: 1.71; acc: 0.39
Batch: 540; loss: 1.73; acc: 0.41
Batch: 560; loss: 1.44; acc: 0.45
Batch: 580; loss: 1.63; acc: 0.45
Batch: 600; loss: 1.8; acc: 0.33
Batch: 620; loss: 1.76; acc: 0.25
Batch: 640; loss: 1.42; acc: 0.53
Batch: 660; loss: 1.62; acc: 0.44
Batch: 680; loss: 1.71; acc: 0.36
Batch: 700; loss: 1.5; acc: 0.5
Batch: 720; loss: 1.61; acc: 0.52
Batch: 740; loss: 1.76; acc: 0.36
Batch: 760; loss: 1.8; acc: 0.39
Batch: 780; loss: 1.49; acc: 0.48
Train Epoch over. train_loss: 1.65; train_accuracy: 0.42 

1.8970767996506765e-05
4.336260644777212e-06
Batch: 0; loss: 1.63; acc: 0.45
Batch: 20; loss: 1.84; acc: 0.42
Batch: 40; loss: 1.63; acc: 0.52
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.44; acc: 0.59
Batch: 100; loss: 1.66; acc: 0.38
Batch: 120; loss: 1.74; acc: 0.45
Batch: 140; loss: 1.46; acc: 0.47
Val Epoch over. val_loss: 1.6147484543976511; val_accuracy: 0.43919187898089174 

The current subspace-distance is: 4.336260644777212e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.78; acc: 0.38
Batch: 20; loss: 1.55; acc: 0.41
Batch: 40; loss: 1.74; acc: 0.44
Batch: 60; loss: 1.63; acc: 0.41
Batch: 80; loss: 1.43; acc: 0.53
Batch: 100; loss: 1.71; acc: 0.38
Batch: 120; loss: 1.65; acc: 0.44
Batch: 140; loss: 1.7; acc: 0.41
Batch: 160; loss: 1.57; acc: 0.45
Batch: 180; loss: 1.63; acc: 0.39
Batch: 200; loss: 1.64; acc: 0.47
Batch: 220; loss: 1.66; acc: 0.47
Batch: 240; loss: 1.75; acc: 0.38
Batch: 260; loss: 1.5; acc: 0.47
Batch: 280; loss: 1.54; acc: 0.44
Batch: 300; loss: 1.54; acc: 0.45
Batch: 320; loss: 1.76; acc: 0.48
Batch: 340; loss: 1.82; acc: 0.38
Batch: 360; loss: 1.74; acc: 0.31
Batch: 380; loss: 1.65; acc: 0.5
Batch: 400; loss: 1.67; acc: 0.44
Batch: 420; loss: 1.65; acc: 0.36
Batch: 440; loss: 1.37; acc: 0.59
Batch: 460; loss: 1.68; acc: 0.39
Batch: 480; loss: 1.78; acc: 0.42
Batch: 500; loss: 1.5; acc: 0.47
Batch: 520; loss: 1.62; acc: 0.5
Batch: 540; loss: 1.73; acc: 0.42
Batch: 560; loss: 1.82; acc: 0.38
Batch: 580; loss: 1.7; acc: 0.36
Batch: 600; loss: 1.65; acc: 0.41
Batch: 620; loss: 1.68; acc: 0.36
Batch: 640; loss: 1.46; acc: 0.52
Batch: 660; loss: 1.69; acc: 0.41
Batch: 680; loss: 1.39; acc: 0.55
Batch: 700; loss: 1.62; acc: 0.45
Batch: 720; loss: 1.63; acc: 0.42
Batch: 740; loss: 1.57; acc: 0.52
Batch: 760; loss: 1.56; acc: 0.44
Batch: 780; loss: 1.59; acc: 0.41
Train Epoch over. train_loss: 1.65; train_accuracy: 0.42 

1.9596916899899952e-05
8.121059181576129e-06
Batch: 0; loss: 1.62; acc: 0.45
Batch: 20; loss: 1.81; acc: 0.44
Batch: 40; loss: 1.61; acc: 0.5
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.42; acc: 0.56
Batch: 100; loss: 1.65; acc: 0.36
Batch: 120; loss: 1.76; acc: 0.44
Batch: 140; loss: 1.45; acc: 0.47
Val Epoch over. val_loss: 1.6101016049172467; val_accuracy: 0.4362062101910828 

The current subspace-distance is: 8.121059181576129e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.52; acc: 0.5
Batch: 20; loss: 1.91; acc: 0.36
Batch: 40; loss: 1.67; acc: 0.44
Batch: 60; loss: 1.74; acc: 0.44
Batch: 80; loss: 1.66; acc: 0.41
Batch: 100; loss: 1.59; acc: 0.45
Batch: 120; loss: 1.68; acc: 0.45
Batch: 140; loss: 1.64; acc: 0.42
Batch: 160; loss: 1.66; acc: 0.48
Batch: 180; loss: 1.58; acc: 0.38
Batch: 200; loss: 1.75; acc: 0.34
Batch: 220; loss: 1.77; acc: 0.31
Batch: 240; loss: 1.43; acc: 0.53
Batch: 260; loss: 1.72; acc: 0.39
Batch: 280; loss: 1.46; acc: 0.47
Batch: 300; loss: 1.62; acc: 0.44
Batch: 320; loss: 1.8; acc: 0.41
Batch: 340; loss: 1.53; acc: 0.45
Batch: 360; loss: 1.68; acc: 0.33
Batch: 380; loss: 1.4; acc: 0.55
Batch: 400; loss: 1.62; acc: 0.48
Batch: 420; loss: 1.51; acc: 0.48
Batch: 440; loss: 1.55; acc: 0.48
Batch: 460; loss: 1.66; acc: 0.39
Batch: 480; loss: 1.91; acc: 0.31
Batch: 500; loss: 1.77; acc: 0.38
Batch: 520; loss: 1.67; acc: 0.33
Batch: 540; loss: 1.67; acc: 0.38
Batch: 560; loss: 1.59; acc: 0.44
Batch: 580; loss: 1.54; acc: 0.45
Batch: 600; loss: 1.61; acc: 0.47
Batch: 620; loss: 1.69; acc: 0.42
Batch: 640; loss: 1.8; acc: 0.28
Batch: 660; loss: 1.83; acc: 0.42
Batch: 680; loss: 1.61; acc: 0.42
Batch: 700; loss: 1.53; acc: 0.5
Batch: 720; loss: 1.67; acc: 0.42
Batch: 740; loss: 1.71; acc: 0.42
Batch: 760; loss: 1.63; acc: 0.31
Batch: 780; loss: 1.77; acc: 0.31
Train Epoch over. train_loss: 1.65; train_accuracy: 0.42 

1.9541494111763313e-05
4.959141733706929e-06
Batch: 0; loss: 1.61; acc: 0.45
Batch: 20; loss: 1.83; acc: 0.42
Batch: 40; loss: 1.61; acc: 0.5
Batch: 60; loss: 1.7; acc: 0.42
Batch: 80; loss: 1.43; acc: 0.56
Batch: 100; loss: 1.65; acc: 0.33
Batch: 120; loss: 1.73; acc: 0.45
Batch: 140; loss: 1.45; acc: 0.44
Val Epoch over. val_loss: 1.6074111256629797; val_accuracy: 0.4377985668789809 

The current subspace-distance is: 4.959141733706929e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.72; acc: 0.36
Batch: 20; loss: 1.78; acc: 0.33
Batch: 40; loss: 1.78; acc: 0.36
Batch: 60; loss: 1.88; acc: 0.38
Batch: 80; loss: 1.56; acc: 0.45
Batch: 100; loss: 1.65; acc: 0.44
Batch: 120; loss: 1.65; acc: 0.41
Batch: 140; loss: 1.57; acc: 0.36
Batch: 160; loss: 1.92; acc: 0.31
Batch: 180; loss: 1.69; acc: 0.42
Batch: 200; loss: 1.71; acc: 0.38
Batch: 220; loss: 1.6; acc: 0.47
Batch: 240; loss: 1.6; acc: 0.42
Batch: 260; loss: 1.46; acc: 0.47
Batch: 280; loss: 1.59; acc: 0.42
Batch: 300; loss: 1.59; acc: 0.47
Batch: 320; loss: 1.5; acc: 0.45
Batch: 340; loss: 1.76; acc: 0.3
Batch: 360; loss: 1.71; acc: 0.41
Batch: 380; loss: 1.82; acc: 0.39
Batch: 400; loss: 1.59; acc: 0.42
Batch: 420; loss: 1.6; acc: 0.42
Batch: 440; loss: 1.67; acc: 0.39
Batch: 460; loss: 1.71; acc: 0.33
Batch: 480; loss: 1.69; acc: 0.39
Batch: 500; loss: 1.58; acc: 0.52
Batch: 520; loss: 1.8; acc: 0.34
Batch: 540; loss: 1.75; acc: 0.36
Batch: 560; loss: 1.56; acc: 0.42
Batch: 580; loss: 1.69; acc: 0.38
Batch: 600; loss: 1.56; acc: 0.47
Batch: 620; loss: 1.88; acc: 0.36
Batch: 640; loss: 1.74; acc: 0.31
Batch: 660; loss: 1.68; acc: 0.41
Batch: 680; loss: 1.68; acc: 0.47
Batch: 700; loss: 1.67; acc: 0.38
Batch: 720; loss: 1.34; acc: 0.56
Batch: 740; loss: 1.71; acc: 0.3
Batch: 760; loss: 1.71; acc: 0.34
Batch: 780; loss: 1.63; acc: 0.47
Train Epoch over. train_loss: 1.65; train_accuracy: 0.41 

1.94579715753207e-05
6.549059435201343e-06
Batch: 0; loss: 1.61; acc: 0.44
Batch: 20; loss: 1.83; acc: 0.44
Batch: 40; loss: 1.62; acc: 0.5
Batch: 60; loss: 1.71; acc: 0.42
Batch: 80; loss: 1.42; acc: 0.55
Batch: 100; loss: 1.66; acc: 0.36
Batch: 120; loss: 1.74; acc: 0.45
Batch: 140; loss: 1.46; acc: 0.44
Val Epoch over. val_loss: 1.6079508871029897; val_accuracy: 0.43710191082802546 

The current subspace-distance is: 6.549059435201343e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.82; acc: 0.39
Batch: 20; loss: 1.81; acc: 0.34
Batch: 40; loss: 1.53; acc: 0.45
Batch: 60; loss: 1.55; acc: 0.47
Batch: 80; loss: 1.6; acc: 0.38
Batch: 100; loss: 1.76; acc: 0.39
Batch: 120; loss: 1.67; acc: 0.48
Batch: 140; loss: 1.61; acc: 0.5
Batch: 160; loss: 1.81; acc: 0.27
Batch: 180; loss: 1.67; acc: 0.45
Batch: 200; loss: 1.83; acc: 0.42
Batch: 220; loss: 1.6; acc: 0.47
Batch: 240; loss: 1.48; acc: 0.53
Batch: 260; loss: 1.8; acc: 0.38
Batch: 280; loss: 1.67; acc: 0.41
Batch: 300; loss: 1.46; acc: 0.47
Batch: 320; loss: 1.61; acc: 0.44
Batch: 340; loss: 1.55; acc: 0.41
Batch: 360; loss: 1.56; acc: 0.42
Batch: 380; loss: 1.49; acc: 0.44
Batch: 400; loss: 1.63; acc: 0.41
Batch: 420; loss: 1.46; acc: 0.5
Batch: 440; loss: 1.82; acc: 0.27
Batch: 460; loss: 1.64; acc: 0.38
Batch: 480; loss: 1.77; acc: 0.42
Batch: 500; loss: 1.66; acc: 0.45
Batch: 520; loss: 1.59; acc: 0.38
Batch: 540; loss: 1.58; acc: 0.44
Batch: 560; loss: 1.78; acc: 0.34
Batch: 580; loss: 1.71; acc: 0.31
Batch: 600; loss: 1.67; acc: 0.33
Batch: 620; loss: 1.61; acc: 0.41
Batch: 640; loss: 1.92; acc: 0.27
Batch: 660; loss: 1.66; acc: 0.45
Batch: 680; loss: 1.81; acc: 0.36
Batch: 700; loss: 1.72; acc: 0.34
Batch: 720; loss: 1.67; acc: 0.41
Batch: 740; loss: 1.67; acc: 0.44
Batch: 760; loss: 1.6; acc: 0.39
Batch: 780; loss: 1.74; acc: 0.44
Train Epoch over. train_loss: 1.65; train_accuracy: 0.41 

2.1068563000881113e-05
6.275031864788616e-06
Batch: 0; loss: 1.61; acc: 0.44
Batch: 20; loss: 1.81; acc: 0.38
Batch: 40; loss: 1.6; acc: 0.47
Batch: 60; loss: 1.72; acc: 0.38
Batch: 80; loss: 1.43; acc: 0.59
Batch: 100; loss: 1.66; acc: 0.34
Batch: 120; loss: 1.74; acc: 0.42
Batch: 140; loss: 1.43; acc: 0.47
Val Epoch over. val_loss: 1.6108762056204924; val_accuracy: 0.430234872611465 

The current subspace-distance is: 6.275031864788616e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.84; acc: 0.27
Batch: 20; loss: 1.54; acc: 0.48
Batch: 40; loss: 1.86; acc: 0.38
Batch: 60; loss: 1.66; acc: 0.41
Batch: 80; loss: 1.59; acc: 0.41
Batch: 100; loss: 1.71; acc: 0.36
Batch: 120; loss: 1.51; acc: 0.44
Batch: 140; loss: 1.39; acc: 0.56
Batch: 160; loss: 1.55; acc: 0.45
Batch: 180; loss: 1.45; acc: 0.42
Batch: 200; loss: 1.75; acc: 0.45
Batch: 220; loss: 1.58; acc: 0.45
Batch: 240; loss: 1.52; acc: 0.44
Batch: 260; loss: 1.87; acc: 0.33
Batch: 280; loss: 1.72; acc: 0.36
Batch: 300; loss: 1.6; acc: 0.47
Batch: 320; loss: 1.73; acc: 0.3
Batch: 340; loss: 1.57; acc: 0.45
Batch: 360; loss: 1.55; acc: 0.42
Batch: 380; loss: 1.75; acc: 0.39
Batch: 400; loss: 1.46; acc: 0.48
Batch: 420; loss: 1.52; acc: 0.47
Batch: 440; loss: 1.48; acc: 0.45
Batch: 460; loss: 1.58; acc: 0.39
Batch: 480; loss: 1.74; acc: 0.38
Batch: 500; loss: 1.41; acc: 0.55
Batch: 520; loss: 1.68; acc: 0.44
Batch: 540; loss: 1.75; acc: 0.44
Batch: 560; loss: 1.48; acc: 0.39
Batch: 580; loss: 1.81; acc: 0.31
Batch: 600; loss: 1.62; acc: 0.44
Batch: 620; loss: 1.77; acc: 0.33
Batch: 640; loss: 1.63; acc: 0.41
Batch: 660; loss: 1.65; acc: 0.44
Batch: 680; loss: 1.69; acc: 0.38
Batch: 700; loss: 1.67; acc: 0.48
Batch: 720; loss: 1.76; acc: 0.38
Batch: 740; loss: 1.67; acc: 0.41
Batch: 760; loss: 1.76; acc: 0.34
Batch: 780; loss: 1.6; acc: 0.47
Train Epoch over. train_loss: 1.65; train_accuracy: 0.42 

1.9091459762421437e-05
8.57649229146773e-06
Batch: 0; loss: 1.6; acc: 0.47
Batch: 20; loss: 1.8; acc: 0.45
Batch: 40; loss: 1.6; acc: 0.48
Batch: 60; loss: 1.71; acc: 0.39
Batch: 80; loss: 1.4; acc: 0.59
Batch: 100; loss: 1.65; acc: 0.36
Batch: 120; loss: 1.74; acc: 0.41
Batch: 140; loss: 1.43; acc: 0.47
Val Epoch over. val_loss: 1.6055066479239495; val_accuracy: 0.4359076433121019 

The current subspace-distance is: 8.57649229146773e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.73; acc: 0.48
Batch: 20; loss: 1.64; acc: 0.45
Batch: 40; loss: 1.65; acc: 0.34
Batch: 60; loss: 1.6; acc: 0.42
Batch: 80; loss: 1.68; acc: 0.34
Batch: 100; loss: 1.5; acc: 0.45
Batch: 120; loss: 1.54; acc: 0.47
Batch: 140; loss: 1.95; acc: 0.41
Batch: 160; loss: 1.51; acc: 0.42
Batch: 180; loss: 1.65; acc: 0.47
Batch: 200; loss: 1.61; acc: 0.39
Batch: 220; loss: 1.53; acc: 0.47
Batch: 240; loss: 1.6; acc: 0.45
Batch: 260; loss: 1.66; acc: 0.34
Batch: 280; loss: 1.71; acc: 0.39
Batch: 300; loss: 1.44; acc: 0.45
Batch: 320; loss: 1.75; acc: 0.39
Batch: 340; loss: 1.63; acc: 0.33
Batch: 360; loss: 1.7; acc: 0.34
Batch: 380; loss: 1.46; acc: 0.5
Batch: 400; loss: 1.48; acc: 0.48
Batch: 420; loss: 1.63; acc: 0.45
Batch: 440; loss: 1.71; acc: 0.45
Batch: 460; loss: 1.49; acc: 0.45
Batch: 480; loss: 1.61; acc: 0.44
Batch: 500; loss: 1.59; acc: 0.47
Batch: 520; loss: 1.65; acc: 0.44
Batch: 540; loss: 1.62; acc: 0.45
Batch: 560; loss: 1.61; acc: 0.38
Batch: 580; loss: 1.69; acc: 0.44
Batch: 600; loss: 1.68; acc: 0.47
Batch: 620; loss: 1.81; acc: 0.33
Batch: 640; loss: 1.84; acc: 0.33
Batch: 660; loss: 1.85; acc: 0.41
Batch: 680; loss: 1.59; acc: 0.41
Batch: 700; loss: 1.71; acc: 0.39
Batch: 720; loss: 1.71; acc: 0.34
Batch: 740; loss: 1.77; acc: 0.22
Batch: 760; loss: 1.69; acc: 0.34
Batch: 780; loss: 1.71; acc: 0.36
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

1.9040364350075833e-05
6.6562283791427035e-06
Batch: 0; loss: 1.61; acc: 0.44
Batch: 20; loss: 1.85; acc: 0.41
Batch: 40; loss: 1.63; acc: 0.47
Batch: 60; loss: 1.7; acc: 0.44
Batch: 80; loss: 1.39; acc: 0.55
Batch: 100; loss: 1.66; acc: 0.38
Batch: 120; loss: 1.74; acc: 0.42
Batch: 140; loss: 1.48; acc: 0.48
Val Epoch over. val_loss: 1.6146556154178207; val_accuracy: 0.43799761146496813 

The current subspace-distance is: 6.6562283791427035e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.78; acc: 0.42
Batch: 20; loss: 1.65; acc: 0.45
Batch: 40; loss: 1.64; acc: 0.38
Batch: 60; loss: 1.64; acc: 0.38
Batch: 80; loss: 1.63; acc: 0.47
Batch: 100; loss: 1.47; acc: 0.5
Batch: 120; loss: 1.64; acc: 0.41
Batch: 140; loss: 1.71; acc: 0.38
Batch: 160; loss: 1.63; acc: 0.45
Batch: 180; loss: 1.49; acc: 0.47
Batch: 200; loss: 1.63; acc: 0.44
Batch: 220; loss: 1.95; acc: 0.28
Batch: 240; loss: 1.54; acc: 0.48
Batch: 260; loss: 1.58; acc: 0.44
Batch: 280; loss: 1.76; acc: 0.44
Batch: 300; loss: 1.71; acc: 0.44
Batch: 320; loss: 1.47; acc: 0.5
Batch: 340; loss: 1.7; acc: 0.41
Batch: 360; loss: 1.46; acc: 0.44
Batch: 380; loss: 1.57; acc: 0.38
Batch: 400; loss: 1.58; acc: 0.44
Batch: 420; loss: 1.58; acc: 0.47
Batch: 440; loss: 1.69; acc: 0.42
Batch: 460; loss: 1.28; acc: 0.53
Batch: 480; loss: 1.62; acc: 0.48
Batch: 500; loss: 1.37; acc: 0.5
Batch: 520; loss: 1.69; acc: 0.48
Batch: 540; loss: 1.51; acc: 0.5
Batch: 560; loss: 1.67; acc: 0.45
Batch: 580; loss: 1.52; acc: 0.39
Batch: 600; loss: 1.48; acc: 0.56
Batch: 620; loss: 1.59; acc: 0.44
Batch: 640; loss: 1.64; acc: 0.31
Batch: 660; loss: 1.7; acc: 0.36
Batch: 680; loss: 1.47; acc: 0.56
Batch: 700; loss: 1.74; acc: 0.31
Batch: 720; loss: 1.69; acc: 0.41
Batch: 740; loss: 1.41; acc: 0.47
Batch: 760; loss: 1.56; acc: 0.42
Batch: 780; loss: 1.82; acc: 0.34
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.070041955448687e-05
6.0380994000297505e-06
Batch: 0; loss: 1.6; acc: 0.45
Batch: 20; loss: 1.83; acc: 0.45
Batch: 40; loss: 1.59; acc: 0.47
Batch: 60; loss: 1.71; acc: 0.39
Batch: 80; loss: 1.39; acc: 0.55
Batch: 100; loss: 1.66; acc: 0.36
Batch: 120; loss: 1.76; acc: 0.41
Batch: 140; loss: 1.45; acc: 0.44
Val Epoch over. val_loss: 1.6036979347277598; val_accuracy: 0.430234872611465 

The current subspace-distance is: 6.0380994000297505e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.6; acc: 0.41
Batch: 20; loss: 1.96; acc: 0.28
Batch: 40; loss: 1.66; acc: 0.47
Batch: 60; loss: 1.35; acc: 0.56
Batch: 80; loss: 1.65; acc: 0.44
Batch: 100; loss: 1.45; acc: 0.44
Batch: 120; loss: 1.49; acc: 0.48
Batch: 140; loss: 1.65; acc: 0.44
Batch: 160; loss: 1.62; acc: 0.39
Batch: 180; loss: 1.83; acc: 0.25
Batch: 200; loss: 1.74; acc: 0.38
Batch: 220; loss: 1.67; acc: 0.33
Batch: 240; loss: 1.71; acc: 0.42
Batch: 260; loss: 1.81; acc: 0.33
Batch: 280; loss: 1.58; acc: 0.44
Batch: 300; loss: 1.76; acc: 0.31
Batch: 320; loss: 1.76; acc: 0.36
Batch: 340; loss: 1.77; acc: 0.36
Batch: 360; loss: 1.77; acc: 0.39
Batch: 380; loss: 1.72; acc: 0.39
Batch: 400; loss: 1.68; acc: 0.42
Batch: 420; loss: 1.55; acc: 0.48
Batch: 440; loss: 1.66; acc: 0.31
Batch: 460; loss: 1.43; acc: 0.47
Batch: 480; loss: 1.71; acc: 0.33
Batch: 500; loss: 1.63; acc: 0.45
Batch: 520; loss: 1.69; acc: 0.33
Batch: 540; loss: 1.72; acc: 0.45
Batch: 560; loss: 1.67; acc: 0.41
Batch: 580; loss: 1.5; acc: 0.45
Batch: 600; loss: 1.91; acc: 0.36
Batch: 620; loss: 1.64; acc: 0.31
Batch: 640; loss: 1.86; acc: 0.34
Batch: 660; loss: 1.64; acc: 0.41
Batch: 680; loss: 1.73; acc: 0.36
Batch: 700; loss: 1.61; acc: 0.44
Batch: 720; loss: 1.54; acc: 0.44
Batch: 740; loss: 1.6; acc: 0.42
Batch: 760; loss: 1.62; acc: 0.44
Batch: 780; loss: 1.62; acc: 0.45
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.035235593211837e-05
5.5981836339924484e-06
Batch: 0; loss: 1.59; acc: 0.44
Batch: 20; loss: 1.82; acc: 0.45
Batch: 40; loss: 1.6; acc: 0.48
Batch: 60; loss: 1.7; acc: 0.42
Batch: 80; loss: 1.37; acc: 0.59
Batch: 100; loss: 1.66; acc: 0.38
Batch: 120; loss: 1.74; acc: 0.41
Batch: 140; loss: 1.45; acc: 0.47
Val Epoch over. val_loss: 1.6024978586063263; val_accuracy: 0.43759952229299365 

The current subspace-distance is: 5.5981836339924484e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.61; acc: 0.38
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.68; acc: 0.39
Batch: 60; loss: 1.68; acc: 0.44
Batch: 80; loss: 1.85; acc: 0.31
Batch: 100; loss: 1.72; acc: 0.38
Batch: 120; loss: 1.65; acc: 0.45
Batch: 140; loss: 1.61; acc: 0.38
Batch: 160; loss: 1.81; acc: 0.39
Batch: 180; loss: 1.69; acc: 0.41
Batch: 200; loss: 1.74; acc: 0.39
Batch: 220; loss: 1.78; acc: 0.41
Batch: 240; loss: 1.8; acc: 0.36
Batch: 260; loss: 1.92; acc: 0.3
Batch: 280; loss: 1.66; acc: 0.39
Batch: 300; loss: 1.92; acc: 0.28
Batch: 320; loss: 1.39; acc: 0.53
Batch: 340; loss: 1.96; acc: 0.27
Batch: 360; loss: 1.77; acc: 0.38
Batch: 380; loss: 1.67; acc: 0.38
Batch: 400; loss: 1.59; acc: 0.39
Batch: 420; loss: 1.58; acc: 0.47
Batch: 440; loss: 1.59; acc: 0.38
Batch: 460; loss: 1.76; acc: 0.36
Batch: 480; loss: 1.75; acc: 0.31
Batch: 500; loss: 1.5; acc: 0.47
Batch: 520; loss: 1.61; acc: 0.38
Batch: 540; loss: 1.41; acc: 0.53
Batch: 560; loss: 1.88; acc: 0.38
Batch: 580; loss: 1.59; acc: 0.52
Batch: 600; loss: 1.59; acc: 0.42
Batch: 620; loss: 1.73; acc: 0.38
Batch: 640; loss: 1.5; acc: 0.44
Batch: 660; loss: 1.76; acc: 0.41
Batch: 680; loss: 1.57; acc: 0.44
Batch: 700; loss: 1.7; acc: 0.45
Batch: 720; loss: 1.79; acc: 0.45
Batch: 740; loss: 1.79; acc: 0.33
Batch: 760; loss: 1.81; acc: 0.31
Batch: 780; loss: 1.75; acc: 0.48
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

1.9526429241523147e-05
6.6393181441526394e-06
Batch: 0; loss: 1.59; acc: 0.44
Batch: 20; loss: 1.81; acc: 0.45
Batch: 40; loss: 1.6; acc: 0.5
Batch: 60; loss: 1.7; acc: 0.41
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.65; acc: 0.39
Batch: 120; loss: 1.75; acc: 0.39
Batch: 140; loss: 1.46; acc: 0.45
Val Epoch over. val_loss: 1.6038820637259514; val_accuracy: 0.4403861464968153 

The current subspace-distance is: 6.6393181441526394e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.79; acc: 0.3
Batch: 20; loss: 1.68; acc: 0.41
Batch: 40; loss: 1.44; acc: 0.48
Batch: 60; loss: 1.58; acc: 0.5
Batch: 80; loss: 1.64; acc: 0.41
Batch: 100; loss: 1.53; acc: 0.52
Batch: 120; loss: 1.75; acc: 0.38
Batch: 140; loss: 1.42; acc: 0.5
Batch: 160; loss: 1.51; acc: 0.45
Batch: 180; loss: 1.7; acc: 0.38
Batch: 200; loss: 1.66; acc: 0.42
Batch: 220; loss: 1.54; acc: 0.48
Batch: 240; loss: 1.72; acc: 0.38
Batch: 260; loss: 1.76; acc: 0.36
Batch: 280; loss: 1.45; acc: 0.52
Batch: 300; loss: 1.62; acc: 0.42
Batch: 320; loss: 1.76; acc: 0.39
Batch: 340; loss: 1.41; acc: 0.48
Batch: 360; loss: 1.53; acc: 0.5
Batch: 380; loss: 1.75; acc: 0.36
Batch: 400; loss: 1.61; acc: 0.38
Batch: 420; loss: 1.71; acc: 0.39
Batch: 440; loss: 1.46; acc: 0.5
Batch: 460; loss: 1.6; acc: 0.45
Batch: 480; loss: 1.7; acc: 0.42
Batch: 500; loss: 1.64; acc: 0.41
Batch: 520; loss: 1.74; acc: 0.36
Batch: 540; loss: 1.76; acc: 0.38
Batch: 560; loss: 1.5; acc: 0.38
Batch: 580; loss: 1.64; acc: 0.47
Batch: 600; loss: 2.01; acc: 0.22
Batch: 620; loss: 1.8; acc: 0.31
Batch: 640; loss: 1.67; acc: 0.42
Batch: 660; loss: 1.75; acc: 0.38
Batch: 680; loss: 1.52; acc: 0.45
Batch: 700; loss: 1.79; acc: 0.34
Batch: 720; loss: 1.56; acc: 0.48
Batch: 740; loss: 1.53; acc: 0.42
Batch: 760; loss: 1.51; acc: 0.45
Batch: 780; loss: 1.58; acc: 0.45
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.3969747417140752e-05
7.501663276343606e-06
Batch: 0; loss: 1.6; acc: 0.45
Batch: 20; loss: 1.82; acc: 0.44
Batch: 40; loss: 1.59; acc: 0.47
Batch: 60; loss: 1.7; acc: 0.42
Batch: 80; loss: 1.38; acc: 0.55
Batch: 100; loss: 1.65; acc: 0.38
Batch: 120; loss: 1.75; acc: 0.41
Batch: 140; loss: 1.46; acc: 0.44
Val Epoch over. val_loss: 1.6019254118014292; val_accuracy: 0.43580812101910826 

The current subspace-distance is: 7.501663276343606e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.58; acc: 0.45
Batch: 20; loss: 1.65; acc: 0.48
Batch: 40; loss: 1.55; acc: 0.45
Batch: 60; loss: 1.66; acc: 0.41
Batch: 80; loss: 1.62; acc: 0.44
Batch: 100; loss: 1.52; acc: 0.47
Batch: 120; loss: 1.6; acc: 0.36
Batch: 140; loss: 1.49; acc: 0.52
Batch: 160; loss: 1.79; acc: 0.36
Batch: 180; loss: 1.81; acc: 0.41
Batch: 200; loss: 1.61; acc: 0.42
Batch: 220; loss: 1.61; acc: 0.41
Batch: 240; loss: 1.85; acc: 0.34
Batch: 260; loss: 1.71; acc: 0.44
Batch: 280; loss: 1.52; acc: 0.47
Batch: 300; loss: 1.6; acc: 0.42
Batch: 320; loss: 1.5; acc: 0.45
Batch: 340; loss: 1.75; acc: 0.39
Batch: 360; loss: 1.66; acc: 0.41
Batch: 380; loss: 1.62; acc: 0.41
Batch: 400; loss: 1.53; acc: 0.45
Batch: 420; loss: 1.67; acc: 0.41
Batch: 440; loss: 1.76; acc: 0.36
Batch: 460; loss: 1.48; acc: 0.44
Batch: 480; loss: 1.57; acc: 0.48
Batch: 500; loss: 1.88; acc: 0.39
Batch: 520; loss: 1.64; acc: 0.48
Batch: 540; loss: 1.62; acc: 0.38
Batch: 560; loss: 1.59; acc: 0.48
Batch: 580; loss: 1.69; acc: 0.42
Batch: 600; loss: 1.99; acc: 0.31
Batch: 620; loss: 1.47; acc: 0.5
Batch: 640; loss: 1.63; acc: 0.39
Batch: 660; loss: 1.6; acc: 0.47
Batch: 680; loss: 1.64; acc: 0.47
Batch: 700; loss: 1.46; acc: 0.45
Batch: 720; loss: 1.73; acc: 0.36
Batch: 740; loss: 1.68; acc: 0.34
Batch: 760; loss: 1.79; acc: 0.42
Batch: 780; loss: 1.6; acc: 0.42
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.095517993438989e-05
5.83020482736174e-06
Batch: 0; loss: 1.59; acc: 0.44
Batch: 20; loss: 1.83; acc: 0.44
Batch: 40; loss: 1.59; acc: 0.48
Batch: 60; loss: 1.69; acc: 0.41
Batch: 80; loss: 1.37; acc: 0.59
Batch: 100; loss: 1.65; acc: 0.39
Batch: 120; loss: 1.75; acc: 0.41
Batch: 140; loss: 1.46; acc: 0.44
Val Epoch over. val_loss: 1.6012540068596033; val_accuracy: 0.4359076433121019 

The current subspace-distance is: 5.83020482736174e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.61; acc: 0.48
Batch: 20; loss: 1.86; acc: 0.31
Batch: 40; loss: 1.87; acc: 0.33
Batch: 60; loss: 1.51; acc: 0.47
Batch: 80; loss: 1.47; acc: 0.52
Batch: 100; loss: 1.66; acc: 0.38
Batch: 120; loss: 1.64; acc: 0.41
Batch: 140; loss: 1.43; acc: 0.55
Batch: 160; loss: 1.59; acc: 0.42
Batch: 180; loss: 1.56; acc: 0.47
Batch: 200; loss: 1.79; acc: 0.34
Batch: 220; loss: 1.51; acc: 0.42
Batch: 240; loss: 1.72; acc: 0.38
Batch: 260; loss: 1.68; acc: 0.39
Batch: 280; loss: 1.68; acc: 0.39
Batch: 300; loss: 1.64; acc: 0.55
Batch: 320; loss: 1.56; acc: 0.44
Batch: 340; loss: 1.51; acc: 0.52
Batch: 360; loss: 1.81; acc: 0.3
Batch: 380; loss: 1.74; acc: 0.31
Batch: 400; loss: 1.66; acc: 0.42
Batch: 420; loss: 1.56; acc: 0.42
Batch: 440; loss: 1.89; acc: 0.36
Batch: 460; loss: 1.56; acc: 0.48
Batch: 480; loss: 1.67; acc: 0.41
Batch: 500; loss: 1.84; acc: 0.3
Batch: 520; loss: 1.72; acc: 0.38
Batch: 540; loss: 1.7; acc: 0.44
Batch: 560; loss: 1.68; acc: 0.42
Batch: 580; loss: 1.62; acc: 0.42
Batch: 600; loss: 1.81; acc: 0.39
Batch: 620; loss: 1.68; acc: 0.38
Batch: 640; loss: 1.68; acc: 0.44
Batch: 660; loss: 1.67; acc: 0.34
Batch: 680; loss: 1.57; acc: 0.42
Batch: 700; loss: 1.62; acc: 0.41
Batch: 720; loss: 1.7; acc: 0.39
Batch: 740; loss: 1.72; acc: 0.39
Batch: 760; loss: 1.63; acc: 0.31
Batch: 780; loss: 1.75; acc: 0.36
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.02034498215653e-05
7.313291916943854e-06
Batch: 0; loss: 1.6; acc: 0.44
Batch: 20; loss: 1.83; acc: 0.42
Batch: 40; loss: 1.59; acc: 0.47
Batch: 60; loss: 1.69; acc: 0.41
Batch: 80; loss: 1.37; acc: 0.53
Batch: 100; loss: 1.65; acc: 0.38
Batch: 120; loss: 1.76; acc: 0.41
Batch: 140; loss: 1.47; acc: 0.44
Val Epoch over. val_loss: 1.6018783947464768; val_accuracy: 0.43580812101910826 

The current subspace-distance is: 7.313291916943854e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.71; acc: 0.3
Batch: 20; loss: 1.75; acc: 0.38
Batch: 40; loss: 1.68; acc: 0.5
Batch: 60; loss: 1.5; acc: 0.41
Batch: 80; loss: 1.79; acc: 0.38
Batch: 100; loss: 1.72; acc: 0.45
Batch: 120; loss: 1.71; acc: 0.38
Batch: 140; loss: 1.62; acc: 0.44
Batch: 160; loss: 1.5; acc: 0.47
Batch: 180; loss: 1.6; acc: 0.48
Batch: 200; loss: 1.46; acc: 0.52
Batch: 220; loss: 1.63; acc: 0.45
Batch: 240; loss: 1.87; acc: 0.28
Batch: 260; loss: 1.83; acc: 0.41
Batch: 280; loss: 1.74; acc: 0.34
Batch: 300; loss: 1.65; acc: 0.39
Batch: 320; loss: 1.91; acc: 0.34
Batch: 340; loss: 1.72; acc: 0.3
Batch: 360; loss: 1.67; acc: 0.38
Batch: 380; loss: 1.64; acc: 0.41
Batch: 400; loss: 1.81; acc: 0.39
Batch: 420; loss: 1.67; acc: 0.45
Batch: 440; loss: 1.53; acc: 0.47
Batch: 460; loss: 1.72; acc: 0.41
Batch: 480; loss: 1.61; acc: 0.42
Batch: 500; loss: 1.65; acc: 0.47
Batch: 520; loss: 1.51; acc: 0.42
Batch: 540; loss: 1.55; acc: 0.44
Batch: 560; loss: 1.81; acc: 0.42
Batch: 580; loss: 1.79; acc: 0.34
Batch: 600; loss: 1.6; acc: 0.41
Batch: 620; loss: 1.63; acc: 0.44
Batch: 640; loss: 1.62; acc: 0.39
Batch: 660; loss: 1.72; acc: 0.41
Batch: 680; loss: 1.54; acc: 0.44
Batch: 700; loss: 1.83; acc: 0.42
Batch: 720; loss: 1.76; acc: 0.42
Batch: 740; loss: 1.65; acc: 0.48
Batch: 760; loss: 1.57; acc: 0.52
Batch: 780; loss: 1.51; acc: 0.45
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

1.9471677660476416e-05
6.339982064673677e-06
Batch: 0; loss: 1.59; acc: 0.42
Batch: 20; loss: 1.82; acc: 0.44
Batch: 40; loss: 1.59; acc: 0.47
Batch: 60; loss: 1.69; acc: 0.42
Batch: 80; loss: 1.37; acc: 0.59
Batch: 100; loss: 1.65; acc: 0.39
Batch: 120; loss: 1.75; acc: 0.41
Batch: 140; loss: 1.45; acc: 0.47
Val Epoch over. val_loss: 1.6028521660786526; val_accuracy: 0.432921974522293 

The current subspace-distance is: 6.339982064673677e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.5
Batch: 20; loss: 1.74; acc: 0.33
Batch: 40; loss: 1.59; acc: 0.48
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.69; acc: 0.47
Batch: 100; loss: 1.42; acc: 0.53
Batch: 120; loss: 1.69; acc: 0.33
Batch: 140; loss: 1.86; acc: 0.38
Batch: 160; loss: 1.48; acc: 0.5
Batch: 180; loss: 1.58; acc: 0.45
Batch: 200; loss: 1.73; acc: 0.39
Batch: 220; loss: 1.76; acc: 0.36
Batch: 240; loss: 1.76; acc: 0.38
Batch: 260; loss: 1.52; acc: 0.44
Batch: 280; loss: 1.67; acc: 0.33
Batch: 300; loss: 1.59; acc: 0.44
Batch: 320; loss: 1.48; acc: 0.47
Batch: 340; loss: 1.64; acc: 0.38
Batch: 360; loss: 1.79; acc: 0.41
Batch: 380; loss: 1.7; acc: 0.42
Batch: 400; loss: 1.69; acc: 0.44
Batch: 420; loss: 1.75; acc: 0.39
Batch: 440; loss: 1.65; acc: 0.41
Batch: 460; loss: 1.86; acc: 0.38
Batch: 480; loss: 1.53; acc: 0.48
Batch: 500; loss: 1.62; acc: 0.44
Batch: 520; loss: 1.41; acc: 0.56
Batch: 540; loss: 1.64; acc: 0.42
Batch: 560; loss: 1.79; acc: 0.3
Batch: 580; loss: 1.45; acc: 0.55
Batch: 600; loss: 1.52; acc: 0.45
Batch: 620; loss: 1.66; acc: 0.34
Batch: 640; loss: 1.62; acc: 0.44
Batch: 660; loss: 1.64; acc: 0.48
Batch: 680; loss: 1.66; acc: 0.44
Batch: 700; loss: 1.7; acc: 0.42
Batch: 720; loss: 1.65; acc: 0.38
Batch: 740; loss: 1.61; acc: 0.42
Batch: 760; loss: 1.38; acc: 0.5
Batch: 780; loss: 1.44; acc: 0.52
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.0823867089347914e-05
7.245631422847509e-06
Batch: 0; loss: 1.59; acc: 0.42
Batch: 20; loss: 1.82; acc: 0.42
Batch: 40; loss: 1.59; acc: 0.5
Batch: 60; loss: 1.68; acc: 0.44
Batch: 80; loss: 1.36; acc: 0.59
Batch: 100; loss: 1.65; acc: 0.39
Batch: 120; loss: 1.75; acc: 0.41
Batch: 140; loss: 1.46; acc: 0.44
Val Epoch over. val_loss: 1.6014945469084818; val_accuracy: 0.43640525477707004 

The current subspace-distance is: 7.245631422847509e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.49; acc: 0.45
Batch: 20; loss: 1.77; acc: 0.38
Batch: 40; loss: 1.43; acc: 0.61
Batch: 60; loss: 1.65; acc: 0.34
Batch: 80; loss: 1.73; acc: 0.44
Batch: 100; loss: 1.64; acc: 0.41
Batch: 120; loss: 1.63; acc: 0.39
Batch: 140; loss: 1.71; acc: 0.33
Batch: 160; loss: 1.39; acc: 0.55
Batch: 180; loss: 1.41; acc: 0.55
Batch: 200; loss: 1.81; acc: 0.36
Batch: 220; loss: 1.58; acc: 0.45
Batch: 240; loss: 1.33; acc: 0.52
Batch: 260; loss: 1.73; acc: 0.36
Batch: 280; loss: 1.55; acc: 0.48
Batch: 300; loss: 1.56; acc: 0.47
Batch: 320; loss: 1.73; acc: 0.45
Batch: 340; loss: 1.58; acc: 0.47
Batch: 360; loss: 1.71; acc: 0.39
Batch: 380; loss: 1.49; acc: 0.45
Batch: 400; loss: 1.82; acc: 0.33
Batch: 420; loss: 1.62; acc: 0.44
Batch: 440; loss: 1.65; acc: 0.41
Batch: 460; loss: 1.91; acc: 0.34
Batch: 480; loss: 1.6; acc: 0.41
Batch: 500; loss: 1.62; acc: 0.41
Batch: 520; loss: 1.48; acc: 0.45
Batch: 540; loss: 1.63; acc: 0.39
Batch: 560; loss: 1.7; acc: 0.34
Batch: 580; loss: 1.7; acc: 0.44
Batch: 600; loss: 1.74; acc: 0.39
Batch: 620; loss: 1.65; acc: 0.39
Batch: 640; loss: 1.65; acc: 0.34
Batch: 660; loss: 1.74; acc: 0.33
Batch: 680; loss: 1.72; acc: 0.34
Batch: 700; loss: 1.68; acc: 0.41
Batch: 720; loss: 1.89; acc: 0.34
Batch: 740; loss: 1.74; acc: 0.36
Batch: 760; loss: 1.67; acc: 0.5
Batch: 780; loss: 1.82; acc: 0.38
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.1291771190590225e-05
6.991310328885447e-06
Batch: 0; loss: 1.59; acc: 0.44
Batch: 20; loss: 1.81; acc: 0.44
Batch: 40; loss: 1.59; acc: 0.47
Batch: 60; loss: 1.68; acc: 0.39
Batch: 80; loss: 1.36; acc: 0.59
Batch: 100; loss: 1.64; acc: 0.39
Batch: 120; loss: 1.75; acc: 0.39
Batch: 140; loss: 1.45; acc: 0.44
Val Epoch over. val_loss: 1.6013914430217377; val_accuracy: 0.4330214968152866 

The current subspace-distance is: 6.991310328885447e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.71; acc: 0.41
Batch: 20; loss: 1.53; acc: 0.55
Batch: 40; loss: 1.75; acc: 0.34
Batch: 60; loss: 1.67; acc: 0.44
Batch: 80; loss: 1.7; acc: 0.42
Batch: 100; loss: 1.52; acc: 0.47
Batch: 120; loss: 1.65; acc: 0.41
Batch: 140; loss: 1.51; acc: 0.48
Batch: 160; loss: 1.61; acc: 0.45
Batch: 180; loss: 1.45; acc: 0.45
Batch: 200; loss: 1.52; acc: 0.48
Batch: 220; loss: 1.65; acc: 0.41
Batch: 240; loss: 1.77; acc: 0.33
Batch: 260; loss: 1.56; acc: 0.41
Batch: 280; loss: 1.58; acc: 0.48
Batch: 300; loss: 1.61; acc: 0.38
Batch: 320; loss: 1.78; acc: 0.39
Batch: 340; loss: 1.64; acc: 0.41
Batch: 360; loss: 1.55; acc: 0.48
Batch: 380; loss: 1.69; acc: 0.44
Batch: 400; loss: 1.83; acc: 0.33
Batch: 420; loss: 1.62; acc: 0.41
Batch: 440; loss: 1.57; acc: 0.47
Batch: 460; loss: 1.76; acc: 0.38
Batch: 480; loss: 1.65; acc: 0.39
Batch: 500; loss: 1.58; acc: 0.41
Batch: 520; loss: 1.57; acc: 0.42
Batch: 540; loss: 1.45; acc: 0.53
Batch: 560; loss: 1.57; acc: 0.5
Batch: 580; loss: 1.53; acc: 0.44
Batch: 600; loss: 1.68; acc: 0.41
Batch: 620; loss: 1.66; acc: 0.5
Batch: 640; loss: 1.5; acc: 0.52
Batch: 660; loss: 1.58; acc: 0.38
Batch: 680; loss: 1.38; acc: 0.55
Batch: 700; loss: 1.47; acc: 0.47
Batch: 720; loss: 1.48; acc: 0.41
Batch: 740; loss: 1.66; acc: 0.44
Batch: 760; loss: 1.5; acc: 0.45
Batch: 780; loss: 1.73; acc: 0.36
Train Epoch over. train_loss: 1.64; train_accuracy: 0.42 

2.0182038497296162e-05
6.065493380447151e-06
Batch: 0; loss: 1.59; acc: 0.45
Batch: 20; loss: 1.82; acc: 0.42
Batch: 40; loss: 1.58; acc: 0.48
Batch: 60; loss: 1.68; acc: 0.44
Batch: 80; loss: 1.36; acc: 0.56
Batch: 100; loss: 1.64; acc: 0.39
Batch: 120; loss: 1.76; acc: 0.39
Batch: 140; loss: 1.47; acc: 0.44
Val Epoch over. val_loss: 1.6003358098352032; val_accuracy: 0.43610668789808915 

The current subspace-distance is: 6.065493380447151e-06 

plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 13894
elements in E: 1977400
fraction nonzero: 0.0070263983007990295
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.14
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.31; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.14
Batch: 260; loss: 2.31; acc: 0.17
Batch: 280; loss: 2.32; acc: 0.14
Batch: 300; loss: 2.32; acc: 0.11
Batch: 320; loss: 2.32; acc: 0.14
Batch: 340; loss: 2.3; acc: 0.0
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.31; acc: 0.17
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.31; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.14
Batch: 520; loss: 2.31; acc: 0.14
Batch: 540; loss: 2.31; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.2
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.3; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.31; acc: 0.11
Batch: 720; loss: 2.31; acc: 0.09
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.31; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

7.2930538408400025e-06
5.357924237614498e-07
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Val Epoch over. val_loss: 2.301418100952343; val_accuracy: 0.10648885350318471 

The current subspace-distance is: 5.357924237614498e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.22
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.3; acc: 0.09
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.32; acc: 0.09
Batch: 280; loss: 2.31; acc: 0.09
Batch: 300; loss: 2.32; acc: 0.06
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.31; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.14
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.16
Batch: 500; loss: 2.29; acc: 0.19
Batch: 520; loss: 2.29; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.31; acc: 0.11
Batch: 600; loss: 2.31; acc: 0.11
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.31; acc: 0.08
Batch: 660; loss: 2.3; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.08
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.19
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

8.416934178967495e-06
7.306544489438238e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.05
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Val Epoch over. val_loss: 2.2980758931226792; val_accuracy: 0.10648885350318471 

The current subspace-distance is: 7.306544489438238e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.17
Batch: 160; loss: 2.3; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.17
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.03
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.3; acc: 0.12
Batch: 320; loss: 2.3; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.31; acc: 0.06
Batch: 380; loss: 2.29; acc: 0.23
Batch: 400; loss: 2.29; acc: 0.14
Batch: 420; loss: 2.28; acc: 0.17
Batch: 440; loss: 2.29; acc: 0.2
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.08
Batch: 500; loss: 2.3; acc: 0.08
Batch: 520; loss: 2.3; acc: 0.14
Batch: 540; loss: 2.29; acc: 0.14
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.27; acc: 0.31
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.31; acc: 0.08
Batch: 660; loss: 2.29; acc: 0.2
Batch: 680; loss: 2.3; acc: 0.16
Batch: 700; loss: 2.3; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.31; acc: 0.19
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

8.192871064238716e-06
9.521558581582212e-07
Batch: 0; loss: 2.29; acc: 0.19
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.28; acc: 0.25
Batch: 60; loss: 2.28; acc: 0.19
Batch: 80; loss: 2.29; acc: 0.22
Batch: 100; loss: 2.29; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.29; acc: 0.2
Val Epoch over. val_loss: 2.292107815955095; val_accuracy: 0.18371815286624205 

The current subspace-distance is: 9.521558581582212e-07 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.28; acc: 0.22
Batch: 60; loss: 2.3; acc: 0.16
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.17
Batch: 120; loss: 2.28; acc: 0.27
Batch: 140; loss: 2.29; acc: 0.2
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.22
Batch: 200; loss: 2.28; acc: 0.3
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.29; acc: 0.28
Batch: 280; loss: 2.28; acc: 0.27
Batch: 300; loss: 2.27; acc: 0.31
Batch: 320; loss: 2.28; acc: 0.2
Batch: 340; loss: 2.28; acc: 0.27
Batch: 360; loss: 2.28; acc: 0.19
Batch: 380; loss: 2.28; acc: 0.25
Batch: 400; loss: 2.3; acc: 0.19
Batch: 420; loss: 2.3; acc: 0.19
Batch: 440; loss: 2.3; acc: 0.19
Batch: 460; loss: 2.3; acc: 0.2
Batch: 480; loss: 2.28; acc: 0.2
Batch: 500; loss: 2.29; acc: 0.23
Batch: 520; loss: 2.28; acc: 0.22
Batch: 540; loss: 2.29; acc: 0.16
Batch: 560; loss: 2.28; acc: 0.22
Batch: 580; loss: 2.29; acc: 0.2
Batch: 600; loss: 2.29; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.19
Batch: 640; loss: 2.28; acc: 0.19
Batch: 660; loss: 2.28; acc: 0.17
Batch: 680; loss: 2.28; acc: 0.2
Batch: 700; loss: 2.27; acc: 0.16
Batch: 720; loss: 2.28; acc: 0.19
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.27; acc: 0.28
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.28; train_accuracy: 0.21 

9.496060556557495e-06
1.598005042069417e-06
Batch: 0; loss: 2.27; acc: 0.25
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.26; acc: 0.33
Batch: 60; loss: 2.26; acc: 0.3
Batch: 80; loss: 2.26; acc: 0.3
Batch: 100; loss: 2.27; acc: 0.17
Batch: 120; loss: 2.27; acc: 0.23
Batch: 140; loss: 2.27; acc: 0.2
Val Epoch over. val_loss: 2.2741236170386054; val_accuracy: 0.25278662420382164 

The current subspace-distance is: 1.598005042069417e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.23
Batch: 20; loss: 2.28; acc: 0.28
Batch: 40; loss: 2.27; acc: 0.3
Batch: 60; loss: 2.27; acc: 0.25
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.24; acc: 0.33
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.24; acc: 0.38
Batch: 160; loss: 2.26; acc: 0.31
Batch: 180; loss: 2.28; acc: 0.2
Batch: 200; loss: 2.27; acc: 0.27
Batch: 220; loss: 2.26; acc: 0.34
Batch: 240; loss: 2.27; acc: 0.27
Batch: 260; loss: 2.24; acc: 0.33
Batch: 280; loss: 2.27; acc: 0.25
Batch: 300; loss: 2.24; acc: 0.33
Batch: 320; loss: 2.26; acc: 0.33
Batch: 340; loss: 2.23; acc: 0.33
Batch: 360; loss: 2.25; acc: 0.31
Batch: 380; loss: 2.22; acc: 0.28
Batch: 400; loss: 2.26; acc: 0.17
Batch: 420; loss: 2.23; acc: 0.31
Batch: 440; loss: 2.24; acc: 0.28
Batch: 460; loss: 2.21; acc: 0.34
Batch: 480; loss: 2.19; acc: 0.36
Batch: 500; loss: 2.16; acc: 0.45
Batch: 520; loss: 2.17; acc: 0.33
Batch: 540; loss: 2.19; acc: 0.27
Batch: 560; loss: 2.11; acc: 0.36
Batch: 580; loss: 2.08; acc: 0.38
Batch: 600; loss: 2.12; acc: 0.25
Batch: 620; loss: 2.06; acc: 0.34
Batch: 640; loss: 2.08; acc: 0.28
Batch: 660; loss: 2.02; acc: 0.3
Batch: 680; loss: 1.98; acc: 0.34
Batch: 700; loss: 1.93; acc: 0.36
Batch: 720; loss: 2.03; acc: 0.25
Batch: 740; loss: 1.86; acc: 0.34
Batch: 760; loss: 1.9; acc: 0.28
Batch: 780; loss: 1.76; acc: 0.44
Train Epoch over. train_loss: 2.17; train_accuracy: 0.31 

1.1668477782222908e-05
3.1326001135312254e-06
Batch: 0; loss: 1.88; acc: 0.36
Batch: 20; loss: 1.96; acc: 0.39
Batch: 40; loss: 1.72; acc: 0.38
Batch: 60; loss: 1.7; acc: 0.41
Batch: 80; loss: 1.64; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.22
Batch: 120; loss: 1.87; acc: 0.33
Batch: 140; loss: 1.91; acc: 0.28
Val Epoch over. val_loss: 1.8238098545438926; val_accuracy: 0.34076433121019106 

The current subspace-distance is: 3.1326001135312254e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.93; acc: 0.3
Batch: 20; loss: 1.84; acc: 0.33
Batch: 40; loss: 1.71; acc: 0.39
Batch: 60; loss: 1.91; acc: 0.25
Batch: 80; loss: 1.7; acc: 0.53
Batch: 100; loss: 1.55; acc: 0.44
Batch: 120; loss: 1.64; acc: 0.38
Batch: 140; loss: 1.6; acc: 0.52
Batch: 160; loss: 1.59; acc: 0.44
Batch: 180; loss: 1.5; acc: 0.53
Batch: 200; loss: 1.58; acc: 0.39
Batch: 220; loss: 1.45; acc: 0.5
Batch: 240; loss: 1.46; acc: 0.52
Batch: 260; loss: 1.63; acc: 0.44
Batch: 280; loss: 1.43; acc: 0.48
Batch: 300; loss: 1.34; acc: 0.61
Batch: 320; loss: 1.43; acc: 0.58
Batch: 340; loss: 1.43; acc: 0.52
Batch: 360; loss: 1.35; acc: 0.53
Batch: 380; loss: 1.18; acc: 0.61
Batch: 400; loss: 1.21; acc: 0.53
Batch: 420; loss: 1.41; acc: 0.55
Batch: 440; loss: 1.21; acc: 0.64
Batch: 460; loss: 1.28; acc: 0.58
Batch: 480; loss: 1.13; acc: 0.56
Batch: 500; loss: 1.19; acc: 0.62
Batch: 520; loss: 1.37; acc: 0.55
Batch: 540; loss: 1.26; acc: 0.56
Batch: 560; loss: 1.38; acc: 0.48
Batch: 580; loss: 1.39; acc: 0.61
Batch: 600; loss: 1.33; acc: 0.52
Batch: 620; loss: 1.1; acc: 0.69
Batch: 640; loss: 1.11; acc: 0.64
Batch: 660; loss: 1.05; acc: 0.62
Batch: 680; loss: 1.37; acc: 0.53
Batch: 700; loss: 1.09; acc: 0.75
Batch: 720; loss: 1.34; acc: 0.55
Batch: 740; loss: 0.98; acc: 0.59
Batch: 760; loss: 1.16; acc: 0.64
Batch: 780; loss: 1.29; acc: 0.61
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

2.06231779884547e-05
4.970870122633642e-06
Batch: 0; loss: 1.33; acc: 0.55
Batch: 20; loss: 1.33; acc: 0.56
Batch: 40; loss: 0.99; acc: 0.59
Batch: 60; loss: 0.97; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.64
Batch: 100; loss: 1.08; acc: 0.62
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.73
Val Epoch over. val_loss: 1.193370841870642; val_accuracy: 0.5967356687898089 

The current subspace-distance is: 4.970870122633642e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.06; acc: 0.69
Batch: 40; loss: 1.05; acc: 0.69
Batch: 60; loss: 0.97; acc: 0.67
Batch: 80; loss: 1.13; acc: 0.62
Batch: 100; loss: 1.08; acc: 0.67
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 1.1; acc: 0.64
Batch: 160; loss: 1.37; acc: 0.56
Batch: 180; loss: 1.17; acc: 0.62
Batch: 200; loss: 1.32; acc: 0.52
Batch: 220; loss: 1.02; acc: 0.7
Batch: 240; loss: 1.43; acc: 0.56
Batch: 260; loss: 1.2; acc: 0.61
Batch: 280; loss: 1.13; acc: 0.62
Batch: 300; loss: 1.03; acc: 0.62
Batch: 320; loss: 1.05; acc: 0.62
Batch: 340; loss: 1.21; acc: 0.58
Batch: 360; loss: 0.97; acc: 0.58
Batch: 380; loss: 1.04; acc: 0.66
Batch: 400; loss: 1.14; acc: 0.64
Batch: 420; loss: 0.9; acc: 0.69
Batch: 440; loss: 0.88; acc: 0.66
Batch: 460; loss: 1.15; acc: 0.62
Batch: 480; loss: 0.99; acc: 0.69
Batch: 500; loss: 1.2; acc: 0.62
Batch: 520; loss: 1.5; acc: 0.55
Batch: 540; loss: 1.17; acc: 0.56
Batch: 560; loss: 1.0; acc: 0.62
Batch: 580; loss: 1.13; acc: 0.64
Batch: 600; loss: 1.3; acc: 0.58
Batch: 620; loss: 1.07; acc: 0.7
Batch: 640; loss: 1.13; acc: 0.55
Batch: 660; loss: 1.01; acc: 0.66
Batch: 680; loss: 1.02; acc: 0.69
Batch: 700; loss: 1.08; acc: 0.7
Batch: 720; loss: 1.11; acc: 0.61
Batch: 740; loss: 0.96; acc: 0.64
Batch: 760; loss: 0.98; acc: 0.61
Batch: 780; loss: 1.02; acc: 0.66
Train Epoch over. train_loss: 1.11; train_accuracy: 0.63 

2.3732669433229603e-05
5.224299457040615e-06
Batch: 0; loss: 1.26; acc: 0.42
Batch: 20; loss: 1.48; acc: 0.42
Batch: 40; loss: 1.0; acc: 0.72
Batch: 60; loss: 0.98; acc: 0.56
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.26; acc: 0.55
Batch: 120; loss: 1.22; acc: 0.58
Batch: 140; loss: 0.94; acc: 0.62
Val Epoch over. val_loss: 1.2683758933073397; val_accuracy: 0.5609076433121019 

The current subspace-distance is: 5.224299457040615e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.31; acc: 0.56
Batch: 20; loss: 1.21; acc: 0.56
Batch: 40; loss: 1.23; acc: 0.61
Batch: 60; loss: 1.2; acc: 0.58
Batch: 80; loss: 0.96; acc: 0.69
Batch: 100; loss: 1.04; acc: 0.62
Batch: 120; loss: 1.23; acc: 0.64
Batch: 140; loss: 0.9; acc: 0.72
Batch: 160; loss: 1.23; acc: 0.55
Batch: 180; loss: 1.19; acc: 0.62
Batch: 200; loss: 0.85; acc: 0.7
Batch: 220; loss: 1.37; acc: 0.53
Batch: 240; loss: 1.29; acc: 0.5
Batch: 260; loss: 1.06; acc: 0.64
Batch: 280; loss: 0.96; acc: 0.69
Batch: 300; loss: 1.16; acc: 0.69
Batch: 320; loss: 0.78; acc: 0.73
Batch: 340; loss: 1.04; acc: 0.66
Batch: 360; loss: 0.96; acc: 0.67
Batch: 380; loss: 0.87; acc: 0.72
Batch: 400; loss: 0.98; acc: 0.67
Batch: 420; loss: 1.05; acc: 0.69
Batch: 440; loss: 1.01; acc: 0.61
Batch: 460; loss: 1.31; acc: 0.64
Batch: 480; loss: 0.8; acc: 0.78
Batch: 500; loss: 1.31; acc: 0.56
Batch: 520; loss: 0.83; acc: 0.69
Batch: 540; loss: 1.23; acc: 0.55
Batch: 560; loss: 1.23; acc: 0.59
Batch: 580; loss: 1.03; acc: 0.7
Batch: 600; loss: 0.95; acc: 0.73
Batch: 620; loss: 0.96; acc: 0.7
Batch: 640; loss: 0.98; acc: 0.69
Batch: 660; loss: 1.29; acc: 0.61
Batch: 680; loss: 0.99; acc: 0.61
Batch: 700; loss: 1.0; acc: 0.56
Batch: 720; loss: 0.99; acc: 0.62
Batch: 740; loss: 1.04; acc: 0.7
Batch: 760; loss: 1.04; acc: 0.7
Batch: 780; loss: 1.0; acc: 0.69
Train Epoch over. train_loss: 1.06; train_accuracy: 0.66 

2.2925474695512094e-05
6.552929789904738e-06
Batch: 0; loss: 1.31; acc: 0.62
Batch: 20; loss: 1.86; acc: 0.48
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.04; acc: 0.66
Batch: 80; loss: 1.11; acc: 0.64
Batch: 100; loss: 1.25; acc: 0.64
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 1.11; acc: 0.64
Val Epoch over. val_loss: 1.2672116335030574; val_accuracy: 0.5969347133757962 

The current subspace-distance is: 6.552929789904738e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.47; acc: 0.52
Batch: 20; loss: 1.09; acc: 0.61
Batch: 40; loss: 0.95; acc: 0.72
Batch: 60; loss: 0.98; acc: 0.72
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 1.01; acc: 0.69
Batch: 120; loss: 0.98; acc: 0.61
Batch: 140; loss: 0.73; acc: 0.72
Batch: 160; loss: 1.19; acc: 0.67
Batch: 180; loss: 0.82; acc: 0.73
Batch: 200; loss: 1.2; acc: 0.66
Batch: 220; loss: 0.89; acc: 0.78
Batch: 240; loss: 1.27; acc: 0.61
Batch: 260; loss: 1.19; acc: 0.58
Batch: 280; loss: 1.47; acc: 0.66
Batch: 300; loss: 1.42; acc: 0.64
Batch: 320; loss: 1.05; acc: 0.64
Batch: 340; loss: 1.03; acc: 0.61
Batch: 360; loss: 1.08; acc: 0.69
Batch: 380; loss: 1.07; acc: 0.61
Batch: 400; loss: 0.94; acc: 0.77
Batch: 420; loss: 1.19; acc: 0.58
Batch: 440; loss: 1.0; acc: 0.69
Batch: 460; loss: 0.98; acc: 0.62
Batch: 480; loss: 0.98; acc: 0.64
Batch: 500; loss: 1.3; acc: 0.53
Batch: 520; loss: 1.44; acc: 0.52
Batch: 540; loss: 0.68; acc: 0.8
Batch: 560; loss: 0.9; acc: 0.75
Batch: 580; loss: 1.17; acc: 0.58
Batch: 600; loss: 0.98; acc: 0.7
Batch: 620; loss: 0.88; acc: 0.75
Batch: 640; loss: 1.06; acc: 0.67
Batch: 660; loss: 0.79; acc: 0.72
Batch: 680; loss: 1.06; acc: 0.75
Batch: 700; loss: 0.93; acc: 0.72
Batch: 720; loss: 0.98; acc: 0.69
Batch: 740; loss: 0.89; acc: 0.7
Batch: 760; loss: 1.84; acc: 0.48
Batch: 780; loss: 0.86; acc: 0.7
Train Epoch over. train_loss: 1.04; train_accuracy: 0.66 

2.2967842596699484e-05
5.910581876378274e-06
Batch: 0; loss: 1.04; acc: 0.66
Batch: 20; loss: 1.4; acc: 0.62
Batch: 40; loss: 0.79; acc: 0.75
Batch: 60; loss: 0.9; acc: 0.69
Batch: 80; loss: 0.89; acc: 0.72
Batch: 100; loss: 0.99; acc: 0.69
Batch: 120; loss: 1.31; acc: 0.56
Batch: 140; loss: 0.8; acc: 0.7
Val Epoch over. val_loss: 1.0321305625757593; val_accuracy: 0.6556528662420382 

The current subspace-distance is: 5.910581876378274e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.11; acc: 0.62
Batch: 20; loss: 0.86; acc: 0.7
Batch: 40; loss: 0.95; acc: 0.61
Batch: 60; loss: 1.02; acc: 0.59
Batch: 80; loss: 1.2; acc: 0.66
Batch: 100; loss: 1.14; acc: 0.62
Batch: 120; loss: 0.93; acc: 0.7
Batch: 140; loss: 0.82; acc: 0.8
Batch: 160; loss: 1.13; acc: 0.72
Batch: 180; loss: 1.09; acc: 0.69
Batch: 200; loss: 1.03; acc: 0.67
Batch: 220; loss: 1.11; acc: 0.73
Batch: 240; loss: 1.56; acc: 0.66
Batch: 260; loss: 1.4; acc: 0.62
Batch: 280; loss: 1.03; acc: 0.7
Batch: 300; loss: 1.29; acc: 0.5
Batch: 320; loss: 0.88; acc: 0.69
Batch: 340; loss: 1.54; acc: 0.53
Batch: 360; loss: 1.01; acc: 0.67
Batch: 380; loss: 1.2; acc: 0.66
Batch: 400; loss: 0.95; acc: 0.62
Batch: 420; loss: 1.07; acc: 0.62
Batch: 440; loss: 0.95; acc: 0.72
Batch: 460; loss: 0.9; acc: 0.64
Batch: 480; loss: 1.0; acc: 0.64
Batch: 500; loss: 0.99; acc: 0.7
Batch: 520; loss: 1.01; acc: 0.67
Batch: 540; loss: 0.98; acc: 0.73
Batch: 560; loss: 1.04; acc: 0.72
Batch: 580; loss: 0.93; acc: 0.66
Batch: 600; loss: 1.16; acc: 0.61
Batch: 620; loss: 0.98; acc: 0.73
Batch: 640; loss: 0.94; acc: 0.67
Batch: 660; loss: 0.88; acc: 0.72
Batch: 680; loss: 1.03; acc: 0.61
Batch: 700; loss: 1.06; acc: 0.61
Batch: 720; loss: 0.81; acc: 0.75
Batch: 740; loss: 1.27; acc: 0.61
Batch: 760; loss: 1.1; acc: 0.59
Batch: 780; loss: 0.94; acc: 0.66
Train Epoch over. train_loss: 1.04; train_accuracy: 0.67 

2.6431958758621477e-05
5.358678208722267e-06
Batch: 0; loss: 0.91; acc: 0.66
Batch: 20; loss: 1.31; acc: 0.55
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 0.94; acc: 0.7
Batch: 80; loss: 0.78; acc: 0.73
Batch: 100; loss: 0.88; acc: 0.73
Batch: 120; loss: 1.29; acc: 0.64
Batch: 140; loss: 0.73; acc: 0.8
Val Epoch over. val_loss: 1.0231508753102296; val_accuracy: 0.6773487261146497 

The current subspace-distance is: 5.358678208722267e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.84; acc: 0.69
Batch: 20; loss: 0.71; acc: 0.75
Batch: 40; loss: 1.08; acc: 0.64
Batch: 60; loss: 0.83; acc: 0.67
Batch: 80; loss: 1.05; acc: 0.7
Batch: 100; loss: 1.1; acc: 0.66
Batch: 120; loss: 1.05; acc: 0.7
Batch: 140; loss: 1.24; acc: 0.69
Batch: 160; loss: 0.94; acc: 0.69
Batch: 180; loss: 0.88; acc: 0.75
Batch: 200; loss: 1.11; acc: 0.69
Batch: 220; loss: 0.84; acc: 0.73
Batch: 240; loss: 0.7; acc: 0.75
Batch: 260; loss: 1.15; acc: 0.61
Batch: 280; loss: 1.27; acc: 0.7
Batch: 300; loss: 1.07; acc: 0.67
Batch: 320; loss: 0.92; acc: 0.64
Batch: 340; loss: 1.12; acc: 0.61
Batch: 360; loss: 1.02; acc: 0.72
Batch: 380; loss: 1.13; acc: 0.69
Batch: 400; loss: 1.11; acc: 0.58
Batch: 420; loss: 0.74; acc: 0.83
Batch: 440; loss: 0.94; acc: 0.69
Batch: 460; loss: 0.85; acc: 0.77
Batch: 480; loss: 0.97; acc: 0.67
Batch: 500; loss: 0.83; acc: 0.8
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 1.06; acc: 0.62
Batch: 560; loss: 0.79; acc: 0.77
Batch: 580; loss: 1.12; acc: 0.62
Batch: 600; loss: 0.81; acc: 0.7
Batch: 620; loss: 1.27; acc: 0.59
Batch: 640; loss: 1.14; acc: 0.67
Batch: 660; loss: 0.98; acc: 0.7
Batch: 680; loss: 0.88; acc: 0.73
Batch: 700; loss: 1.0; acc: 0.67
Batch: 720; loss: 0.96; acc: 0.67
Batch: 740; loss: 0.92; acc: 0.73
Batch: 760; loss: 0.74; acc: 0.73
Batch: 780; loss: 1.14; acc: 0.77
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.3724207494524308e-05
5.144238912180299e-06
Batch: 0; loss: 0.92; acc: 0.75
Batch: 20; loss: 1.22; acc: 0.58
Batch: 40; loss: 0.75; acc: 0.72
Batch: 60; loss: 0.84; acc: 0.7
Batch: 80; loss: 0.87; acc: 0.75
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 1.14; acc: 0.64
Batch: 140; loss: 0.63; acc: 0.81
Val Epoch over. val_loss: 0.9580642698676722; val_accuracy: 0.6838176751592356 

The current subspace-distance is: 5.144238912180299e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.85; acc: 0.69
Batch: 20; loss: 1.1; acc: 0.73
Batch: 40; loss: 1.24; acc: 0.66
Batch: 60; loss: 0.81; acc: 0.69
Batch: 80; loss: 0.88; acc: 0.75
Batch: 100; loss: 1.19; acc: 0.64
Batch: 120; loss: 0.8; acc: 0.8
Batch: 140; loss: 0.9; acc: 0.72
Batch: 160; loss: 0.84; acc: 0.72
Batch: 180; loss: 0.88; acc: 0.7
Batch: 200; loss: 0.84; acc: 0.72
Batch: 220; loss: 1.04; acc: 0.72
Batch: 240; loss: 1.19; acc: 0.64
Batch: 260; loss: 1.27; acc: 0.59
Batch: 280; loss: 1.13; acc: 0.64
Batch: 300; loss: 0.81; acc: 0.77
Batch: 320; loss: 1.05; acc: 0.64
Batch: 340; loss: 1.24; acc: 0.53
Batch: 360; loss: 0.89; acc: 0.78
Batch: 380; loss: 1.2; acc: 0.7
Batch: 400; loss: 1.07; acc: 0.72
Batch: 420; loss: 0.91; acc: 0.72
Batch: 440; loss: 1.32; acc: 0.62
Batch: 460; loss: 0.76; acc: 0.73
Batch: 480; loss: 1.3; acc: 0.59
Batch: 500; loss: 1.16; acc: 0.67
Batch: 520; loss: 0.96; acc: 0.62
Batch: 540; loss: 0.79; acc: 0.77
Batch: 560; loss: 0.99; acc: 0.59
Batch: 580; loss: 0.84; acc: 0.72
Batch: 600; loss: 1.1; acc: 0.67
Batch: 620; loss: 0.87; acc: 0.72
Batch: 640; loss: 0.95; acc: 0.69
Batch: 660; loss: 0.83; acc: 0.77
Batch: 680; loss: 1.0; acc: 0.7
Batch: 700; loss: 0.72; acc: 0.72
Batch: 720; loss: 1.13; acc: 0.66
Batch: 740; loss: 1.23; acc: 0.62
Batch: 760; loss: 0.92; acc: 0.75
Batch: 780; loss: 0.94; acc: 0.77
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.3200449504656717e-05
5.315810994943604e-06
Batch: 0; loss: 0.82; acc: 0.69
Batch: 20; loss: 1.23; acc: 0.58
Batch: 40; loss: 0.73; acc: 0.77
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 0.8; acc: 0.77
Batch: 100; loss: 0.8; acc: 0.8
Batch: 120; loss: 1.31; acc: 0.64
Batch: 140; loss: 0.65; acc: 0.78
Val Epoch over. val_loss: 0.9687922718418631; val_accuracy: 0.6950636942675159 

The current subspace-distance is: 5.315810994943604e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.24; acc: 0.66
Batch: 20; loss: 1.0; acc: 0.66
Batch: 40; loss: 0.71; acc: 0.73
Batch: 60; loss: 1.02; acc: 0.67
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.79; acc: 0.75
Batch: 120; loss: 0.85; acc: 0.7
Batch: 140; loss: 0.81; acc: 0.7
Batch: 160; loss: 0.7; acc: 0.72
Batch: 180; loss: 1.09; acc: 0.64
Batch: 200; loss: 0.99; acc: 0.62
Batch: 220; loss: 0.96; acc: 0.69
Batch: 240; loss: 0.86; acc: 0.72
Batch: 260; loss: 1.22; acc: 0.58
Batch: 280; loss: 0.81; acc: 0.72
Batch: 300; loss: 0.73; acc: 0.78
Batch: 320; loss: 1.01; acc: 0.67
Batch: 340; loss: 1.4; acc: 0.61
Batch: 360; loss: 0.82; acc: 0.77
Batch: 380; loss: 0.82; acc: 0.75
Batch: 400; loss: 1.05; acc: 0.66
Batch: 420; loss: 0.97; acc: 0.69
Batch: 440; loss: 0.96; acc: 0.69
Batch: 460; loss: 1.05; acc: 0.67
Batch: 480; loss: 0.94; acc: 0.7
Batch: 500; loss: 1.22; acc: 0.61
Batch: 520; loss: 0.99; acc: 0.7
Batch: 540; loss: 1.25; acc: 0.62
Batch: 560; loss: 0.9; acc: 0.72
Batch: 580; loss: 1.13; acc: 0.66
Batch: 600; loss: 0.8; acc: 0.8
Batch: 620; loss: 0.89; acc: 0.67
Batch: 640; loss: 0.93; acc: 0.7
Batch: 660; loss: 1.21; acc: 0.62
Batch: 680; loss: 0.96; acc: 0.7
Batch: 700; loss: 0.99; acc: 0.7
Batch: 720; loss: 1.18; acc: 0.58
Batch: 740; loss: 1.11; acc: 0.61
Batch: 760; loss: 1.17; acc: 0.7
Batch: 780; loss: 0.72; acc: 0.8
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.2262436687014997e-05
5.788882390334038e-06
Batch: 0; loss: 0.85; acc: 0.7
Batch: 20; loss: 1.25; acc: 0.55
Batch: 40; loss: 0.81; acc: 0.73
Batch: 60; loss: 0.88; acc: 0.73
Batch: 80; loss: 0.89; acc: 0.75
Batch: 100; loss: 0.86; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.66
Batch: 140; loss: 0.59; acc: 0.8
Val Epoch over. val_loss: 0.9749627732167578; val_accuracy: 0.6850119426751592 

The current subspace-distance is: 5.788882390334038e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.07; acc: 0.67
Batch: 20; loss: 0.92; acc: 0.7
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 1.01; acc: 0.7
Batch: 80; loss: 0.99; acc: 0.64
Batch: 100; loss: 0.9; acc: 0.7
Batch: 120; loss: 0.9; acc: 0.78
Batch: 140; loss: 0.9; acc: 0.72
Batch: 160; loss: 1.28; acc: 0.59
Batch: 180; loss: 1.07; acc: 0.69
Batch: 200; loss: 0.82; acc: 0.7
Batch: 220; loss: 0.99; acc: 0.69
Batch: 240; loss: 0.9; acc: 0.77
Batch: 260; loss: 0.99; acc: 0.66
Batch: 280; loss: 0.89; acc: 0.7
Batch: 300; loss: 1.09; acc: 0.64
Batch: 320; loss: 1.33; acc: 0.61
Batch: 340; loss: 0.93; acc: 0.75
Batch: 360; loss: 0.69; acc: 0.75
Batch: 380; loss: 0.81; acc: 0.75
Batch: 400; loss: 0.86; acc: 0.7
Batch: 420; loss: 0.92; acc: 0.67
Batch: 440; loss: 0.89; acc: 0.73
Batch: 460; loss: 0.96; acc: 0.69
Batch: 480; loss: 0.84; acc: 0.75
Batch: 500; loss: 0.96; acc: 0.64
Batch: 520; loss: 0.67; acc: 0.81
Batch: 540; loss: 0.68; acc: 0.81
Batch: 560; loss: 1.03; acc: 0.73
Batch: 580; loss: 1.07; acc: 0.67
Batch: 600; loss: 1.04; acc: 0.61
Batch: 620; loss: 0.95; acc: 0.62
Batch: 640; loss: 0.96; acc: 0.69
Batch: 660; loss: 0.93; acc: 0.73
Batch: 680; loss: 1.08; acc: 0.69
Batch: 700; loss: 1.11; acc: 0.66
Batch: 720; loss: 0.81; acc: 0.69
Batch: 740; loss: 0.94; acc: 0.69
Batch: 760; loss: 1.37; acc: 0.47
Batch: 780; loss: 0.97; acc: 0.7
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.475992550898809e-05
5.7075403674389236e-06
Batch: 0; loss: 0.92; acc: 0.67
Batch: 20; loss: 1.52; acc: 0.5
Batch: 40; loss: 0.87; acc: 0.73
Batch: 60; loss: 0.97; acc: 0.66
Batch: 80; loss: 0.98; acc: 0.69
Batch: 100; loss: 1.01; acc: 0.67
Batch: 120; loss: 1.42; acc: 0.58
Batch: 140; loss: 0.8; acc: 0.66
Val Epoch over. val_loss: 1.1198180074904376; val_accuracy: 0.6216162420382165 

The current subspace-distance is: 5.7075403674389236e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.94; acc: 0.67
Batch: 20; loss: 0.83; acc: 0.8
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.96; acc: 0.67
Batch: 80; loss: 0.87; acc: 0.64
Batch: 100; loss: 0.87; acc: 0.7
Batch: 120; loss: 1.08; acc: 0.7
Batch: 140; loss: 0.97; acc: 0.73
Batch: 160; loss: 0.84; acc: 0.72
Batch: 180; loss: 0.82; acc: 0.75
Batch: 200; loss: 1.09; acc: 0.69
Batch: 220; loss: 1.1; acc: 0.66
Batch: 240; loss: 0.86; acc: 0.73
Batch: 260; loss: 0.89; acc: 0.7
Batch: 280; loss: 1.21; acc: 0.62
Batch: 300; loss: 0.86; acc: 0.66
Batch: 320; loss: 0.86; acc: 0.73
Batch: 340; loss: 0.88; acc: 0.72
Batch: 360; loss: 0.95; acc: 0.69
Batch: 380; loss: 0.89; acc: 0.73
Batch: 400; loss: 1.17; acc: 0.69
Batch: 420; loss: 1.05; acc: 0.7
Batch: 440; loss: 0.96; acc: 0.72
Batch: 460; loss: 0.91; acc: 0.7
Batch: 480; loss: 1.11; acc: 0.64
Batch: 500; loss: 0.76; acc: 0.81
Batch: 520; loss: 0.88; acc: 0.72
Batch: 540; loss: 0.99; acc: 0.67
Batch: 560; loss: 0.86; acc: 0.77
Batch: 580; loss: 1.19; acc: 0.61
Batch: 600; loss: 0.85; acc: 0.75
Batch: 620; loss: 1.23; acc: 0.62
Batch: 640; loss: 0.95; acc: 0.72
Batch: 660; loss: 1.11; acc: 0.67
Batch: 680; loss: 0.92; acc: 0.72
Batch: 700; loss: 1.04; acc: 0.58
Batch: 720; loss: 1.12; acc: 0.61
Batch: 740; loss: 0.96; acc: 0.7
Batch: 760; loss: 1.04; acc: 0.62
Batch: 780; loss: 1.24; acc: 0.62
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.3006123228697106e-05
5.269677785690874e-06
Batch: 0; loss: 0.76; acc: 0.7
Batch: 20; loss: 1.2; acc: 0.53
Batch: 40; loss: 0.73; acc: 0.73
Batch: 60; loss: 0.88; acc: 0.77
Batch: 80; loss: 0.83; acc: 0.77
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.72
Batch: 140; loss: 0.61; acc: 0.75
Val Epoch over. val_loss: 0.9455335109856478; val_accuracy: 0.7040207006369427 

The current subspace-distance is: 5.269677785690874e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.89; acc: 0.75
Batch: 20; loss: 1.11; acc: 0.7
Batch: 40; loss: 1.03; acc: 0.61
Batch: 60; loss: 0.97; acc: 0.67
Batch: 80; loss: 1.12; acc: 0.67
Batch: 100; loss: 0.88; acc: 0.62
Batch: 120; loss: 0.92; acc: 0.78
Batch: 140; loss: 0.95; acc: 0.72
Batch: 160; loss: 1.09; acc: 0.64
Batch: 180; loss: 1.01; acc: 0.7
Batch: 200; loss: 0.92; acc: 0.73
Batch: 220; loss: 0.83; acc: 0.72
Batch: 240; loss: 0.68; acc: 0.75
Batch: 260; loss: 0.91; acc: 0.73
Batch: 280; loss: 0.88; acc: 0.69
Batch: 300; loss: 0.82; acc: 0.75
Batch: 320; loss: 1.0; acc: 0.69
Batch: 340; loss: 0.88; acc: 0.72
Batch: 360; loss: 1.1; acc: 0.56
Batch: 380; loss: 1.15; acc: 0.7
Batch: 400; loss: 1.15; acc: 0.67
Batch: 420; loss: 0.79; acc: 0.75
Batch: 440; loss: 0.83; acc: 0.67
Batch: 460; loss: 0.86; acc: 0.72
Batch: 480; loss: 1.1; acc: 0.66
Batch: 500; loss: 0.73; acc: 0.77
Batch: 520; loss: 0.76; acc: 0.78
Batch: 540; loss: 0.94; acc: 0.72
Batch: 560; loss: 1.06; acc: 0.67
Batch: 580; loss: 1.04; acc: 0.69
Batch: 600; loss: 1.12; acc: 0.69
Batch: 620; loss: 0.84; acc: 0.69
Batch: 640; loss: 0.83; acc: 0.72
Batch: 660; loss: 1.02; acc: 0.72
Batch: 680; loss: 1.24; acc: 0.56
Batch: 700; loss: 0.8; acc: 0.75
Batch: 720; loss: 0.94; acc: 0.64
Batch: 740; loss: 0.68; acc: 0.75
Batch: 760; loss: 0.98; acc: 0.73
Batch: 780; loss: 0.89; acc: 0.61
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.3036282073007897e-05
5.442042947834125e-06
Batch: 0; loss: 0.92; acc: 0.64
Batch: 20; loss: 1.33; acc: 0.62
Batch: 40; loss: 0.82; acc: 0.69
Batch: 60; loss: 1.08; acc: 0.66
Batch: 80; loss: 0.91; acc: 0.75
Batch: 100; loss: 0.9; acc: 0.7
Batch: 120; loss: 1.41; acc: 0.62
Batch: 140; loss: 0.72; acc: 0.67
Val Epoch over. val_loss: 1.032360292544031; val_accuracy: 0.6673964968152867 

The current subspace-distance is: 5.442042947834125e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.21; acc: 0.58
Batch: 20; loss: 1.25; acc: 0.64
Batch: 40; loss: 1.02; acc: 0.7
Batch: 60; loss: 0.85; acc: 0.73
Batch: 80; loss: 1.21; acc: 0.53
Batch: 100; loss: 0.92; acc: 0.66
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 1.19; acc: 0.66
Batch: 180; loss: 1.0; acc: 0.69
Batch: 200; loss: 0.95; acc: 0.7
Batch: 220; loss: 0.89; acc: 0.66
Batch: 240; loss: 0.92; acc: 0.69
Batch: 260; loss: 1.04; acc: 0.64
Batch: 280; loss: 1.02; acc: 0.7
Batch: 300; loss: 0.96; acc: 0.72
Batch: 320; loss: 0.92; acc: 0.69
Batch: 340; loss: 1.21; acc: 0.69
Batch: 360; loss: 0.8; acc: 0.72
Batch: 380; loss: 1.0; acc: 0.72
Batch: 400; loss: 1.11; acc: 0.7
Batch: 420; loss: 1.21; acc: 0.59
Batch: 440; loss: 1.05; acc: 0.66
Batch: 460; loss: 1.16; acc: 0.66
Batch: 480; loss: 0.75; acc: 0.75
Batch: 500; loss: 1.06; acc: 0.64
Batch: 520; loss: 0.88; acc: 0.7
Batch: 540; loss: 0.84; acc: 0.75
Batch: 560; loss: 0.95; acc: 0.73
Batch: 580; loss: 1.16; acc: 0.59
Batch: 600; loss: 0.96; acc: 0.67
Batch: 620; loss: 0.95; acc: 0.69
Batch: 640; loss: 0.94; acc: 0.7
Batch: 660; loss: 1.13; acc: 0.67
Batch: 680; loss: 0.92; acc: 0.67
Batch: 700; loss: 1.26; acc: 0.67
Batch: 720; loss: 1.05; acc: 0.7
Batch: 740; loss: 1.05; acc: 0.66
Batch: 760; loss: 1.06; acc: 0.64
Batch: 780; loss: 0.94; acc: 0.67
Train Epoch over. train_loss: 0.98; train_accuracy: 0.69 

2.1709638531319797e-05
5.085649718239438e-06
Batch: 0; loss: 0.79; acc: 0.7
Batch: 20; loss: 1.29; acc: 0.53
Batch: 40; loss: 0.78; acc: 0.73
Batch: 60; loss: 0.9; acc: 0.72
Batch: 80; loss: 0.93; acc: 0.73
Batch: 100; loss: 0.93; acc: 0.72
Batch: 120; loss: 1.22; acc: 0.7
Batch: 140; loss: 0.67; acc: 0.77
Val Epoch over. val_loss: 0.951771893319051; val_accuracy: 0.693172770700637 

The current subspace-distance is: 5.085649718239438e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 1.05; acc: 0.7
Batch: 40; loss: 1.04; acc: 0.64
Batch: 60; loss: 0.91; acc: 0.73
Batch: 80; loss: 1.22; acc: 0.61
Batch: 100; loss: 1.09; acc: 0.66
Batch: 120; loss: 1.28; acc: 0.56
Batch: 140; loss: 1.13; acc: 0.61
Batch: 160; loss: 1.19; acc: 0.59
Batch: 180; loss: 0.94; acc: 0.69
Batch: 200; loss: 0.85; acc: 0.73
Batch: 220; loss: 1.19; acc: 0.66
Batch: 240; loss: 0.94; acc: 0.72
Batch: 260; loss: 0.99; acc: 0.77
Batch: 280; loss: 1.24; acc: 0.67
Batch: 300; loss: 0.75; acc: 0.78
Batch: 320; loss: 0.83; acc: 0.69
Batch: 340; loss: 0.98; acc: 0.8
Batch: 360; loss: 1.01; acc: 0.67
Batch: 380; loss: 0.79; acc: 0.73
Batch: 400; loss: 0.78; acc: 0.78
Batch: 420; loss: 1.28; acc: 0.66
Batch: 440; loss: 0.98; acc: 0.72
Batch: 460; loss: 0.94; acc: 0.75
Batch: 480; loss: 1.04; acc: 0.64
Batch: 500; loss: 0.82; acc: 0.72
Batch: 520; loss: 1.06; acc: 0.7
Batch: 540; loss: 0.73; acc: 0.77
Batch: 560; loss: 0.8; acc: 0.75
Batch: 580; loss: 1.14; acc: 0.61
Batch: 600; loss: 0.95; acc: 0.7
Batch: 620; loss: 0.94; acc: 0.7
Batch: 640; loss: 0.67; acc: 0.75
Batch: 660; loss: 1.25; acc: 0.61
Batch: 680; loss: 0.9; acc: 0.7
Batch: 700; loss: 0.88; acc: 0.7
Batch: 720; loss: 0.67; acc: 0.75
Batch: 740; loss: 1.21; acc: 0.61
Batch: 760; loss: 0.81; acc: 0.69
Batch: 780; loss: 0.87; acc: 0.73
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

2.384454091952648e-05
5.747022896684939e-06
Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 1.21; acc: 0.59
Batch: 40; loss: 0.72; acc: 0.72
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.89; acc: 0.72
Batch: 100; loss: 0.88; acc: 0.75
Batch: 120; loss: 1.2; acc: 0.69
Batch: 140; loss: 0.6; acc: 0.8
Val Epoch over. val_loss: 0.9126315693946401; val_accuracy: 0.7124800955414012 

The current subspace-distance is: 5.747022896684939e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.98; acc: 0.66
Batch: 20; loss: 1.35; acc: 0.62
Batch: 40; loss: 1.34; acc: 0.58
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 1.02; acc: 0.7
Batch: 120; loss: 1.06; acc: 0.62
Batch: 140; loss: 0.97; acc: 0.7
Batch: 160; loss: 1.15; acc: 0.64
Batch: 180; loss: 0.83; acc: 0.78
Batch: 200; loss: 1.26; acc: 0.62
Batch: 220; loss: 1.05; acc: 0.7
Batch: 240; loss: 1.03; acc: 0.62
Batch: 260; loss: 0.76; acc: 0.72
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.86; acc: 0.73
Batch: 320; loss: 0.9; acc: 0.73
Batch: 340; loss: 1.05; acc: 0.73
Batch: 360; loss: 0.81; acc: 0.72
Batch: 380; loss: 0.94; acc: 0.7
Batch: 400; loss: 0.96; acc: 0.73
Batch: 420; loss: 0.83; acc: 0.75
Batch: 440; loss: 0.91; acc: 0.73
Batch: 460; loss: 1.12; acc: 0.7
Batch: 480; loss: 0.89; acc: 0.69
Batch: 500; loss: 0.78; acc: 0.75
Batch: 520; loss: 0.91; acc: 0.73
Batch: 540; loss: 0.81; acc: 0.78
Batch: 560; loss: 0.84; acc: 0.72
Batch: 580; loss: 0.75; acc: 0.77
Batch: 600; loss: 0.86; acc: 0.67
Batch: 620; loss: 1.03; acc: 0.66
Batch: 640; loss: 1.38; acc: 0.67
Batch: 660; loss: 1.1; acc: 0.69
Batch: 680; loss: 0.94; acc: 0.72
Batch: 700; loss: 0.92; acc: 0.69
Batch: 720; loss: 1.12; acc: 0.67
Batch: 740; loss: 0.99; acc: 0.69
Batch: 760; loss: 1.15; acc: 0.62
Batch: 780; loss: 0.93; acc: 0.7
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

2.336158104299102e-05
5.201593921810854e-06
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 1.25; acc: 0.58
Batch: 40; loss: 0.71; acc: 0.73
Batch: 60; loss: 0.87; acc: 0.72
Batch: 80; loss: 0.87; acc: 0.77
Batch: 100; loss: 0.85; acc: 0.78
Batch: 120; loss: 1.07; acc: 0.73
Batch: 140; loss: 0.58; acc: 0.84
Val Epoch over. val_loss: 0.9085168603119577; val_accuracy: 0.7172571656050956 

The current subspace-distance is: 5.201593921810854e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.78
Batch: 20; loss: 0.94; acc: 0.72
Batch: 40; loss: 1.02; acc: 0.78
Batch: 60; loss: 0.98; acc: 0.69
Batch: 80; loss: 0.86; acc: 0.73
Batch: 100; loss: 1.13; acc: 0.64
Batch: 120; loss: 1.1; acc: 0.75
Batch: 140; loss: 0.63; acc: 0.78
Batch: 160; loss: 0.92; acc: 0.72
Batch: 180; loss: 1.19; acc: 0.66
Batch: 200; loss: 0.82; acc: 0.73
Batch: 220; loss: 1.01; acc: 0.67
Batch: 240; loss: 1.03; acc: 0.7
Batch: 260; loss: 0.91; acc: 0.75
Batch: 280; loss: 0.85; acc: 0.73
Batch: 300; loss: 0.84; acc: 0.8
Batch: 320; loss: 1.13; acc: 0.59
Batch: 340; loss: 1.04; acc: 0.59
Batch: 360; loss: 0.97; acc: 0.73
Batch: 380; loss: 1.33; acc: 0.59
Batch: 400; loss: 1.13; acc: 0.64
Batch: 420; loss: 1.04; acc: 0.62
Batch: 440; loss: 0.96; acc: 0.75
Batch: 460; loss: 0.98; acc: 0.7
Batch: 480; loss: 1.07; acc: 0.73
Batch: 500; loss: 0.96; acc: 0.69
Batch: 520; loss: 1.23; acc: 0.72
Batch: 540; loss: 1.16; acc: 0.61
Batch: 560; loss: 1.17; acc: 0.64
Batch: 580; loss: 1.18; acc: 0.58
Batch: 600; loss: 1.28; acc: 0.66
Batch: 620; loss: 0.92; acc: 0.69
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.95; acc: 0.77
Batch: 680; loss: 0.89; acc: 0.73
Batch: 700; loss: 0.78; acc: 0.77
Batch: 720; loss: 0.93; acc: 0.72
Batch: 740; loss: 0.9; acc: 0.77
Batch: 760; loss: 0.87; acc: 0.7
Batch: 780; loss: 0.76; acc: 0.73
Train Epoch over. train_loss: 0.96; train_accuracy: 0.7 

2.356057484576013e-05
5.1062861530226655e-06
Batch: 0; loss: 0.75; acc: 0.73
Batch: 20; loss: 1.18; acc: 0.62
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.96; acc: 0.7
Batch: 80; loss: 0.89; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 1.17; acc: 0.64
Batch: 140; loss: 0.59; acc: 0.77
Val Epoch over. val_loss: 0.9231341097764908; val_accuracy: 0.7025278662420382 

The current subspace-distance is: 5.1062861530226655e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.2; acc: 0.66
Batch: 20; loss: 1.24; acc: 0.67
Batch: 40; loss: 1.1; acc: 0.56
Batch: 60; loss: 0.92; acc: 0.67
Batch: 80; loss: 0.95; acc: 0.69
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 0.96; acc: 0.7
Batch: 140; loss: 1.01; acc: 0.66
Batch: 160; loss: 0.96; acc: 0.66
Batch: 180; loss: 0.94; acc: 0.7
Batch: 200; loss: 1.11; acc: 0.64
Batch: 220; loss: 0.69; acc: 0.8
Batch: 240; loss: 0.89; acc: 0.72
Batch: 260; loss: 0.82; acc: 0.84
Batch: 280; loss: 0.85; acc: 0.7
Batch: 300; loss: 0.87; acc: 0.7
Batch: 320; loss: 1.18; acc: 0.59
Batch: 340; loss: 0.73; acc: 0.75
Batch: 360; loss: 1.21; acc: 0.7
Batch: 380; loss: 0.89; acc: 0.67
Batch: 400; loss: 0.95; acc: 0.72
Batch: 420; loss: 0.98; acc: 0.73
Batch: 440; loss: 1.0; acc: 0.7
Batch: 460; loss: 0.76; acc: 0.81
Batch: 480; loss: 0.81; acc: 0.72
Batch: 500; loss: 0.98; acc: 0.67
Batch: 520; loss: 0.92; acc: 0.75
Batch: 540; loss: 0.98; acc: 0.7
Batch: 560; loss: 0.89; acc: 0.73
Batch: 580; loss: 1.0; acc: 0.69
Batch: 600; loss: 0.91; acc: 0.72
Batch: 620; loss: 0.79; acc: 0.73
Batch: 640; loss: 0.92; acc: 0.64
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.88; acc: 0.69
Batch: 700; loss: 0.84; acc: 0.75
Batch: 720; loss: 1.12; acc: 0.64
Batch: 740; loss: 0.92; acc: 0.67
Batch: 760; loss: 1.11; acc: 0.61
Batch: 780; loss: 0.8; acc: 0.73
Train Epoch over. train_loss: 0.94; train_accuracy: 0.71 

2.2139147404232062e-05
4.2256251617800444e-06
Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 1.25; acc: 0.64
Batch: 40; loss: 0.79; acc: 0.75
Batch: 60; loss: 0.89; acc: 0.73
Batch: 80; loss: 0.84; acc: 0.72
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.08; acc: 0.72
Batch: 140; loss: 0.52; acc: 0.86
Val Epoch over. val_loss: 0.8923791694413324; val_accuracy: 0.723328025477707 

The current subspace-distance is: 4.2256251617800444e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.96; acc: 0.7
Batch: 20; loss: 0.87; acc: 0.66
Batch: 40; loss: 0.73; acc: 0.78
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 0.95; acc: 0.69
Batch: 100; loss: 0.91; acc: 0.67
Batch: 120; loss: 1.05; acc: 0.72
Batch: 140; loss: 0.82; acc: 0.73
Batch: 160; loss: 0.86; acc: 0.78
Batch: 180; loss: 0.94; acc: 0.69
Batch: 200; loss: 1.14; acc: 0.69
Batch: 220; loss: 0.99; acc: 0.64
Batch: 240; loss: 0.68; acc: 0.8
Batch: 260; loss: 0.8; acc: 0.7
Batch: 280; loss: 0.74; acc: 0.73
Batch: 300; loss: 0.96; acc: 0.75
Batch: 320; loss: 0.85; acc: 0.72
Batch: 340; loss: 0.97; acc: 0.67
Batch: 360; loss: 0.74; acc: 0.78
Batch: 380; loss: 0.98; acc: 0.72
Batch: 400; loss: 0.91; acc: 0.72
Batch: 420; loss: 0.92; acc: 0.72
Batch: 440; loss: 0.97; acc: 0.67
Batch: 460; loss: 0.75; acc: 0.78
Batch: 480; loss: 0.84; acc: 0.69
Batch: 500; loss: 1.11; acc: 0.58
Batch: 520; loss: 0.99; acc: 0.72
Batch: 540; loss: 0.98; acc: 0.66
Batch: 560; loss: 0.91; acc: 0.66
Batch: 580; loss: 1.13; acc: 0.66
Batch: 600; loss: 0.96; acc: 0.66
Batch: 620; loss: 0.92; acc: 0.7
Batch: 640; loss: 1.14; acc: 0.69
Batch: 660; loss: 1.06; acc: 0.66
Batch: 680; loss: 1.19; acc: 0.69
Batch: 700; loss: 0.91; acc: 0.75
Batch: 720; loss: 0.98; acc: 0.7
Batch: 740; loss: 0.95; acc: 0.73
Batch: 760; loss: 1.29; acc: 0.59
Batch: 780; loss: 0.66; acc: 0.8
Train Epoch over. train_loss: 0.94; train_accuracy: 0.71 

2.7278130801278166e-05
4.866575636697235e-06
Batch: 0; loss: 0.64; acc: 0.77
Batch: 20; loss: 1.14; acc: 0.61
Batch: 40; loss: 0.76; acc: 0.75
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.79; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.78
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8809862484218208; val_accuracy: 0.7261146496815286 

The current subspace-distance is: 4.866575636697235e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.85; acc: 0.78
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.89; acc: 0.69
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.92; acc: 0.67
Batch: 100; loss: 1.22; acc: 0.7
Batch: 120; loss: 0.95; acc: 0.72
Batch: 140; loss: 1.13; acc: 0.64
Batch: 160; loss: 1.31; acc: 0.59
Batch: 180; loss: 0.94; acc: 0.67
Batch: 200; loss: 0.99; acc: 0.62
Batch: 220; loss: 0.7; acc: 0.75
Batch: 240; loss: 1.07; acc: 0.67
Batch: 260; loss: 1.4; acc: 0.64
Batch: 280; loss: 1.15; acc: 0.67
Batch: 300; loss: 0.67; acc: 0.77
Batch: 320; loss: 0.96; acc: 0.67
Batch: 340; loss: 1.09; acc: 0.72
Batch: 360; loss: 0.99; acc: 0.72
Batch: 380; loss: 1.08; acc: 0.66
Batch: 400; loss: 0.99; acc: 0.72
Batch: 420; loss: 1.13; acc: 0.69
Batch: 440; loss: 0.97; acc: 0.69
Batch: 460; loss: 0.96; acc: 0.66
Batch: 480; loss: 0.97; acc: 0.77
Batch: 500; loss: 1.24; acc: 0.62
Batch: 520; loss: 0.87; acc: 0.69
Batch: 540; loss: 0.86; acc: 0.72
Batch: 560; loss: 1.01; acc: 0.72
Batch: 580; loss: 1.12; acc: 0.69
Batch: 600; loss: 0.65; acc: 0.78
Batch: 620; loss: 1.0; acc: 0.7
Batch: 640; loss: 1.02; acc: 0.73
Batch: 660; loss: 0.73; acc: 0.78
Batch: 680; loss: 0.86; acc: 0.77
Batch: 700; loss: 0.92; acc: 0.77
Batch: 720; loss: 0.84; acc: 0.73
Batch: 740; loss: 0.97; acc: 0.75
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 1.13; acc: 0.64
Train Epoch over. train_loss: 0.93; train_accuracy: 0.71 

2.4218534235842526e-05
5.1354491006350145e-06
Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 1.16; acc: 0.66
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 0.88; acc: 0.77
Batch: 80; loss: 0.79; acc: 0.69
Batch: 100; loss: 0.92; acc: 0.77
Batch: 120; loss: 1.08; acc: 0.72
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8703972226495196; val_accuracy: 0.7329816878980892 

The current subspace-distance is: 5.1354491006350145e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.96; acc: 0.7
Batch: 20; loss: 0.88; acc: 0.7
Batch: 40; loss: 0.65; acc: 0.8
Batch: 60; loss: 1.03; acc: 0.77
Batch: 80; loss: 0.94; acc: 0.7
Batch: 100; loss: 1.09; acc: 0.67
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 1.09; acc: 0.64
Batch: 160; loss: 1.03; acc: 0.67
Batch: 180; loss: 1.02; acc: 0.62
Batch: 200; loss: 1.32; acc: 0.59
Batch: 220; loss: 1.07; acc: 0.66
Batch: 240; loss: 1.01; acc: 0.66
Batch: 260; loss: 1.12; acc: 0.64
Batch: 280; loss: 0.9; acc: 0.75
Batch: 300; loss: 1.16; acc: 0.62
Batch: 320; loss: 0.99; acc: 0.61
Batch: 340; loss: 0.7; acc: 0.8
Batch: 360; loss: 0.93; acc: 0.73
Batch: 380; loss: 1.05; acc: 0.67
Batch: 400; loss: 1.35; acc: 0.55
Batch: 420; loss: 0.87; acc: 0.77
Batch: 440; loss: 1.05; acc: 0.72
Batch: 460; loss: 1.02; acc: 0.67
Batch: 480; loss: 0.98; acc: 0.73
Batch: 500; loss: 0.89; acc: 0.75
Batch: 520; loss: 0.94; acc: 0.73
Batch: 540; loss: 0.81; acc: 0.72
Batch: 560; loss: 0.77; acc: 0.8
Batch: 580; loss: 0.9; acc: 0.77
Batch: 600; loss: 0.86; acc: 0.7
Batch: 620; loss: 1.04; acc: 0.69
Batch: 640; loss: 1.17; acc: 0.59
Batch: 660; loss: 0.72; acc: 0.78
Batch: 680; loss: 0.85; acc: 0.75
Batch: 700; loss: 0.7; acc: 0.73
Batch: 720; loss: 0.76; acc: 0.78
Batch: 740; loss: 1.07; acc: 0.61
Batch: 760; loss: 1.03; acc: 0.78
Batch: 780; loss: 1.08; acc: 0.69
Train Epoch over. train_loss: 0.93; train_accuracy: 0.71 

2.359673635510262e-05
5.7583001762395725e-06
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 1.1; acc: 0.67
Batch: 40; loss: 0.77; acc: 0.77
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.77; acc: 0.72
Batch: 100; loss: 0.89; acc: 0.75
Batch: 120; loss: 1.1; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.8
Val Epoch over. val_loss: 0.8733402893042109; val_accuracy: 0.7306926751592356 

The current subspace-distance is: 5.7583001762395725e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.8; acc: 0.72
Batch: 20; loss: 1.03; acc: 0.67
Batch: 40; loss: 0.88; acc: 0.8
Batch: 60; loss: 0.96; acc: 0.7
Batch: 80; loss: 0.96; acc: 0.7
Batch: 100; loss: 0.86; acc: 0.73
Batch: 120; loss: 0.86; acc: 0.72
Batch: 140; loss: 0.71; acc: 0.81
Batch: 160; loss: 0.97; acc: 0.7
Batch: 180; loss: 0.97; acc: 0.61
Batch: 200; loss: 1.06; acc: 0.67
Batch: 220; loss: 0.79; acc: 0.83
Batch: 240; loss: 0.85; acc: 0.75
Batch: 260; loss: 0.88; acc: 0.7
Batch: 280; loss: 0.97; acc: 0.7
Batch: 300; loss: 0.87; acc: 0.77
Batch: 320; loss: 1.16; acc: 0.58
Batch: 340; loss: 0.75; acc: 0.8
Batch: 360; loss: 0.7; acc: 0.75
Batch: 380; loss: 1.03; acc: 0.66
Batch: 400; loss: 0.99; acc: 0.66
Batch: 420; loss: 0.94; acc: 0.69
Batch: 440; loss: 1.1; acc: 0.67
Batch: 460; loss: 0.9; acc: 0.72
Batch: 480; loss: 0.94; acc: 0.72
Batch: 500; loss: 0.62; acc: 0.8
Batch: 520; loss: 0.91; acc: 0.69
Batch: 540; loss: 1.09; acc: 0.59
Batch: 560; loss: 0.79; acc: 0.75
Batch: 580; loss: 1.04; acc: 0.67
Batch: 600; loss: 0.97; acc: 0.73
Batch: 620; loss: 1.19; acc: 0.61
Batch: 640; loss: 0.89; acc: 0.73
Batch: 660; loss: 0.77; acc: 0.78
Batch: 680; loss: 1.03; acc: 0.67
Batch: 700; loss: 0.96; acc: 0.7
Batch: 720; loss: 1.02; acc: 0.66
Batch: 740; loss: 0.88; acc: 0.7
Batch: 760; loss: 0.91; acc: 0.73
Batch: 780; loss: 0.94; acc: 0.69
Train Epoch over. train_loss: 0.92; train_accuracy: 0.72 

2.2591548258787952e-05
5.752325705543626e-06
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 1.15; acc: 0.64
Batch: 40; loss: 0.79; acc: 0.8
Batch: 60; loss: 0.89; acc: 0.78
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.07; acc: 0.69
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.8701221743586717; val_accuracy: 0.7327826433121019 

The current subspace-distance is: 5.752325705543626e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.89; acc: 0.7
Batch: 20; loss: 1.26; acc: 0.66
Batch: 40; loss: 0.85; acc: 0.8
Batch: 60; loss: 1.04; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.72
Batch: 100; loss: 1.15; acc: 0.69
Batch: 120; loss: 1.03; acc: 0.67
Batch: 140; loss: 0.76; acc: 0.77
Batch: 160; loss: 1.32; acc: 0.61
Batch: 180; loss: 0.97; acc: 0.7
Batch: 200; loss: 1.05; acc: 0.7
Batch: 220; loss: 0.96; acc: 0.7
Batch: 240; loss: 1.13; acc: 0.62
Batch: 260; loss: 0.93; acc: 0.67
Batch: 280; loss: 1.12; acc: 0.7
Batch: 300; loss: 1.01; acc: 0.7
Batch: 320; loss: 1.0; acc: 0.78
Batch: 340; loss: 1.05; acc: 0.75
Batch: 360; loss: 0.73; acc: 0.8
Batch: 380; loss: 0.94; acc: 0.73
Batch: 400; loss: 0.91; acc: 0.8
Batch: 420; loss: 0.9; acc: 0.73
Batch: 440; loss: 1.01; acc: 0.66
Batch: 460; loss: 0.59; acc: 0.8
Batch: 480; loss: 0.88; acc: 0.7
Batch: 500; loss: 0.91; acc: 0.62
Batch: 520; loss: 1.09; acc: 0.67
Batch: 540; loss: 1.09; acc: 0.7
Batch: 560; loss: 0.76; acc: 0.73
Batch: 580; loss: 0.72; acc: 0.75
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 0.95; acc: 0.72
Batch: 640; loss: 0.91; acc: 0.69
Batch: 660; loss: 1.11; acc: 0.69
Batch: 680; loss: 0.77; acc: 0.73
Batch: 700; loss: 0.75; acc: 0.83
Batch: 720; loss: 0.93; acc: 0.73
Batch: 740; loss: 0.97; acc: 0.7
Batch: 760; loss: 0.82; acc: 0.73
Batch: 780; loss: 0.7; acc: 0.75
Train Epoch over. train_loss: 0.92; train_accuracy: 0.72 

2.237254193460103e-05
5.216846602706937e-06
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 1.09; acc: 0.69
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 0.84; acc: 0.77
Batch: 80; loss: 0.76; acc: 0.72
Batch: 100; loss: 0.93; acc: 0.73
Batch: 120; loss: 1.07; acc: 0.69
Batch: 140; loss: 0.52; acc: 0.81
Val Epoch over. val_loss: 0.8731297520315571; val_accuracy: 0.7334792993630573 

The current subspace-distance is: 5.216846602706937e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.18; acc: 0.67
Batch: 20; loss: 0.84; acc: 0.7
Batch: 40; loss: 0.85; acc: 0.7
Batch: 60; loss: 1.04; acc: 0.67
Batch: 80; loss: 1.0; acc: 0.7
Batch: 100; loss: 1.12; acc: 0.73
Batch: 120; loss: 0.79; acc: 0.7
Batch: 140; loss: 1.18; acc: 0.62
Batch: 160; loss: 0.73; acc: 0.73
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.97; acc: 0.69
Batch: 220; loss: 1.06; acc: 0.72
Batch: 240; loss: 0.86; acc: 0.73
Batch: 260; loss: 0.77; acc: 0.73
Batch: 280; loss: 0.92; acc: 0.66
Batch: 300; loss: 0.74; acc: 0.67
Batch: 320; loss: 0.94; acc: 0.72
Batch: 340; loss: 0.82; acc: 0.77
Batch: 360; loss: 1.13; acc: 0.72
Batch: 380; loss: 0.91; acc: 0.73
Batch: 400; loss: 0.84; acc: 0.73
Batch: 420; loss: 0.66; acc: 0.8
Batch: 440; loss: 0.78; acc: 0.72
Batch: 460; loss: 0.84; acc: 0.69
Batch: 480; loss: 0.95; acc: 0.7
Batch: 500; loss: 1.12; acc: 0.7
Batch: 520; loss: 0.97; acc: 0.67
Batch: 540; loss: 0.86; acc: 0.72
Batch: 560; loss: 0.86; acc: 0.7
Batch: 580; loss: 0.99; acc: 0.67
Batch: 600; loss: 1.03; acc: 0.73
Batch: 620; loss: 0.9; acc: 0.72
Batch: 640; loss: 0.96; acc: 0.75
Batch: 660; loss: 1.05; acc: 0.72
Batch: 680; loss: 1.02; acc: 0.69
Batch: 700; loss: 0.79; acc: 0.75
Batch: 720; loss: 1.19; acc: 0.66
Batch: 740; loss: 0.96; acc: 0.75
Batch: 760; loss: 1.25; acc: 0.59
Batch: 780; loss: 0.91; acc: 0.72
Train Epoch over. train_loss: 0.92; train_accuracy: 0.72 

2.470723120495677e-05
5.711055109713925e-06
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 1.1; acc: 0.64
Batch: 40; loss: 0.8; acc: 0.75
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.75; acc: 0.73
Batch: 100; loss: 0.96; acc: 0.78
Batch: 120; loss: 1.04; acc: 0.69
Batch: 140; loss: 0.48; acc: 0.83
Val Epoch over. val_loss: 0.8565155613194605; val_accuracy: 0.7392515923566879 

The current subspace-distance is: 5.711055109713925e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.87; acc: 0.69
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 0.95; acc: 0.66
Batch: 80; loss: 0.68; acc: 0.77
Batch: 100; loss: 1.16; acc: 0.62
Batch: 120; loss: 0.79; acc: 0.83
Batch: 140; loss: 0.89; acc: 0.75
Batch: 160; loss: 0.79; acc: 0.8
Batch: 180; loss: 0.85; acc: 0.75
Batch: 200; loss: 0.83; acc: 0.77
Batch: 220; loss: 1.04; acc: 0.67
Batch: 240; loss: 0.97; acc: 0.66
Batch: 260; loss: 1.13; acc: 0.66
Batch: 280; loss: 0.86; acc: 0.73
Batch: 300; loss: 0.92; acc: 0.77
Batch: 320; loss: 1.12; acc: 0.67
Batch: 340; loss: 1.35; acc: 0.64
Batch: 360; loss: 0.86; acc: 0.69
Batch: 380; loss: 0.84; acc: 0.77
Batch: 400; loss: 1.28; acc: 0.67
Batch: 420; loss: 1.1; acc: 0.67
Batch: 440; loss: 0.84; acc: 0.75
Batch: 460; loss: 0.81; acc: 0.75
Batch: 480; loss: 1.39; acc: 0.62
Batch: 500; loss: 0.84; acc: 0.72
Batch: 520; loss: 0.94; acc: 0.72
Batch: 540; loss: 0.82; acc: 0.77
Batch: 560; loss: 0.68; acc: 0.77
Batch: 580; loss: 0.75; acc: 0.72
Batch: 600; loss: 0.85; acc: 0.72
Batch: 620; loss: 0.68; acc: 0.77
Batch: 640; loss: 0.88; acc: 0.75
Batch: 660; loss: 0.89; acc: 0.7
Batch: 680; loss: 0.87; acc: 0.7
Batch: 700; loss: 1.28; acc: 0.64
Batch: 720; loss: 1.02; acc: 0.72
Batch: 740; loss: 0.99; acc: 0.75
Batch: 760; loss: 1.02; acc: 0.64
Batch: 780; loss: 0.69; acc: 0.77
Train Epoch over. train_loss: 0.91; train_accuracy: 0.72 

2.2720367269357666e-05
4.811971848539542e-06
Batch: 0; loss: 0.69; acc: 0.75
Batch: 20; loss: 1.07; acc: 0.69
Batch: 40; loss: 0.8; acc: 0.81
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.73
Batch: 100; loss: 0.97; acc: 0.77
Batch: 120; loss: 1.02; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.81
Val Epoch over. val_loss: 0.8508979186510585; val_accuracy: 0.7444267515923567 

The current subspace-distance is: 4.811971848539542e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.82; acc: 0.73
Batch: 20; loss: 0.69; acc: 0.8
Batch: 40; loss: 0.9; acc: 0.75
Batch: 60; loss: 0.61; acc: 0.8
Batch: 80; loss: 1.08; acc: 0.64
Batch: 100; loss: 0.76; acc: 0.75
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 1.15; acc: 0.62
Batch: 160; loss: 0.96; acc: 0.7
Batch: 180; loss: 1.28; acc: 0.56
Batch: 200; loss: 0.9; acc: 0.69
Batch: 220; loss: 0.85; acc: 0.7
Batch: 240; loss: 0.82; acc: 0.75
Batch: 260; loss: 0.82; acc: 0.77
Batch: 280; loss: 0.64; acc: 0.75
Batch: 300; loss: 0.76; acc: 0.77
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.89; acc: 0.73
Batch: 360; loss: 1.56; acc: 0.67
Batch: 380; loss: 1.24; acc: 0.61
Batch: 400; loss: 1.21; acc: 0.62
Batch: 420; loss: 1.03; acc: 0.67
Batch: 440; loss: 1.09; acc: 0.7
Batch: 460; loss: 0.9; acc: 0.72
Batch: 480; loss: 1.16; acc: 0.64
Batch: 500; loss: 0.94; acc: 0.75
Batch: 520; loss: 0.87; acc: 0.7
Batch: 540; loss: 0.92; acc: 0.67
Batch: 560; loss: 0.96; acc: 0.72
Batch: 580; loss: 0.76; acc: 0.73
Batch: 600; loss: 0.78; acc: 0.73
Batch: 620; loss: 0.88; acc: 0.7
Batch: 640; loss: 0.8; acc: 0.75
Batch: 660; loss: 0.81; acc: 0.73
Batch: 680; loss: 0.64; acc: 0.84
Batch: 700; loss: 0.83; acc: 0.77
Batch: 720; loss: 0.98; acc: 0.75
Batch: 740; loss: 0.81; acc: 0.73
Batch: 760; loss: 0.78; acc: 0.69
Batch: 780; loss: 0.96; acc: 0.69
Train Epoch over. train_loss: 0.9; train_accuracy: 0.72 

2.4066714104264975e-05
5.4848769650561735e-06
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 1.06; acc: 0.7
Batch: 40; loss: 0.8; acc: 0.8
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.73; acc: 0.75
Batch: 100; loss: 0.94; acc: 0.78
Batch: 120; loss: 1.03; acc: 0.72
Batch: 140; loss: 0.53; acc: 0.78
Val Epoch over. val_loss: 0.8488159536556074; val_accuracy: 0.7461186305732485 

The current subspace-distance is: 5.4848769650561735e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.61; acc: 0.77
Batch: 40; loss: 0.9; acc: 0.67
Batch: 60; loss: 1.0; acc: 0.67
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.84; acc: 0.78
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.76; acc: 0.73
Batch: 160; loss: 1.13; acc: 0.64
Batch: 180; loss: 0.89; acc: 0.73
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 0.85; acc: 0.77
Batch: 240; loss: 1.03; acc: 0.67
Batch: 260; loss: 1.02; acc: 0.83
Batch: 280; loss: 0.74; acc: 0.78
Batch: 300; loss: 0.91; acc: 0.69
Batch: 320; loss: 0.97; acc: 0.67
Batch: 340; loss: 0.93; acc: 0.8
Batch: 360; loss: 0.78; acc: 0.83
Batch: 380; loss: 0.96; acc: 0.72
Batch: 400; loss: 0.98; acc: 0.73
Batch: 420; loss: 1.15; acc: 0.64
Batch: 440; loss: 1.05; acc: 0.61
Batch: 460; loss: 0.96; acc: 0.7
Batch: 480; loss: 1.24; acc: 0.59
Batch: 500; loss: 0.8; acc: 0.77
Batch: 520; loss: 0.76; acc: 0.81
Batch: 540; loss: 0.86; acc: 0.8
Batch: 560; loss: 0.69; acc: 0.84
Batch: 580; loss: 0.86; acc: 0.7
Batch: 600; loss: 0.73; acc: 0.81
Batch: 620; loss: 1.18; acc: 0.62
Batch: 640; loss: 1.04; acc: 0.69
Batch: 660; loss: 0.91; acc: 0.72
Batch: 680; loss: 1.13; acc: 0.69
Batch: 700; loss: 0.97; acc: 0.67
Batch: 720; loss: 0.95; acc: 0.72
Batch: 740; loss: 1.02; acc: 0.73
Batch: 760; loss: 1.02; acc: 0.66
Batch: 780; loss: 0.84; acc: 0.69
Train Epoch over. train_loss: 0.9; train_accuracy: 0.73 

2.3625301764695905e-05
5.189688636164647e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 1.05; acc: 0.7
Batch: 40; loss: 0.81; acc: 0.77
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 0.98; acc: 0.75
Batch: 120; loss: 1.05; acc: 0.66
Batch: 140; loss: 0.48; acc: 0.91
Val Epoch over. val_loss: 0.8443345968510695; val_accuracy: 0.7434315286624203 

The current subspace-distance is: 5.189688636164647e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.1; acc: 0.62
Batch: 20; loss: 0.8; acc: 0.78
Batch: 40; loss: 0.93; acc: 0.72
Batch: 60; loss: 1.15; acc: 0.66
Batch: 80; loss: 0.79; acc: 0.7
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 1.05; acc: 0.7
Batch: 140; loss: 0.85; acc: 0.77
Batch: 160; loss: 0.83; acc: 0.73
Batch: 180; loss: 1.08; acc: 0.73
Batch: 200; loss: 0.98; acc: 0.59
Batch: 220; loss: 0.87; acc: 0.78
Batch: 240; loss: 0.72; acc: 0.77
Batch: 260; loss: 1.06; acc: 0.72
Batch: 280; loss: 0.72; acc: 0.72
Batch: 300; loss: 0.63; acc: 0.81
Batch: 320; loss: 0.89; acc: 0.73
Batch: 340; loss: 0.56; acc: 0.78
Batch: 360; loss: 0.99; acc: 0.72
Batch: 380; loss: 1.04; acc: 0.67
Batch: 400; loss: 0.72; acc: 0.78
Batch: 420; loss: 0.93; acc: 0.77
Batch: 440; loss: 0.84; acc: 0.69
Batch: 460; loss: 0.81; acc: 0.8
Batch: 480; loss: 0.93; acc: 0.73
Batch: 500; loss: 0.87; acc: 0.75
Batch: 520; loss: 0.99; acc: 0.69
Batch: 540; loss: 0.8; acc: 0.77
Batch: 560; loss: 0.61; acc: 0.8
Batch: 580; loss: 0.88; acc: 0.7
Batch: 600; loss: 0.68; acc: 0.8
Batch: 620; loss: 0.87; acc: 0.77
Batch: 640; loss: 0.98; acc: 0.73
Batch: 660; loss: 0.73; acc: 0.77
Batch: 680; loss: 1.01; acc: 0.73
Batch: 700; loss: 0.87; acc: 0.73
Batch: 720; loss: 0.93; acc: 0.7
Batch: 740; loss: 0.79; acc: 0.78
Batch: 760; loss: 1.23; acc: 0.62
Batch: 780; loss: 1.15; acc: 0.62
Train Epoch over. train_loss: 0.89; train_accuracy: 0.73 

2.2799131329520606e-05
6.206941634445684e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.67
Batch: 40; loss: 0.81; acc: 0.8
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.72; acc: 0.75
Batch: 100; loss: 0.92; acc: 0.8
Batch: 120; loss: 0.99; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.83
Val Epoch over. val_loss: 0.8408852502418931; val_accuracy: 0.7474124203821656 

The current subspace-distance is: 6.206941634445684e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.98; acc: 0.69
Batch: 20; loss: 1.01; acc: 0.69
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.96; acc: 0.7
Batch: 100; loss: 0.97; acc: 0.67
Batch: 120; loss: 0.92; acc: 0.75
Batch: 140; loss: 0.89; acc: 0.73
Batch: 160; loss: 0.77; acc: 0.77
Batch: 180; loss: 0.98; acc: 0.7
Batch: 200; loss: 0.94; acc: 0.72
Batch: 220; loss: 0.96; acc: 0.69
Batch: 240; loss: 0.98; acc: 0.72
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.84; acc: 0.66
Batch: 300; loss: 0.65; acc: 0.81
Batch: 320; loss: 0.99; acc: 0.73
Batch: 340; loss: 0.84; acc: 0.75
Batch: 360; loss: 1.07; acc: 0.64
Batch: 380; loss: 1.13; acc: 0.73
Batch: 400; loss: 0.88; acc: 0.77
Batch: 420; loss: 0.73; acc: 0.78
Batch: 440; loss: 0.84; acc: 0.72
Batch: 460; loss: 0.68; acc: 0.75
Batch: 480; loss: 0.95; acc: 0.72
Batch: 500; loss: 0.84; acc: 0.7
Batch: 520; loss: 0.88; acc: 0.72
Batch: 540; loss: 0.9; acc: 0.77
Batch: 560; loss: 0.74; acc: 0.77
Batch: 580; loss: 1.02; acc: 0.7
Batch: 600; loss: 0.9; acc: 0.78
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.97; acc: 0.62
Batch: 660; loss: 0.77; acc: 0.8
Batch: 680; loss: 1.11; acc: 0.78
Batch: 700; loss: 1.06; acc: 0.64
Batch: 720; loss: 0.81; acc: 0.77
Batch: 740; loss: 0.71; acc: 0.73
Batch: 760; loss: 0.99; acc: 0.69
Batch: 780; loss: 0.75; acc: 0.75
Train Epoch over. train_loss: 0.89; train_accuracy: 0.73 

2.357025005039759e-05
4.929958777211141e-06
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 1.02; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.78
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.88; acc: 0.81
Batch: 120; loss: 1.01; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.81
Val Epoch over. val_loss: 0.8364322618314415; val_accuracy: 0.7483081210191083 

The current subspace-distance is: 4.929958777211141e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.94; acc: 0.69
Batch: 40; loss: 0.64; acc: 0.77
Batch: 60; loss: 1.16; acc: 0.66
Batch: 80; loss: 1.13; acc: 0.64
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 1.01; acc: 0.7
Batch: 140; loss: 0.88; acc: 0.67
Batch: 160; loss: 0.8; acc: 0.81
Batch: 180; loss: 0.85; acc: 0.73
Batch: 200; loss: 1.19; acc: 0.66
Batch: 220; loss: 1.22; acc: 0.69
Batch: 240; loss: 1.1; acc: 0.64
Batch: 260; loss: 0.8; acc: 0.72
Batch: 280; loss: 0.89; acc: 0.73
Batch: 300; loss: 0.68; acc: 0.77
Batch: 320; loss: 0.84; acc: 0.73
Batch: 340; loss: 1.08; acc: 0.75
Batch: 360; loss: 0.87; acc: 0.73
Batch: 380; loss: 0.86; acc: 0.75
Batch: 400; loss: 0.92; acc: 0.67
Batch: 420; loss: 0.91; acc: 0.72
Batch: 440; loss: 0.99; acc: 0.83
Batch: 460; loss: 0.92; acc: 0.7
Batch: 480; loss: 1.01; acc: 0.69
Batch: 500; loss: 0.97; acc: 0.73
Batch: 520; loss: 1.01; acc: 0.69
Batch: 540; loss: 0.81; acc: 0.73
Batch: 560; loss: 0.87; acc: 0.77
Batch: 580; loss: 1.0; acc: 0.72
Batch: 600; loss: 0.91; acc: 0.72
Batch: 620; loss: 0.86; acc: 0.75
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 1.0; acc: 0.66
Batch: 680; loss: 0.69; acc: 0.81
Batch: 700; loss: 0.96; acc: 0.64
Batch: 720; loss: 0.83; acc: 0.77
Batch: 740; loss: 1.02; acc: 0.75
Batch: 760; loss: 0.76; acc: 0.75
Batch: 780; loss: 0.49; acc: 0.89
Train Epoch over. train_loss: 0.89; train_accuracy: 0.73 

2.3870214135968126e-05
6.199039034981979e-06
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 1.0; acc: 0.7
Batch: 40; loss: 0.8; acc: 0.8
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.87; acc: 0.8
Batch: 120; loss: 1.01; acc: 0.7
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.8303649304019418; val_accuracy: 0.7495023885350318 

The current subspace-distance is: 6.199039034981979e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.86; acc: 0.69
Batch: 20; loss: 0.63; acc: 0.83
Batch: 40; loss: 1.07; acc: 0.66
Batch: 60; loss: 0.79; acc: 0.75
Batch: 80; loss: 1.03; acc: 0.75
Batch: 100; loss: 1.08; acc: 0.69
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 1.28; acc: 0.64
Batch: 160; loss: 0.8; acc: 0.69
Batch: 180; loss: 0.83; acc: 0.72
Batch: 200; loss: 0.8; acc: 0.75
Batch: 220; loss: 0.59; acc: 0.78
Batch: 240; loss: 0.74; acc: 0.8
Batch: 260; loss: 0.99; acc: 0.69
Batch: 280; loss: 1.32; acc: 0.62
Batch: 300; loss: 0.93; acc: 0.67
Batch: 320; loss: 0.85; acc: 0.73
Batch: 340; loss: 0.86; acc: 0.78
Batch: 360; loss: 0.88; acc: 0.78
Batch: 380; loss: 0.65; acc: 0.8
Batch: 400; loss: 0.94; acc: 0.67
Batch: 420; loss: 1.08; acc: 0.67
Batch: 440; loss: 0.81; acc: 0.69
Batch: 460; loss: 0.83; acc: 0.77
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.8; acc: 0.69
Batch: 520; loss: 0.95; acc: 0.69
Batch: 540; loss: 1.22; acc: 0.62
Batch: 560; loss: 0.73; acc: 0.77
Batch: 580; loss: 0.95; acc: 0.66
Batch: 600; loss: 0.76; acc: 0.73
Batch: 620; loss: 0.78; acc: 0.78
Batch: 640; loss: 0.88; acc: 0.72
Batch: 660; loss: 1.02; acc: 0.7
Batch: 680; loss: 1.12; acc: 0.64
Batch: 700; loss: 0.81; acc: 0.72
Batch: 720; loss: 1.0; acc: 0.7
Batch: 740; loss: 0.76; acc: 0.8
Batch: 760; loss: 0.84; acc: 0.73
Batch: 780; loss: 0.65; acc: 0.78
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.1958961951895617e-05
4.915855697618099e-06
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 0.99; acc: 0.7
Batch: 40; loss: 0.81; acc: 0.77
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.87; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.8281251573638552; val_accuracy: 0.7517914012738853 

The current subspace-distance is: 4.915855697618099e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.81; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 1.27; acc: 0.66
Batch: 60; loss: 0.82; acc: 0.78
Batch: 80; loss: 0.77; acc: 0.83
Batch: 100; loss: 0.8; acc: 0.75
Batch: 120; loss: 0.94; acc: 0.7
Batch: 140; loss: 0.79; acc: 0.73
Batch: 160; loss: 0.78; acc: 0.78
Batch: 180; loss: 0.6; acc: 0.77
Batch: 200; loss: 1.21; acc: 0.67
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 0.77; acc: 0.75
Batch: 260; loss: 0.67; acc: 0.75
Batch: 280; loss: 1.01; acc: 0.69
Batch: 300; loss: 0.55; acc: 0.81
Batch: 320; loss: 0.91; acc: 0.77
Batch: 340; loss: 0.91; acc: 0.7
Batch: 360; loss: 0.8; acc: 0.78
Batch: 380; loss: 1.04; acc: 0.73
Batch: 400; loss: 0.76; acc: 0.72
Batch: 420; loss: 0.83; acc: 0.75
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.96; acc: 0.72
Batch: 480; loss: 0.94; acc: 0.64
Batch: 500; loss: 0.94; acc: 0.77
Batch: 520; loss: 0.81; acc: 0.78
Batch: 540; loss: 0.98; acc: 0.77
Batch: 560; loss: 0.89; acc: 0.72
Batch: 580; loss: 1.18; acc: 0.73
Batch: 600; loss: 0.94; acc: 0.72
Batch: 620; loss: 0.77; acc: 0.8
Batch: 640; loss: 0.7; acc: 0.77
Batch: 660; loss: 0.91; acc: 0.73
Batch: 680; loss: 0.85; acc: 0.77
Batch: 700; loss: 0.65; acc: 0.84
Batch: 720; loss: 0.92; acc: 0.75
Batch: 740; loss: 0.85; acc: 0.7
Batch: 760; loss: 0.95; acc: 0.73
Batch: 780; loss: 0.71; acc: 0.78
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.3764887373545207e-05
5.803068688692292e-06
Batch: 0; loss: 0.75; acc: 0.73
Batch: 20; loss: 0.98; acc: 0.69
Batch: 40; loss: 0.8; acc: 0.73
Batch: 60; loss: 0.79; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.84; acc: 0.81
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.8343986956177244; val_accuracy: 0.7476114649681529 

The current subspace-distance is: 5.803068688692292e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.84; acc: 0.75
Batch: 20; loss: 1.07; acc: 0.73
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 1.12; acc: 0.67
Batch: 80; loss: 0.94; acc: 0.73
Batch: 100; loss: 1.07; acc: 0.64
Batch: 120; loss: 0.95; acc: 0.72
Batch: 140; loss: 0.87; acc: 0.69
Batch: 160; loss: 0.86; acc: 0.69
Batch: 180; loss: 1.0; acc: 0.66
Batch: 200; loss: 0.92; acc: 0.7
Batch: 220; loss: 0.73; acc: 0.77
Batch: 240; loss: 0.64; acc: 0.81
Batch: 260; loss: 1.05; acc: 0.64
Batch: 280; loss: 0.61; acc: 0.81
Batch: 300; loss: 0.74; acc: 0.81
Batch: 320; loss: 0.8; acc: 0.78
Batch: 340; loss: 0.63; acc: 0.81
Batch: 360; loss: 0.56; acc: 0.83
Batch: 380; loss: 1.0; acc: 0.69
Batch: 400; loss: 0.68; acc: 0.72
Batch: 420; loss: 0.55; acc: 0.88
Batch: 440; loss: 0.96; acc: 0.69
Batch: 460; loss: 0.96; acc: 0.69
Batch: 480; loss: 0.96; acc: 0.73
Batch: 500; loss: 0.89; acc: 0.67
Batch: 520; loss: 0.82; acc: 0.72
Batch: 540; loss: 0.95; acc: 0.67
Batch: 560; loss: 0.66; acc: 0.78
Batch: 580; loss: 0.88; acc: 0.75
Batch: 600; loss: 0.86; acc: 0.72
Batch: 620; loss: 0.65; acc: 0.83
Batch: 640; loss: 0.83; acc: 0.67
Batch: 660; loss: 0.8; acc: 0.73
Batch: 680; loss: 0.68; acc: 0.77
Batch: 700; loss: 0.71; acc: 0.78
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 1.16; acc: 0.66
Batch: 760; loss: 0.91; acc: 0.73
Batch: 780; loss: 0.99; acc: 0.64
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.4087288693408482e-05
5.087802037451183e-06
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 0.81; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 0.86; acc: 0.81
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.52; acc: 0.86
Val Epoch over. val_loss: 0.8291650989632697; val_accuracy: 0.74890525477707 

The current subspace-distance is: 5.087802037451183e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.95; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.7
Batch: 40; loss: 0.8; acc: 0.7
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 0.68; acc: 0.77
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.8; acc: 0.7
Batch: 140; loss: 0.78; acc: 0.72
Batch: 160; loss: 1.09; acc: 0.62
Batch: 180; loss: 0.69; acc: 0.78
Batch: 200; loss: 0.98; acc: 0.72
Batch: 220; loss: 1.12; acc: 0.67
Batch: 240; loss: 0.97; acc: 0.78
Batch: 260; loss: 0.67; acc: 0.8
Batch: 280; loss: 0.87; acc: 0.67
Batch: 300; loss: 0.82; acc: 0.77
Batch: 320; loss: 0.75; acc: 0.77
Batch: 340; loss: 0.9; acc: 0.69
Batch: 360; loss: 1.03; acc: 0.7
Batch: 380; loss: 0.58; acc: 0.81
Batch: 400; loss: 0.77; acc: 0.83
Batch: 420; loss: 0.76; acc: 0.77
Batch: 440; loss: 0.87; acc: 0.77
Batch: 460; loss: 0.81; acc: 0.8
Batch: 480; loss: 0.88; acc: 0.67
Batch: 500; loss: 0.71; acc: 0.78
Batch: 520; loss: 1.19; acc: 0.62
Batch: 540; loss: 0.83; acc: 0.72
Batch: 560; loss: 1.1; acc: 0.67
Batch: 580; loss: 0.95; acc: 0.75
Batch: 600; loss: 1.08; acc: 0.7
Batch: 620; loss: 0.91; acc: 0.69
Batch: 640; loss: 0.86; acc: 0.8
Batch: 660; loss: 1.16; acc: 0.7
Batch: 680; loss: 1.33; acc: 0.75
Batch: 700; loss: 1.04; acc: 0.69
Batch: 720; loss: 0.41; acc: 0.83
Batch: 740; loss: 0.8; acc: 0.73
Batch: 760; loss: 0.86; acc: 0.78
Batch: 780; loss: 0.79; acc: 0.77
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.1771124011138454e-05
5.5686241466901265e-06
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.99; acc: 0.72
Batch: 40; loss: 0.81; acc: 0.78
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.75
Batch: 100; loss: 0.85; acc: 0.81
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 0.52; acc: 0.83
Val Epoch over. val_loss: 0.8301472800552465; val_accuracy: 0.748109076433121 

The current subspace-distance is: 5.5686241466901265e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 1.1; acc: 0.67
Batch: 40; loss: 0.87; acc: 0.72
Batch: 60; loss: 0.76; acc: 0.81
Batch: 80; loss: 0.63; acc: 0.83
Batch: 100; loss: 1.09; acc: 0.7
Batch: 120; loss: 0.97; acc: 0.7
Batch: 140; loss: 0.82; acc: 0.72
Batch: 160; loss: 0.76; acc: 0.73
Batch: 180; loss: 0.84; acc: 0.69
Batch: 200; loss: 1.03; acc: 0.64
Batch: 220; loss: 0.96; acc: 0.73
Batch: 240; loss: 0.73; acc: 0.78
Batch: 260; loss: 1.08; acc: 0.64
Batch: 280; loss: 0.75; acc: 0.81
Batch: 300; loss: 0.98; acc: 0.7
Batch: 320; loss: 0.8; acc: 0.7
Batch: 340; loss: 0.92; acc: 0.7
Batch: 360; loss: 0.9; acc: 0.69
Batch: 380; loss: 0.77; acc: 0.77
Batch: 400; loss: 0.71; acc: 0.75
Batch: 420; loss: 0.58; acc: 0.88
Batch: 440; loss: 1.06; acc: 0.61
Batch: 460; loss: 0.84; acc: 0.73
Batch: 480; loss: 0.81; acc: 0.72
Batch: 500; loss: 0.84; acc: 0.69
Batch: 520; loss: 1.01; acc: 0.69
Batch: 540; loss: 0.88; acc: 0.72
Batch: 560; loss: 1.16; acc: 0.64
Batch: 580; loss: 0.91; acc: 0.72
Batch: 600; loss: 0.69; acc: 0.78
Batch: 620; loss: 0.82; acc: 0.81
Batch: 640; loss: 0.86; acc: 0.77
Batch: 660; loss: 0.74; acc: 0.8
Batch: 680; loss: 0.76; acc: 0.75
Batch: 700; loss: 0.91; acc: 0.75
Batch: 720; loss: 0.95; acc: 0.67
Batch: 740; loss: 1.12; acc: 0.69
Batch: 760; loss: 0.88; acc: 0.72
Batch: 780; loss: 0.7; acc: 0.78
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.160101939807646e-05
4.992280082660727e-06
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 0.96; acc: 0.72
Batch: 40; loss: 0.81; acc: 0.78
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.85; acc: 0.81
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.48; acc: 0.88
Val Epoch over. val_loss: 0.8281903760448383; val_accuracy: 0.7479100318471338 

The current subspace-distance is: 4.992280082660727e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.14; acc: 0.7
Batch: 20; loss: 0.81; acc: 0.72
Batch: 40; loss: 0.85; acc: 0.75
Batch: 60; loss: 0.91; acc: 0.72
Batch: 80; loss: 0.71; acc: 0.73
Batch: 100; loss: 1.06; acc: 0.72
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.86; acc: 0.77
Batch: 160; loss: 0.8; acc: 0.77
Batch: 180; loss: 0.79; acc: 0.8
Batch: 200; loss: 1.05; acc: 0.66
Batch: 220; loss: 0.78; acc: 0.7
Batch: 240; loss: 0.67; acc: 0.78
Batch: 260; loss: 1.18; acc: 0.64
Batch: 280; loss: 0.73; acc: 0.83
Batch: 300; loss: 0.74; acc: 0.8
Batch: 320; loss: 0.75; acc: 0.78
Batch: 340; loss: 0.79; acc: 0.81
Batch: 360; loss: 0.93; acc: 0.64
Batch: 380; loss: 1.0; acc: 0.73
Batch: 400; loss: 0.74; acc: 0.73
Batch: 420; loss: 0.83; acc: 0.73
Batch: 440; loss: 1.02; acc: 0.72
Batch: 460; loss: 0.68; acc: 0.84
Batch: 480; loss: 0.89; acc: 0.72
Batch: 500; loss: 0.62; acc: 0.8
Batch: 520; loss: 1.0; acc: 0.67
Batch: 540; loss: 0.82; acc: 0.7
Batch: 560; loss: 0.68; acc: 0.75
Batch: 580; loss: 1.04; acc: 0.75
Batch: 600; loss: 0.98; acc: 0.69
Batch: 620; loss: 1.08; acc: 0.69
Batch: 640; loss: 0.91; acc: 0.73
Batch: 660; loss: 1.12; acc: 0.72
Batch: 680; loss: 0.86; acc: 0.67
Batch: 700; loss: 1.02; acc: 0.66
Batch: 720; loss: 1.05; acc: 0.69
Batch: 740; loss: 0.84; acc: 0.77
Batch: 760; loss: 1.2; acc: 0.61
Batch: 780; loss: 0.81; acc: 0.78
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.398467950115446e-05
5.905188118049409e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.94; acc: 0.73
Batch: 40; loss: 0.79; acc: 0.78
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.82; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 0.48; acc: 0.88
Val Epoch over. val_loss: 0.8222571529780224; val_accuracy: 0.7488057324840764 

The current subspace-distance is: 5.905188118049409e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.07; acc: 0.69
Batch: 20; loss: 0.93; acc: 0.73
Batch: 40; loss: 0.86; acc: 0.78
Batch: 60; loss: 0.72; acc: 0.8
Batch: 80; loss: 0.81; acc: 0.7
Batch: 100; loss: 0.77; acc: 0.78
Batch: 120; loss: 0.83; acc: 0.69
Batch: 140; loss: 1.13; acc: 0.66
Batch: 160; loss: 1.1; acc: 0.72
Batch: 180; loss: 0.88; acc: 0.75
Batch: 200; loss: 0.93; acc: 0.64
Batch: 220; loss: 0.79; acc: 0.77
Batch: 240; loss: 0.78; acc: 0.78
Batch: 260; loss: 0.78; acc: 0.69
Batch: 280; loss: 0.95; acc: 0.66
Batch: 300; loss: 0.76; acc: 0.77
Batch: 320; loss: 0.96; acc: 0.66
Batch: 340; loss: 0.82; acc: 0.73
Batch: 360; loss: 0.92; acc: 0.69
Batch: 380; loss: 0.99; acc: 0.64
Batch: 400; loss: 0.79; acc: 0.77
Batch: 420; loss: 0.94; acc: 0.69
Batch: 440; loss: 0.91; acc: 0.75
Batch: 460; loss: 0.69; acc: 0.77
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.92; acc: 0.66
Batch: 520; loss: 0.84; acc: 0.73
Batch: 540; loss: 0.93; acc: 0.78
Batch: 560; loss: 0.85; acc: 0.81
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 1.03; acc: 0.69
Batch: 620; loss: 1.01; acc: 0.7
Batch: 640; loss: 1.03; acc: 0.72
Batch: 660; loss: 0.92; acc: 0.73
Batch: 680; loss: 0.81; acc: 0.8
Batch: 700; loss: 1.32; acc: 0.69
Batch: 720; loss: 1.05; acc: 0.7
Batch: 740; loss: 0.71; acc: 0.77
Batch: 760; loss: 0.8; acc: 0.78
Batch: 780; loss: 1.01; acc: 0.73
Train Epoch over. train_loss: 0.88; train_accuracy: 0.73 

2.368047717027366e-05
4.871484634350054e-06
Batch: 0; loss: 0.75; acc: 0.7
Batch: 20; loss: 0.94; acc: 0.73
Batch: 40; loss: 0.79; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.82; acc: 0.8
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.8252756493106769; val_accuracy: 0.7467157643312102 

The current subspace-distance is: 4.871484634350054e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.78; acc: 0.73
Batch: 20; loss: 1.18; acc: 0.66
Batch: 40; loss: 0.83; acc: 0.72
Batch: 60; loss: 1.09; acc: 0.69
Batch: 80; loss: 0.83; acc: 0.72
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 0.9; acc: 0.72
Batch: 140; loss: 1.16; acc: 0.61
Batch: 160; loss: 1.09; acc: 0.62
Batch: 180; loss: 0.77; acc: 0.7
Batch: 200; loss: 0.64; acc: 0.8
Batch: 220; loss: 1.08; acc: 0.73
Batch: 240; loss: 0.92; acc: 0.73
Batch: 260; loss: 1.07; acc: 0.67
Batch: 280; loss: 0.88; acc: 0.61
Batch: 300; loss: 0.99; acc: 0.7
Batch: 320; loss: 0.76; acc: 0.83
Batch: 340; loss: 0.84; acc: 0.69
Batch: 360; loss: 1.32; acc: 0.64
Batch: 380; loss: 0.68; acc: 0.73
Batch: 400; loss: 0.94; acc: 0.73
Batch: 420; loss: 0.59; acc: 0.78
Batch: 440; loss: 0.9; acc: 0.77
Batch: 460; loss: 0.8; acc: 0.8
Batch: 480; loss: 0.77; acc: 0.83
Batch: 500; loss: 1.1; acc: 0.67
Batch: 520; loss: 0.99; acc: 0.7
Batch: 540; loss: 1.05; acc: 0.69
Batch: 560; loss: 0.74; acc: 0.78
Batch: 580; loss: 0.62; acc: 0.77
Batch: 600; loss: 0.69; acc: 0.73
Batch: 620; loss: 0.73; acc: 0.86
Batch: 640; loss: 1.02; acc: 0.66
Batch: 660; loss: 0.6; acc: 0.84
Batch: 680; loss: 0.84; acc: 0.73
Batch: 700; loss: 0.91; acc: 0.62
Batch: 720; loss: 0.79; acc: 0.75
Batch: 740; loss: 0.65; acc: 0.78
Batch: 760; loss: 0.71; acc: 0.78
Batch: 780; loss: 0.86; acc: 0.77
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.3518810849054717e-05
5.187048827792751e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 0.75; acc: 0.75
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.8
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8212474607358313; val_accuracy: 0.7517914012738853 

The current subspace-distance is: 5.187048827792751e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.88; acc: 0.77
Batch: 20; loss: 1.03; acc: 0.77
Batch: 40; loss: 1.03; acc: 0.7
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.82; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 0.96; acc: 0.72
Batch: 140; loss: 0.91; acc: 0.73
Batch: 160; loss: 0.83; acc: 0.77
Batch: 180; loss: 0.84; acc: 0.72
Batch: 200; loss: 1.01; acc: 0.64
Batch: 220; loss: 1.04; acc: 0.72
Batch: 240; loss: 0.82; acc: 0.77
Batch: 260; loss: 0.66; acc: 0.77
Batch: 280; loss: 0.74; acc: 0.83
Batch: 300; loss: 0.72; acc: 0.78
Batch: 320; loss: 0.79; acc: 0.78
Batch: 340; loss: 0.75; acc: 0.8
Batch: 360; loss: 1.08; acc: 0.61
Batch: 380; loss: 1.2; acc: 0.69
Batch: 400; loss: 0.91; acc: 0.78
Batch: 420; loss: 0.69; acc: 0.84
Batch: 440; loss: 0.94; acc: 0.72
Batch: 460; loss: 0.75; acc: 0.75
Batch: 480; loss: 0.83; acc: 0.73
Batch: 500; loss: 0.82; acc: 0.73
Batch: 520; loss: 0.83; acc: 0.77
Batch: 540; loss: 1.02; acc: 0.73
Batch: 560; loss: 0.94; acc: 0.72
Batch: 580; loss: 0.99; acc: 0.8
Batch: 600; loss: 1.07; acc: 0.75
Batch: 620; loss: 1.03; acc: 0.67
Batch: 640; loss: 0.92; acc: 0.7
Batch: 660; loss: 1.0; acc: 0.77
Batch: 680; loss: 0.98; acc: 0.77
Batch: 700; loss: 0.71; acc: 0.78
Batch: 720; loss: 1.04; acc: 0.66
Batch: 740; loss: 0.86; acc: 0.72
Batch: 760; loss: 0.73; acc: 0.75
Batch: 780; loss: 0.96; acc: 0.73
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.185084122174885e-05
4.746987997350516e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.92; acc: 0.73
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 0.75; acc: 0.75
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.82; acc: 0.8
Batch: 120; loss: 0.99; acc: 0.66
Batch: 140; loss: 0.48; acc: 0.86
Val Epoch over. val_loss: 0.8204267089533958; val_accuracy: 0.7516918789808917 

The current subspace-distance is: 4.746987997350516e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.1; acc: 0.67
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.93; acc: 0.69
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.9; acc: 0.73
Batch: 100; loss: 0.68; acc: 0.72
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 1.12; acc: 0.59
Batch: 160; loss: 0.64; acc: 0.81
Batch: 180; loss: 0.72; acc: 0.75
Batch: 200; loss: 0.68; acc: 0.81
Batch: 220; loss: 1.11; acc: 0.64
Batch: 240; loss: 1.1; acc: 0.64
Batch: 260; loss: 1.18; acc: 0.66
Batch: 280; loss: 0.79; acc: 0.72
Batch: 300; loss: 0.84; acc: 0.73
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.83; acc: 0.75
Batch: 360; loss: 0.61; acc: 0.83
Batch: 380; loss: 0.91; acc: 0.7
Batch: 400; loss: 0.88; acc: 0.66
Batch: 420; loss: 0.83; acc: 0.73
Batch: 440; loss: 0.9; acc: 0.67
Batch: 460; loss: 0.56; acc: 0.83
Batch: 480; loss: 0.94; acc: 0.73
Batch: 500; loss: 0.69; acc: 0.81
Batch: 520; loss: 0.75; acc: 0.75
Batch: 540; loss: 0.65; acc: 0.8
Batch: 560; loss: 0.9; acc: 0.75
Batch: 580; loss: 0.97; acc: 0.72
Batch: 600; loss: 1.0; acc: 0.75
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.82; acc: 0.75
Batch: 660; loss: 0.92; acc: 0.73
Batch: 680; loss: 0.79; acc: 0.78
Batch: 700; loss: 0.96; acc: 0.75
Batch: 720; loss: 1.03; acc: 0.67
Batch: 740; loss: 0.75; acc: 0.8
Batch: 760; loss: 0.88; acc: 0.72
Batch: 780; loss: 0.94; acc: 0.69
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.316528116352856e-05
6.022951765771722e-06
Batch: 0; loss: 0.74; acc: 0.72
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 0.78; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 0.99; acc: 0.69
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8217978422429152; val_accuracy: 0.7487062101910829 

The current subspace-distance is: 6.022951765771722e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.02; acc: 0.67
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 1.05; acc: 0.72
Batch: 80; loss: 0.86; acc: 0.77
Batch: 100; loss: 0.68; acc: 0.77
Batch: 120; loss: 0.86; acc: 0.75
Batch: 140; loss: 0.81; acc: 0.72
Batch: 160; loss: 0.68; acc: 0.78
Batch: 180; loss: 0.9; acc: 0.67
Batch: 200; loss: 0.97; acc: 0.7
Batch: 220; loss: 1.16; acc: 0.64
Batch: 240; loss: 1.04; acc: 0.7
Batch: 260; loss: 0.8; acc: 0.73
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.67; acc: 0.75
Batch: 320; loss: 0.9; acc: 0.73
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.71; acc: 0.8
Batch: 380; loss: 0.65; acc: 0.8
Batch: 400; loss: 0.96; acc: 0.73
Batch: 420; loss: 0.91; acc: 0.73
Batch: 440; loss: 0.86; acc: 0.77
Batch: 460; loss: 0.88; acc: 0.75
Batch: 480; loss: 0.95; acc: 0.66
Batch: 500; loss: 0.9; acc: 0.69
Batch: 520; loss: 0.97; acc: 0.69
Batch: 540; loss: 0.91; acc: 0.75
Batch: 560; loss: 0.88; acc: 0.78
Batch: 580; loss: 0.71; acc: 0.73
Batch: 600; loss: 1.1; acc: 0.66
Batch: 620; loss: 0.77; acc: 0.77
Batch: 640; loss: 0.68; acc: 0.72
Batch: 660; loss: 0.88; acc: 0.72
Batch: 680; loss: 0.64; acc: 0.78
Batch: 700; loss: 1.0; acc: 0.67
Batch: 720; loss: 0.82; acc: 0.73
Batch: 740; loss: 0.79; acc: 0.72
Batch: 760; loss: 0.74; acc: 0.77
Batch: 780; loss: 0.95; acc: 0.78
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.2858073862153105e-05
5.785180292150471e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.94; acc: 0.73
Batch: 40; loss: 0.78; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.82; acc: 0.8
Batch: 120; loss: 0.98; acc: 0.67
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.82188604060252; val_accuracy: 0.7504976114649682 

The current subspace-distance is: 5.785180292150471e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.86; acc: 0.69
Batch: 20; loss: 0.88; acc: 0.77
Batch: 40; loss: 0.7; acc: 0.73
Batch: 60; loss: 1.03; acc: 0.67
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 0.81; acc: 0.78
Batch: 120; loss: 1.03; acc: 0.7
Batch: 140; loss: 0.82; acc: 0.7
Batch: 160; loss: 0.8; acc: 0.73
Batch: 180; loss: 0.85; acc: 0.73
Batch: 200; loss: 0.88; acc: 0.7
Batch: 220; loss: 0.96; acc: 0.69
Batch: 240; loss: 0.82; acc: 0.72
Batch: 260; loss: 0.89; acc: 0.73
Batch: 280; loss: 1.02; acc: 0.69
Batch: 300; loss: 0.82; acc: 0.7
Batch: 320; loss: 0.64; acc: 0.81
Batch: 340; loss: 1.14; acc: 0.69
Batch: 360; loss: 0.89; acc: 0.73
Batch: 380; loss: 0.78; acc: 0.73
Batch: 400; loss: 0.89; acc: 0.77
Batch: 420; loss: 0.84; acc: 0.72
Batch: 440; loss: 0.89; acc: 0.75
Batch: 460; loss: 0.84; acc: 0.75
Batch: 480; loss: 0.66; acc: 0.84
Batch: 500; loss: 0.99; acc: 0.7
Batch: 520; loss: 0.78; acc: 0.72
Batch: 540; loss: 0.8; acc: 0.78
Batch: 560; loss: 0.79; acc: 0.73
Batch: 580; loss: 0.93; acc: 0.67
Batch: 600; loss: 0.9; acc: 0.72
Batch: 620; loss: 0.93; acc: 0.78
Batch: 640; loss: 0.97; acc: 0.66
Batch: 660; loss: 0.81; acc: 0.75
Batch: 680; loss: 1.15; acc: 0.67
Batch: 700; loss: 1.08; acc: 0.62
Batch: 720; loss: 1.24; acc: 0.69
Batch: 740; loss: 0.84; acc: 0.73
Batch: 760; loss: 1.03; acc: 0.7
Batch: 780; loss: 1.11; acc: 0.67
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.2706997697241604e-05
5.6053690968838055e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.73
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.78
Batch: 120; loss: 0.99; acc: 0.64
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.8212610657807369; val_accuracy: 0.7495023885350318 

The current subspace-distance is: 5.6053690968838055e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.93; acc: 0.72
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 0.86; acc: 0.72
Batch: 60; loss: 1.02; acc: 0.59
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 0.87; acc: 0.67
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.86; acc: 0.67
Batch: 160; loss: 0.83; acc: 0.75
Batch: 180; loss: 0.91; acc: 0.66
Batch: 200; loss: 0.95; acc: 0.67
Batch: 220; loss: 0.66; acc: 0.83
Batch: 240; loss: 0.9; acc: 0.84
Batch: 260; loss: 0.97; acc: 0.73
Batch: 280; loss: 0.91; acc: 0.67
Batch: 300; loss: 0.77; acc: 0.78
Batch: 320; loss: 0.82; acc: 0.72
Batch: 340; loss: 0.76; acc: 0.8
Batch: 360; loss: 0.86; acc: 0.7
Batch: 380; loss: 1.19; acc: 0.61
Batch: 400; loss: 1.07; acc: 0.69
Batch: 420; loss: 1.0; acc: 0.75
Batch: 440; loss: 1.13; acc: 0.64
Batch: 460; loss: 0.67; acc: 0.86
Batch: 480; loss: 1.01; acc: 0.67
Batch: 500; loss: 0.71; acc: 0.72
Batch: 520; loss: 0.94; acc: 0.69
Batch: 540; loss: 0.84; acc: 0.75
Batch: 560; loss: 0.99; acc: 0.73
Batch: 580; loss: 0.76; acc: 0.75
Batch: 600; loss: 1.02; acc: 0.69
Batch: 620; loss: 0.94; acc: 0.73
Batch: 640; loss: 0.93; acc: 0.69
Batch: 660; loss: 0.74; acc: 0.72
Batch: 680; loss: 0.91; acc: 0.7
Batch: 700; loss: 0.85; acc: 0.69
Batch: 720; loss: 0.89; acc: 0.7
Batch: 740; loss: 0.69; acc: 0.78
Batch: 760; loss: 0.89; acc: 0.7
Batch: 780; loss: 0.89; acc: 0.75
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.336344368814025e-05
5.3640446822100785e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.77; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.73
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 0.99; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.86
Val Epoch over. val_loss: 0.8208099459386935; val_accuracy: 0.7496019108280255 

The current subspace-distance is: 5.3640446822100785e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.79; acc: 0.69
Batch: 20; loss: 0.78; acc: 0.75
Batch: 40; loss: 1.26; acc: 0.7
Batch: 60; loss: 1.05; acc: 0.69
Batch: 80; loss: 0.9; acc: 0.7
Batch: 100; loss: 1.01; acc: 0.67
Batch: 120; loss: 1.01; acc: 0.78
Batch: 140; loss: 0.87; acc: 0.75
Batch: 160; loss: 0.89; acc: 0.75
Batch: 180; loss: 0.68; acc: 0.73
Batch: 200; loss: 0.81; acc: 0.77
Batch: 220; loss: 0.59; acc: 0.88
Batch: 240; loss: 1.21; acc: 0.64
Batch: 260; loss: 0.88; acc: 0.72
Batch: 280; loss: 1.06; acc: 0.62
Batch: 300; loss: 0.97; acc: 0.67
Batch: 320; loss: 0.73; acc: 0.77
Batch: 340; loss: 0.62; acc: 0.8
Batch: 360; loss: 0.92; acc: 0.72
Batch: 380; loss: 0.9; acc: 0.67
Batch: 400; loss: 1.17; acc: 0.72
Batch: 420; loss: 1.25; acc: 0.64
Batch: 440; loss: 1.01; acc: 0.64
Batch: 460; loss: 0.7; acc: 0.77
Batch: 480; loss: 1.02; acc: 0.66
Batch: 500; loss: 0.93; acc: 0.64
Batch: 520; loss: 0.84; acc: 0.77
Batch: 540; loss: 0.89; acc: 0.72
Batch: 560; loss: 0.81; acc: 0.7
Batch: 580; loss: 0.99; acc: 0.69
Batch: 600; loss: 0.74; acc: 0.73
Batch: 620; loss: 0.85; acc: 0.78
Batch: 640; loss: 0.79; acc: 0.75
Batch: 660; loss: 0.73; acc: 0.75
Batch: 680; loss: 0.95; acc: 0.7
Batch: 700; loss: 1.15; acc: 0.66
Batch: 720; loss: 1.15; acc: 0.66
Batch: 740; loss: 0.92; acc: 0.7
Batch: 760; loss: 0.76; acc: 0.77
Batch: 780; loss: 0.8; acc: 0.75
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.2666748918709345e-05
5.50182949154987e-06
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 1.0; acc: 0.67
Batch: 140; loss: 0.48; acc: 0.86
Val Epoch over. val_loss: 0.8198355931764955; val_accuracy: 0.7506966560509554 

The current subspace-distance is: 5.50182949154987e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.79; acc: 0.81
Batch: 20; loss: 1.0; acc: 0.72
Batch: 40; loss: 0.95; acc: 0.69
Batch: 60; loss: 0.7; acc: 0.73
Batch: 80; loss: 0.98; acc: 0.66
Batch: 100; loss: 0.75; acc: 0.8
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.7; acc: 0.81
Batch: 160; loss: 0.62; acc: 0.78
Batch: 180; loss: 0.67; acc: 0.78
Batch: 200; loss: 1.06; acc: 0.69
Batch: 220; loss: 1.21; acc: 0.61
Batch: 240; loss: 0.84; acc: 0.78
Batch: 260; loss: 1.42; acc: 0.69
Batch: 280; loss: 0.92; acc: 0.7
Batch: 300; loss: 0.65; acc: 0.77
Batch: 320; loss: 0.94; acc: 0.75
Batch: 340; loss: 0.88; acc: 0.75
Batch: 360; loss: 0.81; acc: 0.75
Batch: 380; loss: 0.85; acc: 0.73
Batch: 400; loss: 0.72; acc: 0.75
Batch: 420; loss: 1.03; acc: 0.64
Batch: 440; loss: 0.91; acc: 0.67
Batch: 460; loss: 1.06; acc: 0.69
Batch: 480; loss: 0.92; acc: 0.73
Batch: 500; loss: 0.65; acc: 0.77
Batch: 520; loss: 0.78; acc: 0.78
Batch: 540; loss: 0.93; acc: 0.73
Batch: 560; loss: 0.89; acc: 0.7
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.86; acc: 0.67
Batch: 620; loss: 0.7; acc: 0.78
Batch: 640; loss: 1.19; acc: 0.62
Batch: 660; loss: 0.95; acc: 0.72
Batch: 680; loss: 0.96; acc: 0.72
Batch: 700; loss: 0.92; acc: 0.64
Batch: 720; loss: 1.05; acc: 0.73
Batch: 740; loss: 0.87; acc: 0.73
Batch: 760; loss: 0.66; acc: 0.8
Batch: 780; loss: 0.82; acc: 0.75
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.3115480871638283e-05
5.419472472567577e-06
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.77; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.72
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 0.99; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8190754238207629; val_accuracy: 0.7494028662420382 

The current subspace-distance is: 5.419472472567577e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.86; acc: 0.77
Batch: 20; loss: 0.67; acc: 0.86
Batch: 40; loss: 0.8; acc: 0.67
Batch: 60; loss: 0.79; acc: 0.78
Batch: 80; loss: 0.9; acc: 0.69
Batch: 100; loss: 0.91; acc: 0.73
Batch: 120; loss: 1.42; acc: 0.55
Batch: 140; loss: 0.85; acc: 0.7
Batch: 160; loss: 1.05; acc: 0.75
Batch: 180; loss: 0.74; acc: 0.8
Batch: 200; loss: 0.82; acc: 0.75
Batch: 220; loss: 0.88; acc: 0.73
Batch: 240; loss: 0.5; acc: 0.84
Batch: 260; loss: 1.09; acc: 0.67
Batch: 280; loss: 0.85; acc: 0.73
Batch: 300; loss: 0.86; acc: 0.72
Batch: 320; loss: 0.74; acc: 0.81
Batch: 340; loss: 0.84; acc: 0.81
Batch: 360; loss: 0.7; acc: 0.84
Batch: 380; loss: 0.81; acc: 0.81
Batch: 400; loss: 1.15; acc: 0.67
Batch: 420; loss: 0.79; acc: 0.73
Batch: 440; loss: 1.03; acc: 0.69
Batch: 460; loss: 0.86; acc: 0.7
Batch: 480; loss: 0.71; acc: 0.8
Batch: 500; loss: 0.84; acc: 0.73
Batch: 520; loss: 0.73; acc: 0.8
Batch: 540; loss: 0.94; acc: 0.67
Batch: 560; loss: 1.19; acc: 0.64
Batch: 580; loss: 0.9; acc: 0.75
Batch: 600; loss: 0.86; acc: 0.77
Batch: 620; loss: 1.04; acc: 0.64
Batch: 640; loss: 1.46; acc: 0.62
Batch: 660; loss: 0.66; acc: 0.84
Batch: 680; loss: 0.95; acc: 0.73
Batch: 700; loss: 0.84; acc: 0.72
Batch: 720; loss: 1.07; acc: 0.72
Batch: 740; loss: 0.71; acc: 0.75
Batch: 760; loss: 0.88; acc: 0.69
Batch: 780; loss: 1.07; acc: 0.67
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.4593611669843085e-05
5.459954536490841e-06
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.91; acc: 0.73
Batch: 40; loss: 0.77; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.8; acc: 0.78
Batch: 120; loss: 1.0; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.89
Val Epoch over. val_loss: 0.8192542882481958; val_accuracy: 0.7502985668789809 

The current subspace-distance is: 5.459954536490841e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.18; acc: 0.64
Batch: 20; loss: 0.8; acc: 0.73
Batch: 40; loss: 0.87; acc: 0.77
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 0.59; acc: 0.88
Batch: 100; loss: 1.22; acc: 0.61
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.91; acc: 0.69
Batch: 160; loss: 0.69; acc: 0.78
Batch: 180; loss: 0.73; acc: 0.75
Batch: 200; loss: 0.94; acc: 0.72
Batch: 220; loss: 0.81; acc: 0.73
Batch: 240; loss: 0.92; acc: 0.66
Batch: 260; loss: 0.63; acc: 0.77
Batch: 280; loss: 1.12; acc: 0.69
Batch: 300; loss: 0.89; acc: 0.72
Batch: 320; loss: 0.86; acc: 0.73
Batch: 340; loss: 1.0; acc: 0.69
Batch: 360; loss: 1.05; acc: 0.69
Batch: 380; loss: 0.96; acc: 0.73
Batch: 400; loss: 1.06; acc: 0.73
Batch: 420; loss: 0.93; acc: 0.72
Batch: 440; loss: 0.69; acc: 0.75
Batch: 460; loss: 0.86; acc: 0.73
Batch: 480; loss: 0.72; acc: 0.73
Batch: 500; loss: 0.92; acc: 0.75
Batch: 520; loss: 0.94; acc: 0.81
Batch: 540; loss: 0.84; acc: 0.72
Batch: 560; loss: 0.91; acc: 0.8
Batch: 580; loss: 0.89; acc: 0.75
Batch: 600; loss: 0.74; acc: 0.83
Batch: 620; loss: 0.8; acc: 0.75
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 0.84; acc: 0.8
Batch: 680; loss: 0.86; acc: 0.72
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.68; acc: 0.8
Batch: 740; loss: 1.03; acc: 0.69
Batch: 760; loss: 0.8; acc: 0.8
Batch: 780; loss: 0.89; acc: 0.75
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

2.3036731363390572e-05
5.2031145969522186e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.91; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 0.99; acc: 0.69
Batch: 140; loss: 0.48; acc: 0.86
Val Epoch over. val_loss: 0.8187490764317239; val_accuracy: 0.7501990445859873 

The current subspace-distance is: 5.2031145969522186e-06 

plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 28430
elements in E: 3954800
fraction nonzero: 0.007188732679275817
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.11
Batch: 60; loss: 2.31; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.2
Batch: 100; loss: 2.31; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.31; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.2
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.31; acc: 0.06
Batch: 220; loss: 2.31; acc: 0.09
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.17
Batch: 280; loss: 2.31; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.31; acc: 0.14
Batch: 340; loss: 2.3; acc: 0.0
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.31; acc: 0.17
Batch: 400; loss: 2.31; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.31; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.3; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.2
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.31; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.3; acc: 0.08
Batch: 680; loss: 2.31; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.31; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

9.418415174877737e-06
5.5695466016914e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Val Epoch over. val_loss: 2.3002749324604204; val_accuracy: 0.10648885350318471 

The current subspace-distance is: 5.5695466016914e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.31; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.31; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.28; acc: 0.22
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.09
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.31; acc: 0.09
Batch: 300; loss: 2.31; acc: 0.06
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.16
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.29; acc: 0.17
Batch: 500; loss: 2.28; acc: 0.19
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.3; acc: 0.22
Batch: 600; loss: 2.3; acc: 0.14
Batch: 620; loss: 2.29; acc: 0.19
Batch: 640; loss: 2.3; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.12
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.28; acc: 0.19
Batch: 740; loss: 2.28; acc: 0.19
Batch: 760; loss: 2.28; acc: 0.22
Batch: 780; loss: 2.28; acc: 0.22
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

1.0006588126998395e-05
9.66789912126842e-07
Batch: 0; loss: 2.28; acc: 0.2
Batch: 20; loss: 2.29; acc: 0.17
Batch: 40; loss: 2.27; acc: 0.25
Batch: 60; loss: 2.28; acc: 0.25
Batch: 80; loss: 2.28; acc: 0.22
Batch: 100; loss: 2.28; acc: 0.19
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.19
Val Epoch over. val_loss: 2.2863077008800143; val_accuracy: 0.1969546178343949 

The current subspace-distance is: 9.66789912126842e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.19
Batch: 20; loss: 2.27; acc: 0.3
Batch: 40; loss: 2.28; acc: 0.25
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.28; acc: 0.22
Batch: 100; loss: 2.29; acc: 0.19
Batch: 120; loss: 2.28; acc: 0.23
Batch: 140; loss: 2.26; acc: 0.3
Batch: 160; loss: 2.28; acc: 0.28
Batch: 180; loss: 2.27; acc: 0.3
Batch: 200; loss: 2.27; acc: 0.25
Batch: 220; loss: 2.26; acc: 0.3
Batch: 240; loss: 2.28; acc: 0.28
Batch: 260; loss: 2.27; acc: 0.2
Batch: 280; loss: 2.26; acc: 0.23
Batch: 300; loss: 2.26; acc: 0.25
Batch: 320; loss: 2.26; acc: 0.2
Batch: 340; loss: 2.25; acc: 0.23
Batch: 360; loss: 2.26; acc: 0.2
Batch: 380; loss: 2.22; acc: 0.39
Batch: 400; loss: 2.22; acc: 0.3
Batch: 420; loss: 2.21; acc: 0.38
Batch: 440; loss: 2.2; acc: 0.42
Batch: 460; loss: 2.22; acc: 0.27
Batch: 480; loss: 2.22; acc: 0.23
Batch: 500; loss: 2.2; acc: 0.31
Batch: 520; loss: 2.18; acc: 0.22
Batch: 540; loss: 2.13; acc: 0.38
Batch: 560; loss: 2.15; acc: 0.28
Batch: 580; loss: 2.06; acc: 0.44
Batch: 600; loss: 2.08; acc: 0.48
Batch: 620; loss: 2.08; acc: 0.31
Batch: 640; loss: 2.04; acc: 0.34
Batch: 660; loss: 1.77; acc: 0.42
Batch: 680; loss: 1.87; acc: 0.34
Batch: 700; loss: 1.56; acc: 0.56
Batch: 720; loss: 1.57; acc: 0.45
Batch: 740; loss: 1.6; acc: 0.47
Batch: 760; loss: 1.45; acc: 0.5
Batch: 780; loss: 1.26; acc: 0.61
Train Epoch over. train_loss: 2.12; train_accuracy: 0.32 

1.327242443949217e-05
3.908320650225505e-06
Batch: 0; loss: 1.66; acc: 0.39
Batch: 20; loss: 1.79; acc: 0.41
Batch: 40; loss: 1.35; acc: 0.52
Batch: 60; loss: 1.48; acc: 0.42
Batch: 80; loss: 1.52; acc: 0.47
Batch: 100; loss: 1.6; acc: 0.45
Batch: 120; loss: 1.56; acc: 0.47
Batch: 140; loss: 1.36; acc: 0.56
Val Epoch over. val_loss: 1.5562902149880768; val_accuracy: 0.44158041401273884 

The current subspace-distance is: 3.908320650225505e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.28; acc: 0.48
Batch: 40; loss: 1.17; acc: 0.56
Batch: 60; loss: 1.31; acc: 0.56
Batch: 80; loss: 1.32; acc: 0.45
Batch: 100; loss: 1.49; acc: 0.48
Batch: 120; loss: 1.13; acc: 0.61
Batch: 140; loss: 1.78; acc: 0.44
Batch: 160; loss: 0.82; acc: 0.78
Batch: 180; loss: 0.87; acc: 0.73
Batch: 200; loss: 1.09; acc: 0.66
Batch: 220; loss: 1.49; acc: 0.58
Batch: 240; loss: 0.82; acc: 0.73
Batch: 260; loss: 0.94; acc: 0.73
Batch: 280; loss: 0.92; acc: 0.64
Batch: 300; loss: 1.04; acc: 0.69
Batch: 320; loss: 1.04; acc: 0.7
Batch: 340; loss: 0.65; acc: 0.83
Batch: 360; loss: 0.77; acc: 0.75
Batch: 380; loss: 0.88; acc: 0.69
Batch: 400; loss: 0.74; acc: 0.73
Batch: 420; loss: 0.95; acc: 0.67
Batch: 440; loss: 0.93; acc: 0.64
Batch: 460; loss: 1.17; acc: 0.67
Batch: 480; loss: 1.1; acc: 0.58
Batch: 500; loss: 0.92; acc: 0.66
Batch: 520; loss: 0.78; acc: 0.7
Batch: 540; loss: 0.73; acc: 0.75
Batch: 560; loss: 0.74; acc: 0.73
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.66; acc: 0.72
Batch: 620; loss: 0.93; acc: 0.73
Batch: 640; loss: 1.17; acc: 0.75
Batch: 660; loss: 0.84; acc: 0.7
Batch: 680; loss: 0.68; acc: 0.83
Batch: 700; loss: 0.72; acc: 0.77
Batch: 720; loss: 0.6; acc: 0.77
Batch: 740; loss: 0.95; acc: 0.7
Batch: 760; loss: 0.89; acc: 0.72
Batch: 780; loss: 1.3; acc: 0.66
Train Epoch over. train_loss: 0.98; train_accuracy: 0.68 

2.223992851213552e-05
4.991106379748089e-06
Batch: 0; loss: 0.66; acc: 0.83
Batch: 20; loss: 0.96; acc: 0.7
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.11; acc: 0.64
Batch: 140; loss: 0.46; acc: 0.88
Val Epoch over. val_loss: 0.7105315842066601; val_accuracy: 0.7751791401273885 

The current subspace-distance is: 4.991106379748089e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.72
Batch: 20; loss: 0.86; acc: 0.8
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 1.04; acc: 0.7
Batch: 80; loss: 0.65; acc: 0.83
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 0.94; acc: 0.67
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.85; acc: 0.7
Batch: 180; loss: 0.81; acc: 0.75
Batch: 200; loss: 0.57; acc: 0.84
Batch: 220; loss: 0.74; acc: 0.75
Batch: 240; loss: 0.66; acc: 0.78
Batch: 260; loss: 0.74; acc: 0.78
Batch: 280; loss: 0.63; acc: 0.77
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.9; acc: 0.64
Batch: 340; loss: 0.94; acc: 0.7
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.58; acc: 0.81
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.51; acc: 0.88
Batch: 440; loss: 0.64; acc: 0.77
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.61; acc: 0.75
Batch: 500; loss: 0.89; acc: 0.72
Batch: 520; loss: 0.5; acc: 0.88
Batch: 540; loss: 0.6; acc: 0.78
Batch: 560; loss: 0.6; acc: 0.84
Batch: 580; loss: 0.67; acc: 0.75
Batch: 600; loss: 0.69; acc: 0.75
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.63; acc: 0.78
Batch: 660; loss: 0.82; acc: 0.75
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.6; acc: 0.83
Batch: 740; loss: 0.46; acc: 0.84
Batch: 760; loss: 0.75; acc: 0.83
Batch: 780; loss: 0.64; acc: 0.78
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.4463723093504086e-05
5.402032002166379e-06
Batch: 0; loss: 0.62; acc: 0.86
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.75; acc: 0.75
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.35; acc: 0.88
Val Epoch over. val_loss: 0.5627869575456449; val_accuracy: 0.817078025477707 

The current subspace-distance is: 5.402032002166379e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.88
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 1.01; acc: 0.73
Batch: 60; loss: 0.63; acc: 0.8
Batch: 80; loss: 0.47; acc: 0.83
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.65; acc: 0.72
Batch: 140; loss: 0.54; acc: 0.81
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.79; acc: 0.81
Batch: 200; loss: 0.61; acc: 0.78
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.51; acc: 0.81
Batch: 260; loss: 0.56; acc: 0.8
Batch: 280; loss: 0.59; acc: 0.84
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.93; acc: 0.69
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.47; acc: 0.83
Batch: 440; loss: 0.49; acc: 0.81
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.47; acc: 0.83
Batch: 520; loss: 0.6; acc: 0.8
Batch: 540; loss: 0.58; acc: 0.8
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.57; acc: 0.83
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.9; acc: 0.7
Batch: 660; loss: 0.46; acc: 0.91
Batch: 680; loss: 0.63; acc: 0.73
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.71; acc: 0.81
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.62; train_accuracy: 0.8 

2.5121062208199874e-05
6.863527232781053e-06
Batch: 0; loss: 0.7; acc: 0.81
Batch: 20; loss: 0.88; acc: 0.75
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.83; acc: 0.72
Batch: 120; loss: 0.95; acc: 0.72
Batch: 140; loss: 0.38; acc: 0.86
Val Epoch over. val_loss: 0.6850815284404026; val_accuracy: 0.7625398089171974 

The current subspace-distance is: 6.863527232781053e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.76; acc: 0.72
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.56; acc: 0.8
Batch: 160; loss: 0.95; acc: 0.66
Batch: 180; loss: 0.58; acc: 0.78
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.65; acc: 0.8
Batch: 300; loss: 0.45; acc: 0.81
Batch: 320; loss: 0.57; acc: 0.81
Batch: 340; loss: 0.74; acc: 0.73
Batch: 360; loss: 0.44; acc: 0.86
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.61; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.84
Batch: 440; loss: 0.69; acc: 0.75
Batch: 460; loss: 0.64; acc: 0.83
Batch: 480; loss: 0.64; acc: 0.78
Batch: 500; loss: 0.55; acc: 0.78
Batch: 520; loss: 0.9; acc: 0.69
Batch: 540; loss: 0.81; acc: 0.78
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.81; acc: 0.75
Batch: 620; loss: 0.78; acc: 0.81
Batch: 640; loss: 0.63; acc: 0.78
Batch: 660; loss: 0.52; acc: 0.81
Batch: 680; loss: 0.69; acc: 0.83
Batch: 700; loss: 0.51; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.51; acc: 0.81
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

2.502232018741779e-05
5.929144663241459e-06
Batch: 0; loss: 1.33; acc: 0.66
Batch: 20; loss: 1.85; acc: 0.48
Batch: 40; loss: 1.15; acc: 0.75
Batch: 60; loss: 1.07; acc: 0.62
Batch: 80; loss: 1.26; acc: 0.55
Batch: 100; loss: 1.38; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.56
Batch: 140; loss: 0.74; acc: 0.7
Val Epoch over. val_loss: 1.277768483966779; val_accuracy: 0.6134554140127388 

The current subspace-distance is: 5.929144663241459e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.66
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 1.02; acc: 0.7
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.85; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.8
Batch: 160; loss: 0.93; acc: 0.72
Batch: 180; loss: 0.53; acc: 0.8
Batch: 200; loss: 0.59; acc: 0.77
Batch: 220; loss: 0.75; acc: 0.73
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.6; acc: 0.8
Batch: 280; loss: 1.12; acc: 0.64
Batch: 300; loss: 0.76; acc: 0.8
Batch: 320; loss: 0.69; acc: 0.78
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.8; acc: 0.77
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.58; acc: 0.75
Batch: 460; loss: 0.72; acc: 0.8
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.61; acc: 0.78
Batch: 580; loss: 0.7; acc: 0.78
Batch: 600; loss: 0.55; acc: 0.78
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 0.45; acc: 0.92
Batch: 660; loss: 0.75; acc: 0.78
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.83
Batch: 720; loss: 0.44; acc: 0.77
Batch: 740; loss: 0.69; acc: 0.77
Batch: 760; loss: 0.89; acc: 0.78
Batch: 780; loss: 0.56; acc: 0.88
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

2.526705793570727e-05
6.208568720467156e-06
Batch: 0; loss: 0.59; acc: 0.91
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.66; acc: 0.8
Batch: 120; loss: 0.78; acc: 0.7
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.618240204491433; val_accuracy: 0.8004578025477707 

The current subspace-distance is: 6.208568720467156e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.63; acc: 0.84
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.8; acc: 0.75
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.77; acc: 0.69
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.5; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.68; acc: 0.73
Batch: 300; loss: 0.96; acc: 0.72
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.66; acc: 0.8
Batch: 360; loss: 0.69; acc: 0.78
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.72; acc: 0.75
Batch: 500; loss: 0.74; acc: 0.77
Batch: 520; loss: 0.98; acc: 0.73
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.83
Batch: 580; loss: 0.58; acc: 0.77
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.4; acc: 0.95
Batch: 640; loss: 0.62; acc: 0.77
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.55; acc: 0.8
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.63; acc: 0.83
Batch: 780; loss: 0.55; acc: 0.78
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.6725499992608093e-05
6.559750090673333e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.83
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.27; acc: 0.88
Val Epoch over. val_loss: 0.48470732218520657; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 6.559750090673333e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.66; acc: 0.75
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.76; acc: 0.78
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.96; acc: 0.66
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.69; acc: 0.78
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 0.49; acc: 0.8
Batch: 360; loss: 0.54; acc: 0.8
Batch: 380; loss: 0.85; acc: 0.75
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.8
Batch: 540; loss: 0.51; acc: 0.78
Batch: 560; loss: 0.61; acc: 0.77
Batch: 580; loss: 0.49; acc: 0.81
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.56; acc: 0.78
Batch: 640; loss: 0.68; acc: 0.73
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.81
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 0.53; acc: 0.8
Batch: 780; loss: 0.54; acc: 0.8
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.5864581402856857e-05
6.662559371761745e-06
Batch: 0; loss: 0.75; acc: 0.67
Batch: 20; loss: 1.02; acc: 0.69
Batch: 40; loss: 0.63; acc: 0.8
Batch: 60; loss: 0.81; acc: 0.8
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.84; acc: 0.81
Batch: 120; loss: 1.23; acc: 0.58
Batch: 140; loss: 0.68; acc: 0.78
Val Epoch over. val_loss: 0.8545189019601056; val_accuracy: 0.7241242038216561 

The current subspace-distance is: 6.662559371761745e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.81
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.6; acc: 0.86
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.55; acc: 0.8
Batch: 280; loss: 0.54; acc: 0.86
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.63; acc: 0.81
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.58; acc: 0.84
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.71; acc: 0.78
Batch: 560; loss: 0.23; acc: 0.97
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.53; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.56; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

2.7728756322176196e-05
7.070259016472846e-06
Batch: 0; loss: 0.35; acc: 0.94
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.43314069528488597; val_accuracy: 0.8577826433121019 

The current subspace-distance is: 7.070259016472846e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.22; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.55; acc: 0.91
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.54; acc: 0.83
Batch: 240; loss: 0.75; acc: 0.8
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.48; acc: 0.88
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.52; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.66; acc: 0.78
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.58; acc: 0.84
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.4; acc: 0.81
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.54; acc: 0.83
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.49; acc: 0.8
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.7369385861675255e-05
5.847756710863905e-06
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.28; acc: 0.92
Val Epoch over. val_loss: 0.42749901030473647; val_accuracy: 0.8726114649681529 

The current subspace-distance is: 5.847756710863905e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.86
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.61; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.57; acc: 0.81
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.71; acc: 0.78
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.61; acc: 0.8
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.62; acc: 0.84
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.53; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.52; acc: 0.84
Batch: 560; loss: 0.57; acc: 0.81
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.57; acc: 0.8
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.57; acc: 0.75
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 0.76; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.7421907361713238e-05
6.753291017957963e-06
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.28; acc: 0.92
Val Epoch over. val_loss: 0.4405944282841531; val_accuracy: 0.8598726114649682 

The current subspace-distance is: 6.753291017957963e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.6; acc: 0.83
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.54; acc: 0.81
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.92
Batch: 320; loss: 0.81; acc: 0.78
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.59; acc: 0.86
Batch: 600; loss: 0.6; acc: 0.73
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.55; acc: 0.8
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.6522804546402767e-05
6.299871984083438e-06
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.8
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.4; acc: 0.86
Val Epoch over. val_loss: 0.5385386096254275; val_accuracy: 0.8225517515923567 

The current subspace-distance is: 6.299871984083438e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.8
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.34; acc: 0.84
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.55; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.83
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.62; acc: 0.83
Batch: 640; loss: 0.38; acc: 0.81
Batch: 660; loss: 0.65; acc: 0.81
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.42; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

2.7211548513150774e-05
6.617804046982201e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3426652728657054; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 6.617804046982201e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.83
Batch: 160; loss: 0.4; acc: 0.81
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.61; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.84
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.81
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.45; acc: 0.81
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

2.6966703444486484e-05
7.126564469217556e-06
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.38686140788019086; val_accuracy: 0.8786823248407644 

The current subspace-distance is: 7.126564469217556e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.63; acc: 0.81
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.58; acc: 0.84
Batch: 180; loss: 0.47; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.46; acc: 0.83
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.44; acc: 0.91
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.55; acc: 0.83
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.84
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.71; acc: 0.81
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

2.7218013201490976e-05
7.199881565611577e-06
Batch: 0; loss: 0.93; acc: 0.7
Batch: 20; loss: 0.97; acc: 0.69
Batch: 40; loss: 0.73; acc: 0.77
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.93; acc: 0.64
Batch: 100; loss: 0.82; acc: 0.75
Batch: 120; loss: 1.59; acc: 0.56
Batch: 140; loss: 0.64; acc: 0.7
Val Epoch over. val_loss: 0.9017775003697462; val_accuracy: 0.705015923566879 

The current subspace-distance is: 7.199881565611577e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.87; acc: 0.77
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.72; acc: 0.73
Batch: 280; loss: 0.75; acc: 0.78
Batch: 300; loss: 0.35; acc: 0.83
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.57; acc: 0.78
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.5; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.59; acc: 0.84
Batch: 700; loss: 0.49; acc: 0.78
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.87 

2.6877552954829298e-05
6.448290605476359e-06
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.3999899159760992; val_accuracy: 0.8705214968152867 

The current subspace-distance is: 6.448290605476359e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.71; acc: 0.8
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.86
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.84
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.61; acc: 0.84
Batch: 340; loss: 0.46; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.56; acc: 0.81
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.8
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.43; acc: 0.83
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.5; acc: 0.84
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.7255460736341774e-05
6.768837465642719e-06
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.21; acc: 0.89
Val Epoch over. val_loss: 0.35510595270972345; val_accuracy: 0.886843152866242 

The current subspace-distance is: 6.768837465642719e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.73; acc: 0.78
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.57; acc: 0.83
Batch: 240; loss: 0.31; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.81
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.62; acc: 0.81
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.43; acc: 0.83
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.84
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.87 

2.6594329028739594e-05
6.7136566030967515e-06
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.37708053899228955; val_accuracy: 0.8738057324840764 

The current subspace-distance is: 6.7136566030967515e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.95
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.7482003133627586e-05
6.317676707112696e-06
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.34781896541262886; val_accuracy: 0.8871417197452229 

The current subspace-distance is: 6.317676707112696e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.5; acc: 0.8
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.52; acc: 0.83
Batch: 580; loss: 0.52; acc: 0.8
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.638402656884864e-05
6.890993063279893e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.3231713426815476; val_accuracy: 0.8960987261146497 

The current subspace-distance is: 6.890993063279893e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.81; acc: 0.81
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.83
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.57; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.84
Batch: 420; loss: 0.36; acc: 0.84
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.81
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.88
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.6722396796685643e-05
6.353123353619594e-06
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.92
Val Epoch over. val_loss: 0.3178611392523073; val_accuracy: 0.8999800955414012 

The current subspace-distance is: 6.353123353619594e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.83
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.64; acc: 0.8
Batch: 160; loss: 0.4; acc: 0.84
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.58; acc: 0.81
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.61; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.82; acc: 0.81
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.52; acc: 0.83
Batch: 480; loss: 0.43; acc: 0.83
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.51; acc: 0.83
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.758334085228853e-05
6.8063018261455e-06
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.3748553022267712; val_accuracy: 0.8807722929936306 

The current subspace-distance is: 6.8063018261455e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.81
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.69; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.81
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.62; acc: 0.84
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.57; acc: 0.84
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.49; acc: 0.81
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.83
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.86
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.6429817808093503e-05
7.357176855293801e-06
Batch: 0; loss: 0.27; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.32889896669205587; val_accuracy: 0.8927149681528662 

The current subspace-distance is: 7.357176855293801e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.62; acc: 0.77
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.39; acc: 0.81
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.54; acc: 0.89
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.4; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.63; acc: 0.84
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.6477433493710123e-05
6.421158104785718e-06
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3268161074845654; val_accuracy: 0.8951035031847133 

The current subspace-distance is: 6.421158104785718e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.55; acc: 0.84
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.52; acc: 0.84
Batch: 580; loss: 0.57; acc: 0.84
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.47; acc: 0.8
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.630614471854642e-05
6.43488147034077e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.31389696461854466; val_accuracy: 0.9001791401273885 

The current subspace-distance is: 6.43488147034077e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.62; acc: 0.81
Batch: 240; loss: 0.54; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.49; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.78
Batch: 420; loss: 0.62; acc: 0.77
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.68; acc: 0.81
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.34; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.81
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.84
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.6909057851298712e-05
7.035509497654857e-06
Batch: 0; loss: 0.3; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.3316814357972449; val_accuracy: 0.8965963375796179 

The current subspace-distance is: 7.035509497654857e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.41; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.49; acc: 0.81
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.44; acc: 0.83
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.2; acc: 0.97
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.83
Batch: 460; loss: 0.64; acc: 0.78
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.6983458155882545e-05
7.4712743298732676e-06
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3889299482581722; val_accuracy: 0.8719148089171974 

The current subspace-distance is: 7.4712743298732676e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.84
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.4; acc: 0.84
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.39; acc: 0.84
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.57; acc: 0.78
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.8
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.68; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.6132351194974035e-05
7.279731562448433e-06
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3291133206551242; val_accuracy: 0.8959992038216561 

The current subspace-distance is: 7.279731562448433e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.8
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.49; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.44; acc: 0.81
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.83
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.58; acc: 0.89
Batch: 480; loss: 0.45; acc: 0.81
Batch: 500; loss: 0.54; acc: 0.86
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.57; acc: 0.84
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.81
Batch: 740; loss: 0.46; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.7555410269997083e-05
7.708026714681182e-06
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.3137571177664836; val_accuracy: 0.9007762738853503 

The current subspace-distance is: 7.708026714681182e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.54; acc: 0.86
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.7236228561378084e-05
7.089265182003146e-06
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.33563413489965876; val_accuracy: 0.8941082802547771 

The current subspace-distance is: 7.089265182003146e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.52; acc: 0.84
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.54; acc: 0.83
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.51; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.51; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.46; acc: 0.83
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.650633905432187e-05
6.800657502026297e-06
Batch: 0; loss: 0.26; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.30797571696008846; val_accuracy: 0.9020700636942676 

The current subspace-distance is: 6.800657502026297e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.8
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.64; acc: 0.78
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.26; acc: 0.86
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.59; acc: 0.8
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.84
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.8
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.7236255846219137e-05
6.294770173553843e-06
Batch: 0; loss: 0.26; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.30625125765800476; val_accuracy: 0.9033638535031847 

The current subspace-distance is: 6.294770173553843e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.45; acc: 0.81
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.7341757231624797e-05
7.742469279037323e-06
Batch: 0; loss: 0.28; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.31520899117087864; val_accuracy: 0.9004777070063694 

The current subspace-distance is: 7.742469279037323e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.75; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.46; acc: 0.83
Batch: 380; loss: 0.2; acc: 0.98
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.5; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.8292291972320527e-05
8.167548003257252e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3086213617093244; val_accuracy: 0.9029657643312102 

The current subspace-distance is: 8.167548003257252e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.86
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.78
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.715091613936238e-05
7.742724847048521e-06
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.31786160488986664; val_accuracy: 0.8994824840764332 

The current subspace-distance is: 7.742724847048521e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.63; acc: 0.84
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.84
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.67; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.88
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.8107864636695012e-05
6.779782324883854e-06
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.31209176254405335; val_accuracy: 0.9022691082802548 

The current subspace-distance is: 6.779782324883854e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.69; acc: 0.8
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.52; acc: 0.8
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.44; acc: 0.83
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.6489797164686024e-05
6.888132702442817e-06
Batch: 0; loss: 0.25; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.30248205195281913; val_accuracy: 0.9037619426751592 

The current subspace-distance is: 6.888132702442817e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.91
Batch: 160; loss: 0.72; acc: 0.84
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.39; acc: 0.83
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.86
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.83
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.5; acc: 0.86
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.48; acc: 0.88
Batch: 720; loss: 0.51; acc: 0.83
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.7794438210548833e-05
7.2934544732561335e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.33002398616284323; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 7.2934544732561335e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.86
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.51; acc: 0.88
Batch: 560; loss: 0.55; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.7004469302482903e-05
6.756508355465485e-06
Batch: 0; loss: 0.26; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3029666021703535; val_accuracy: 0.904359076433121 

The current subspace-distance is: 6.756508355465485e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.38; acc: 0.84
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.7; acc: 0.8
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.39; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.92
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.7082471206085756e-05
6.963078703847714e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.30243957014220535; val_accuracy: 0.9039609872611465 

The current subspace-distance is: 6.963078703847714e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.83
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.89 

2.771117760858033e-05
7.309563443413936e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.30469129422003294; val_accuracy: 0.9026671974522293 

The current subspace-distance is: 7.309563443413936e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.7835600121761672e-05
7.197982085926924e-06
Batch: 0; loss: 0.27; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.305357679250134; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 7.197982085926924e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.52; acc: 0.78
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.25; acc: 0.88
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.54; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.84
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.57; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.52; acc: 0.88
Batch: 780; loss: 0.59; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.711100569285918e-05
6.736851901223417e-06
Batch: 0; loss: 0.26; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.30570930299485566; val_accuracy: 0.9030652866242038 

The current subspace-distance is: 6.736851901223417e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.5; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.31; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.83
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.4; acc: 0.92
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.7063120796810836e-05
7.2837574407458305e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3028768198268049; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 7.2837574407458305e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.94
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.39; acc: 0.84
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.52; acc: 0.83
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.6722489565145224e-05
6.979798854445107e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.30160129931607066; val_accuracy: 0.9047571656050956 

The current subspace-distance is: 6.979798854445107e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.47; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.5; acc: 0.8
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.86
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.7776268325396813e-05
7.712597835052293e-06
Batch: 0; loss: 0.26; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3023217334916258; val_accuracy: 0.9042595541401274 

The current subspace-distance is: 7.712597835052293e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.8
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.79; acc: 0.75
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.66; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.81
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.7153108021593653e-05
6.801677045586985e-06
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.78; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.30459436200037127; val_accuracy: 0.9033638535031847 

The current subspace-distance is: 6.801677045586985e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.97
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.51; acc: 0.8
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.53; acc: 0.88
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.89 

2.6587054890114814e-05
7.434203780576354e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3039397005062954; val_accuracy: 0.9032643312101911 

The current subspace-distance is: 7.434203780576354e-06 

plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 42475
elements in E: 5932200
fraction nonzero: 0.0071600755200431545
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.31; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.31; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.31; acc: 0.08
Batch: 160; loss: 2.29; acc: 0.19
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.31; acc: 0.06
Batch: 220; loss: 2.31; acc: 0.09
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.17
Batch: 280; loss: 2.31; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.31; acc: 0.14
Batch: 340; loss: 2.3; acc: 0.0
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.31; acc: 0.17
Batch: 400; loss: 2.31; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.31; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.3; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.2
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.3; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.31; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

1.0866099728445988e-05
6.351714887387061e-07
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Val Epoch over. val_loss: 2.2987002946768595; val_accuracy: 0.10648885350318471 

The current subspace-distance is: 6.351714887387061e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.28; acc: 0.22
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.09
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.31; acc: 0.06
Batch: 320; loss: 2.28; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.28; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.17
Batch: 500; loss: 2.27; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.2
Batch: 540; loss: 2.28; acc: 0.14
Batch: 560; loss: 2.28; acc: 0.17
Batch: 580; loss: 2.28; acc: 0.16
Batch: 600; loss: 2.28; acc: 0.2
Batch: 620; loss: 2.27; acc: 0.23
Batch: 640; loss: 2.29; acc: 0.16
Batch: 660; loss: 2.26; acc: 0.22
Batch: 680; loss: 2.24; acc: 0.23
Batch: 700; loss: 2.25; acc: 0.23
Batch: 720; loss: 2.23; acc: 0.3
Batch: 740; loss: 2.22; acc: 0.28
Batch: 760; loss: 2.18; acc: 0.28
Batch: 780; loss: 2.19; acc: 0.3
Train Epoch over. train_loss: 2.28; train_accuracy: 0.15 

1.1020491001545452e-05
1.4308907339000143e-06
Batch: 0; loss: 2.19; acc: 0.31
Batch: 20; loss: 2.25; acc: 0.17
Batch: 40; loss: 2.15; acc: 0.3
Batch: 60; loss: 2.18; acc: 0.27
Batch: 80; loss: 2.17; acc: 0.3
Batch: 100; loss: 2.22; acc: 0.28
Batch: 120; loss: 2.21; acc: 0.19
Batch: 140; loss: 2.22; acc: 0.23
Val Epoch over. val_loss: 2.194605781773853; val_accuracy: 0.23964968152866242 

The current subspace-distance is: 1.4308907339000143e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.2; acc: 0.28
Batch: 20; loss: 2.13; acc: 0.3
Batch: 40; loss: 2.11; acc: 0.36
Batch: 60; loss: 2.08; acc: 0.27
Batch: 80; loss: 1.97; acc: 0.45
Batch: 100; loss: 1.84; acc: 0.33
Batch: 120; loss: 1.8; acc: 0.38
Batch: 140; loss: 1.59; acc: 0.39
Batch: 160; loss: 1.66; acc: 0.42
Batch: 180; loss: 1.44; acc: 0.42
Batch: 200; loss: 1.54; acc: 0.45
Batch: 220; loss: 1.55; acc: 0.44
Batch: 240; loss: 2.32; acc: 0.28
Batch: 260; loss: 1.43; acc: 0.48
Batch: 280; loss: 1.69; acc: 0.52
Batch: 300; loss: 0.9; acc: 0.72
Batch: 320; loss: 1.28; acc: 0.58
Batch: 340; loss: 0.93; acc: 0.62
Batch: 360; loss: 0.82; acc: 0.69
Batch: 380; loss: 0.75; acc: 0.7
Batch: 400; loss: 1.73; acc: 0.52
Batch: 420; loss: 0.76; acc: 0.77
Batch: 440; loss: 0.66; acc: 0.75
Batch: 460; loss: 0.89; acc: 0.67
Batch: 480; loss: 0.89; acc: 0.67
Batch: 500; loss: 0.87; acc: 0.69
Batch: 520; loss: 0.83; acc: 0.72
Batch: 540; loss: 0.7; acc: 0.75
Batch: 560; loss: 0.75; acc: 0.83
Batch: 580; loss: 0.77; acc: 0.73
Batch: 600; loss: 0.73; acc: 0.81
Batch: 620; loss: 0.89; acc: 0.73
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 0.83; acc: 0.72
Batch: 680; loss: 0.91; acc: 0.7
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.74; acc: 0.78
Batch: 740; loss: 0.61; acc: 0.86
Batch: 760; loss: 1.05; acc: 0.72
Batch: 780; loss: 0.52; acc: 0.83
Train Epoch over. train_loss: 1.18; train_accuracy: 0.61 

1.974500628421083e-05
6.050046067684889e-06
Batch: 0; loss: 1.2; acc: 0.64
Batch: 20; loss: 1.24; acc: 0.58
Batch: 40; loss: 0.72; acc: 0.73
Batch: 60; loss: 1.04; acc: 0.7
Batch: 80; loss: 0.94; acc: 0.67
Batch: 100; loss: 1.09; acc: 0.67
Batch: 120; loss: 1.79; acc: 0.48
Batch: 140; loss: 0.85; acc: 0.72
Val Epoch over. val_loss: 1.1254883461697087; val_accuracy: 0.6402269108280255 

The current subspace-distance is: 6.050046067684889e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.09; acc: 0.58
Batch: 20; loss: 1.17; acc: 0.66
Batch: 40; loss: 0.48; acc: 0.78
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.67; acc: 0.8
Batch: 100; loss: 0.58; acc: 0.78
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.62; acc: 0.8
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.79; acc: 0.75
Batch: 240; loss: 0.49; acc: 0.89
Batch: 260; loss: 0.53; acc: 0.84
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.91; acc: 0.73
Batch: 320; loss: 1.1; acc: 0.75
Batch: 340; loss: 0.5; acc: 0.83
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.64; acc: 0.73
Batch: 440; loss: 0.53; acc: 0.81
Batch: 460; loss: 0.74; acc: 0.75
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.56; acc: 0.86
Batch: 540; loss: 0.47; acc: 0.83
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.5; acc: 0.81
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.4658904294483364e-05
6.551300430146512e-06
Batch: 0; loss: 3.73; acc: 0.23
Batch: 20; loss: 4.47; acc: 0.2
Batch: 40; loss: 3.02; acc: 0.23
Batch: 60; loss: 3.36; acc: 0.28
Batch: 80; loss: 3.56; acc: 0.27
Batch: 100; loss: 3.74; acc: 0.27
Batch: 120; loss: 4.38; acc: 0.22
Batch: 140; loss: 3.61; acc: 0.31
Val Epoch over. val_loss: 3.59513797577779; val_accuracy: 0.2757762738853503 

The current subspace-distance is: 6.551300430146512e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 3.55; acc: 0.23
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.64; acc: 0.77
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.65; acc: 0.81
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.8
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.61; acc: 0.78
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.81
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.86; acc: 0.73
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.48; acc: 0.81
Batch: 580; loss: 0.41; acc: 0.84
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.6496734790271148e-05
7.120023838069756e-06
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.98; acc: 0.69
Batch: 40; loss: 0.72; acc: 0.77
Batch: 60; loss: 0.99; acc: 0.66
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 1.0; acc: 0.78
Batch: 120; loss: 1.34; acc: 0.69
Batch: 140; loss: 0.59; acc: 0.8
Val Epoch over. val_loss: 0.7863668340976071; val_accuracy: 0.7623407643312102 

The current subspace-distance is: 7.120023838069756e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.64; acc: 0.78
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 0.29; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.69; acc: 0.83
Batch: 200; loss: 0.58; acc: 0.78
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.89; acc: 0.67
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.56; acc: 0.81
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.46; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.84
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.76; acc: 0.83
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.7; acc: 0.8
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.5; acc: 0.83
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.57; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.83
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.81
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.6460777007741854e-05
6.3263946685765404e-06
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.96; acc: 0.7
Batch: 140; loss: 0.65; acc: 0.86
Val Epoch over. val_loss: 0.5876252956830772; val_accuracy: 0.8179737261146497 

The current subspace-distance is: 6.3263946685765404e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.68; acc: 0.78
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.56; acc: 0.8
Batch: 220; loss: 0.57; acc: 0.86
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.83
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.46; acc: 0.8
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.47; acc: 0.81
Batch: 460; loss: 0.38; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.71; acc: 0.78
Batch: 540; loss: 0.55; acc: 0.81
Batch: 560; loss: 0.77; acc: 0.72
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.65; acc: 0.77
Batch: 620; loss: 0.72; acc: 0.84
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.81
Batch: 760; loss: 0.4; acc: 0.84
Batch: 780; loss: 0.56; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

2.751971078396309e-05
6.944208507775329e-06
Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 1.0; acc: 0.73
Batch: 40; loss: 0.6; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 0.9; acc: 0.72
Batch: 120; loss: 1.07; acc: 0.67
Batch: 140; loss: 0.58; acc: 0.83
Val Epoch over. val_loss: 0.794647653201583; val_accuracy: 0.7565684713375797 

The current subspace-distance is: 6.944208507775329e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.4; acc: 0.84
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.84; acc: 0.75
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.58; acc: 0.83
Batch: 280; loss: 0.61; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.81
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.61; acc: 0.84
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.65; acc: 0.8
Batch: 480; loss: 0.39; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.42; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.69; acc: 0.81
Batch: 680; loss: 0.24; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.81; acc: 0.72
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.708148349483963e-05
6.504004886664916e-06
Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 1.02; acc: 0.66
Batch: 40; loss: 0.61; acc: 0.84
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.57; acc: 0.81
Batch: 120; loss: 1.1; acc: 0.73
Batch: 140; loss: 0.5; acc: 0.83
Val Epoch over. val_loss: 0.7553105675111151; val_accuracy: 0.7654259554140127 

The current subspace-distance is: 6.504004886664916e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.74; acc: 0.78
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.81
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.91; acc: 0.77
Batch: 300; loss: 0.57; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.6; acc: 0.84
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.51; acc: 0.84
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.75; acc: 0.75
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.48; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.57; acc: 0.81
Batch: 680; loss: 0.46; acc: 0.81
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.99; acc: 0.73
Batch: 740; loss: 0.25; acc: 0.88
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

2.8701724659185857e-05
6.7712644522544e-06
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.61; acc: 0.78
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.65; acc: 0.81
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.4942859957457348; val_accuracy: 0.8377786624203821 

The current subspace-distance is: 6.7712644522544e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.77
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.96; acc: 0.72
Batch: 80; loss: 0.87; acc: 0.7
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.81
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.56; acc: 0.81
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.97
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.8356285838526674e-05
8.054516911215615e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.5381312190916887; val_accuracy: 0.8312101910828026 

The current subspace-distance is: 8.054516911215615e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.81
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.97
Batch: 440; loss: 0.55; acc: 0.89
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.92
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.8171687517897226e-05
6.170538199512521e-06
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.27879371266266345; val_accuracy: 0.9093351910828026 

The current subspace-distance is: 6.170538199512521e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.58; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.66; acc: 0.84
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.28; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.41; acc: 0.83
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.6; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.7830537874251604e-05
7.222504791570827e-06
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26826524891101633; val_accuracy: 0.9170979299363057 

The current subspace-distance is: 7.222504791570827e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.98
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.97
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.5; acc: 0.83
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.86
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.81
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.8534697776194662e-05
7.3234982664871495e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.8; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.2852873857708494; val_accuracy: 0.9107285031847133 

The current subspace-distance is: 7.3234982664871495e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.83
Batch: 340; loss: 0.34; acc: 0.86
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.915895493060816e-05
7.422360795317218e-06
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2909579583129306; val_accuracy: 0.9056528662420382 

The current subspace-distance is: 7.422360795317218e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.64; acc: 0.81
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.8700722396024503e-05
7.47412286727922e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.94
Batch: 120; loss: 0.79; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.28197718240842695; val_accuracy: 0.9134156050955414 

The current subspace-distance is: 7.47412286727922e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.46; acc: 0.81
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.868893170671072e-05
6.741159722878365e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.3072083722918656; val_accuracy: 0.9054538216560509 

The current subspace-distance is: 6.741159722878365e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.47; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.89
Batch: 540; loss: 0.09; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.48; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.9164579245843925e-05
7.881443707447033e-06
Batch: 0; loss: 0.59; acc: 0.75
Batch: 20; loss: 0.73; acc: 0.75
Batch: 40; loss: 0.51; acc: 0.89
Batch: 60; loss: 0.63; acc: 0.8
Batch: 80; loss: 0.68; acc: 0.7
Batch: 100; loss: 0.61; acc: 0.84
Batch: 120; loss: 1.24; acc: 0.75
Batch: 140; loss: 0.32; acc: 0.94
Val Epoch over. val_loss: 0.6931101714919328; val_accuracy: 0.794984076433121 

The current subspace-distance is: 7.881443707447033e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.88
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.44; acc: 0.81
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.44; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.9029877623543143e-05
7.611447472299915e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2532238790611173; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 7.611447472299915e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 0.32; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.54; acc: 0.84
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.86
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.47; acc: 0.83
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.44; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.830599987646565e-05
7.098430160112912e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2627114332547993; val_accuracy: 0.9178941082802548 

The current subspace-distance is: 7.098430160112912e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.53; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.91
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.41; acc: 0.86
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.84
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.9041744710411876e-05
7.146647021727404e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.26633186344128507; val_accuracy: 0.9157046178343949 

The current subspace-distance is: 7.146647021727404e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.881456384784542e-05
7.677563189645298e-06
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22041722327755514; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 7.677563189645298e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.881606087612454e-05
6.695599495287752e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21679164203488901; val_accuracy: 0.9349124203821656 

The current subspace-distance is: 6.695599495287752e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.57; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.8266127628739923e-05
7.158957487263251e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2216416138704795; val_accuracy: 0.9323248407643312 

The current subspace-distance is: 7.158957487263251e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.47; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.83
Batch: 420; loss: 0.17; acc: 0.98
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.48; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.9328324671951123e-05
7.564786301372806e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21633806321651314; val_accuracy: 0.9338176751592356 

The current subspace-distance is: 7.564786301372806e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.55; acc: 0.8
Batch: 220; loss: 0.24; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.51; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.9409815397229977e-05
7.953652129799593e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22942908506864196; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 7.953652129799593e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.23; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.928777212218847e-05
7.14329007678316e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.22514354919267307; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 7.14329007678316e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.86
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.4; acc: 0.83
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.55; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.893939927162137e-05
7.0663650149072055e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.08; acc: 1.0
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.23423849202834876; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 7.0663650149072055e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.52; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.9426131732179783e-05
8.225911187764723e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2075857913275813; val_accuracy: 0.9363057324840764 

The current subspace-distance is: 8.225911187764723e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.52; acc: 0.88
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.6; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.86
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.19; acc: 0.98
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.886465154006146e-05
7.746585652057547e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.22801321284596326; val_accuracy: 0.9292396496815286 

The current subspace-distance is: 7.746585652057547e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.91
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.8483036658144556e-05
7.421247119054897e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.86
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21604860104193355; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 7.421247119054897e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.56; acc: 0.81
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.51; acc: 0.81
Batch: 200; loss: 0.16; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.42; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9718417863477953e-05
7.5810926318808924e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20810815710930308; val_accuracy: 0.932921974522293 

The current subspace-distance is: 7.5810926318808924e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.95
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9029652068857104e-05
7.9333412941196e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21325414822359753; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 7.9333412941196e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.86
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9395880119409412e-05
7.2213147177535575e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.20345473899298414; val_accuracy: 0.9357085987261147 

The current subspace-distance is: 7.2213147177535575e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.83
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.88
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.91
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9324304705369286e-05
7.12233986632782e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20776289798746442; val_accuracy: 0.933718152866242 

The current subspace-distance is: 7.12233986632782e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.83
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.12; acc: 1.0
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.97
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.88
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.8593594834092073e-05
7.180491593317129e-06
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2031258418206956; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 7.180491593317129e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9003227609791793e-05
6.918751751072705e-06
Batch: 0; loss: 0.16; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20394546348767675; val_accuracy: 0.9353105095541401 

The current subspace-distance is: 6.918751751072705e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.88
Batch: 180; loss: 0.09; acc: 1.0
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.47; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9473741960828193e-05
7.388005542452447e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20227642385822953; val_accuracy: 0.9353105095541401 

The current subspace-distance is: 7.388005542452447e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.35; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.98
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.8417851353879087e-05
7.314438789762789e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20416558595599643; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 7.314438789762789e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.98
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.32; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.916922494478058e-05
7.239959813887253e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1998789079344956; val_accuracy: 0.9357085987261147 

The current subspace-distance is: 7.239959813887253e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.07; acc: 1.0
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9253907996462658e-05
7.241018465720117e-06
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20163348623237032; val_accuracy: 0.934812898089172 

The current subspace-distance is: 7.241018465720117e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.05; acc: 1.0
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.98
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9507173167075962e-05
7.017284133326029e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.199329518730853; val_accuracy: 0.9355095541401274 

The current subspace-distance is: 7.017284133326029e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.54; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.86
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.954560113721527e-05
7.111772902135272e-06
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19994871370541822; val_accuracy: 0.9353105095541401 

The current subspace-distance is: 7.111772902135272e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.42; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.99552375508938e-05
7.204351732070791e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20173043719712336; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 7.204351732070791e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.4; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.51; acc: 0.81
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.27; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.53; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.8947069949936122e-05
6.908312570885755e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19890850198686502; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 6.908312570885755e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.28; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.06; acc: 1.0
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.937255885626655e-05
7.377675046882359e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.1998738011546955; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 7.377675046882359e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.89
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.45; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9546545192715712e-05
8.041098226385657e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.1990644086840426; val_accuracy: 0.9354100318471338 

The current subspace-distance is: 8.041098226385657e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.97
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9108885428286158e-05
7.287329026439693e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19799097736549984; val_accuracy: 0.9381966560509554 

The current subspace-distance is: 7.287329026439693e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.63; acc: 0.88
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.37; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.08; acc: 1.0
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.9009119316469878e-05
7.347678092628485e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.199337559283539; val_accuracy: 0.9369028662420382 

The current subspace-distance is: 7.347678092628485e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.8998349080211483e-05
7.566783551737899e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19753700546967756; val_accuracy: 0.9373009554140127 

The current subspace-distance is: 7.566783551737899e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.83
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.986140134453308e-05
7.3947371674876194e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19941126315551957; val_accuracy: 0.9366042993630573 

The current subspace-distance is: 7.3947371674876194e-06 

plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 56363
elements in E: 7909600
fraction nonzero: 0.007125897643370082
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.31; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.2
Batch: 100; loss: 2.31; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.31; acc: 0.16
Batch: 160; loss: 2.29; acc: 0.22
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.3; acc: 0.16
Batch: 220; loss: 2.31; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.17
Batch: 260; loss: 2.3; acc: 0.22
Batch: 280; loss: 2.31; acc: 0.14
Batch: 300; loss: 2.31; acc: 0.12
Batch: 320; loss: 2.31; acc: 0.14
Batch: 340; loss: 2.3; acc: 0.0
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.3; acc: 0.17
Batch: 400; loss: 2.3; acc: 0.14
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.14
Batch: 500; loss: 2.29; acc: 0.16
Batch: 520; loss: 2.3; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.22
Batch: 580; loss: 2.29; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.29; acc: 0.14
Batch: 660; loss: 2.29; acc: 0.12
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.29; acc: 0.14
Batch: 740; loss: 2.28; acc: 0.14
Batch: 760; loss: 2.28; acc: 0.19
Batch: 780; loss: 2.29; acc: 0.16
Train Epoch over. train_loss: 2.3; train_accuracy: 0.13 

1.0882277820201125e-05
1.0012396387537592e-06
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.22
Batch: 60; loss: 2.27; acc: 0.17
Batch: 80; loss: 2.28; acc: 0.23
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.28; acc: 0.09
Val Epoch over. val_loss: 2.2832438520565153; val_accuracy: 0.17396496815286625 

The current subspace-distance is: 1.0012396387537592e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.2
Batch: 40; loss: 2.28; acc: 0.22
Batch: 60; loss: 2.28; acc: 0.22
Batch: 80; loss: 2.27; acc: 0.38
Batch: 100; loss: 2.27; acc: 0.33
Batch: 120; loss: 2.26; acc: 0.3
Batch: 140; loss: 2.26; acc: 0.22
Batch: 160; loss: 2.26; acc: 0.22
Batch: 180; loss: 2.2; acc: 0.36
Batch: 200; loss: 2.23; acc: 0.27
Batch: 220; loss: 2.21; acc: 0.2
Batch: 240; loss: 2.2; acc: 0.31
Batch: 260; loss: 2.19; acc: 0.25
Batch: 280; loss: 2.11; acc: 0.28
Batch: 300; loss: 1.99; acc: 0.38
Batch: 320; loss: 1.84; acc: 0.39
Batch: 340; loss: 1.49; acc: 0.48
Batch: 360; loss: 1.68; acc: 0.39
Batch: 380; loss: 1.24; acc: 0.58
Batch: 400; loss: 1.03; acc: 0.69
Batch: 420; loss: 1.38; acc: 0.5
Batch: 440; loss: 1.22; acc: 0.56
Batch: 460; loss: 1.0; acc: 0.64
Batch: 480; loss: 1.26; acc: 0.52
Batch: 500; loss: 0.99; acc: 0.64
Batch: 520; loss: 1.21; acc: 0.64
Batch: 540; loss: 0.76; acc: 0.73
Batch: 560; loss: 0.96; acc: 0.67
Batch: 580; loss: 0.92; acc: 0.72
Batch: 600; loss: 0.66; acc: 0.8
Batch: 620; loss: 0.75; acc: 0.72
Batch: 640; loss: 0.91; acc: 0.67
Batch: 660; loss: 1.38; acc: 0.66
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.79; acc: 0.72
Batch: 720; loss: 0.95; acc: 0.64
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 0.62; acc: 0.78
Batch: 780; loss: 0.81; acc: 0.75
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

1.6613861589576118e-05
5.22243954037549e-06
Batch: 0; loss: 0.69; acc: 0.75
Batch: 20; loss: 0.99; acc: 0.69
Batch: 40; loss: 0.77; acc: 0.75
Batch: 60; loss: 1.09; acc: 0.64
Batch: 80; loss: 0.96; acc: 0.69
Batch: 100; loss: 0.88; acc: 0.66
Batch: 120; loss: 1.56; acc: 0.58
Batch: 140; loss: 0.55; acc: 0.78
Val Epoch over. val_loss: 0.971464395712895; val_accuracy: 0.6659036624203821 

The current subspace-distance is: 5.22243954037549e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.07; acc: 0.61
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.8
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.62; acc: 0.8
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.65; acc: 0.8
Batch: 220; loss: 0.5; acc: 0.89
Batch: 240; loss: 0.67; acc: 0.77
Batch: 260; loss: 0.79; acc: 0.78
Batch: 280; loss: 0.55; acc: 0.78
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.93; acc: 0.77
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.65; acc: 0.84
Batch: 400; loss: 0.73; acc: 0.8
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.57; acc: 0.8
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.57; acc: 0.78
Batch: 520; loss: 0.45; acc: 0.8
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.72; acc: 0.81
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.45; acc: 0.83
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.35; acc: 0.92
Batch: 760; loss: 0.51; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

2.2730848286300898e-05
6.433541329897707e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.81
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.40557044979398416; val_accuracy: 0.8717157643312102 

The current subspace-distance is: 6.433541329897707e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.48; acc: 0.81
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.81
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.58; acc: 0.8
Batch: 220; loss: 0.45; acc: 0.81
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.66; acc: 0.84
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.62; acc: 0.81
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.61; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.55; acc: 0.86
Batch: 660; loss: 0.48; acc: 0.88
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.422352736175526e-05
7.588469543406973e-06
Batch: 0; loss: 1.62; acc: 0.59
Batch: 20; loss: 1.85; acc: 0.52
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 1.2; acc: 0.64
Batch: 80; loss: 1.34; acc: 0.61
Batch: 100; loss: 1.34; acc: 0.67
Batch: 120; loss: 1.82; acc: 0.61
Batch: 140; loss: 1.01; acc: 0.67
Val Epoch over. val_loss: 1.4258562246705317; val_accuracy: 0.6157444267515924 

The current subspace-distance is: 7.588469543406973e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.5; acc: 0.64
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.52; acc: 0.81
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.84
Batch: 300; loss: 0.47; acc: 0.78
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.5; acc: 0.8
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.59; acc: 0.81
Batch: 460; loss: 0.24; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.5973005904234014e-05
7.743162314000074e-06
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.4163831842078525; val_accuracy: 0.8680334394904459 

The current subspace-distance is: 7.743162314000074e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.43; acc: 0.92
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.57; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.71; acc: 0.8
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.7059697458753362e-05
7.76006891101133e-06
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.46; acc: 0.91
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.77
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 1.16; acc: 0.75
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.6398788889881911; val_accuracy: 0.8005573248407644 

The current subspace-distance is: 7.76006891101133e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.83
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.56; acc: 0.8
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.86
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.5; acc: 0.83
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.5; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.51; acc: 0.8
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.7143176339450292e-05
7.502675089199329e-06
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.86; acc: 0.81
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.73; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.34; acc: 0.84
Val Epoch over. val_loss: 0.5582866066960013; val_accuracy: 0.8321058917197452 

The current subspace-distance is: 7.502675089199329e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.51; acc: 0.78
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.86
Batch: 780; loss: 0.68; acc: 0.81
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.7617135856417008e-05
8.38465439301217e-06
Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 1.2; acc: 0.73
Batch: 40; loss: 0.59; acc: 0.88
Batch: 60; loss: 0.91; acc: 0.75
Batch: 80; loss: 1.02; acc: 0.7
Batch: 100; loss: 0.92; acc: 0.81
Batch: 120; loss: 1.07; acc: 0.72
Batch: 140; loss: 0.51; acc: 0.83
Val Epoch over. val_loss: 0.8421365083402889; val_accuracy: 0.7706011146496815 

The current subspace-distance is: 8.38465439301217e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.97; acc: 0.75
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.84
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.63; acc: 0.86
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.8407581339706667e-05
8.89404327608645e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.26376972349870736; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 8.89404327608645e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.97
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.83
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.84
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.88
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.8193919206387363e-05
8.74748729984276e-06
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.27735835629378913; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 8.74748729984276e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.84
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.84
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.9190599889261648e-05
8.916855222196318e-06
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19943356817694985; val_accuracy: 0.9372014331210191 

The current subspace-distance is: 8.916855222196318e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.59; acc: 0.88
Batch: 260; loss: 0.26; acc: 0.88
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.92
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.918531208706554e-05
8.646804417367093e-06
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20357432743166662; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 8.646804417367093e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.48; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.9137230740161613e-05
7.977921995916404e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20246245606452418; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 7.977921995916404e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.67; acc: 0.84
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.98
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.986857907671947e-05
9.768620657268912e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.27724655715238516; val_accuracy: 0.9137141719745223 

The current subspace-distance is: 9.768620657268912e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.91
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.84
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.917542587965727e-05
8.99011138244532e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.23745580295183857; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 8.99011138244532e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.55; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.9480786906788126e-05
8.873191291058902e-06
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2252775413832467; val_accuracy: 0.9322253184713376 

The current subspace-distance is: 8.873191291058902e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.21; acc: 0.97
Batch: 580; loss: 0.51; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.8912674679304473e-05
8.86490579432575e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2009290776031602; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 8.86490579432575e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.44; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.905669498431962e-05
8.629557669337373e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.89
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19239910451137715; val_accuracy: 0.9417794585987261 

The current subspace-distance is: 8.629557669337373e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.8895978175569326e-05
8.985908607428428e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21113503708913448; val_accuracy: 0.9384952229299363 

The current subspace-distance is: 8.985908607428428e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.9474669645424e-05
9.561598744767252e-06
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2534823392986492; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 9.561598744767252e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.89
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.42; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.9436947443173267e-05
8.670719580550212e-06
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18543636640474484; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 8.670719580550212e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.86
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.23; acc: 0.88
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.9169426852604374e-05
8.5874553406029e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17818665494371183; val_accuracy: 0.9433718152866242 

The current subspace-distance is: 8.5874553406029e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.49; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.46; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.08; acc: 1.0
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.902634696511086e-05
9.161913112620823e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1799853186176461; val_accuracy: 0.9456608280254777 

The current subspace-distance is: 9.161913112620823e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.92219701805152e-05
7.953288331918884e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1922374201262263; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 7.953288331918884e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.89
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.918955397035461e-05
8.909128155210055e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1846511683717465; val_accuracy: 0.9430732484076433 

The current subspace-distance is: 8.909128155210055e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.88
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.07; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.06; acc: 1.0
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.987657717312686e-05
9.255617442249786e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.91
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18033833385320605; val_accuracy: 0.9445660828025477 

The current subspace-distance is: 9.255617442249786e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.91
Batch: 240; loss: 0.1; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.07; acc: 1.0
Batch: 660; loss: 0.24; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.919985490734689e-05
8.317045285366476e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1882387629004231; val_accuracy: 0.942078025477707 

The current subspace-distance is: 8.317045285366476e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.9744227504124865e-05
9.34670060814824e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18119536216851254; val_accuracy: 0.9448646496815286 

The current subspace-distance is: 9.34670060814824e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.42; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.912671880039852e-05
8.453418558929116e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18370838025525496; val_accuracy: 0.9440684713375797 

The current subspace-distance is: 8.453418558929116e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.95
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.86
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.9727940273005515e-05
8.929426257964224e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1824098449603767; val_accuracy: 0.9426751592356688 

The current subspace-distance is: 8.929426257964224e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.98
Batch: 460; loss: 0.33; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.06; acc: 1.0
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.94557903544046e-05
9.305400453740731e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18011406333939095; val_accuracy: 0.9441679936305732 

The current subspace-distance is: 9.305400453740731e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.92
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.88
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.9595445084851235e-05
9.05672277440317e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17436845145028107; val_accuracy: 0.9468550955414012 

The current subspace-distance is: 9.05672277440317e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.4; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.9776900191791356e-05
8.72750661073951e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17327059161179004; val_accuracy: 0.9473527070063694 

The current subspace-distance is: 8.72750661073951e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.51; acc: 0.88
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.9269207516335882e-05
9.542512998450547e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17254525135348367; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 9.542512998450547e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.9615612220368348e-05
9.316099749412388e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1734928613718433; val_accuracy: 0.9484474522292994 

The current subspace-distance is: 9.316099749412388e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.27; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.9492133762687445e-05
8.488996172673069e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1758758640391337; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 8.488996172673069e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.88
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.34; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.9494041882571764e-05
8.430526577285491e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17537501188600138; val_accuracy: 0.9464570063694268 

The current subspace-distance is: 8.430526577285491e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.924996442743577e-05
9.217313163389917e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17635019968269736; val_accuracy: 0.9453622611464968 

The current subspace-distance is: 9.217313163389917e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

3.0242905268096365e-05
8.687660738360137e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17495719363592613; val_accuracy: 0.9472531847133758 

The current subspace-distance is: 8.687660738360137e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.16; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.44; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.89
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.9694887416553684e-05
9.35518528422108e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17531251515837232; val_accuracy: 0.9459593949044586 

The current subspace-distance is: 9.35518528422108e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.09; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.9884206014685333e-05
9.767357369128149e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17224046728532216; val_accuracy: 0.948546974522293 

The current subspace-distance is: 9.767357369128149e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.15; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

3.0320679798023775e-05
8.115308446576819e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1723089975714209; val_accuracy: 0.9486464968152867 

The current subspace-distance is: 8.115308446576819e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.33; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.42; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.9783748686895706e-05
9.107210644287989e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17227319550884376; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 9.107210644287989e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.9908485885243863e-05
8.648113180242945e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17295645518453828; val_accuracy: 0.9483479299363057 

The current subspace-distance is: 8.648113180242945e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.43; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.39; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.927984496636782e-05
8.410203918174375e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17239883644091095; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 8.410203918174375e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.88
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.86
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.92
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.92
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

3.0116529160295613e-05
9.591160051058978e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17250026154456435; val_accuracy: 0.9487460191082803 

The current subspace-distance is: 9.591160051058978e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.97
Batch: 740; loss: 0.07; acc: 1.0
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.9760116376564838e-05
9.19971353141591e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17224502358229676; val_accuracy: 0.9486464968152867 

The current subspace-distance is: 9.19971353141591e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.05; acc: 1.0
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.08; acc: 1.0
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.9810669730068184e-05
8.855350642988924e-06
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1718699418328655; val_accuracy: 0.9482484076433121 

The current subspace-distance is: 8.855350642988924e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.1; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.36; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.55; acc: 0.91
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.9875856853323057e-05
9.461726222070865e-06
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17204545886154957; val_accuracy: 0.9482484076433121 

The current subspace-distance is: 9.461726222070865e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.27; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.91
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.92997901851777e-05
9.125062206294388e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1724564639115884; val_accuracy: 0.9477507961783439 

The current subspace-distance is: 9.125062206294388e-06 

plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 69983
elements in E: 9887000
fraction nonzero: 0.007078284616162638
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.29; acc: 0.2
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.29; acc: 0.2
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.31; acc: 0.06
Batch: 220; loss: 2.3; acc: 0.09
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.17
Batch: 280; loss: 2.31; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.11
Batch: 320; loss: 2.31; acc: 0.14
Batch: 340; loss: 2.31; acc: 0.0
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.3; acc: 0.17
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.3; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.2
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.3; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.29; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.12
Batch: 760; loss: 2.29; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.11 

1.0921022294496652e-05
9.684314363767044e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.05
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.28; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.09
Val Epoch over. val_loss: 2.287780922689256; val_accuracy: 0.10648885350318471 

The current subspace-distance is: 9.684314363767044e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.28; acc: 0.08
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.28; acc: 0.22
Batch: 80; loss: 2.27; acc: 0.27
Batch: 100; loss: 2.28; acc: 0.19
Batch: 120; loss: 2.28; acc: 0.23
Batch: 140; loss: 2.27; acc: 0.19
Batch: 160; loss: 2.25; acc: 0.31
Batch: 180; loss: 2.21; acc: 0.38
Batch: 200; loss: 2.23; acc: 0.27
Batch: 220; loss: 2.21; acc: 0.28
Batch: 240; loss: 2.17; acc: 0.25
Batch: 260; loss: 2.18; acc: 0.2
Batch: 280; loss: 2.08; acc: 0.3
Batch: 300; loss: 2.03; acc: 0.3
Batch: 320; loss: 1.8; acc: 0.31
Batch: 340; loss: 1.43; acc: 0.55
Batch: 360; loss: 1.43; acc: 0.55
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.16; acc: 0.58
Batch: 420; loss: 1.25; acc: 0.47
Batch: 440; loss: 1.08; acc: 0.66
Batch: 460; loss: 0.94; acc: 0.72
Batch: 480; loss: 0.94; acc: 0.7
Batch: 500; loss: 0.67; acc: 0.8
Batch: 520; loss: 1.26; acc: 0.59
Batch: 540; loss: 0.57; acc: 0.8
Batch: 560; loss: 0.81; acc: 0.69
Batch: 580; loss: 0.65; acc: 0.83
Batch: 600; loss: 0.68; acc: 0.78
Batch: 620; loss: 0.72; acc: 0.73
Batch: 640; loss: 0.66; acc: 0.81
Batch: 660; loss: 0.88; acc: 0.77
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.81; acc: 0.77
Batch: 720; loss: 1.19; acc: 0.58
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.57; acc: 0.78
Batch: 780; loss: 0.52; acc: 0.81
Train Epoch over. train_loss: 1.44; train_accuracy: 0.52 

1.656089079915546e-05
6.100370683270739e-06
Batch: 0; loss: 0.72; acc: 0.75
Batch: 20; loss: 1.01; acc: 0.66
Batch: 40; loss: 0.49; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.73
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.81; acc: 0.72
Batch: 120; loss: 1.22; acc: 0.73
Batch: 140; loss: 0.55; acc: 0.86
Val Epoch over. val_loss: 0.8110105664866745; val_accuracy: 0.7465167197452229 

The current subspace-distance is: 6.100370683270739e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.67
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.67; acc: 0.83
Batch: 220; loss: 0.83; acc: 0.69
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.9; acc: 0.75
Batch: 280; loss: 0.52; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.64; acc: 0.75
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.62; acc: 0.81
Batch: 400; loss: 0.54; acc: 0.84
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.59; acc: 0.84
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.86
Batch: 620; loss: 0.64; acc: 0.78
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.61; acc: 0.83
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.83
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.2763502784073353e-05
7.357733920798637e-06
Batch: 0; loss: 0.97; acc: 0.75
Batch: 20; loss: 1.19; acc: 0.7
Batch: 40; loss: 0.67; acc: 0.84
Batch: 60; loss: 0.87; acc: 0.78
Batch: 80; loss: 1.17; acc: 0.77
Batch: 100; loss: 0.73; acc: 0.81
Batch: 120; loss: 1.48; acc: 0.64
Batch: 140; loss: 0.59; acc: 0.86
Val Epoch over. val_loss: 0.8772273524931282; val_accuracy: 0.7674164012738853 

The current subspace-distance is: 7.357733920798637e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.27; acc: 0.66
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.48; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.57; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.62; acc: 0.81
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.45; acc: 0.81
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.4241493520094082e-05
7.1618637775827665e-06
Batch: 0; loss: 0.73; acc: 0.81
Batch: 20; loss: 0.89; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.68; acc: 0.81
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 1.09; acc: 0.66
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.6446860455403662; val_accuracy: 0.8140923566878981 

The current subspace-distance is: 7.1618637775827665e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.99; acc: 0.77
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.5651735995779745e-05
8.875768799043726e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.28659716882048897; val_accuracy: 0.9107285031847133 

The current subspace-distance is: 8.875768799043726e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.88
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.5; acc: 0.81
Batch: 620; loss: 0.33; acc: 0.83
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.6530882678343914e-05
8.53095934871817e-06
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.77
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.83
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.55; acc: 0.88
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.4058707362147653; val_accuracy: 0.8667396496815286 

The current subspace-distance is: 8.53095934871817e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.86
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.51; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.6982688723364845e-05
8.169510692823678e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.64; acc: 0.84
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.84
Batch: 80; loss: 0.6; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.86
Batch: 120; loss: 1.15; acc: 0.77
Batch: 140; loss: 0.18; acc: 0.91
Val Epoch over. val_loss: 0.5090539948955463; val_accuracy: 0.852906050955414 

The current subspace-distance is: 8.169510692823678e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.97
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.6; acc: 0.83
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.7616795705398545e-05
9.079938536160626e-06
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.74; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.88
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.425930932970943; val_accuracy: 0.872312898089172 

The current subspace-distance is: 9.079938536160626e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.38; acc: 0.83
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.07; acc: 1.0
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.88
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.08; acc: 1.0
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.66; acc: 0.75
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.802238850563299e-05
8.367016562260687e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.30846457109804365; val_accuracy: 0.9048566878980892 

The current subspace-distance is: 8.367016562260687e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.7767722713178955e-05
8.670201168570202e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.27302274212336086; val_accuracy: 0.9152070063694268 

The current subspace-distance is: 8.670201168570202e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.88
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.8153353923698887e-05
8.60134696267778e-06
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19533246385443742; val_accuracy: 0.9403861464968153 

The current subspace-distance is: 8.60134696267778e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.95
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.98
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.8336966352071613e-05
8.865635209076572e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.17496031564274792; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 8.865635209076572e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.8433953048079275e-05
9.63172806223156e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17011843925448739; val_accuracy: 0.9470541401273885 

The current subspace-distance is: 9.63172806223156e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.8092486900277436e-05
9.111739018408116e-06
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.3119701942203531; val_accuracy: 0.9030652866242038 

The current subspace-distance is: 9.111739018408116e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.91
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.4; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.94 

2.8962518626940437e-05
1.0115471013705246e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1756716162488339; val_accuracy: 0.943968949044586 

The current subspace-distance is: 1.0115471013705246e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.32; acc: 0.86
Batch: 460; loss: 0.1; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.785229116852861e-05
8.84631481312681e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.25537001811395027; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 8.84631481312681e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.8974014639970846e-05
8.726301530259661e-06
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.16549986338681855; val_accuracy: 0.9486464968152867 

The current subspace-distance is: 8.726301530259661e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.41; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.48; acc: 0.88
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.8145404940005392e-05
8.612587407696992e-06
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20123986368346367; val_accuracy: 0.9368033439490446 

The current subspace-distance is: 8.612587407696992e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.8335838578641415e-05
8.956544661486987e-06
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15004624656526147; val_accuracy: 0.955015923566879 

The current subspace-distance is: 8.956544661486987e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.8289527108427137e-05
9.030450200953055e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.24238236281712344; val_accuracy: 0.9272492038216561 

The current subspace-distance is: 9.030450200953055e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.837547981471289e-05
9.230618161382154e-06
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.147858778738482; val_accuracy: 0.9544187898089171 

The current subspace-distance is: 9.230618161382154e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8504524379968643e-05
8.995705684355926e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14617940892649303; val_accuracy: 0.9568073248407644 

The current subspace-distance is: 8.995705684355926e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.98
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.861981738533359e-05
9.014227543957531e-06
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1602597292631295; val_accuracy: 0.9495421974522293 

The current subspace-distance is: 9.014227543957531e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.2; acc: 0.91
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.887475238821935e-05
9.187619070871733e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14759697142252876; val_accuracy: 0.95421974522293 

The current subspace-distance is: 9.187619070871733e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.89
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.1; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.79493960988475e-05
8.713267561688554e-06
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1568849859937171; val_accuracy: 0.9525278662420382 

The current subspace-distance is: 8.713267561688554e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.92
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.89
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8795566322514787e-05
8.754039299674332e-06
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1490830742771838; val_accuracy: 0.9556130573248408 

The current subspace-distance is: 8.754039299674332e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.15; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.852100988093298e-05
9.16269164008554e-06
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1524731604868819; val_accuracy: 0.9524283439490446 

The current subspace-distance is: 9.16269164008554e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8716427550534718e-05
9.44819112191908e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15738283606708808; val_accuracy: 0.9515326433121019 

The current subspace-distance is: 9.44819112191908e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.05; acc: 1.0
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.88
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.8373435270623304e-05
9.023410711961333e-06
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16575106095736195; val_accuracy: 0.949343152866242 

The current subspace-distance is: 9.023410711961333e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.22; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.843317088263575e-05
8.880857421900146e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16305770372651565; val_accuracy: 0.9511345541401274 

The current subspace-distance is: 8.880857421900146e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.89
Batch: 20; loss: 0.05; acc: 1.0
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.35; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.02; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.33; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8498696337919682e-05
8.676806828589179e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.144283356999231; val_accuracy: 0.9548168789808917 

The current subspace-distance is: 8.676806828589179e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.34; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.37; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.95
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8901840778416954e-05
9.21348237170605e-06
Batch: 0; loss: 0.08; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14293090220849225; val_accuracy: 0.9567078025477707 

The current subspace-distance is: 9.21348237170605e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.98
Batch: 300; loss: 0.28; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8481839763117023e-05
9.422366019862238e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14127586105731643; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 9.422366019862238e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.936195960501209e-05
9.155137377092615e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1399143192632373; val_accuracy: 0.9573049363057324 

The current subspace-distance is: 9.155137377092615e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.03; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.33; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.08; acc: 1.0
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.886981201299932e-05
9.706433957035188e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1478650951224148; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 9.706433957035188e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.856667197193019e-05
8.886356226867065e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.01; acc: 0.98
Val Epoch over. val_loss: 0.13852024929016638; val_accuracy: 0.9575039808917197 

The current subspace-distance is: 8.886356226867065e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.9051680030534044e-05
9.237817721441388e-06
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1399668371720109; val_accuracy: 0.956906847133758 

The current subspace-distance is: 9.237817721441388e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.08; acc: 1.0
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8934322472196072e-05
9.349217179988045e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14069837173980893; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 9.349217179988045e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.07; acc: 1.0
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8862752515124157e-05
9.5048353614402e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1402260635083743; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.5048353614402e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.9087406801409088e-05
9.638880328566302e-06
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.14545015689388963; val_accuracy: 0.9561106687898089 

The current subspace-distance is: 9.638880328566302e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.07; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.90767948172288e-05
9.020904144563247e-06
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1388740795812789; val_accuracy: 0.9583996815286624 

The current subspace-distance is: 9.020904144563247e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8914568247273564e-05
9.828010661294684e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13899541075584615; val_accuracy: 0.9583996815286624 

The current subspace-distance is: 9.828010661294684e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.98
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.903359563788399e-05
9.577650416758843e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.01; acc: 0.98
Val Epoch over. val_loss: 0.14018477539822555; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 9.577650416758843e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.90831030724803e-05
9.556338227412198e-06
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14082367011719638; val_accuracy: 0.9574044585987261 

The current subspace-distance is: 9.556338227412198e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.98
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.875075369956903e-05
9.244255124940537e-06
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14122577810031214; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.244255124940537e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.9168180844862945e-05
9.717853572510649e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14021566558842827; val_accuracy: 0.9579020700636943 

The current subspace-distance is: 9.717853572510649e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.07; acc: 1.0
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8292932256590575e-05
8.861452442943119e-06
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.01; acc: 0.98
Val Epoch over. val_loss: 0.1394939232309153; val_accuracy: 0.9573049363057324 

The current subspace-distance is: 8.861452442943119e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.884511741285678e-05
9.163888535113074e-06
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14039268579547573; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.163888535113074e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.954978117486462e-05
9.897081326926127e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1400361755376409; val_accuracy: 0.9563097133757962 

The current subspace-distance is: 9.897081326926127e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.08; acc: 1.0
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.8761696739820763e-05
8.690824870427605e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1404901968825395; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 8.690824870427605e-06 

plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
plots/subspace_training/reg_lenet_2/2020-01-22 20:48:50/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
