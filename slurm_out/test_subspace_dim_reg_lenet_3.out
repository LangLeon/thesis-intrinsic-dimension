model : reg_lenet_3
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 1
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : False
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 14:40:21
nonzero elements in E: 2138
elements in E: 449900
fraction nonzero: 0.0047521671482551675
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.31; acc: 0.16
Batch: 160; loss: 2.32; acc: 0.05
Batch: 180; loss: 2.32; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.31; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.08
Batch: 380; loss: 2.3; acc: 0.08
Batch: 400; loss: 2.3; acc: 0.11
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.31; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.12
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.31; acc: 0.08
Batch: 520; loss: 2.31; acc: 0.06
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.29; acc: 0.16
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.29; acc: 0.17
Batch: 680; loss: 2.31; acc: 0.09
Batch: 700; loss: 2.3; acc: 0.06
Batch: 720; loss: 2.3; acc: 0.16
Batch: 740; loss: 2.31; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.06
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.11
Val Epoch over. val_loss: 2.3027772660468036; val_accuracy: 0.09623805732484077 

The current subspace-distance is: 1.991510316656786e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.31; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.3; acc: 0.11
Batch: 180; loss: 2.31; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.11
Batch: 240; loss: 2.31; acc: 0.08
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.29; acc: 0.2
Batch: 300; loss: 2.28; acc: 0.19
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.3; acc: 0.16
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.12
Batch: 440; loss: 2.31; acc: 0.02
Batch: 460; loss: 2.3; acc: 0.06
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.08
Batch: 520; loss: 2.31; acc: 0.08
Batch: 540; loss: 2.32; acc: 0.02
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.3; acc: 0.06
Batch: 600; loss: 2.31; acc: 0.06
Batch: 620; loss: 2.3; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.12
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.28; acc: 0.2
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.3; acc: 0.09
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.29; acc: 0.17
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.11
Val Epoch over. val_loss: 2.300465371198715; val_accuracy: 0.09623805732484077 

The current subspace-distance is: 2.5918182018358493e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.06
Batch: 20; loss: 2.31; acc: 0.03
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.05
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.08
Batch: 240; loss: 2.31; acc: 0.03
Batch: 260; loss: 2.31; acc: 0.05
Batch: 280; loss: 2.3; acc: 0.14
Batch: 300; loss: 2.3; acc: 0.14
Batch: 320; loss: 2.28; acc: 0.17
Batch: 340; loss: 2.3; acc: 0.12
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.28; acc: 0.12
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.3; acc: 0.08
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.05
Batch: 480; loss: 2.28; acc: 0.16
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.3; acc: 0.09
Batch: 540; loss: 2.3; acc: 0.06
Batch: 560; loss: 2.31; acc: 0.06
Batch: 580; loss: 2.31; acc: 0.08
Batch: 600; loss: 2.31; acc: 0.06
Batch: 620; loss: 2.31; acc: 0.03
Batch: 640; loss: 2.28; acc: 0.16
Batch: 660; loss: 2.29; acc: 0.17
Batch: 680; loss: 2.3; acc: 0.16
Batch: 700; loss: 2.31; acc: 0.03
Batch: 720; loss: 2.3; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.05
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.3; acc: 0.09
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.11
Val Epoch over. val_loss: 2.2980738020246956; val_accuracy: 0.09623805732484077 

The current subspace-distance is: 3.435816552155302e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.16
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.29; acc: 0.12
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.31; acc: 0.08
Batch: 240; loss: 2.28; acc: 0.17
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.05
Batch: 300; loss: 2.3; acc: 0.09
Batch: 320; loss: 2.31; acc: 0.03
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.29; acc: 0.06
Batch: 380; loss: 2.3; acc: 0.06
Batch: 400; loss: 2.29; acc: 0.06
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.31; acc: 0.06
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.3; acc: 0.14
Batch: 520; loss: 2.29; acc: 0.12
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.29; acc: 0.17
Batch: 580; loss: 2.3; acc: 0.11
Batch: 600; loss: 2.28; acc: 0.11
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.3; acc: 0.08
Batch: 660; loss: 2.3; acc: 0.11
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.05
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.31; acc: 0.06
Batch: 760; loss: 2.31; acc: 0.03
Batch: 780; loss: 2.3; acc: 0.05
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.11
Val Epoch over. val_loss: 2.296666772502243; val_accuracy: 0.09623805732484077 

The current subspace-distance is: 5.071766736364225e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.12
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.29; acc: 0.09
Batch: 220; loss: 2.3; acc: 0.08
Batch: 240; loss: 2.31; acc: 0.06
Batch: 260; loss: 2.28; acc: 0.12
Batch: 280; loss: 2.28; acc: 0.16
Batch: 300; loss: 2.3; acc: 0.06
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.05
Batch: 380; loss: 2.3; acc: 0.06
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.11
Batch: 460; loss: 2.3; acc: 0.06
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.08
Batch: 520; loss: 2.29; acc: 0.08
Batch: 540; loss: 2.29; acc: 0.11
Batch: 560; loss: 2.3; acc: 0.08
Batch: 580; loss: 2.3; acc: 0.14
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.28; acc: 0.14
Batch: 640; loss: 2.3; acc: 0.05
Batch: 660; loss: 2.3; acc: 0.16
Batch: 680; loss: 2.3; acc: 0.06
Batch: 700; loss: 2.3; acc: 0.02
Batch: 720; loss: 2.31; acc: 0.08
Batch: 740; loss: 2.29; acc: 0.06
Batch: 760; loss: 2.28; acc: 0.11
Batch: 780; loss: 2.3; acc: 0.06
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.28; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.11
Val Epoch over. val_loss: 2.294503031262926; val_accuracy: 0.09643710191082802 

The current subspace-distance is: 6.000147095619468e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.05
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.05
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.03
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.29; acc: 0.08
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.16
Batch: 220; loss: 2.29; acc: 0.08
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.08
Batch: 280; loss: 2.3; acc: 0.08
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.29; acc: 0.09
Batch: 440; loss: 2.28; acc: 0.12
Batch: 460; loss: 2.28; acc: 0.16
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.29; acc: 0.09
Batch: 540; loss: 2.29; acc: 0.16
Batch: 560; loss: 2.28; acc: 0.16
Batch: 580; loss: 2.3; acc: 0.06
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.08
Batch: 640; loss: 2.3; acc: 0.06
Batch: 660; loss: 2.3; acc: 0.03
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.27; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.28; acc: 0.16
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.3; acc: 0.06
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.17
Batch: 40; loss: 2.28; acc: 0.11
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.28; acc: 0.17
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2896119819325245; val_accuracy: 0.10589171974522293 

The current subspace-distance is: 6.352895070449449e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.28; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.28; acc: 0.22
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.05
Batch: 220; loss: 2.29; acc: 0.14
Batch: 240; loss: 2.28; acc: 0.08
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.08
Batch: 300; loss: 2.28; acc: 0.16
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.06
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.29; acc: 0.09
Batch: 420; loss: 2.28; acc: 0.11
Batch: 440; loss: 2.28; acc: 0.19
Batch: 460; loss: 2.3; acc: 0.06
Batch: 480; loss: 2.29; acc: 0.16
Batch: 500; loss: 2.28; acc: 0.08
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.27; acc: 0.23
Batch: 560; loss: 2.29; acc: 0.12
Batch: 580; loss: 2.28; acc: 0.09
Batch: 600; loss: 2.28; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.28; acc: 0.12
Batch: 660; loss: 2.28; acc: 0.16
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.28; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.09
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.23
Batch: 40; loss: 2.27; acc: 0.17
Batch: 60; loss: 2.27; acc: 0.17
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.27; acc: 0.14
Batch: 120; loss: 2.27; acc: 0.17
Batch: 140; loss: 2.28; acc: 0.14
Val Epoch over. val_loss: 2.28499698790775; val_accuracy: 0.13465366242038215 

The current subspace-distance is: 6.8430522333073895e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.03
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.28; acc: 0.22
Batch: 160; loss: 2.28; acc: 0.16
Batch: 180; loss: 2.28; acc: 0.16
Batch: 200; loss: 2.27; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.23
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.3; acc: 0.06
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.26; acc: 0.34
Batch: 320; loss: 2.28; acc: 0.16
Batch: 340; loss: 2.28; acc: 0.14
Batch: 360; loss: 2.28; acc: 0.17
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.27; acc: 0.16
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.27; acc: 0.19
Batch: 460; loss: 2.28; acc: 0.12
Batch: 480; loss: 2.27; acc: 0.19
Batch: 500; loss: 2.28; acc: 0.08
Batch: 520; loss: 2.28; acc: 0.17
Batch: 540; loss: 2.28; acc: 0.17
Batch: 560; loss: 2.27; acc: 0.23
Batch: 580; loss: 2.28; acc: 0.19
Batch: 600; loss: 2.28; acc: 0.2
Batch: 620; loss: 2.28; acc: 0.16
Batch: 640; loss: 2.27; acc: 0.2
Batch: 660; loss: 2.27; acc: 0.22
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.28; acc: 0.17
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.27; acc: 0.11
Batch: 760; loss: 2.28; acc: 0.12
Batch: 780; loss: 2.28; acc: 0.17
Train Epoch over. train_loss: 2.28; train_accuracy: 0.16 

Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.28; acc: 0.3
Batch: 40; loss: 2.26; acc: 0.22
Batch: 60; loss: 2.27; acc: 0.27
Batch: 80; loss: 2.27; acc: 0.19
Batch: 100; loss: 2.26; acc: 0.22
Batch: 120; loss: 2.27; acc: 0.27
Batch: 140; loss: 2.27; acc: 0.22
Val Epoch over. val_loss: 2.2777001888129362; val_accuracy: 0.19406847133757962 

The current subspace-distance is: 9.92481545836199e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.27; acc: 0.19
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.25; acc: 0.34
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.27; acc: 0.27
Batch: 140; loss: 2.27; acc: 0.19
Batch: 160; loss: 2.28; acc: 0.23
Batch: 180; loss: 2.26; acc: 0.22
Batch: 200; loss: 2.28; acc: 0.22
Batch: 220; loss: 2.27; acc: 0.23
Batch: 240; loss: 2.27; acc: 0.23
Batch: 260; loss: 2.28; acc: 0.17
Batch: 280; loss: 2.26; acc: 0.27
Batch: 300; loss: 2.28; acc: 0.16
Batch: 320; loss: 2.29; acc: 0.14
Batch: 340; loss: 2.28; acc: 0.27
Batch: 360; loss: 2.27; acc: 0.22
Batch: 380; loss: 2.28; acc: 0.08
Batch: 400; loss: 2.27; acc: 0.16
Batch: 420; loss: 2.28; acc: 0.19
Batch: 440; loss: 2.28; acc: 0.11
Batch: 460; loss: 2.27; acc: 0.27
Batch: 480; loss: 2.27; acc: 0.25
Batch: 500; loss: 2.28; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.22
Batch: 540; loss: 2.25; acc: 0.3
Batch: 560; loss: 2.27; acc: 0.27
Batch: 580; loss: 2.28; acc: 0.19
Batch: 600; loss: 2.26; acc: 0.25
Batch: 620; loss: 2.26; acc: 0.28
Batch: 640; loss: 2.26; acc: 0.22
Batch: 660; loss: 2.28; acc: 0.23
Batch: 680; loss: 2.27; acc: 0.19
Batch: 700; loss: 2.26; acc: 0.23
Batch: 720; loss: 2.28; acc: 0.2
Batch: 740; loss: 2.25; acc: 0.25
Batch: 760; loss: 2.26; acc: 0.27
Batch: 780; loss: 2.26; acc: 0.22
Train Epoch over. train_loss: 2.27; train_accuracy: 0.21 

Batch: 0; loss: 2.28; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.25
Batch: 40; loss: 2.23; acc: 0.28
Batch: 60; loss: 2.25; acc: 0.25
Batch: 80; loss: 2.25; acc: 0.3
Batch: 100; loss: 2.23; acc: 0.34
Batch: 120; loss: 2.25; acc: 0.27
Batch: 140; loss: 2.26; acc: 0.33
Val Epoch over. val_loss: 2.2635243683104305; val_accuracy: 0.23168789808917198 

The current subspace-distance is: 1.1829173672595061e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.25
Batch: 20; loss: 2.28; acc: 0.16
Batch: 40; loss: 2.26; acc: 0.23
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.26; acc: 0.31
Batch: 120; loss: 2.25; acc: 0.22
Batch: 140; loss: 2.24; acc: 0.27
Batch: 160; loss: 2.26; acc: 0.23
Batch: 180; loss: 2.27; acc: 0.22
Batch: 200; loss: 2.28; acc: 0.27
Batch: 220; loss: 2.26; acc: 0.2
Batch: 240; loss: 2.25; acc: 0.22
Batch: 260; loss: 2.26; acc: 0.25
Batch: 280; loss: 2.26; acc: 0.17
Batch: 300; loss: 2.26; acc: 0.22
Batch: 320; loss: 2.25; acc: 0.28
Batch: 340; loss: 2.27; acc: 0.17
Batch: 360; loss: 2.25; acc: 0.28
Batch: 380; loss: 2.25; acc: 0.23
Batch: 400; loss: 2.25; acc: 0.22
Batch: 420; loss: 2.19; acc: 0.45
Batch: 440; loss: 2.27; acc: 0.25
Batch: 460; loss: 2.28; acc: 0.14
Batch: 480; loss: 2.25; acc: 0.2
Batch: 500; loss: 2.26; acc: 0.25
Batch: 520; loss: 2.27; acc: 0.08
Batch: 540; loss: 2.27; acc: 0.11
Batch: 560; loss: 2.24; acc: 0.23
Batch: 580; loss: 2.27; acc: 0.12
Batch: 600; loss: 2.26; acc: 0.3
Batch: 620; loss: 2.25; acc: 0.25
Batch: 640; loss: 2.23; acc: 0.23
Batch: 660; loss: 2.27; acc: 0.17
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.26; acc: 0.19
Batch: 720; loss: 2.25; acc: 0.17
Batch: 740; loss: 2.27; acc: 0.12
Batch: 760; loss: 2.25; acc: 0.14
Batch: 780; loss: 2.23; acc: 0.2
Train Epoch over. train_loss: 2.26; train_accuracy: 0.22 

Batch: 0; loss: 2.28; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.22
Batch: 40; loss: 2.21; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.19
Batch: 80; loss: 2.22; acc: 0.23
Batch: 100; loss: 2.19; acc: 0.36
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.25; acc: 0.3
Val Epoch over. val_loss: 2.2464252717935356; val_accuracy: 0.21666003184713375 

The current subspace-distance is: 1.4101616216066759e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.22; acc: 0.2
Batch: 20; loss: 2.25; acc: 0.19
Batch: 40; loss: 2.22; acc: 0.23
Batch: 60; loss: 2.22; acc: 0.28
Batch: 80; loss: 2.27; acc: 0.2
Batch: 100; loss: 2.23; acc: 0.19
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.27; acc: 0.22
Batch: 160; loss: 2.24; acc: 0.25
Batch: 180; loss: 2.25; acc: 0.27
Batch: 200; loss: 2.25; acc: 0.17
Batch: 220; loss: 2.29; acc: 0.16
Batch: 240; loss: 2.23; acc: 0.2
Batch: 260; loss: 2.25; acc: 0.22
Batch: 280; loss: 2.22; acc: 0.28
Batch: 300; loss: 2.28; acc: 0.19
Batch: 320; loss: 2.23; acc: 0.27
Batch: 340; loss: 2.21; acc: 0.27
Batch: 360; loss: 2.23; acc: 0.22
Batch: 380; loss: 2.23; acc: 0.17
Batch: 400; loss: 2.25; acc: 0.23
Batch: 420; loss: 2.25; acc: 0.22
Batch: 440; loss: 2.25; acc: 0.16
Batch: 460; loss: 2.26; acc: 0.17
Batch: 480; loss: 2.25; acc: 0.19
Batch: 500; loss: 2.29; acc: 0.2
Batch: 520; loss: 2.25; acc: 0.22
Batch: 540; loss: 2.23; acc: 0.16
Batch: 560; loss: 2.27; acc: 0.17
Batch: 580; loss: 2.27; acc: 0.31
Batch: 600; loss: 2.19; acc: 0.25
Batch: 620; loss: 2.25; acc: 0.2
Batch: 640; loss: 2.24; acc: 0.2
Batch: 660; loss: 2.24; acc: 0.19
Batch: 680; loss: 2.24; acc: 0.23
Batch: 700; loss: 2.23; acc: 0.27
Batch: 720; loss: 2.24; acc: 0.17
Batch: 740; loss: 2.22; acc: 0.25
Batch: 760; loss: 2.29; acc: 0.17
Batch: 780; loss: 2.31; acc: 0.12
Train Epoch over. train_loss: 2.25; train_accuracy: 0.21 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.27; acc: 0.22
Batch: 40; loss: 2.2; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.19
Batch: 80; loss: 2.21; acc: 0.22
Batch: 100; loss: 2.18; acc: 0.33
Batch: 120; loss: 2.23; acc: 0.14
Batch: 140; loss: 2.24; acc: 0.28
Val Epoch over. val_loss: 2.239792021976155; val_accuracy: 0.20879777070063693 

The current subspace-distance is: 1.5186276868917048e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 2.25; acc: 0.23
Batch: 20; loss: 2.25; acc: 0.12
Batch: 40; loss: 2.27; acc: 0.16
Batch: 60; loss: 2.26; acc: 0.25
Batch: 80; loss: 2.24; acc: 0.19
Batch: 100; loss: 2.27; acc: 0.14
Batch: 120; loss: 2.23; acc: 0.25
Batch: 140; loss: 2.2; acc: 0.33
Batch: 160; loss: 2.24; acc: 0.28
Batch: 180; loss: 2.2; acc: 0.23
Batch: 200; loss: 2.26; acc: 0.2
Batch: 220; loss: 2.2; acc: 0.25
Batch: 240; loss: 2.28; acc: 0.17
Batch: 260; loss: 2.24; acc: 0.25
Batch: 280; loss: 2.24; acc: 0.2
Batch: 300; loss: 2.2; acc: 0.22
Batch: 320; loss: 2.2; acc: 0.25
Batch: 340; loss: 2.22; acc: 0.22
Batch: 360; loss: 2.18; acc: 0.28
Batch: 380; loss: 2.28; acc: 0.19
Batch: 400; loss: 2.24; acc: 0.14
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.2; acc: 0.28
Batch: 460; loss: 2.26; acc: 0.16
Batch: 480; loss: 2.24; acc: 0.16
Batch: 500; loss: 2.24; acc: 0.19
Batch: 520; loss: 2.28; acc: 0.12
Batch: 540; loss: 2.26; acc: 0.14
Batch: 560; loss: 2.24; acc: 0.22
Batch: 580; loss: 2.24; acc: 0.19
Batch: 600; loss: 2.24; acc: 0.17
Batch: 620; loss: 2.2; acc: 0.25
Batch: 640; loss: 2.23; acc: 0.22
Batch: 660; loss: 2.27; acc: 0.14
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.23; acc: 0.14
Batch: 720; loss: 2.27; acc: 0.17
Batch: 740; loss: 2.26; acc: 0.27
Batch: 760; loss: 2.26; acc: 0.16
Batch: 780; loss: 2.23; acc: 0.22
Train Epoch over. train_loss: 2.24; train_accuracy: 0.2 

Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.23
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.19
Batch: 80; loss: 2.21; acc: 0.22
Batch: 100; loss: 2.16; acc: 0.3
Batch: 120; loss: 2.23; acc: 0.11
Batch: 140; loss: 2.23; acc: 0.22
Val Epoch over. val_loss: 2.2338912502215926; val_accuracy: 0.20660828025477707 

The current subspace-distance is: 1.7370926798321307e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.25; acc: 0.17
Batch: 60; loss: 2.22; acc: 0.2
Batch: 80; loss: 2.23; acc: 0.2
Batch: 100; loss: 2.21; acc: 0.25
Batch: 120; loss: 2.27; acc: 0.17
Batch: 140; loss: 2.25; acc: 0.19
Batch: 160; loss: 2.24; acc: 0.14
Batch: 180; loss: 2.22; acc: 0.25
Batch: 200; loss: 2.24; acc: 0.22
Batch: 220; loss: 2.26; acc: 0.22
Batch: 240; loss: 2.25; acc: 0.22
Batch: 260; loss: 2.21; acc: 0.23
Batch: 280; loss: 2.23; acc: 0.28
Batch: 300; loss: 2.24; acc: 0.2
Batch: 320; loss: 2.26; acc: 0.12
Batch: 340; loss: 2.21; acc: 0.27
Batch: 360; loss: 2.27; acc: 0.12
Batch: 380; loss: 2.25; acc: 0.19
Batch: 400; loss: 2.24; acc: 0.23
Batch: 420; loss: 2.32; acc: 0.16
Batch: 440; loss: 2.25; acc: 0.16
Batch: 460; loss: 2.18; acc: 0.22
Batch: 480; loss: 2.27; acc: 0.19
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.14
Batch: 540; loss: 2.21; acc: 0.17
Batch: 560; loss: 2.25; acc: 0.23
Batch: 580; loss: 2.23; acc: 0.2
Batch: 600; loss: 2.28; acc: 0.19
Batch: 620; loss: 2.21; acc: 0.2
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.27; acc: 0.17
Batch: 680; loss: 2.25; acc: 0.19
Batch: 700; loss: 2.22; acc: 0.2
Batch: 720; loss: 2.2; acc: 0.23
Batch: 740; loss: 2.24; acc: 0.12
Batch: 760; loss: 2.19; acc: 0.27
Batch: 780; loss: 2.22; acc: 0.17
Train Epoch over. train_loss: 2.24; train_accuracy: 0.2 

Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.26; acc: 0.25
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.17
Batch: 80; loss: 2.2; acc: 0.22
Batch: 100; loss: 2.16; acc: 0.3
Batch: 120; loss: 2.23; acc: 0.14
Batch: 140; loss: 2.23; acc: 0.16
Val Epoch over. val_loss: 2.2290249463099583; val_accuracy: 0.20402070063694266 

The current subspace-distance is: 1.8241691577713937e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 2.25; acc: 0.2
Batch: 20; loss: 2.27; acc: 0.12
Batch: 40; loss: 2.2; acc: 0.28
Batch: 60; loss: 2.24; acc: 0.2
Batch: 80; loss: 2.25; acc: 0.22
Batch: 100; loss: 2.23; acc: 0.27
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.21; acc: 0.22
Batch: 160; loss: 2.2; acc: 0.23
Batch: 180; loss: 2.22; acc: 0.19
Batch: 200; loss: 2.24; acc: 0.25
Batch: 220; loss: 2.21; acc: 0.19
Batch: 240; loss: 2.2; acc: 0.27
Batch: 260; loss: 2.18; acc: 0.28
Batch: 280; loss: 2.22; acc: 0.19
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.25; acc: 0.22
Batch: 340; loss: 2.2; acc: 0.23
Batch: 360; loss: 2.21; acc: 0.25
Batch: 380; loss: 2.26; acc: 0.09
Batch: 400; loss: 2.22; acc: 0.16
Batch: 420; loss: 2.25; acc: 0.22
Batch: 440; loss: 2.27; acc: 0.2
Batch: 460; loss: 2.2; acc: 0.27
Batch: 480; loss: 2.23; acc: 0.16
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.26; acc: 0.14
Batch: 540; loss: 2.21; acc: 0.2
Batch: 560; loss: 2.23; acc: 0.23
Batch: 580; loss: 2.24; acc: 0.16
Batch: 600; loss: 2.21; acc: 0.27
Batch: 620; loss: 2.26; acc: 0.17
Batch: 640; loss: 2.23; acc: 0.27
Batch: 660; loss: 2.23; acc: 0.17
Batch: 680; loss: 2.22; acc: 0.16
Batch: 700; loss: 2.25; acc: 0.17
Batch: 720; loss: 2.22; acc: 0.23
Batch: 740; loss: 2.26; acc: 0.16
Batch: 760; loss: 2.26; acc: 0.19
Batch: 780; loss: 2.18; acc: 0.27
Train Epoch over. train_loss: 2.23; train_accuracy: 0.2 

Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.25; acc: 0.23
Batch: 40; loss: 2.19; acc: 0.23
Batch: 60; loss: 2.23; acc: 0.17
Batch: 80; loss: 2.19; acc: 0.2
Batch: 100; loss: 2.15; acc: 0.3
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.22; acc: 0.16
Val Epoch over. val_loss: 2.2250455595125818; val_accuracy: 0.20113455414012738 

The current subspace-distance is: 1.9547580450307578e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 2.26; acc: 0.2
Batch: 20; loss: 2.25; acc: 0.19
Batch: 40; loss: 2.24; acc: 0.09
Batch: 60; loss: 2.17; acc: 0.31
Batch: 80; loss: 2.26; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.28; acc: 0.17
Batch: 160; loss: 2.21; acc: 0.25
Batch: 180; loss: 2.28; acc: 0.14
Batch: 200; loss: 2.26; acc: 0.16
Batch: 220; loss: 2.21; acc: 0.19
Batch: 240; loss: 2.17; acc: 0.31
Batch: 260; loss: 2.24; acc: 0.16
Batch: 280; loss: 2.21; acc: 0.25
Batch: 300; loss: 2.21; acc: 0.25
Batch: 320; loss: 2.2; acc: 0.22
Batch: 340; loss: 2.21; acc: 0.16
Batch: 360; loss: 2.3; acc: 0.17
Batch: 380; loss: 2.28; acc: 0.14
Batch: 400; loss: 2.3; acc: 0.11
Batch: 420; loss: 2.25; acc: 0.2
Batch: 440; loss: 2.24; acc: 0.23
Batch: 460; loss: 2.2; acc: 0.14
Batch: 480; loss: 2.31; acc: 0.11
Batch: 500; loss: 2.21; acc: 0.2
Batch: 520; loss: 2.22; acc: 0.25
Batch: 540; loss: 2.22; acc: 0.17
Batch: 560; loss: 2.21; acc: 0.22
Batch: 580; loss: 2.24; acc: 0.17
Batch: 600; loss: 2.24; acc: 0.2
Batch: 620; loss: 2.19; acc: 0.23
Batch: 640; loss: 2.21; acc: 0.2
Batch: 660; loss: 2.18; acc: 0.25
Batch: 680; loss: 2.22; acc: 0.23
Batch: 700; loss: 2.25; acc: 0.25
Batch: 720; loss: 2.27; acc: 0.17
Batch: 740; loss: 2.18; acc: 0.27
Batch: 760; loss: 2.23; acc: 0.19
Batch: 780; loss: 2.14; acc: 0.33
Train Epoch over. train_loss: 2.23; train_accuracy: 0.2 

Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.25; acc: 0.22
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.16
Batch: 80; loss: 2.19; acc: 0.2
Batch: 100; loss: 2.14; acc: 0.25
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.22; acc: 0.17
Val Epoch over. val_loss: 2.221385542754155; val_accuracy: 0.19735270700636942 

The current subspace-distance is: 2.0213014067849144e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 2.23; acc: 0.12
Batch: 20; loss: 2.26; acc: 0.23
Batch: 40; loss: 2.25; acc: 0.14
Batch: 60; loss: 2.23; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.23; acc: 0.19
Batch: 120; loss: 2.21; acc: 0.2
Batch: 140; loss: 2.19; acc: 0.31
Batch: 160; loss: 2.27; acc: 0.2
Batch: 180; loss: 2.25; acc: 0.14
Batch: 200; loss: 2.25; acc: 0.23
Batch: 220; loss: 2.23; acc: 0.2
Batch: 240; loss: 2.2; acc: 0.19
Batch: 260; loss: 2.23; acc: 0.14
Batch: 280; loss: 2.22; acc: 0.2
Batch: 300; loss: 2.2; acc: 0.19
Batch: 320; loss: 2.24; acc: 0.17
Batch: 340; loss: 2.21; acc: 0.27
Batch: 360; loss: 2.28; acc: 0.14
Batch: 380; loss: 2.32; acc: 0.11
Batch: 400; loss: 2.21; acc: 0.23
Batch: 420; loss: 2.16; acc: 0.31
Batch: 440; loss: 2.24; acc: 0.2
Batch: 460; loss: 2.17; acc: 0.22
Batch: 480; loss: 2.22; acc: 0.2
Batch: 500; loss: 2.23; acc: 0.19
Batch: 520; loss: 2.17; acc: 0.23
Batch: 540; loss: 2.26; acc: 0.17
Batch: 560; loss: 2.17; acc: 0.23
Batch: 580; loss: 2.25; acc: 0.09
Batch: 600; loss: 2.2; acc: 0.23
Batch: 620; loss: 2.24; acc: 0.16
Batch: 640; loss: 2.26; acc: 0.09
Batch: 660; loss: 2.23; acc: 0.12
Batch: 680; loss: 2.14; acc: 0.27
Batch: 700; loss: 2.17; acc: 0.22
Batch: 720; loss: 2.19; acc: 0.2
Batch: 740; loss: 2.22; acc: 0.2
Batch: 760; loss: 2.22; acc: 0.19
Batch: 780; loss: 2.35; acc: 0.16
Train Epoch over. train_loss: 2.23; train_accuracy: 0.19 

Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.16
Batch: 80; loss: 2.18; acc: 0.2
Batch: 100; loss: 2.14; acc: 0.25
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.22; acc: 0.19
Val Epoch over. val_loss: 2.218378141427496; val_accuracy: 0.19546178343949044 

The current subspace-distance is: 2.194454282289371e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 2.2; acc: 0.19
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.26; acc: 0.14
Batch: 60; loss: 2.27; acc: 0.16
Batch: 80; loss: 2.23; acc: 0.17
Batch: 100; loss: 2.22; acc: 0.11
Batch: 120; loss: 2.27; acc: 0.14
Batch: 140; loss: 2.24; acc: 0.12
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.23; acc: 0.16
Batch: 200; loss: 2.12; acc: 0.28
Batch: 220; loss: 2.26; acc: 0.14
Batch: 240; loss: 2.23; acc: 0.11
Batch: 260; loss: 2.17; acc: 0.22
Batch: 280; loss: 2.26; acc: 0.17
Batch: 300; loss: 2.22; acc: 0.2
Batch: 320; loss: 2.21; acc: 0.17
Batch: 340; loss: 2.21; acc: 0.2
Batch: 360; loss: 2.18; acc: 0.28
Batch: 380; loss: 2.23; acc: 0.23
Batch: 400; loss: 2.22; acc: 0.2
Batch: 420; loss: 2.22; acc: 0.19
Batch: 440; loss: 2.17; acc: 0.25
Batch: 460; loss: 2.23; acc: 0.22
Batch: 480; loss: 2.24; acc: 0.2
Batch: 500; loss: 2.26; acc: 0.16
Batch: 520; loss: 2.2; acc: 0.17
Batch: 540; loss: 2.26; acc: 0.14
Batch: 560; loss: 2.19; acc: 0.3
Batch: 580; loss: 2.25; acc: 0.2
Batch: 600; loss: 2.25; acc: 0.16
Batch: 620; loss: 2.19; acc: 0.22
Batch: 640; loss: 2.22; acc: 0.2
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.28; acc: 0.12
Batch: 700; loss: 2.19; acc: 0.23
Batch: 720; loss: 2.25; acc: 0.16
Batch: 740; loss: 2.21; acc: 0.25
Batch: 760; loss: 2.22; acc: 0.19
Batch: 780; loss: 2.22; acc: 0.2
Train Epoch over. train_loss: 2.23; train_accuracy: 0.19 

Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.18; acc: 0.19
Batch: 100; loss: 2.14; acc: 0.27
Batch: 120; loss: 2.25; acc: 0.14
Batch: 140; loss: 2.21; acc: 0.16
Val Epoch over. val_loss: 2.2157146854765095; val_accuracy: 0.19197850318471338 

The current subspace-distance is: 2.260955261590425e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 2.27; acc: 0.17
Batch: 20; loss: 2.24; acc: 0.16
Batch: 40; loss: 2.26; acc: 0.19
Batch: 60; loss: 2.2; acc: 0.16
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.23; acc: 0.2
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Batch: 160; loss: 2.31; acc: 0.14
Batch: 180; loss: 2.21; acc: 0.17
Batch: 200; loss: 2.29; acc: 0.08
Batch: 220; loss: 2.19; acc: 0.17
Batch: 240; loss: 2.27; acc: 0.12
Batch: 260; loss: 2.22; acc: 0.25
Batch: 280; loss: 2.17; acc: 0.23
Batch: 300; loss: 2.25; acc: 0.11
Batch: 320; loss: 2.16; acc: 0.12
Batch: 340; loss: 2.19; acc: 0.17
Batch: 360; loss: 2.2; acc: 0.2
Batch: 380; loss: 2.27; acc: 0.16
Batch: 400; loss: 2.19; acc: 0.19
Batch: 420; loss: 2.25; acc: 0.23
Batch: 440; loss: 2.25; acc: 0.16
Batch: 460; loss: 2.25; acc: 0.16
Batch: 480; loss: 2.24; acc: 0.16
Batch: 500; loss: 2.3; acc: 0.16
Batch: 520; loss: 2.27; acc: 0.09
Batch: 540; loss: 2.28; acc: 0.16
Batch: 560; loss: 2.21; acc: 0.2
Batch: 580; loss: 2.25; acc: 0.16
Batch: 600; loss: 2.21; acc: 0.19
Batch: 620; loss: 2.26; acc: 0.16
Batch: 640; loss: 2.31; acc: 0.11
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.23; acc: 0.19
Batch: 700; loss: 2.2; acc: 0.19
Batch: 720; loss: 2.25; acc: 0.14
Batch: 740; loss: 2.26; acc: 0.09
Batch: 760; loss: 2.23; acc: 0.16
Batch: 780; loss: 2.21; acc: 0.22
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.23
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.2
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.25; acc: 0.16
Batch: 140; loss: 2.21; acc: 0.16
Val Epoch over. val_loss: 2.2136525728140666; val_accuracy: 0.1907842356687898 

The current subspace-distance is: 2.410977140243631e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 2.18; acc: 0.25
Batch: 20; loss: 2.27; acc: 0.14
Batch: 40; loss: 2.17; acc: 0.22
Batch: 60; loss: 2.25; acc: 0.16
Batch: 80; loss: 2.18; acc: 0.19
Batch: 100; loss: 2.17; acc: 0.19
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.25; acc: 0.12
Batch: 160; loss: 2.26; acc: 0.14
Batch: 180; loss: 2.16; acc: 0.27
Batch: 200; loss: 2.18; acc: 0.16
Batch: 220; loss: 2.27; acc: 0.17
Batch: 240; loss: 2.24; acc: 0.16
Batch: 260; loss: 2.26; acc: 0.11
Batch: 280; loss: 2.18; acc: 0.23
Batch: 300; loss: 2.27; acc: 0.16
Batch: 320; loss: 2.23; acc: 0.14
Batch: 340; loss: 2.22; acc: 0.17
Batch: 360; loss: 2.23; acc: 0.23
Batch: 380; loss: 2.31; acc: 0.17
Batch: 400; loss: 2.2; acc: 0.16
Batch: 420; loss: 2.27; acc: 0.08
Batch: 440; loss: 2.21; acc: 0.11
Batch: 460; loss: 2.23; acc: 0.3
Batch: 480; loss: 2.12; acc: 0.27
Batch: 500; loss: 2.24; acc: 0.2
Batch: 520; loss: 2.24; acc: 0.14
Batch: 540; loss: 2.25; acc: 0.14
Batch: 560; loss: 2.24; acc: 0.16
Batch: 580; loss: 2.25; acc: 0.2
Batch: 600; loss: 2.16; acc: 0.23
Batch: 620; loss: 2.16; acc: 0.19
Batch: 640; loss: 2.17; acc: 0.2
Batch: 660; loss: 2.24; acc: 0.14
Batch: 680; loss: 2.34; acc: 0.14
Batch: 700; loss: 2.16; acc: 0.3
Batch: 720; loss: 2.14; acc: 0.22
Batch: 740; loss: 2.26; acc: 0.09
Batch: 760; loss: 2.21; acc: 0.19
Batch: 780; loss: 2.26; acc: 0.19
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.19; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.26; acc: 0.12
Batch: 140; loss: 2.21; acc: 0.16
Val Epoch over. val_loss: 2.2120846714943077; val_accuracy: 0.18690286624203822 

The current subspace-distance is: 2.627952562761493e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 2.18; acc: 0.25
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.22; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.21; acc: 0.23
Batch: 100; loss: 2.17; acc: 0.19
Batch: 120; loss: 2.15; acc: 0.23
Batch: 140; loss: 2.31; acc: 0.09
Batch: 160; loss: 2.2; acc: 0.2
Batch: 180; loss: 2.25; acc: 0.22
Batch: 200; loss: 2.18; acc: 0.19
Batch: 220; loss: 2.19; acc: 0.2
Batch: 240; loss: 2.18; acc: 0.19
Batch: 260; loss: 2.18; acc: 0.17
Batch: 280; loss: 2.23; acc: 0.14
Batch: 300; loss: 2.3; acc: 0.08
Batch: 320; loss: 2.25; acc: 0.14
Batch: 340; loss: 2.22; acc: 0.17
Batch: 360; loss: 2.25; acc: 0.17
Batch: 380; loss: 2.24; acc: 0.19
Batch: 400; loss: 2.24; acc: 0.16
Batch: 420; loss: 2.28; acc: 0.16
Batch: 440; loss: 2.19; acc: 0.17
Batch: 460; loss: 2.24; acc: 0.19
Batch: 480; loss: 2.21; acc: 0.19
Batch: 500; loss: 2.18; acc: 0.2
Batch: 520; loss: 2.19; acc: 0.2
Batch: 540; loss: 2.25; acc: 0.09
Batch: 560; loss: 2.2; acc: 0.22
Batch: 580; loss: 2.25; acc: 0.19
Batch: 600; loss: 2.2; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.21; acc: 0.19
Batch: 660; loss: 2.2; acc: 0.2
Batch: 680; loss: 2.34; acc: 0.09
Batch: 700; loss: 2.36; acc: 0.11
Batch: 720; loss: 2.17; acc: 0.19
Batch: 740; loss: 2.25; acc: 0.14
Batch: 760; loss: 2.19; acc: 0.2
Batch: 780; loss: 2.26; acc: 0.12
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.21; acc: 0.17
Val Epoch over. val_loss: 2.2110054280347886; val_accuracy: 0.1846138535031847 

The current subspace-distance is: 2.4323477191501297e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.21; acc: 0.17
Batch: 20; loss: 2.15; acc: 0.23
Batch: 40; loss: 2.23; acc: 0.11
Batch: 60; loss: 2.25; acc: 0.11
Batch: 80; loss: 2.25; acc: 0.17
Batch: 100; loss: 2.21; acc: 0.19
Batch: 120; loss: 2.24; acc: 0.16
Batch: 140; loss: 2.25; acc: 0.17
Batch: 160; loss: 2.24; acc: 0.12
Batch: 180; loss: 2.24; acc: 0.19
Batch: 200; loss: 2.25; acc: 0.2
Batch: 220; loss: 2.27; acc: 0.2
Batch: 240; loss: 2.2; acc: 0.2
Batch: 260; loss: 2.31; acc: 0.12
Batch: 280; loss: 2.2; acc: 0.19
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.32; acc: 0.16
Batch: 340; loss: 2.21; acc: 0.2
Batch: 360; loss: 2.15; acc: 0.2
Batch: 380; loss: 2.26; acc: 0.16
Batch: 400; loss: 2.27; acc: 0.16
Batch: 420; loss: 2.22; acc: 0.2
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.27; acc: 0.17
Batch: 480; loss: 2.18; acc: 0.23
Batch: 500; loss: 2.22; acc: 0.19
Batch: 520; loss: 2.19; acc: 0.2
Batch: 540; loss: 2.16; acc: 0.19
Batch: 560; loss: 2.24; acc: 0.16
Batch: 580; loss: 2.13; acc: 0.23
Batch: 600; loss: 2.22; acc: 0.17
Batch: 620; loss: 2.17; acc: 0.22
Batch: 640; loss: 2.17; acc: 0.16
Batch: 660; loss: 2.24; acc: 0.23
Batch: 680; loss: 2.27; acc: 0.16
Batch: 700; loss: 2.24; acc: 0.17
Batch: 720; loss: 2.14; acc: 0.25
Batch: 740; loss: 2.19; acc: 0.17
Batch: 760; loss: 2.28; acc: 0.14
Batch: 780; loss: 2.24; acc: 0.12
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.17
Val Epoch over. val_loss: 2.210712861103617; val_accuracy: 0.1852109872611465 

The current subspace-distance is: 2.8937061870237812e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.23; acc: 0.17
Batch: 20; loss: 2.27; acc: 0.11
Batch: 40; loss: 2.16; acc: 0.27
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.23; acc: 0.22
Batch: 100; loss: 2.22; acc: 0.12
Batch: 120; loss: 2.26; acc: 0.14
Batch: 140; loss: 2.18; acc: 0.27
Batch: 160; loss: 2.22; acc: 0.23
Batch: 180; loss: 2.19; acc: 0.2
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.23; acc: 0.22
Batch: 240; loss: 2.22; acc: 0.19
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.14
Batch: 300; loss: 2.27; acc: 0.11
Batch: 320; loss: 2.32; acc: 0.16
Batch: 340; loss: 2.19; acc: 0.23
Batch: 360; loss: 2.31; acc: 0.17
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.25; acc: 0.09
Batch: 420; loss: 2.17; acc: 0.17
Batch: 440; loss: 2.21; acc: 0.16
Batch: 460; loss: 2.27; acc: 0.09
Batch: 480; loss: 2.21; acc: 0.19
Batch: 500; loss: 2.23; acc: 0.12
Batch: 520; loss: 2.18; acc: 0.22
Batch: 540; loss: 2.2; acc: 0.16
Batch: 560; loss: 2.18; acc: 0.12
Batch: 580; loss: 2.22; acc: 0.12
Batch: 600; loss: 2.23; acc: 0.12
Batch: 620; loss: 2.18; acc: 0.28
Batch: 640; loss: 2.16; acc: 0.19
Batch: 660; loss: 2.16; acc: 0.22
Batch: 680; loss: 2.22; acc: 0.17
Batch: 700; loss: 2.21; acc: 0.2
Batch: 720; loss: 2.2; acc: 0.27
Batch: 740; loss: 2.21; acc: 0.19
Batch: 760; loss: 2.18; acc: 0.2
Batch: 780; loss: 2.21; acc: 0.14
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.17
Val Epoch over. val_loss: 2.210463291520526; val_accuracy: 0.1845143312101911 

The current subspace-distance is: 2.940041304100305e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.23; acc: 0.16
Batch: 40; loss: 2.22; acc: 0.2
Batch: 60; loss: 2.24; acc: 0.22
Batch: 80; loss: 2.15; acc: 0.25
Batch: 100; loss: 2.21; acc: 0.2
Batch: 120; loss: 2.18; acc: 0.22
Batch: 140; loss: 2.23; acc: 0.16
Batch: 160; loss: 2.27; acc: 0.2
Batch: 180; loss: 2.2; acc: 0.16
Batch: 200; loss: 2.17; acc: 0.19
Batch: 220; loss: 2.19; acc: 0.19
Batch: 240; loss: 2.28; acc: 0.17
Batch: 260; loss: 2.16; acc: 0.27
Batch: 280; loss: 2.23; acc: 0.2
Batch: 300; loss: 2.21; acc: 0.25
Batch: 320; loss: 2.21; acc: 0.19
Batch: 340; loss: 2.19; acc: 0.17
Batch: 360; loss: 2.32; acc: 0.06
Batch: 380; loss: 2.33; acc: 0.08
Batch: 400; loss: 2.28; acc: 0.17
Batch: 420; loss: 2.33; acc: 0.06
Batch: 440; loss: 2.21; acc: 0.2
Batch: 460; loss: 2.2; acc: 0.17
Batch: 480; loss: 2.3; acc: 0.14
Batch: 500; loss: 2.19; acc: 0.16
Batch: 520; loss: 2.2; acc: 0.23
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.26; acc: 0.11
Batch: 580; loss: 2.17; acc: 0.23
Batch: 600; loss: 2.27; acc: 0.14
Batch: 620; loss: 2.27; acc: 0.11
Batch: 640; loss: 2.23; acc: 0.2
Batch: 660; loss: 2.25; acc: 0.19
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.25; acc: 0.17
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.35; acc: 0.06
Batch: 760; loss: 2.21; acc: 0.2
Batch: 780; loss: 2.17; acc: 0.23
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.27
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.17
Val Epoch over. val_loss: 2.2102023294776867; val_accuracy: 0.18401671974522293 

The current subspace-distance is: 2.8132175430073403e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.11
Batch: 40; loss: 2.25; acc: 0.14
Batch: 60; loss: 2.16; acc: 0.3
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.25; acc: 0.19
Batch: 120; loss: 2.21; acc: 0.23
Batch: 140; loss: 2.25; acc: 0.11
Batch: 160; loss: 2.2; acc: 0.19
Batch: 180; loss: 2.28; acc: 0.17
Batch: 200; loss: 2.17; acc: 0.23
Batch: 220; loss: 2.23; acc: 0.16
Batch: 240; loss: 2.25; acc: 0.16
Batch: 260; loss: 2.26; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.2; acc: 0.2
Batch: 320; loss: 2.28; acc: 0.09
Batch: 340; loss: 2.19; acc: 0.16
Batch: 360; loss: 2.21; acc: 0.19
Batch: 380; loss: 2.14; acc: 0.16
Batch: 400; loss: 2.31; acc: 0.09
Batch: 420; loss: 2.27; acc: 0.09
Batch: 440; loss: 2.2; acc: 0.17
Batch: 460; loss: 2.22; acc: 0.2
Batch: 480; loss: 2.26; acc: 0.2
Batch: 500; loss: 2.22; acc: 0.17
Batch: 520; loss: 2.19; acc: 0.22
Batch: 540; loss: 2.22; acc: 0.19
Batch: 560; loss: 2.23; acc: 0.14
Batch: 580; loss: 2.2; acc: 0.19
Batch: 600; loss: 2.22; acc: 0.22
Batch: 620; loss: 2.22; acc: 0.2
Batch: 640; loss: 2.19; acc: 0.17
Batch: 660; loss: 2.19; acc: 0.2
Batch: 680; loss: 2.18; acc: 0.14
Batch: 700; loss: 2.13; acc: 0.31
Batch: 720; loss: 2.24; acc: 0.19
Batch: 740; loss: 2.2; acc: 0.23
Batch: 760; loss: 2.19; acc: 0.17
Batch: 780; loss: 2.24; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.25
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.17
Val Epoch over. val_loss: 2.2098713999341246; val_accuracy: 0.18252388535031847 

The current subspace-distance is: 2.8730280973832123e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.21; acc: 0.19
Batch: 20; loss: 2.21; acc: 0.2
Batch: 40; loss: 2.2; acc: 0.16
Batch: 60; loss: 2.16; acc: 0.33
Batch: 80; loss: 2.23; acc: 0.19
Batch: 100; loss: 2.23; acc: 0.22
Batch: 120; loss: 2.24; acc: 0.22
Batch: 140; loss: 2.21; acc: 0.22
Batch: 160; loss: 2.27; acc: 0.14
Batch: 180; loss: 2.23; acc: 0.16
Batch: 200; loss: 2.2; acc: 0.16
Batch: 220; loss: 2.2; acc: 0.12
Batch: 240; loss: 2.21; acc: 0.16
Batch: 260; loss: 2.16; acc: 0.22
Batch: 280; loss: 2.26; acc: 0.16
Batch: 300; loss: 2.26; acc: 0.16
Batch: 320; loss: 2.19; acc: 0.2
Batch: 340; loss: 2.26; acc: 0.12
Batch: 360; loss: 2.18; acc: 0.16
Batch: 380; loss: 2.28; acc: 0.17
Batch: 400; loss: 2.25; acc: 0.19
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.23; acc: 0.17
Batch: 460; loss: 2.17; acc: 0.22
Batch: 480; loss: 2.18; acc: 0.2
Batch: 500; loss: 2.26; acc: 0.16
Batch: 520; loss: 2.19; acc: 0.22
Batch: 540; loss: 2.19; acc: 0.22
Batch: 560; loss: 2.17; acc: 0.28
Batch: 580; loss: 2.13; acc: 0.22
Batch: 600; loss: 2.26; acc: 0.11
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.2; acc: 0.22
Batch: 660; loss: 2.17; acc: 0.22
Batch: 680; loss: 2.22; acc: 0.16
Batch: 700; loss: 2.35; acc: 0.06
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.34; acc: 0.12
Batch: 760; loss: 2.19; acc: 0.28
Batch: 780; loss: 2.36; acc: 0.08
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.14
Batch: 100; loss: 2.13; acc: 0.25
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.19
Val Epoch over. val_loss: 2.2096089238573793; val_accuracy: 0.1819267515923567 

The current subspace-distance is: 2.9688946597161703e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.18; acc: 0.2
Batch: 20; loss: 2.22; acc: 0.19
Batch: 40; loss: 2.24; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.19; acc: 0.25
Batch: 100; loss: 2.22; acc: 0.17
Batch: 120; loss: 2.19; acc: 0.14
Batch: 140; loss: 2.17; acc: 0.22
Batch: 160; loss: 2.23; acc: 0.16
Batch: 180; loss: 2.24; acc: 0.17
Batch: 200; loss: 2.18; acc: 0.22
Batch: 220; loss: 2.22; acc: 0.16
Batch: 240; loss: 2.23; acc: 0.16
Batch: 260; loss: 2.25; acc: 0.14
Batch: 280; loss: 2.2; acc: 0.22
Batch: 300; loss: 2.21; acc: 0.27
Batch: 320; loss: 2.22; acc: 0.16
Batch: 340; loss: 2.2; acc: 0.2
Batch: 360; loss: 2.22; acc: 0.12
Batch: 380; loss: 2.2; acc: 0.12
Batch: 400; loss: 2.19; acc: 0.19
Batch: 420; loss: 2.3; acc: 0.08
Batch: 440; loss: 2.27; acc: 0.11
Batch: 460; loss: 2.12; acc: 0.27
Batch: 480; loss: 2.27; acc: 0.14
Batch: 500; loss: 2.14; acc: 0.22
Batch: 520; loss: 2.22; acc: 0.17
Batch: 540; loss: 2.15; acc: 0.23
Batch: 560; loss: 2.26; acc: 0.12
Batch: 580; loss: 2.25; acc: 0.17
Batch: 600; loss: 2.26; acc: 0.08
Batch: 620; loss: 2.22; acc: 0.2
Batch: 640; loss: 2.33; acc: 0.09
Batch: 660; loss: 2.22; acc: 0.16
Batch: 680; loss: 2.19; acc: 0.17
Batch: 700; loss: 2.24; acc: 0.2
Batch: 720; loss: 2.2; acc: 0.2
Batch: 740; loss: 2.32; acc: 0.11
Batch: 760; loss: 2.26; acc: 0.17
Batch: 780; loss: 2.18; acc: 0.27
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.14
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.19
Val Epoch over. val_loss: 2.2093020594044095; val_accuracy: 0.18172770700636942 

The current subspace-distance is: 3.0334087568917312e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.27; acc: 0.17
Batch: 20; loss: 2.22; acc: 0.17
Batch: 40; loss: 2.27; acc: 0.14
Batch: 60; loss: 2.27; acc: 0.23
Batch: 80; loss: 2.22; acc: 0.2
Batch: 100; loss: 2.22; acc: 0.16
Batch: 120; loss: 2.23; acc: 0.16
Batch: 140; loss: 2.22; acc: 0.19
Batch: 160; loss: 2.21; acc: 0.23
Batch: 180; loss: 2.24; acc: 0.12
Batch: 200; loss: 2.25; acc: 0.19
Batch: 220; loss: 2.21; acc: 0.2
Batch: 240; loss: 2.24; acc: 0.17
Batch: 260; loss: 2.2; acc: 0.22
Batch: 280; loss: 2.06; acc: 0.31
Batch: 300; loss: 2.17; acc: 0.16
Batch: 320; loss: 2.24; acc: 0.16
Batch: 340; loss: 2.21; acc: 0.14
Batch: 360; loss: 2.21; acc: 0.2
Batch: 380; loss: 2.25; acc: 0.09
Batch: 400; loss: 2.19; acc: 0.17
Batch: 420; loss: 2.32; acc: 0.11
Batch: 440; loss: 2.28; acc: 0.11
Batch: 460; loss: 2.11; acc: 0.25
Batch: 480; loss: 2.34; acc: 0.08
Batch: 500; loss: 2.18; acc: 0.2
Batch: 520; loss: 2.25; acc: 0.16
Batch: 540; loss: 2.16; acc: 0.2
Batch: 560; loss: 2.24; acc: 0.17
Batch: 580; loss: 2.21; acc: 0.22
Batch: 600; loss: 2.18; acc: 0.17
Batch: 620; loss: 2.31; acc: 0.12
Batch: 640; loss: 2.36; acc: 0.11
Batch: 660; loss: 2.16; acc: 0.23
Batch: 680; loss: 2.19; acc: 0.27
Batch: 700; loss: 2.2; acc: 0.22
Batch: 720; loss: 2.3; acc: 0.16
Batch: 740; loss: 2.2; acc: 0.23
Batch: 760; loss: 2.25; acc: 0.14
Batch: 780; loss: 2.19; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.14
Batch: 80; loss: 2.17; acc: 0.14
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.19
Val Epoch over. val_loss: 2.208955506610263; val_accuracy: 0.18182722929936307 

The current subspace-distance is: 3.083614865317941e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.22; acc: 0.2
Batch: 20; loss: 2.18; acc: 0.17
Batch: 40; loss: 2.21; acc: 0.22
Batch: 60; loss: 2.25; acc: 0.12
Batch: 80; loss: 2.24; acc: 0.2
Batch: 100; loss: 2.23; acc: 0.14
Batch: 120; loss: 2.21; acc: 0.19
Batch: 140; loss: 2.23; acc: 0.16
Batch: 160; loss: 2.21; acc: 0.11
Batch: 180; loss: 2.27; acc: 0.11
Batch: 200; loss: 2.2; acc: 0.19
Batch: 220; loss: 2.23; acc: 0.22
Batch: 240; loss: 2.22; acc: 0.14
Batch: 260; loss: 2.15; acc: 0.2
Batch: 280; loss: 2.25; acc: 0.14
Batch: 300; loss: 2.26; acc: 0.17
Batch: 320; loss: 2.23; acc: 0.12
Batch: 340; loss: 2.2; acc: 0.12
Batch: 360; loss: 2.24; acc: 0.14
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.16; acc: 0.23
Batch: 420; loss: 2.31; acc: 0.06
Batch: 440; loss: 2.26; acc: 0.17
Batch: 460; loss: 2.24; acc: 0.16
Batch: 480; loss: 2.2; acc: 0.2
Batch: 500; loss: 2.21; acc: 0.22
Batch: 520; loss: 2.29; acc: 0.16
Batch: 540; loss: 2.28; acc: 0.12
Batch: 560; loss: 2.19; acc: 0.19
Batch: 580; loss: 2.23; acc: 0.16
Batch: 600; loss: 2.14; acc: 0.2
Batch: 620; loss: 2.21; acc: 0.16
Batch: 640; loss: 2.25; acc: 0.09
Batch: 660; loss: 2.32; acc: 0.14
Batch: 680; loss: 2.28; acc: 0.09
Batch: 700; loss: 2.2; acc: 0.23
Batch: 720; loss: 2.18; acc: 0.14
Batch: 740; loss: 2.27; acc: 0.14
Batch: 760; loss: 2.3; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2086080289950036; val_accuracy: 0.18172770700636942 

The current subspace-distance is: 3.189998824382201e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.22; acc: 0.11
Batch: 20; loss: 2.23; acc: 0.14
Batch: 40; loss: 2.23; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.17
Batch: 80; loss: 2.31; acc: 0.14
Batch: 100; loss: 2.24; acc: 0.19
Batch: 120; loss: 2.18; acc: 0.2
Batch: 140; loss: 2.21; acc: 0.17
Batch: 160; loss: 2.24; acc: 0.17
Batch: 180; loss: 2.23; acc: 0.16
Batch: 200; loss: 2.25; acc: 0.12
Batch: 220; loss: 2.19; acc: 0.22
Batch: 240; loss: 2.2; acc: 0.2
Batch: 260; loss: 2.21; acc: 0.19
Batch: 280; loss: 2.17; acc: 0.19
Batch: 300; loss: 2.23; acc: 0.16
Batch: 320; loss: 2.19; acc: 0.19
Batch: 340; loss: 2.16; acc: 0.22
Batch: 360; loss: 2.22; acc: 0.17
Batch: 380; loss: 2.28; acc: 0.14
Batch: 400; loss: 2.2; acc: 0.19
Batch: 420; loss: 2.22; acc: 0.19
Batch: 440; loss: 2.28; acc: 0.16
Batch: 460; loss: 2.22; acc: 0.11
Batch: 480; loss: 2.26; acc: 0.09
Batch: 500; loss: 2.11; acc: 0.25
Batch: 520; loss: 2.27; acc: 0.12
Batch: 540; loss: 2.18; acc: 0.12
Batch: 560; loss: 2.19; acc: 0.2
Batch: 580; loss: 2.24; acc: 0.11
Batch: 600; loss: 2.18; acc: 0.25
Batch: 620; loss: 2.21; acc: 0.14
Batch: 640; loss: 2.24; acc: 0.12
Batch: 660; loss: 2.22; acc: 0.19
Batch: 680; loss: 2.17; acc: 0.19
Batch: 700; loss: 2.15; acc: 0.23
Batch: 720; loss: 2.19; acc: 0.23
Batch: 740; loss: 2.2; acc: 0.23
Batch: 760; loss: 2.29; acc: 0.11
Batch: 780; loss: 2.22; acc: 0.22
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2082734047227603; val_accuracy: 0.1800358280254777 

The current subspace-distance is: 2.9780747354379855e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.27; acc: 0.14
Batch: 40; loss: 2.23; acc: 0.09
Batch: 60; loss: 2.23; acc: 0.2
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.18; acc: 0.11
Batch: 140; loss: 2.25; acc: 0.14
Batch: 160; loss: 2.18; acc: 0.22
Batch: 180; loss: 2.23; acc: 0.19
Batch: 200; loss: 2.19; acc: 0.16
Batch: 220; loss: 2.18; acc: 0.19
Batch: 240; loss: 2.22; acc: 0.22
Batch: 260; loss: 2.26; acc: 0.14
Batch: 280; loss: 2.22; acc: 0.23
Batch: 300; loss: 2.23; acc: 0.19
Batch: 320; loss: 2.2; acc: 0.2
Batch: 340; loss: 2.16; acc: 0.25
Batch: 360; loss: 2.17; acc: 0.27
Batch: 380; loss: 2.21; acc: 0.16
Batch: 400; loss: 2.23; acc: 0.2
Batch: 420; loss: 2.23; acc: 0.2
Batch: 440; loss: 2.24; acc: 0.16
Batch: 460; loss: 2.21; acc: 0.19
Batch: 480; loss: 2.23; acc: 0.16
Batch: 500; loss: 2.26; acc: 0.16
Batch: 520; loss: 2.19; acc: 0.19
Batch: 540; loss: 2.21; acc: 0.2
Batch: 560; loss: 2.26; acc: 0.12
Batch: 580; loss: 2.28; acc: 0.14
Batch: 600; loss: 2.26; acc: 0.16
Batch: 620; loss: 2.16; acc: 0.27
Batch: 640; loss: 2.19; acc: 0.14
Batch: 660; loss: 2.24; acc: 0.19
Batch: 680; loss: 2.24; acc: 0.16
Batch: 700; loss: 2.25; acc: 0.12
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.17; acc: 0.22
Batch: 760; loss: 2.24; acc: 0.16
Batch: 780; loss: 2.18; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.207909907505011; val_accuracy: 0.18013535031847133 

The current subspace-distance is: 3.056331479456276e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.16; acc: 0.22
Batch: 20; loss: 2.35; acc: 0.09
Batch: 40; loss: 2.17; acc: 0.23
Batch: 60; loss: 2.18; acc: 0.25
Batch: 80; loss: 2.17; acc: 0.2
Batch: 100; loss: 2.22; acc: 0.22
Batch: 120; loss: 2.24; acc: 0.22
Batch: 140; loss: 2.14; acc: 0.17
Batch: 160; loss: 2.26; acc: 0.14
Batch: 180; loss: 2.17; acc: 0.16
Batch: 200; loss: 2.23; acc: 0.19
Batch: 220; loss: 2.1; acc: 0.31
Batch: 240; loss: 2.28; acc: 0.25
Batch: 260; loss: 2.31; acc: 0.12
Batch: 280; loss: 2.24; acc: 0.14
Batch: 300; loss: 2.25; acc: 0.14
Batch: 320; loss: 2.28; acc: 0.2
Batch: 340; loss: 2.12; acc: 0.25
Batch: 360; loss: 2.21; acc: 0.19
Batch: 380; loss: 2.18; acc: 0.19
Batch: 400; loss: 2.2; acc: 0.17
Batch: 420; loss: 2.26; acc: 0.11
Batch: 440; loss: 2.2; acc: 0.25
Batch: 460; loss: 2.16; acc: 0.22
Batch: 480; loss: 2.19; acc: 0.17
Batch: 500; loss: 2.21; acc: 0.22
Batch: 520; loss: 2.18; acc: 0.17
Batch: 540; loss: 2.32; acc: 0.17
Batch: 560; loss: 2.24; acc: 0.17
Batch: 580; loss: 2.22; acc: 0.16
Batch: 600; loss: 2.26; acc: 0.16
Batch: 620; loss: 2.33; acc: 0.16
Batch: 640; loss: 2.22; acc: 0.16
Batch: 660; loss: 2.17; acc: 0.2
Batch: 680; loss: 2.19; acc: 0.16
Batch: 700; loss: 2.24; acc: 0.14
Batch: 720; loss: 2.16; acc: 0.19
Batch: 740; loss: 2.2; acc: 0.2
Batch: 760; loss: 2.13; acc: 0.19
Batch: 780; loss: 2.19; acc: 0.16
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.207743079798996; val_accuracy: 0.18043391719745222 

The current subspace-distance is: 3.063102121814154e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.21; acc: 0.19
Batch: 20; loss: 2.22; acc: 0.17
Batch: 40; loss: 2.27; acc: 0.11
Batch: 60; loss: 2.18; acc: 0.22
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.2; acc: 0.16
Batch: 120; loss: 2.26; acc: 0.14
Batch: 140; loss: 2.09; acc: 0.28
Batch: 160; loss: 2.19; acc: 0.16
Batch: 180; loss: 2.19; acc: 0.19
Batch: 200; loss: 2.19; acc: 0.23
Batch: 220; loss: 2.21; acc: 0.16
Batch: 240; loss: 2.23; acc: 0.12
Batch: 260; loss: 2.18; acc: 0.22
Batch: 280; loss: 2.26; acc: 0.11
Batch: 300; loss: 2.29; acc: 0.16
Batch: 320; loss: 2.18; acc: 0.19
Batch: 340; loss: 2.25; acc: 0.14
Batch: 360; loss: 2.23; acc: 0.12
Batch: 380; loss: 2.26; acc: 0.17
Batch: 400; loss: 2.23; acc: 0.16
Batch: 420; loss: 2.21; acc: 0.19
Batch: 440; loss: 2.22; acc: 0.2
Batch: 460; loss: 2.24; acc: 0.22
Batch: 480; loss: 2.2; acc: 0.2
Batch: 500; loss: 2.26; acc: 0.09
Batch: 520; loss: 2.13; acc: 0.27
Batch: 540; loss: 2.07; acc: 0.25
Batch: 560; loss: 2.23; acc: 0.16
Batch: 580; loss: 2.21; acc: 0.19
Batch: 600; loss: 2.16; acc: 0.23
Batch: 620; loss: 2.18; acc: 0.25
Batch: 640; loss: 2.19; acc: 0.22
Batch: 660; loss: 2.26; acc: 0.17
Batch: 680; loss: 2.12; acc: 0.27
Batch: 700; loss: 2.22; acc: 0.19
Batch: 720; loss: 2.31; acc: 0.08
Batch: 740; loss: 2.15; acc: 0.23
Batch: 760; loss: 2.31; acc: 0.16
Batch: 780; loss: 2.19; acc: 0.2
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.207577315105754; val_accuracy: 0.1806329617834395 

The current subspace-distance is: 3.2108830055221915e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.23; acc: 0.16
Batch: 20; loss: 2.25; acc: 0.12
Batch: 40; loss: 2.25; acc: 0.16
Batch: 60; loss: 2.17; acc: 0.17
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.21; acc: 0.17
Batch: 120; loss: 2.26; acc: 0.09
Batch: 140; loss: 2.24; acc: 0.17
Batch: 160; loss: 2.19; acc: 0.19
Batch: 180; loss: 2.19; acc: 0.17
Batch: 200; loss: 2.24; acc: 0.17
Batch: 220; loss: 2.28; acc: 0.09
Batch: 240; loss: 2.27; acc: 0.09
Batch: 260; loss: 2.25; acc: 0.2
Batch: 280; loss: 2.12; acc: 0.27
Batch: 300; loss: 2.21; acc: 0.16
Batch: 320; loss: 2.23; acc: 0.19
Batch: 340; loss: 2.27; acc: 0.14
Batch: 360; loss: 2.17; acc: 0.2
Batch: 380; loss: 2.19; acc: 0.2
Batch: 400; loss: 2.18; acc: 0.22
Batch: 420; loss: 2.22; acc: 0.17
Batch: 440; loss: 2.23; acc: 0.17
Batch: 460; loss: 2.27; acc: 0.16
Batch: 480; loss: 2.17; acc: 0.22
Batch: 500; loss: 2.22; acc: 0.25
Batch: 520; loss: 2.23; acc: 0.17
Batch: 540; loss: 2.19; acc: 0.19
Batch: 560; loss: 2.27; acc: 0.16
Batch: 580; loss: 2.26; acc: 0.11
Batch: 600; loss: 2.17; acc: 0.2
Batch: 620; loss: 2.31; acc: 0.16
Batch: 640; loss: 2.33; acc: 0.09
Batch: 660; loss: 2.16; acc: 0.22
Batch: 680; loss: 2.22; acc: 0.17
Batch: 700; loss: 2.18; acc: 0.16
Batch: 720; loss: 2.23; acc: 0.17
Batch: 740; loss: 2.17; acc: 0.17
Batch: 760; loss: 2.39; acc: 0.11
Batch: 780; loss: 2.31; acc: 0.06
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.25
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.207401063032211; val_accuracy: 0.18093152866242038 

The current subspace-distance is: 3.166530586895533e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.16; acc: 0.22
Batch: 20; loss: 2.21; acc: 0.22
Batch: 40; loss: 2.24; acc: 0.16
Batch: 60; loss: 2.25; acc: 0.17
Batch: 80; loss: 2.15; acc: 0.2
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.19; acc: 0.2
Batch: 160; loss: 2.26; acc: 0.12
Batch: 180; loss: 2.17; acc: 0.19
Batch: 200; loss: 2.21; acc: 0.22
Batch: 220; loss: 2.22; acc: 0.16
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.15; acc: 0.23
Batch: 280; loss: 2.18; acc: 0.16
Batch: 300; loss: 2.2; acc: 0.17
Batch: 320; loss: 2.23; acc: 0.17
Batch: 340; loss: 2.26; acc: 0.14
Batch: 360; loss: 2.24; acc: 0.16
Batch: 380; loss: 2.26; acc: 0.12
Batch: 400; loss: 2.21; acc: 0.17
Batch: 420; loss: 2.26; acc: 0.17
Batch: 440; loss: 2.27; acc: 0.17
Batch: 460; loss: 2.25; acc: 0.16
Batch: 480; loss: 2.22; acc: 0.16
Batch: 500; loss: 2.23; acc: 0.11
Batch: 520; loss: 2.2; acc: 0.25
Batch: 540; loss: 2.2; acc: 0.12
Batch: 560; loss: 2.23; acc: 0.19
Batch: 580; loss: 2.22; acc: 0.2
Batch: 600; loss: 2.15; acc: 0.2
Batch: 620; loss: 2.13; acc: 0.2
Batch: 640; loss: 2.2; acc: 0.2
Batch: 660; loss: 2.23; acc: 0.19
Batch: 680; loss: 2.23; acc: 0.17
Batch: 700; loss: 2.17; acc: 0.2
Batch: 720; loss: 2.19; acc: 0.16
Batch: 740; loss: 2.23; acc: 0.12
Batch: 760; loss: 2.27; acc: 0.22
Batch: 780; loss: 2.18; acc: 0.19
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.25
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.207252087866425; val_accuracy: 0.1807324840764331 

The current subspace-distance is: 3.088375524384901e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.12; acc: 0.3
Batch: 20; loss: 2.2; acc: 0.19
Batch: 40; loss: 2.17; acc: 0.19
Batch: 60; loss: 2.22; acc: 0.16
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.25; acc: 0.11
Batch: 120; loss: 2.26; acc: 0.12
Batch: 140; loss: 2.21; acc: 0.22
Batch: 160; loss: 2.27; acc: 0.09
Batch: 180; loss: 2.15; acc: 0.2
Batch: 200; loss: 2.31; acc: 0.09
Batch: 220; loss: 2.2; acc: 0.17
Batch: 240; loss: 2.19; acc: 0.2
Batch: 260; loss: 2.26; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.2; acc: 0.16
Batch: 320; loss: 2.34; acc: 0.11
Batch: 340; loss: 2.14; acc: 0.19
Batch: 360; loss: 2.14; acc: 0.23
Batch: 380; loss: 2.21; acc: 0.14
Batch: 400; loss: 2.2; acc: 0.2
Batch: 420; loss: 2.22; acc: 0.17
Batch: 440; loss: 2.18; acc: 0.17
Batch: 460; loss: 2.28; acc: 0.16
Batch: 480; loss: 2.17; acc: 0.2
Batch: 500; loss: 2.2; acc: 0.19
Batch: 520; loss: 2.26; acc: 0.14
Batch: 540; loss: 2.2; acc: 0.14
Batch: 560; loss: 2.14; acc: 0.23
Batch: 580; loss: 2.16; acc: 0.25
Batch: 600; loss: 2.2; acc: 0.19
Batch: 620; loss: 2.28; acc: 0.12
Batch: 640; loss: 2.36; acc: 0.08
Batch: 660; loss: 2.24; acc: 0.14
Batch: 680; loss: 2.28; acc: 0.14
Batch: 700; loss: 2.2; acc: 0.2
Batch: 720; loss: 2.27; acc: 0.16
Batch: 740; loss: 2.2; acc: 0.16
Batch: 760; loss: 2.1; acc: 0.23
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.25
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2070989623950545; val_accuracy: 0.1807324840764331 

The current subspace-distance is: 3.0131528546917252e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.28; acc: 0.2
Batch: 20; loss: 2.22; acc: 0.19
Batch: 40; loss: 2.23; acc: 0.17
Batch: 60; loss: 2.27; acc: 0.12
Batch: 80; loss: 2.18; acc: 0.2
Batch: 100; loss: 2.15; acc: 0.28
Batch: 120; loss: 2.24; acc: 0.12
Batch: 140; loss: 2.19; acc: 0.22
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.12; acc: 0.2
Batch: 200; loss: 2.14; acc: 0.23
Batch: 220; loss: 2.19; acc: 0.17
Batch: 240; loss: 2.3; acc: 0.14
Batch: 260; loss: 2.18; acc: 0.19
Batch: 280; loss: 2.24; acc: 0.16
Batch: 300; loss: 2.2; acc: 0.19
Batch: 320; loss: 2.25; acc: 0.19
Batch: 340; loss: 2.26; acc: 0.16
Batch: 360; loss: 2.26; acc: 0.12
Batch: 380; loss: 2.24; acc: 0.16
Batch: 400; loss: 2.17; acc: 0.17
Batch: 420; loss: 2.19; acc: 0.19
Batch: 440; loss: 2.2; acc: 0.14
Batch: 460; loss: 2.19; acc: 0.17
Batch: 480; loss: 2.22; acc: 0.17
Batch: 500; loss: 2.23; acc: 0.22
Batch: 520; loss: 2.22; acc: 0.22
Batch: 540; loss: 2.28; acc: 0.14
Batch: 560; loss: 2.18; acc: 0.19
Batch: 580; loss: 2.2; acc: 0.17
Batch: 600; loss: 2.17; acc: 0.16
Batch: 620; loss: 2.18; acc: 0.2
Batch: 640; loss: 2.28; acc: 0.16
Batch: 660; loss: 2.23; acc: 0.23
Batch: 680; loss: 2.26; acc: 0.09
Batch: 700; loss: 2.22; acc: 0.11
Batch: 720; loss: 2.26; acc: 0.14
Batch: 740; loss: 2.19; acc: 0.2
Batch: 760; loss: 2.25; acc: 0.14
Batch: 780; loss: 2.23; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.25
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.17; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.206907717285642; val_accuracy: 0.18053343949044587 

The current subspace-distance is: 3.046693018404767e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.19; acc: 0.23
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.25; acc: 0.16
Batch: 60; loss: 2.21; acc: 0.16
Batch: 80; loss: 2.24; acc: 0.14
Batch: 100; loss: 2.24; acc: 0.14
Batch: 120; loss: 2.23; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.19
Batch: 160; loss: 2.14; acc: 0.23
Batch: 180; loss: 2.31; acc: 0.11
Batch: 200; loss: 2.2; acc: 0.22
Batch: 220; loss: 2.2; acc: 0.16
Batch: 240; loss: 2.2; acc: 0.2
Batch: 260; loss: 2.27; acc: 0.2
Batch: 280; loss: 2.22; acc: 0.22
Batch: 300; loss: 2.25; acc: 0.12
Batch: 320; loss: 2.23; acc: 0.14
Batch: 340; loss: 2.25; acc: 0.14
Batch: 360; loss: 2.27; acc: 0.19
Batch: 380; loss: 2.16; acc: 0.2
Batch: 400; loss: 2.21; acc: 0.14
Batch: 420; loss: 2.26; acc: 0.14
Batch: 440; loss: 2.21; acc: 0.17
Batch: 460; loss: 2.15; acc: 0.17
Batch: 480; loss: 2.24; acc: 0.2
Batch: 500; loss: 2.17; acc: 0.28
Batch: 520; loss: 2.17; acc: 0.22
Batch: 540; loss: 2.39; acc: 0.05
Batch: 560; loss: 2.24; acc: 0.17
Batch: 580; loss: 2.17; acc: 0.2
Batch: 600; loss: 2.25; acc: 0.14
Batch: 620; loss: 2.16; acc: 0.19
Batch: 640; loss: 2.25; acc: 0.16
Batch: 660; loss: 2.27; acc: 0.11
Batch: 680; loss: 2.31; acc: 0.06
Batch: 700; loss: 2.25; acc: 0.2
Batch: 720; loss: 2.18; acc: 0.22
Batch: 740; loss: 2.24; acc: 0.19
Batch: 760; loss: 2.31; acc: 0.12
Batch: 780; loss: 2.14; acc: 0.22
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2067491127427217; val_accuracy: 0.1803343949044586 

The current subspace-distance is: 3.2269144867314026e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.25; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.08
Batch: 40; loss: 2.24; acc: 0.19
Batch: 60; loss: 2.31; acc: 0.05
Batch: 80; loss: 2.23; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.17; acc: 0.25
Batch: 140; loss: 2.24; acc: 0.14
Batch: 160; loss: 2.19; acc: 0.19
Batch: 180; loss: 2.21; acc: 0.19
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.18; acc: 0.12
Batch: 240; loss: 2.17; acc: 0.17
Batch: 260; loss: 2.17; acc: 0.22
Batch: 280; loss: 2.28; acc: 0.14
Batch: 300; loss: 2.25; acc: 0.14
Batch: 320; loss: 2.21; acc: 0.2
Batch: 340; loss: 2.27; acc: 0.14
Batch: 360; loss: 2.21; acc: 0.19
Batch: 380; loss: 2.23; acc: 0.16
Batch: 400; loss: 2.28; acc: 0.22
Batch: 420; loss: 2.25; acc: 0.2
Batch: 440; loss: 2.22; acc: 0.11
Batch: 460; loss: 2.2; acc: 0.19
Batch: 480; loss: 2.23; acc: 0.17
Batch: 500; loss: 2.33; acc: 0.08
Batch: 520; loss: 2.22; acc: 0.19
Batch: 540; loss: 2.28; acc: 0.12
Batch: 560; loss: 2.15; acc: 0.31
Batch: 580; loss: 2.16; acc: 0.2
Batch: 600; loss: 2.23; acc: 0.17
Batch: 620; loss: 2.25; acc: 0.22
Batch: 640; loss: 2.29; acc: 0.14
Batch: 660; loss: 2.19; acc: 0.2
Batch: 680; loss: 2.15; acc: 0.23
Batch: 700; loss: 2.19; acc: 0.22
Batch: 720; loss: 2.2; acc: 0.22
Batch: 740; loss: 2.15; acc: 0.19
Batch: 760; loss: 2.2; acc: 0.2
Batch: 780; loss: 2.24; acc: 0.19
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.206588881790258; val_accuracy: 0.18013535031847133 

The current subspace-distance is: 3.286267747171223e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.25; acc: 0.19
Batch: 20; loss: 2.14; acc: 0.2
Batch: 40; loss: 2.28; acc: 0.11
Batch: 60; loss: 2.26; acc: 0.19
Batch: 80; loss: 2.14; acc: 0.23
Batch: 100; loss: 2.19; acc: 0.17
Batch: 120; loss: 2.14; acc: 0.25
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.27; acc: 0.14
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.15; acc: 0.22
Batch: 220; loss: 2.19; acc: 0.22
Batch: 240; loss: 2.28; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.11
Batch: 280; loss: 2.23; acc: 0.17
Batch: 300; loss: 2.34; acc: 0.05
Batch: 320; loss: 2.15; acc: 0.17
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.12
Batch: 380; loss: 2.13; acc: 0.23
Batch: 400; loss: 2.17; acc: 0.19
Batch: 420; loss: 2.24; acc: 0.12
Batch: 440; loss: 2.24; acc: 0.14
Batch: 460; loss: 2.07; acc: 0.28
Batch: 480; loss: 2.31; acc: 0.16
Batch: 500; loss: 2.16; acc: 0.28
Batch: 520; loss: 2.18; acc: 0.25
Batch: 540; loss: 2.26; acc: 0.08
Batch: 560; loss: 2.22; acc: 0.16
Batch: 580; loss: 2.23; acc: 0.16
Batch: 600; loss: 2.24; acc: 0.16
Batch: 620; loss: 2.26; acc: 0.12
Batch: 640; loss: 2.18; acc: 0.17
Batch: 660; loss: 2.24; acc: 0.17
Batch: 680; loss: 2.25; acc: 0.19
Batch: 700; loss: 2.27; acc: 0.11
Batch: 720; loss: 2.13; acc: 0.2
Batch: 740; loss: 2.25; acc: 0.19
Batch: 760; loss: 2.16; acc: 0.2
Batch: 780; loss: 2.2; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.206407442214383; val_accuracy: 0.18023487261146498 

The current subspace-distance is: 3.464113251538947e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.23; acc: 0.16
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.23; acc: 0.14
Batch: 60; loss: 2.17; acc: 0.23
Batch: 80; loss: 2.25; acc: 0.17
Batch: 100; loss: 2.25; acc: 0.14
Batch: 120; loss: 2.12; acc: 0.22
Batch: 140; loss: 2.19; acc: 0.23
Batch: 160; loss: 2.23; acc: 0.12
Batch: 180; loss: 2.2; acc: 0.25
Batch: 200; loss: 2.19; acc: 0.27
Batch: 220; loss: 2.22; acc: 0.16
Batch: 240; loss: 2.2; acc: 0.19
Batch: 260; loss: 2.12; acc: 0.27
Batch: 280; loss: 2.19; acc: 0.23
Batch: 300; loss: 2.24; acc: 0.09
Batch: 320; loss: 2.27; acc: 0.12
Batch: 340; loss: 2.25; acc: 0.2
Batch: 360; loss: 2.13; acc: 0.17
Batch: 380; loss: 2.34; acc: 0.14
Batch: 400; loss: 2.22; acc: 0.16
Batch: 420; loss: 2.26; acc: 0.16
Batch: 440; loss: 2.18; acc: 0.2
Batch: 460; loss: 2.22; acc: 0.19
Batch: 480; loss: 2.16; acc: 0.2
Batch: 500; loss: 2.24; acc: 0.09
Batch: 520; loss: 2.22; acc: 0.12
Batch: 540; loss: 2.2; acc: 0.2
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.22; acc: 0.16
Batch: 600; loss: 2.16; acc: 0.17
Batch: 620; loss: 2.17; acc: 0.19
Batch: 640; loss: 2.17; acc: 0.22
Batch: 660; loss: 2.18; acc: 0.19
Batch: 680; loss: 2.27; acc: 0.11
Batch: 700; loss: 2.25; acc: 0.16
Batch: 720; loss: 2.13; acc: 0.22
Batch: 740; loss: 2.22; acc: 0.22
Batch: 760; loss: 2.14; acc: 0.27
Batch: 780; loss: 2.24; acc: 0.11
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2062340116804573; val_accuracy: 0.17993630573248406 

The current subspace-distance is: 3.515561547828838e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.24; acc: 0.2
Batch: 20; loss: 2.24; acc: 0.12
Batch: 40; loss: 2.21; acc: 0.16
Batch: 60; loss: 2.27; acc: 0.19
Batch: 80; loss: 2.34; acc: 0.05
Batch: 100; loss: 2.22; acc: 0.2
Batch: 120; loss: 2.14; acc: 0.23
Batch: 140; loss: 2.19; acc: 0.17
Batch: 160; loss: 2.29; acc: 0.09
Batch: 180; loss: 2.27; acc: 0.14
Batch: 200; loss: 2.23; acc: 0.2
Batch: 220; loss: 2.17; acc: 0.16
Batch: 240; loss: 2.23; acc: 0.12
Batch: 260; loss: 2.2; acc: 0.19
Batch: 280; loss: 2.17; acc: 0.2
Batch: 300; loss: 2.18; acc: 0.19
Batch: 320; loss: 2.16; acc: 0.22
Batch: 340; loss: 2.22; acc: 0.14
Batch: 360; loss: 2.21; acc: 0.19
Batch: 380; loss: 2.21; acc: 0.14
Batch: 400; loss: 2.14; acc: 0.25
Batch: 420; loss: 2.26; acc: 0.14
Batch: 440; loss: 2.19; acc: 0.22
Batch: 460; loss: 2.28; acc: 0.11
Batch: 480; loss: 2.16; acc: 0.17
Batch: 500; loss: 2.34; acc: 0.08
Batch: 520; loss: 2.18; acc: 0.25
Batch: 540; loss: 2.17; acc: 0.23
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.23; acc: 0.19
Batch: 600; loss: 2.24; acc: 0.17
Batch: 620; loss: 2.22; acc: 0.17
Batch: 640; loss: 2.21; acc: 0.2
Batch: 660; loss: 2.26; acc: 0.12
Batch: 680; loss: 2.19; acc: 0.19
Batch: 700; loss: 2.24; acc: 0.19
Batch: 720; loss: 2.26; acc: 0.11
Batch: 740; loss: 2.14; acc: 0.22
Batch: 760; loss: 2.21; acc: 0.2
Batch: 780; loss: 2.31; acc: 0.16
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.206162736674023; val_accuracy: 0.18023487261146498 

The current subspace-distance is: 3.741408363566734e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.17
Batch: 40; loss: 2.2; acc: 0.2
Batch: 60; loss: 2.15; acc: 0.27
Batch: 80; loss: 2.25; acc: 0.08
Batch: 100; loss: 2.2; acc: 0.17
Batch: 120; loss: 2.29; acc: 0.17
Batch: 140; loss: 2.2; acc: 0.17
Batch: 160; loss: 2.29; acc: 0.12
Batch: 180; loss: 2.27; acc: 0.16
Batch: 200; loss: 2.2; acc: 0.16
Batch: 220; loss: 2.26; acc: 0.2
Batch: 240; loss: 2.2; acc: 0.19
Batch: 260; loss: 2.24; acc: 0.11
Batch: 280; loss: 2.18; acc: 0.23
Batch: 300; loss: 2.17; acc: 0.22
Batch: 320; loss: 2.25; acc: 0.2
Batch: 340; loss: 2.23; acc: 0.17
Batch: 360; loss: 2.25; acc: 0.19
Batch: 380; loss: 2.19; acc: 0.16
Batch: 400; loss: 2.28; acc: 0.17
Batch: 420; loss: 2.31; acc: 0.11
Batch: 440; loss: 2.22; acc: 0.19
Batch: 460; loss: 2.17; acc: 0.22
Batch: 480; loss: 2.17; acc: 0.16
Batch: 500; loss: 2.24; acc: 0.09
Batch: 520; loss: 2.22; acc: 0.19
Batch: 540; loss: 2.21; acc: 0.19
Batch: 560; loss: 2.21; acc: 0.17
Batch: 580; loss: 2.23; acc: 0.17
Batch: 600; loss: 2.13; acc: 0.31
Batch: 620; loss: 2.25; acc: 0.14
Batch: 640; loss: 2.24; acc: 0.16
Batch: 660; loss: 2.25; acc: 0.12
Batch: 680; loss: 2.16; acc: 0.2
Batch: 700; loss: 2.26; acc: 0.2
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.2; acc: 0.23
Batch: 760; loss: 2.23; acc: 0.2
Batch: 780; loss: 2.24; acc: 0.09
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2060899005574024; val_accuracy: 0.18023487261146498 

The current subspace-distance is: 3.916062996722758e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.25; acc: 0.17
Batch: 20; loss: 2.21; acc: 0.28
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.13; acc: 0.23
Batch: 80; loss: 2.14; acc: 0.2
Batch: 100; loss: 2.24; acc: 0.17
Batch: 120; loss: 2.26; acc: 0.12
Batch: 140; loss: 2.25; acc: 0.17
Batch: 160; loss: 2.32; acc: 0.11
Batch: 180; loss: 2.13; acc: 0.23
Batch: 200; loss: 2.24; acc: 0.16
Batch: 220; loss: 2.27; acc: 0.16
Batch: 240; loss: 2.26; acc: 0.09
Batch: 260; loss: 2.16; acc: 0.23
Batch: 280; loss: 2.16; acc: 0.17
Batch: 300; loss: 2.18; acc: 0.17
Batch: 320; loss: 2.3; acc: 0.14
Batch: 340; loss: 2.15; acc: 0.2
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.25; acc: 0.12
Batch: 400; loss: 2.28; acc: 0.08
Batch: 420; loss: 2.21; acc: 0.14
Batch: 440; loss: 2.27; acc: 0.12
Batch: 460; loss: 2.26; acc: 0.12
Batch: 480; loss: 2.27; acc: 0.22
Batch: 500; loss: 2.24; acc: 0.19
Batch: 520; loss: 2.23; acc: 0.19
Batch: 540; loss: 2.21; acc: 0.19
Batch: 560; loss: 2.19; acc: 0.14
Batch: 580; loss: 2.15; acc: 0.17
Batch: 600; loss: 2.22; acc: 0.19
Batch: 620; loss: 2.3; acc: 0.16
Batch: 640; loss: 2.24; acc: 0.22
Batch: 660; loss: 2.31; acc: 0.09
Batch: 680; loss: 2.23; acc: 0.16
Batch: 700; loss: 2.2; acc: 0.12
Batch: 720; loss: 2.26; acc: 0.14
Batch: 740; loss: 2.19; acc: 0.27
Batch: 760; loss: 2.19; acc: 0.11
Batch: 780; loss: 2.31; acc: 0.08
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.2
Val Epoch over. val_loss: 2.2060163370363273; val_accuracy: 0.18083200636942676 

The current subspace-distance is: 4.0879072912503034e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.19; acc: 0.16
Batch: 20; loss: 2.25; acc: 0.09
Batch: 40; loss: 2.2; acc: 0.2
Batch: 60; loss: 2.21; acc: 0.16
Batch: 80; loss: 2.18; acc: 0.2
Batch: 100; loss: 2.24; acc: 0.14
Batch: 120; loss: 2.23; acc: 0.17
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.26; acc: 0.16
Batch: 200; loss: 2.2; acc: 0.2
Batch: 220; loss: 2.35; acc: 0.17
Batch: 240; loss: 2.2; acc: 0.22
Batch: 260; loss: 2.33; acc: 0.11
Batch: 280; loss: 2.26; acc: 0.14
Batch: 300; loss: 2.19; acc: 0.17
Batch: 320; loss: 2.25; acc: 0.12
Batch: 340; loss: 2.25; acc: 0.14
Batch: 360; loss: 2.17; acc: 0.25
Batch: 380; loss: 2.12; acc: 0.31
Batch: 400; loss: 2.23; acc: 0.12
Batch: 420; loss: 2.24; acc: 0.16
Batch: 440; loss: 2.29; acc: 0.16
Batch: 460; loss: 2.11; acc: 0.25
Batch: 480; loss: 2.26; acc: 0.08
Batch: 500; loss: 2.25; acc: 0.12
Batch: 520; loss: 2.28; acc: 0.17
Batch: 540; loss: 2.25; acc: 0.16
Batch: 560; loss: 2.16; acc: 0.25
Batch: 580; loss: 2.24; acc: 0.14
Batch: 600; loss: 2.25; acc: 0.16
Batch: 620; loss: 2.18; acc: 0.17
Batch: 640; loss: 2.29; acc: 0.17
Batch: 660; loss: 2.23; acc: 0.16
Batch: 680; loss: 2.17; acc: 0.2
Batch: 700; loss: 2.17; acc: 0.22
Batch: 720; loss: 2.21; acc: 0.17
Batch: 740; loss: 2.18; acc: 0.2
Batch: 760; loss: 2.18; acc: 0.19
Batch: 780; loss: 2.18; acc: 0.22
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.2059370514693533; val_accuracy: 0.18093152866242038 

The current subspace-distance is: 4.248157347319648e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.28; acc: 0.11
Batch: 20; loss: 2.13; acc: 0.27
Batch: 40; loss: 2.17; acc: 0.2
Batch: 60; loss: 2.14; acc: 0.25
Batch: 80; loss: 2.17; acc: 0.2
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.23; acc: 0.2
Batch: 140; loss: 2.23; acc: 0.2
Batch: 160; loss: 2.21; acc: 0.14
Batch: 180; loss: 2.23; acc: 0.11
Batch: 200; loss: 2.22; acc: 0.2
Batch: 220; loss: 2.16; acc: 0.23
Batch: 240; loss: 2.19; acc: 0.17
Batch: 260; loss: 2.29; acc: 0.22
Batch: 280; loss: 2.25; acc: 0.19
Batch: 300; loss: 2.16; acc: 0.22
Batch: 320; loss: 2.14; acc: 0.25
Batch: 340; loss: 2.18; acc: 0.19
Batch: 360; loss: 2.21; acc: 0.14
Batch: 380; loss: 2.25; acc: 0.17
Batch: 400; loss: 2.26; acc: 0.16
Batch: 420; loss: 2.18; acc: 0.22
Batch: 440; loss: 2.24; acc: 0.16
Batch: 460; loss: 2.21; acc: 0.22
Batch: 480; loss: 2.1; acc: 0.23
Batch: 500; loss: 2.22; acc: 0.19
Batch: 520; loss: 2.23; acc: 0.14
Batch: 540; loss: 2.24; acc: 0.14
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.22; acc: 0.19
Batch: 600; loss: 2.23; acc: 0.14
Batch: 620; loss: 2.19; acc: 0.22
Batch: 640; loss: 2.28; acc: 0.16
Batch: 660; loss: 2.28; acc: 0.11
Batch: 680; loss: 2.25; acc: 0.19
Batch: 700; loss: 2.18; acc: 0.2
Batch: 720; loss: 2.18; acc: 0.19
Batch: 740; loss: 2.27; acc: 0.08
Batch: 760; loss: 2.21; acc: 0.2
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.2058603581349563; val_accuracy: 0.18053343949044587 

The current subspace-distance is: 4.4307340431259945e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.16; acc: 0.19
Batch: 20; loss: 2.25; acc: 0.09
Batch: 40; loss: 2.17; acc: 0.22
Batch: 60; loss: 2.23; acc: 0.19
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.18; acc: 0.19
Batch: 120; loss: 2.13; acc: 0.19
Batch: 140; loss: 2.21; acc: 0.17
Batch: 160; loss: 2.23; acc: 0.2
Batch: 180; loss: 2.19; acc: 0.17
Batch: 200; loss: 2.2; acc: 0.2
Batch: 220; loss: 2.2; acc: 0.22
Batch: 240; loss: 2.3; acc: 0.09
Batch: 260; loss: 2.25; acc: 0.16
Batch: 280; loss: 2.16; acc: 0.2
Batch: 300; loss: 2.22; acc: 0.2
Batch: 320; loss: 2.2; acc: 0.17
Batch: 340; loss: 2.16; acc: 0.28
Batch: 360; loss: 2.19; acc: 0.19
Batch: 380; loss: 2.3; acc: 0.11
Batch: 400; loss: 2.24; acc: 0.14
Batch: 420; loss: 2.17; acc: 0.19
Batch: 440; loss: 2.25; acc: 0.14
Batch: 460; loss: 2.23; acc: 0.16
Batch: 480; loss: 2.18; acc: 0.19
Batch: 500; loss: 2.23; acc: 0.19
Batch: 520; loss: 2.24; acc: 0.12
Batch: 540; loss: 2.15; acc: 0.22
Batch: 560; loss: 2.15; acc: 0.22
Batch: 580; loss: 2.2; acc: 0.17
Batch: 600; loss: 2.25; acc: 0.14
Batch: 620; loss: 2.18; acc: 0.17
Batch: 640; loss: 2.27; acc: 0.11
Batch: 660; loss: 2.18; acc: 0.22
Batch: 680; loss: 2.16; acc: 0.25
Batch: 700; loss: 2.19; acc: 0.23
Batch: 720; loss: 2.26; acc: 0.16
Batch: 740; loss: 2.25; acc: 0.16
Batch: 760; loss: 2.19; acc: 0.17
Batch: 780; loss: 2.25; acc: 0.12
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.2057823117371576; val_accuracy: 0.18093152866242038 

The current subspace-distance is: 4.453859946806915e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.27; acc: 0.08
Batch: 20; loss: 2.42; acc: 0.08
Batch: 40; loss: 2.19; acc: 0.23
Batch: 60; loss: 2.28; acc: 0.17
Batch: 80; loss: 2.24; acc: 0.12
Batch: 100; loss: 2.24; acc: 0.17
Batch: 120; loss: 2.21; acc: 0.23
Batch: 140; loss: 2.16; acc: 0.23
Batch: 160; loss: 2.16; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.21; acc: 0.12
Batch: 220; loss: 2.3; acc: 0.06
Batch: 240; loss: 2.26; acc: 0.22
Batch: 260; loss: 2.25; acc: 0.14
Batch: 280; loss: 2.13; acc: 0.12
Batch: 300; loss: 2.28; acc: 0.16
Batch: 320; loss: 2.28; acc: 0.22
Batch: 340; loss: 2.19; acc: 0.28
Batch: 360; loss: 2.2; acc: 0.16
Batch: 380; loss: 2.21; acc: 0.17
Batch: 400; loss: 2.22; acc: 0.17
Batch: 420; loss: 2.16; acc: 0.17
Batch: 440; loss: 2.25; acc: 0.16
Batch: 460; loss: 2.34; acc: 0.11
Batch: 480; loss: 2.23; acc: 0.11
Batch: 500; loss: 2.18; acc: 0.2
Batch: 520; loss: 2.26; acc: 0.14
Batch: 540; loss: 2.26; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.17
Batch: 580; loss: 2.28; acc: 0.08
Batch: 600; loss: 2.2; acc: 0.22
Batch: 620; loss: 2.23; acc: 0.22
Batch: 640; loss: 2.29; acc: 0.09
Batch: 660; loss: 2.17; acc: 0.2
Batch: 680; loss: 2.14; acc: 0.23
Batch: 700; loss: 2.2; acc: 0.2
Batch: 720; loss: 2.16; acc: 0.22
Batch: 740; loss: 2.27; acc: 0.11
Batch: 760; loss: 2.26; acc: 0.09
Batch: 780; loss: 2.25; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.205700787769002; val_accuracy: 0.18103105095541402 

The current subspace-distance is: 5.017694638809189e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.21; acc: 0.16
Batch: 20; loss: 2.23; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.17
Batch: 60; loss: 2.27; acc: 0.16
Batch: 80; loss: 2.21; acc: 0.2
Batch: 100; loss: 2.2; acc: 0.16
Batch: 120; loss: 2.16; acc: 0.22
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.22; acc: 0.16
Batch: 180; loss: 2.23; acc: 0.16
Batch: 200; loss: 2.24; acc: 0.17
Batch: 220; loss: 2.14; acc: 0.22
Batch: 240; loss: 2.18; acc: 0.2
Batch: 260; loss: 2.26; acc: 0.17
Batch: 280; loss: 2.23; acc: 0.16
Batch: 300; loss: 2.2; acc: 0.17
Batch: 320; loss: 2.22; acc: 0.19
Batch: 340; loss: 2.22; acc: 0.16
Batch: 360; loss: 2.13; acc: 0.23
Batch: 380; loss: 2.15; acc: 0.17
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.22; acc: 0.14
Batch: 440; loss: 2.26; acc: 0.19
Batch: 460; loss: 2.25; acc: 0.16
Batch: 480; loss: 2.27; acc: 0.11
Batch: 500; loss: 2.24; acc: 0.2
Batch: 520; loss: 2.25; acc: 0.12
Batch: 540; loss: 2.25; acc: 0.16
Batch: 560; loss: 2.05; acc: 0.31
Batch: 580; loss: 2.19; acc: 0.19
Batch: 600; loss: 2.22; acc: 0.12
Batch: 620; loss: 2.21; acc: 0.2
Batch: 640; loss: 2.24; acc: 0.17
Batch: 660; loss: 2.18; acc: 0.2
Batch: 680; loss: 2.19; acc: 0.16
Batch: 700; loss: 2.23; acc: 0.16
Batch: 720; loss: 2.34; acc: 0.09
Batch: 740; loss: 2.13; acc: 0.25
Batch: 760; loss: 2.26; acc: 0.11
Batch: 780; loss: 2.34; acc: 0.19
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.2056173731566995; val_accuracy: 0.18113057324840764 

The current subspace-distance is: 4.94732812512666e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.25; acc: 0.14
Batch: 20; loss: 2.19; acc: 0.2
Batch: 40; loss: 2.19; acc: 0.22
Batch: 60; loss: 2.22; acc: 0.16
Batch: 80; loss: 2.17; acc: 0.16
Batch: 100; loss: 2.16; acc: 0.14
Batch: 120; loss: 2.19; acc: 0.22
Batch: 140; loss: 2.25; acc: 0.14
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.25; acc: 0.19
Batch: 200; loss: 2.22; acc: 0.23
Batch: 220; loss: 2.27; acc: 0.14
Batch: 240; loss: 2.28; acc: 0.16
Batch: 260; loss: 2.26; acc: 0.09
Batch: 280; loss: 2.16; acc: 0.23
Batch: 300; loss: 2.35; acc: 0.08
Batch: 320; loss: 2.14; acc: 0.2
Batch: 340; loss: 2.19; acc: 0.17
Batch: 360; loss: 2.19; acc: 0.17
Batch: 380; loss: 2.28; acc: 0.08
Batch: 400; loss: 2.18; acc: 0.17
Batch: 420; loss: 2.23; acc: 0.08
Batch: 440; loss: 2.21; acc: 0.19
Batch: 460; loss: 2.08; acc: 0.27
Batch: 480; loss: 2.27; acc: 0.17
Batch: 500; loss: 2.24; acc: 0.16
Batch: 520; loss: 2.26; acc: 0.14
Batch: 540; loss: 2.18; acc: 0.2
Batch: 560; loss: 2.09; acc: 0.23
Batch: 580; loss: 2.17; acc: 0.25
Batch: 600; loss: 2.26; acc: 0.14
Batch: 620; loss: 2.28; acc: 0.17
Batch: 640; loss: 2.28; acc: 0.19
Batch: 660; loss: 2.28; acc: 0.12
Batch: 680; loss: 2.25; acc: 0.12
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.3; acc: 0.17
Batch: 740; loss: 2.17; acc: 0.2
Batch: 760; loss: 2.21; acc: 0.14
Batch: 780; loss: 2.18; acc: 0.17
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.2055313055682335; val_accuracy: 0.18113057324840764 

The current subspace-distance is: 4.8103349399752915e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.27; acc: 0.16
Batch: 20; loss: 2.31; acc: 0.11
Batch: 40; loss: 2.25; acc: 0.12
Batch: 60; loss: 2.25; acc: 0.17
Batch: 80; loss: 2.19; acc: 0.22
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.24; acc: 0.14
Batch: 140; loss: 2.26; acc: 0.14
Batch: 160; loss: 2.14; acc: 0.16
Batch: 180; loss: 2.23; acc: 0.19
Batch: 200; loss: 2.12; acc: 0.25
Batch: 220; loss: 2.2; acc: 0.19
Batch: 240; loss: 2.16; acc: 0.2
Batch: 260; loss: 2.23; acc: 0.08
Batch: 280; loss: 2.27; acc: 0.09
Batch: 300; loss: 2.23; acc: 0.16
Batch: 320; loss: 2.2; acc: 0.19
Batch: 340; loss: 2.19; acc: 0.19
Batch: 360; loss: 2.2; acc: 0.17
Batch: 380; loss: 2.24; acc: 0.17
Batch: 400; loss: 2.07; acc: 0.3
Batch: 420; loss: 2.23; acc: 0.16
Batch: 440; loss: 2.19; acc: 0.16
Batch: 460; loss: 2.22; acc: 0.14
Batch: 480; loss: 2.16; acc: 0.2
Batch: 500; loss: 2.2; acc: 0.19
Batch: 520; loss: 2.24; acc: 0.17
Batch: 540; loss: 2.19; acc: 0.2
Batch: 560; loss: 2.27; acc: 0.17
Batch: 580; loss: 2.15; acc: 0.22
Batch: 600; loss: 2.19; acc: 0.16
Batch: 620; loss: 2.16; acc: 0.19
Batch: 640; loss: 2.12; acc: 0.28
Batch: 660; loss: 2.2; acc: 0.16
Batch: 680; loss: 2.21; acc: 0.19
Batch: 700; loss: 2.19; acc: 0.17
Batch: 720; loss: 2.31; acc: 0.11
Batch: 740; loss: 2.2; acc: 0.19
Batch: 760; loss: 2.18; acc: 0.22
Batch: 780; loss: 2.2; acc: 0.23
Train Epoch over. train_loss: 2.22; train_accuracy: 0.17 

Batch: 0; loss: 2.27; acc: 0.12
Batch: 20; loss: 2.24; acc: 0.22
Batch: 40; loss: 2.18; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.12
Batch: 80; loss: 2.16; acc: 0.17
Batch: 100; loss: 2.13; acc: 0.23
Batch: 120; loss: 2.29; acc: 0.11
Batch: 140; loss: 2.2; acc: 0.22
Val Epoch over. val_loss: 2.2054439274368773; val_accuracy: 0.18083200636942676 

The current subspace-distance is: 4.769915176439099e-05 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_10_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 5243
elements in E: 1124750
fraction nonzero: 0.004661480328961991
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.31; acc: 0.16
Batch: 160; loss: 2.32; acc: 0.05
Batch: 180; loss: 2.32; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.31; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.08
Batch: 380; loss: 2.3; acc: 0.08
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.16
Batch: 440; loss: 2.31; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.14
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.31; acc: 0.09
Batch: 520; loss: 2.3; acc: 0.06
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.29; acc: 0.19
Batch: 600; loss: 2.29; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.17
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.29; acc: 0.23
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.06
Batch: 720; loss: 2.29; acc: 0.19
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.29; acc: 0.08
Batch: 780; loss: 2.28; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.16
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.2
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.22
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.29; acc: 0.19
Val Epoch over. val_loss: 2.2947304704386715; val_accuracy: 0.12768710191082802 

The current subspace-distance is: 2.7117421268485487e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.28; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.3; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.16
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.16
Batch: 200; loss: 2.27; acc: 0.23
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.11
Batch: 280; loss: 2.28; acc: 0.16
Batch: 300; loss: 2.27; acc: 0.25
Batch: 320; loss: 2.29; acc: 0.25
Batch: 340; loss: 2.29; acc: 0.19
Batch: 360; loss: 2.28; acc: 0.19
Batch: 380; loss: 2.27; acc: 0.22
Batch: 400; loss: 2.29; acc: 0.17
Batch: 420; loss: 2.28; acc: 0.16
Batch: 440; loss: 2.29; acc: 0.14
Batch: 460; loss: 2.29; acc: 0.08
Batch: 480; loss: 2.28; acc: 0.19
Batch: 500; loss: 2.28; acc: 0.16
Batch: 520; loss: 2.29; acc: 0.05
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.28; acc: 0.2
Batch: 580; loss: 2.28; acc: 0.19
Batch: 600; loss: 2.28; acc: 0.11
Batch: 620; loss: 2.29; acc: 0.14
Batch: 640; loss: 2.28; acc: 0.12
Batch: 660; loss: 2.27; acc: 0.22
Batch: 680; loss: 2.27; acc: 0.2
Batch: 700; loss: 2.27; acc: 0.27
Batch: 720; loss: 2.26; acc: 0.19
Batch: 740; loss: 2.27; acc: 0.22
Batch: 760; loss: 2.28; acc: 0.2
Batch: 780; loss: 2.27; acc: 0.14
Train Epoch over. train_loss: 2.29; train_accuracy: 0.15 

Batch: 0; loss: 2.26; acc: 0.2
Batch: 20; loss: 2.27; acc: 0.19
Batch: 40; loss: 2.26; acc: 0.2
Batch: 60; loss: 2.28; acc: 0.23
Batch: 80; loss: 2.27; acc: 0.27
Batch: 100; loss: 2.27; acc: 0.17
Batch: 120; loss: 2.27; acc: 0.22
Batch: 140; loss: 2.27; acc: 0.23
Val Epoch over. val_loss: 2.273516916165686; val_accuracy: 0.18511146496815287 

The current subspace-distance is: 4.350005383457756e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.29; acc: 0.16
Batch: 40; loss: 2.25; acc: 0.17
Batch: 60; loss: 2.27; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.23
Batch: 100; loss: 2.27; acc: 0.27
Batch: 120; loss: 2.28; acc: 0.2
Batch: 140; loss: 2.27; acc: 0.23
Batch: 160; loss: 2.26; acc: 0.22
Batch: 180; loss: 2.27; acc: 0.17
Batch: 200; loss: 2.27; acc: 0.2
Batch: 220; loss: 2.25; acc: 0.34
Batch: 240; loss: 2.25; acc: 0.27
Batch: 260; loss: 2.26; acc: 0.19
Batch: 280; loss: 2.26; acc: 0.16
Batch: 300; loss: 2.27; acc: 0.19
Batch: 320; loss: 2.27; acc: 0.22
Batch: 340; loss: 2.27; acc: 0.22
Batch: 360; loss: 2.24; acc: 0.31
Batch: 380; loss: 2.24; acc: 0.3
Batch: 400; loss: 2.25; acc: 0.3
Batch: 420; loss: 2.24; acc: 0.3
Batch: 440; loss: 2.25; acc: 0.22
Batch: 460; loss: 2.27; acc: 0.12
Batch: 480; loss: 2.23; acc: 0.31
Batch: 500; loss: 2.26; acc: 0.19
Batch: 520; loss: 2.27; acc: 0.17
Batch: 540; loss: 2.26; acc: 0.23
Batch: 560; loss: 2.25; acc: 0.22
Batch: 580; loss: 2.25; acc: 0.22
Batch: 600; loss: 2.23; acc: 0.28
Batch: 620; loss: 2.26; acc: 0.23
Batch: 640; loss: 2.2; acc: 0.34
Batch: 660; loss: 2.22; acc: 0.31
Batch: 680; loss: 2.19; acc: 0.28
Batch: 700; loss: 2.25; acc: 0.22
Batch: 720; loss: 2.26; acc: 0.14
Batch: 740; loss: 2.26; acc: 0.19
Batch: 760; loss: 2.24; acc: 0.2
Batch: 780; loss: 2.25; acc: 0.2
Train Epoch over. train_loss: 2.26; train_accuracy: 0.22 

Batch: 0; loss: 2.22; acc: 0.31
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.21; acc: 0.23
Batch: 60; loss: 2.24; acc: 0.28
Batch: 80; loss: 2.23; acc: 0.36
Batch: 100; loss: 2.24; acc: 0.22
Batch: 120; loss: 2.24; acc: 0.34
Batch: 140; loss: 2.21; acc: 0.25
Val Epoch over. val_loss: 2.2319722464130183; val_accuracy: 0.2461186305732484 

The current subspace-distance is: 6.945211225684034e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.17; acc: 0.34
Batch: 20; loss: 2.21; acc: 0.25
Batch: 40; loss: 2.23; acc: 0.22
Batch: 60; loss: 2.24; acc: 0.25
Batch: 80; loss: 2.25; acc: 0.2
Batch: 100; loss: 2.19; acc: 0.38
Batch: 120; loss: 2.21; acc: 0.25
Batch: 140; loss: 2.25; acc: 0.2
Batch: 160; loss: 2.23; acc: 0.28
Batch: 180; loss: 2.17; acc: 0.33
Batch: 200; loss: 2.17; acc: 0.25
Batch: 220; loss: 2.22; acc: 0.19
Batch: 240; loss: 2.22; acc: 0.3
Batch: 260; loss: 2.19; acc: 0.25
Batch: 280; loss: 2.19; acc: 0.28
Batch: 300; loss: 2.25; acc: 0.22
Batch: 320; loss: 2.2; acc: 0.3
Batch: 340; loss: 2.23; acc: 0.14
Batch: 360; loss: 2.14; acc: 0.36
Batch: 380; loss: 2.24; acc: 0.27
Batch: 400; loss: 2.21; acc: 0.36
Batch: 420; loss: 2.2; acc: 0.25
Batch: 440; loss: 2.15; acc: 0.39
Batch: 460; loss: 2.2; acc: 0.33
Batch: 480; loss: 2.16; acc: 0.31
Batch: 500; loss: 2.18; acc: 0.25
Batch: 520; loss: 2.13; acc: 0.28
Batch: 540; loss: 2.16; acc: 0.28
Batch: 560; loss: 2.07; acc: 0.3
Batch: 580; loss: 2.07; acc: 0.36
Batch: 600; loss: 2.01; acc: 0.44
Batch: 620; loss: 2.12; acc: 0.3
Batch: 640; loss: 2.1; acc: 0.33
Batch: 660; loss: 2.07; acc: 0.23
Batch: 680; loss: 2.13; acc: 0.33
Batch: 700; loss: 2.09; acc: 0.25
Batch: 720; loss: 2.09; acc: 0.23
Batch: 740; loss: 2.03; acc: 0.28
Batch: 760; loss: 2.0; acc: 0.27
Batch: 780; loss: 2.13; acc: 0.31
Train Epoch over. train_loss: 2.17; train_accuracy: 0.28 

Batch: 0; loss: 2.04; acc: 0.33
Batch: 20; loss: 2.13; acc: 0.22
Batch: 40; loss: 1.93; acc: 0.39
Batch: 60; loss: 2.0; acc: 0.42
Batch: 80; loss: 2.04; acc: 0.28
Batch: 100; loss: 2.07; acc: 0.31
Batch: 120; loss: 2.11; acc: 0.3
Batch: 140; loss: 2.05; acc: 0.28
Val Epoch over. val_loss: 2.0480806652907355; val_accuracy: 0.31080812101910826 

The current subspace-distance is: 1.21533521451056e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.13; acc: 0.22
Batch: 20; loss: 2.05; acc: 0.3
Batch: 40; loss: 1.85; acc: 0.39
Batch: 60; loss: 2.06; acc: 0.33
Batch: 80; loss: 2.02; acc: 0.27
Batch: 100; loss: 2.04; acc: 0.36
Batch: 120; loss: 2.11; acc: 0.25
Batch: 140; loss: 2.15; acc: 0.23
Batch: 160; loss: 1.83; acc: 0.38
Batch: 180; loss: 2.07; acc: 0.27
Batch: 200; loss: 1.86; acc: 0.36
Batch: 220; loss: 1.95; acc: 0.42
Batch: 240; loss: 2.11; acc: 0.36
Batch: 260; loss: 2.08; acc: 0.34
Batch: 280; loss: 1.9; acc: 0.39
Batch: 300; loss: 1.94; acc: 0.31
Batch: 320; loss: 2.06; acc: 0.31
Batch: 340; loss: 1.89; acc: 0.3
Batch: 360; loss: 2.0; acc: 0.36
Batch: 380; loss: 2.02; acc: 0.36
Batch: 400; loss: 1.88; acc: 0.44
Batch: 420; loss: 2.1; acc: 0.34
Batch: 440; loss: 1.92; acc: 0.39
Batch: 460; loss: 2.07; acc: 0.27
Batch: 480; loss: 2.01; acc: 0.36
Batch: 500; loss: 1.99; acc: 0.34
Batch: 520; loss: 2.0; acc: 0.36
Batch: 540; loss: 2.02; acc: 0.39
Batch: 560; loss: 1.99; acc: 0.33
Batch: 580; loss: 2.24; acc: 0.17
Batch: 600; loss: 1.75; acc: 0.47
Batch: 620; loss: 2.01; acc: 0.36
Batch: 640; loss: 1.92; acc: 0.41
Batch: 660; loss: 1.84; acc: 0.42
Batch: 680; loss: 1.94; acc: 0.33
Batch: 700; loss: 2.08; acc: 0.33
Batch: 720; loss: 1.93; acc: 0.41
Batch: 740; loss: 1.97; acc: 0.33
Batch: 760; loss: 2.02; acc: 0.25
Batch: 780; loss: 1.89; acc: 0.39
Train Epoch over. train_loss: 1.99; train_accuracy: 0.33 

Batch: 0; loss: 1.97; acc: 0.3
Batch: 20; loss: 2.13; acc: 0.3
Batch: 40; loss: 1.7; acc: 0.44
Batch: 60; loss: 1.77; acc: 0.44
Batch: 80; loss: 1.89; acc: 0.36
Batch: 100; loss: 1.89; acc: 0.36
Batch: 120; loss: 1.96; acc: 0.3
Batch: 140; loss: 1.84; acc: 0.41
Val Epoch over. val_loss: 1.8807620926267783; val_accuracy: 0.3443471337579618 

The current subspace-distance is: 1.47619066410698e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.01; acc: 0.33
Batch: 20; loss: 2.09; acc: 0.33
Batch: 40; loss: 1.72; acc: 0.39
Batch: 60; loss: 1.79; acc: 0.38
Batch: 80; loss: 2.04; acc: 0.23
Batch: 100; loss: 1.84; acc: 0.33
Batch: 120; loss: 1.93; acc: 0.22
Batch: 140; loss: 1.84; acc: 0.33
Batch: 160; loss: 1.77; acc: 0.36
Batch: 180; loss: 1.89; acc: 0.28
Batch: 200; loss: 1.79; acc: 0.38
Batch: 220; loss: 1.5; acc: 0.41
Batch: 240; loss: 1.98; acc: 0.28
Batch: 260; loss: 1.92; acc: 0.28
Batch: 280; loss: 1.78; acc: 0.34
Batch: 300; loss: 1.72; acc: 0.39
Batch: 320; loss: 1.79; acc: 0.39
Batch: 340; loss: 1.83; acc: 0.38
Batch: 360; loss: 1.69; acc: 0.39
Batch: 380; loss: 1.72; acc: 0.28
Batch: 400; loss: 1.73; acc: 0.36
Batch: 420; loss: 1.66; acc: 0.47
Batch: 440; loss: 1.76; acc: 0.36
Batch: 460; loss: 1.69; acc: 0.39
Batch: 480; loss: 1.62; acc: 0.48
Batch: 500; loss: 1.81; acc: 0.34
Batch: 520; loss: 1.7; acc: 0.42
Batch: 540; loss: 1.73; acc: 0.36
Batch: 560; loss: 1.75; acc: 0.42
Batch: 580; loss: 1.66; acc: 0.44
Batch: 600; loss: 1.68; acc: 0.39
Batch: 620; loss: 1.81; acc: 0.38
Batch: 640; loss: 1.67; acc: 0.36
Batch: 660; loss: 1.42; acc: 0.48
Batch: 680; loss: 2.02; acc: 0.27
Batch: 700; loss: 1.36; acc: 0.53
Batch: 720; loss: 1.61; acc: 0.44
Batch: 740; loss: 1.81; acc: 0.41
Batch: 760; loss: 1.69; acc: 0.42
Batch: 780; loss: 1.42; acc: 0.52
Train Epoch over. train_loss: 1.73; train_accuracy: 0.38 

Batch: 0; loss: 1.59; acc: 0.52
Batch: 20; loss: 1.95; acc: 0.39
Batch: 40; loss: 1.35; acc: 0.58
Batch: 60; loss: 1.57; acc: 0.5
Batch: 80; loss: 1.62; acc: 0.48
Batch: 100; loss: 1.63; acc: 0.44
Batch: 120; loss: 1.8; acc: 0.45
Batch: 140; loss: 1.58; acc: 0.38
Val Epoch over. val_loss: 1.6143218582602823; val_accuracy: 0.43929140127388533 

The current subspace-distance is: 1.7788388504413888e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.65; acc: 0.44
Batch: 20; loss: 1.66; acc: 0.41
Batch: 40; loss: 1.47; acc: 0.48
Batch: 60; loss: 1.7; acc: 0.38
Batch: 80; loss: 1.68; acc: 0.53
Batch: 100; loss: 1.54; acc: 0.48
Batch: 120; loss: 1.6; acc: 0.44
Batch: 140; loss: 1.85; acc: 0.33
Batch: 160; loss: 1.73; acc: 0.39
Batch: 180; loss: 1.77; acc: 0.44
Batch: 200; loss: 1.51; acc: 0.44
Batch: 220; loss: 1.46; acc: 0.5
Batch: 240; loss: 1.43; acc: 0.55
Batch: 260; loss: 1.32; acc: 0.62
Batch: 280; loss: 1.42; acc: 0.42
Batch: 300; loss: 1.56; acc: 0.44
Batch: 320; loss: 1.81; acc: 0.41
Batch: 340; loss: 1.6; acc: 0.48
Batch: 360; loss: 1.56; acc: 0.5
Batch: 380; loss: 1.83; acc: 0.33
Batch: 400; loss: 1.56; acc: 0.41
Batch: 420; loss: 1.66; acc: 0.42
Batch: 440; loss: 1.71; acc: 0.34
Batch: 460; loss: 1.64; acc: 0.39
Batch: 480; loss: 1.53; acc: 0.47
Batch: 500; loss: 1.63; acc: 0.41
Batch: 520; loss: 1.5; acc: 0.47
Batch: 540; loss: 1.5; acc: 0.53
Batch: 560; loss: 1.65; acc: 0.42
Batch: 580; loss: 1.57; acc: 0.5
Batch: 600; loss: 1.71; acc: 0.47
Batch: 620; loss: 1.86; acc: 0.38
Batch: 640; loss: 1.56; acc: 0.45
Batch: 660; loss: 1.64; acc: 0.45
Batch: 680; loss: 1.62; acc: 0.5
Batch: 700; loss: 1.64; acc: 0.45
Batch: 720; loss: 1.58; acc: 0.45
Batch: 740; loss: 1.65; acc: 0.45
Batch: 760; loss: 1.58; acc: 0.42
Batch: 780; loss: 1.58; acc: 0.44
Train Epoch over. train_loss: 1.62; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.45
Batch: 20; loss: 1.9; acc: 0.39
Batch: 40; loss: 1.3; acc: 0.56
Batch: 60; loss: 1.56; acc: 0.41
Batch: 80; loss: 1.61; acc: 0.47
Batch: 100; loss: 1.66; acc: 0.47
Batch: 120; loss: 1.8; acc: 0.41
Batch: 140; loss: 1.61; acc: 0.38
Val Epoch over. val_loss: 1.600739021969449; val_accuracy: 0.45461783439490444 

The current subspace-distance is: 2.1321915482985787e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.58; acc: 0.53
Batch: 20; loss: 1.65; acc: 0.39
Batch: 40; loss: 1.77; acc: 0.41
Batch: 60; loss: 1.6; acc: 0.55
Batch: 80; loss: 1.49; acc: 0.52
Batch: 100; loss: 1.45; acc: 0.55
Batch: 120; loss: 1.78; acc: 0.36
Batch: 140; loss: 1.61; acc: 0.41
Batch: 160; loss: 1.53; acc: 0.44
Batch: 180; loss: 1.67; acc: 0.41
Batch: 200; loss: 1.6; acc: 0.44
Batch: 220; loss: 1.56; acc: 0.41
Batch: 240; loss: 1.57; acc: 0.45
Batch: 260; loss: 1.71; acc: 0.45
Batch: 280; loss: 1.56; acc: 0.48
Batch: 300; loss: 1.6; acc: 0.45
Batch: 320; loss: 1.47; acc: 0.52
Batch: 340; loss: 1.62; acc: 0.41
Batch: 360; loss: 1.49; acc: 0.48
Batch: 380; loss: 1.51; acc: 0.53
Batch: 400; loss: 1.52; acc: 0.53
Batch: 420; loss: 1.51; acc: 0.42
Batch: 440; loss: 1.45; acc: 0.5
Batch: 460; loss: 1.68; acc: 0.47
Batch: 480; loss: 1.34; acc: 0.53
Batch: 500; loss: 1.57; acc: 0.53
Batch: 520; loss: 1.58; acc: 0.44
Batch: 540; loss: 1.39; acc: 0.56
Batch: 560; loss: 1.56; acc: 0.52
Batch: 580; loss: 1.64; acc: 0.41
Batch: 600; loss: 1.88; acc: 0.38
Batch: 620; loss: 1.72; acc: 0.47
Batch: 640; loss: 1.56; acc: 0.47
Batch: 660; loss: 1.47; acc: 0.53
Batch: 680; loss: 1.52; acc: 0.47
Batch: 700; loss: 1.57; acc: 0.45
Batch: 720; loss: 1.64; acc: 0.34
Batch: 740; loss: 1.4; acc: 0.55
Batch: 760; loss: 1.66; acc: 0.48
Batch: 780; loss: 1.53; acc: 0.48
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.59; acc: 0.45
Batch: 20; loss: 1.91; acc: 0.38
Batch: 40; loss: 1.29; acc: 0.61
Batch: 60; loss: 1.56; acc: 0.53
Batch: 80; loss: 1.63; acc: 0.45
Batch: 100; loss: 1.67; acc: 0.45
Batch: 120; loss: 1.76; acc: 0.47
Batch: 140; loss: 1.59; acc: 0.41
Val Epoch over. val_loss: 1.6032413737789082; val_accuracy: 0.4557125796178344 

The current subspace-distance is: 2.461193798808381e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.53; acc: 0.44
Batch: 20; loss: 1.58; acc: 0.47
Batch: 40; loss: 1.54; acc: 0.47
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.89; acc: 0.38
Batch: 100; loss: 1.65; acc: 0.47
Batch: 120; loss: 1.65; acc: 0.39
Batch: 140; loss: 1.72; acc: 0.45
Batch: 160; loss: 1.67; acc: 0.44
Batch: 180; loss: 1.78; acc: 0.36
Batch: 200; loss: 1.57; acc: 0.48
Batch: 220; loss: 1.56; acc: 0.52
Batch: 240; loss: 1.64; acc: 0.41
Batch: 260; loss: 1.84; acc: 0.38
Batch: 280; loss: 1.65; acc: 0.44
Batch: 300; loss: 1.59; acc: 0.45
Batch: 320; loss: 1.57; acc: 0.52
Batch: 340; loss: 1.71; acc: 0.45
Batch: 360; loss: 1.54; acc: 0.48
Batch: 380; loss: 1.69; acc: 0.42
Batch: 400; loss: 1.67; acc: 0.41
Batch: 420; loss: 1.9; acc: 0.44
Batch: 440; loss: 1.62; acc: 0.39
Batch: 460; loss: 1.82; acc: 0.39
Batch: 480; loss: 1.39; acc: 0.58
Batch: 500; loss: 1.74; acc: 0.36
Batch: 520; loss: 1.37; acc: 0.48
Batch: 540; loss: 1.56; acc: 0.42
Batch: 560; loss: 1.67; acc: 0.39
Batch: 580; loss: 1.82; acc: 0.31
Batch: 600; loss: 1.59; acc: 0.45
Batch: 620; loss: 1.43; acc: 0.53
Batch: 640; loss: 1.5; acc: 0.53
Batch: 660; loss: 1.39; acc: 0.48
Batch: 680; loss: 1.72; acc: 0.41
Batch: 700; loss: 1.57; acc: 0.38
Batch: 720; loss: 1.72; acc: 0.44
Batch: 740; loss: 1.62; acc: 0.42
Batch: 760; loss: 1.44; acc: 0.55
Batch: 780; loss: 1.59; acc: 0.47
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.53; acc: 0.47
Batch: 20; loss: 1.85; acc: 0.45
Batch: 40; loss: 1.26; acc: 0.58
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.6; acc: 0.52
Batch: 120; loss: 1.73; acc: 0.45
Batch: 140; loss: 1.56; acc: 0.41
Val Epoch over. val_loss: 1.5909761926930421; val_accuracy: 0.4576035031847134 

The current subspace-distance is: 2.838466207322199e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.58; acc: 0.47
Batch: 20; loss: 1.62; acc: 0.52
Batch: 40; loss: 1.56; acc: 0.45
Batch: 60; loss: 1.87; acc: 0.34
Batch: 80; loss: 1.49; acc: 0.47
Batch: 100; loss: 1.64; acc: 0.45
Batch: 120; loss: 1.64; acc: 0.45
Batch: 140; loss: 1.65; acc: 0.39
Batch: 160; loss: 1.51; acc: 0.5
Batch: 180; loss: 1.94; acc: 0.34
Batch: 200; loss: 1.68; acc: 0.45
Batch: 220; loss: 1.58; acc: 0.41
Batch: 240; loss: 1.59; acc: 0.45
Batch: 260; loss: 1.65; acc: 0.53
Batch: 280; loss: 1.6; acc: 0.42
Batch: 300; loss: 1.57; acc: 0.38
Batch: 320; loss: 1.73; acc: 0.39
Batch: 340; loss: 1.56; acc: 0.42
Batch: 360; loss: 1.6; acc: 0.41
Batch: 380; loss: 1.37; acc: 0.53
Batch: 400; loss: 1.41; acc: 0.53
Batch: 420; loss: 1.51; acc: 0.58
Batch: 440; loss: 1.68; acc: 0.33
Batch: 460; loss: 1.59; acc: 0.48
Batch: 480; loss: 1.77; acc: 0.48
Batch: 500; loss: 1.66; acc: 0.44
Batch: 520; loss: 1.49; acc: 0.5
Batch: 540; loss: 1.32; acc: 0.58
Batch: 560; loss: 1.82; acc: 0.34
Batch: 580; loss: 1.6; acc: 0.45
Batch: 600; loss: 1.72; acc: 0.45
Batch: 620; loss: 1.53; acc: 0.56
Batch: 640; loss: 1.6; acc: 0.45
Batch: 660; loss: 1.57; acc: 0.45
Batch: 680; loss: 1.78; acc: 0.42
Batch: 700; loss: 1.6; acc: 0.44
Batch: 720; loss: 1.41; acc: 0.5
Batch: 740; loss: 1.4; acc: 0.52
Batch: 760; loss: 1.46; acc: 0.52
Batch: 780; loss: 1.73; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.47
Batch: 20; loss: 1.85; acc: 0.41
Batch: 40; loss: 1.24; acc: 0.61
Batch: 60; loss: 1.51; acc: 0.45
Batch: 80; loss: 1.6; acc: 0.48
Batch: 100; loss: 1.59; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.41
Batch: 140; loss: 1.62; acc: 0.39
Val Epoch over. val_loss: 1.5960753427189627; val_accuracy: 0.45173168789808915 

The current subspace-distance is: 2.9163988074287772e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.47; acc: 0.5
Batch: 20; loss: 1.69; acc: 0.38
Batch: 40; loss: 1.61; acc: 0.48
Batch: 60; loss: 1.47; acc: 0.55
Batch: 80; loss: 1.55; acc: 0.5
Batch: 100; loss: 1.56; acc: 0.42
Batch: 120; loss: 1.78; acc: 0.39
Batch: 140; loss: 1.64; acc: 0.5
Batch: 160; loss: 1.58; acc: 0.42
Batch: 180; loss: 1.53; acc: 0.5
Batch: 200; loss: 1.39; acc: 0.61
Batch: 220; loss: 1.67; acc: 0.39
Batch: 240; loss: 1.52; acc: 0.47
Batch: 260; loss: 1.56; acc: 0.5
Batch: 280; loss: 1.49; acc: 0.47
Batch: 300; loss: 1.6; acc: 0.5
Batch: 320; loss: 1.36; acc: 0.56
Batch: 340; loss: 1.63; acc: 0.41
Batch: 360; loss: 1.48; acc: 0.45
Batch: 380; loss: 1.75; acc: 0.44
Batch: 400; loss: 1.53; acc: 0.59
Batch: 420; loss: 1.67; acc: 0.41
Batch: 440; loss: 1.69; acc: 0.42
Batch: 460; loss: 1.58; acc: 0.48
Batch: 480; loss: 1.67; acc: 0.41
Batch: 500; loss: 1.81; acc: 0.34
Batch: 520; loss: 1.52; acc: 0.45
Batch: 540; loss: 1.58; acc: 0.42
Batch: 560; loss: 1.86; acc: 0.39
Batch: 580; loss: 1.77; acc: 0.36
Batch: 600; loss: 1.47; acc: 0.53
Batch: 620; loss: 1.47; acc: 0.45
Batch: 640; loss: 1.78; acc: 0.38
Batch: 660; loss: 1.54; acc: 0.44
Batch: 680; loss: 1.61; acc: 0.44
Batch: 700; loss: 1.55; acc: 0.44
Batch: 720; loss: 1.48; acc: 0.58
Batch: 740; loss: 1.54; acc: 0.5
Batch: 760; loss: 1.69; acc: 0.45
Batch: 780; loss: 1.95; acc: 0.3
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.87; acc: 0.45
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.41
Val Epoch over. val_loss: 1.584239331020671; val_accuracy: 0.4589968152866242 

The current subspace-distance is: 2.986149411299266e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.69; acc: 0.42
Batch: 20; loss: 1.73; acc: 0.44
Batch: 40; loss: 1.67; acc: 0.41
Batch: 60; loss: 1.66; acc: 0.44
Batch: 80; loss: 1.63; acc: 0.44
Batch: 100; loss: 1.72; acc: 0.52
Batch: 120; loss: 1.73; acc: 0.44
Batch: 140; loss: 1.68; acc: 0.41
Batch: 160; loss: 1.71; acc: 0.41
Batch: 180; loss: 1.64; acc: 0.39
Batch: 200; loss: 1.69; acc: 0.39
Batch: 220; loss: 1.57; acc: 0.48
Batch: 240; loss: 1.54; acc: 0.47
Batch: 260; loss: 1.58; acc: 0.48
Batch: 280; loss: 1.78; acc: 0.39
Batch: 300; loss: 1.84; acc: 0.39
Batch: 320; loss: 1.4; acc: 0.5
Batch: 340; loss: 1.53; acc: 0.47
Batch: 360; loss: 1.48; acc: 0.47
Batch: 380; loss: 1.6; acc: 0.36
Batch: 400; loss: 1.41; acc: 0.61
Batch: 420; loss: 1.62; acc: 0.58
Batch: 440; loss: 1.52; acc: 0.56
Batch: 460; loss: 1.64; acc: 0.41
Batch: 480; loss: 1.57; acc: 0.45
Batch: 500; loss: 1.68; acc: 0.47
Batch: 520; loss: 1.48; acc: 0.58
Batch: 540; loss: 1.53; acc: 0.48
Batch: 560; loss: 1.63; acc: 0.42
Batch: 580; loss: 1.89; acc: 0.36
Batch: 600; loss: 1.8; acc: 0.42
Batch: 620; loss: 1.76; acc: 0.39
Batch: 640; loss: 1.46; acc: 0.53
Batch: 660; loss: 1.72; acc: 0.39
Batch: 680; loss: 1.67; acc: 0.53
Batch: 700; loss: 1.73; acc: 0.41
Batch: 720; loss: 1.58; acc: 0.41
Batch: 740; loss: 1.51; acc: 0.5
Batch: 760; loss: 1.45; acc: 0.5
Batch: 780; loss: 1.7; acc: 0.48
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.88; acc: 0.42
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.53; acc: 0.48
Batch: 80; loss: 1.58; acc: 0.47
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5837387469164126; val_accuracy: 0.4612858280254777 

The current subspace-distance is: 3.229802314308472e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.42; acc: 0.5
Batch: 20; loss: 1.38; acc: 0.59
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.77; acc: 0.34
Batch: 80; loss: 1.75; acc: 0.39
Batch: 100; loss: 1.57; acc: 0.48
Batch: 120; loss: 1.66; acc: 0.47
Batch: 140; loss: 1.61; acc: 0.47
Batch: 160; loss: 1.58; acc: 0.39
Batch: 180; loss: 1.52; acc: 0.5
Batch: 200; loss: 1.45; acc: 0.53
Batch: 220; loss: 1.75; acc: 0.42
Batch: 240; loss: 1.58; acc: 0.47
Batch: 260; loss: 1.59; acc: 0.47
Batch: 280; loss: 1.85; acc: 0.38
Batch: 300; loss: 1.78; acc: 0.3
Batch: 320; loss: 1.7; acc: 0.41
Batch: 340; loss: 1.58; acc: 0.44
Batch: 360; loss: 1.83; acc: 0.38
Batch: 380; loss: 1.56; acc: 0.45
Batch: 400; loss: 1.52; acc: 0.56
Batch: 420; loss: 1.52; acc: 0.53
Batch: 440; loss: 1.7; acc: 0.41
Batch: 460; loss: 1.53; acc: 0.53
Batch: 480; loss: 2.0; acc: 0.28
Batch: 500; loss: 1.66; acc: 0.44
Batch: 520; loss: 1.65; acc: 0.44
Batch: 540; loss: 1.61; acc: 0.48
Batch: 560; loss: 1.81; acc: 0.36
Batch: 580; loss: 1.55; acc: 0.48
Batch: 600; loss: 1.51; acc: 0.42
Batch: 620; loss: 1.56; acc: 0.45
Batch: 640; loss: 1.71; acc: 0.36
Batch: 660; loss: 1.76; acc: 0.47
Batch: 680; loss: 1.43; acc: 0.52
Batch: 700; loss: 1.53; acc: 0.53
Batch: 720; loss: 1.57; acc: 0.45
Batch: 740; loss: 1.57; acc: 0.47
Batch: 760; loss: 1.32; acc: 0.58
Batch: 780; loss: 1.34; acc: 0.5
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.5
Batch: 20; loss: 1.88; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.53; acc: 0.45
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.76; acc: 0.42
Batch: 140; loss: 1.58; acc: 0.45
Val Epoch over. val_loss: 1.5840973034026518; val_accuracy: 0.4592953821656051 

The current subspace-distance is: 3.698951695696451e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.61; acc: 0.45
Batch: 20; loss: 1.65; acc: 0.45
Batch: 40; loss: 1.43; acc: 0.55
Batch: 60; loss: 1.81; acc: 0.38
Batch: 80; loss: 1.53; acc: 0.5
Batch: 100; loss: 1.6; acc: 0.53
Batch: 120; loss: 1.57; acc: 0.52
Batch: 140; loss: 1.58; acc: 0.44
Batch: 160; loss: 1.5; acc: 0.47
Batch: 180; loss: 1.58; acc: 0.41
Batch: 200; loss: 1.75; acc: 0.36
Batch: 220; loss: 1.38; acc: 0.56
Batch: 240; loss: 1.45; acc: 0.53
Batch: 260; loss: 1.61; acc: 0.39
Batch: 280; loss: 1.71; acc: 0.41
Batch: 300; loss: 1.52; acc: 0.55
Batch: 320; loss: 1.89; acc: 0.38
Batch: 340; loss: 1.73; acc: 0.48
Batch: 360; loss: 1.78; acc: 0.42
Batch: 380; loss: 1.33; acc: 0.56
Batch: 400; loss: 1.67; acc: 0.52
Batch: 420; loss: 1.75; acc: 0.42
Batch: 440; loss: 1.72; acc: 0.41
Batch: 460; loss: 1.59; acc: 0.38
Batch: 480; loss: 1.64; acc: 0.45
Batch: 500; loss: 1.66; acc: 0.44
Batch: 520; loss: 1.74; acc: 0.42
Batch: 540; loss: 1.58; acc: 0.42
Batch: 560; loss: 1.65; acc: 0.41
Batch: 580; loss: 1.67; acc: 0.47
Batch: 600; loss: 1.69; acc: 0.47
Batch: 620; loss: 1.58; acc: 0.5
Batch: 640; loss: 2.06; acc: 0.39
Batch: 660; loss: 1.5; acc: 0.52
Batch: 680; loss: 1.52; acc: 0.5
Batch: 700; loss: 1.51; acc: 0.42
Batch: 720; loss: 1.6; acc: 0.47
Batch: 740; loss: 1.54; acc: 0.48
Batch: 760; loss: 1.61; acc: 0.44
Batch: 780; loss: 1.56; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.53; acc: 0.47
Batch: 20; loss: 1.86; acc: 0.45
Batch: 40; loss: 1.23; acc: 0.62
Batch: 60; loss: 1.51; acc: 0.47
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.59; acc: 0.48
Batch: 120; loss: 1.73; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.41
Val Epoch over. val_loss: 1.590055204500818; val_accuracy: 0.45431926751592355 

The current subspace-distance is: 3.84092127205804e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.75; acc: 0.34
Batch: 20; loss: 1.4; acc: 0.42
Batch: 40; loss: 1.58; acc: 0.44
Batch: 60; loss: 1.79; acc: 0.42
Batch: 80; loss: 1.71; acc: 0.44
Batch: 100; loss: 1.75; acc: 0.42
Batch: 120; loss: 1.63; acc: 0.41
Batch: 140; loss: 1.62; acc: 0.42
Batch: 160; loss: 1.67; acc: 0.45
Batch: 180; loss: 1.41; acc: 0.62
Batch: 200; loss: 1.66; acc: 0.41
Batch: 220; loss: 1.7; acc: 0.39
Batch: 240; loss: 1.47; acc: 0.5
Batch: 260; loss: 1.52; acc: 0.5
Batch: 280; loss: 1.63; acc: 0.52
Batch: 300; loss: 1.73; acc: 0.36
Batch: 320; loss: 1.55; acc: 0.44
Batch: 340; loss: 1.66; acc: 0.44
Batch: 360; loss: 1.66; acc: 0.5
Batch: 380; loss: 1.58; acc: 0.45
Batch: 400; loss: 1.6; acc: 0.48
Batch: 420; loss: 1.72; acc: 0.42
Batch: 440; loss: 1.55; acc: 0.53
Batch: 460; loss: 1.74; acc: 0.44
Batch: 480; loss: 1.59; acc: 0.53
Batch: 500; loss: 1.58; acc: 0.44
Batch: 520; loss: 1.45; acc: 0.52
Batch: 540; loss: 1.47; acc: 0.5
Batch: 560; loss: 1.59; acc: 0.48
Batch: 580; loss: 1.81; acc: 0.36
Batch: 600; loss: 1.58; acc: 0.44
Batch: 620; loss: 1.48; acc: 0.5
Batch: 640; loss: 1.6; acc: 0.45
Batch: 660; loss: 1.62; acc: 0.31
Batch: 680; loss: 1.48; acc: 0.47
Batch: 700; loss: 1.72; acc: 0.44
Batch: 720; loss: 1.54; acc: 0.53
Batch: 740; loss: 1.66; acc: 0.44
Batch: 760; loss: 1.77; acc: 0.39
Batch: 780; loss: 1.48; acc: 0.48
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.44
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.54; acc: 0.42
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.63; acc: 0.48
Batch: 120; loss: 1.76; acc: 0.42
Batch: 140; loss: 1.58; acc: 0.41
Val Epoch over. val_loss: 1.5871719357314382; val_accuracy: 0.4534235668789809 

The current subspace-distance is: 4.349893060862087e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.57; acc: 0.48
Batch: 20; loss: 1.75; acc: 0.41
Batch: 40; loss: 1.59; acc: 0.47
Batch: 60; loss: 1.55; acc: 0.34
Batch: 80; loss: 1.53; acc: 0.48
Batch: 100; loss: 1.65; acc: 0.39
Batch: 120; loss: 1.61; acc: 0.42
Batch: 140; loss: 1.63; acc: 0.52
Batch: 160; loss: 1.56; acc: 0.39
Batch: 180; loss: 1.58; acc: 0.52
Batch: 200; loss: 1.48; acc: 0.61
Batch: 220; loss: 1.64; acc: 0.42
Batch: 240; loss: 1.58; acc: 0.45
Batch: 260; loss: 1.7; acc: 0.39
Batch: 280; loss: 1.58; acc: 0.45
Batch: 300; loss: 1.54; acc: 0.5
Batch: 320; loss: 1.61; acc: 0.45
Batch: 340; loss: 1.52; acc: 0.45
Batch: 360; loss: 1.77; acc: 0.36
Batch: 380; loss: 1.53; acc: 0.42
Batch: 400; loss: 1.83; acc: 0.39
Batch: 420; loss: 1.63; acc: 0.45
Batch: 440; loss: 1.69; acc: 0.34
Batch: 460; loss: 1.85; acc: 0.42
Batch: 480; loss: 1.62; acc: 0.42
Batch: 500; loss: 1.54; acc: 0.48
Batch: 520; loss: 1.68; acc: 0.41
Batch: 540; loss: 1.73; acc: 0.44
Batch: 560; loss: 1.53; acc: 0.45
Batch: 580; loss: 1.65; acc: 0.45
Batch: 600; loss: 1.63; acc: 0.45
Batch: 620; loss: 1.61; acc: 0.39
Batch: 640; loss: 1.49; acc: 0.55
Batch: 660; loss: 1.53; acc: 0.52
Batch: 680; loss: 1.73; acc: 0.52
Batch: 700; loss: 1.38; acc: 0.53
Batch: 720; loss: 1.71; acc: 0.39
Batch: 740; loss: 1.39; acc: 0.56
Batch: 760; loss: 1.64; acc: 0.47
Batch: 780; loss: 1.52; acc: 0.48
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.47
Batch: 20; loss: 1.88; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.54; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.63; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.59; acc: 0.41
Val Epoch over. val_loss: 1.5869241117671797; val_accuracy: 0.45849920382165604 

The current subspace-distance is: 4.3716878280974925e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.59; acc: 0.52
Batch: 20; loss: 1.57; acc: 0.47
Batch: 40; loss: 1.72; acc: 0.38
Batch: 60; loss: 1.74; acc: 0.53
Batch: 80; loss: 1.61; acc: 0.5
Batch: 100; loss: 1.65; acc: 0.38
Batch: 120; loss: 1.65; acc: 0.45
Batch: 140; loss: 1.55; acc: 0.47
Batch: 160; loss: 1.54; acc: 0.47
Batch: 180; loss: 1.5; acc: 0.52
Batch: 200; loss: 1.55; acc: 0.44
Batch: 220; loss: 1.55; acc: 0.44
Batch: 240; loss: 1.55; acc: 0.45
Batch: 260; loss: 1.52; acc: 0.42
Batch: 280; loss: 1.91; acc: 0.36
Batch: 300; loss: 1.71; acc: 0.44
Batch: 320; loss: 1.57; acc: 0.55
Batch: 340; loss: 1.57; acc: 0.41
Batch: 360; loss: 1.7; acc: 0.42
Batch: 380; loss: 1.6; acc: 0.5
Batch: 400; loss: 1.45; acc: 0.48
Batch: 420; loss: 1.6; acc: 0.42
Batch: 440; loss: 1.5; acc: 0.52
Batch: 460; loss: 1.58; acc: 0.48
Batch: 480; loss: 1.44; acc: 0.52
Batch: 500; loss: 1.42; acc: 0.47
Batch: 520; loss: 1.86; acc: 0.39
Batch: 540; loss: 1.52; acc: 0.56
Batch: 560; loss: 1.54; acc: 0.44
Batch: 580; loss: 1.83; acc: 0.33
Batch: 600; loss: 2.0; acc: 0.39
Batch: 620; loss: 1.41; acc: 0.56
Batch: 640; loss: 1.76; acc: 0.41
Batch: 660; loss: 1.53; acc: 0.53
Batch: 680; loss: 1.77; acc: 0.42
Batch: 700; loss: 1.64; acc: 0.38
Batch: 720; loss: 1.47; acc: 0.56
Batch: 740; loss: 1.54; acc: 0.45
Batch: 760; loss: 1.68; acc: 0.34
Batch: 780; loss: 1.53; acc: 0.38
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.56; acc: 0.48
Batch: 20; loss: 1.89; acc: 0.38
Batch: 40; loss: 1.26; acc: 0.64
Batch: 60; loss: 1.55; acc: 0.45
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.64; acc: 0.44
Batch: 120; loss: 1.77; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.44
Val Epoch over. val_loss: 1.585787404115033; val_accuracy: 0.4615843949044586 

The current subspace-distance is: 4.310964504838921e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.68; acc: 0.42
Batch: 20; loss: 1.66; acc: 0.44
Batch: 40; loss: 1.52; acc: 0.45
Batch: 60; loss: 1.53; acc: 0.5
Batch: 80; loss: 1.6; acc: 0.45
Batch: 100; loss: 1.56; acc: 0.48
Batch: 120; loss: 1.54; acc: 0.44
Batch: 140; loss: 1.62; acc: 0.38
Batch: 160; loss: 1.56; acc: 0.52
Batch: 180; loss: 1.58; acc: 0.41
Batch: 200; loss: 1.57; acc: 0.39
Batch: 220; loss: 1.67; acc: 0.39
Batch: 240; loss: 1.72; acc: 0.45
Batch: 260; loss: 1.45; acc: 0.5
Batch: 280; loss: 1.64; acc: 0.42
Batch: 300; loss: 1.63; acc: 0.5
Batch: 320; loss: 1.67; acc: 0.5
Batch: 340; loss: 1.53; acc: 0.47
Batch: 360; loss: 1.62; acc: 0.41
Batch: 380; loss: 1.71; acc: 0.45
Batch: 400; loss: 1.6; acc: 0.41
Batch: 420; loss: 1.41; acc: 0.52
Batch: 440; loss: 1.6; acc: 0.47
Batch: 460; loss: 1.92; acc: 0.33
Batch: 480; loss: 1.74; acc: 0.33
Batch: 500; loss: 1.75; acc: 0.36
Batch: 520; loss: 1.75; acc: 0.39
Batch: 540; loss: 1.72; acc: 0.38
Batch: 560; loss: 1.76; acc: 0.42
Batch: 580; loss: 1.69; acc: 0.45
Batch: 600; loss: 1.77; acc: 0.34
Batch: 620; loss: 1.83; acc: 0.33
Batch: 640; loss: 1.77; acc: 0.44
Batch: 660; loss: 1.57; acc: 0.44
Batch: 680; loss: 1.39; acc: 0.58
Batch: 700; loss: 1.45; acc: 0.52
Batch: 720; loss: 1.55; acc: 0.45
Batch: 740; loss: 1.89; acc: 0.34
Batch: 760; loss: 1.85; acc: 0.42
Batch: 780; loss: 1.62; acc: 0.45
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.47
Batch: 20; loss: 1.88; acc: 0.44
Batch: 40; loss: 1.26; acc: 0.61
Batch: 60; loss: 1.53; acc: 0.47
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.76; acc: 0.42
Batch: 140; loss: 1.57; acc: 0.42
Val Epoch over. val_loss: 1.5841692769603364; val_accuracy: 0.46178343949044587 

The current subspace-distance is: 4.507232370087877e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.58; acc: 0.53
Batch: 20; loss: 1.39; acc: 0.52
Batch: 40; loss: 1.51; acc: 0.48
Batch: 60; loss: 1.6; acc: 0.44
Batch: 80; loss: 1.49; acc: 0.48
Batch: 100; loss: 1.39; acc: 0.52
Batch: 120; loss: 1.54; acc: 0.41
Batch: 140; loss: 1.76; acc: 0.38
Batch: 160; loss: 1.73; acc: 0.42
Batch: 180; loss: 1.75; acc: 0.41
Batch: 200; loss: 1.5; acc: 0.55
Batch: 220; loss: 1.46; acc: 0.48
Batch: 240; loss: 1.65; acc: 0.47
Batch: 260; loss: 1.64; acc: 0.36
Batch: 280; loss: 1.67; acc: 0.38
Batch: 300; loss: 1.61; acc: 0.48
Batch: 320; loss: 1.44; acc: 0.5
Batch: 340; loss: 1.63; acc: 0.42
Batch: 360; loss: 1.37; acc: 0.58
Batch: 380; loss: 1.66; acc: 0.47
Batch: 400; loss: 1.38; acc: 0.45
Batch: 420; loss: 1.66; acc: 0.28
Batch: 440; loss: 1.84; acc: 0.34
Batch: 460; loss: 1.78; acc: 0.31
Batch: 480; loss: 1.41; acc: 0.53
Batch: 500; loss: 1.57; acc: 0.52
Batch: 520; loss: 1.48; acc: 0.52
Batch: 540; loss: 1.73; acc: 0.41
Batch: 560; loss: 1.66; acc: 0.41
Batch: 580; loss: 1.73; acc: 0.38
Batch: 600; loss: 1.45; acc: 0.56
Batch: 620; loss: 1.51; acc: 0.44
Batch: 640; loss: 1.6; acc: 0.45
Batch: 660; loss: 1.62; acc: 0.47
Batch: 680; loss: 1.67; acc: 0.47
Batch: 700; loss: 1.64; acc: 0.44
Batch: 720; loss: 1.7; acc: 0.42
Batch: 740; loss: 1.76; acc: 0.38
Batch: 760; loss: 1.6; acc: 0.48
Batch: 780; loss: 1.64; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.47
Batch: 20; loss: 1.87; acc: 0.39
Batch: 40; loss: 1.25; acc: 0.64
Batch: 60; loss: 1.53; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.42
Val Epoch over. val_loss: 1.5845679105467099; val_accuracy: 0.460390127388535 

The current subspace-distance is: 4.7674715460743755e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.6; acc: 0.5
Batch: 20; loss: 1.57; acc: 0.48
Batch: 40; loss: 1.75; acc: 0.48
Batch: 60; loss: 1.9; acc: 0.33
Batch: 80; loss: 1.6; acc: 0.48
Batch: 100; loss: 1.62; acc: 0.41
Batch: 120; loss: 1.74; acc: 0.41
Batch: 140; loss: 1.46; acc: 0.53
Batch: 160; loss: 1.47; acc: 0.56
Batch: 180; loss: 1.4; acc: 0.5
Batch: 200; loss: 1.55; acc: 0.41
Batch: 220; loss: 1.48; acc: 0.52
Batch: 240; loss: 1.66; acc: 0.38
Batch: 260; loss: 1.5; acc: 0.48
Batch: 280; loss: 1.72; acc: 0.47
Batch: 300; loss: 1.56; acc: 0.56
Batch: 320; loss: 1.66; acc: 0.45
Batch: 340; loss: 1.45; acc: 0.47
Batch: 360; loss: 1.4; acc: 0.52
Batch: 380; loss: 1.57; acc: 0.42
Batch: 400; loss: 1.6; acc: 0.48
Batch: 420; loss: 1.56; acc: 0.45
Batch: 440; loss: 1.46; acc: 0.62
Batch: 460; loss: 1.47; acc: 0.52
Batch: 480; loss: 1.49; acc: 0.55
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.66; acc: 0.48
Batch: 540; loss: 1.48; acc: 0.47
Batch: 560; loss: 1.72; acc: 0.41
Batch: 580; loss: 1.6; acc: 0.36
Batch: 600; loss: 1.66; acc: 0.39
Batch: 620; loss: 1.45; acc: 0.55
Batch: 640; loss: 1.6; acc: 0.42
Batch: 660; loss: 1.49; acc: 0.47
Batch: 680; loss: 1.83; acc: 0.36
Batch: 700; loss: 1.46; acc: 0.55
Batch: 720; loss: 1.48; acc: 0.53
Batch: 740; loss: 1.69; acc: 0.41
Batch: 760; loss: 1.9; acc: 0.3
Batch: 780; loss: 1.7; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.88; acc: 0.44
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.47
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.38
Val Epoch over. val_loss: 1.584655092020703; val_accuracy: 0.461484872611465 

The current subspace-distance is: 4.858737884205766e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.62; acc: 0.45
Batch: 20; loss: 1.73; acc: 0.33
Batch: 40; loss: 1.88; acc: 0.31
Batch: 60; loss: 1.54; acc: 0.5
Batch: 80; loss: 1.76; acc: 0.41
Batch: 100; loss: 1.62; acc: 0.47
Batch: 120; loss: 1.5; acc: 0.48
Batch: 140; loss: 1.42; acc: 0.48
Batch: 160; loss: 1.64; acc: 0.48
Batch: 180; loss: 1.76; acc: 0.33
Batch: 200; loss: 1.57; acc: 0.48
Batch: 220; loss: 1.65; acc: 0.47
Batch: 240; loss: 1.74; acc: 0.38
Batch: 260; loss: 1.44; acc: 0.53
Batch: 280; loss: 1.58; acc: 0.47
Batch: 300; loss: 1.58; acc: 0.47
Batch: 320; loss: 1.72; acc: 0.47
Batch: 340; loss: 1.66; acc: 0.44
Batch: 360; loss: 1.47; acc: 0.52
Batch: 380; loss: 1.72; acc: 0.42
Batch: 400; loss: 1.65; acc: 0.48
Batch: 420; loss: 1.71; acc: 0.39
Batch: 440; loss: 1.43; acc: 0.53
Batch: 460; loss: 1.81; acc: 0.36
Batch: 480; loss: 1.57; acc: 0.39
Batch: 500; loss: 1.58; acc: 0.48
Batch: 520; loss: 1.45; acc: 0.52
Batch: 540; loss: 1.42; acc: 0.5
Batch: 560; loss: 1.64; acc: 0.44
Batch: 580; loss: 1.55; acc: 0.45
Batch: 600; loss: 1.9; acc: 0.3
Batch: 620; loss: 1.5; acc: 0.44
Batch: 640; loss: 1.58; acc: 0.42
Batch: 660; loss: 1.69; acc: 0.36
Batch: 680; loss: 1.65; acc: 0.42
Batch: 700; loss: 1.5; acc: 0.52
Batch: 720; loss: 1.5; acc: 0.47
Batch: 740; loss: 1.73; acc: 0.45
Batch: 760; loss: 1.69; acc: 0.42
Batch: 780; loss: 1.71; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.86; acc: 0.42
Batch: 40; loss: 1.25; acc: 0.59
Batch: 60; loss: 1.51; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.45
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.42
Val Epoch over. val_loss: 1.585131718854236; val_accuracy: 0.45740445859872614 

The current subspace-distance is: 4.98365807288792e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.66; acc: 0.44
Batch: 20; loss: 1.6; acc: 0.44
Batch: 40; loss: 1.5; acc: 0.41
Batch: 60; loss: 1.35; acc: 0.53
Batch: 80; loss: 1.43; acc: 0.48
Batch: 100; loss: 1.57; acc: 0.44
Batch: 120; loss: 1.5; acc: 0.44
Batch: 140; loss: 1.72; acc: 0.36
Batch: 160; loss: 1.53; acc: 0.5
Batch: 180; loss: 1.74; acc: 0.39
Batch: 200; loss: 1.81; acc: 0.52
Batch: 220; loss: 1.74; acc: 0.36
Batch: 240; loss: 1.86; acc: 0.3
Batch: 260; loss: 1.64; acc: 0.36
Batch: 280; loss: 1.69; acc: 0.42
Batch: 300; loss: 1.38; acc: 0.53
Batch: 320; loss: 1.76; acc: 0.33
Batch: 340; loss: 1.52; acc: 0.48
Batch: 360; loss: 1.81; acc: 0.41
Batch: 380; loss: 1.76; acc: 0.34
Batch: 400; loss: 1.64; acc: 0.42
Batch: 420; loss: 1.56; acc: 0.45
Batch: 440; loss: 1.48; acc: 0.48
Batch: 460; loss: 1.92; acc: 0.34
Batch: 480; loss: 1.66; acc: 0.48
Batch: 500; loss: 1.42; acc: 0.5
Batch: 520; loss: 1.45; acc: 0.53
Batch: 540; loss: 1.49; acc: 0.59
Batch: 560; loss: 1.63; acc: 0.38
Batch: 580; loss: 1.54; acc: 0.42
Batch: 600; loss: 1.66; acc: 0.45
Batch: 620; loss: 1.64; acc: 0.36
Batch: 640; loss: 1.36; acc: 0.52
Batch: 660; loss: 1.77; acc: 0.36
Batch: 680; loss: 1.7; acc: 0.34
Batch: 700; loss: 1.67; acc: 0.42
Batch: 720; loss: 1.81; acc: 0.36
Batch: 740; loss: 1.67; acc: 0.39
Batch: 760; loss: 1.61; acc: 0.42
Batch: 780; loss: 1.47; acc: 0.53
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.86; acc: 0.44
Batch: 40; loss: 1.24; acc: 0.62
Batch: 60; loss: 1.51; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.6; acc: 0.48
Batch: 120; loss: 1.73; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.39
Val Epoch over. val_loss: 1.58529536663347; val_accuracy: 0.4589968152866242 

The current subspace-distance is: 5.05302450619638e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.55; acc: 0.44
Batch: 20; loss: 1.58; acc: 0.5
Batch: 40; loss: 1.47; acc: 0.55
Batch: 60; loss: 1.52; acc: 0.53
Batch: 80; loss: 1.48; acc: 0.5
Batch: 100; loss: 1.78; acc: 0.36
Batch: 120; loss: 1.71; acc: 0.41
Batch: 140; loss: 2.09; acc: 0.3
Batch: 160; loss: 1.64; acc: 0.48
Batch: 180; loss: 1.59; acc: 0.42
Batch: 200; loss: 1.77; acc: 0.38
Batch: 220; loss: 1.85; acc: 0.38
Batch: 240; loss: 1.51; acc: 0.41
Batch: 260; loss: 1.58; acc: 0.48
Batch: 280; loss: 1.49; acc: 0.5
Batch: 300; loss: 1.38; acc: 0.56
Batch: 320; loss: 1.32; acc: 0.59
Batch: 340; loss: 1.54; acc: 0.44
Batch: 360; loss: 1.81; acc: 0.44
Batch: 380; loss: 1.6; acc: 0.41
Batch: 400; loss: 1.88; acc: 0.36
Batch: 420; loss: 1.69; acc: 0.45
Batch: 440; loss: 1.8; acc: 0.47
Batch: 460; loss: 1.67; acc: 0.39
Batch: 480; loss: 1.67; acc: 0.38
Batch: 500; loss: 1.62; acc: 0.42
Batch: 520; loss: 1.61; acc: 0.36
Batch: 540; loss: 1.56; acc: 0.45
Batch: 560; loss: 1.7; acc: 0.44
Batch: 580; loss: 1.48; acc: 0.5
Batch: 600; loss: 1.71; acc: 0.42
Batch: 620; loss: 1.59; acc: 0.45
Batch: 640; loss: 1.63; acc: 0.39
Batch: 660; loss: 1.73; acc: 0.41
Batch: 680; loss: 1.41; acc: 0.53
Batch: 700; loss: 1.55; acc: 0.59
Batch: 720; loss: 1.68; acc: 0.39
Batch: 740; loss: 1.47; acc: 0.5
Batch: 760; loss: 1.76; acc: 0.33
Batch: 780; loss: 1.55; acc: 0.39
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.88; acc: 0.44
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.45
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.41
Val Epoch over. val_loss: 1.5842171542963404; val_accuracy: 0.4598925159235669 

The current subspace-distance is: 5.0874394219135866e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.65; acc: 0.5
Batch: 20; loss: 1.62; acc: 0.36
Batch: 40; loss: 1.48; acc: 0.5
Batch: 60; loss: 1.38; acc: 0.55
Batch: 80; loss: 1.82; acc: 0.36
Batch: 100; loss: 1.81; acc: 0.38
Batch: 120; loss: 1.49; acc: 0.45
Batch: 140; loss: 1.61; acc: 0.39
Batch: 160; loss: 1.62; acc: 0.45
Batch: 180; loss: 1.78; acc: 0.31
Batch: 200; loss: 1.79; acc: 0.41
Batch: 220; loss: 1.49; acc: 0.53
Batch: 240; loss: 1.63; acc: 0.48
Batch: 260; loss: 1.55; acc: 0.53
Batch: 280; loss: 1.66; acc: 0.45
Batch: 300; loss: 1.56; acc: 0.47
Batch: 320; loss: 1.76; acc: 0.41
Batch: 340; loss: 1.61; acc: 0.41
Batch: 360; loss: 1.67; acc: 0.45
Batch: 380; loss: 1.76; acc: 0.41
Batch: 400; loss: 1.42; acc: 0.55
Batch: 420; loss: 1.94; acc: 0.31
Batch: 440; loss: 1.54; acc: 0.47
Batch: 460; loss: 1.45; acc: 0.52
Batch: 480; loss: 1.56; acc: 0.45
Batch: 500; loss: 1.56; acc: 0.5
Batch: 520; loss: 1.74; acc: 0.48
Batch: 540; loss: 1.57; acc: 0.42
Batch: 560; loss: 1.67; acc: 0.41
Batch: 580; loss: 1.43; acc: 0.53
Batch: 600; loss: 1.61; acc: 0.44
Batch: 620; loss: 1.67; acc: 0.44
Batch: 640; loss: 1.53; acc: 0.42
Batch: 660; loss: 1.75; acc: 0.47
Batch: 680; loss: 1.57; acc: 0.42
Batch: 700; loss: 1.6; acc: 0.44
Batch: 720; loss: 1.72; acc: 0.42
Batch: 740; loss: 1.47; acc: 0.55
Batch: 760; loss: 1.8; acc: 0.38
Batch: 780; loss: 1.48; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.42
Batch: 40; loss: 1.26; acc: 0.59
Batch: 60; loss: 1.53; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.76; acc: 0.42
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5839959276709588; val_accuracy: 0.461484872611465 

The current subspace-distance is: 4.9919355660676956e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.81; acc: 0.39
Batch: 20; loss: 1.44; acc: 0.55
Batch: 40; loss: 1.38; acc: 0.47
Batch: 60; loss: 1.67; acc: 0.41
Batch: 80; loss: 1.58; acc: 0.53
Batch: 100; loss: 1.75; acc: 0.42
Batch: 120; loss: 1.69; acc: 0.34
Batch: 140; loss: 1.88; acc: 0.31
Batch: 160; loss: 1.7; acc: 0.48
Batch: 180; loss: 1.5; acc: 0.52
Batch: 200; loss: 1.8; acc: 0.38
Batch: 220; loss: 1.78; acc: 0.38
Batch: 240; loss: 1.57; acc: 0.41
Batch: 260; loss: 1.55; acc: 0.48
Batch: 280; loss: 1.36; acc: 0.55
Batch: 300; loss: 1.75; acc: 0.41
Batch: 320; loss: 1.52; acc: 0.47
Batch: 340; loss: 1.7; acc: 0.45
Batch: 360; loss: 1.42; acc: 0.45
Batch: 380; loss: 1.57; acc: 0.44
Batch: 400; loss: 1.58; acc: 0.41
Batch: 420; loss: 1.43; acc: 0.55
Batch: 440; loss: 1.85; acc: 0.38
Batch: 460; loss: 1.78; acc: 0.48
Batch: 480; loss: 1.36; acc: 0.53
Batch: 500; loss: 1.59; acc: 0.5
Batch: 520; loss: 1.62; acc: 0.41
Batch: 540; loss: 1.5; acc: 0.53
Batch: 560; loss: 1.57; acc: 0.42
Batch: 580; loss: 1.57; acc: 0.44
Batch: 600; loss: 1.67; acc: 0.47
Batch: 620; loss: 1.76; acc: 0.5
Batch: 640; loss: 1.79; acc: 0.33
Batch: 660; loss: 1.43; acc: 0.56
Batch: 680; loss: 1.66; acc: 0.44
Batch: 700; loss: 1.64; acc: 0.42
Batch: 720; loss: 1.51; acc: 0.5
Batch: 740; loss: 1.49; acc: 0.48
Batch: 760; loss: 1.71; acc: 0.42
Batch: 780; loss: 1.47; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.85; acc: 0.42
Batch: 40; loss: 1.24; acc: 0.61
Batch: 60; loss: 1.51; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.45
Batch: 100; loss: 1.6; acc: 0.48
Batch: 120; loss: 1.73; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.42
Val Epoch over. val_loss: 1.5859790288718643; val_accuracy: 0.4573049363057325 

The current subspace-distance is: 5.3737170674139634e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.53; acc: 0.47
Batch: 20; loss: 1.63; acc: 0.48
Batch: 40; loss: 1.73; acc: 0.41
Batch: 60; loss: 1.65; acc: 0.42
Batch: 80; loss: 1.77; acc: 0.44
Batch: 100; loss: 1.56; acc: 0.48
Batch: 120; loss: 1.77; acc: 0.38
Batch: 140; loss: 1.62; acc: 0.5
Batch: 160; loss: 1.5; acc: 0.42
Batch: 180; loss: 1.22; acc: 0.58
Batch: 200; loss: 1.78; acc: 0.36
Batch: 220; loss: 1.79; acc: 0.41
Batch: 240; loss: 1.64; acc: 0.5
Batch: 260; loss: 1.84; acc: 0.34
Batch: 280; loss: 1.56; acc: 0.41
Batch: 300; loss: 1.82; acc: 0.33
Batch: 320; loss: 1.4; acc: 0.5
Batch: 340; loss: 1.62; acc: 0.52
Batch: 360; loss: 1.74; acc: 0.36
Batch: 380; loss: 1.49; acc: 0.48
Batch: 400; loss: 1.74; acc: 0.39
Batch: 420; loss: 1.52; acc: 0.41
Batch: 440; loss: 1.5; acc: 0.52
Batch: 460; loss: 1.46; acc: 0.52
Batch: 480; loss: 1.49; acc: 0.55
Batch: 500; loss: 1.51; acc: 0.47
Batch: 520; loss: 1.65; acc: 0.45
Batch: 540; loss: 1.52; acc: 0.41
Batch: 560; loss: 1.83; acc: 0.39
Batch: 580; loss: 1.63; acc: 0.41
Batch: 600; loss: 1.62; acc: 0.5
Batch: 620; loss: 1.55; acc: 0.44
Batch: 640; loss: 1.78; acc: 0.39
Batch: 660; loss: 1.75; acc: 0.42
Batch: 680; loss: 1.61; acc: 0.44
Batch: 700; loss: 1.55; acc: 0.5
Batch: 720; loss: 1.66; acc: 0.42
Batch: 740; loss: 1.51; acc: 0.55
Batch: 760; loss: 1.48; acc: 0.53
Batch: 780; loss: 1.71; acc: 0.41
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.48
Batch: 20; loss: 1.88; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.53; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.63; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.42
Batch: 140; loss: 1.57; acc: 0.42
Val Epoch over. val_loss: 1.5840536333193445; val_accuracy: 0.4619824840764331 

The current subspace-distance is: 5.812610106659122e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.51; acc: 0.56
Batch: 20; loss: 1.54; acc: 0.52
Batch: 40; loss: 1.71; acc: 0.47
Batch: 60; loss: 1.86; acc: 0.38
Batch: 80; loss: 1.47; acc: 0.45
Batch: 100; loss: 1.68; acc: 0.45
Batch: 120; loss: 1.52; acc: 0.44
Batch: 140; loss: 1.51; acc: 0.53
Batch: 160; loss: 1.54; acc: 0.39
Batch: 180; loss: 1.67; acc: 0.38
Batch: 200; loss: 1.52; acc: 0.5
Batch: 220; loss: 1.51; acc: 0.48
Batch: 240; loss: 1.53; acc: 0.48
Batch: 260; loss: 1.7; acc: 0.42
Batch: 280; loss: 1.47; acc: 0.48
Batch: 300; loss: 1.58; acc: 0.48
Batch: 320; loss: 1.58; acc: 0.47
Batch: 340; loss: 1.54; acc: 0.45
Batch: 360; loss: 1.59; acc: 0.44
Batch: 380; loss: 1.54; acc: 0.56
Batch: 400; loss: 1.67; acc: 0.45
Batch: 420; loss: 1.7; acc: 0.42
Batch: 440; loss: 1.71; acc: 0.45
Batch: 460; loss: 1.55; acc: 0.48
Batch: 480; loss: 1.73; acc: 0.44
Batch: 500; loss: 1.72; acc: 0.45
Batch: 520; loss: 1.58; acc: 0.52
Batch: 540; loss: 1.51; acc: 0.5
Batch: 560; loss: 1.7; acc: 0.34
Batch: 580; loss: 1.49; acc: 0.55
Batch: 600; loss: 1.52; acc: 0.47
Batch: 620; loss: 1.55; acc: 0.48
Batch: 640; loss: 1.59; acc: 0.48
Batch: 660; loss: 1.58; acc: 0.48
Batch: 680; loss: 1.63; acc: 0.45
Batch: 700; loss: 1.65; acc: 0.45
Batch: 720; loss: 1.73; acc: 0.45
Batch: 740; loss: 1.68; acc: 0.42
Batch: 760; loss: 1.7; acc: 0.44
Batch: 780; loss: 1.68; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.87; acc: 0.39
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.42
Batch: 140; loss: 1.58; acc: 0.44
Val Epoch over. val_loss: 1.5839345887967735; val_accuracy: 0.45869824840764334 

The current subspace-distance is: 6.135697185527533e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.71; acc: 0.48
Batch: 20; loss: 2.07; acc: 0.28
Batch: 40; loss: 1.59; acc: 0.42
Batch: 60; loss: 1.49; acc: 0.5
Batch: 80; loss: 1.63; acc: 0.48
Batch: 100; loss: 1.51; acc: 0.55
Batch: 120; loss: 1.61; acc: 0.45
Batch: 140; loss: 1.64; acc: 0.48
Batch: 160; loss: 1.66; acc: 0.45
Batch: 180; loss: 1.69; acc: 0.38
Batch: 200; loss: 1.57; acc: 0.53
Batch: 220; loss: 1.68; acc: 0.48
Batch: 240; loss: 1.67; acc: 0.44
Batch: 260; loss: 1.46; acc: 0.52
Batch: 280; loss: 1.48; acc: 0.47
Batch: 300; loss: 1.53; acc: 0.48
Batch: 320; loss: 1.44; acc: 0.52
Batch: 340; loss: 1.58; acc: 0.42
Batch: 360; loss: 1.5; acc: 0.5
Batch: 380; loss: 1.67; acc: 0.36
Batch: 400; loss: 1.53; acc: 0.53
Batch: 420; loss: 1.65; acc: 0.47
Batch: 440; loss: 1.7; acc: 0.45
Batch: 460; loss: 1.42; acc: 0.55
Batch: 480; loss: 1.53; acc: 0.53
Batch: 500; loss: 1.66; acc: 0.39
Batch: 520; loss: 1.72; acc: 0.41
Batch: 540; loss: 1.82; acc: 0.48
Batch: 560; loss: 1.5; acc: 0.5
Batch: 580; loss: 1.67; acc: 0.47
Batch: 600; loss: 1.66; acc: 0.47
Batch: 620; loss: 1.72; acc: 0.39
Batch: 640; loss: 1.75; acc: 0.47
Batch: 660; loss: 1.55; acc: 0.45
Batch: 680; loss: 1.65; acc: 0.45
Batch: 700; loss: 1.68; acc: 0.42
Batch: 720; loss: 1.63; acc: 0.48
Batch: 740; loss: 1.65; acc: 0.42
Batch: 760; loss: 1.71; acc: 0.41
Batch: 780; loss: 1.69; acc: 0.42
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.42
Batch: 140; loss: 1.57; acc: 0.45
Val Epoch over. val_loss: 1.5836654051094299; val_accuracy: 0.4583001592356688 

The current subspace-distance is: 6.220211798790842e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.6; acc: 0.45
Batch: 20; loss: 1.6; acc: 0.45
Batch: 40; loss: 1.54; acc: 0.44
Batch: 60; loss: 1.6; acc: 0.44
Batch: 80; loss: 1.69; acc: 0.41
Batch: 100; loss: 1.81; acc: 0.39
Batch: 120; loss: 1.52; acc: 0.48
Batch: 140; loss: 1.87; acc: 0.38
Batch: 160; loss: 1.88; acc: 0.36
Batch: 180; loss: 1.61; acc: 0.36
Batch: 200; loss: 1.39; acc: 0.52
Batch: 220; loss: 1.55; acc: 0.48
Batch: 240; loss: 1.64; acc: 0.42
Batch: 260; loss: 1.67; acc: 0.44
Batch: 280; loss: 1.6; acc: 0.45
Batch: 300; loss: 1.72; acc: 0.41
Batch: 320; loss: 1.63; acc: 0.45
Batch: 340; loss: 1.72; acc: 0.38
Batch: 360; loss: 1.69; acc: 0.45
Batch: 380; loss: 1.64; acc: 0.47
Batch: 400; loss: 1.54; acc: 0.5
Batch: 420; loss: 1.68; acc: 0.45
Batch: 440; loss: 1.73; acc: 0.38
Batch: 460; loss: 1.57; acc: 0.48
Batch: 480; loss: 1.52; acc: 0.55
Batch: 500; loss: 1.69; acc: 0.47
Batch: 520; loss: 1.66; acc: 0.5
Batch: 540; loss: 1.63; acc: 0.48
Batch: 560; loss: 1.65; acc: 0.42
Batch: 580; loss: 1.75; acc: 0.44
Batch: 600; loss: 1.58; acc: 0.42
Batch: 620; loss: 1.7; acc: 0.42
Batch: 640; loss: 1.67; acc: 0.41
Batch: 660; loss: 1.66; acc: 0.39
Batch: 680; loss: 1.55; acc: 0.5
Batch: 700; loss: 1.69; acc: 0.44
Batch: 720; loss: 1.66; acc: 0.47
Batch: 740; loss: 1.35; acc: 0.53
Batch: 760; loss: 1.82; acc: 0.39
Batch: 780; loss: 1.39; acc: 0.5
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.87; acc: 0.42
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.58; acc: 0.48
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.42
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5834953617897762; val_accuracy: 0.4592953821656051 

The current subspace-distance is: 6.191504508024082e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.75; acc: 0.36
Batch: 20; loss: 1.68; acc: 0.36
Batch: 40; loss: 1.5; acc: 0.44
Batch: 60; loss: 1.84; acc: 0.33
Batch: 80; loss: 1.58; acc: 0.5
Batch: 100; loss: 1.61; acc: 0.47
Batch: 120; loss: 1.71; acc: 0.39
Batch: 140; loss: 1.78; acc: 0.41
Batch: 160; loss: 1.74; acc: 0.39
Batch: 180; loss: 1.56; acc: 0.53
Batch: 200; loss: 1.78; acc: 0.36
Batch: 220; loss: 1.5; acc: 0.53
Batch: 240; loss: 1.63; acc: 0.41
Batch: 260; loss: 1.91; acc: 0.39
Batch: 280; loss: 1.87; acc: 0.39
Batch: 300; loss: 1.45; acc: 0.5
Batch: 320; loss: 1.47; acc: 0.52
Batch: 340; loss: 1.64; acc: 0.41
Batch: 360; loss: 1.56; acc: 0.48
Batch: 380; loss: 1.58; acc: 0.45
Batch: 400; loss: 1.77; acc: 0.41
Batch: 420; loss: 1.6; acc: 0.47
Batch: 440; loss: 1.73; acc: 0.31
Batch: 460; loss: 1.72; acc: 0.38
Batch: 480; loss: 1.6; acc: 0.48
Batch: 500; loss: 1.35; acc: 0.55
Batch: 520; loss: 1.66; acc: 0.5
Batch: 540; loss: 1.41; acc: 0.44
Batch: 560; loss: 1.77; acc: 0.36
Batch: 580; loss: 1.7; acc: 0.44
Batch: 600; loss: 1.8; acc: 0.38
Batch: 620; loss: 1.63; acc: 0.39
Batch: 640; loss: 1.49; acc: 0.42
Batch: 660; loss: 1.6; acc: 0.48
Batch: 680; loss: 1.62; acc: 0.47
Batch: 700; loss: 1.7; acc: 0.39
Batch: 720; loss: 1.93; acc: 0.41
Batch: 740; loss: 1.43; acc: 0.52
Batch: 760; loss: 1.69; acc: 0.45
Batch: 780; loss: 1.51; acc: 0.5
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.45
Batch: 20; loss: 1.86; acc: 0.42
Batch: 40; loss: 1.25; acc: 0.59
Batch: 60; loss: 1.51; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.584576991712971; val_accuracy: 0.4589968152866242 

The current subspace-distance is: 6.358751852530986e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.47; acc: 0.47
Batch: 20; loss: 1.86; acc: 0.39
Batch: 40; loss: 1.64; acc: 0.47
Batch: 60; loss: 1.5; acc: 0.53
Batch: 80; loss: 1.4; acc: 0.52
Batch: 100; loss: 1.89; acc: 0.38
Batch: 120; loss: 1.62; acc: 0.53
Batch: 140; loss: 1.78; acc: 0.39
Batch: 160; loss: 1.53; acc: 0.48
Batch: 180; loss: 1.54; acc: 0.47
Batch: 200; loss: 1.48; acc: 0.5
Batch: 220; loss: 1.48; acc: 0.55
Batch: 240; loss: 1.52; acc: 0.48
Batch: 260; loss: 1.52; acc: 0.45
Batch: 280; loss: 1.56; acc: 0.5
Batch: 300; loss: 1.57; acc: 0.36
Batch: 320; loss: 1.66; acc: 0.45
Batch: 340; loss: 1.62; acc: 0.42
Batch: 360; loss: 1.54; acc: 0.52
Batch: 380; loss: 1.5; acc: 0.5
Batch: 400; loss: 1.66; acc: 0.41
Batch: 420; loss: 1.75; acc: 0.39
Batch: 440; loss: 1.76; acc: 0.39
Batch: 460; loss: 1.6; acc: 0.39
Batch: 480; loss: 1.57; acc: 0.5
Batch: 500; loss: 1.37; acc: 0.52
Batch: 520; loss: 1.88; acc: 0.3
Batch: 540; loss: 1.68; acc: 0.48
Batch: 560; loss: 1.68; acc: 0.38
Batch: 580; loss: 1.67; acc: 0.44
Batch: 600; loss: 1.91; acc: 0.33
Batch: 620; loss: 1.54; acc: 0.42
Batch: 640; loss: 1.57; acc: 0.47
Batch: 660; loss: 1.64; acc: 0.47
Batch: 680; loss: 1.63; acc: 0.48
Batch: 700; loss: 1.72; acc: 0.36
Batch: 720; loss: 1.67; acc: 0.45
Batch: 740; loss: 1.57; acc: 0.36
Batch: 760; loss: 1.62; acc: 0.42
Batch: 780; loss: 1.7; acc: 0.45
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.44
Val Epoch over. val_loss: 1.5842952584005465; val_accuracy: 0.4585987261146497 

The current subspace-distance is: 5.9394806157797575e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.69; acc: 0.44
Batch: 20; loss: 1.64; acc: 0.5
Batch: 40; loss: 1.52; acc: 0.53
Batch: 60; loss: 1.46; acc: 0.45
Batch: 80; loss: 1.67; acc: 0.44
Batch: 100; loss: 1.66; acc: 0.42
Batch: 120; loss: 1.66; acc: 0.45
Batch: 140; loss: 1.59; acc: 0.44
Batch: 160; loss: 1.6; acc: 0.39
Batch: 180; loss: 1.66; acc: 0.41
Batch: 200; loss: 1.56; acc: 0.55
Batch: 220; loss: 1.58; acc: 0.48
Batch: 240; loss: 1.81; acc: 0.33
Batch: 260; loss: 1.77; acc: 0.34
Batch: 280; loss: 1.66; acc: 0.41
Batch: 300; loss: 1.5; acc: 0.44
Batch: 320; loss: 1.48; acc: 0.44
Batch: 340; loss: 1.82; acc: 0.33
Batch: 360; loss: 1.73; acc: 0.36
Batch: 380; loss: 1.71; acc: 0.42
Batch: 400; loss: 1.44; acc: 0.52
Batch: 420; loss: 1.67; acc: 0.41
Batch: 440; loss: 1.43; acc: 0.56
Batch: 460; loss: 1.57; acc: 0.52
Batch: 480; loss: 1.55; acc: 0.44
Batch: 500; loss: 1.59; acc: 0.5
Batch: 520; loss: 1.55; acc: 0.44
Batch: 540; loss: 1.56; acc: 0.5
Batch: 560; loss: 1.65; acc: 0.44
Batch: 580; loss: 1.69; acc: 0.45
Batch: 600; loss: 1.68; acc: 0.47
Batch: 620; loss: 1.74; acc: 0.39
Batch: 640; loss: 1.61; acc: 0.42
Batch: 660; loss: 1.73; acc: 0.42
Batch: 680; loss: 1.52; acc: 0.53
Batch: 700; loss: 1.62; acc: 0.41
Batch: 720; loss: 1.47; acc: 0.45
Batch: 740; loss: 1.52; acc: 0.47
Batch: 760; loss: 1.59; acc: 0.36
Batch: 780; loss: 1.74; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.42
Val Epoch over. val_loss: 1.583816891263245; val_accuracy: 0.46048964968152867 

The current subspace-distance is: 6.262705574044958e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.58; acc: 0.53
Batch: 20; loss: 1.93; acc: 0.33
Batch: 40; loss: 1.56; acc: 0.47
Batch: 60; loss: 1.58; acc: 0.44
Batch: 80; loss: 1.61; acc: 0.45
Batch: 100; loss: 1.59; acc: 0.55
Batch: 120; loss: 1.7; acc: 0.48
Batch: 140; loss: 1.91; acc: 0.33
Batch: 160; loss: 1.67; acc: 0.38
Batch: 180; loss: 1.8; acc: 0.36
Batch: 200; loss: 1.49; acc: 0.45
Batch: 220; loss: 1.78; acc: 0.38
Batch: 240; loss: 1.69; acc: 0.41
Batch: 260; loss: 1.57; acc: 0.48
Batch: 280; loss: 1.42; acc: 0.53
Batch: 300; loss: 1.68; acc: 0.39
Batch: 320; loss: 1.55; acc: 0.5
Batch: 340; loss: 1.42; acc: 0.59
Batch: 360; loss: 1.54; acc: 0.48
Batch: 380; loss: 1.66; acc: 0.45
Batch: 400; loss: 1.57; acc: 0.44
Batch: 420; loss: 1.49; acc: 0.53
Batch: 440; loss: 1.73; acc: 0.44
Batch: 460; loss: 1.49; acc: 0.45
Batch: 480; loss: 1.52; acc: 0.48
Batch: 500; loss: 1.57; acc: 0.41
Batch: 520; loss: 1.66; acc: 0.38
Batch: 540; loss: 1.67; acc: 0.44
Batch: 560; loss: 1.7; acc: 0.42
Batch: 580; loss: 1.8; acc: 0.39
Batch: 600; loss: 1.59; acc: 0.47
Batch: 620; loss: 1.56; acc: 0.52
Batch: 640; loss: 1.65; acc: 0.44
Batch: 660; loss: 1.69; acc: 0.41
Batch: 680; loss: 1.55; acc: 0.39
Batch: 700; loss: 1.68; acc: 0.41
Batch: 720; loss: 1.57; acc: 0.42
Batch: 740; loss: 1.45; acc: 0.48
Batch: 760; loss: 1.8; acc: 0.31
Batch: 780; loss: 1.6; acc: 0.45
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.5
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.42
Val Epoch over. val_loss: 1.5841025584822248; val_accuracy: 0.46009156050955413 

The current subspace-distance is: 6.510917592095211e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.7; acc: 0.48
Batch: 40; loss: 1.8; acc: 0.41
Batch: 60; loss: 1.76; acc: 0.39
Batch: 80; loss: 1.45; acc: 0.56
Batch: 100; loss: 1.74; acc: 0.41
Batch: 120; loss: 1.67; acc: 0.47
Batch: 140; loss: 1.33; acc: 0.55
Batch: 160; loss: 1.39; acc: 0.55
Batch: 180; loss: 1.44; acc: 0.45
Batch: 200; loss: 1.36; acc: 0.61
Batch: 220; loss: 1.69; acc: 0.44
Batch: 240; loss: 1.52; acc: 0.58
Batch: 260; loss: 1.53; acc: 0.42
Batch: 280; loss: 1.41; acc: 0.5
Batch: 300; loss: 1.59; acc: 0.48
Batch: 320; loss: 1.64; acc: 0.38
Batch: 340; loss: 1.76; acc: 0.45
Batch: 360; loss: 1.62; acc: 0.44
Batch: 380; loss: 1.58; acc: 0.42
Batch: 400; loss: 1.67; acc: 0.42
Batch: 420; loss: 1.76; acc: 0.47
Batch: 440; loss: 1.59; acc: 0.44
Batch: 460; loss: 1.56; acc: 0.45
Batch: 480; loss: 1.83; acc: 0.38
Batch: 500; loss: 1.81; acc: 0.42
Batch: 520; loss: 1.53; acc: 0.5
Batch: 540; loss: 1.6; acc: 0.47
Batch: 560; loss: 1.47; acc: 0.56
Batch: 580; loss: 1.71; acc: 0.45
Batch: 600; loss: 1.53; acc: 0.5
Batch: 620; loss: 1.61; acc: 0.44
Batch: 640; loss: 1.77; acc: 0.39
Batch: 660; loss: 1.77; acc: 0.44
Batch: 680; loss: 1.47; acc: 0.5
Batch: 700; loss: 1.46; acc: 0.48
Batch: 720; loss: 1.65; acc: 0.47
Batch: 740; loss: 1.5; acc: 0.5
Batch: 760; loss: 1.65; acc: 0.44
Batch: 780; loss: 1.5; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.5
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.53; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.42
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5838651414130145; val_accuracy: 0.46138535031847133 

The current subspace-distance is: 6.758269591955468e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.61; acc: 0.39
Batch: 20; loss: 1.77; acc: 0.34
Batch: 40; loss: 1.74; acc: 0.42
Batch: 60; loss: 1.69; acc: 0.48
Batch: 80; loss: 1.61; acc: 0.55
Batch: 100; loss: 1.71; acc: 0.47
Batch: 120; loss: 1.63; acc: 0.38
Batch: 140; loss: 1.85; acc: 0.42
Batch: 160; loss: 1.61; acc: 0.42
Batch: 180; loss: 1.58; acc: 0.44
Batch: 200; loss: 1.62; acc: 0.41
Batch: 220; loss: 1.71; acc: 0.38
Batch: 240; loss: 1.61; acc: 0.5
Batch: 260; loss: 1.67; acc: 0.38
Batch: 280; loss: 1.59; acc: 0.56
Batch: 300; loss: 1.66; acc: 0.52
Batch: 320; loss: 1.65; acc: 0.39
Batch: 340; loss: 1.71; acc: 0.39
Batch: 360; loss: 1.55; acc: 0.5
Batch: 380; loss: 1.48; acc: 0.58
Batch: 400; loss: 1.48; acc: 0.48
Batch: 420; loss: 1.61; acc: 0.44
Batch: 440; loss: 1.7; acc: 0.41
Batch: 460; loss: 1.72; acc: 0.44
Batch: 480; loss: 1.57; acc: 0.45
Batch: 500; loss: 1.74; acc: 0.36
Batch: 520; loss: 1.52; acc: 0.56
Batch: 540; loss: 1.61; acc: 0.47
Batch: 560; loss: 1.67; acc: 0.39
Batch: 580; loss: 1.54; acc: 0.45
Batch: 600; loss: 1.46; acc: 0.48
Batch: 620; loss: 1.69; acc: 0.45
Batch: 640; loss: 1.74; acc: 0.39
Batch: 660; loss: 1.43; acc: 0.45
Batch: 680; loss: 1.55; acc: 0.44
Batch: 700; loss: 1.55; acc: 0.48
Batch: 720; loss: 1.66; acc: 0.39
Batch: 740; loss: 1.73; acc: 0.42
Batch: 760; loss: 1.56; acc: 0.5
Batch: 780; loss: 1.46; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.55; acc: 0.5
Batch: 20; loss: 1.88; acc: 0.41
Batch: 40; loss: 1.26; acc: 0.62
Batch: 60; loss: 1.53; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.63; acc: 0.47
Batch: 120; loss: 1.76; acc: 0.41
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5838711011181972; val_accuracy: 0.4612858280254777 

The current subspace-distance is: 6.497182766906917e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.61; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.5
Batch: 40; loss: 1.77; acc: 0.39
Batch: 60; loss: 1.59; acc: 0.42
Batch: 80; loss: 1.71; acc: 0.44
Batch: 100; loss: 1.76; acc: 0.42
Batch: 120; loss: 1.48; acc: 0.42
Batch: 140; loss: 1.62; acc: 0.44
Batch: 160; loss: 1.8; acc: 0.36
Batch: 180; loss: 1.68; acc: 0.41
Batch: 200; loss: 1.67; acc: 0.38
Batch: 220; loss: 1.68; acc: 0.34
Batch: 240; loss: 1.82; acc: 0.42
Batch: 260; loss: 1.62; acc: 0.47
Batch: 280; loss: 1.66; acc: 0.38
Batch: 300; loss: 1.52; acc: 0.52
Batch: 320; loss: 1.7; acc: 0.52
Batch: 340; loss: 1.75; acc: 0.39
Batch: 360; loss: 1.68; acc: 0.5
Batch: 380; loss: 1.47; acc: 0.53
Batch: 400; loss: 1.58; acc: 0.48
Batch: 420; loss: 1.67; acc: 0.39
Batch: 440; loss: 1.44; acc: 0.56
Batch: 460; loss: 1.39; acc: 0.47
Batch: 480; loss: 1.57; acc: 0.45
Batch: 500; loss: 1.58; acc: 0.47
Batch: 520; loss: 1.61; acc: 0.5
Batch: 540; loss: 1.68; acc: 0.55
Batch: 560; loss: 1.6; acc: 0.42
Batch: 580; loss: 1.83; acc: 0.45
Batch: 600; loss: 1.7; acc: 0.44
Batch: 620; loss: 1.65; acc: 0.41
Batch: 640; loss: 1.48; acc: 0.55
Batch: 660; loss: 1.78; acc: 0.39
Batch: 680; loss: 1.74; acc: 0.39
Batch: 700; loss: 1.52; acc: 0.45
Batch: 720; loss: 1.64; acc: 0.31
Batch: 740; loss: 1.64; acc: 0.45
Batch: 760; loss: 1.64; acc: 0.44
Batch: 780; loss: 1.35; acc: 0.52
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.51; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.58; acc: 0.44
Val Epoch over. val_loss: 1.5843583208740137; val_accuracy: 0.4576035031847134 

The current subspace-distance is: 6.415956158889458e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.87; acc: 0.41
Batch: 20; loss: 1.64; acc: 0.47
Batch: 40; loss: 1.62; acc: 0.47
Batch: 60; loss: 1.67; acc: 0.45
Batch: 80; loss: 1.56; acc: 0.5
Batch: 100; loss: 1.77; acc: 0.34
Batch: 120; loss: 1.52; acc: 0.56
Batch: 140; loss: 1.67; acc: 0.41
Batch: 160; loss: 1.53; acc: 0.53
Batch: 180; loss: 1.92; acc: 0.41
Batch: 200; loss: 1.59; acc: 0.44
Batch: 220; loss: 1.67; acc: 0.36
Batch: 240; loss: 1.71; acc: 0.34
Batch: 260; loss: 1.59; acc: 0.48
Batch: 280; loss: 1.39; acc: 0.52
Batch: 300; loss: 1.62; acc: 0.47
Batch: 320; loss: 1.42; acc: 0.56
Batch: 340; loss: 1.73; acc: 0.41
Batch: 360; loss: 1.43; acc: 0.58
Batch: 380; loss: 1.57; acc: 0.5
Batch: 400; loss: 1.8; acc: 0.39
Batch: 420; loss: 1.77; acc: 0.33
Batch: 440; loss: 1.39; acc: 0.61
Batch: 460; loss: 1.62; acc: 0.42
Batch: 480; loss: 1.83; acc: 0.38
Batch: 500; loss: 1.77; acc: 0.44
Batch: 520; loss: 1.59; acc: 0.5
Batch: 540; loss: 1.62; acc: 0.47
Batch: 560; loss: 1.43; acc: 0.45
Batch: 580; loss: 1.6; acc: 0.5
Batch: 600; loss: 1.55; acc: 0.5
Batch: 620; loss: 1.55; acc: 0.5
Batch: 640; loss: 1.61; acc: 0.5
Batch: 660; loss: 1.61; acc: 0.48
Batch: 680; loss: 1.7; acc: 0.42
Batch: 700; loss: 1.44; acc: 0.53
Batch: 720; loss: 1.55; acc: 0.45
Batch: 740; loss: 1.74; acc: 0.42
Batch: 760; loss: 1.62; acc: 0.44
Batch: 780; loss: 1.4; acc: 0.53
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.47
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5840842108817617; val_accuracy: 0.45740445859872614 

The current subspace-distance is: 6.853324157418683e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 1.65; acc: 0.42
Batch: 40; loss: 1.68; acc: 0.47
Batch: 60; loss: 1.59; acc: 0.45
Batch: 80; loss: 1.55; acc: 0.5
Batch: 100; loss: 1.86; acc: 0.33
Batch: 120; loss: 1.63; acc: 0.48
Batch: 140; loss: 1.62; acc: 0.48
Batch: 160; loss: 1.52; acc: 0.5
Batch: 180; loss: 1.6; acc: 0.5
Batch: 200; loss: 1.59; acc: 0.45
Batch: 220; loss: 1.58; acc: 0.53
Batch: 240; loss: 1.69; acc: 0.41
Batch: 260; loss: 1.78; acc: 0.45
Batch: 280; loss: 1.69; acc: 0.47
Batch: 300; loss: 1.76; acc: 0.42
Batch: 320; loss: 1.62; acc: 0.45
Batch: 340; loss: 1.59; acc: 0.5
Batch: 360; loss: 1.57; acc: 0.41
Batch: 380; loss: 1.51; acc: 0.42
Batch: 400; loss: 1.4; acc: 0.53
Batch: 420; loss: 1.63; acc: 0.44
Batch: 440; loss: 1.67; acc: 0.42
Batch: 460; loss: 1.7; acc: 0.39
Batch: 480; loss: 1.63; acc: 0.39
Batch: 500; loss: 1.71; acc: 0.34
Batch: 520; loss: 1.71; acc: 0.36
Batch: 540; loss: 1.57; acc: 0.44
Batch: 560; loss: 1.49; acc: 0.48
Batch: 580; loss: 1.64; acc: 0.41
Batch: 600; loss: 1.7; acc: 0.44
Batch: 620; loss: 1.59; acc: 0.55
Batch: 640; loss: 1.58; acc: 0.52
Batch: 660; loss: 1.59; acc: 0.45
Batch: 680; loss: 1.42; acc: 0.52
Batch: 700; loss: 1.48; acc: 0.47
Batch: 720; loss: 1.69; acc: 0.44
Batch: 740; loss: 1.66; acc: 0.44
Batch: 760; loss: 1.61; acc: 0.48
Batch: 780; loss: 1.44; acc: 0.56
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5836988512877446; val_accuracy: 0.4588972929936306 

The current subspace-distance is: 6.673247116850689e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.56; acc: 0.44
Batch: 20; loss: 1.56; acc: 0.53
Batch: 40; loss: 1.66; acc: 0.45
Batch: 60; loss: 1.66; acc: 0.42
Batch: 80; loss: 1.52; acc: 0.44
Batch: 100; loss: 1.46; acc: 0.55
Batch: 120; loss: 1.67; acc: 0.5
Batch: 140; loss: 1.72; acc: 0.41
Batch: 160; loss: 1.4; acc: 0.56
Batch: 180; loss: 1.51; acc: 0.42
Batch: 200; loss: 1.42; acc: 0.55
Batch: 220; loss: 1.54; acc: 0.45
Batch: 240; loss: 1.58; acc: 0.47
Batch: 260; loss: 1.54; acc: 0.47
Batch: 280; loss: 1.49; acc: 0.5
Batch: 300; loss: 1.9; acc: 0.3
Batch: 320; loss: 1.47; acc: 0.5
Batch: 340; loss: 1.72; acc: 0.38
Batch: 360; loss: 1.61; acc: 0.47
Batch: 380; loss: 1.49; acc: 0.53
Batch: 400; loss: 1.78; acc: 0.33
Batch: 420; loss: 1.6; acc: 0.45
Batch: 440; loss: 1.53; acc: 0.5
Batch: 460; loss: 1.57; acc: 0.45
Batch: 480; loss: 1.48; acc: 0.45
Batch: 500; loss: 1.6; acc: 0.5
Batch: 520; loss: 1.76; acc: 0.42
Batch: 540; loss: 1.68; acc: 0.44
Batch: 560; loss: 1.52; acc: 0.41
Batch: 580; loss: 1.96; acc: 0.28
Batch: 600; loss: 1.94; acc: 0.33
Batch: 620; loss: 1.68; acc: 0.41
Batch: 640; loss: 1.69; acc: 0.38
Batch: 660; loss: 1.65; acc: 0.48
Batch: 680; loss: 1.74; acc: 0.5
Batch: 700; loss: 1.69; acc: 0.39
Batch: 720; loss: 1.33; acc: 0.59
Batch: 740; loss: 1.7; acc: 0.36
Batch: 760; loss: 1.86; acc: 0.33
Batch: 780; loss: 1.7; acc: 0.36
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.583922810615248; val_accuracy: 0.4590963375796178 

The current subspace-distance is: 6.809880869695917e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.51; acc: 0.48
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.69; acc: 0.44
Batch: 60; loss: 1.65; acc: 0.45
Batch: 80; loss: 1.52; acc: 0.58
Batch: 100; loss: 1.67; acc: 0.34
Batch: 120; loss: 1.48; acc: 0.52
Batch: 140; loss: 1.62; acc: 0.42
Batch: 160; loss: 1.68; acc: 0.41
Batch: 180; loss: 1.71; acc: 0.45
Batch: 200; loss: 1.62; acc: 0.48
Batch: 220; loss: 1.71; acc: 0.42
Batch: 240; loss: 1.47; acc: 0.5
Batch: 260; loss: 1.51; acc: 0.48
Batch: 280; loss: 1.57; acc: 0.45
Batch: 300; loss: 1.72; acc: 0.39
Batch: 320; loss: 1.62; acc: 0.38
Batch: 340; loss: 1.71; acc: 0.38
Batch: 360; loss: 1.5; acc: 0.53
Batch: 380; loss: 1.6; acc: 0.44
Batch: 400; loss: 1.9; acc: 0.33
Batch: 420; loss: 1.75; acc: 0.41
Batch: 440; loss: 1.66; acc: 0.44
Batch: 460; loss: 1.57; acc: 0.48
Batch: 480; loss: 1.76; acc: 0.41
Batch: 500; loss: 1.63; acc: 0.45
Batch: 520; loss: 1.7; acc: 0.42
Batch: 540; loss: 1.36; acc: 0.56
Batch: 560; loss: 1.62; acc: 0.42
Batch: 580; loss: 1.58; acc: 0.5
Batch: 600; loss: 1.53; acc: 0.48
Batch: 620; loss: 1.6; acc: 0.47
Batch: 640; loss: 1.7; acc: 0.41
Batch: 660; loss: 1.52; acc: 0.5
Batch: 680; loss: 1.46; acc: 0.55
Batch: 700; loss: 1.82; acc: 0.33
Batch: 720; loss: 1.92; acc: 0.3
Batch: 740; loss: 1.68; acc: 0.48
Batch: 760; loss: 1.54; acc: 0.5
Batch: 780; loss: 1.81; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.86; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.51; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5844537862546884; val_accuracy: 0.4581011146496815 

The current subspace-distance is: 7.031606219243258e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.67; acc: 0.52
Batch: 20; loss: 1.44; acc: 0.48
Batch: 40; loss: 1.75; acc: 0.41
Batch: 60; loss: 1.65; acc: 0.42
Batch: 80; loss: 1.48; acc: 0.5
Batch: 100; loss: 1.66; acc: 0.45
Batch: 120; loss: 1.51; acc: 0.48
Batch: 140; loss: 1.63; acc: 0.41
Batch: 160; loss: 1.51; acc: 0.5
Batch: 180; loss: 1.92; acc: 0.39
Batch: 200; loss: 1.85; acc: 0.34
Batch: 220; loss: 1.39; acc: 0.53
Batch: 240; loss: 1.75; acc: 0.39
Batch: 260; loss: 1.68; acc: 0.41
Batch: 280; loss: 1.51; acc: 0.48
Batch: 300; loss: 1.72; acc: 0.41
Batch: 320; loss: 1.73; acc: 0.36
Batch: 340; loss: 1.51; acc: 0.42
Batch: 360; loss: 1.6; acc: 0.39
Batch: 380; loss: 1.42; acc: 0.55
Batch: 400; loss: 1.64; acc: 0.45
Batch: 420; loss: 1.46; acc: 0.53
Batch: 440; loss: 1.5; acc: 0.53
Batch: 460; loss: 1.63; acc: 0.45
Batch: 480; loss: 1.34; acc: 0.59
Batch: 500; loss: 1.62; acc: 0.41
Batch: 520; loss: 1.65; acc: 0.42
Batch: 540; loss: 1.48; acc: 0.41
Batch: 560; loss: 1.63; acc: 0.45
Batch: 580; loss: 1.68; acc: 0.47
Batch: 600; loss: 1.57; acc: 0.47
Batch: 620; loss: 1.77; acc: 0.44
Batch: 640; loss: 1.75; acc: 0.36
Batch: 660; loss: 1.65; acc: 0.44
Batch: 680; loss: 1.61; acc: 0.42
Batch: 700; loss: 1.56; acc: 0.44
Batch: 720; loss: 1.41; acc: 0.53
Batch: 740; loss: 1.6; acc: 0.44
Batch: 760; loss: 1.49; acc: 0.52
Batch: 780; loss: 1.82; acc: 0.33
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.42
Val Epoch over. val_loss: 1.583679349559128; val_accuracy: 0.4601910828025478 

The current subspace-distance is: 7.212105265352875e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 1.53; acc: 0.52
Batch: 40; loss: 1.69; acc: 0.39
Batch: 60; loss: 1.54; acc: 0.5
Batch: 80; loss: 1.77; acc: 0.39
Batch: 100; loss: 1.65; acc: 0.41
Batch: 120; loss: 1.57; acc: 0.39
Batch: 140; loss: 1.67; acc: 0.34
Batch: 160; loss: 1.38; acc: 0.53
Batch: 180; loss: 1.48; acc: 0.45
Batch: 200; loss: 1.6; acc: 0.48
Batch: 220; loss: 1.83; acc: 0.34
Batch: 240; loss: 1.53; acc: 0.48
Batch: 260; loss: 1.51; acc: 0.44
Batch: 280; loss: 1.52; acc: 0.44
Batch: 300; loss: 1.38; acc: 0.55
Batch: 320; loss: 1.8; acc: 0.39
Batch: 340; loss: 1.77; acc: 0.34
Batch: 360; loss: 1.72; acc: 0.41
Batch: 380; loss: 1.5; acc: 0.45
Batch: 400; loss: 1.91; acc: 0.31
Batch: 420; loss: 1.68; acc: 0.48
Batch: 440; loss: 1.87; acc: 0.34
Batch: 460; loss: 1.48; acc: 0.44
Batch: 480; loss: 1.58; acc: 0.48
Batch: 500; loss: 1.67; acc: 0.44
Batch: 520; loss: 1.26; acc: 0.56
Batch: 540; loss: 1.47; acc: 0.55
Batch: 560; loss: 1.71; acc: 0.41
Batch: 580; loss: 1.57; acc: 0.38
Batch: 600; loss: 1.49; acc: 0.44
Batch: 620; loss: 1.41; acc: 0.55
Batch: 640; loss: 1.75; acc: 0.39
Batch: 660; loss: 1.75; acc: 0.38
Batch: 680; loss: 1.57; acc: 0.48
Batch: 700; loss: 1.61; acc: 0.39
Batch: 720; loss: 1.57; acc: 0.48
Batch: 740; loss: 1.44; acc: 0.5
Batch: 760; loss: 1.55; acc: 0.5
Batch: 780; loss: 1.67; acc: 0.38
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5836909318425854; val_accuracy: 0.4599920382165605 

The current subspace-distance is: 7.598022784804925e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.61; acc: 0.48
Batch: 20; loss: 1.67; acc: 0.36
Batch: 40; loss: 1.64; acc: 0.47
Batch: 60; loss: 1.65; acc: 0.47
Batch: 80; loss: 1.57; acc: 0.47
Batch: 100; loss: 1.56; acc: 0.47
Batch: 120; loss: 1.7; acc: 0.47
Batch: 140; loss: 1.63; acc: 0.47
Batch: 160; loss: 1.79; acc: 0.34
Batch: 180; loss: 1.56; acc: 0.5
Batch: 200; loss: 1.55; acc: 0.47
Batch: 220; loss: 1.64; acc: 0.45
Batch: 240; loss: 1.77; acc: 0.5
Batch: 260; loss: 1.5; acc: 0.48
Batch: 280; loss: 1.42; acc: 0.52
Batch: 300; loss: 1.31; acc: 0.61
Batch: 320; loss: 1.76; acc: 0.38
Batch: 340; loss: 1.54; acc: 0.5
Batch: 360; loss: 1.46; acc: 0.53
Batch: 380; loss: 1.69; acc: 0.39
Batch: 400; loss: 1.47; acc: 0.52
Batch: 420; loss: 1.6; acc: 0.48
Batch: 440; loss: 1.51; acc: 0.55
Batch: 460; loss: 1.59; acc: 0.44
Batch: 480; loss: 1.44; acc: 0.56
Batch: 500; loss: 1.64; acc: 0.47
Batch: 520; loss: 1.65; acc: 0.41
Batch: 540; loss: 1.56; acc: 0.5
Batch: 560; loss: 1.53; acc: 0.5
Batch: 580; loss: 1.64; acc: 0.45
Batch: 600; loss: 1.53; acc: 0.48
Batch: 620; loss: 1.6; acc: 0.45
Batch: 640; loss: 1.69; acc: 0.42
Batch: 660; loss: 1.77; acc: 0.42
Batch: 680; loss: 1.64; acc: 0.52
Batch: 700; loss: 1.77; acc: 0.39
Batch: 720; loss: 1.67; acc: 0.44
Batch: 740; loss: 1.48; acc: 0.53
Batch: 760; loss: 1.74; acc: 0.45
Batch: 780; loss: 1.49; acc: 0.5
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.42
Val Epoch over. val_loss: 1.5836124852964073; val_accuracy: 0.459593949044586 

The current subspace-distance is: 7.951441511977464e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.75; acc: 0.41
Batch: 20; loss: 1.48; acc: 0.45
Batch: 40; loss: 1.51; acc: 0.5
Batch: 60; loss: 1.63; acc: 0.39
Batch: 80; loss: 1.78; acc: 0.3
Batch: 100; loss: 1.68; acc: 0.39
Batch: 120; loss: 1.54; acc: 0.47
Batch: 140; loss: 1.64; acc: 0.42
Batch: 160; loss: 1.79; acc: 0.38
Batch: 180; loss: 1.51; acc: 0.52
Batch: 200; loss: 1.7; acc: 0.45
Batch: 220; loss: 1.75; acc: 0.39
Batch: 240; loss: 1.65; acc: 0.52
Batch: 260; loss: 1.53; acc: 0.44
Batch: 280; loss: 1.62; acc: 0.5
Batch: 300; loss: 1.41; acc: 0.53
Batch: 320; loss: 1.52; acc: 0.39
Batch: 340; loss: 1.86; acc: 0.36
Batch: 360; loss: 1.78; acc: 0.41
Batch: 380; loss: 1.6; acc: 0.47
Batch: 400; loss: 1.75; acc: 0.33
Batch: 420; loss: 1.57; acc: 0.45
Batch: 440; loss: 1.42; acc: 0.48
Batch: 460; loss: 1.48; acc: 0.56
Batch: 480; loss: 1.6; acc: 0.42
Batch: 500; loss: 1.75; acc: 0.38
Batch: 520; loss: 1.76; acc: 0.38
Batch: 540; loss: 1.37; acc: 0.58
Batch: 560; loss: 1.46; acc: 0.48
Batch: 580; loss: 1.7; acc: 0.39
Batch: 600; loss: 1.58; acc: 0.52
Batch: 620; loss: 1.71; acc: 0.41
Batch: 640; loss: 1.64; acc: 0.41
Batch: 660; loss: 1.8; acc: 0.42
Batch: 680; loss: 1.53; acc: 0.48
Batch: 700; loss: 1.39; acc: 0.55
Batch: 720; loss: 1.75; acc: 0.42
Batch: 740; loss: 1.37; acc: 0.53
Batch: 760; loss: 1.78; acc: 0.36
Batch: 780; loss: 1.71; acc: 0.45
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.583627162465624; val_accuracy: 0.4589968152866242 

The current subspace-distance is: 7.884252408985049e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.79; acc: 0.33
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.54; acc: 0.48
Batch: 60; loss: 1.44; acc: 0.52
Batch: 80; loss: 1.46; acc: 0.53
Batch: 100; loss: 1.43; acc: 0.5
Batch: 120; loss: 1.88; acc: 0.31
Batch: 140; loss: 1.73; acc: 0.42
Batch: 160; loss: 1.67; acc: 0.38
Batch: 180; loss: 1.72; acc: 0.39
Batch: 200; loss: 1.71; acc: 0.42
Batch: 220; loss: 1.58; acc: 0.44
Batch: 240; loss: 1.72; acc: 0.39
Batch: 260; loss: 1.31; acc: 0.58
Batch: 280; loss: 1.39; acc: 0.58
Batch: 300; loss: 1.47; acc: 0.53
Batch: 320; loss: 1.52; acc: 0.44
Batch: 340; loss: 1.65; acc: 0.38
Batch: 360; loss: 1.69; acc: 0.44
Batch: 380; loss: 1.67; acc: 0.41
Batch: 400; loss: 1.43; acc: 0.52
Batch: 420; loss: 1.6; acc: 0.41
Batch: 440; loss: 1.6; acc: 0.44
Batch: 460; loss: 1.57; acc: 0.47
Batch: 480; loss: 1.62; acc: 0.47
Batch: 500; loss: 1.72; acc: 0.39
Batch: 520; loss: 1.52; acc: 0.5
Batch: 540; loss: 1.65; acc: 0.52
Batch: 560; loss: 1.88; acc: 0.38
Batch: 580; loss: 1.6; acc: 0.53
Batch: 600; loss: 1.44; acc: 0.5
Batch: 620; loss: 1.56; acc: 0.52
Batch: 640; loss: 1.88; acc: 0.42
Batch: 660; loss: 1.64; acc: 0.53
Batch: 680; loss: 1.64; acc: 0.42
Batch: 700; loss: 1.61; acc: 0.44
Batch: 720; loss: 1.97; acc: 0.42
Batch: 740; loss: 1.74; acc: 0.36
Batch: 760; loss: 1.7; acc: 0.41
Batch: 780; loss: 1.75; acc: 0.39
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5837453208911192; val_accuracy: 0.45949442675159236 

The current subspace-distance is: 8.207261271309108e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.57; acc: 0.55
Batch: 20; loss: 1.55; acc: 0.36
Batch: 40; loss: 1.59; acc: 0.52
Batch: 60; loss: 1.56; acc: 0.52
Batch: 80; loss: 1.57; acc: 0.41
Batch: 100; loss: 1.49; acc: 0.47
Batch: 120; loss: 1.45; acc: 0.53
Batch: 140; loss: 1.63; acc: 0.45
Batch: 160; loss: 1.65; acc: 0.42
Batch: 180; loss: 1.62; acc: 0.39
Batch: 200; loss: 1.69; acc: 0.39
Batch: 220; loss: 1.78; acc: 0.38
Batch: 240; loss: 1.56; acc: 0.52
Batch: 260; loss: 1.56; acc: 0.48
Batch: 280; loss: 1.69; acc: 0.47
Batch: 300; loss: 1.53; acc: 0.52
Batch: 320; loss: 1.5; acc: 0.42
Batch: 340; loss: 1.77; acc: 0.39
Batch: 360; loss: 1.52; acc: 0.44
Batch: 380; loss: 1.9; acc: 0.38
Batch: 400; loss: 1.67; acc: 0.45
Batch: 420; loss: 1.54; acc: 0.39
Batch: 440; loss: 1.55; acc: 0.42
Batch: 460; loss: 1.73; acc: 0.44
Batch: 480; loss: 1.34; acc: 0.47
Batch: 500; loss: 1.88; acc: 0.36
Batch: 520; loss: 1.55; acc: 0.53
Batch: 540; loss: 1.67; acc: 0.41
Batch: 560; loss: 1.48; acc: 0.47
Batch: 580; loss: 1.51; acc: 0.47
Batch: 600; loss: 1.71; acc: 0.39
Batch: 620; loss: 1.64; acc: 0.44
Batch: 640; loss: 1.73; acc: 0.39
Batch: 660; loss: 1.62; acc: 0.41
Batch: 680; loss: 1.63; acc: 0.44
Batch: 700; loss: 1.25; acc: 0.67
Batch: 720; loss: 1.69; acc: 0.44
Batch: 740; loss: 1.54; acc: 0.48
Batch: 760; loss: 1.75; acc: 0.45
Batch: 780; loss: 1.68; acc: 0.47
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.61; acc: 0.48
Batch: 120; loss: 1.74; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5838579038146194; val_accuracy: 0.4590963375796178 

The current subspace-distance is: 8.004730625543743e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.81; acc: 0.42
Batch: 20; loss: 1.43; acc: 0.52
Batch: 40; loss: 1.53; acc: 0.5
Batch: 60; loss: 1.82; acc: 0.36
Batch: 80; loss: 1.61; acc: 0.41
Batch: 100; loss: 1.72; acc: 0.33
Batch: 120; loss: 1.66; acc: 0.45
Batch: 140; loss: 1.57; acc: 0.48
Batch: 160; loss: 1.6; acc: 0.5
Batch: 180; loss: 1.73; acc: 0.41
Batch: 200; loss: 1.81; acc: 0.41
Batch: 220; loss: 1.57; acc: 0.56
Batch: 240; loss: 1.74; acc: 0.39
Batch: 260; loss: 1.56; acc: 0.48
Batch: 280; loss: 1.7; acc: 0.38
Batch: 300; loss: 1.64; acc: 0.41
Batch: 320; loss: 1.6; acc: 0.41
Batch: 340; loss: 1.48; acc: 0.52
Batch: 360; loss: 1.5; acc: 0.59
Batch: 380; loss: 1.78; acc: 0.42
Batch: 400; loss: 1.5; acc: 0.5
Batch: 420; loss: 1.64; acc: 0.41
Batch: 440; loss: 1.72; acc: 0.42
Batch: 460; loss: 1.57; acc: 0.48
Batch: 480; loss: 1.59; acc: 0.44
Batch: 500; loss: 1.72; acc: 0.39
Batch: 520; loss: 1.89; acc: 0.34
Batch: 540; loss: 1.66; acc: 0.47
Batch: 560; loss: 1.51; acc: 0.5
Batch: 580; loss: 1.67; acc: 0.39
Batch: 600; loss: 1.29; acc: 0.61
Batch: 620; loss: 1.55; acc: 0.39
Batch: 640; loss: 1.59; acc: 0.45
Batch: 660; loss: 1.62; acc: 0.48
Batch: 680; loss: 1.59; acc: 0.45
Batch: 700; loss: 1.36; acc: 0.47
Batch: 720; loss: 1.61; acc: 0.5
Batch: 740; loss: 1.67; acc: 0.36
Batch: 760; loss: 1.73; acc: 0.45
Batch: 780; loss: 1.67; acc: 0.45
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5836327797288348; val_accuracy: 0.4589968152866242 

The current subspace-distance is: 8.278367749881e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.59; acc: 0.38
Batch: 20; loss: 1.81; acc: 0.39
Batch: 40; loss: 1.52; acc: 0.47
Batch: 60; loss: 1.51; acc: 0.44
Batch: 80; loss: 1.44; acc: 0.48
Batch: 100; loss: 1.64; acc: 0.47
Batch: 120; loss: 1.63; acc: 0.48
Batch: 140; loss: 1.48; acc: 0.41
Batch: 160; loss: 1.69; acc: 0.38
Batch: 180; loss: 1.45; acc: 0.5
Batch: 200; loss: 1.54; acc: 0.44
Batch: 220; loss: 1.54; acc: 0.48
Batch: 240; loss: 1.45; acc: 0.53
Batch: 260; loss: 1.72; acc: 0.42
Batch: 280; loss: 1.39; acc: 0.52
Batch: 300; loss: 1.5; acc: 0.48
Batch: 320; loss: 1.55; acc: 0.5
Batch: 340; loss: 1.57; acc: 0.42
Batch: 360; loss: 1.54; acc: 0.47
Batch: 380; loss: 1.64; acc: 0.53
Batch: 400; loss: 2.03; acc: 0.34
Batch: 420; loss: 1.68; acc: 0.42
Batch: 440; loss: 1.45; acc: 0.52
Batch: 460; loss: 1.69; acc: 0.47
Batch: 480; loss: 1.4; acc: 0.53
Batch: 500; loss: 1.61; acc: 0.5
Batch: 520; loss: 1.88; acc: 0.39
Batch: 540; loss: 1.62; acc: 0.42
Batch: 560; loss: 1.38; acc: 0.55
Batch: 580; loss: 1.46; acc: 0.55
Batch: 600; loss: 1.74; acc: 0.42
Batch: 620; loss: 1.48; acc: 0.45
Batch: 640; loss: 1.56; acc: 0.45
Batch: 660; loss: 1.62; acc: 0.47
Batch: 680; loss: 1.49; acc: 0.47
Batch: 700; loss: 1.58; acc: 0.45
Batch: 720; loss: 1.81; acc: 0.42
Batch: 740; loss: 1.43; acc: 0.53
Batch: 760; loss: 1.45; acc: 0.52
Batch: 780; loss: 1.6; acc: 0.47
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5835853951751806; val_accuracy: 0.4596934713375796 

The current subspace-distance is: 8.485994476359338e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.5; acc: 0.5
Batch: 20; loss: 1.45; acc: 0.58
Batch: 40; loss: 1.55; acc: 0.55
Batch: 60; loss: 1.61; acc: 0.41
Batch: 80; loss: 1.63; acc: 0.41
Batch: 100; loss: 1.33; acc: 0.61
Batch: 120; loss: 1.55; acc: 0.44
Batch: 140; loss: 1.67; acc: 0.48
Batch: 160; loss: 1.67; acc: 0.38
Batch: 180; loss: 1.55; acc: 0.48
Batch: 200; loss: 1.77; acc: 0.41
Batch: 220; loss: 1.54; acc: 0.5
Batch: 240; loss: 1.43; acc: 0.55
Batch: 260; loss: 1.85; acc: 0.39
Batch: 280; loss: 1.5; acc: 0.48
Batch: 300; loss: 1.74; acc: 0.45
Batch: 320; loss: 1.37; acc: 0.58
Batch: 340; loss: 1.56; acc: 0.42
Batch: 360; loss: 1.81; acc: 0.36
Batch: 380; loss: 1.55; acc: 0.55
Batch: 400; loss: 1.58; acc: 0.42
Batch: 420; loss: 1.68; acc: 0.52
Batch: 440; loss: 1.48; acc: 0.5
Batch: 460; loss: 1.32; acc: 0.58
Batch: 480; loss: 1.43; acc: 0.44
Batch: 500; loss: 1.59; acc: 0.47
Batch: 520; loss: 1.57; acc: 0.53
Batch: 540; loss: 1.76; acc: 0.38
Batch: 560; loss: 1.59; acc: 0.52
Batch: 580; loss: 1.43; acc: 0.56
Batch: 600; loss: 1.53; acc: 0.52
Batch: 620; loss: 1.42; acc: 0.5
Batch: 640; loss: 1.63; acc: 0.45
Batch: 660; loss: 1.65; acc: 0.44
Batch: 680; loss: 1.66; acc: 0.42
Batch: 700; loss: 1.6; acc: 0.42
Batch: 720; loss: 1.48; acc: 0.53
Batch: 740; loss: 1.57; acc: 0.47
Batch: 760; loss: 1.7; acc: 0.41
Batch: 780; loss: 1.55; acc: 0.34
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5836867283863627; val_accuracy: 0.4602906050955414 

The current subspace-distance is: 8.406778943026438e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 1.51; acc: 0.53
Batch: 40; loss: 1.74; acc: 0.47
Batch: 60; loss: 1.51; acc: 0.45
Batch: 80; loss: 1.57; acc: 0.5
Batch: 100; loss: 1.65; acc: 0.47
Batch: 120; loss: 1.73; acc: 0.48
Batch: 140; loss: 1.65; acc: 0.42
Batch: 160; loss: 1.52; acc: 0.45
Batch: 180; loss: 1.72; acc: 0.42
Batch: 200; loss: 1.48; acc: 0.47
Batch: 220; loss: 1.72; acc: 0.38
Batch: 240; loss: 1.72; acc: 0.41
Batch: 260; loss: 1.73; acc: 0.41
Batch: 280; loss: 1.77; acc: 0.38
Batch: 300; loss: 1.59; acc: 0.42
Batch: 320; loss: 1.49; acc: 0.5
Batch: 340; loss: 1.53; acc: 0.5
Batch: 360; loss: 1.47; acc: 0.45
Batch: 380; loss: 1.79; acc: 0.34
Batch: 400; loss: 1.48; acc: 0.42
Batch: 420; loss: 1.43; acc: 0.56
Batch: 440; loss: 1.69; acc: 0.39
Batch: 460; loss: 1.53; acc: 0.41
Batch: 480; loss: 1.78; acc: 0.33
Batch: 500; loss: 1.86; acc: 0.36
Batch: 520; loss: 1.43; acc: 0.52
Batch: 540; loss: 1.5; acc: 0.41
Batch: 560; loss: 1.68; acc: 0.36
Batch: 580; loss: 1.54; acc: 0.48
Batch: 600; loss: 1.57; acc: 0.52
Batch: 620; loss: 1.68; acc: 0.47
Batch: 640; loss: 1.86; acc: 0.36
Batch: 660; loss: 1.6; acc: 0.38
Batch: 680; loss: 1.49; acc: 0.52
Batch: 700; loss: 1.54; acc: 0.52
Batch: 720; loss: 1.47; acc: 0.55
Batch: 740; loss: 1.47; acc: 0.55
Batch: 760; loss: 1.53; acc: 0.47
Batch: 780; loss: 1.53; acc: 0.44
Train Epoch over. train_loss: 1.61; train_accuracy: 0.45 

Batch: 0; loss: 1.54; acc: 0.48
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.25; acc: 0.61
Batch: 60; loss: 1.52; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.62; acc: 0.48
Batch: 120; loss: 1.75; acc: 0.44
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5837483892015591; val_accuracy: 0.4596934713375796 

The current subspace-distance is: 8.252722182078287e-05 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_25_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 10720
elements in E: 2249500
fraction nonzero: 0.004765503445210047
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.31; acc: 0.16
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.32; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.28; acc: 0.16
Batch: 340; loss: 2.31; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.08
Batch: 380; loss: 2.3; acc: 0.08
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.09
Batch: 460; loss: 2.3; acc: 0.12
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.31; acc: 0.08
Batch: 520; loss: 2.3; acc: 0.06
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.16
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.12
Batch: 660; loss: 2.28; acc: 0.17
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.06
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.29; acc: 0.06
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

Batch: 0; loss: 2.28; acc: 0.09
Batch: 20; loss: 2.28; acc: 0.16
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.16
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.29; acc: 0.11
Val Epoch over. val_loss: 2.2884829454361255; val_accuracy: 0.09882563694267515 

The current subspace-distance is: 3.9090405152819585e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.17
Batch: 140; loss: 2.29; acc: 0.11
Batch: 160; loss: 2.28; acc: 0.19
Batch: 180; loss: 2.29; acc: 0.23
Batch: 200; loss: 2.27; acc: 0.22
Batch: 220; loss: 2.28; acc: 0.23
Batch: 240; loss: 2.28; acc: 0.22
Batch: 260; loss: 2.27; acc: 0.27
Batch: 280; loss: 2.27; acc: 0.33
Batch: 300; loss: 2.25; acc: 0.36
Batch: 320; loss: 2.26; acc: 0.28
Batch: 340; loss: 2.28; acc: 0.23
Batch: 360; loss: 2.27; acc: 0.2
Batch: 380; loss: 2.26; acc: 0.27
Batch: 400; loss: 2.27; acc: 0.25
Batch: 420; loss: 2.24; acc: 0.31
Batch: 440; loss: 2.25; acc: 0.27
Batch: 460; loss: 2.23; acc: 0.3
Batch: 480; loss: 2.25; acc: 0.22
Batch: 500; loss: 2.23; acc: 0.23
Batch: 520; loss: 2.19; acc: 0.38
Batch: 540; loss: 2.25; acc: 0.25
Batch: 560; loss: 2.23; acc: 0.22
Batch: 580; loss: 2.22; acc: 0.19
Batch: 600; loss: 2.22; acc: 0.28
Batch: 620; loss: 2.21; acc: 0.25
Batch: 640; loss: 2.2; acc: 0.25
Batch: 660; loss: 2.21; acc: 0.2
Batch: 680; loss: 2.18; acc: 0.23
Batch: 700; loss: 2.18; acc: 0.17
Batch: 720; loss: 2.2; acc: 0.16
Batch: 740; loss: 2.1; acc: 0.28
Batch: 760; loss: 2.19; acc: 0.17
Batch: 780; loss: 2.09; acc: 0.27
Train Epoch over. train_loss: 2.24; train_accuracy: 0.22 

Batch: 0; loss: 2.13; acc: 0.2
Batch: 20; loss: 2.17; acc: 0.17
Batch: 40; loss: 2.12; acc: 0.25
Batch: 60; loss: 2.15; acc: 0.19
Batch: 80; loss: 2.14; acc: 0.25
Batch: 100; loss: 2.14; acc: 0.25
Batch: 120; loss: 2.16; acc: 0.2
Batch: 140; loss: 2.19; acc: 0.16
Val Epoch over. val_loss: 2.140305901788602; val_accuracy: 0.2360668789808917 

The current subspace-distance is: 6.907093847985379e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.15; acc: 0.25
Batch: 20; loss: 2.19; acc: 0.19
Batch: 40; loss: 2.18; acc: 0.16
Batch: 60; loss: 2.12; acc: 0.23
Batch: 80; loss: 2.12; acc: 0.19
Batch: 100; loss: 2.12; acc: 0.23
Batch: 120; loss: 2.06; acc: 0.22
Batch: 140; loss: 2.07; acc: 0.22
Batch: 160; loss: 2.04; acc: 0.27
Batch: 180; loss: 1.96; acc: 0.3
Batch: 200; loss: 2.05; acc: 0.25
Batch: 220; loss: 2.07; acc: 0.19
Batch: 240; loss: 1.89; acc: 0.3
Batch: 260; loss: 1.96; acc: 0.36
Batch: 280; loss: 1.97; acc: 0.23
Batch: 300; loss: 1.88; acc: 0.33
Batch: 320; loss: 1.94; acc: 0.2
Batch: 340; loss: 1.96; acc: 0.3
Batch: 360; loss: 1.79; acc: 0.34
Batch: 380; loss: 1.78; acc: 0.38
Batch: 400; loss: 1.85; acc: 0.39
Batch: 420; loss: 1.83; acc: 0.39
Batch: 440; loss: 1.85; acc: 0.38
Batch: 460; loss: 1.61; acc: 0.42
Batch: 480; loss: 1.77; acc: 0.39
Batch: 500; loss: 1.56; acc: 0.44
Batch: 520; loss: 1.56; acc: 0.47
Batch: 540; loss: 1.75; acc: 0.33
Batch: 560; loss: 1.51; acc: 0.45
Batch: 580; loss: 1.45; acc: 0.52
Batch: 600; loss: 1.64; acc: 0.47
Batch: 620; loss: 1.27; acc: 0.56
Batch: 640; loss: 1.41; acc: 0.58
Batch: 660; loss: 1.47; acc: 0.56
Batch: 680; loss: 1.55; acc: 0.48
Batch: 700; loss: 1.54; acc: 0.47
Batch: 720; loss: 1.62; acc: 0.47
Batch: 740; loss: 1.23; acc: 0.62
Batch: 760; loss: 1.24; acc: 0.61
Batch: 780; loss: 1.06; acc: 0.72
Train Epoch over. train_loss: 1.75; train_accuracy: 0.39 

Batch: 0; loss: 1.63; acc: 0.45
Batch: 20; loss: 1.77; acc: 0.41
Batch: 40; loss: 0.9; acc: 0.81
Batch: 60; loss: 1.32; acc: 0.62
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.3; acc: 0.61
Batch: 120; loss: 1.51; acc: 0.55
Batch: 140; loss: 1.21; acc: 0.59
Val Epoch over. val_loss: 1.3186447631781268; val_accuracy: 0.5685708598726115 

The current subspace-distance is: 1.3881952327210456e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.59; acc: 0.48
Batch: 20; loss: 1.36; acc: 0.53
Batch: 40; loss: 1.32; acc: 0.64
Batch: 60; loss: 1.2; acc: 0.62
Batch: 80; loss: 1.29; acc: 0.56
Batch: 100; loss: 1.3; acc: 0.53
Batch: 120; loss: 1.25; acc: 0.55
Batch: 140; loss: 1.19; acc: 0.58
Batch: 160; loss: 1.15; acc: 0.58
Batch: 180; loss: 1.11; acc: 0.55
Batch: 200; loss: 1.32; acc: 0.59
Batch: 220; loss: 1.19; acc: 0.64
Batch: 240; loss: 1.52; acc: 0.53
Batch: 260; loss: 1.14; acc: 0.7
Batch: 280; loss: 1.02; acc: 0.72
Batch: 300; loss: 1.52; acc: 0.55
Batch: 320; loss: 1.09; acc: 0.64
Batch: 340; loss: 1.37; acc: 0.5
Batch: 360; loss: 1.1; acc: 0.66
Batch: 380; loss: 1.19; acc: 0.58
Batch: 400; loss: 1.31; acc: 0.56
Batch: 420; loss: 1.3; acc: 0.56
Batch: 440; loss: 1.03; acc: 0.7
Batch: 460; loss: 0.95; acc: 0.67
Batch: 480; loss: 1.02; acc: 0.55
Batch: 500; loss: 1.02; acc: 0.7
Batch: 520; loss: 1.28; acc: 0.55
Batch: 540; loss: 1.31; acc: 0.56
Batch: 560; loss: 1.31; acc: 0.64
Batch: 580; loss: 0.93; acc: 0.7
Batch: 600; loss: 1.26; acc: 0.69
Batch: 620; loss: 1.28; acc: 0.64
Batch: 640; loss: 1.25; acc: 0.64
Batch: 660; loss: 1.03; acc: 0.7
Batch: 680; loss: 1.31; acc: 0.53
Batch: 700; loss: 1.36; acc: 0.55
Batch: 720; loss: 1.42; acc: 0.53
Batch: 740; loss: 1.07; acc: 0.67
Batch: 760; loss: 1.17; acc: 0.62
Batch: 780; loss: 1.01; acc: 0.59
Train Epoch over. train_loss: 1.24; train_accuracy: 0.61 

Batch: 0; loss: 1.47; acc: 0.55
Batch: 20; loss: 1.51; acc: 0.5
Batch: 40; loss: 0.84; acc: 0.75
Batch: 60; loss: 1.15; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.61
Batch: 100; loss: 1.11; acc: 0.64
Batch: 120; loss: 1.3; acc: 0.59
Batch: 140; loss: 1.11; acc: 0.62
Val Epoch over. val_loss: 1.1704921866678129; val_accuracy: 0.6156449044585988 

The current subspace-distance is: 1.9229126337449998e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.15; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.48
Batch: 40; loss: 1.12; acc: 0.62
Batch: 60; loss: 1.26; acc: 0.56
Batch: 80; loss: 1.29; acc: 0.62
Batch: 100; loss: 1.05; acc: 0.66
Batch: 120; loss: 1.34; acc: 0.56
Batch: 140; loss: 1.44; acc: 0.52
Batch: 160; loss: 0.96; acc: 0.66
Batch: 180; loss: 1.06; acc: 0.69
Batch: 200; loss: 1.26; acc: 0.61
Batch: 220; loss: 1.31; acc: 0.53
Batch: 240; loss: 0.97; acc: 0.67
Batch: 260; loss: 1.24; acc: 0.62
Batch: 280; loss: 1.0; acc: 0.62
Batch: 300; loss: 1.19; acc: 0.62
Batch: 320; loss: 1.22; acc: 0.66
Batch: 340; loss: 1.04; acc: 0.67
Batch: 360; loss: 1.48; acc: 0.45
Batch: 380; loss: 1.05; acc: 0.66
Batch: 400; loss: 1.21; acc: 0.58
Batch: 420; loss: 1.24; acc: 0.55
Batch: 440; loss: 1.23; acc: 0.66
Batch: 460; loss: 1.19; acc: 0.62
Batch: 480; loss: 1.17; acc: 0.58
Batch: 500; loss: 1.11; acc: 0.69
Batch: 520; loss: 1.11; acc: 0.64
Batch: 540; loss: 1.23; acc: 0.53
Batch: 560; loss: 1.31; acc: 0.56
Batch: 580; loss: 1.32; acc: 0.58
Batch: 600; loss: 1.02; acc: 0.61
Batch: 620; loss: 1.16; acc: 0.62
Batch: 640; loss: 1.0; acc: 0.7
Batch: 660; loss: 0.99; acc: 0.62
Batch: 680; loss: 1.26; acc: 0.64
Batch: 700; loss: 1.54; acc: 0.56
Batch: 720; loss: 1.23; acc: 0.59
Batch: 740; loss: 1.08; acc: 0.62
Batch: 760; loss: 1.03; acc: 0.72
Batch: 780; loss: 1.04; acc: 0.69
Train Epoch over. train_loss: 1.16; train_accuracy: 0.62 

Batch: 0; loss: 1.4; acc: 0.5
Batch: 20; loss: 1.56; acc: 0.52
Batch: 40; loss: 0.74; acc: 0.8
Batch: 60; loss: 1.13; acc: 0.67
Batch: 80; loss: 1.12; acc: 0.66
Batch: 100; loss: 1.11; acc: 0.64
Batch: 120; loss: 1.24; acc: 0.59
Batch: 140; loss: 1.15; acc: 0.61
Val Epoch over. val_loss: 1.1114997996646128; val_accuracy: 0.6362460191082803 

The current subspace-distance is: 2.4535260308766738e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.66
Batch: 20; loss: 1.54; acc: 0.48
Batch: 40; loss: 1.19; acc: 0.7
Batch: 60; loss: 0.98; acc: 0.67
Batch: 80; loss: 1.12; acc: 0.59
Batch: 100; loss: 1.16; acc: 0.61
Batch: 120; loss: 1.21; acc: 0.61
Batch: 140; loss: 1.13; acc: 0.66
Batch: 160; loss: 0.92; acc: 0.73
Batch: 180; loss: 1.6; acc: 0.52
Batch: 200; loss: 1.05; acc: 0.61
Batch: 220; loss: 0.92; acc: 0.73
Batch: 240; loss: 1.31; acc: 0.56
Batch: 260; loss: 1.27; acc: 0.61
Batch: 280; loss: 0.89; acc: 0.75
Batch: 300; loss: 1.11; acc: 0.66
Batch: 320; loss: 1.04; acc: 0.69
Batch: 340; loss: 1.13; acc: 0.67
Batch: 360; loss: 1.08; acc: 0.58
Batch: 380; loss: 1.31; acc: 0.58
Batch: 400; loss: 1.1; acc: 0.62
Batch: 420; loss: 0.96; acc: 0.67
Batch: 440; loss: 0.96; acc: 0.66
Batch: 460; loss: 0.97; acc: 0.66
Batch: 480; loss: 1.16; acc: 0.66
Batch: 500; loss: 1.34; acc: 0.58
Batch: 520; loss: 1.29; acc: 0.56
Batch: 540; loss: 1.15; acc: 0.64
Batch: 560; loss: 1.52; acc: 0.52
Batch: 580; loss: 1.16; acc: 0.61
Batch: 600; loss: 1.01; acc: 0.62
Batch: 620; loss: 1.36; acc: 0.56
Batch: 640; loss: 1.17; acc: 0.61
Batch: 660; loss: 1.42; acc: 0.55
Batch: 680; loss: 1.44; acc: 0.53
Batch: 700; loss: 1.17; acc: 0.62
Batch: 720; loss: 1.36; acc: 0.62
Batch: 740; loss: 0.97; acc: 0.7
Batch: 760; loss: 1.01; acc: 0.64
Batch: 780; loss: 1.14; acc: 0.67
Train Epoch over. train_loss: 1.15; train_accuracy: 0.63 

Batch: 0; loss: 1.31; acc: 0.56
Batch: 20; loss: 1.57; acc: 0.48
Batch: 40; loss: 0.73; acc: 0.78
Batch: 60; loss: 1.12; acc: 0.66
Batch: 80; loss: 1.07; acc: 0.7
Batch: 100; loss: 1.15; acc: 0.61
Batch: 120; loss: 1.24; acc: 0.56
Batch: 140; loss: 1.16; acc: 0.62
Val Epoch over. val_loss: 1.1070092381185788; val_accuracy: 0.6307722929936306 

The current subspace-distance is: 2.9868067940697074e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.22; acc: 0.61
Batch: 20; loss: 1.4; acc: 0.53
Batch: 40; loss: 1.1; acc: 0.62
Batch: 60; loss: 1.15; acc: 0.61
Batch: 80; loss: 1.15; acc: 0.58
Batch: 100; loss: 1.25; acc: 0.66
Batch: 120; loss: 1.12; acc: 0.66
Batch: 140; loss: 1.29; acc: 0.53
Batch: 160; loss: 1.31; acc: 0.59
Batch: 180; loss: 1.4; acc: 0.53
Batch: 200; loss: 0.95; acc: 0.66
Batch: 220; loss: 0.94; acc: 0.77
Batch: 240; loss: 1.06; acc: 0.67
Batch: 260; loss: 1.09; acc: 0.72
Batch: 280; loss: 0.77; acc: 0.67
Batch: 300; loss: 1.02; acc: 0.61
Batch: 320; loss: 1.2; acc: 0.67
Batch: 340; loss: 1.1; acc: 0.7
Batch: 360; loss: 1.1; acc: 0.62
Batch: 380; loss: 1.5; acc: 0.53
Batch: 400; loss: 0.78; acc: 0.75
Batch: 420; loss: 0.94; acc: 0.7
Batch: 440; loss: 1.1; acc: 0.66
Batch: 460; loss: 1.16; acc: 0.56
Batch: 480; loss: 1.12; acc: 0.69
Batch: 500; loss: 1.21; acc: 0.69
Batch: 520; loss: 1.11; acc: 0.7
Batch: 540; loss: 1.03; acc: 0.64
Batch: 560; loss: 1.12; acc: 0.64
Batch: 580; loss: 0.88; acc: 0.67
Batch: 600; loss: 1.23; acc: 0.64
Batch: 620; loss: 1.2; acc: 0.64
Batch: 640; loss: 1.16; acc: 0.62
Batch: 660; loss: 1.18; acc: 0.7
Batch: 680; loss: 1.18; acc: 0.67
Batch: 700; loss: 1.09; acc: 0.61
Batch: 720; loss: 1.22; acc: 0.56
Batch: 740; loss: 1.07; acc: 0.61
Batch: 760; loss: 1.02; acc: 0.66
Batch: 780; loss: 1.18; acc: 0.66
Train Epoch over. train_loss: 1.13; train_accuracy: 0.64 

Batch: 0; loss: 1.21; acc: 0.53
Batch: 20; loss: 1.56; acc: 0.53
Batch: 40; loss: 0.72; acc: 0.86
Batch: 60; loss: 1.12; acc: 0.67
Batch: 80; loss: 1.02; acc: 0.67
Batch: 100; loss: 1.07; acc: 0.62
Batch: 120; loss: 1.32; acc: 0.61
Batch: 140; loss: 1.23; acc: 0.64
Val Epoch over. val_loss: 1.0932871463951792; val_accuracy: 0.644406847133758 

The current subspace-distance is: 3.373788422322832e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.04; acc: 0.62
Batch: 20; loss: 0.95; acc: 0.69
Batch: 40; loss: 1.14; acc: 0.66
Batch: 60; loss: 1.15; acc: 0.62
Batch: 80; loss: 1.15; acc: 0.64
Batch: 100; loss: 0.8; acc: 0.73
Batch: 120; loss: 1.15; acc: 0.67
Batch: 140; loss: 1.04; acc: 0.69
Batch: 160; loss: 1.19; acc: 0.64
Batch: 180; loss: 0.9; acc: 0.72
Batch: 200; loss: 1.21; acc: 0.59
Batch: 220; loss: 1.11; acc: 0.61
Batch: 240; loss: 1.15; acc: 0.61
Batch: 260; loss: 0.96; acc: 0.67
Batch: 280; loss: 1.25; acc: 0.64
Batch: 300; loss: 1.21; acc: 0.62
Batch: 320; loss: 0.97; acc: 0.66
Batch: 340; loss: 1.1; acc: 0.61
Batch: 360; loss: 1.18; acc: 0.62
Batch: 380; loss: 1.18; acc: 0.62
Batch: 400; loss: 1.17; acc: 0.66
Batch: 420; loss: 0.9; acc: 0.7
Batch: 440; loss: 1.04; acc: 0.73
Batch: 460; loss: 1.2; acc: 0.53
Batch: 480; loss: 0.95; acc: 0.64
Batch: 500; loss: 1.03; acc: 0.66
Batch: 520; loss: 1.13; acc: 0.62
Batch: 540; loss: 0.95; acc: 0.64
Batch: 560; loss: 1.39; acc: 0.61
Batch: 580; loss: 1.02; acc: 0.67
Batch: 600; loss: 1.06; acc: 0.59
Batch: 620; loss: 1.14; acc: 0.66
Batch: 640; loss: 1.16; acc: 0.67
Batch: 660; loss: 1.41; acc: 0.59
Batch: 680; loss: 0.92; acc: 0.67
Batch: 700; loss: 1.02; acc: 0.67
Batch: 720; loss: 1.26; acc: 0.61
Batch: 740; loss: 1.1; acc: 0.69
Batch: 760; loss: 1.2; acc: 0.62
Batch: 780; loss: 0.85; acc: 0.73
Train Epoch over. train_loss: 1.11; train_accuracy: 0.64 

Batch: 0; loss: 1.32; acc: 0.53
Batch: 20; loss: 1.47; acc: 0.5
Batch: 40; loss: 0.75; acc: 0.77
Batch: 60; loss: 1.11; acc: 0.56
Batch: 80; loss: 0.95; acc: 0.69
Batch: 100; loss: 1.08; acc: 0.64
Batch: 120; loss: 1.2; acc: 0.61
Batch: 140; loss: 1.13; acc: 0.56
Val Epoch over. val_loss: 1.1047509046876507; val_accuracy: 0.6358479299363057 

The current subspace-distance is: 3.542942431522533e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.61
Batch: 20; loss: 1.04; acc: 0.66
Batch: 40; loss: 1.28; acc: 0.58
Batch: 60; loss: 0.81; acc: 0.75
Batch: 80; loss: 1.17; acc: 0.58
Batch: 100; loss: 1.15; acc: 0.64
Batch: 120; loss: 1.09; acc: 0.64
Batch: 140; loss: 1.12; acc: 0.66
Batch: 160; loss: 1.21; acc: 0.55
Batch: 180; loss: 1.18; acc: 0.61
Batch: 200; loss: 0.95; acc: 0.7
Batch: 220; loss: 1.02; acc: 0.7
Batch: 240; loss: 1.27; acc: 0.62
Batch: 260; loss: 1.15; acc: 0.59
Batch: 280; loss: 1.0; acc: 0.64
Batch: 300; loss: 1.27; acc: 0.59
Batch: 320; loss: 0.97; acc: 0.67
Batch: 340; loss: 1.36; acc: 0.53
Batch: 360; loss: 1.23; acc: 0.56
Batch: 380; loss: 0.83; acc: 0.7
Batch: 400; loss: 1.3; acc: 0.58
Batch: 420; loss: 1.21; acc: 0.59
Batch: 440; loss: 1.23; acc: 0.59
Batch: 460; loss: 1.32; acc: 0.52
Batch: 480; loss: 1.02; acc: 0.72
Batch: 500; loss: 1.42; acc: 0.61
Batch: 520; loss: 1.21; acc: 0.62
Batch: 540; loss: 1.06; acc: 0.64
Batch: 560; loss: 1.06; acc: 0.7
Batch: 580; loss: 1.2; acc: 0.59
Batch: 600; loss: 1.26; acc: 0.58
Batch: 620; loss: 0.96; acc: 0.66
Batch: 640; loss: 1.11; acc: 0.69
Batch: 660; loss: 1.07; acc: 0.64
Batch: 680; loss: 1.08; acc: 0.66
Batch: 700; loss: 1.16; acc: 0.64
Batch: 720; loss: 1.17; acc: 0.64
Batch: 740; loss: 1.17; acc: 0.62
Batch: 760; loss: 1.08; acc: 0.67
Batch: 780; loss: 0.94; acc: 0.73
Train Epoch over. train_loss: 1.1; train_accuracy: 0.65 

Batch: 0; loss: 1.17; acc: 0.56
Batch: 20; loss: 1.34; acc: 0.53
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.94; acc: 0.7
Batch: 80; loss: 0.79; acc: 0.69
Batch: 100; loss: 0.9; acc: 0.72
Batch: 120; loss: 1.22; acc: 0.55
Batch: 140; loss: 1.04; acc: 0.7
Val Epoch over. val_loss: 1.063030638132885; val_accuracy: 0.6667993630573248 

The current subspace-distance is: 3.990876939496957e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.66
Batch: 20; loss: 1.22; acc: 0.59
Batch: 40; loss: 0.87; acc: 0.7
Batch: 60; loss: 1.22; acc: 0.58
Batch: 80; loss: 1.0; acc: 0.7
Batch: 100; loss: 1.23; acc: 0.64
Batch: 120; loss: 0.93; acc: 0.78
Batch: 140; loss: 1.1; acc: 0.62
Batch: 160; loss: 0.95; acc: 0.61
Batch: 180; loss: 1.32; acc: 0.59
Batch: 200; loss: 1.18; acc: 0.58
Batch: 220; loss: 1.12; acc: 0.67
Batch: 240; loss: 1.13; acc: 0.59
Batch: 260; loss: 1.09; acc: 0.66
Batch: 280; loss: 1.07; acc: 0.67
Batch: 300; loss: 1.02; acc: 0.67
Batch: 320; loss: 1.08; acc: 0.62
Batch: 340; loss: 1.16; acc: 0.7
Batch: 360; loss: 1.0; acc: 0.61
Batch: 380; loss: 0.76; acc: 0.75
Batch: 400; loss: 0.98; acc: 0.67
Batch: 420; loss: 0.9; acc: 0.72
Batch: 440; loss: 0.95; acc: 0.72
Batch: 460; loss: 1.13; acc: 0.61
Batch: 480; loss: 1.15; acc: 0.62
Batch: 500; loss: 1.21; acc: 0.61
Batch: 520; loss: 0.96; acc: 0.66
Batch: 540; loss: 0.9; acc: 0.7
Batch: 560; loss: 1.14; acc: 0.7
Batch: 580; loss: 0.87; acc: 0.7
Batch: 600; loss: 1.11; acc: 0.73
Batch: 620; loss: 1.04; acc: 0.72
Batch: 640; loss: 1.0; acc: 0.7
Batch: 660; loss: 1.08; acc: 0.66
Batch: 680; loss: 1.23; acc: 0.62
Batch: 700; loss: 1.13; acc: 0.69
Batch: 720; loss: 1.22; acc: 0.61
Batch: 740; loss: 1.08; acc: 0.67
Batch: 760; loss: 0.99; acc: 0.64
Batch: 780; loss: 1.39; acc: 0.61
Train Epoch over. train_loss: 1.09; train_accuracy: 0.65 

Batch: 0; loss: 1.17; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.59
Batch: 40; loss: 0.7; acc: 0.75
Batch: 60; loss: 1.01; acc: 0.62
Batch: 80; loss: 0.81; acc: 0.73
Batch: 100; loss: 0.91; acc: 0.73
Batch: 120; loss: 1.16; acc: 0.55
Batch: 140; loss: 0.97; acc: 0.69
Val Epoch over. val_loss: 1.0379334126308466; val_accuracy: 0.6606289808917197 

The current subspace-distance is: 4.401555997901596e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.06; acc: 0.69
Batch: 20; loss: 1.13; acc: 0.64
Batch: 40; loss: 1.21; acc: 0.58
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 1.12; acc: 0.7
Batch: 100; loss: 0.99; acc: 0.67
Batch: 120; loss: 1.23; acc: 0.62
Batch: 140; loss: 1.1; acc: 0.64
Batch: 160; loss: 1.18; acc: 0.58
Batch: 180; loss: 0.94; acc: 0.7
Batch: 200; loss: 1.01; acc: 0.7
Batch: 220; loss: 1.09; acc: 0.59
Batch: 240; loss: 0.97; acc: 0.7
Batch: 260; loss: 1.11; acc: 0.69
Batch: 280; loss: 0.91; acc: 0.73
Batch: 300; loss: 0.85; acc: 0.69
Batch: 320; loss: 0.82; acc: 0.78
Batch: 340; loss: 1.05; acc: 0.67
Batch: 360; loss: 0.96; acc: 0.7
Batch: 380; loss: 1.05; acc: 0.66
Batch: 400; loss: 1.14; acc: 0.64
Batch: 420; loss: 1.11; acc: 0.56
Batch: 440; loss: 1.0; acc: 0.69
Batch: 460; loss: 1.01; acc: 0.7
Batch: 480; loss: 0.98; acc: 0.7
Batch: 500; loss: 1.33; acc: 0.64
Batch: 520; loss: 1.13; acc: 0.64
Batch: 540; loss: 1.26; acc: 0.59
Batch: 560; loss: 1.31; acc: 0.55
Batch: 580; loss: 1.19; acc: 0.64
Batch: 600; loss: 0.98; acc: 0.69
Batch: 620; loss: 1.04; acc: 0.69
Batch: 640; loss: 0.88; acc: 0.7
Batch: 660; loss: 0.91; acc: 0.72
Batch: 680; loss: 1.04; acc: 0.66
Batch: 700; loss: 1.03; acc: 0.67
Batch: 720; loss: 0.97; acc: 0.66
Batch: 740; loss: 0.92; acc: 0.66
Batch: 760; loss: 1.03; acc: 0.66
Batch: 780; loss: 1.4; acc: 0.56
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.59
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 1.01; acc: 0.62
Batch: 80; loss: 0.77; acc: 0.73
Batch: 100; loss: 0.94; acc: 0.72
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 0.95; acc: 0.66
Val Epoch over. val_loss: 1.0108150836009129; val_accuracy: 0.6734673566878981 

The current subspace-distance is: 4.730376531369984e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.09; acc: 0.67
Batch: 20; loss: 1.26; acc: 0.59
Batch: 40; loss: 1.08; acc: 0.7
Batch: 60; loss: 0.93; acc: 0.75
Batch: 80; loss: 0.99; acc: 0.69
Batch: 100; loss: 1.19; acc: 0.64
Batch: 120; loss: 1.43; acc: 0.59
Batch: 140; loss: 1.15; acc: 0.69
Batch: 160; loss: 1.06; acc: 0.7
Batch: 180; loss: 1.09; acc: 0.64
Batch: 200; loss: 1.15; acc: 0.61
Batch: 220; loss: 0.98; acc: 0.69
Batch: 240; loss: 1.0; acc: 0.62
Batch: 260; loss: 0.98; acc: 0.66
Batch: 280; loss: 1.1; acc: 0.66
Batch: 300; loss: 0.95; acc: 0.66
Batch: 320; loss: 0.81; acc: 0.78
Batch: 340; loss: 0.85; acc: 0.73
Batch: 360; loss: 0.97; acc: 0.67
Batch: 380; loss: 0.98; acc: 0.73
Batch: 400; loss: 0.98; acc: 0.62
Batch: 420; loss: 0.92; acc: 0.67
Batch: 440; loss: 1.24; acc: 0.69
Batch: 460; loss: 1.11; acc: 0.66
Batch: 480; loss: 0.83; acc: 0.66
Batch: 500; loss: 1.13; acc: 0.61
Batch: 520; loss: 0.81; acc: 0.7
Batch: 540; loss: 0.85; acc: 0.75
Batch: 560; loss: 1.13; acc: 0.61
Batch: 580; loss: 1.17; acc: 0.64
Batch: 600; loss: 1.3; acc: 0.58
Batch: 620; loss: 1.15; acc: 0.58
Batch: 640; loss: 0.79; acc: 0.7
Batch: 660; loss: 1.18; acc: 0.58
Batch: 680; loss: 1.19; acc: 0.66
Batch: 700; loss: 1.06; acc: 0.67
Batch: 720; loss: 1.16; acc: 0.61
Batch: 740; loss: 1.02; acc: 0.69
Batch: 760; loss: 1.18; acc: 0.66
Batch: 780; loss: 1.25; acc: 0.61
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.18; acc: 0.58
Batch: 20; loss: 1.31; acc: 0.55
Batch: 40; loss: 0.72; acc: 0.78
Batch: 60; loss: 1.05; acc: 0.61
Batch: 80; loss: 0.82; acc: 0.72
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 1.13; acc: 0.64
Batch: 140; loss: 0.99; acc: 0.66
Val Epoch over. val_loss: 1.0405613187771694; val_accuracy: 0.6610270700636943 

The current subspace-distance is: 5.1160237489966676e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.16; acc: 0.58
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 1.1; acc: 0.59
Batch: 60; loss: 1.19; acc: 0.62
Batch: 80; loss: 1.08; acc: 0.66
Batch: 100; loss: 1.02; acc: 0.59
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.9; acc: 0.75
Batch: 160; loss: 1.01; acc: 0.67
Batch: 180; loss: 1.39; acc: 0.55
Batch: 200; loss: 1.05; acc: 0.61
Batch: 220; loss: 1.29; acc: 0.59
Batch: 240; loss: 0.98; acc: 0.7
Batch: 260; loss: 1.17; acc: 0.56
Batch: 280; loss: 1.27; acc: 0.66
Batch: 300; loss: 1.05; acc: 0.7
Batch: 320; loss: 1.14; acc: 0.66
Batch: 340; loss: 1.03; acc: 0.7
Batch: 360; loss: 1.22; acc: 0.58
Batch: 380; loss: 1.04; acc: 0.67
Batch: 400; loss: 0.98; acc: 0.66
Batch: 420; loss: 1.24; acc: 0.59
Batch: 440; loss: 1.08; acc: 0.66
Batch: 460; loss: 1.09; acc: 0.61
Batch: 480; loss: 1.17; acc: 0.61
Batch: 500; loss: 0.95; acc: 0.67
Batch: 520; loss: 1.27; acc: 0.61
Batch: 540; loss: 1.1; acc: 0.66
Batch: 560; loss: 1.14; acc: 0.62
Batch: 580; loss: 1.1; acc: 0.67
Batch: 600; loss: 1.22; acc: 0.58
Batch: 620; loss: 0.89; acc: 0.77
Batch: 640; loss: 1.01; acc: 0.58
Batch: 660; loss: 1.17; acc: 0.61
Batch: 680; loss: 0.86; acc: 0.77
Batch: 700; loss: 0.99; acc: 0.7
Batch: 720; loss: 0.95; acc: 0.69
Batch: 740; loss: 1.22; acc: 0.64
Batch: 760; loss: 1.06; acc: 0.7
Batch: 780; loss: 1.03; acc: 0.67
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.61
Batch: 20; loss: 1.33; acc: 0.58
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 1.05; acc: 0.61
Batch: 80; loss: 0.79; acc: 0.7
Batch: 100; loss: 0.96; acc: 0.67
Batch: 120; loss: 1.19; acc: 0.59
Batch: 140; loss: 1.02; acc: 0.64
Val Epoch over. val_loss: 1.021001302512588; val_accuracy: 0.6678941082802548 

The current subspace-distance is: 5.353346932679415e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.19; acc: 0.59
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 1.03; acc: 0.69
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.92; acc: 0.62
Batch: 100; loss: 1.22; acc: 0.67
Batch: 120; loss: 1.16; acc: 0.7
Batch: 140; loss: 0.81; acc: 0.75
Batch: 160; loss: 0.93; acc: 0.69
Batch: 180; loss: 0.98; acc: 0.72
Batch: 200; loss: 1.18; acc: 0.53
Batch: 220; loss: 1.03; acc: 0.7
Batch: 240; loss: 1.12; acc: 0.58
Batch: 260; loss: 0.99; acc: 0.72
Batch: 280; loss: 1.11; acc: 0.67
Batch: 300; loss: 0.87; acc: 0.73
Batch: 320; loss: 1.35; acc: 0.67
Batch: 340; loss: 1.3; acc: 0.62
Batch: 360; loss: 1.1; acc: 0.69
Batch: 380; loss: 1.07; acc: 0.59
Batch: 400; loss: 1.07; acc: 0.73
Batch: 420; loss: 1.03; acc: 0.59
Batch: 440; loss: 1.17; acc: 0.56
Batch: 460; loss: 1.39; acc: 0.52
Batch: 480; loss: 0.85; acc: 0.78
Batch: 500; loss: 0.9; acc: 0.7
Batch: 520; loss: 1.09; acc: 0.64
Batch: 540; loss: 1.11; acc: 0.67
Batch: 560; loss: 1.33; acc: 0.59
Batch: 580; loss: 0.84; acc: 0.75
Batch: 600; loss: 1.18; acc: 0.62
Batch: 620; loss: 1.53; acc: 0.56
Batch: 640; loss: 1.08; acc: 0.61
Batch: 660; loss: 1.08; acc: 0.69
Batch: 680; loss: 1.1; acc: 0.66
Batch: 700; loss: 1.1; acc: 0.56
Batch: 720; loss: 0.95; acc: 0.7
Batch: 740; loss: 1.17; acc: 0.61
Batch: 760; loss: 1.06; acc: 0.62
Batch: 780; loss: 1.03; acc: 0.72
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.62
Batch: 20; loss: 1.32; acc: 0.58
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.99; acc: 0.62
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.19; acc: 0.59
Batch: 140; loss: 1.02; acc: 0.64
Val Epoch over. val_loss: 1.0268781739435378; val_accuracy: 0.6720740445859873 

The current subspace-distance is: 5.471038457471877e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.08; acc: 0.66
Batch: 20; loss: 0.99; acc: 0.72
Batch: 40; loss: 1.09; acc: 0.64
Batch: 60; loss: 1.22; acc: 0.59
Batch: 80; loss: 1.16; acc: 0.67
Batch: 100; loss: 1.15; acc: 0.67
Batch: 120; loss: 0.93; acc: 0.7
Batch: 140; loss: 1.16; acc: 0.64
Batch: 160; loss: 0.91; acc: 0.7
Batch: 180; loss: 0.94; acc: 0.64
Batch: 200; loss: 1.13; acc: 0.66
Batch: 220; loss: 1.05; acc: 0.58
Batch: 240; loss: 1.12; acc: 0.73
Batch: 260; loss: 0.94; acc: 0.75
Batch: 280; loss: 0.97; acc: 0.7
Batch: 300; loss: 1.28; acc: 0.61
Batch: 320; loss: 0.98; acc: 0.77
Batch: 340; loss: 1.13; acc: 0.62
Batch: 360; loss: 1.19; acc: 0.62
Batch: 380; loss: 1.14; acc: 0.61
Batch: 400; loss: 1.11; acc: 0.61
Batch: 420; loss: 1.2; acc: 0.62
Batch: 440; loss: 1.0; acc: 0.61
Batch: 460; loss: 1.2; acc: 0.58
Batch: 480; loss: 1.22; acc: 0.56
Batch: 500; loss: 0.94; acc: 0.7
Batch: 520; loss: 0.97; acc: 0.69
Batch: 540; loss: 1.09; acc: 0.64
Batch: 560; loss: 1.21; acc: 0.62
Batch: 580; loss: 1.17; acc: 0.58
Batch: 600; loss: 1.2; acc: 0.61
Batch: 620; loss: 0.91; acc: 0.72
Batch: 640; loss: 1.17; acc: 0.66
Batch: 660; loss: 0.92; acc: 0.67
Batch: 680; loss: 1.18; acc: 0.59
Batch: 700; loss: 1.22; acc: 0.66
Batch: 720; loss: 0.96; acc: 0.62
Batch: 740; loss: 1.28; acc: 0.64
Batch: 760; loss: 1.05; acc: 0.67
Batch: 780; loss: 1.24; acc: 0.62
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.14; acc: 0.59
Batch: 20; loss: 1.31; acc: 0.56
Batch: 40; loss: 0.69; acc: 0.78
Batch: 60; loss: 1.01; acc: 0.62
Batch: 80; loss: 0.78; acc: 0.75
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 1.01; acc: 0.66
Val Epoch over. val_loss: 1.0180068513390366; val_accuracy: 0.6697850318471338 

The current subspace-distance is: 5.7554141676519066e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.07; acc: 0.66
Batch: 20; loss: 1.48; acc: 0.53
Batch: 40; loss: 0.95; acc: 0.72
Batch: 60; loss: 1.23; acc: 0.66
Batch: 80; loss: 1.15; acc: 0.58
Batch: 100; loss: 1.06; acc: 0.66
Batch: 120; loss: 1.03; acc: 0.62
Batch: 140; loss: 1.16; acc: 0.67
Batch: 160; loss: 1.04; acc: 0.72
Batch: 180; loss: 1.02; acc: 0.69
Batch: 200; loss: 1.22; acc: 0.66
Batch: 220; loss: 0.92; acc: 0.7
Batch: 240; loss: 1.02; acc: 0.69
Batch: 260; loss: 1.03; acc: 0.69
Batch: 280; loss: 1.16; acc: 0.66
Batch: 300; loss: 1.07; acc: 0.61
Batch: 320; loss: 1.1; acc: 0.62
Batch: 340; loss: 1.07; acc: 0.67
Batch: 360; loss: 1.09; acc: 0.73
Batch: 380; loss: 1.03; acc: 0.69
Batch: 400; loss: 1.11; acc: 0.61
Batch: 420; loss: 0.86; acc: 0.77
Batch: 440; loss: 1.19; acc: 0.62
Batch: 460; loss: 1.2; acc: 0.59
Batch: 480; loss: 1.25; acc: 0.55
Batch: 500; loss: 1.04; acc: 0.69
Batch: 520; loss: 1.02; acc: 0.67
Batch: 540; loss: 1.26; acc: 0.61
Batch: 560; loss: 1.15; acc: 0.67
Batch: 580; loss: 1.14; acc: 0.66
Batch: 600; loss: 0.87; acc: 0.72
Batch: 620; loss: 0.88; acc: 0.66
Batch: 640; loss: 1.05; acc: 0.72
Batch: 660; loss: 1.1; acc: 0.66
Batch: 680; loss: 1.31; acc: 0.53
Batch: 700; loss: 0.82; acc: 0.7
Batch: 720; loss: 1.16; acc: 0.67
Batch: 740; loss: 0.98; acc: 0.62
Batch: 760; loss: 1.02; acc: 0.61
Batch: 780; loss: 0.97; acc: 0.67
Train Epoch over. train_loss: 1.08; train_accuracy: 0.65 

Batch: 0; loss: 1.1; acc: 0.66
Batch: 20; loss: 1.34; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 1.01; acc: 0.61
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.93; acc: 0.69
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 1.02; acc: 0.66
Val Epoch over. val_loss: 1.0193877189782015; val_accuracy: 0.6677945859872612 

The current subspace-distance is: 5.864066770300269e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.05; acc: 0.61
Batch: 20; loss: 1.13; acc: 0.62
Batch: 40; loss: 1.29; acc: 0.56
Batch: 60; loss: 1.31; acc: 0.61
Batch: 80; loss: 0.97; acc: 0.81
Batch: 100; loss: 1.21; acc: 0.64
Batch: 120; loss: 1.22; acc: 0.59
Batch: 140; loss: 1.2; acc: 0.69
Batch: 160; loss: 1.09; acc: 0.7
Batch: 180; loss: 1.18; acc: 0.67
Batch: 200; loss: 0.95; acc: 0.7
Batch: 220; loss: 1.08; acc: 0.66
Batch: 240; loss: 1.05; acc: 0.66
Batch: 260; loss: 0.95; acc: 0.66
Batch: 280; loss: 1.19; acc: 0.61
Batch: 300; loss: 1.12; acc: 0.62
Batch: 320; loss: 0.99; acc: 0.73
Batch: 340; loss: 1.07; acc: 0.69
Batch: 360; loss: 1.08; acc: 0.69
Batch: 380; loss: 1.2; acc: 0.61
Batch: 400; loss: 1.14; acc: 0.66
Batch: 420; loss: 1.01; acc: 0.66
Batch: 440; loss: 0.86; acc: 0.73
Batch: 460; loss: 1.01; acc: 0.73
Batch: 480; loss: 0.98; acc: 0.75
Batch: 500; loss: 1.13; acc: 0.59
Batch: 520; loss: 1.14; acc: 0.69
Batch: 540; loss: 1.35; acc: 0.59
Batch: 560; loss: 1.21; acc: 0.56
Batch: 580; loss: 1.19; acc: 0.66
Batch: 600; loss: 1.3; acc: 0.58
Batch: 620; loss: 1.1; acc: 0.7
Batch: 640; loss: 1.03; acc: 0.67
Batch: 660; loss: 0.83; acc: 0.77
Batch: 680; loss: 1.0; acc: 0.72
Batch: 700; loss: 1.06; acc: 0.66
Batch: 720; loss: 0.84; acc: 0.66
Batch: 740; loss: 0.91; acc: 0.73
Batch: 760; loss: 0.75; acc: 0.84
Batch: 780; loss: 1.07; acc: 0.62
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.56
Batch: 20; loss: 1.32; acc: 0.55
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 1.05; acc: 0.62
Batch: 80; loss: 0.8; acc: 0.69
Batch: 100; loss: 0.96; acc: 0.69
Batch: 120; loss: 1.19; acc: 0.58
Batch: 140; loss: 1.0; acc: 0.66
Val Epoch over. val_loss: 1.0209426211703354; val_accuracy: 0.666202229299363 

The current subspace-distance is: 6.0439033404691145e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.04; acc: 0.69
Batch: 20; loss: 1.06; acc: 0.64
Batch: 40; loss: 0.97; acc: 0.69
Batch: 60; loss: 1.01; acc: 0.67
Batch: 80; loss: 1.08; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.64
Batch: 120; loss: 0.98; acc: 0.67
Batch: 140; loss: 0.84; acc: 0.73
Batch: 160; loss: 0.98; acc: 0.66
Batch: 180; loss: 1.14; acc: 0.56
Batch: 200; loss: 0.88; acc: 0.73
Batch: 220; loss: 0.96; acc: 0.72
Batch: 240; loss: 0.99; acc: 0.59
Batch: 260; loss: 0.75; acc: 0.73
Batch: 280; loss: 1.22; acc: 0.59
Batch: 300; loss: 0.78; acc: 0.8
Batch: 320; loss: 1.18; acc: 0.62
Batch: 340; loss: 1.28; acc: 0.66
Batch: 360; loss: 1.15; acc: 0.62
Batch: 380; loss: 1.55; acc: 0.5
Batch: 400; loss: 1.22; acc: 0.62
Batch: 420; loss: 1.06; acc: 0.67
Batch: 440; loss: 1.19; acc: 0.58
Batch: 460; loss: 1.4; acc: 0.58
Batch: 480; loss: 1.18; acc: 0.66
Batch: 500; loss: 1.08; acc: 0.64
Batch: 520; loss: 1.02; acc: 0.59
Batch: 540; loss: 1.15; acc: 0.67
Batch: 560; loss: 1.44; acc: 0.53
Batch: 580; loss: 0.94; acc: 0.64
Batch: 600; loss: 1.06; acc: 0.69
Batch: 620; loss: 1.14; acc: 0.67
Batch: 640; loss: 1.03; acc: 0.66
Batch: 660; loss: 1.13; acc: 0.56
Batch: 680; loss: 1.06; acc: 0.64
Batch: 700; loss: 0.92; acc: 0.69
Batch: 720; loss: 0.91; acc: 0.73
Batch: 740; loss: 1.29; acc: 0.56
Batch: 760; loss: 1.5; acc: 0.59
Batch: 780; loss: 1.08; acc: 0.64
Train Epoch over. train_loss: 1.08; train_accuracy: 0.65 

Batch: 0; loss: 1.14; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.58
Batch: 40; loss: 0.69; acc: 0.84
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 1.17; acc: 0.56
Batch: 140; loss: 0.94; acc: 0.67
Val Epoch over. val_loss: 1.0193952732025438; val_accuracy: 0.6721735668789809 

The current subspace-distance is: 6.551491969730705e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.09; acc: 0.64
Batch: 20; loss: 1.02; acc: 0.7
Batch: 40; loss: 1.0; acc: 0.64
Batch: 60; loss: 0.85; acc: 0.7
Batch: 80; loss: 0.88; acc: 0.7
Batch: 100; loss: 0.94; acc: 0.75
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 1.2; acc: 0.62
Batch: 160; loss: 0.91; acc: 0.67
Batch: 180; loss: 1.39; acc: 0.64
Batch: 200; loss: 1.0; acc: 0.64
Batch: 220; loss: 0.95; acc: 0.64
Batch: 240; loss: 1.27; acc: 0.53
Batch: 260; loss: 0.99; acc: 0.7
Batch: 280; loss: 1.17; acc: 0.72
Batch: 300; loss: 1.26; acc: 0.59
Batch: 320; loss: 0.86; acc: 0.7
Batch: 340; loss: 1.12; acc: 0.64
Batch: 360; loss: 0.83; acc: 0.72
Batch: 380; loss: 1.1; acc: 0.62
Batch: 400; loss: 1.16; acc: 0.56
Batch: 420; loss: 1.16; acc: 0.58
Batch: 440; loss: 1.43; acc: 0.59
Batch: 460; loss: 0.94; acc: 0.64
Batch: 480; loss: 0.98; acc: 0.7
Batch: 500; loss: 1.05; acc: 0.69
Batch: 520; loss: 1.12; acc: 0.62
Batch: 540; loss: 1.07; acc: 0.7
Batch: 560; loss: 1.02; acc: 0.7
Batch: 580; loss: 0.75; acc: 0.75
Batch: 600; loss: 0.86; acc: 0.77
Batch: 620; loss: 0.92; acc: 0.7
Batch: 640; loss: 0.92; acc: 0.69
Batch: 660; loss: 1.17; acc: 0.62
Batch: 680; loss: 1.19; acc: 0.61
Batch: 700; loss: 0.86; acc: 0.75
Batch: 720; loss: 1.18; acc: 0.67
Batch: 740; loss: 1.12; acc: 0.67
Batch: 760; loss: 0.84; acc: 0.72
Batch: 780; loss: 1.16; acc: 0.66
Train Epoch over. train_loss: 1.08; train_accuracy: 0.66 

Batch: 0; loss: 1.13; acc: 0.61
Batch: 20; loss: 1.31; acc: 0.56
Batch: 40; loss: 0.71; acc: 0.8
Batch: 60; loss: 0.97; acc: 0.67
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.55
Batch: 140; loss: 1.01; acc: 0.67
Val Epoch over. val_loss: 1.0290574978111655; val_accuracy: 0.6685907643312102 

The current subspace-distance is: 6.582871719729155e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 1.21; acc: 0.66
Batch: 40; loss: 1.17; acc: 0.64
Batch: 60; loss: 1.43; acc: 0.55
Batch: 80; loss: 0.9; acc: 0.73
Batch: 100; loss: 1.08; acc: 0.59
Batch: 120; loss: 1.14; acc: 0.67
Batch: 140; loss: 1.23; acc: 0.64
Batch: 160; loss: 0.96; acc: 0.69
Batch: 180; loss: 0.83; acc: 0.81
Batch: 200; loss: 1.02; acc: 0.66
Batch: 220; loss: 1.1; acc: 0.67
Batch: 240; loss: 1.07; acc: 0.66
Batch: 260; loss: 1.25; acc: 0.62
Batch: 280; loss: 1.15; acc: 0.64
Batch: 300; loss: 1.19; acc: 0.55
Batch: 320; loss: 1.27; acc: 0.67
Batch: 340; loss: 1.0; acc: 0.72
Batch: 360; loss: 0.95; acc: 0.72
Batch: 380; loss: 1.01; acc: 0.64
Batch: 400; loss: 1.17; acc: 0.58
Batch: 420; loss: 1.0; acc: 0.67
Batch: 440; loss: 0.89; acc: 0.72
Batch: 460; loss: 0.97; acc: 0.7
Batch: 480; loss: 0.83; acc: 0.69
Batch: 500; loss: 0.85; acc: 0.75
Batch: 520; loss: 1.45; acc: 0.67
Batch: 540; loss: 1.09; acc: 0.62
Batch: 560; loss: 1.36; acc: 0.56
Batch: 580; loss: 1.14; acc: 0.58
Batch: 600; loss: 0.99; acc: 0.67
Batch: 620; loss: 1.04; acc: 0.62
Batch: 640; loss: 1.16; acc: 0.61
Batch: 660; loss: 1.22; acc: 0.59
Batch: 680; loss: 0.99; acc: 0.62
Batch: 700; loss: 1.01; acc: 0.64
Batch: 720; loss: 0.99; acc: 0.69
Batch: 740; loss: 1.12; acc: 0.67
Batch: 760; loss: 1.32; acc: 0.61
Batch: 780; loss: 1.06; acc: 0.66
Train Epoch over. train_loss: 1.08; train_accuracy: 0.65 

Batch: 0; loss: 1.1; acc: 0.61
Batch: 20; loss: 1.3; acc: 0.59
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.98; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.93; acc: 0.73
Batch: 120; loss: 1.18; acc: 0.58
Batch: 140; loss: 0.95; acc: 0.69
Val Epoch over. val_loss: 1.01666352285701; val_accuracy: 0.67296974522293 

The current subspace-distance is: 6.748486339347437e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.27; acc: 0.59
Batch: 20; loss: 1.29; acc: 0.67
Batch: 40; loss: 1.05; acc: 0.62
Batch: 60; loss: 0.97; acc: 0.66
Batch: 80; loss: 1.14; acc: 0.67
Batch: 100; loss: 1.0; acc: 0.72
Batch: 120; loss: 0.98; acc: 0.66
Batch: 140; loss: 1.19; acc: 0.62
Batch: 160; loss: 0.88; acc: 0.62
Batch: 180; loss: 0.97; acc: 0.67
Batch: 200; loss: 1.13; acc: 0.66
Batch: 220; loss: 1.2; acc: 0.58
Batch: 240; loss: 1.19; acc: 0.66
Batch: 260; loss: 0.81; acc: 0.78
Batch: 280; loss: 0.86; acc: 0.7
Batch: 300; loss: 1.29; acc: 0.55
Batch: 320; loss: 1.04; acc: 0.7
Batch: 340; loss: 0.97; acc: 0.72
Batch: 360; loss: 0.78; acc: 0.77
Batch: 380; loss: 1.17; acc: 0.59
Batch: 400; loss: 0.91; acc: 0.8
Batch: 420; loss: 1.17; acc: 0.61
Batch: 440; loss: 0.97; acc: 0.72
Batch: 460; loss: 1.18; acc: 0.67
Batch: 480; loss: 1.06; acc: 0.67
Batch: 500; loss: 1.15; acc: 0.58
Batch: 520; loss: 1.01; acc: 0.64
Batch: 540; loss: 1.01; acc: 0.64
Batch: 560; loss: 1.06; acc: 0.55
Batch: 580; loss: 0.99; acc: 0.62
Batch: 600; loss: 1.15; acc: 0.62
Batch: 620; loss: 0.82; acc: 0.72
Batch: 640; loss: 1.01; acc: 0.72
Batch: 660; loss: 1.02; acc: 0.62
Batch: 680; loss: 1.22; acc: 0.59
Batch: 700; loss: 1.04; acc: 0.67
Batch: 720; loss: 0.78; acc: 0.72
Batch: 740; loss: 1.23; acc: 0.62
Batch: 760; loss: 1.18; acc: 0.55
Batch: 780; loss: 0.98; acc: 0.64
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.62
Batch: 20; loss: 1.29; acc: 0.55
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.98; acc: 0.64
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.7
Val Epoch over. val_loss: 1.011494678676508; val_accuracy: 0.6724721337579618 

The current subspace-distance is: 7.221677515190095e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.27; acc: 0.59
Batch: 20; loss: 1.03; acc: 0.67
Batch: 40; loss: 1.04; acc: 0.62
Batch: 60; loss: 0.94; acc: 0.66
Batch: 80; loss: 0.87; acc: 0.72
Batch: 100; loss: 1.02; acc: 0.72
Batch: 120; loss: 0.87; acc: 0.69
Batch: 140; loss: 1.37; acc: 0.59
Batch: 160; loss: 0.98; acc: 0.64
Batch: 180; loss: 1.05; acc: 0.67
Batch: 200; loss: 1.11; acc: 0.67
Batch: 220; loss: 1.09; acc: 0.66
Batch: 240; loss: 1.23; acc: 0.67
Batch: 260; loss: 1.15; acc: 0.61
Batch: 280; loss: 1.02; acc: 0.64
Batch: 300; loss: 0.91; acc: 0.73
Batch: 320; loss: 1.11; acc: 0.66
Batch: 340; loss: 0.91; acc: 0.7
Batch: 360; loss: 1.28; acc: 0.61
Batch: 380; loss: 1.53; acc: 0.53
Batch: 400; loss: 1.12; acc: 0.67
Batch: 420; loss: 0.92; acc: 0.67
Batch: 440; loss: 1.09; acc: 0.64
Batch: 460; loss: 1.21; acc: 0.58
Batch: 480; loss: 0.99; acc: 0.7
Batch: 500; loss: 0.9; acc: 0.77
Batch: 520; loss: 1.01; acc: 0.67
Batch: 540; loss: 0.97; acc: 0.77
Batch: 560; loss: 0.95; acc: 0.69
Batch: 580; loss: 0.81; acc: 0.75
Batch: 600; loss: 1.18; acc: 0.67
Batch: 620; loss: 1.06; acc: 0.58
Batch: 640; loss: 1.15; acc: 0.67
Batch: 660; loss: 1.16; acc: 0.58
Batch: 680; loss: 1.07; acc: 0.61
Batch: 700; loss: 1.14; acc: 0.58
Batch: 720; loss: 1.04; acc: 0.75
Batch: 740; loss: 1.3; acc: 0.61
Batch: 760; loss: 1.02; acc: 0.7
Batch: 780; loss: 1.13; acc: 0.59
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.62
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.62
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.96; acc: 0.67
Val Epoch over. val_loss: 1.0121538202474072; val_accuracy: 0.6758558917197452 

The current subspace-distance is: 7.087965786922723e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.16; acc: 0.62
Batch: 20; loss: 1.14; acc: 0.64
Batch: 40; loss: 0.83; acc: 0.7
Batch: 60; loss: 1.15; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.06; acc: 0.56
Batch: 120; loss: 0.94; acc: 0.69
Batch: 140; loss: 1.27; acc: 0.58
Batch: 160; loss: 0.89; acc: 0.69
Batch: 180; loss: 1.02; acc: 0.7
Batch: 200; loss: 0.96; acc: 0.66
Batch: 220; loss: 1.08; acc: 0.64
Batch: 240; loss: 0.98; acc: 0.67
Batch: 260; loss: 1.06; acc: 0.64
Batch: 280; loss: 0.95; acc: 0.66
Batch: 300; loss: 0.71; acc: 0.8
Batch: 320; loss: 1.03; acc: 0.72
Batch: 340; loss: 1.07; acc: 0.7
Batch: 360; loss: 1.22; acc: 0.59
Batch: 380; loss: 1.2; acc: 0.64
Batch: 400; loss: 1.28; acc: 0.62
Batch: 420; loss: 1.31; acc: 0.58
Batch: 440; loss: 1.13; acc: 0.61
Batch: 460; loss: 1.26; acc: 0.61
Batch: 480; loss: 0.98; acc: 0.67
Batch: 500; loss: 1.12; acc: 0.61
Batch: 520; loss: 0.96; acc: 0.73
Batch: 540; loss: 0.93; acc: 0.78
Batch: 560; loss: 1.04; acc: 0.64
Batch: 580; loss: 1.08; acc: 0.66
Batch: 600; loss: 1.21; acc: 0.64
Batch: 620; loss: 1.02; acc: 0.64
Batch: 640; loss: 0.98; acc: 0.64
Batch: 660; loss: 1.17; acc: 0.62
Batch: 680; loss: 1.03; acc: 0.69
Batch: 700; loss: 1.01; acc: 0.61
Batch: 720; loss: 1.24; acc: 0.58
Batch: 740; loss: 0.84; acc: 0.75
Batch: 760; loss: 1.09; acc: 0.58
Batch: 780; loss: 0.89; acc: 0.7
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.59
Batch: 20; loss: 1.31; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.67
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.93; acc: 0.72
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.98; acc: 0.64
Val Epoch over. val_loss: 1.0110311990330934; val_accuracy: 0.6732683121019108 

The current subspace-distance is: 7.374055712716654e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.23; acc: 0.66
Batch: 20; loss: 1.1; acc: 0.59
Batch: 40; loss: 1.06; acc: 0.67
Batch: 60; loss: 0.69; acc: 0.83
Batch: 80; loss: 1.18; acc: 0.58
Batch: 100; loss: 1.22; acc: 0.66
Batch: 120; loss: 0.88; acc: 0.72
Batch: 140; loss: 1.06; acc: 0.72
Batch: 160; loss: 1.17; acc: 0.72
Batch: 180; loss: 1.12; acc: 0.64
Batch: 200; loss: 1.5; acc: 0.61
Batch: 220; loss: 1.17; acc: 0.64
Batch: 240; loss: 1.03; acc: 0.69
Batch: 260; loss: 0.99; acc: 0.7
Batch: 280; loss: 1.09; acc: 0.67
Batch: 300; loss: 1.06; acc: 0.62
Batch: 320; loss: 1.21; acc: 0.66
Batch: 340; loss: 1.22; acc: 0.69
Batch: 360; loss: 1.19; acc: 0.66
Batch: 380; loss: 1.03; acc: 0.64
Batch: 400; loss: 0.99; acc: 0.62
Batch: 420; loss: 1.3; acc: 0.55
Batch: 440; loss: 0.87; acc: 0.8
Batch: 460; loss: 1.0; acc: 0.73
Batch: 480; loss: 1.13; acc: 0.62
Batch: 500; loss: 0.8; acc: 0.75
Batch: 520; loss: 1.21; acc: 0.56
Batch: 540; loss: 1.09; acc: 0.67
Batch: 560; loss: 1.21; acc: 0.55
Batch: 580; loss: 1.04; acc: 0.67
Batch: 600; loss: 1.13; acc: 0.58
Batch: 620; loss: 1.36; acc: 0.58
Batch: 640; loss: 0.96; acc: 0.69
Batch: 660; loss: 1.41; acc: 0.48
Batch: 680; loss: 0.92; acc: 0.7
Batch: 700; loss: 1.34; acc: 0.59
Batch: 720; loss: 1.5; acc: 0.61
Batch: 740; loss: 1.01; acc: 0.7
Batch: 760; loss: 1.49; acc: 0.5
Batch: 780; loss: 0.95; acc: 0.62
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.58
Batch: 20; loss: 1.29; acc: 0.56
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 1.01; acc: 0.64
Batch: 80; loss: 0.77; acc: 0.73
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.69
Val Epoch over. val_loss: 1.0111761468990592; val_accuracy: 0.6711783439490446 

The current subspace-distance is: 7.557103526778519e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.18; acc: 0.55
Batch: 20; loss: 0.91; acc: 0.72
Batch: 40; loss: 0.87; acc: 0.67
Batch: 60; loss: 0.94; acc: 0.7
Batch: 80; loss: 1.01; acc: 0.66
Batch: 100; loss: 0.96; acc: 0.73
Batch: 120; loss: 0.98; acc: 0.7
Batch: 140; loss: 1.13; acc: 0.66
Batch: 160; loss: 1.2; acc: 0.64
Batch: 180; loss: 1.06; acc: 0.61
Batch: 200; loss: 1.0; acc: 0.67
Batch: 220; loss: 1.29; acc: 0.48
Batch: 240; loss: 1.16; acc: 0.69
Batch: 260; loss: 1.06; acc: 0.66
Batch: 280; loss: 0.87; acc: 0.72
Batch: 300; loss: 1.27; acc: 0.64
Batch: 320; loss: 0.91; acc: 0.67
Batch: 340; loss: 1.07; acc: 0.62
Batch: 360; loss: 1.02; acc: 0.67
Batch: 380; loss: 1.02; acc: 0.69
Batch: 400; loss: 1.13; acc: 0.61
Batch: 420; loss: 1.05; acc: 0.66
Batch: 440; loss: 1.34; acc: 0.66
Batch: 460; loss: 1.1; acc: 0.67
Batch: 480; loss: 1.0; acc: 0.62
Batch: 500; loss: 0.97; acc: 0.7
Batch: 520; loss: 0.96; acc: 0.75
Batch: 540; loss: 1.1; acc: 0.62
Batch: 560; loss: 1.06; acc: 0.7
Batch: 580; loss: 1.11; acc: 0.64
Batch: 600; loss: 0.91; acc: 0.69
Batch: 620; loss: 0.99; acc: 0.72
Batch: 640; loss: 1.27; acc: 0.66
Batch: 660; loss: 0.97; acc: 0.72
Batch: 680; loss: 1.22; acc: 0.56
Batch: 700; loss: 1.09; acc: 0.72
Batch: 720; loss: 0.91; acc: 0.69
Batch: 740; loss: 1.0; acc: 0.62
Batch: 760; loss: 1.09; acc: 0.69
Batch: 780; loss: 1.01; acc: 0.69
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.62
Batch: 20; loss: 1.3; acc: 0.58
Batch: 40; loss: 0.7; acc: 0.8
Batch: 60; loss: 0.98; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.9; acc: 0.72
Batch: 120; loss: 1.18; acc: 0.56
Batch: 140; loss: 1.0; acc: 0.66
Val Epoch over. val_loss: 1.016796139395161; val_accuracy: 0.675656847133758 

The current subspace-distance is: 7.798552542226389e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.01; acc: 0.69
Batch: 20; loss: 1.11; acc: 0.66
Batch: 40; loss: 1.11; acc: 0.64
Batch: 60; loss: 1.14; acc: 0.62
Batch: 80; loss: 1.21; acc: 0.59
Batch: 100; loss: 1.18; acc: 0.62
Batch: 120; loss: 1.02; acc: 0.66
Batch: 140; loss: 0.9; acc: 0.67
Batch: 160; loss: 1.18; acc: 0.62
Batch: 180; loss: 0.96; acc: 0.73
Batch: 200; loss: 1.03; acc: 0.75
Batch: 220; loss: 1.24; acc: 0.61
Batch: 240; loss: 1.13; acc: 0.64
Batch: 260; loss: 1.08; acc: 0.66
Batch: 280; loss: 0.84; acc: 0.66
Batch: 300; loss: 1.33; acc: 0.53
Batch: 320; loss: 0.88; acc: 0.73
Batch: 340; loss: 1.13; acc: 0.66
Batch: 360; loss: 1.27; acc: 0.59
Batch: 380; loss: 1.1; acc: 0.64
Batch: 400; loss: 1.24; acc: 0.59
Batch: 420; loss: 1.13; acc: 0.52
Batch: 440; loss: 1.09; acc: 0.64
Batch: 460; loss: 1.12; acc: 0.61
Batch: 480; loss: 1.1; acc: 0.56
Batch: 500; loss: 1.1; acc: 0.67
Batch: 520; loss: 1.18; acc: 0.56
Batch: 540; loss: 0.84; acc: 0.69
Batch: 560; loss: 1.36; acc: 0.58
Batch: 580; loss: 1.13; acc: 0.61
Batch: 600; loss: 1.03; acc: 0.64
Batch: 620; loss: 1.05; acc: 0.69
Batch: 640; loss: 1.1; acc: 0.59
Batch: 660; loss: 1.16; acc: 0.59
Batch: 680; loss: 0.84; acc: 0.73
Batch: 700; loss: 0.96; acc: 0.73
Batch: 720; loss: 1.18; acc: 0.66
Batch: 740; loss: 1.14; acc: 0.61
Batch: 760; loss: 0.97; acc: 0.69
Batch: 780; loss: 1.11; acc: 0.56
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.31; acc: 0.58
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 1.02; acc: 0.59
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 1.0; acc: 0.66
Val Epoch over. val_loss: 1.014080250718791; val_accuracy: 0.6732683121019108 

The current subspace-distance is: 8.032857294892892e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.06; acc: 0.7
Batch: 20; loss: 1.09; acc: 0.66
Batch: 40; loss: 1.29; acc: 0.61
Batch: 60; loss: 1.0; acc: 0.73
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 1.42; acc: 0.5
Batch: 120; loss: 0.87; acc: 0.66
Batch: 140; loss: 1.05; acc: 0.66
Batch: 160; loss: 0.98; acc: 0.62
Batch: 180; loss: 1.26; acc: 0.59
Batch: 200; loss: 0.98; acc: 0.64
Batch: 220; loss: 0.96; acc: 0.69
Batch: 240; loss: 1.19; acc: 0.62
Batch: 260; loss: 0.99; acc: 0.72
Batch: 280; loss: 0.82; acc: 0.73
Batch: 300; loss: 0.98; acc: 0.62
Batch: 320; loss: 1.04; acc: 0.69
Batch: 340; loss: 0.87; acc: 0.69
Batch: 360; loss: 1.14; acc: 0.62
Batch: 380; loss: 1.06; acc: 0.66
Batch: 400; loss: 1.05; acc: 0.69
Batch: 420; loss: 1.27; acc: 0.59
Batch: 440; loss: 1.15; acc: 0.59
Batch: 460; loss: 1.08; acc: 0.7
Batch: 480; loss: 1.05; acc: 0.67
Batch: 500; loss: 1.09; acc: 0.7
Batch: 520; loss: 1.19; acc: 0.58
Batch: 540; loss: 1.29; acc: 0.59
Batch: 560; loss: 1.28; acc: 0.61
Batch: 580; loss: 0.75; acc: 0.73
Batch: 600; loss: 0.95; acc: 0.69
Batch: 620; loss: 1.0; acc: 0.73
Batch: 640; loss: 1.07; acc: 0.61
Batch: 660; loss: 1.27; acc: 0.62
Batch: 680; loss: 1.06; acc: 0.67
Batch: 700; loss: 0.96; acc: 0.77
Batch: 720; loss: 1.11; acc: 0.58
Batch: 740; loss: 1.12; acc: 0.66
Batch: 760; loss: 1.1; acc: 0.66
Batch: 780; loss: 0.98; acc: 0.64
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.59
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.98; acc: 0.66
Val Epoch over. val_loss: 1.010362471744513; val_accuracy: 0.6735668789808917 

The current subspace-distance is: 8.34664679132402e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.95; acc: 0.7
Batch: 20; loss: 0.91; acc: 0.67
Batch: 40; loss: 1.07; acc: 0.61
Batch: 60; loss: 0.73; acc: 0.75
Batch: 80; loss: 0.98; acc: 0.73
Batch: 100; loss: 1.04; acc: 0.69
Batch: 120; loss: 0.98; acc: 0.67
Batch: 140; loss: 1.1; acc: 0.66
Batch: 160; loss: 1.15; acc: 0.62
Batch: 180; loss: 1.07; acc: 0.62
Batch: 200; loss: 1.14; acc: 0.66
Batch: 220; loss: 0.98; acc: 0.62
Batch: 240; loss: 1.12; acc: 0.59
Batch: 260; loss: 1.05; acc: 0.58
Batch: 280; loss: 1.05; acc: 0.7
Batch: 300; loss: 1.24; acc: 0.62
Batch: 320; loss: 0.96; acc: 0.64
Batch: 340; loss: 0.97; acc: 0.66
Batch: 360; loss: 1.3; acc: 0.66
Batch: 380; loss: 1.17; acc: 0.66
Batch: 400; loss: 1.23; acc: 0.58
Batch: 420; loss: 0.91; acc: 0.72
Batch: 440; loss: 1.27; acc: 0.56
Batch: 460; loss: 1.28; acc: 0.61
Batch: 480; loss: 1.16; acc: 0.55
Batch: 500; loss: 1.13; acc: 0.58
Batch: 520; loss: 1.03; acc: 0.64
Batch: 540; loss: 1.15; acc: 0.62
Batch: 560; loss: 0.97; acc: 0.67
Batch: 580; loss: 1.11; acc: 0.56
Batch: 600; loss: 1.13; acc: 0.61
Batch: 620; loss: 1.16; acc: 0.62
Batch: 640; loss: 1.15; acc: 0.66
Batch: 660; loss: 1.01; acc: 0.72
Batch: 680; loss: 1.05; acc: 0.77
Batch: 700; loss: 1.39; acc: 0.53
Batch: 720; loss: 1.09; acc: 0.67
Batch: 740; loss: 1.25; acc: 0.59
Batch: 760; loss: 1.28; acc: 0.59
Batch: 780; loss: 1.24; acc: 0.53
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.61
Batch: 20; loss: 1.29; acc: 0.58
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 0.98; acc: 0.67
Val Epoch over. val_loss: 1.011155538118569; val_accuracy: 0.6736664012738853 

The current subspace-distance is: 8.647693175589666e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.08; acc: 0.61
Batch: 20; loss: 1.03; acc: 0.72
Batch: 40; loss: 1.08; acc: 0.66
Batch: 60; loss: 0.95; acc: 0.7
Batch: 80; loss: 1.17; acc: 0.61
Batch: 100; loss: 1.11; acc: 0.64
Batch: 120; loss: 1.03; acc: 0.61
Batch: 140; loss: 1.19; acc: 0.58
Batch: 160; loss: 1.16; acc: 0.66
Batch: 180; loss: 1.01; acc: 0.61
Batch: 200; loss: 0.86; acc: 0.7
Batch: 220; loss: 1.24; acc: 0.61
Batch: 240; loss: 0.9; acc: 0.69
Batch: 260; loss: 1.1; acc: 0.58
Batch: 280; loss: 0.97; acc: 0.73
Batch: 300; loss: 0.94; acc: 0.67
Batch: 320; loss: 1.01; acc: 0.62
Batch: 340; loss: 0.88; acc: 0.73
Batch: 360; loss: 1.13; acc: 0.62
Batch: 380; loss: 0.95; acc: 0.7
Batch: 400; loss: 1.01; acc: 0.7
Batch: 420; loss: 1.12; acc: 0.58
Batch: 440; loss: 1.2; acc: 0.61
Batch: 460; loss: 1.13; acc: 0.67
Batch: 480; loss: 1.27; acc: 0.64
Batch: 500; loss: 1.49; acc: 0.52
Batch: 520; loss: 0.99; acc: 0.7
Batch: 540; loss: 0.98; acc: 0.67
Batch: 560; loss: 1.13; acc: 0.61
Batch: 580; loss: 1.08; acc: 0.66
Batch: 600; loss: 1.09; acc: 0.66
Batch: 620; loss: 1.09; acc: 0.66
Batch: 640; loss: 0.97; acc: 0.67
Batch: 660; loss: 1.09; acc: 0.64
Batch: 680; loss: 1.36; acc: 0.64
Batch: 700; loss: 1.07; acc: 0.67
Batch: 720; loss: 0.95; acc: 0.67
Batch: 740; loss: 0.98; acc: 0.69
Batch: 760; loss: 0.95; acc: 0.72
Batch: 780; loss: 0.77; acc: 0.75
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.59
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.93; acc: 0.73
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.96; acc: 0.69
Val Epoch over. val_loss: 1.0088783373498613; val_accuracy: 0.6747611464968153 

The current subspace-distance is: 8.788050035946071e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.34; acc: 0.5
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 1.03; acc: 0.69
Batch: 60; loss: 1.46; acc: 0.53
Batch: 80; loss: 1.26; acc: 0.55
Batch: 100; loss: 0.81; acc: 0.72
Batch: 120; loss: 1.1; acc: 0.66
Batch: 140; loss: 1.09; acc: 0.69
Batch: 160; loss: 1.26; acc: 0.59
Batch: 180; loss: 1.01; acc: 0.69
Batch: 200; loss: 1.07; acc: 0.61
Batch: 220; loss: 1.01; acc: 0.67
Batch: 240; loss: 0.83; acc: 0.7
Batch: 260; loss: 1.1; acc: 0.69
Batch: 280; loss: 1.18; acc: 0.59
Batch: 300; loss: 0.89; acc: 0.73
Batch: 320; loss: 1.01; acc: 0.69
Batch: 340; loss: 1.1; acc: 0.69
Batch: 360; loss: 1.12; acc: 0.64
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.09; acc: 0.59
Batch: 420; loss: 0.99; acc: 0.64
Batch: 440; loss: 1.1; acc: 0.66
Batch: 460; loss: 1.16; acc: 0.64
Batch: 480; loss: 1.13; acc: 0.58
Batch: 500; loss: 0.89; acc: 0.72
Batch: 520; loss: 1.13; acc: 0.62
Batch: 540; loss: 1.01; acc: 0.62
Batch: 560; loss: 1.12; acc: 0.61
Batch: 580; loss: 1.3; acc: 0.62
Batch: 600; loss: 1.29; acc: 0.62
Batch: 620; loss: 1.09; acc: 0.59
Batch: 640; loss: 1.03; acc: 0.66
Batch: 660; loss: 1.1; acc: 0.62
Batch: 680; loss: 1.41; acc: 0.55
Batch: 700; loss: 1.52; acc: 0.53
Batch: 720; loss: 1.12; acc: 0.61
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 1.04; acc: 0.7
Batch: 780; loss: 1.0; acc: 0.69
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.62
Batch: 20; loss: 1.28; acc: 0.58
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 0.99; acc: 0.64
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.72
Batch: 120; loss: 1.16; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.67
Val Epoch over. val_loss: 1.0085615846002178; val_accuracy: 0.6751592356687898 

The current subspace-distance is: 8.806508412817493e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.21; acc: 0.61
Batch: 20; loss: 1.25; acc: 0.61
Batch: 40; loss: 1.13; acc: 0.61
Batch: 60; loss: 0.85; acc: 0.72
Batch: 80; loss: 1.05; acc: 0.64
Batch: 100; loss: 1.35; acc: 0.59
Batch: 120; loss: 1.24; acc: 0.59
Batch: 140; loss: 1.32; acc: 0.55
Batch: 160; loss: 1.05; acc: 0.61
Batch: 180; loss: 0.98; acc: 0.64
Batch: 200; loss: 1.3; acc: 0.55
Batch: 220; loss: 1.19; acc: 0.66
Batch: 240; loss: 1.09; acc: 0.61
Batch: 260; loss: 1.13; acc: 0.61
Batch: 280; loss: 0.87; acc: 0.69
Batch: 300; loss: 1.11; acc: 0.72
Batch: 320; loss: 1.09; acc: 0.59
Batch: 340; loss: 1.09; acc: 0.7
Batch: 360; loss: 0.95; acc: 0.69
Batch: 380; loss: 0.91; acc: 0.66
Batch: 400; loss: 1.04; acc: 0.64
Batch: 420; loss: 1.28; acc: 0.62
Batch: 440; loss: 1.22; acc: 0.58
Batch: 460; loss: 1.04; acc: 0.62
Batch: 480; loss: 1.0; acc: 0.7
Batch: 500; loss: 1.12; acc: 0.62
Batch: 520; loss: 1.27; acc: 0.61
Batch: 540; loss: 1.11; acc: 0.61
Batch: 560; loss: 1.04; acc: 0.66
Batch: 580; loss: 1.31; acc: 0.53
Batch: 600; loss: 1.48; acc: 0.53
Batch: 620; loss: 1.34; acc: 0.61
Batch: 640; loss: 1.12; acc: 0.67
Batch: 660; loss: 1.15; acc: 0.59
Batch: 680; loss: 1.17; acc: 0.64
Batch: 700; loss: 1.02; acc: 0.66
Batch: 720; loss: 1.01; acc: 0.59
Batch: 740; loss: 1.2; acc: 0.62
Batch: 760; loss: 1.14; acc: 0.62
Batch: 780; loss: 1.04; acc: 0.64
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 0.99; acc: 0.64
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.56
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0102881762632139; val_accuracy: 0.6741640127388535 

The current subspace-distance is: 9.305724233854562e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.94; acc: 0.64
Batch: 20; loss: 1.14; acc: 0.66
Batch: 40; loss: 1.31; acc: 0.55
Batch: 60; loss: 0.94; acc: 0.69
Batch: 80; loss: 1.01; acc: 0.64
Batch: 100; loss: 0.96; acc: 0.62
Batch: 120; loss: 1.22; acc: 0.61
Batch: 140; loss: 0.96; acc: 0.64
Batch: 160; loss: 1.11; acc: 0.59
Batch: 180; loss: 0.93; acc: 0.73
Batch: 200; loss: 0.9; acc: 0.66
Batch: 220; loss: 0.91; acc: 0.7
Batch: 240; loss: 1.19; acc: 0.62
Batch: 260; loss: 1.38; acc: 0.56
Batch: 280; loss: 1.05; acc: 0.64
Batch: 300; loss: 0.9; acc: 0.75
Batch: 320; loss: 1.06; acc: 0.62
Batch: 340; loss: 1.1; acc: 0.7
Batch: 360; loss: 1.03; acc: 0.66
Batch: 380; loss: 1.06; acc: 0.67
Batch: 400; loss: 0.98; acc: 0.59
Batch: 420; loss: 0.96; acc: 0.67
Batch: 440; loss: 1.04; acc: 0.72
Batch: 460; loss: 1.33; acc: 0.53
Batch: 480; loss: 0.93; acc: 0.66
Batch: 500; loss: 1.1; acc: 0.61
Batch: 520; loss: 0.86; acc: 0.75
Batch: 540; loss: 1.28; acc: 0.69
Batch: 560; loss: 1.22; acc: 0.62
Batch: 580; loss: 1.22; acc: 0.58
Batch: 600; loss: 1.1; acc: 0.67
Batch: 620; loss: 1.16; acc: 0.59
Batch: 640; loss: 1.05; acc: 0.64
Batch: 660; loss: 1.0; acc: 0.7
Batch: 680; loss: 0.9; acc: 0.72
Batch: 700; loss: 0.98; acc: 0.69
Batch: 720; loss: 1.1; acc: 0.66
Batch: 740; loss: 1.07; acc: 0.61
Batch: 760; loss: 0.78; acc: 0.8
Batch: 780; loss: 1.07; acc: 0.66
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.58
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 0.99; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.66
Val Epoch over. val_loss: 1.008766747584009; val_accuracy: 0.6754578025477707 

The current subspace-distance is: 9.373937064083293e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.15; acc: 0.7
Batch: 20; loss: 1.28; acc: 0.62
Batch: 40; loss: 1.3; acc: 0.56
Batch: 60; loss: 1.31; acc: 0.61
Batch: 80; loss: 1.06; acc: 0.62
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 1.07; acc: 0.66
Batch: 160; loss: 1.2; acc: 0.58
Batch: 180; loss: 1.39; acc: 0.56
Batch: 200; loss: 0.98; acc: 0.64
Batch: 220; loss: 0.93; acc: 0.75
Batch: 240; loss: 1.25; acc: 0.59
Batch: 260; loss: 1.16; acc: 0.64
Batch: 280; loss: 0.95; acc: 0.69
Batch: 300; loss: 1.05; acc: 0.69
Batch: 320; loss: 1.28; acc: 0.55
Batch: 340; loss: 0.93; acc: 0.66
Batch: 360; loss: 0.92; acc: 0.75
Batch: 380; loss: 0.97; acc: 0.66
Batch: 400; loss: 1.09; acc: 0.59
Batch: 420; loss: 0.99; acc: 0.73
Batch: 440; loss: 1.09; acc: 0.67
Batch: 460; loss: 0.89; acc: 0.7
Batch: 480; loss: 0.86; acc: 0.77
Batch: 500; loss: 1.05; acc: 0.69
Batch: 520; loss: 1.18; acc: 0.59
Batch: 540; loss: 1.04; acc: 0.7
Batch: 560; loss: 1.0; acc: 0.72
Batch: 580; loss: 1.35; acc: 0.59
Batch: 600; loss: 1.13; acc: 0.69
Batch: 620; loss: 0.89; acc: 0.67
Batch: 640; loss: 1.35; acc: 0.53
Batch: 660; loss: 1.18; acc: 0.59
Batch: 680; loss: 1.09; acc: 0.64
Batch: 700; loss: 1.02; acc: 0.66
Batch: 720; loss: 1.15; acc: 0.59
Batch: 740; loss: 0.98; acc: 0.64
Batch: 760; loss: 1.19; acc: 0.73
Batch: 780; loss: 1.13; acc: 0.67
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.1; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.98; acc: 0.66
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.58
Batch: 140; loss: 0.98; acc: 0.66
Val Epoch over. val_loss: 1.0123007255754652; val_accuracy: 0.6749601910828026 

The current subspace-distance is: 9.400689305039123e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.99; acc: 0.69
Batch: 20; loss: 1.16; acc: 0.66
Batch: 40; loss: 1.13; acc: 0.66
Batch: 60; loss: 1.36; acc: 0.62
Batch: 80; loss: 0.94; acc: 0.72
Batch: 100; loss: 0.95; acc: 0.73
Batch: 120; loss: 1.05; acc: 0.7
Batch: 140; loss: 1.09; acc: 0.67
Batch: 160; loss: 1.03; acc: 0.67
Batch: 180; loss: 0.97; acc: 0.67
Batch: 200; loss: 0.74; acc: 0.75
Batch: 220; loss: 1.1; acc: 0.67
Batch: 240; loss: 0.89; acc: 0.77
Batch: 260; loss: 1.0; acc: 0.69
Batch: 280; loss: 0.91; acc: 0.77
Batch: 300; loss: 1.05; acc: 0.69
Batch: 320; loss: 0.81; acc: 0.7
Batch: 340; loss: 1.28; acc: 0.59
Batch: 360; loss: 1.07; acc: 0.66
Batch: 380; loss: 0.91; acc: 0.69
Batch: 400; loss: 0.97; acc: 0.59
Batch: 420; loss: 1.24; acc: 0.67
Batch: 440; loss: 1.2; acc: 0.67
Batch: 460; loss: 0.95; acc: 0.73
Batch: 480; loss: 1.24; acc: 0.62
Batch: 500; loss: 1.18; acc: 0.56
Batch: 520; loss: 0.98; acc: 0.72
Batch: 540; loss: 0.96; acc: 0.66
Batch: 560; loss: 0.82; acc: 0.77
Batch: 580; loss: 0.91; acc: 0.73
Batch: 600; loss: 1.13; acc: 0.64
Batch: 620; loss: 1.24; acc: 0.67
Batch: 640; loss: 0.79; acc: 0.77
Batch: 660; loss: 1.11; acc: 0.67
Batch: 680; loss: 1.18; acc: 0.66
Batch: 700; loss: 1.15; acc: 0.58
Batch: 720; loss: 0.81; acc: 0.78
Batch: 740; loss: 1.11; acc: 0.56
Batch: 760; loss: 1.26; acc: 0.53
Batch: 780; loss: 1.02; acc: 0.72
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.29; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.58
Batch: 140; loss: 0.98; acc: 0.66
Val Epoch over. val_loss: 1.0113956381560891; val_accuracy: 0.674562101910828 

The current subspace-distance is: 9.67642044997774e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.0; acc: 0.61
Batch: 20; loss: 1.49; acc: 0.55
Batch: 40; loss: 1.15; acc: 0.62
Batch: 60; loss: 1.17; acc: 0.64
Batch: 80; loss: 1.21; acc: 0.61
Batch: 100; loss: 1.01; acc: 0.62
Batch: 120; loss: 1.07; acc: 0.67
Batch: 140; loss: 1.23; acc: 0.61
Batch: 160; loss: 1.3; acc: 0.53
Batch: 180; loss: 0.95; acc: 0.73
Batch: 200; loss: 1.11; acc: 0.67
Batch: 220; loss: 1.1; acc: 0.64
Batch: 240; loss: 0.9; acc: 0.62
Batch: 260; loss: 1.01; acc: 0.67
Batch: 280; loss: 1.02; acc: 0.7
Batch: 300; loss: 1.26; acc: 0.58
Batch: 320; loss: 1.18; acc: 0.62
Batch: 340; loss: 1.09; acc: 0.69
Batch: 360; loss: 0.93; acc: 0.72
Batch: 380; loss: 1.17; acc: 0.58
Batch: 400; loss: 0.88; acc: 0.72
Batch: 420; loss: 1.25; acc: 0.56
Batch: 440; loss: 1.13; acc: 0.66
Batch: 460; loss: 1.04; acc: 0.61
Batch: 480; loss: 1.19; acc: 0.61
Batch: 500; loss: 1.24; acc: 0.56
Batch: 520; loss: 0.96; acc: 0.78
Batch: 540; loss: 1.0; acc: 0.67
Batch: 560; loss: 1.36; acc: 0.64
Batch: 580; loss: 1.02; acc: 0.64
Batch: 600; loss: 0.97; acc: 0.64
Batch: 620; loss: 0.99; acc: 0.67
Batch: 640; loss: 1.3; acc: 0.61
Batch: 660; loss: 1.04; acc: 0.58
Batch: 680; loss: 1.11; acc: 0.67
Batch: 700; loss: 0.88; acc: 0.72
Batch: 720; loss: 1.09; acc: 0.61
Batch: 740; loss: 1.05; acc: 0.64
Batch: 760; loss: 1.12; acc: 0.61
Batch: 780; loss: 1.07; acc: 0.66
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.62
Batch: 20; loss: 1.29; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0109096131506998; val_accuracy: 0.6721735668789809 

The current subspace-distance is: 9.616936586098745e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.05; acc: 0.61
Batch: 20; loss: 1.18; acc: 0.69
Batch: 40; loss: 1.26; acc: 0.52
Batch: 60; loss: 1.15; acc: 0.55
Batch: 80; loss: 1.19; acc: 0.62
Batch: 100; loss: 0.86; acc: 0.72
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 1.11; acc: 0.64
Batch: 160; loss: 1.14; acc: 0.67
Batch: 180; loss: 1.3; acc: 0.59
Batch: 200; loss: 1.04; acc: 0.73
Batch: 220; loss: 1.15; acc: 0.62
Batch: 240; loss: 1.25; acc: 0.55
Batch: 260; loss: 1.1; acc: 0.62
Batch: 280; loss: 1.43; acc: 0.61
Batch: 300; loss: 1.17; acc: 0.59
Batch: 320; loss: 1.04; acc: 0.7
Batch: 340; loss: 1.1; acc: 0.67
Batch: 360; loss: 1.15; acc: 0.62
Batch: 380; loss: 0.99; acc: 0.62
Batch: 400; loss: 1.0; acc: 0.75
Batch: 420; loss: 1.01; acc: 0.69
Batch: 440; loss: 0.9; acc: 0.69
Batch: 460; loss: 0.93; acc: 0.72
Batch: 480; loss: 0.72; acc: 0.8
Batch: 500; loss: 1.0; acc: 0.75
Batch: 520; loss: 1.14; acc: 0.67
Batch: 540; loss: 1.08; acc: 0.72
Batch: 560; loss: 1.1; acc: 0.67
Batch: 580; loss: 1.13; acc: 0.69
Batch: 600; loss: 1.05; acc: 0.61
Batch: 620; loss: 1.32; acc: 0.59
Batch: 640; loss: 1.03; acc: 0.62
Batch: 660; loss: 1.14; acc: 0.58
Batch: 680; loss: 1.04; acc: 0.67
Batch: 700; loss: 0.95; acc: 0.7
Batch: 720; loss: 1.05; acc: 0.72
Batch: 740; loss: 1.24; acc: 0.62
Batch: 760; loss: 1.01; acc: 0.69
Batch: 780; loss: 1.04; acc: 0.66
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.59
Batch: 20; loss: 1.29; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.99; acc: 0.64
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 0.99; acc: 0.67
Val Epoch over. val_loss: 1.0116517976590782; val_accuracy: 0.6712778662420382 

The current subspace-distance is: 9.583110659150407e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.19; acc: 0.62
Batch: 20; loss: 0.88; acc: 0.75
Batch: 40; loss: 1.48; acc: 0.61
Batch: 60; loss: 1.15; acc: 0.69
Batch: 80; loss: 0.88; acc: 0.73
Batch: 100; loss: 1.07; acc: 0.64
Batch: 120; loss: 0.9; acc: 0.75
Batch: 140; loss: 1.3; acc: 0.59
Batch: 160; loss: 1.16; acc: 0.64
Batch: 180; loss: 1.24; acc: 0.61
Batch: 200; loss: 1.12; acc: 0.62
Batch: 220; loss: 1.15; acc: 0.59
Batch: 240; loss: 0.99; acc: 0.69
Batch: 260; loss: 0.98; acc: 0.59
Batch: 280; loss: 1.04; acc: 0.66
Batch: 300; loss: 0.86; acc: 0.66
Batch: 320; loss: 1.05; acc: 0.72
Batch: 340; loss: 0.94; acc: 0.72
Batch: 360; loss: 0.96; acc: 0.64
Batch: 380; loss: 1.26; acc: 0.64
Batch: 400; loss: 1.09; acc: 0.69
Batch: 420; loss: 1.12; acc: 0.66
Batch: 440; loss: 0.85; acc: 0.73
Batch: 460; loss: 0.97; acc: 0.73
Batch: 480; loss: 1.2; acc: 0.59
Batch: 500; loss: 1.12; acc: 0.69
Batch: 520; loss: 1.13; acc: 0.67
Batch: 540; loss: 1.04; acc: 0.7
Batch: 560; loss: 0.72; acc: 0.78
Batch: 580; loss: 0.93; acc: 0.73
Batch: 600; loss: 0.99; acc: 0.72
Batch: 620; loss: 1.03; acc: 0.59
Batch: 640; loss: 1.07; acc: 0.72
Batch: 660; loss: 1.27; acc: 0.64
Batch: 680; loss: 1.3; acc: 0.61
Batch: 700; loss: 1.13; acc: 0.67
Batch: 720; loss: 1.14; acc: 0.59
Batch: 740; loss: 1.09; acc: 0.64
Batch: 760; loss: 1.19; acc: 0.59
Batch: 780; loss: 0.84; acc: 0.69
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0093879187183015; val_accuracy: 0.67296974522293 

The current subspace-distance is: 9.440745634492487e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.32; acc: 0.61
Batch: 20; loss: 1.06; acc: 0.61
Batch: 40; loss: 1.19; acc: 0.61
Batch: 60; loss: 1.38; acc: 0.58
Batch: 80; loss: 0.99; acc: 0.7
Batch: 100; loss: 1.14; acc: 0.64
Batch: 120; loss: 1.43; acc: 0.55
Batch: 140; loss: 1.04; acc: 0.64
Batch: 160; loss: 0.87; acc: 0.67
Batch: 180; loss: 0.93; acc: 0.67
Batch: 200; loss: 0.89; acc: 0.69
Batch: 220; loss: 1.06; acc: 0.64
Batch: 240; loss: 1.16; acc: 0.72
Batch: 260; loss: 1.18; acc: 0.66
Batch: 280; loss: 0.94; acc: 0.7
Batch: 300; loss: 1.03; acc: 0.67
Batch: 320; loss: 1.21; acc: 0.73
Batch: 340; loss: 1.25; acc: 0.52
Batch: 360; loss: 1.13; acc: 0.72
Batch: 380; loss: 0.8; acc: 0.77
Batch: 400; loss: 0.8; acc: 0.7
Batch: 420; loss: 0.99; acc: 0.69
Batch: 440; loss: 1.28; acc: 0.64
Batch: 460; loss: 1.16; acc: 0.62
Batch: 480; loss: 1.09; acc: 0.64
Batch: 500; loss: 1.25; acc: 0.59
Batch: 520; loss: 1.04; acc: 0.73
Batch: 540; loss: 1.0; acc: 0.62
Batch: 560; loss: 0.91; acc: 0.69
Batch: 580; loss: 0.89; acc: 0.75
Batch: 600; loss: 0.96; acc: 0.7
Batch: 620; loss: 1.24; acc: 0.62
Batch: 640; loss: 1.26; acc: 0.62
Batch: 660; loss: 1.06; acc: 0.67
Batch: 680; loss: 0.84; acc: 0.73
Batch: 700; loss: 0.97; acc: 0.67
Batch: 720; loss: 0.96; acc: 0.75
Batch: 740; loss: 1.19; acc: 0.59
Batch: 760; loss: 0.92; acc: 0.69
Batch: 780; loss: 0.85; acc: 0.73
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.59
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.96; acc: 0.66
Val Epoch over. val_loss: 1.0090304776361794; val_accuracy: 0.6753582802547771 

The current subspace-distance is: 9.621505159884691e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.19; acc: 0.67
Batch: 20; loss: 1.1; acc: 0.67
Batch: 40; loss: 1.06; acc: 0.56
Batch: 60; loss: 1.35; acc: 0.58
Batch: 80; loss: 1.09; acc: 0.62
Batch: 100; loss: 1.16; acc: 0.67
Batch: 120; loss: 1.19; acc: 0.62
Batch: 140; loss: 1.24; acc: 0.61
Batch: 160; loss: 1.05; acc: 0.62
Batch: 180; loss: 0.97; acc: 0.69
Batch: 200; loss: 0.92; acc: 0.77
Batch: 220; loss: 1.37; acc: 0.66
Batch: 240; loss: 1.07; acc: 0.64
Batch: 260; loss: 0.95; acc: 0.75
Batch: 280; loss: 0.99; acc: 0.75
Batch: 300; loss: 1.13; acc: 0.64
Batch: 320; loss: 1.19; acc: 0.66
Batch: 340; loss: 1.22; acc: 0.67
Batch: 360; loss: 0.91; acc: 0.75
Batch: 380; loss: 1.04; acc: 0.73
Batch: 400; loss: 1.27; acc: 0.61
Batch: 420; loss: 0.98; acc: 0.72
Batch: 440; loss: 1.09; acc: 0.59
Batch: 460; loss: 1.18; acc: 0.62
Batch: 480; loss: 1.0; acc: 0.7
Batch: 500; loss: 1.16; acc: 0.66
Batch: 520; loss: 1.07; acc: 0.58
Batch: 540; loss: 1.06; acc: 0.61
Batch: 560; loss: 1.02; acc: 0.66
Batch: 580; loss: 1.24; acc: 0.61
Batch: 600; loss: 1.17; acc: 0.61
Batch: 620; loss: 1.02; acc: 0.73
Batch: 640; loss: 0.97; acc: 0.77
Batch: 660; loss: 1.18; acc: 0.66
Batch: 680; loss: 0.88; acc: 0.73
Batch: 700; loss: 0.92; acc: 0.67
Batch: 720; loss: 0.71; acc: 0.77
Batch: 740; loss: 1.18; acc: 0.64
Batch: 760; loss: 1.37; acc: 0.52
Batch: 780; loss: 1.29; acc: 0.61
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.96; acc: 0.66
Val Epoch over. val_loss: 1.0085503413419055; val_accuracy: 0.6747611464968153 

The current subspace-distance is: 9.864520689006895e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.27; acc: 0.58
Batch: 20; loss: 1.32; acc: 0.61
Batch: 40; loss: 1.25; acc: 0.66
Batch: 60; loss: 1.18; acc: 0.64
Batch: 80; loss: 1.08; acc: 0.67
Batch: 100; loss: 1.4; acc: 0.67
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 1.2; acc: 0.61
Batch: 160; loss: 1.02; acc: 0.62
Batch: 180; loss: 1.18; acc: 0.66
Batch: 200; loss: 1.24; acc: 0.62
Batch: 220; loss: 1.08; acc: 0.64
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.96; acc: 0.7
Batch: 280; loss: 1.3; acc: 0.59
Batch: 300; loss: 1.16; acc: 0.64
Batch: 320; loss: 1.21; acc: 0.61
Batch: 340; loss: 1.34; acc: 0.61
Batch: 360; loss: 1.04; acc: 0.67
Batch: 380; loss: 1.15; acc: 0.61
Batch: 400; loss: 1.48; acc: 0.61
Batch: 420; loss: 1.17; acc: 0.59
Batch: 440; loss: 0.9; acc: 0.67
Batch: 460; loss: 1.06; acc: 0.64
Batch: 480; loss: 0.96; acc: 0.7
Batch: 500; loss: 1.1; acc: 0.64
Batch: 520; loss: 1.04; acc: 0.66
Batch: 540; loss: 1.0; acc: 0.64
Batch: 560; loss: 1.05; acc: 0.67
Batch: 580; loss: 1.05; acc: 0.67
Batch: 600; loss: 1.33; acc: 0.64
Batch: 620; loss: 1.38; acc: 0.55
Batch: 640; loss: 1.07; acc: 0.73
Batch: 660; loss: 0.99; acc: 0.72
Batch: 680; loss: 0.85; acc: 0.67
Batch: 700; loss: 1.32; acc: 0.5
Batch: 720; loss: 0.91; acc: 0.69
Batch: 740; loss: 1.21; acc: 0.59
Batch: 760; loss: 0.97; acc: 0.69
Batch: 780; loss: 1.21; acc: 0.61
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.61
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0094302285249066; val_accuracy: 0.6747611464968153 

The current subspace-distance is: 0.00010191622277488932 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.01; acc: 0.69
Batch: 20; loss: 1.05; acc: 0.58
Batch: 40; loss: 1.35; acc: 0.56
Batch: 60; loss: 1.28; acc: 0.52
Batch: 80; loss: 1.09; acc: 0.64
Batch: 100; loss: 1.06; acc: 0.64
Batch: 120; loss: 1.17; acc: 0.66
Batch: 140; loss: 1.19; acc: 0.61
Batch: 160; loss: 1.04; acc: 0.64
Batch: 180; loss: 1.21; acc: 0.66
Batch: 200; loss: 1.12; acc: 0.64
Batch: 220; loss: 1.07; acc: 0.66
Batch: 240; loss: 1.09; acc: 0.66
Batch: 260; loss: 1.26; acc: 0.69
Batch: 280; loss: 0.9; acc: 0.66
Batch: 300; loss: 1.16; acc: 0.7
Batch: 320; loss: 0.86; acc: 0.72
Batch: 340; loss: 0.97; acc: 0.75
Batch: 360; loss: 0.96; acc: 0.7
Batch: 380; loss: 1.04; acc: 0.67
Batch: 400; loss: 0.95; acc: 0.69
Batch: 420; loss: 0.85; acc: 0.77
Batch: 440; loss: 0.82; acc: 0.73
Batch: 460; loss: 0.95; acc: 0.69
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.99; acc: 0.69
Batch: 520; loss: 0.96; acc: 0.77
Batch: 540; loss: 1.21; acc: 0.64
Batch: 560; loss: 0.97; acc: 0.7
Batch: 580; loss: 1.17; acc: 0.56
Batch: 600; loss: 1.15; acc: 0.53
Batch: 620; loss: 1.38; acc: 0.52
Batch: 640; loss: 1.03; acc: 0.67
Batch: 660; loss: 1.37; acc: 0.58
Batch: 680; loss: 1.23; acc: 0.69
Batch: 700; loss: 1.01; acc: 0.64
Batch: 720; loss: 0.97; acc: 0.67
Batch: 740; loss: 0.95; acc: 0.7
Batch: 760; loss: 0.91; acc: 0.67
Batch: 780; loss: 1.06; acc: 0.67
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.29; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.61
Batch: 140; loss: 0.98; acc: 0.66
Val Epoch over. val_loss: 1.0095609255657074; val_accuracy: 0.673765923566879 

The current subspace-distance is: 0.00010456104064360261 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.13; acc: 0.69
Batch: 20; loss: 1.2; acc: 0.56
Batch: 40; loss: 1.39; acc: 0.53
Batch: 60; loss: 1.14; acc: 0.64
Batch: 80; loss: 0.97; acc: 0.66
Batch: 100; loss: 1.21; acc: 0.59
Batch: 120; loss: 1.01; acc: 0.67
Batch: 140; loss: 1.03; acc: 0.7
Batch: 160; loss: 1.03; acc: 0.7
Batch: 180; loss: 1.02; acc: 0.64
Batch: 200; loss: 1.12; acc: 0.56
Batch: 220; loss: 1.16; acc: 0.58
Batch: 240; loss: 1.12; acc: 0.64
Batch: 260; loss: 1.14; acc: 0.66
Batch: 280; loss: 1.3; acc: 0.56
Batch: 300; loss: 0.99; acc: 0.7
Batch: 320; loss: 1.04; acc: 0.72
Batch: 340; loss: 1.12; acc: 0.62
Batch: 360; loss: 1.07; acc: 0.64
Batch: 380; loss: 0.89; acc: 0.75
Batch: 400; loss: 1.3; acc: 0.59
Batch: 420; loss: 1.37; acc: 0.58
Batch: 440; loss: 1.4; acc: 0.59
Batch: 460; loss: 1.05; acc: 0.64
Batch: 480; loss: 1.24; acc: 0.64
Batch: 500; loss: 0.95; acc: 0.69
Batch: 520; loss: 0.86; acc: 0.7
Batch: 540; loss: 0.74; acc: 0.8
Batch: 560; loss: 0.97; acc: 0.75
Batch: 580; loss: 0.94; acc: 0.62
Batch: 600; loss: 1.0; acc: 0.64
Batch: 620; loss: 0.97; acc: 0.66
Batch: 640; loss: 1.05; acc: 0.67
Batch: 660; loss: 0.96; acc: 0.72
Batch: 680; loss: 0.9; acc: 0.75
Batch: 700; loss: 1.23; acc: 0.61
Batch: 720; loss: 1.16; acc: 0.69
Batch: 740; loss: 0.91; acc: 0.77
Batch: 760; loss: 1.09; acc: 0.64
Batch: 780; loss: 0.93; acc: 0.7
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.62
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0102953861473472; val_accuracy: 0.6749601910828026 

The current subspace-distance is: 0.00010953331366181374 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.93; acc: 0.69
Batch: 20; loss: 1.18; acc: 0.64
Batch: 40; loss: 1.05; acc: 0.62
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.87; acc: 0.78
Batch: 100; loss: 1.14; acc: 0.64
Batch: 120; loss: 1.17; acc: 0.67
Batch: 140; loss: 1.0; acc: 0.7
Batch: 160; loss: 1.06; acc: 0.59
Batch: 180; loss: 1.06; acc: 0.61
Batch: 200; loss: 1.29; acc: 0.64
Batch: 220; loss: 1.13; acc: 0.58
Batch: 240; loss: 1.14; acc: 0.59
Batch: 260; loss: 0.86; acc: 0.69
Batch: 280; loss: 1.1; acc: 0.66
Batch: 300; loss: 1.0; acc: 0.75
Batch: 320; loss: 1.1; acc: 0.7
Batch: 340; loss: 0.91; acc: 0.72
Batch: 360; loss: 0.99; acc: 0.73
Batch: 380; loss: 1.34; acc: 0.52
Batch: 400; loss: 1.03; acc: 0.67
Batch: 420; loss: 1.17; acc: 0.62
Batch: 440; loss: 1.06; acc: 0.67
Batch: 460; loss: 1.01; acc: 0.67
Batch: 480; loss: 1.07; acc: 0.7
Batch: 500; loss: 0.96; acc: 0.67
Batch: 520; loss: 1.06; acc: 0.64
Batch: 540; loss: 1.13; acc: 0.62
Batch: 560; loss: 1.17; acc: 0.52
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 1.01; acc: 0.69
Batch: 620; loss: 1.21; acc: 0.64
Batch: 640; loss: 0.96; acc: 0.66
Batch: 660; loss: 0.95; acc: 0.7
Batch: 680; loss: 1.14; acc: 0.69
Batch: 700; loss: 1.11; acc: 0.64
Batch: 720; loss: 1.14; acc: 0.64
Batch: 740; loss: 0.94; acc: 0.61
Batch: 760; loss: 1.07; acc: 0.66
Batch: 780; loss: 1.1; acc: 0.78
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.29; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.98; acc: 0.66
Val Epoch over. val_loss: 1.009957466915155; val_accuracy: 0.6746616242038217 

The current subspace-distance is: 0.00010828582890098915 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.27; acc: 0.59
Batch: 20; loss: 1.19; acc: 0.55
Batch: 40; loss: 0.9; acc: 0.77
Batch: 60; loss: 1.33; acc: 0.58
Batch: 80; loss: 1.18; acc: 0.58
Batch: 100; loss: 1.29; acc: 0.64
Batch: 120; loss: 1.06; acc: 0.69
Batch: 140; loss: 1.16; acc: 0.62
Batch: 160; loss: 1.02; acc: 0.73
Batch: 180; loss: 1.34; acc: 0.61
Batch: 200; loss: 0.97; acc: 0.61
Batch: 220; loss: 1.36; acc: 0.55
Batch: 240; loss: 1.3; acc: 0.61
Batch: 260; loss: 1.02; acc: 0.69
Batch: 280; loss: 0.96; acc: 0.7
Batch: 300; loss: 1.05; acc: 0.67
Batch: 320; loss: 0.89; acc: 0.75
Batch: 340; loss: 1.16; acc: 0.69
Batch: 360; loss: 1.0; acc: 0.67
Batch: 380; loss: 1.19; acc: 0.58
Batch: 400; loss: 1.02; acc: 0.7
Batch: 420; loss: 1.23; acc: 0.66
Batch: 440; loss: 0.83; acc: 0.72
Batch: 460; loss: 0.86; acc: 0.75
Batch: 480; loss: 1.09; acc: 0.69
Batch: 500; loss: 1.02; acc: 0.64
Batch: 520; loss: 1.21; acc: 0.58
Batch: 540; loss: 0.92; acc: 0.7
Batch: 560; loss: 1.13; acc: 0.73
Batch: 580; loss: 1.22; acc: 0.62
Batch: 600; loss: 0.87; acc: 0.75
Batch: 620; loss: 0.93; acc: 0.73
Batch: 640; loss: 0.87; acc: 0.66
Batch: 660; loss: 1.02; acc: 0.61
Batch: 680; loss: 1.05; acc: 0.67
Batch: 700; loss: 1.04; acc: 0.58
Batch: 720; loss: 1.1; acc: 0.64
Batch: 740; loss: 0.88; acc: 0.67
Batch: 760; loss: 1.13; acc: 0.58
Batch: 780; loss: 1.32; acc: 0.66
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 1.0; acc: 0.62
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0093365247082557; val_accuracy: 0.6742635350318471 

The current subspace-distance is: 0.00011053671914851293 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.12; acc: 0.62
Batch: 20; loss: 0.95; acc: 0.69
Batch: 40; loss: 1.17; acc: 0.64
Batch: 60; loss: 0.83; acc: 0.73
Batch: 80; loss: 0.97; acc: 0.66
Batch: 100; loss: 1.04; acc: 0.66
Batch: 120; loss: 1.24; acc: 0.61
Batch: 140; loss: 1.14; acc: 0.62
Batch: 160; loss: 1.27; acc: 0.62
Batch: 180; loss: 1.1; acc: 0.62
Batch: 200; loss: 1.05; acc: 0.72
Batch: 220; loss: 1.1; acc: 0.75
Batch: 240; loss: 1.21; acc: 0.55
Batch: 260; loss: 1.01; acc: 0.72
Batch: 280; loss: 1.02; acc: 0.59
Batch: 300; loss: 1.08; acc: 0.66
Batch: 320; loss: 1.13; acc: 0.67
Batch: 340; loss: 1.42; acc: 0.55
Batch: 360; loss: 1.06; acc: 0.67
Batch: 380; loss: 1.33; acc: 0.62
Batch: 400; loss: 0.94; acc: 0.7
Batch: 420; loss: 1.32; acc: 0.67
Batch: 440; loss: 0.82; acc: 0.7
Batch: 460; loss: 0.88; acc: 0.66
Batch: 480; loss: 1.0; acc: 0.67
Batch: 500; loss: 1.26; acc: 0.62
Batch: 520; loss: 0.96; acc: 0.73
Batch: 540; loss: 1.21; acc: 0.59
Batch: 560; loss: 1.07; acc: 0.7
Batch: 580; loss: 1.2; acc: 0.62
Batch: 600; loss: 0.89; acc: 0.69
Batch: 620; loss: 1.07; acc: 0.7
Batch: 640; loss: 0.97; acc: 0.7
Batch: 660; loss: 1.01; acc: 0.72
Batch: 680; loss: 1.02; acc: 0.67
Batch: 700; loss: 1.15; acc: 0.64
Batch: 720; loss: 1.25; acc: 0.53
Batch: 740; loss: 1.15; acc: 0.59
Batch: 760; loss: 0.93; acc: 0.67
Batch: 780; loss: 0.93; acc: 0.72
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.61
Batch: 140; loss: 0.97; acc: 0.67
Val Epoch over. val_loss: 1.009452087863995; val_accuracy: 0.6738654458598726 

The current subspace-distance is: 0.00010981175000779331 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.15; acc: 0.64
Batch: 20; loss: 0.94; acc: 0.69
Batch: 40; loss: 0.96; acc: 0.64
Batch: 60; loss: 0.89; acc: 0.72
Batch: 80; loss: 0.87; acc: 0.72
Batch: 100; loss: 0.82; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.61
Batch: 140; loss: 0.96; acc: 0.69
Batch: 160; loss: 0.98; acc: 0.73
Batch: 180; loss: 1.05; acc: 0.67
Batch: 200; loss: 1.12; acc: 0.61
Batch: 220; loss: 1.01; acc: 0.72
Batch: 240; loss: 0.91; acc: 0.72
Batch: 260; loss: 0.82; acc: 0.73
Batch: 280; loss: 1.0; acc: 0.62
Batch: 300; loss: 1.16; acc: 0.64
Batch: 320; loss: 1.08; acc: 0.61
Batch: 340; loss: 1.18; acc: 0.66
Batch: 360; loss: 0.89; acc: 0.67
Batch: 380; loss: 1.18; acc: 0.64
Batch: 400; loss: 1.07; acc: 0.61
Batch: 420; loss: 0.99; acc: 0.66
Batch: 440; loss: 0.83; acc: 0.69
Batch: 460; loss: 1.13; acc: 0.7
Batch: 480; loss: 0.74; acc: 0.8
Batch: 500; loss: 1.43; acc: 0.56
Batch: 520; loss: 1.07; acc: 0.66
Batch: 540; loss: 1.18; acc: 0.58
Batch: 560; loss: 0.85; acc: 0.73
Batch: 580; loss: 1.08; acc: 0.72
Batch: 600; loss: 1.05; acc: 0.7
Batch: 620; loss: 0.89; acc: 0.69
Batch: 640; loss: 0.97; acc: 0.78
Batch: 660; loss: 1.32; acc: 0.59
Batch: 680; loss: 0.84; acc: 0.75
Batch: 700; loss: 1.06; acc: 0.69
Batch: 720; loss: 0.89; acc: 0.67
Batch: 740; loss: 1.13; acc: 0.62
Batch: 760; loss: 0.97; acc: 0.69
Batch: 780; loss: 1.32; acc: 0.52
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.010033900950365; val_accuracy: 0.6742635350318471 

The current subspace-distance is: 0.00011075003567384556 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.18; acc: 0.59
Batch: 20; loss: 1.09; acc: 0.64
Batch: 40; loss: 0.94; acc: 0.59
Batch: 60; loss: 1.1; acc: 0.58
Batch: 80; loss: 0.83; acc: 0.75
Batch: 100; loss: 1.11; acc: 0.64
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 1.14; acc: 0.62
Batch: 160; loss: 0.97; acc: 0.69
Batch: 180; loss: 0.79; acc: 0.77
Batch: 200; loss: 0.87; acc: 0.62
Batch: 220; loss: 1.18; acc: 0.66
Batch: 240; loss: 0.98; acc: 0.64
Batch: 260; loss: 1.1; acc: 0.62
Batch: 280; loss: 1.35; acc: 0.59
Batch: 300; loss: 1.16; acc: 0.61
Batch: 320; loss: 1.02; acc: 0.67
Batch: 340; loss: 0.85; acc: 0.67
Batch: 360; loss: 0.91; acc: 0.7
Batch: 380; loss: 1.15; acc: 0.59
Batch: 400; loss: 0.95; acc: 0.7
Batch: 420; loss: 0.94; acc: 0.72
Batch: 440; loss: 1.05; acc: 0.66
Batch: 460; loss: 1.16; acc: 0.61
Batch: 480; loss: 1.08; acc: 0.69
Batch: 500; loss: 1.21; acc: 0.55
Batch: 520; loss: 1.28; acc: 0.64
Batch: 540; loss: 1.18; acc: 0.62
Batch: 560; loss: 0.88; acc: 0.64
Batch: 580; loss: 1.21; acc: 0.56
Batch: 600; loss: 0.81; acc: 0.75
Batch: 620; loss: 1.03; acc: 0.67
Batch: 640; loss: 1.03; acc: 0.64
Batch: 660; loss: 1.01; acc: 0.7
Batch: 680; loss: 1.3; acc: 0.66
Batch: 700; loss: 1.02; acc: 0.69
Batch: 720; loss: 1.17; acc: 0.58
Batch: 740; loss: 0.69; acc: 0.75
Batch: 760; loss: 1.09; acc: 0.66
Batch: 780; loss: 0.97; acc: 0.67
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0093759848813342; val_accuracy: 0.6741640127388535 

The current subspace-distance is: 0.00011446966527728364 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.9; acc: 0.69
Batch: 20; loss: 1.15; acc: 0.64
Batch: 40; loss: 0.89; acc: 0.72
Batch: 60; loss: 1.06; acc: 0.59
Batch: 80; loss: 1.32; acc: 0.52
Batch: 100; loss: 1.34; acc: 0.53
Batch: 120; loss: 1.06; acc: 0.58
Batch: 140; loss: 0.98; acc: 0.66
Batch: 160; loss: 1.07; acc: 0.62
Batch: 180; loss: 1.23; acc: 0.61
Batch: 200; loss: 1.13; acc: 0.67
Batch: 220; loss: 0.99; acc: 0.66
Batch: 240; loss: 0.9; acc: 0.69
Batch: 260; loss: 0.91; acc: 0.66
Batch: 280; loss: 0.95; acc: 0.75
Batch: 300; loss: 0.95; acc: 0.69
Batch: 320; loss: 1.32; acc: 0.64
Batch: 340; loss: 1.04; acc: 0.67
Batch: 360; loss: 1.19; acc: 0.59
Batch: 380; loss: 1.2; acc: 0.64
Batch: 400; loss: 1.63; acc: 0.44
Batch: 420; loss: 1.15; acc: 0.66
Batch: 440; loss: 0.83; acc: 0.75
Batch: 460; loss: 1.1; acc: 0.59
Batch: 480; loss: 0.99; acc: 0.67
Batch: 500; loss: 1.15; acc: 0.66
Batch: 520; loss: 1.27; acc: 0.59
Batch: 540; loss: 1.36; acc: 0.56
Batch: 560; loss: 1.03; acc: 0.69
Batch: 580; loss: 0.93; acc: 0.69
Batch: 600; loss: 1.2; acc: 0.7
Batch: 620; loss: 0.88; acc: 0.77
Batch: 640; loss: 1.07; acc: 0.73
Batch: 660; loss: 1.12; acc: 0.61
Batch: 680; loss: 1.07; acc: 0.62
Batch: 700; loss: 1.14; acc: 0.64
Batch: 720; loss: 0.99; acc: 0.67
Batch: 740; loss: 0.85; acc: 0.75
Batch: 760; loss: 0.95; acc: 0.66
Batch: 780; loss: 1.03; acc: 0.69
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0089194546839235; val_accuracy: 0.6742635350318471 

The current subspace-distance is: 0.00011443018593126908 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.02; acc: 0.73
Batch: 20; loss: 1.09; acc: 0.69
Batch: 40; loss: 0.97; acc: 0.72
Batch: 60; loss: 0.94; acc: 0.62
Batch: 80; loss: 0.9; acc: 0.73
Batch: 100; loss: 0.96; acc: 0.69
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.96; acc: 0.62
Batch: 160; loss: 1.26; acc: 0.59
Batch: 180; loss: 1.01; acc: 0.77
Batch: 200; loss: 1.08; acc: 0.64
Batch: 220; loss: 1.06; acc: 0.69
Batch: 240; loss: 1.02; acc: 0.64
Batch: 260; loss: 1.46; acc: 0.62
Batch: 280; loss: 1.01; acc: 0.7
Batch: 300; loss: 1.23; acc: 0.61
Batch: 320; loss: 0.95; acc: 0.62
Batch: 340; loss: 0.8; acc: 0.78
Batch: 360; loss: 1.26; acc: 0.62
Batch: 380; loss: 1.12; acc: 0.58
Batch: 400; loss: 1.05; acc: 0.73
Batch: 420; loss: 0.75; acc: 0.8
Batch: 440; loss: 1.05; acc: 0.67
Batch: 460; loss: 0.86; acc: 0.77
Batch: 480; loss: 0.98; acc: 0.66
Batch: 500; loss: 1.2; acc: 0.62
Batch: 520; loss: 0.99; acc: 0.69
Batch: 540; loss: 1.11; acc: 0.7
Batch: 560; loss: 1.05; acc: 0.62
Batch: 580; loss: 0.87; acc: 0.77
Batch: 600; loss: 1.07; acc: 0.62
Batch: 620; loss: 1.01; acc: 0.69
Batch: 640; loss: 1.29; acc: 0.62
Batch: 660; loss: 0.81; acc: 0.75
Batch: 680; loss: 1.06; acc: 0.62
Batch: 700; loss: 1.31; acc: 0.61
Batch: 720; loss: 1.03; acc: 0.67
Batch: 740; loss: 1.19; acc: 0.67
Batch: 760; loss: 1.26; acc: 0.53
Batch: 780; loss: 1.0; acc: 0.64
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.11; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.59
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.16; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0092410471788638; val_accuracy: 0.6738654458598726 

The current subspace-distance is: 0.00011786013055825606 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.14; acc: 0.59
Batch: 20; loss: 1.18; acc: 0.56
Batch: 40; loss: 1.06; acc: 0.67
Batch: 60; loss: 0.96; acc: 0.7
Batch: 80; loss: 0.93; acc: 0.75
Batch: 100; loss: 1.22; acc: 0.58
Batch: 120; loss: 1.08; acc: 0.67
Batch: 140; loss: 1.4; acc: 0.66
Batch: 160; loss: 1.12; acc: 0.7
Batch: 180; loss: 1.15; acc: 0.67
Batch: 200; loss: 0.86; acc: 0.72
Batch: 220; loss: 1.04; acc: 0.64
Batch: 240; loss: 1.12; acc: 0.62
Batch: 260; loss: 0.95; acc: 0.7
Batch: 280; loss: 1.14; acc: 0.62
Batch: 300; loss: 0.93; acc: 0.75
Batch: 320; loss: 0.9; acc: 0.72
Batch: 340; loss: 1.18; acc: 0.59
Batch: 360; loss: 1.03; acc: 0.64
Batch: 380; loss: 1.26; acc: 0.56
Batch: 400; loss: 1.06; acc: 0.72
Batch: 420; loss: 0.92; acc: 0.67
Batch: 440; loss: 1.49; acc: 0.56
Batch: 460; loss: 0.98; acc: 0.64
Batch: 480; loss: 1.01; acc: 0.69
Batch: 500; loss: 1.13; acc: 0.66
Batch: 520; loss: 1.11; acc: 0.62
Batch: 540; loss: 1.14; acc: 0.62
Batch: 560; loss: 0.92; acc: 0.73
Batch: 580; loss: 0.94; acc: 0.73
Batch: 600; loss: 0.93; acc: 0.7
Batch: 620; loss: 1.02; acc: 0.67
Batch: 640; loss: 1.3; acc: 0.58
Batch: 660; loss: 1.1; acc: 0.62
Batch: 680; loss: 1.03; acc: 0.66
Batch: 700; loss: 1.09; acc: 0.62
Batch: 720; loss: 0.97; acc: 0.7
Batch: 740; loss: 0.94; acc: 0.7
Batch: 760; loss: 1.35; acc: 0.59
Batch: 780; loss: 1.19; acc: 0.61
Train Epoch over. train_loss: 1.07; train_accuracy: 0.66 

Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.28; acc: 0.56
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 1.0; acc: 0.61
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.97; acc: 0.66
Val Epoch over. val_loss: 1.0093291595483282; val_accuracy: 0.6735668789808917 

The current subspace-distance is: 0.00011750846897484735 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 15942
elements in E: 3374250
fraction nonzero: 0.004724605467881751
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.29; acc: 0.12
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.28; acc: 0.16
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.08
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.28; acc: 0.11
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.28; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.08
Batch: 520; loss: 2.29; acc: 0.06
Batch: 540; loss: 2.28; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.27; acc: 0.16
Batch: 620; loss: 2.27; acc: 0.14
Batch: 640; loss: 2.26; acc: 0.2
Batch: 660; loss: 2.26; acc: 0.2
Batch: 680; loss: 2.27; acc: 0.17
Batch: 700; loss: 2.27; acc: 0.09
Batch: 720; loss: 2.24; acc: 0.16
Batch: 740; loss: 2.28; acc: 0.08
Batch: 760; loss: 2.26; acc: 0.12
Batch: 780; loss: 2.24; acc: 0.23
Train Epoch over. train_loss: 2.29; train_accuracy: 0.11 

Batch: 0; loss: 2.26; acc: 0.11
Batch: 20; loss: 2.27; acc: 0.14
Batch: 40; loss: 2.25; acc: 0.16
Batch: 60; loss: 2.25; acc: 0.25
Batch: 80; loss: 2.25; acc: 0.12
Batch: 100; loss: 2.26; acc: 0.17
Batch: 120; loss: 2.26; acc: 0.12
Batch: 140; loss: 2.26; acc: 0.14
Val Epoch over. val_loss: 2.2572086328154155; val_accuracy: 0.14261544585987262 

The current subspace-distance is: 4.78402307635406e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.14
Batch: 20; loss: 2.24; acc: 0.17
Batch: 40; loss: 2.24; acc: 0.19
Batch: 60; loss: 2.24; acc: 0.23
Batch: 80; loss: 2.23; acc: 0.22
Batch: 100; loss: 2.23; acc: 0.19
Batch: 120; loss: 2.21; acc: 0.22
Batch: 140; loss: 2.24; acc: 0.12
Batch: 160; loss: 2.2; acc: 0.2
Batch: 180; loss: 2.23; acc: 0.11
Batch: 200; loss: 2.2; acc: 0.2
Batch: 220; loss: 2.19; acc: 0.17
Batch: 240; loss: 2.13; acc: 0.25
Batch: 260; loss: 2.12; acc: 0.22
Batch: 280; loss: 2.11; acc: 0.2
Batch: 300; loss: 2.06; acc: 0.14
Batch: 320; loss: 1.99; acc: 0.3
Batch: 340; loss: 2.01; acc: 0.31
Batch: 360; loss: 1.77; acc: 0.39
Batch: 380; loss: 1.77; acc: 0.39
Batch: 400; loss: 1.68; acc: 0.38
Batch: 420; loss: 1.37; acc: 0.53
Batch: 440; loss: 1.45; acc: 0.52
Batch: 460; loss: 1.27; acc: 0.64
Batch: 480; loss: 1.46; acc: 0.48
Batch: 500; loss: 1.2; acc: 0.53
Batch: 520; loss: 0.99; acc: 0.59
Batch: 540; loss: 1.36; acc: 0.5
Batch: 560; loss: 1.13; acc: 0.58
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 1.01; acc: 0.72
Batch: 620; loss: 1.5; acc: 0.52
Batch: 640; loss: 1.03; acc: 0.67
Batch: 660; loss: 1.1; acc: 0.53
Batch: 680; loss: 0.96; acc: 0.73
Batch: 700; loss: 1.12; acc: 0.62
Batch: 720; loss: 1.01; acc: 0.67
Batch: 740; loss: 1.0; acc: 0.62
Batch: 760; loss: 1.18; acc: 0.66
Batch: 780; loss: 0.8; acc: 0.81
Train Epoch over. train_loss: 1.66; train_accuracy: 0.42 

Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.73; acc: 0.48
Batch: 40; loss: 0.99; acc: 0.69
Batch: 60; loss: 1.3; acc: 0.52
Batch: 80; loss: 1.31; acc: 0.55
Batch: 100; loss: 1.35; acc: 0.55
Batch: 120; loss: 1.74; acc: 0.38
Batch: 140; loss: 1.26; acc: 0.59
Val Epoch over. val_loss: 1.3197910713542038; val_accuracy: 0.5362261146496815 

The current subspace-distance is: 1.2827006685256492e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.58
Batch: 20; loss: 0.84; acc: 0.78
Batch: 40; loss: 1.01; acc: 0.61
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 0.99; acc: 0.67
Batch: 100; loss: 0.77; acc: 0.73
Batch: 120; loss: 1.03; acc: 0.67
Batch: 140; loss: 0.92; acc: 0.69
Batch: 160; loss: 0.92; acc: 0.72
Batch: 180; loss: 1.1; acc: 0.67
Batch: 200; loss: 0.8; acc: 0.77
Batch: 220; loss: 0.91; acc: 0.69
Batch: 240; loss: 0.96; acc: 0.64
Batch: 260; loss: 0.65; acc: 0.86
Batch: 280; loss: 0.83; acc: 0.72
Batch: 300; loss: 0.98; acc: 0.69
Batch: 320; loss: 0.79; acc: 0.7
Batch: 340; loss: 0.77; acc: 0.8
Batch: 360; loss: 0.83; acc: 0.72
Batch: 380; loss: 0.96; acc: 0.61
Batch: 400; loss: 0.76; acc: 0.7
Batch: 420; loss: 1.22; acc: 0.67
Batch: 440; loss: 1.21; acc: 0.62
Batch: 460; loss: 1.25; acc: 0.58
Batch: 480; loss: 0.86; acc: 0.8
Batch: 500; loss: 0.69; acc: 0.77
Batch: 520; loss: 0.9; acc: 0.72
Batch: 540; loss: 0.82; acc: 0.72
Batch: 560; loss: 1.3; acc: 0.58
Batch: 580; loss: 0.96; acc: 0.64
Batch: 600; loss: 0.73; acc: 0.73
Batch: 620; loss: 0.93; acc: 0.66
Batch: 640; loss: 0.96; acc: 0.66
Batch: 660; loss: 0.78; acc: 0.72
Batch: 680; loss: 1.19; acc: 0.61
Batch: 700; loss: 0.95; acc: 0.73
Batch: 720; loss: 0.99; acc: 0.66
Batch: 740; loss: 0.66; acc: 0.81
Batch: 760; loss: 0.84; acc: 0.69
Batch: 780; loss: 0.81; acc: 0.72
Train Epoch over. train_loss: 0.96; train_accuracy: 0.68 

Batch: 0; loss: 0.93; acc: 0.7
Batch: 20; loss: 1.15; acc: 0.62
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.73
Batch: 80; loss: 0.59; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.77
Batch: 120; loss: 1.07; acc: 0.64
Batch: 140; loss: 0.7; acc: 0.73
Val Epoch over. val_loss: 0.7927100180061; val_accuracy: 0.7349721337579618 

The current subspace-distance is: 1.942549533850979e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.66
Batch: 20; loss: 0.54; acc: 0.78
Batch: 40; loss: 0.97; acc: 0.72
Batch: 60; loss: 0.9; acc: 0.61
Batch: 80; loss: 1.07; acc: 0.59
Batch: 100; loss: 0.95; acc: 0.69
Batch: 120; loss: 2.03; acc: 0.53
Batch: 140; loss: 0.66; acc: 0.78
Batch: 160; loss: 0.82; acc: 0.78
Batch: 180; loss: 0.84; acc: 0.67
Batch: 200; loss: 0.78; acc: 0.8
Batch: 220; loss: 0.96; acc: 0.73
Batch: 240; loss: 1.04; acc: 0.61
Batch: 260; loss: 0.81; acc: 0.72
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.89; acc: 0.67
Batch: 320; loss: 0.87; acc: 0.72
Batch: 340; loss: 0.97; acc: 0.69
Batch: 360; loss: 0.64; acc: 0.77
Batch: 380; loss: 0.78; acc: 0.7
Batch: 400; loss: 0.7; acc: 0.84
Batch: 420; loss: 0.82; acc: 0.73
Batch: 440; loss: 0.68; acc: 0.81
Batch: 460; loss: 0.88; acc: 0.69
Batch: 480; loss: 1.0; acc: 0.58
Batch: 500; loss: 0.72; acc: 0.83
Batch: 520; loss: 0.95; acc: 0.67
Batch: 540; loss: 0.95; acc: 0.72
Batch: 560; loss: 0.86; acc: 0.73
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.59; acc: 0.89
Batch: 620; loss: 1.12; acc: 0.61
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.9; acc: 0.73
Batch: 700; loss: 0.75; acc: 0.81
Batch: 720; loss: 1.02; acc: 0.7
Batch: 740; loss: 0.62; acc: 0.8
Batch: 760; loss: 0.98; acc: 0.73
Batch: 780; loss: 0.75; acc: 0.78
Train Epoch over. train_loss: 0.87; train_accuracy: 0.72 

Batch: 0; loss: 0.94; acc: 0.77
Batch: 20; loss: 1.18; acc: 0.72
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.83; acc: 0.72
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.78
Batch: 120; loss: 1.1; acc: 0.66
Batch: 140; loss: 0.89; acc: 0.67
Val Epoch over. val_loss: 0.8438034017754209; val_accuracy: 0.7156648089171974 

The current subspace-distance is: 2.68194326054072e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.91; acc: 0.7
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.8
Batch: 80; loss: 0.9; acc: 0.72
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 0.95; acc: 0.77
Batch: 140; loss: 0.94; acc: 0.75
Batch: 160; loss: 0.81; acc: 0.73
Batch: 180; loss: 0.77; acc: 0.72
Batch: 200; loss: 0.68; acc: 0.81
Batch: 220; loss: 1.06; acc: 0.69
Batch: 240; loss: 0.77; acc: 0.8
Batch: 260; loss: 0.83; acc: 0.72
Batch: 280; loss: 0.6; acc: 0.78
Batch: 300; loss: 0.63; acc: 0.81
Batch: 320; loss: 0.75; acc: 0.75
Batch: 340; loss: 0.65; acc: 0.77
Batch: 360; loss: 1.08; acc: 0.58
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.67; acc: 0.78
Batch: 420; loss: 0.78; acc: 0.73
Batch: 440; loss: 0.66; acc: 0.77
Batch: 460; loss: 0.94; acc: 0.67
Batch: 480; loss: 0.76; acc: 0.75
Batch: 500; loss: 1.1; acc: 0.58
Batch: 520; loss: 0.97; acc: 0.72
Batch: 540; loss: 1.02; acc: 0.72
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.81; acc: 0.7
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 1.1; acc: 0.56
Batch: 640; loss: 0.91; acc: 0.78
Batch: 660; loss: 0.92; acc: 0.69
Batch: 680; loss: 0.95; acc: 0.73
Batch: 700; loss: 0.87; acc: 0.73
Batch: 720; loss: 0.77; acc: 0.78
Batch: 740; loss: 0.9; acc: 0.66
Batch: 760; loss: 0.81; acc: 0.75
Batch: 780; loss: 0.7; acc: 0.75
Train Epoch over. train_loss: 0.87; train_accuracy: 0.72 

Batch: 0; loss: 1.08; acc: 0.61
Batch: 20; loss: 1.85; acc: 0.61
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 1.16; acc: 0.77
Batch: 80; loss: 0.98; acc: 0.78
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 1.5; acc: 0.67
Batch: 140; loss: 1.13; acc: 0.67
Val Epoch over. val_loss: 1.0408818256703152; val_accuracy: 0.6752587579617835 

The current subspace-distance is: 3.151441705995239e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.22; acc: 0.62
Batch: 20; loss: 1.0; acc: 0.73
Batch: 40; loss: 2.25; acc: 0.44
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.86; acc: 0.73
Batch: 100; loss: 0.87; acc: 0.67
Batch: 120; loss: 1.52; acc: 0.52
Batch: 140; loss: 0.8; acc: 0.72
Batch: 160; loss: 0.72; acc: 0.77
Batch: 180; loss: 1.13; acc: 0.67
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.88; acc: 0.7
Batch: 260; loss: 0.81; acc: 0.69
Batch: 280; loss: 0.74; acc: 0.77
Batch: 300; loss: 0.75; acc: 0.72
Batch: 320; loss: 1.09; acc: 0.53
Batch: 340; loss: 0.79; acc: 0.75
Batch: 360; loss: 0.86; acc: 0.69
Batch: 380; loss: 1.0; acc: 0.67
Batch: 400; loss: 0.87; acc: 0.7
Batch: 420; loss: 0.65; acc: 0.83
Batch: 440; loss: 0.59; acc: 0.78
Batch: 460; loss: 0.85; acc: 0.78
Batch: 480; loss: 1.03; acc: 0.66
Batch: 500; loss: 0.86; acc: 0.69
Batch: 520; loss: 0.71; acc: 0.8
Batch: 540; loss: 1.49; acc: 0.56
Batch: 560; loss: 1.05; acc: 0.81
Batch: 580; loss: 0.73; acc: 0.77
Batch: 600; loss: 0.93; acc: 0.61
Batch: 620; loss: 1.28; acc: 0.59
Batch: 640; loss: 0.86; acc: 0.75
Batch: 660; loss: 0.88; acc: 0.7
Batch: 680; loss: 1.07; acc: 0.59
Batch: 700; loss: 0.77; acc: 0.77
Batch: 720; loss: 0.66; acc: 0.75
Batch: 740; loss: 0.67; acc: 0.78
Batch: 760; loss: 0.73; acc: 0.75
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 1.16; acc: 0.62
Batch: 20; loss: 1.41; acc: 0.56
Batch: 40; loss: 0.65; acc: 0.84
Batch: 60; loss: 1.22; acc: 0.66
Batch: 80; loss: 0.99; acc: 0.75
Batch: 100; loss: 0.99; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.66
Batch: 140; loss: 1.08; acc: 0.56
Val Epoch over. val_loss: 1.0599827610763015; val_accuracy: 0.6658041401273885 

The current subspace-distance is: 3.722583642229438e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.96; acc: 0.66
Batch: 20; loss: 1.0; acc: 0.72
Batch: 40; loss: 1.02; acc: 0.59
Batch: 60; loss: 0.87; acc: 0.75
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.74; acc: 0.83
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.87; acc: 0.67
Batch: 160; loss: 1.77; acc: 0.45
Batch: 180; loss: 1.01; acc: 0.7
Batch: 200; loss: 0.74; acc: 0.78
Batch: 220; loss: 0.91; acc: 0.72
Batch: 240; loss: 0.62; acc: 0.75
Batch: 260; loss: 0.59; acc: 0.8
Batch: 280; loss: 0.57; acc: 0.73
Batch: 300; loss: 0.71; acc: 0.75
Batch: 320; loss: 0.78; acc: 0.75
Batch: 340; loss: 0.56; acc: 0.77
Batch: 360; loss: 1.01; acc: 0.66
Batch: 380; loss: 0.82; acc: 0.73
Batch: 400; loss: 0.78; acc: 0.72
Batch: 420; loss: 0.67; acc: 0.8
Batch: 440; loss: 0.68; acc: 0.8
Batch: 460; loss: 0.8; acc: 0.77
Batch: 480; loss: 1.1; acc: 0.66
Batch: 500; loss: 1.81; acc: 0.58
Batch: 520; loss: 0.6; acc: 0.75
Batch: 540; loss: 0.68; acc: 0.75
Batch: 560; loss: 0.69; acc: 0.77
Batch: 580; loss: 0.76; acc: 0.75
Batch: 600; loss: 0.89; acc: 0.73
Batch: 620; loss: 0.88; acc: 0.7
Batch: 640; loss: 0.59; acc: 0.8
Batch: 660; loss: 0.76; acc: 0.75
Batch: 680; loss: 0.66; acc: 0.75
Batch: 700; loss: 0.71; acc: 0.7
Batch: 720; loss: 0.94; acc: 0.67
Batch: 740; loss: 0.52; acc: 0.81
Batch: 760; loss: 0.78; acc: 0.78
Batch: 780; loss: 1.12; acc: 0.64
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.95; acc: 0.67
Batch: 20; loss: 1.36; acc: 0.64
Batch: 40; loss: 0.58; acc: 0.8
Batch: 60; loss: 0.99; acc: 0.67
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 0.9; acc: 0.69
Batch: 120; loss: 1.06; acc: 0.66
Batch: 140; loss: 0.87; acc: 0.66
Val Epoch over. val_loss: 0.8700862039046683; val_accuracy: 0.7082006369426752 

The current subspace-distance is: 3.9269223634619266e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.73
Batch: 20; loss: 0.77; acc: 0.73
Batch: 40; loss: 1.11; acc: 0.69
Batch: 60; loss: 0.85; acc: 0.73
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.64; acc: 0.75
Batch: 120; loss: 0.86; acc: 0.67
Batch: 140; loss: 0.74; acc: 0.7
Batch: 160; loss: 0.6; acc: 0.77
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.86; acc: 0.72
Batch: 220; loss: 0.79; acc: 0.67
Batch: 240; loss: 0.84; acc: 0.77
Batch: 260; loss: 0.6; acc: 0.75
Batch: 280; loss: 0.67; acc: 0.81
Batch: 300; loss: 0.59; acc: 0.81
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.72; acc: 0.73
Batch: 360; loss: 0.79; acc: 0.78
Batch: 380; loss: 0.82; acc: 0.73
Batch: 400; loss: 0.72; acc: 0.75
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.9; acc: 0.72
Batch: 460; loss: 0.77; acc: 0.75
Batch: 480; loss: 0.68; acc: 0.84
Batch: 500; loss: 0.68; acc: 0.78
Batch: 520; loss: 1.15; acc: 0.61
Batch: 540; loss: 0.59; acc: 0.73
Batch: 560; loss: 0.98; acc: 0.61
Batch: 580; loss: 0.6; acc: 0.8
Batch: 600; loss: 1.1; acc: 0.7
Batch: 620; loss: 0.69; acc: 0.75
Batch: 640; loss: 0.75; acc: 0.69
Batch: 660; loss: 0.88; acc: 0.73
Batch: 680; loss: 0.82; acc: 0.73
Batch: 700; loss: 0.75; acc: 0.75
Batch: 720; loss: 0.79; acc: 0.7
Batch: 740; loss: 0.7; acc: 0.78
Batch: 760; loss: 0.78; acc: 0.75
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

Batch: 0; loss: 0.77; acc: 0.7
Batch: 20; loss: 1.26; acc: 0.62
Batch: 40; loss: 0.51; acc: 0.8
Batch: 60; loss: 1.01; acc: 0.73
Batch: 80; loss: 0.69; acc: 0.81
Batch: 100; loss: 0.91; acc: 0.7
Batch: 120; loss: 1.29; acc: 0.66
Batch: 140; loss: 0.54; acc: 0.78
Val Epoch over. val_loss: 0.893426806683753; val_accuracy: 0.7011345541401274 

The current subspace-distance is: 4.304852700443007e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.89; acc: 0.7
Batch: 100; loss: 0.87; acc: 0.7
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.57; acc: 0.83
Batch: 160; loss: 0.76; acc: 0.75
Batch: 180; loss: 0.84; acc: 0.69
Batch: 200; loss: 0.64; acc: 0.8
Batch: 220; loss: 0.67; acc: 0.72
Batch: 240; loss: 0.8; acc: 0.77
Batch: 260; loss: 1.08; acc: 0.58
Batch: 280; loss: 0.82; acc: 0.75
Batch: 300; loss: 0.71; acc: 0.7
Batch: 320; loss: 0.8; acc: 0.75
Batch: 340; loss: 0.8; acc: 0.73
Batch: 360; loss: 0.88; acc: 0.73
Batch: 380; loss: 0.76; acc: 0.73
Batch: 400; loss: 0.75; acc: 0.78
Batch: 420; loss: 1.01; acc: 0.61
Batch: 440; loss: 0.67; acc: 0.73
Batch: 460; loss: 0.91; acc: 0.72
Batch: 480; loss: 0.78; acc: 0.81
Batch: 500; loss: 0.92; acc: 0.72
Batch: 520; loss: 0.7; acc: 0.77
Batch: 540; loss: 0.83; acc: 0.75
Batch: 560; loss: 0.93; acc: 0.73
Batch: 580; loss: 0.79; acc: 0.72
Batch: 600; loss: 0.89; acc: 0.73
Batch: 620; loss: 0.55; acc: 0.77
Batch: 640; loss: 0.97; acc: 0.69
Batch: 660; loss: 0.77; acc: 0.77
Batch: 680; loss: 0.8; acc: 0.69
Batch: 700; loss: 0.71; acc: 0.75
Batch: 720; loss: 0.9; acc: 0.72
Batch: 740; loss: 0.69; acc: 0.81
Batch: 760; loss: 0.81; acc: 0.66
Batch: 780; loss: 0.66; acc: 0.77
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

Batch: 0; loss: 0.81; acc: 0.69
Batch: 20; loss: 0.99; acc: 0.61
Batch: 40; loss: 0.48; acc: 0.81
Batch: 60; loss: 0.82; acc: 0.7
Batch: 80; loss: 0.67; acc: 0.77
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.0; acc: 0.67
Batch: 140; loss: 0.6; acc: 0.78
Val Epoch over. val_loss: 0.9329175871268959; val_accuracy: 0.6821257961783439 

The current subspace-distance is: 4.6893452235963196e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 0.82; acc: 0.67
Batch: 40; loss: 0.81; acc: 0.83
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 1.19; acc: 0.69
Batch: 100; loss: 0.8; acc: 0.7
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 1.09; acc: 0.67
Batch: 160; loss: 0.66; acc: 0.77
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.74; acc: 0.69
Batch: 220; loss: 0.66; acc: 0.8
Batch: 240; loss: 0.85; acc: 0.7
Batch: 260; loss: 0.46; acc: 0.83
Batch: 280; loss: 0.96; acc: 0.64
Batch: 300; loss: 0.81; acc: 0.7
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.63; acc: 0.8
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.69; acc: 0.77
Batch: 400; loss: 0.61; acc: 0.8
Batch: 420; loss: 0.81; acc: 0.75
Batch: 440; loss: 0.65; acc: 0.81
Batch: 460; loss: 1.16; acc: 0.69
Batch: 480; loss: 0.75; acc: 0.77
Batch: 500; loss: 0.59; acc: 0.77
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 0.87; acc: 0.78
Batch: 560; loss: 0.74; acc: 0.8
Batch: 580; loss: 0.98; acc: 0.8
Batch: 600; loss: 0.64; acc: 0.8
Batch: 620; loss: 0.81; acc: 0.73
Batch: 640; loss: 0.5; acc: 0.77
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 1.08; acc: 0.7
Batch: 700; loss: 0.69; acc: 0.73
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 1.05; acc: 0.62
Batch: 780; loss: 0.74; acc: 0.75
Train Epoch over. train_loss: 0.73; train_accuracy: 0.77 

Batch: 0; loss: 0.75; acc: 0.7
Batch: 20; loss: 0.81; acc: 0.78
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 1.01; acc: 0.73
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.86; acc: 0.67
Batch: 140; loss: 0.51; acc: 0.81
Val Epoch over. val_loss: 0.7189854560004678; val_accuracy: 0.7641321656050956 

The current subspace-distance is: 4.958590216119774e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.74; acc: 0.72
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.61; acc: 0.8
Batch: 160; loss: 0.75; acc: 0.75
Batch: 180; loss: 0.4; acc: 0.84
Batch: 200; loss: 0.49; acc: 0.83
Batch: 220; loss: 0.76; acc: 0.73
Batch: 240; loss: 0.63; acc: 0.83
Batch: 260; loss: 0.7; acc: 0.77
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.49; acc: 0.81
Batch: 340; loss: 0.82; acc: 0.77
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.63; acc: 0.81
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.76; acc: 0.8
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.64; acc: 0.78
Batch: 580; loss: 0.85; acc: 0.73
Batch: 600; loss: 0.58; acc: 0.83
Batch: 620; loss: 0.61; acc: 0.78
Batch: 640; loss: 0.56; acc: 0.78
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.63; acc: 0.81
Batch: 700; loss: 0.51; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.81
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.86; acc: 0.7
Train Epoch over. train_loss: 0.61; train_accuracy: 0.81 

Batch: 0; loss: 0.53; acc: 0.78
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.76; acc: 0.81
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.34; acc: 0.86
Val Epoch over. val_loss: 0.5550421041667841; val_accuracy: 0.8211584394904459 

The current subspace-distance is: 5.497601887327619e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.84
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.73; acc: 0.75
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.65; acc: 0.77
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.59; acc: 0.81
Batch: 160; loss: 0.67; acc: 0.78
Batch: 180; loss: 0.57; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.88
Batch: 220; loss: 0.49; acc: 0.83
Batch: 240; loss: 0.52; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.74; acc: 0.83
Batch: 300; loss: 0.62; acc: 0.8
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.51; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.62; acc: 0.83
Batch: 400; loss: 0.59; acc: 0.81
Batch: 420; loss: 0.62; acc: 0.77
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.72; acc: 0.72
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.72; acc: 0.81
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.92
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.84; acc: 0.77
Batch: 600; loss: 0.66; acc: 0.77
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.53; acc: 0.89
Batch: 660; loss: 0.82; acc: 0.72
Batch: 680; loss: 0.5; acc: 0.83
Batch: 700; loss: 0.72; acc: 0.78
Batch: 720; loss: 0.5; acc: 0.84
Batch: 740; loss: 0.49; acc: 0.89
Batch: 760; loss: 0.67; acc: 0.84
Batch: 780; loss: 0.71; acc: 0.81
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

Batch: 0; loss: 0.72; acc: 0.69
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.73; acc: 0.72
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.59; acc: 0.77
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.48; acc: 0.86
Val Epoch over. val_loss: 0.7540591886848401; val_accuracy: 0.7402468152866242 

The current subspace-distance is: 5.6943590607261285e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 0.83; acc: 0.72
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.79; acc: 0.75
Batch: 200; loss: 0.64; acc: 0.81
Batch: 220; loss: 0.71; acc: 0.81
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.56; acc: 0.84
Batch: 280; loss: 0.68; acc: 0.77
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.62; acc: 0.83
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.9; acc: 0.72
Batch: 380; loss: 0.51; acc: 0.89
Batch: 400; loss: 0.55; acc: 0.73
Batch: 420; loss: 0.78; acc: 0.8
Batch: 440; loss: 0.57; acc: 0.81
Batch: 460; loss: 0.66; acc: 0.78
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.61; acc: 0.86
Batch: 520; loss: 0.65; acc: 0.81
Batch: 540; loss: 0.62; acc: 0.81
Batch: 560; loss: 0.67; acc: 0.77
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.63; acc: 0.78
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.6; acc: 0.8
Batch: 680; loss: 0.47; acc: 0.91
Batch: 700; loss: 0.67; acc: 0.83
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.8; acc: 0.7
Batch: 760; loss: 0.67; acc: 0.8
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

Batch: 0; loss: 0.53; acc: 0.72
Batch: 20; loss: 0.72; acc: 0.77
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.78; acc: 0.75
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.5830670137693927; val_accuracy: 0.8200636942675159 

The current subspace-distance is: 5.875022543477826e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.67; acc: 0.83
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.79; acc: 0.7
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.38; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.63; acc: 0.83
Batch: 200; loss: 0.67; acc: 0.8
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.77; acc: 0.75
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.64; acc: 0.83
Batch: 340; loss: 0.63; acc: 0.83
Batch: 360; loss: 0.65; acc: 0.77
Batch: 380; loss: 0.57; acc: 0.83
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.46; acc: 0.86
Batch: 440; loss: 0.9; acc: 0.66
Batch: 460; loss: 0.8; acc: 0.75
Batch: 480; loss: 0.46; acc: 0.83
Batch: 500; loss: 0.63; acc: 0.78
Batch: 520; loss: 0.62; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.79; acc: 0.7
Batch: 620; loss: 0.89; acc: 0.73
Batch: 640; loss: 0.73; acc: 0.77
Batch: 660; loss: 0.55; acc: 0.77
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.83
Batch: 720; loss: 0.55; acc: 0.81
Batch: 740; loss: 0.67; acc: 0.77
Batch: 760; loss: 0.67; acc: 0.81
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.89; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.7
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.5900383373354651; val_accuracy: 0.8119028662420382 

The current subspace-distance is: 6.333010969683528e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.76; acc: 0.73
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.81; acc: 0.72
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.72; acc: 0.81
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.72; acc: 0.83
Batch: 200; loss: 0.47; acc: 0.81
Batch: 220; loss: 0.5; acc: 0.8
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.72; acc: 0.78
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.83
Batch: 340; loss: 0.76; acc: 0.77
Batch: 360; loss: 0.57; acc: 0.81
Batch: 380; loss: 0.74; acc: 0.72
Batch: 400; loss: 0.78; acc: 0.75
Batch: 420; loss: 0.56; acc: 0.81
Batch: 440; loss: 0.61; acc: 0.84
Batch: 460; loss: 0.7; acc: 0.81
Batch: 480; loss: 0.59; acc: 0.8
Batch: 500; loss: 0.54; acc: 0.81
Batch: 520; loss: 0.94; acc: 0.73
Batch: 540; loss: 0.58; acc: 0.86
Batch: 560; loss: 1.01; acc: 0.7
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.56; acc: 0.78
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.63; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.82; acc: 0.69
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.73; acc: 0.8
Batch: 760; loss: 0.6; acc: 0.75
Batch: 780; loss: 0.62; acc: 0.83
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.74; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.32; acc: 0.92
Val Epoch over. val_loss: 0.5544685131045664; val_accuracy: 0.8267316878980892 

The current subspace-distance is: 6.491442036349326e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.71; acc: 0.81
Batch: 20; loss: 0.76; acc: 0.75
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.8; acc: 0.7
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.78; acc: 0.8
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.47; acc: 0.81
Batch: 220; loss: 0.68; acc: 0.77
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.55; acc: 0.83
Batch: 280; loss: 0.59; acc: 0.83
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.97; acc: 0.66
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.84; acc: 0.75
Batch: 380; loss: 0.32; acc: 0.86
Batch: 400; loss: 0.54; acc: 0.8
Batch: 420; loss: 0.6; acc: 0.83
Batch: 440; loss: 0.75; acc: 0.77
Batch: 460; loss: 0.63; acc: 0.81
Batch: 480; loss: 0.5; acc: 0.86
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.72; acc: 0.78
Batch: 540; loss: 0.52; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.67; acc: 0.8
Batch: 660; loss: 0.74; acc: 0.73
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.58; acc: 0.78
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.59; train_accuracy: 0.82 

Batch: 0; loss: 0.51; acc: 0.8
Batch: 20; loss: 0.67; acc: 0.83
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.83; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.37; acc: 0.88
Val Epoch over. val_loss: 0.5583194013993451; val_accuracy: 0.8213574840764332 

The current subspace-distance is: 6.767464947188273e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.62; acc: 0.75
Batch: 60; loss: 0.85; acc: 0.8
Batch: 80; loss: 0.73; acc: 0.73
Batch: 100; loss: 0.61; acc: 0.84
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.79; acc: 0.78
Batch: 160; loss: 0.68; acc: 0.77
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.88
Batch: 280; loss: 0.79; acc: 0.8
Batch: 300; loss: 0.56; acc: 0.8
Batch: 320; loss: 0.55; acc: 0.78
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.81; acc: 0.77
Batch: 380; loss: 0.56; acc: 0.8
Batch: 400; loss: 0.72; acc: 0.77
Batch: 420; loss: 0.85; acc: 0.72
Batch: 440; loss: 0.77; acc: 0.77
Batch: 460; loss: 0.58; acc: 0.83
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.44; acc: 0.83
Batch: 520; loss: 0.6; acc: 0.73
Batch: 540; loss: 0.95; acc: 0.72
Batch: 560; loss: 0.6; acc: 0.78
Batch: 580; loss: 0.59; acc: 0.8
Batch: 600; loss: 0.61; acc: 0.78
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.69; acc: 0.8
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.74; acc: 0.67
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.59; acc: 0.78
Batch: 780; loss: 0.59; acc: 0.77
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.57; acc: 0.77
Batch: 20; loss: 0.8; acc: 0.83
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.8; acc: 0.8
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.31; acc: 0.92
Val Epoch over. val_loss: 0.5574248565040576; val_accuracy: 0.8282245222929936 

The current subspace-distance is: 7.126876880647615e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.61; acc: 0.8
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.58; acc: 0.83
Batch: 220; loss: 0.72; acc: 0.73
Batch: 240; loss: 0.79; acc: 0.77
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.65; acc: 0.75
Batch: 300; loss: 0.63; acc: 0.8
Batch: 320; loss: 0.72; acc: 0.83
Batch: 340; loss: 0.84; acc: 0.77
Batch: 360; loss: 0.65; acc: 0.78
Batch: 380; loss: 0.72; acc: 0.73
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.75; acc: 0.72
Batch: 480; loss: 0.56; acc: 0.78
Batch: 500; loss: 0.91; acc: 0.75
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.91; acc: 0.75
Batch: 560; loss: 0.68; acc: 0.73
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.78; acc: 0.75
Batch: 620; loss: 0.76; acc: 0.77
Batch: 640; loss: 0.55; acc: 0.78
Batch: 660; loss: 0.82; acc: 0.7
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.52; acc: 0.88
Batch: 720; loss: 0.56; acc: 0.89
Batch: 740; loss: 0.9; acc: 0.73
Batch: 760; loss: 0.93; acc: 0.8
Batch: 780; loss: 0.52; acc: 0.86
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.79; acc: 0.78
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.81; acc: 0.7
Batch: 140; loss: 0.31; acc: 0.94
Val Epoch over. val_loss: 0.6231949367340962; val_accuracy: 0.8044386942675159 

The current subspace-distance is: 7.48890161048621e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.8; acc: 0.78
Batch: 20; loss: 0.63; acc: 0.83
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.53; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.62; acc: 0.8
Batch: 180; loss: 0.98; acc: 0.73
Batch: 200; loss: 0.47; acc: 0.83
Batch: 220; loss: 0.51; acc: 0.88
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.51; acc: 0.84
Batch: 280; loss: 0.5; acc: 0.8
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.71; acc: 0.8
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.59; acc: 0.83
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.81; acc: 0.78
Batch: 440; loss: 0.65; acc: 0.77
Batch: 460; loss: 0.63; acc: 0.81
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.63; acc: 0.77
Batch: 540; loss: 0.88; acc: 0.7
Batch: 560; loss: 0.71; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.57; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.62; acc: 0.78
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.74; acc: 0.77
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.62; acc: 0.75
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.7; acc: 0.75
Batch: 20; loss: 1.05; acc: 0.73
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 1.03; acc: 0.75
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.91; acc: 0.7
Batch: 140; loss: 0.45; acc: 0.81
Val Epoch over. val_loss: 0.6907105505656285; val_accuracy: 0.7871218152866242 

The current subspace-distance is: 7.758870196994394e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.78
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.84; acc: 0.69
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.62; acc: 0.75
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.56; acc: 0.81
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.71; acc: 0.81
Batch: 220; loss: 0.47; acc: 0.81
Batch: 240; loss: 0.56; acc: 0.89
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.57; acc: 0.77
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.92
Batch: 400; loss: 0.73; acc: 0.81
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.61; acc: 0.83
Batch: 460; loss: 0.67; acc: 0.77
Batch: 480; loss: 0.6; acc: 0.81
Batch: 500; loss: 0.6; acc: 0.81
Batch: 520; loss: 0.72; acc: 0.8
Batch: 540; loss: 0.62; acc: 0.77
Batch: 560; loss: 0.52; acc: 0.83
Batch: 580; loss: 0.46; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.91
Batch: 620; loss: 0.53; acc: 0.81
Batch: 640; loss: 0.59; acc: 0.84
Batch: 660; loss: 0.75; acc: 0.7
Batch: 680; loss: 0.63; acc: 0.83
Batch: 700; loss: 0.65; acc: 0.77
Batch: 720; loss: 0.62; acc: 0.81
Batch: 740; loss: 0.73; acc: 0.77
Batch: 760; loss: 0.6; acc: 0.83
Batch: 780; loss: 0.76; acc: 0.73
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.71; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.64; acc: 0.73
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5486740884697361; val_accuracy: 0.8285230891719745 

The current subspace-distance is: 8.072772470768541e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.91
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.61; acc: 0.77
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.66; acc: 0.77
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.62; acc: 0.75
Batch: 200; loss: 0.66; acc: 0.81
Batch: 220; loss: 0.77; acc: 0.75
Batch: 240; loss: 0.75; acc: 0.75
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.55; acc: 0.89
Batch: 300; loss: 0.69; acc: 0.81
Batch: 320; loss: 0.66; acc: 0.8
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.7; acc: 0.78
Batch: 480; loss: 0.58; acc: 0.86
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.59; acc: 0.8
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.58; acc: 0.77
Batch: 580; loss: 0.52; acc: 0.83
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.84
Batch: 680; loss: 0.83; acc: 0.75
Batch: 700; loss: 0.7; acc: 0.8
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.53; acc: 0.84
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.61; acc: 0.86
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.73; acc: 0.83
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.3; acc: 0.94
Val Epoch over. val_loss: 0.5343710136166804; val_accuracy: 0.8303144904458599 

The current subspace-distance is: 8.263569179689512e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.58; acc: 0.8
Batch: 160; loss: 0.77; acc: 0.69
Batch: 180; loss: 0.61; acc: 0.84
Batch: 200; loss: 0.59; acc: 0.77
Batch: 220; loss: 0.57; acc: 0.84
Batch: 240; loss: 0.59; acc: 0.86
Batch: 260; loss: 0.84; acc: 0.73
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.71; acc: 0.8
Batch: 320; loss: 0.53; acc: 0.81
Batch: 340; loss: 0.66; acc: 0.83
Batch: 360; loss: 0.94; acc: 0.77
Batch: 380; loss: 0.82; acc: 0.77
Batch: 400; loss: 0.66; acc: 0.78
Batch: 420; loss: 0.54; acc: 0.81
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.79; acc: 0.73
Batch: 480; loss: 0.68; acc: 0.78
Batch: 500; loss: 0.51; acc: 0.86
Batch: 520; loss: 0.52; acc: 0.78
Batch: 540; loss: 0.58; acc: 0.78
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.63; acc: 0.77
Batch: 640; loss: 0.49; acc: 0.89
Batch: 660; loss: 0.5; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.64; acc: 0.75
Batch: 760; loss: 0.52; acc: 0.88
Batch: 780; loss: 0.55; acc: 0.83
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.78
Batch: 20; loss: 0.6; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5301887426216891; val_accuracy: 0.8331011146496815 

The current subspace-distance is: 8.63558379933238e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.44; acc: 0.81
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.82; acc: 0.73
Batch: 160; loss: 0.58; acc: 0.73
Batch: 180; loss: 0.77; acc: 0.8
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.59; acc: 0.84
Batch: 240; loss: 0.52; acc: 0.81
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.56; acc: 0.81
Batch: 320; loss: 0.48; acc: 0.78
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.83
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.68; acc: 0.78
Batch: 440; loss: 0.54; acc: 0.77
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.92; acc: 0.75
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.65; acc: 0.83
Batch: 540; loss: 0.48; acc: 0.88
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.57; acc: 0.84
Batch: 600; loss: 0.53; acc: 0.8
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.7; acc: 0.72
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.56; acc: 0.89
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.71; acc: 0.78
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.52; acc: 0.83
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5251103447880715; val_accuracy: 0.8369824840764332 

The current subspace-distance is: 8.986701868707314e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.63; acc: 0.72
Batch: 20; loss: 0.8; acc: 0.73
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.78; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.36; acc: 0.94
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.68; acc: 0.75
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.66; acc: 0.81
Batch: 260; loss: 0.62; acc: 0.81
Batch: 280; loss: 0.7; acc: 0.78
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.53; acc: 0.86
Batch: 340; loss: 0.56; acc: 0.8
Batch: 360; loss: 0.6; acc: 0.8
Batch: 380; loss: 0.62; acc: 0.83
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.59; acc: 0.81
Batch: 440; loss: 0.54; acc: 0.78
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.61; acc: 0.8
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.68; acc: 0.77
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.6; acc: 0.83
Batch: 580; loss: 0.78; acc: 0.8
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.75; acc: 0.72
Batch: 640; loss: 0.46; acc: 0.8
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 0.75; acc: 0.78
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.62; acc: 0.81
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.92; acc: 0.69
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.55; acc: 0.73
Batch: 20; loss: 0.92; acc: 0.78
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.82; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.89
Val Epoch over. val_loss: 0.5547320750203861; val_accuracy: 0.8294187898089171 

The current subspace-distance is: 9.143103670794517e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.81
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.78; acc: 0.73
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.62; acc: 0.81
Batch: 240; loss: 0.6; acc: 0.78
Batch: 260; loss: 0.54; acc: 0.81
Batch: 280; loss: 0.44; acc: 0.81
Batch: 300; loss: 0.69; acc: 0.81
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.47; acc: 0.8
Batch: 400; loss: 0.52; acc: 0.8
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.61; acc: 0.73
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.46; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.52; acc: 0.86
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.69; acc: 0.75
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.66; acc: 0.78
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.53; acc: 0.8
Batch: 700; loss: 0.61; acc: 0.84
Batch: 720; loss: 0.66; acc: 0.83
Batch: 740; loss: 0.47; acc: 0.78
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.51; acc: 0.78
Batch: 20; loss: 0.72; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.79; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.529197671848118; val_accuracy: 0.8343949044585988 

The current subspace-distance is: 9.434056119062006e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.79; acc: 0.8
Batch: 60; loss: 0.66; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.86; acc: 0.67
Batch: 120; loss: 0.79; acc: 0.67
Batch: 140; loss: 0.5; acc: 0.81
Batch: 160; loss: 0.44; acc: 0.8
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.72; acc: 0.81
Batch: 220; loss: 0.73; acc: 0.83
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 0.58; acc: 0.84
Batch: 280; loss: 0.48; acc: 0.81
Batch: 300; loss: 0.8; acc: 0.8
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.65; acc: 0.84
Batch: 360; loss: 0.83; acc: 0.7
Batch: 380; loss: 0.67; acc: 0.81
Batch: 400; loss: 0.59; acc: 0.75
Batch: 420; loss: 0.64; acc: 0.83
Batch: 440; loss: 0.58; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.65; acc: 0.8
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.66; acc: 0.78
Batch: 580; loss: 0.53; acc: 0.83
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.79; acc: 0.73
Batch: 660; loss: 0.9; acc: 0.77
Batch: 680; loss: 0.54; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.51; acc: 0.81
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.58; acc: 0.81
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.51; acc: 0.77
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.76; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.5356038519816034; val_accuracy: 0.8296178343949044 

The current subspace-distance is: 9.478173160459846e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.52; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.75
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.58; acc: 0.81
Batch: 180; loss: 0.57; acc: 0.83
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.88
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.67; acc: 0.8
Batch: 280; loss: 0.62; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.34; acc: 0.84
Batch: 360; loss: 0.57; acc: 0.81
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.49; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.83
Batch: 440; loss: 0.82; acc: 0.75
Batch: 460; loss: 0.79; acc: 0.77
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.63; acc: 0.75
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.72; acc: 0.81
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.59; acc: 0.75
Batch: 660; loss: 0.55; acc: 0.8
Batch: 680; loss: 0.57; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.81; acc: 0.75
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.67; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.78
Batch: 20; loss: 0.73; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5272442535230308; val_accuracy: 0.8346934713375797 

The current subspace-distance is: 9.873838280327618e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.69; acc: 0.8
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.54; acc: 0.8
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.78; acc: 0.75
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.58; acc: 0.8
Batch: 240; loss: 0.68; acc: 0.77
Batch: 260; loss: 0.47; acc: 0.83
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.54; acc: 0.83
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.51; acc: 0.8
Batch: 400; loss: 0.53; acc: 0.8
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.71; acc: 0.75
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.61; acc: 0.77
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.86; acc: 0.83
Batch: 560; loss: 0.42; acc: 0.83
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.69; acc: 0.7
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.67; acc: 0.8
Batch: 680; loss: 0.52; acc: 0.88
Batch: 700; loss: 0.6; acc: 0.78
Batch: 720; loss: 0.76; acc: 0.78
Batch: 740; loss: 0.5; acc: 0.78
Batch: 760; loss: 0.66; acc: 0.83
Batch: 780; loss: 0.9; acc: 0.73
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.53; acc: 0.78
Batch: 20; loss: 0.73; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.76; acc: 0.81
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.5552563866612258; val_accuracy: 0.8213574840764332 

The current subspace-distance is: 9.975042485166341e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.9; acc: 0.72
Batch: 20; loss: 0.66; acc: 0.8
Batch: 40; loss: 0.58; acc: 0.8
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.6; acc: 0.78
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.64; acc: 0.77
Batch: 240; loss: 0.64; acc: 0.81
Batch: 260; loss: 0.84; acc: 0.86
Batch: 280; loss: 0.47; acc: 0.83
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.57; acc: 0.78
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.63; acc: 0.83
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.62; acc: 0.86
Batch: 500; loss: 0.97; acc: 0.72
Batch: 520; loss: 0.62; acc: 0.81
Batch: 540; loss: 0.6; acc: 0.83
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.54; acc: 0.83
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.92
Batch: 660; loss: 0.57; acc: 0.84
Batch: 680; loss: 0.93; acc: 0.72
Batch: 700; loss: 0.59; acc: 0.84
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.81; acc: 0.78
Batch: 780; loss: 0.47; acc: 0.84
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.71; acc: 0.8
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.72; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5307956578055765; val_accuracy: 0.8323049363057324 

The current subspace-distance is: 0.0001029291088343598 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.77; acc: 0.77
Batch: 20; loss: 0.66; acc: 0.83
Batch: 40; loss: 0.65; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.8
Batch: 80; loss: 0.71; acc: 0.75
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.71; acc: 0.78
Batch: 160; loss: 0.61; acc: 0.8
Batch: 180; loss: 0.53; acc: 0.78
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.71; acc: 0.73
Batch: 280; loss: 0.48; acc: 0.83
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.82; acc: 0.77
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.62; acc: 0.8
Batch: 380; loss: 0.88; acc: 0.75
Batch: 400; loss: 0.6; acc: 0.77
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.63; acc: 0.81
Batch: 480; loss: 0.59; acc: 0.78
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.75; acc: 0.77
Batch: 560; loss: 0.67; acc: 0.77
Batch: 580; loss: 0.83; acc: 0.73
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.65; acc: 0.8
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.68; acc: 0.77
Batch: 680; loss: 0.59; acc: 0.89
Batch: 700; loss: 0.5; acc: 0.83
Batch: 720; loss: 0.81; acc: 0.72
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.62; acc: 0.83
Batch: 780; loss: 0.86; acc: 0.81
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.51; acc: 0.78
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5343468074396158; val_accuracy: 0.831906847133758 

The current subspace-distance is: 0.0001046889228746295 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.73; acc: 0.75
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.58; acc: 0.88
Batch: 100; loss: 0.9; acc: 0.7
Batch: 120; loss: 0.77; acc: 0.83
Batch: 140; loss: 0.59; acc: 0.8
Batch: 160; loss: 0.48; acc: 0.8
Batch: 180; loss: 0.37; acc: 0.92
Batch: 200; loss: 0.56; acc: 0.8
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.46; acc: 0.81
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.71; acc: 0.8
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.53; acc: 0.8
Batch: 360; loss: 0.84; acc: 0.7
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.69; acc: 0.8
Batch: 420; loss: 0.71; acc: 0.77
Batch: 440; loss: 0.67; acc: 0.78
Batch: 460; loss: 0.63; acc: 0.75
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.54; acc: 0.83
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.58; acc: 0.86
Batch: 560; loss: 0.55; acc: 0.84
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.94; acc: 0.75
Batch: 620; loss: 0.72; acc: 0.77
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.67; acc: 0.78
Batch: 680; loss: 0.8; acc: 0.8
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.61; acc: 0.86
Batch: 760; loss: 0.59; acc: 0.8
Batch: 780; loss: 0.75; acc: 0.78
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.519921997455275; val_accuracy: 0.8370820063694268 

The current subspace-distance is: 0.00010720369755290449 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.8
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.58; acc: 0.8
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.75; acc: 0.75
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.56; acc: 0.8
Batch: 380; loss: 0.65; acc: 0.8
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.65; acc: 0.78
Batch: 440; loss: 0.64; acc: 0.8
Batch: 460; loss: 0.63; acc: 0.75
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.9; acc: 0.75
Batch: 560; loss: 1.01; acc: 0.62
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.64; acc: 0.78
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.65; acc: 0.83
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.51; acc: 0.75
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.56; acc: 0.83
Batch: 760; loss: 0.46; acc: 0.84
Batch: 780; loss: 0.74; acc: 0.78
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.8
Batch: 20; loss: 0.62; acc: 0.83
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.72; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5236810592898897; val_accuracy: 0.8365843949044586 

The current subspace-distance is: 0.00010712732910178602 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.55; acc: 0.86
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.62; acc: 0.8
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.65; acc: 0.8
Batch: 160; loss: 0.6; acc: 0.83
Batch: 180; loss: 0.79; acc: 0.78
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.54; acc: 0.81
Batch: 240; loss: 0.69; acc: 0.73
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.6; acc: 0.78
Batch: 340; loss: 0.73; acc: 0.75
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.76; acc: 0.72
Batch: 460; loss: 0.46; acc: 0.8
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.68; acc: 0.78
Batch: 520; loss: 0.56; acc: 0.84
Batch: 540; loss: 0.61; acc: 0.83
Batch: 560; loss: 0.64; acc: 0.72
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.6; acc: 0.78
Batch: 640; loss: 0.78; acc: 0.77
Batch: 660; loss: 0.62; acc: 0.83
Batch: 680; loss: 0.53; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.89
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.57; acc: 0.84
Batch: 780; loss: 0.56; acc: 0.78
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.68; acc: 0.83
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.62; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5243751549037399; val_accuracy: 0.8340963375796179 

The current subspace-distance is: 0.00011034588533220813 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.59; acc: 0.77
Batch: 20; loss: 0.53; acc: 0.78
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.9; acc: 0.78
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.49; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.5; acc: 0.84
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.69; acc: 0.77
Batch: 320; loss: 0.47; acc: 0.81
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.61; acc: 0.84
Batch: 440; loss: 0.67; acc: 0.75
Batch: 460; loss: 0.6; acc: 0.83
Batch: 480; loss: 0.85; acc: 0.73
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.52; acc: 0.83
Batch: 580; loss: 0.58; acc: 0.88
Batch: 600; loss: 0.57; acc: 0.83
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.65; acc: 0.81
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.6; acc: 0.81
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.57; acc: 0.77
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.72; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.72; acc: 0.8
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5240396664590593; val_accuracy: 0.8348925159235668 

The current subspace-distance is: 0.00011229130905121565 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.96; acc: 0.62
Batch: 40; loss: 0.81; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.8
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.57; acc: 0.84
Batch: 160; loss: 0.69; acc: 0.72
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.54; acc: 0.81
Batch: 220; loss: 0.57; acc: 0.81
Batch: 240; loss: 0.73; acc: 0.77
Batch: 260; loss: 0.5; acc: 0.84
Batch: 280; loss: 0.66; acc: 0.8
Batch: 300; loss: 0.88; acc: 0.77
Batch: 320; loss: 0.53; acc: 0.8
Batch: 340; loss: 0.57; acc: 0.84
Batch: 360; loss: 0.51; acc: 0.88
Batch: 380; loss: 0.69; acc: 0.72
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.6; acc: 0.78
Batch: 440; loss: 0.56; acc: 0.88
Batch: 460; loss: 0.69; acc: 0.81
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.54; acc: 0.88
Batch: 520; loss: 0.54; acc: 0.83
Batch: 540; loss: 0.69; acc: 0.78
Batch: 560; loss: 0.56; acc: 0.77
Batch: 580; loss: 0.75; acc: 0.73
Batch: 600; loss: 0.49; acc: 0.81
Batch: 620; loss: 0.52; acc: 0.86
Batch: 640; loss: 0.74; acc: 0.77
Batch: 660; loss: 0.59; acc: 0.84
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 0.94; acc: 0.72
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.71; acc: 0.83
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.64; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5218081583927392; val_accuracy: 0.8367834394904459 

The current subspace-distance is: 0.00011241334868827835 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.81
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.75; acc: 0.78
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.81
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.72; acc: 0.8
Batch: 200; loss: 0.76; acc: 0.75
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.61; acc: 0.81
Batch: 260; loss: 0.66; acc: 0.78
Batch: 280; loss: 0.57; acc: 0.78
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.75; acc: 0.78
Batch: 340; loss: 0.68; acc: 0.83
Batch: 360; loss: 0.57; acc: 0.8
Batch: 380; loss: 0.48; acc: 0.89
Batch: 400; loss: 0.67; acc: 0.83
Batch: 420; loss: 0.56; acc: 0.78
Batch: 440; loss: 0.52; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.63; acc: 0.75
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.59; acc: 0.83
Batch: 600; loss: 0.51; acc: 0.75
Batch: 620; loss: 0.63; acc: 0.81
Batch: 640; loss: 0.52; acc: 0.8
Batch: 660; loss: 0.67; acc: 0.69
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.7; acc: 0.77
Batch: 740; loss: 0.87; acc: 0.73
Batch: 760; loss: 0.72; acc: 0.75
Batch: 780; loss: 0.63; acc: 0.77
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5225700743638786; val_accuracy: 0.8369824840764332 

The current subspace-distance is: 0.0001144646666944027 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.78; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 0.56; acc: 0.84
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.67; acc: 0.78
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.6; acc: 0.75
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.66; acc: 0.8
Batch: 240; loss: 0.47; acc: 0.83
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.71; acc: 0.75
Batch: 360; loss: 0.61; acc: 0.8
Batch: 380; loss: 0.49; acc: 0.88
Batch: 400; loss: 0.6; acc: 0.75
Batch: 420; loss: 0.64; acc: 0.78
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.7; acc: 0.77
Batch: 500; loss: 0.45; acc: 0.91
Batch: 520; loss: 0.71; acc: 0.81
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.61; acc: 0.77
Batch: 600; loss: 0.38; acc: 0.84
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.71; acc: 0.83
Batch: 680; loss: 0.7; acc: 0.77
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 0.71; acc: 0.77
Batch: 740; loss: 0.65; acc: 0.83
Batch: 760; loss: 0.7; acc: 0.81
Batch: 780; loss: 0.42; acc: 0.91
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.526722106014847; val_accuracy: 0.8346934713375797 

The current subspace-distance is: 0.0001175240395241417 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.82; acc: 0.72
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.66; acc: 0.73
Batch: 80; loss: 0.55; acc: 0.78
Batch: 100; loss: 0.63; acc: 0.77
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.62; acc: 0.88
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.56; acc: 0.81
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.42; acc: 0.81
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.67; acc: 0.81
Batch: 340; loss: 0.69; acc: 0.78
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.84
Batch: 400; loss: 0.44; acc: 0.83
Batch: 420; loss: 0.5; acc: 0.86
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.73; acc: 0.78
Batch: 480; loss: 0.55; acc: 0.81
Batch: 500; loss: 0.83; acc: 0.73
Batch: 520; loss: 0.56; acc: 0.83
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.59; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.81
Batch: 600; loss: 0.6; acc: 0.78
Batch: 620; loss: 0.64; acc: 0.8
Batch: 640; loss: 0.5; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.65; acc: 0.78
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.63; acc: 0.78
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.74; acc: 0.77
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5204545239069659; val_accuracy: 0.8378781847133758 

The current subspace-distance is: 0.00012194692681077868 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.65; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.79; acc: 0.78
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.9; acc: 0.75
Batch: 160; loss: 0.48; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.73; acc: 0.84
Batch: 240; loss: 0.75; acc: 0.78
Batch: 260; loss: 0.52; acc: 0.83
Batch: 280; loss: 0.64; acc: 0.77
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.64; acc: 0.78
Batch: 400; loss: 0.78; acc: 0.77
Batch: 420; loss: 0.68; acc: 0.83
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.68; acc: 0.78
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.77; acc: 0.83
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.7; acc: 0.84
Batch: 600; loss: 0.58; acc: 0.81
Batch: 620; loss: 0.66; acc: 0.81
Batch: 640; loss: 0.71; acc: 0.81
Batch: 660; loss: 0.58; acc: 0.81
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.53; acc: 0.83
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.71; acc: 0.77
Batch: 760; loss: 0.81; acc: 0.78
Batch: 780; loss: 0.85; acc: 0.77
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.51; acc: 0.78
Batch: 20; loss: 0.66; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5266156196119679; val_accuracy: 0.8341958598726115 

The current subspace-distance is: 0.0001225620653713122 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.72; acc: 0.77
Batch: 40; loss: 0.87; acc: 0.8
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.87; acc: 0.75
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.71; acc: 0.77
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.53; acc: 0.8
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.86; acc: 0.7
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.56; acc: 0.81
Batch: 380; loss: 0.59; acc: 0.8
Batch: 400; loss: 0.95; acc: 0.62
Batch: 420; loss: 0.63; acc: 0.83
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.68; acc: 0.84
Batch: 480; loss: 0.57; acc: 0.83
Batch: 500; loss: 0.5; acc: 0.88
Batch: 520; loss: 0.57; acc: 0.81
Batch: 540; loss: 0.52; acc: 0.81
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.83; acc: 0.77
Batch: 620; loss: 0.67; acc: 0.77
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.57; acc: 0.8
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.8; acc: 0.77
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.62; acc: 0.81
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.7; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5199394089401148; val_accuracy: 0.8358877388535032 

The current subspace-distance is: 0.0001232590584550053 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.6; acc: 0.75
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.51; acc: 0.8
Batch: 140; loss: 0.47; acc: 0.81
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.51; acc: 0.8
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.73; acc: 0.78
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.71; acc: 0.78
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.72; acc: 0.8
Batch: 400; loss: 0.51; acc: 0.83
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.52; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.56; acc: 0.8
Batch: 580; loss: 0.65; acc: 0.8
Batch: 600; loss: 0.62; acc: 0.77
Batch: 620; loss: 0.67; acc: 0.73
Batch: 640; loss: 0.63; acc: 0.78
Batch: 660; loss: 0.79; acc: 0.73
Batch: 680; loss: 0.71; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.83
Batch: 720; loss: 0.5; acc: 0.92
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5192195670619891; val_accuracy: 0.836484872611465 

The current subspace-distance is: 0.0001264251914108172 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.63; acc: 0.86
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.86; acc: 0.8
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.84; acc: 0.77
Batch: 120; loss: 0.54; acc: 0.75
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.6; acc: 0.78
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.71; acc: 0.72
Batch: 220; loss: 0.47; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.84
Batch: 280; loss: 0.74; acc: 0.81
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.61; acc: 0.83
Batch: 340; loss: 0.76; acc: 0.78
Batch: 360; loss: 0.62; acc: 0.81
Batch: 380; loss: 0.58; acc: 0.8
Batch: 400; loss: 0.61; acc: 0.84
Batch: 420; loss: 0.68; acc: 0.8
Batch: 440; loss: 0.52; acc: 0.8
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.53; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.88
Batch: 560; loss: 0.52; acc: 0.89
Batch: 580; loss: 0.54; acc: 0.8
Batch: 600; loss: 0.59; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.81
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.53; acc: 0.8
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.7; acc: 0.77
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.62; acc: 0.78
Batch: 780; loss: 0.7; acc: 0.78
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.73; acc: 0.77
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5194120729804799; val_accuracy: 0.8367834394904459 

The current subspace-distance is: 0.00012547121150419116 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.8; acc: 0.83
Batch: 40; loss: 0.49; acc: 0.78
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.79; acc: 0.78
Batch: 220; loss: 0.63; acc: 0.75
Batch: 240; loss: 0.78; acc: 0.73
Batch: 260; loss: 0.46; acc: 0.89
Batch: 280; loss: 0.42; acc: 0.83
Batch: 300; loss: 0.63; acc: 0.77
Batch: 320; loss: 0.46; acc: 0.91
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.75; acc: 0.7
Batch: 400; loss: 0.6; acc: 0.81
Batch: 420; loss: 0.78; acc: 0.78
Batch: 440; loss: 0.7; acc: 0.81
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.89
Batch: 540; loss: 0.61; acc: 0.83
Batch: 560; loss: 0.5; acc: 0.81
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.78; acc: 0.75
Batch: 680; loss: 0.67; acc: 0.78
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.62; acc: 0.77
Batch: 780; loss: 0.67; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5205613185835493; val_accuracy: 0.8360867834394905 

The current subspace-distance is: 0.00012633235019166023 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.99; acc: 0.7
Batch: 100; loss: 0.62; acc: 0.73
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.59; acc: 0.78
Batch: 160; loss: 0.85; acc: 0.73
Batch: 180; loss: 0.81; acc: 0.75
Batch: 200; loss: 0.87; acc: 0.78
Batch: 220; loss: 0.84; acc: 0.72
Batch: 240; loss: 0.71; acc: 0.81
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.55; acc: 0.83
Batch: 380; loss: 0.73; acc: 0.7
Batch: 400; loss: 0.57; acc: 0.88
Batch: 420; loss: 0.58; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.8
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.66; acc: 0.81
Batch: 500; loss: 0.63; acc: 0.73
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.8
Batch: 560; loss: 0.53; acc: 0.88
Batch: 580; loss: 0.58; acc: 0.83
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.55; acc: 0.81
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.57; acc: 0.86
Batch: 780; loss: 0.87; acc: 0.77
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.78
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5190766155719757; val_accuracy: 0.8358877388535032 

The current subspace-distance is: 0.00012803179561160505 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.74; acc: 0.7
Batch: 140; loss: 0.75; acc: 0.88
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.6; acc: 0.81
Batch: 200; loss: 0.5; acc: 0.83
Batch: 220; loss: 0.67; acc: 0.77
Batch: 240; loss: 0.51; acc: 0.81
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.83
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.64; acc: 0.75
Batch: 360; loss: 0.72; acc: 0.78
Batch: 380; loss: 0.65; acc: 0.78
Batch: 400; loss: 0.58; acc: 0.83
Batch: 420; loss: 0.67; acc: 0.8
Batch: 440; loss: 0.46; acc: 0.83
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.47; acc: 0.81
Batch: 520; loss: 0.56; acc: 0.88
Batch: 540; loss: 0.72; acc: 0.75
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.59; acc: 0.77
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.5; acc: 0.81
Batch: 640; loss: 0.7; acc: 0.8
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.61; acc: 0.84
Batch: 720; loss: 0.73; acc: 0.8
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.55; acc: 0.88
Batch: 780; loss: 0.68; acc: 0.8
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5189202846425354; val_accuracy: 0.8359872611464968 

The current subspace-distance is: 0.0001284210738958791 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.78
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.61; acc: 0.8
Batch: 160; loss: 0.59; acc: 0.8
Batch: 180; loss: 0.7; acc: 0.73
Batch: 200; loss: 0.75; acc: 0.73
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.81
Batch: 280; loss: 0.72; acc: 0.8
Batch: 300; loss: 0.71; acc: 0.81
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.67; acc: 0.81
Batch: 360; loss: 0.51; acc: 0.83
Batch: 380; loss: 0.73; acc: 0.75
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.58; acc: 0.81
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.58; acc: 0.88
Batch: 540; loss: 0.51; acc: 0.78
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.53; acc: 0.81
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.77; acc: 0.81
Batch: 640; loss: 0.55; acc: 0.78
Batch: 660; loss: 0.58; acc: 0.84
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.57; acc: 0.81
Batch: 720; loss: 0.66; acc: 0.8
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.61; acc: 0.77
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.72; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.94
Val Epoch over. val_loss: 0.5188747723201278; val_accuracy: 0.836484872611465 

The current subspace-distance is: 0.0001304960169363767 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.66; acc: 0.77
Batch: 40; loss: 0.53; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.86; acc: 0.83
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.65; acc: 0.77
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.69; acc: 0.77
Batch: 240; loss: 0.55; acc: 0.78
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.55; acc: 0.81
Batch: 320; loss: 0.72; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.58; acc: 0.73
Batch: 380; loss: 0.6; acc: 0.86
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.58; acc: 0.77
Batch: 460; loss: 0.76; acc: 0.73
Batch: 480; loss: 0.84; acc: 0.75
Batch: 500; loss: 0.71; acc: 0.83
Batch: 520; loss: 0.63; acc: 0.78
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.51; acc: 0.8
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.52; acc: 0.8
Batch: 620; loss: 0.66; acc: 0.8
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.44; acc: 0.92
Batch: 680; loss: 0.6; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.44; acc: 0.83
Batch: 780; loss: 0.65; acc: 0.75
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.92
Val Epoch over. val_loss: 0.5188035087031164; val_accuracy: 0.8367834394904459 

The current subspace-distance is: 0.00012937842984683812 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.92
Batch: 20; loss: 0.73; acc: 0.75
Batch: 40; loss: 0.57; acc: 0.86
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.64; acc: 0.81
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.66; acc: 0.81
Batch: 340; loss: 0.58; acc: 0.8
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.63; acc: 0.8
Batch: 400; loss: 0.85; acc: 0.81
Batch: 420; loss: 0.63; acc: 0.8
Batch: 440; loss: 0.27; acc: 0.95
Batch: 460; loss: 0.74; acc: 0.84
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.62; acc: 0.75
Batch: 520; loss: 0.68; acc: 0.8
Batch: 540; loss: 0.95; acc: 0.73
Batch: 560; loss: 0.56; acc: 0.8
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.76; acc: 0.8
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.7; acc: 0.73
Batch: 680; loss: 0.64; acc: 0.8
Batch: 700; loss: 0.51; acc: 0.81
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.59; acc: 0.8
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.62; acc: 0.77
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.49; acc: 0.78
Batch: 20; loss: 0.66; acc: 0.83
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5193901205328619; val_accuracy: 0.8377786624203821 

The current subspace-distance is: 0.00013209377357270569 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.81; acc: 0.7
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.79; acc: 0.78
Batch: 160; loss: 0.81; acc: 0.77
Batch: 180; loss: 0.56; acc: 0.8
Batch: 200; loss: 0.64; acc: 0.81
Batch: 220; loss: 0.67; acc: 0.75
Batch: 240; loss: 0.84; acc: 0.83
Batch: 260; loss: 1.01; acc: 0.75
Batch: 280; loss: 0.65; acc: 0.8
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.68; acc: 0.78
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.69; acc: 0.78
Batch: 380; loss: 0.57; acc: 0.78
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.62; acc: 0.86
Batch: 440; loss: 0.52; acc: 0.8
Batch: 460; loss: 0.48; acc: 0.84
Batch: 480; loss: 0.65; acc: 0.81
Batch: 500; loss: 0.62; acc: 0.77
Batch: 520; loss: 0.59; acc: 0.78
Batch: 540; loss: 0.67; acc: 0.81
Batch: 560; loss: 0.51; acc: 0.83
Batch: 580; loss: 0.81; acc: 0.8
Batch: 600; loss: 0.72; acc: 0.78
Batch: 620; loss: 0.69; acc: 0.8
Batch: 640; loss: 0.73; acc: 0.75
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.6; acc: 0.86
Batch: 700; loss: 0.82; acc: 0.78
Batch: 720; loss: 0.68; acc: 0.78
Batch: 740; loss: 0.6; acc: 0.83
Batch: 760; loss: 0.64; acc: 0.77
Batch: 780; loss: 0.48; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5179791852926753; val_accuracy: 0.8371815286624203 

The current subspace-distance is: 0.0001327425125055015 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.71; acc: 0.78
Batch: 40; loss: 0.76; acc: 0.84
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.55; acc: 0.8
Batch: 140; loss: 0.8; acc: 0.72
Batch: 160; loss: 0.53; acc: 0.8
Batch: 180; loss: 0.81; acc: 0.72
Batch: 200; loss: 0.54; acc: 0.86
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.65; acc: 0.83
Batch: 260; loss: 0.63; acc: 0.75
Batch: 280; loss: 0.56; acc: 0.81
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.56; acc: 0.8
Batch: 380; loss: 0.75; acc: 0.8
Batch: 400; loss: 0.56; acc: 0.81
Batch: 420; loss: 0.57; acc: 0.84
Batch: 440; loss: 0.9; acc: 0.72
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.59; acc: 0.8
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.53; acc: 0.83
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.87; acc: 0.78
Batch: 660; loss: 0.46; acc: 0.89
Batch: 680; loss: 0.54; acc: 0.8
Batch: 700; loss: 0.55; acc: 0.8
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.55; acc: 0.78
Batch: 760; loss: 0.54; acc: 0.89
Batch: 780; loss: 0.58; acc: 0.78
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.5; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.94
Val Epoch over. val_loss: 0.5190288427339238; val_accuracy: 0.8369824840764332 

The current subspace-distance is: 0.0001339019654551521 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_75_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 21026
elements in E: 4499000
fraction nonzero: 0.004673482996221383
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.17
Batch: 160; loss: 2.31; acc: 0.06
Batch: 180; loss: 2.31; acc: 0.06
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.14
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.11
Batch: 300; loss: 2.27; acc: 0.11
Batch: 320; loss: 2.27; acc: 0.17
Batch: 340; loss: 2.28; acc: 0.12
Batch: 360; loss: 2.27; acc: 0.12
Batch: 380; loss: 2.27; acc: 0.08
Batch: 400; loss: 2.26; acc: 0.16
Batch: 420; loss: 2.26; acc: 0.22
Batch: 440; loss: 2.24; acc: 0.11
Batch: 460; loss: 2.25; acc: 0.2
Batch: 480; loss: 2.24; acc: 0.19
Batch: 500; loss: 2.24; acc: 0.25
Batch: 520; loss: 2.21; acc: 0.28
Batch: 540; loss: 2.19; acc: 0.23
Batch: 560; loss: 2.15; acc: 0.36
Batch: 580; loss: 2.15; acc: 0.25
Batch: 600; loss: 2.07; acc: 0.45
Batch: 620; loss: 2.09; acc: 0.44
Batch: 640; loss: 2.01; acc: 0.33
Batch: 660; loss: 1.91; acc: 0.48
Batch: 680; loss: 1.8; acc: 0.47
Batch: 700; loss: 1.63; acc: 0.59
Batch: 720; loss: 1.56; acc: 0.5
Batch: 740; loss: 1.43; acc: 0.56
Batch: 760; loss: 1.34; acc: 0.59
Batch: 780; loss: 1.38; acc: 0.58
Train Epoch over. train_loss: 2.14; train_accuracy: 0.22 

Batch: 0; loss: 1.52; acc: 0.44
Batch: 20; loss: 1.63; acc: 0.47
Batch: 40; loss: 1.1; acc: 0.67
Batch: 60; loss: 1.25; acc: 0.59
Batch: 80; loss: 1.15; acc: 0.69
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.46; acc: 0.52
Batch: 140; loss: 1.21; acc: 0.55
Val Epoch over. val_loss: 1.3536250188851813; val_accuracy: 0.5365246815286624 

The current subspace-distance is: 8.241988325607963e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.37; acc: 0.53
Batch: 20; loss: 1.26; acc: 0.64
Batch: 40; loss: 1.19; acc: 0.59
Batch: 60; loss: 1.21; acc: 0.59
Batch: 80; loss: 1.03; acc: 0.7
Batch: 100; loss: 1.13; acc: 0.62
Batch: 120; loss: 0.91; acc: 0.77
Batch: 140; loss: 1.05; acc: 0.67
Batch: 160; loss: 0.98; acc: 0.7
Batch: 180; loss: 1.27; acc: 0.55
Batch: 200; loss: 0.88; acc: 0.78
Batch: 220; loss: 0.92; acc: 0.7
Batch: 240; loss: 0.87; acc: 0.77
Batch: 260; loss: 1.23; acc: 0.62
Batch: 280; loss: 0.99; acc: 0.66
Batch: 300; loss: 0.83; acc: 0.67
Batch: 320; loss: 1.02; acc: 0.62
Batch: 340; loss: 1.01; acc: 0.69
Batch: 360; loss: 0.83; acc: 0.7
Batch: 380; loss: 0.85; acc: 0.7
Batch: 400; loss: 1.18; acc: 0.59
Batch: 420; loss: 0.78; acc: 0.77
Batch: 440; loss: 0.78; acc: 0.8
Batch: 460; loss: 0.83; acc: 0.67
Batch: 480; loss: 0.87; acc: 0.67
Batch: 500; loss: 0.94; acc: 0.62
Batch: 520; loss: 0.59; acc: 0.83
Batch: 540; loss: 0.87; acc: 0.72
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.61; acc: 0.8
Batch: 600; loss: 0.83; acc: 0.69
Batch: 620; loss: 1.02; acc: 0.69
Batch: 640; loss: 1.58; acc: 0.59
Batch: 660; loss: 0.71; acc: 0.77
Batch: 680; loss: 0.83; acc: 0.7
Batch: 700; loss: 0.77; acc: 0.77
Batch: 720; loss: 0.7; acc: 0.78
Batch: 740; loss: 0.72; acc: 0.72
Batch: 760; loss: 0.78; acc: 0.7
Batch: 780; loss: 0.77; acc: 0.78
Train Epoch over. train_loss: 0.93; train_accuracy: 0.7 

Batch: 0; loss: 0.95; acc: 0.64
Batch: 20; loss: 0.92; acc: 0.73
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.67; acc: 0.77
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 1.11; acc: 0.64
Batch: 140; loss: 0.53; acc: 0.84
Val Epoch over. val_loss: 0.8108207317674236; val_accuracy: 0.727906050955414 

The current subspace-distance is: 1.8432057913742028e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.67
Batch: 20; loss: 0.62; acc: 0.86
Batch: 40; loss: 0.7; acc: 0.78
Batch: 60; loss: 0.81; acc: 0.77
Batch: 80; loss: 0.72; acc: 0.78
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.8; acc: 0.75
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 0.96; acc: 0.64
Batch: 180; loss: 0.65; acc: 0.66
Batch: 200; loss: 0.62; acc: 0.8
Batch: 220; loss: 0.74; acc: 0.8
Batch: 240; loss: 1.05; acc: 0.69
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.98; acc: 0.67
Batch: 300; loss: 0.72; acc: 0.8
Batch: 320; loss: 0.79; acc: 0.78
Batch: 340; loss: 0.75; acc: 0.77
Batch: 360; loss: 0.67; acc: 0.81
Batch: 380; loss: 0.68; acc: 0.81
Batch: 400; loss: 0.6; acc: 0.8
Batch: 420; loss: 0.72; acc: 0.83
Batch: 440; loss: 0.72; acc: 0.8
Batch: 460; loss: 1.27; acc: 0.58
Batch: 480; loss: 0.77; acc: 0.8
Batch: 500; loss: 0.75; acc: 0.73
Batch: 520; loss: 0.91; acc: 0.7
Batch: 540; loss: 0.61; acc: 0.84
Batch: 560; loss: 0.66; acc: 0.84
Batch: 580; loss: 0.83; acc: 0.78
Batch: 600; loss: 0.68; acc: 0.73
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.49; acc: 0.83
Batch: 660; loss: 0.86; acc: 0.72
Batch: 680; loss: 0.73; acc: 0.7
Batch: 700; loss: 0.84; acc: 0.73
Batch: 720; loss: 0.8; acc: 0.77
Batch: 740; loss: 0.7; acc: 0.78
Batch: 760; loss: 0.63; acc: 0.73
Batch: 780; loss: 0.72; acc: 0.73
Train Epoch over. train_loss: 0.74; train_accuracy: 0.76 

Batch: 0; loss: 1.82; acc: 0.47
Batch: 20; loss: 1.74; acc: 0.44
Batch: 40; loss: 1.31; acc: 0.59
Batch: 60; loss: 1.55; acc: 0.61
Batch: 80; loss: 1.4; acc: 0.61
Batch: 100; loss: 1.65; acc: 0.59
Batch: 120; loss: 2.14; acc: 0.44
Batch: 140; loss: 1.33; acc: 0.53
Val Epoch over. val_loss: 1.5604919802611041; val_accuracy: 0.5612062101910829 

The current subspace-distance is: 2.592002238088753e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.61; acc: 0.5
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.83; acc: 0.78
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.93; acc: 0.66
Batch: 100; loss: 0.74; acc: 0.78
Batch: 120; loss: 1.07; acc: 0.69
Batch: 140; loss: 0.53; acc: 0.89
Batch: 160; loss: 0.69; acc: 0.81
Batch: 180; loss: 1.17; acc: 0.62
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.61; acc: 0.81
Batch: 240; loss: 0.68; acc: 0.69
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.53; acc: 0.89
Batch: 300; loss: 0.73; acc: 0.77
Batch: 320; loss: 1.04; acc: 0.59
Batch: 340; loss: 1.12; acc: 0.66
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.82; acc: 0.73
Batch: 400; loss: 0.6; acc: 0.81
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.67; acc: 0.83
Batch: 460; loss: 1.01; acc: 0.62
Batch: 480; loss: 0.76; acc: 0.73
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.85; acc: 0.75
Batch: 540; loss: 1.18; acc: 0.66
Batch: 560; loss: 0.61; acc: 0.81
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.71; acc: 0.69
Batch: 640; loss: 0.7; acc: 0.77
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.79; acc: 0.77
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 1.0; acc: 0.72
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.83; acc: 0.77
Batch: 780; loss: 0.48; acc: 0.84
Train Epoch over. train_loss: 0.72; train_accuracy: 0.77 

Batch: 0; loss: 1.32; acc: 0.5
Batch: 20; loss: 1.05; acc: 0.7
Batch: 40; loss: 0.75; acc: 0.7
Batch: 60; loss: 1.32; acc: 0.56
Batch: 80; loss: 0.84; acc: 0.75
Batch: 100; loss: 1.0; acc: 0.69
Batch: 120; loss: 1.68; acc: 0.47
Batch: 140; loss: 0.78; acc: 0.72
Val Epoch over. val_loss: 1.104924045740419; val_accuracy: 0.637937898089172 

The current subspace-distance is: 3.175933670718223e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.64
Batch: 20; loss: 0.68; acc: 0.8
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.74; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.8
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.82; acc: 0.77
Batch: 160; loss: 0.62; acc: 0.84
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.6; acc: 0.81
Batch: 220; loss: 0.79; acc: 0.75
Batch: 240; loss: 0.49; acc: 0.8
Batch: 260; loss: 0.61; acc: 0.83
Batch: 280; loss: 0.65; acc: 0.77
Batch: 300; loss: 0.77; acc: 0.75
Batch: 320; loss: 1.08; acc: 0.75
Batch: 340; loss: 0.61; acc: 0.86
Batch: 360; loss: 0.99; acc: 0.69
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.85; acc: 0.73
Batch: 440; loss: 0.59; acc: 0.78
Batch: 460; loss: 0.8; acc: 0.72
Batch: 480; loss: 0.72; acc: 0.77
Batch: 500; loss: 0.58; acc: 0.78
Batch: 520; loss: 0.5; acc: 0.77
Batch: 540; loss: 0.81; acc: 0.8
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.49; acc: 0.89
Batch: 620; loss: 0.74; acc: 0.81
Batch: 640; loss: 0.79; acc: 0.73
Batch: 660; loss: 0.76; acc: 0.77
Batch: 680; loss: 0.71; acc: 0.75
Batch: 700; loss: 0.83; acc: 0.8
Batch: 720; loss: 0.8; acc: 0.72
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 0.72; acc: 0.75
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.75
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.98; acc: 0.7
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.5808022174106282; val_accuracy: 0.8148885350318471 

The current subspace-distance is: 3.8809317629784346e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.86; acc: 0.73
Batch: 40; loss: 0.63; acc: 0.75
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.76; acc: 0.72
Batch: 100; loss: 0.7; acc: 0.73
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.79; acc: 0.75
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.74; acc: 0.77
Batch: 260; loss: 0.59; acc: 0.81
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.77; acc: 0.7
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.62; acc: 0.78
Batch: 380; loss: 0.73; acc: 0.75
Batch: 400; loss: 0.64; acc: 0.81
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.5; acc: 0.83
Batch: 460; loss: 0.68; acc: 0.78
Batch: 480; loss: 0.87; acc: 0.7
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.57; acc: 0.78
Batch: 540; loss: 0.6; acc: 0.75
Batch: 560; loss: 1.11; acc: 0.8
Batch: 580; loss: 0.53; acc: 0.8
Batch: 600; loss: 0.96; acc: 0.7
Batch: 620; loss: 0.89; acc: 0.78
Batch: 640; loss: 0.41; acc: 0.84
Batch: 660; loss: 1.13; acc: 0.64
Batch: 680; loss: 0.87; acc: 0.72
Batch: 700; loss: 0.71; acc: 0.75
Batch: 720; loss: 0.57; acc: 0.78
Batch: 740; loss: 0.46; acc: 0.86
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.6; acc: 0.86
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 1.08; acc: 0.67
Batch: 20; loss: 0.86; acc: 0.67
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.88; acc: 0.73
Batch: 80; loss: 0.66; acc: 0.8
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 1.19; acc: 0.67
Batch: 140; loss: 0.39; acc: 0.84
Val Epoch over. val_loss: 0.7089642726691665; val_accuracy: 0.7676154458598726 

The current subspace-distance is: 4.3123087380081415e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.72
Batch: 20; loss: 0.96; acc: 0.67
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.76; acc: 0.78
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.71; acc: 0.75
Batch: 160; loss: 0.53; acc: 0.81
Batch: 180; loss: 0.88; acc: 0.7
Batch: 200; loss: 0.52; acc: 0.83
Batch: 220; loss: 0.7; acc: 0.78
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.5; acc: 0.84
Batch: 280; loss: 0.62; acc: 0.77
Batch: 300; loss: 0.52; acc: 0.81
Batch: 320; loss: 0.85; acc: 0.73
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.69; acc: 0.75
Batch: 380; loss: 0.89; acc: 0.66
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.54; acc: 0.8
Batch: 440; loss: 0.82; acc: 0.69
Batch: 460; loss: 0.57; acc: 0.81
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.77; acc: 0.67
Batch: 520; loss: 0.57; acc: 0.8
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.63; acc: 0.83
Batch: 580; loss: 0.74; acc: 0.73
Batch: 600; loss: 0.71; acc: 0.72
Batch: 620; loss: 0.65; acc: 0.73
Batch: 640; loss: 0.53; acc: 0.83
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.8; acc: 0.75
Batch: 700; loss: 0.86; acc: 0.72
Batch: 720; loss: 0.85; acc: 0.69
Batch: 740; loss: 0.48; acc: 0.83
Batch: 760; loss: 0.67; acc: 0.77
Batch: 780; loss: 1.06; acc: 0.72
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 1.03; acc: 0.67
Batch: 20; loss: 0.8; acc: 0.73
Batch: 40; loss: 0.43; acc: 0.81
Batch: 60; loss: 1.03; acc: 0.7
Batch: 80; loss: 0.53; acc: 0.78
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 1.27; acc: 0.62
Batch: 140; loss: 0.63; acc: 0.7
Val Epoch over. val_loss: 0.7910995356216552; val_accuracy: 0.7352707006369427 

The current subspace-distance is: 4.597328006639145e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.72
Batch: 20; loss: 0.71; acc: 0.83
Batch: 40; loss: 0.79; acc: 0.7
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.6; acc: 0.75
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 0.85; acc: 0.77
Batch: 180; loss: 0.47; acc: 0.91
Batch: 200; loss: 0.71; acc: 0.75
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.78
Batch: 260; loss: 0.85; acc: 0.77
Batch: 280; loss: 0.75; acc: 0.77
Batch: 300; loss: 0.95; acc: 0.64
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.66; acc: 0.75
Batch: 360; loss: 0.9; acc: 0.72
Batch: 380; loss: 0.48; acc: 0.88
Batch: 400; loss: 0.79; acc: 0.8
Batch: 420; loss: 0.6; acc: 0.84
Batch: 440; loss: 0.78; acc: 0.73
Batch: 460; loss: 0.87; acc: 0.72
Batch: 480; loss: 0.62; acc: 0.86
Batch: 500; loss: 0.64; acc: 0.77
Batch: 520; loss: 0.53; acc: 0.81
Batch: 540; loss: 0.48; acc: 0.78
Batch: 560; loss: 0.83; acc: 0.67
Batch: 580; loss: 0.71; acc: 0.73
Batch: 600; loss: 1.45; acc: 0.61
Batch: 620; loss: 0.55; acc: 0.89
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 1.31; acc: 0.55
Batch: 680; loss: 0.7; acc: 0.77
Batch: 700; loss: 0.69; acc: 0.75
Batch: 720; loss: 0.74; acc: 0.77
Batch: 740; loss: 0.9; acc: 0.72
Batch: 760; loss: 0.95; acc: 0.75
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 1.03; acc: 0.67
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.95; acc: 0.7
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.85; acc: 0.72
Batch: 120; loss: 1.34; acc: 0.59
Batch: 140; loss: 0.36; acc: 0.86
Val Epoch over. val_loss: 0.787243726337032; val_accuracy: 0.7412420382165605 

The current subspace-distance is: 5.116921602166258e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.82; acc: 0.7
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 0.71; acc: 0.73
Batch: 120; loss: 0.74; acc: 0.83
Batch: 140; loss: 0.58; acc: 0.8
Batch: 160; loss: 0.89; acc: 0.77
Batch: 180; loss: 0.79; acc: 0.78
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.8
Batch: 240; loss: 0.63; acc: 0.75
Batch: 260; loss: 0.66; acc: 0.81
Batch: 280; loss: 1.17; acc: 0.61
Batch: 300; loss: 0.57; acc: 0.88
Batch: 320; loss: 0.62; acc: 0.77
Batch: 340; loss: 1.06; acc: 0.7
Batch: 360; loss: 0.96; acc: 0.67
Batch: 380; loss: 0.66; acc: 0.72
Batch: 400; loss: 0.43; acc: 0.81
Batch: 420; loss: 0.89; acc: 0.77
Batch: 440; loss: 0.54; acc: 0.86
Batch: 460; loss: 0.82; acc: 0.67
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.78; acc: 0.72
Batch: 520; loss: 0.55; acc: 0.78
Batch: 540; loss: 0.63; acc: 0.72
Batch: 560; loss: 1.19; acc: 0.66
Batch: 580; loss: 0.91; acc: 0.69
Batch: 600; loss: 0.63; acc: 0.86
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.71; acc: 0.77
Batch: 680; loss: 0.78; acc: 0.72
Batch: 700; loss: 0.75; acc: 0.78
Batch: 720; loss: 0.68; acc: 0.75
Batch: 740; loss: 1.06; acc: 0.72
Batch: 760; loss: 0.68; acc: 0.8
Batch: 780; loss: 0.88; acc: 0.69
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 1.35; acc: 0.61
Batch: 20; loss: 1.48; acc: 0.59
Batch: 40; loss: 0.83; acc: 0.73
Batch: 60; loss: 1.24; acc: 0.75
Batch: 80; loss: 0.74; acc: 0.8
Batch: 100; loss: 1.13; acc: 0.78
Batch: 120; loss: 1.23; acc: 0.64
Batch: 140; loss: 0.78; acc: 0.67
Val Epoch over. val_loss: 1.1221759543297396; val_accuracy: 0.6751592356687898 

The current subspace-distance is: 5.602081000688486e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.28; acc: 0.66
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.7; acc: 0.75
Batch: 80; loss: 0.63; acc: 0.78
Batch: 100; loss: 0.67; acc: 0.66
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 0.52; acc: 0.77
Batch: 180; loss: 0.69; acc: 0.75
Batch: 200; loss: 0.96; acc: 0.73
Batch: 220; loss: 0.81; acc: 0.75
Batch: 240; loss: 0.84; acc: 0.72
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.98; acc: 0.69
Batch: 300; loss: 0.85; acc: 0.7
Batch: 320; loss: 0.74; acc: 0.73
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.75; acc: 0.78
Batch: 420; loss: 0.61; acc: 0.83
Batch: 440; loss: 0.96; acc: 0.69
Batch: 460; loss: 0.81; acc: 0.7
Batch: 480; loss: 0.69; acc: 0.83
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.55; acc: 0.8
Batch: 540; loss: 0.72; acc: 0.72
Batch: 560; loss: 0.66; acc: 0.75
Batch: 580; loss: 0.78; acc: 0.77
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 0.62; acc: 0.83
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.55; acc: 0.81
Batch: 680; loss: 0.94; acc: 0.67
Batch: 700; loss: 0.7; acc: 0.77
Batch: 720; loss: 0.77; acc: 0.75
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.72; acc: 0.78
Batch: 780; loss: 0.75; acc: 0.75
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

Batch: 0; loss: 0.9; acc: 0.7
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.83; acc: 0.75
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.94; acc: 0.69
Batch: 140; loss: 0.4; acc: 0.84
Val Epoch over. val_loss: 0.5821239589505894; val_accuracy: 0.8113057324840764 

The current subspace-distance is: 6.019544889568351e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.9; acc: 0.77
Batch: 40; loss: 0.65; acc: 0.75
Batch: 60; loss: 0.54; acc: 0.77
Batch: 80; loss: 0.64; acc: 0.77
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.64; acc: 0.77
Batch: 160; loss: 0.57; acc: 0.77
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.7; acc: 0.81
Batch: 240; loss: 0.58; acc: 0.86
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.73; acc: 0.78
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.81
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.57; acc: 0.78
Batch: 480; loss: 0.47; acc: 0.83
Batch: 500; loss: 0.59; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.75; acc: 0.8
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.62; acc: 0.81
Batch: 600; loss: 0.44; acc: 0.83
Batch: 620; loss: 0.71; acc: 0.81
Batch: 640; loss: 0.66; acc: 0.78
Batch: 660; loss: 0.42; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.83
Batch: 780; loss: 0.8; acc: 0.73
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

Batch: 0; loss: 0.87; acc: 0.77
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.5272715949708489; val_accuracy: 0.8335987261146497 

The current subspace-distance is: 6.267334538279101e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.66; acc: 0.81
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.6; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.57; acc: 0.83
Batch: 300; loss: 0.64; acc: 0.81
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.63; acc: 0.8
Batch: 360; loss: 0.53; acc: 0.8
Batch: 380; loss: 0.59; acc: 0.83
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.72; acc: 0.8
Batch: 480; loss: 0.58; acc: 0.8
Batch: 500; loss: 0.6; acc: 0.84
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.61; acc: 0.81
Batch: 580; loss: 0.59; acc: 0.77
Batch: 600; loss: 0.75; acc: 0.8
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.66; acc: 0.77
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.57; acc: 0.81
Batch: 720; loss: 0.75; acc: 0.75
Batch: 740; loss: 0.62; acc: 0.83
Batch: 760; loss: 0.66; acc: 0.83
Batch: 780; loss: 0.62; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.79; acc: 0.77
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.96; acc: 0.73
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 0.36; acc: 0.86
Val Epoch over. val_loss: 0.6502412701867948; val_accuracy: 0.7879179936305732 

The current subspace-distance is: 6.783799472032115e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.69; acc: 0.84
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.72; acc: 0.77
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.48; acc: 0.83
Batch: 280; loss: 0.62; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.85; acc: 0.75
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.66; acc: 0.8
Batch: 380; loss: 0.57; acc: 0.73
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.64; acc: 0.8
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.69; acc: 0.78
Batch: 520; loss: 0.55; acc: 0.78
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.55; acc: 0.8
Batch: 600; loss: 0.59; acc: 0.83
Batch: 620; loss: 0.55; acc: 0.86
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.64; acc: 0.8
Batch: 760; loss: 0.54; acc: 0.81
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.57; acc: 0.78
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.81; acc: 0.77
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.79; acc: 0.75
Batch: 140; loss: 0.27; acc: 0.94
Val Epoch over. val_loss: 0.5549370842944285; val_accuracy: 0.8255374203821656 

The current subspace-distance is: 6.968992965994403e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.7; acc: 0.81
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.77; acc: 0.78
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.83
Batch: 180; loss: 0.66; acc: 0.78
Batch: 200; loss: 0.59; acc: 0.8
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.63; acc: 0.83
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.67; acc: 0.8
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.71; acc: 0.81
Batch: 440; loss: 0.7; acc: 0.72
Batch: 460; loss: 0.67; acc: 0.78
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.6; acc: 0.83
Batch: 560; loss: 0.59; acc: 0.77
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.67; acc: 0.73
Batch: 660; loss: 0.51; acc: 0.83
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.72; acc: 0.78
Batch: 760; loss: 0.48; acc: 0.81
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.65; acc: 0.75
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.85; acc: 0.73
Batch: 140; loss: 0.28; acc: 0.89
Val Epoch over. val_loss: 0.5153601169586182; val_accuracy: 0.8351910828025477 

The current subspace-distance is: 7.384717173408717e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.77; acc: 0.75
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.75; acc: 0.75
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.51; acc: 0.86
Batch: 260; loss: 0.61; acc: 0.8
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.82; acc: 0.73
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.76; acc: 0.78
Batch: 400; loss: 0.49; acc: 0.83
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.79; acc: 0.77
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.59; acc: 0.81
Batch: 540; loss: 0.63; acc: 0.8
Batch: 560; loss: 0.92; acc: 0.7
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.66; acc: 0.83
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.67; acc: 0.78
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.55; acc: 0.78
Batch: 720; loss: 0.58; acc: 0.78
Batch: 740; loss: 0.81; acc: 0.8
Batch: 760; loss: 0.56; acc: 0.81
Batch: 780; loss: 0.58; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.9; acc: 0.73
Batch: 20; loss: 0.49; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.5189717457552624; val_accuracy: 0.8341958598726115 

The current subspace-distance is: 7.651520718354732e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.81
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.43; acc: 0.83
Batch: 200; loss: 0.54; acc: 0.8
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.33; acc: 0.84
Batch: 260; loss: 0.53; acc: 0.84
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 1.02; acc: 0.73
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.83; acc: 0.7
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.76; acc: 0.78
Batch: 460; loss: 0.65; acc: 0.77
Batch: 480; loss: 0.54; acc: 0.81
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.72; acc: 0.78
Batch: 540; loss: 0.71; acc: 0.77
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.69; acc: 0.77
Batch: 680; loss: 0.64; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.7; acc: 0.77
Batch: 780; loss: 0.47; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.72
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.5078514386324366; val_accuracy: 0.8395700636942676 

The current subspace-distance is: 7.843815546948463e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.69; acc: 0.83
Batch: 80; loss: 0.67; acc: 0.8
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.66; acc: 0.83
Batch: 180; loss: 0.76; acc: 0.73
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.69; acc: 0.81
Batch: 240; loss: 0.51; acc: 0.83
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.87; acc: 0.78
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.51; acc: 0.81
Batch: 360; loss: 0.69; acc: 0.8
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.71; acc: 0.77
Batch: 460; loss: 0.62; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.71; acc: 0.73
Batch: 540; loss: 0.99; acc: 0.77
Batch: 560; loss: 0.59; acc: 0.81
Batch: 580; loss: 0.51; acc: 0.81
Batch: 600; loss: 0.92; acc: 0.7
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.53; acc: 0.86
Batch: 660; loss: 0.48; acc: 0.81
Batch: 680; loss: 0.76; acc: 0.72
Batch: 700; loss: 0.51; acc: 0.8
Batch: 720; loss: 0.43; acc: 0.83
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 1.27; acc: 0.59
Batch: 20; loss: 0.84; acc: 0.73
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.89; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.88; acc: 0.75
Batch: 120; loss: 1.36; acc: 0.56
Batch: 140; loss: 0.57; acc: 0.75
Val Epoch over. val_loss: 0.8529117338976283; val_accuracy: 0.71984474522293 

The current subspace-distance is: 8.068435272434726e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.05; acc: 0.73
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.67; acc: 0.77
Batch: 80; loss: 0.55; acc: 0.77
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.53; acc: 0.8
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.46; acc: 0.83
Batch: 180; loss: 0.55; acc: 0.81
Batch: 200; loss: 0.44; acc: 0.83
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.59; acc: 0.83
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.8
Batch: 320; loss: 0.65; acc: 0.72
Batch: 340; loss: 0.68; acc: 0.73
Batch: 360; loss: 0.76; acc: 0.8
Batch: 380; loss: 0.72; acc: 0.78
Batch: 400; loss: 0.45; acc: 0.83
Batch: 420; loss: 0.43; acc: 0.83
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.66; acc: 0.81
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.75; acc: 0.77
Batch: 520; loss: 0.6; acc: 0.78
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.55; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.55; acc: 0.77
Batch: 620; loss: 0.56; acc: 0.77
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.68; acc: 0.73
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.49; acc: 0.89
Batch: 740; loss: 0.62; acc: 0.81
Batch: 760; loss: 0.85; acc: 0.8
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 1.01; acc: 0.73
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.78; acc: 0.7
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.5441208557718119; val_accuracy: 0.8290207006369427 

The current subspace-distance is: 8.278543828055263e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.68; acc: 0.84
Batch: 20; loss: 0.62; acc: 0.83
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.57; acc: 0.88
Batch: 140; loss: 0.65; acc: 0.83
Batch: 160; loss: 0.83; acc: 0.73
Batch: 180; loss: 0.86; acc: 0.7
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.66; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.49; acc: 0.81
Batch: 280; loss: 0.84; acc: 0.7
Batch: 300; loss: 0.71; acc: 0.81
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.69; acc: 0.81
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.75; acc: 0.75
Batch: 400; loss: 0.51; acc: 0.81
Batch: 420; loss: 0.63; acc: 0.77
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.86; acc: 0.73
Batch: 480; loss: 0.43; acc: 0.84
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.77; acc: 0.81
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.62; acc: 0.86
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.57; acc: 0.86
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.74; acc: 0.8
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

Batch: 0; loss: 1.08; acc: 0.72
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 0.28; acc: 0.86
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.67; acc: 0.77
Batch: 120; loss: 0.99; acc: 0.69
Batch: 140; loss: 0.42; acc: 0.81
Val Epoch over. val_loss: 0.7246573116559132; val_accuracy: 0.7767714968152867 

The current subspace-distance is: 8.558564877603203e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.75; acc: 0.73
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.59; acc: 0.81
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.45; acc: 0.78
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.53; acc: 0.8
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.53; acc: 0.81
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.58; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.86; acc: 0.73
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.72; acc: 0.8
Batch: 520; loss: 0.61; acc: 0.84
Batch: 540; loss: 0.67; acc: 0.77
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.48; acc: 0.8
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.69; acc: 0.78
Batch: 680; loss: 0.55; acc: 0.78
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.66; acc: 0.86
Batch: 740; loss: 0.59; acc: 0.77
Batch: 760; loss: 0.6; acc: 0.84
Batch: 780; loss: 0.52; acc: 0.77
Train Epoch over. train_loss: 0.55; train_accuracy: 0.82 

Batch: 0; loss: 1.0; acc: 0.61
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.5926372049150953; val_accuracy: 0.8053343949044586 

The current subspace-distance is: 8.722696657059714e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.63; acc: 0.8
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.62; acc: 0.77
Batch: 200; loss: 0.62; acc: 0.8
Batch: 220; loss: 0.64; acc: 0.75
Batch: 240; loss: 0.58; acc: 0.8
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.81; acc: 0.78
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.39; acc: 0.84
Batch: 420; loss: 0.49; acc: 0.81
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.65; acc: 0.77
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.53; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.56; acc: 0.81
Batch: 660; loss: 0.48; acc: 0.81
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.53; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.65; acc: 0.81
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.83; acc: 0.7
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.94; acc: 0.67
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.5480021561027333; val_accuracy: 0.8226512738853503 

The current subspace-distance is: 8.996514225145802e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.46; acc: 0.83
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.54; acc: 0.78
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.58; acc: 0.73
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.64; acc: 0.78
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.66; acc: 0.8
Batch: 360; loss: 0.92; acc: 0.77
Batch: 380; loss: 0.64; acc: 0.8
Batch: 400; loss: 0.74; acc: 0.77
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.49; acc: 0.83
Batch: 540; loss: 0.51; acc: 0.84
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.52; acc: 0.84
Batch: 600; loss: 0.43; acc: 0.91
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.52; acc: 0.81
Batch: 660; loss: 0.75; acc: 0.73
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.63; acc: 0.8
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.88
Val Epoch over. val_loss: 0.47962797352462816; val_accuracy: 0.8472332802547771 

The current subspace-distance is: 9.227505506714806e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.59; acc: 0.78
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.67; acc: 0.77
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.56; acc: 0.89
Batch: 140; loss: 0.68; acc: 0.78
Batch: 160; loss: 0.55; acc: 0.83
Batch: 180; loss: 0.71; acc: 0.77
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.61; acc: 0.84
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.64; acc: 0.81
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.51; acc: 0.81
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.55; acc: 0.81
Batch: 480; loss: 0.7; acc: 0.73
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.66; acc: 0.75
Batch: 540; loss: 0.5; acc: 0.81
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.45; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.54; acc: 0.86
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.77; acc: 0.8
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.53; acc: 0.78
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.79; acc: 0.72
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.48557150439851604; val_accuracy: 0.8473328025477707 

The current subspace-distance is: 9.418504487257451e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.81
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.51; acc: 0.81
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.59; acc: 0.83
Batch: 220; loss: 0.59; acc: 0.81
Batch: 240; loss: 0.69; acc: 0.8
Batch: 260; loss: 0.48; acc: 0.84
Batch: 280; loss: 0.63; acc: 0.75
Batch: 300; loss: 0.72; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.79; acc: 0.67
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.4; acc: 0.84
Batch: 480; loss: 0.55; acc: 0.83
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.66; acc: 0.83
Batch: 580; loss: 0.66; acc: 0.81
Batch: 600; loss: 0.66; acc: 0.84
Batch: 620; loss: 0.7; acc: 0.81
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.71; acc: 0.77
Batch: 680; loss: 0.6; acc: 0.8
Batch: 700; loss: 0.64; acc: 0.77
Batch: 720; loss: 0.69; acc: 0.81
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.72; acc: 0.78
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.7
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4905828452034361; val_accuracy: 0.8449442675159236 

The current subspace-distance is: 9.50977555476129e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.66; acc: 0.77
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.48; acc: 0.83
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.61; acc: 0.78
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.59; acc: 0.86
Batch: 200; loss: 0.47; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.58; acc: 0.81
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.83
Batch: 320; loss: 0.51; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.44; acc: 0.81
Batch: 380; loss: 0.57; acc: 0.75
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.51; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.81
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.4; acc: 0.83
Batch: 520; loss: 0.51; acc: 0.83
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.58; acc: 0.8
Batch: 580; loss: 0.74; acc: 0.8
Batch: 600; loss: 0.44; acc: 0.86
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.49; acc: 0.89
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.57; acc: 0.83
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.48; acc: 0.78
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.79; acc: 0.77
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.7
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.49577238652736516; val_accuracy: 0.8419585987261147 

The current subspace-distance is: 9.75507718976587e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.56; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.73; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.43; acc: 0.84
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 0.6; acc: 0.8
Batch: 240; loss: 0.75; acc: 0.81
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.72; acc: 0.78
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.57; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.57; acc: 0.84
Batch: 440; loss: 0.59; acc: 0.8
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.83
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.54; acc: 0.8
Batch: 560; loss: 0.73; acc: 0.8
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.55; acc: 0.81
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.6; acc: 0.75
Batch: 680; loss: 0.61; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.81
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.4824928386006386; val_accuracy: 0.8471337579617835 

The current subspace-distance is: 0.00010056736937258393 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.48; acc: 0.81
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 0.47; acc: 0.8
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.65; acc: 0.8
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.57; acc: 0.78
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.65; acc: 0.88
Batch: 460; loss: 0.75; acc: 0.77
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.68; acc: 0.81
Batch: 520; loss: 0.67; acc: 0.78
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.61; acc: 0.8
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.84
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.51; acc: 0.81
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.51; acc: 0.84
Batch: 740; loss: 0.51; acc: 0.8
Batch: 760; loss: 0.59; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.4866280158993545; val_accuracy: 0.8457404458598726 

The current subspace-distance is: 0.00010414851567475125 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.53; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.5; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.67; acc: 0.81
Batch: 240; loss: 0.58; acc: 0.86
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.38; acc: 0.84
Batch: 340; loss: 0.65; acc: 0.8
Batch: 360; loss: 0.44; acc: 0.83
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.59; acc: 0.78
Batch: 420; loss: 0.67; acc: 0.77
Batch: 440; loss: 0.63; acc: 0.8
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.74; acc: 0.75
Batch: 500; loss: 0.55; acc: 0.8
Batch: 520; loss: 0.53; acc: 0.78
Batch: 540; loss: 0.82; acc: 0.81
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.78; acc: 0.8
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.91
Batch: 640; loss: 0.56; acc: 0.84
Batch: 660; loss: 0.59; acc: 0.78
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.65; acc: 0.8
Batch: 720; loss: 0.63; acc: 0.8
Batch: 740; loss: 0.73; acc: 0.78
Batch: 760; loss: 0.69; acc: 0.81
Batch: 780; loss: 0.67; acc: 0.78
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.74; acc: 0.78
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.69
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.5137063524905284; val_accuracy: 0.8336982484076433 

The current subspace-distance is: 0.0001067276461981237 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.68; acc: 0.77
Batch: 40; loss: 0.6; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.75; acc: 0.81
Batch: 160; loss: 0.46; acc: 0.83
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.81
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.77; acc: 0.81
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.49; acc: 0.88
Batch: 360; loss: 0.51; acc: 0.81
Batch: 380; loss: 0.48; acc: 0.83
Batch: 400; loss: 0.69; acc: 0.73
Batch: 420; loss: 0.5; acc: 0.83
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.57; acc: 0.86
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.47; acc: 0.81
Batch: 540; loss: 0.41; acc: 0.83
Batch: 560; loss: 0.38; acc: 0.92
Batch: 580; loss: 0.51; acc: 0.81
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.55; acc: 0.88
Batch: 680; loss: 0.55; acc: 0.8
Batch: 700; loss: 0.69; acc: 0.83
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.81
Batch: 760; loss: 0.55; acc: 0.83
Batch: 780; loss: 0.53; acc: 0.8
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.4782195268732727; val_accuracy: 0.8506170382165605 

The current subspace-distance is: 0.00011149015335831791 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.98; acc: 0.72
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.78
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.84; acc: 0.67
Batch: 100; loss: 0.54; acc: 0.8
Batch: 120; loss: 0.61; acc: 0.77
Batch: 140; loss: 0.72; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.78
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.56; acc: 0.8
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.58; acc: 0.88
Batch: 340; loss: 0.79; acc: 0.72
Batch: 360; loss: 0.62; acc: 0.8
Batch: 380; loss: 0.74; acc: 0.78
Batch: 400; loss: 0.48; acc: 0.81
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.51; acc: 0.8
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.79; acc: 0.73
Batch: 580; loss: 0.79; acc: 0.77
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.45; acc: 0.8
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.56; acc: 0.8
Batch: 700; loss: 0.38; acc: 0.83
Batch: 720; loss: 0.67; acc: 0.78
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.69; acc: 0.78
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.74; acc: 0.78
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.69
Batch: 140; loss: 0.22; acc: 0.89
Val Epoch over. val_loss: 0.49664213674463287; val_accuracy: 0.8415605095541401 

The current subspace-distance is: 0.00011326526146149263 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.81
Batch: 20; loss: 0.72; acc: 0.78
Batch: 40; loss: 0.49; acc: 0.81
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.77; acc: 0.8
Batch: 100; loss: 0.89; acc: 0.75
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.55; acc: 0.84
Batch: 160; loss: 0.61; acc: 0.78
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.54; acc: 0.77
Batch: 220; loss: 0.4; acc: 0.83
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.45; acc: 0.81
Batch: 300; loss: 0.49; acc: 0.81
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.83
Batch: 420; loss: 0.66; acc: 0.77
Batch: 440; loss: 0.7; acc: 0.8
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.63; acc: 0.75
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.48; acc: 0.81
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.73; acc: 0.8
Batch: 620; loss: 0.64; acc: 0.83
Batch: 640; loss: 0.62; acc: 0.86
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.48; acc: 0.89
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 0.38; acc: 0.92
Batch: 780; loss: 0.72; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.75
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.91
Val Epoch over. val_loss: 0.47986088389424003; val_accuracy: 0.847531847133758 

The current subspace-distance is: 0.00011505474685691297 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.66; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.86
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.86
Batch: 240; loss: 0.63; acc: 0.84
Batch: 260; loss: 0.94; acc: 0.73
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.67; acc: 0.78
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.57; acc: 0.84
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.59; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.86
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.59; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.63; acc: 0.84
Batch: 560; loss: 0.73; acc: 0.75
Batch: 580; loss: 0.48; acc: 0.89
Batch: 600; loss: 0.58; acc: 0.8
Batch: 620; loss: 0.64; acc: 0.83
Batch: 640; loss: 0.45; acc: 0.83
Batch: 660; loss: 0.38; acc: 0.84
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.54; acc: 0.83
Batch: 780; loss: 0.63; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.81; acc: 0.73
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.72
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.47424427111437367; val_accuracy: 0.849422770700637 

The current subspace-distance is: 0.00011599223216762766 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.72
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.58; acc: 0.78
Batch: 60; loss: 0.66; acc: 0.78
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.6; acc: 0.77
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.59; acc: 0.75
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.71; acc: 0.77
Batch: 200; loss: 0.44; acc: 0.83
Batch: 220; loss: 0.55; acc: 0.84
Batch: 240; loss: 0.73; acc: 0.81
Batch: 260; loss: 0.36; acc: 0.84
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.68; acc: 0.77
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.53; acc: 0.83
Batch: 440; loss: 0.63; acc: 0.81
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.74; acc: 0.75
Batch: 520; loss: 0.63; acc: 0.81
Batch: 540; loss: 0.63; acc: 0.84
Batch: 560; loss: 0.56; acc: 0.81
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.58; acc: 0.81
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.76; acc: 0.7
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.83
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.48; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.75
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.7
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.47819358176866156; val_accuracy: 0.8484275477707006 

The current subspace-distance is: 0.0001181210100185126 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.72
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.68; acc: 0.83
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.84
Batch: 160; loss: 0.75; acc: 0.83
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.95
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.56; acc: 0.86
Batch: 300; loss: 0.56; acc: 0.75
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.8
Batch: 360; loss: 0.65; acc: 0.77
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.62; acc: 0.83
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.64; acc: 0.78
Batch: 480; loss: 0.75; acc: 0.77
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.52; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.58; acc: 0.8
Batch: 620; loss: 0.6; acc: 0.8
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.66; acc: 0.73
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.88
Batch: 720; loss: 0.52; acc: 0.8
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.71; acc: 0.81
Batch: 780; loss: 0.6; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.81; acc: 0.77
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.7
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.47799182146977465; val_accuracy: 0.8473328025477707 

The current subspace-distance is: 0.00011749508121283725 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.69; acc: 0.75
Batch: 40; loss: 0.86; acc: 0.83
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.71; acc: 0.81
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.58; acc: 0.83
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.55; acc: 0.81
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.88
Batch: 280; loss: 0.54; acc: 0.77
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.68; acc: 0.77
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.56; acc: 0.8
Batch: 440; loss: 0.45; acc: 0.83
Batch: 460; loss: 0.61; acc: 0.78
Batch: 480; loss: 0.57; acc: 0.83
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.43; acc: 0.91
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.61; acc: 0.83
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.46; acc: 0.88
Batch: 740; loss: 0.8; acc: 0.73
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.67; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.83; acc: 0.75
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.7
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4744057988475083; val_accuracy: 0.8514132165605095 

The current subspace-distance is: 0.00011945116420974955 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.77
Batch: 40; loss: 0.69; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.56; acc: 0.83
Batch: 180; loss: 0.75; acc: 0.83
Batch: 200; loss: 0.77; acc: 0.81
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.66; acc: 0.77
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.61; acc: 0.81
Batch: 300; loss: 0.51; acc: 0.84
Batch: 320; loss: 0.65; acc: 0.8
Batch: 340; loss: 0.73; acc: 0.8
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.42; acc: 0.92
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.18; acc: 0.98
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.61; acc: 0.86
Batch: 520; loss: 0.57; acc: 0.81
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.71; acc: 0.73
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.81
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.58; acc: 0.78
Batch: 680; loss: 0.55; acc: 0.83
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.55; acc: 0.8
Batch: 740; loss: 0.74; acc: 0.75
Batch: 760; loss: 0.64; acc: 0.84
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.89
Val Epoch over. val_loss: 0.47833024743635943; val_accuracy: 0.8503184713375797 

The current subspace-distance is: 0.00012179069017292932 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.73
Batch: 140; loss: 0.8; acc: 0.73
Batch: 160; loss: 0.49; acc: 0.88
Batch: 180; loss: 0.52; acc: 0.88
Batch: 200; loss: 0.76; acc: 0.77
Batch: 220; loss: 0.57; acc: 0.77
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.77
Batch: 300; loss: 0.48; acc: 0.8
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.81
Batch: 360; loss: 0.64; acc: 0.84
Batch: 380; loss: 0.63; acc: 0.8
Batch: 400; loss: 0.61; acc: 0.84
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.38; acc: 0.83
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.61; acc: 0.81
Batch: 540; loss: 0.63; acc: 0.78
Batch: 560; loss: 0.4; acc: 0.83
Batch: 580; loss: 0.64; acc: 0.8
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.64; acc: 0.81
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.53; acc: 0.78
Batch: 680; loss: 0.62; acc: 0.77
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.63; acc: 0.88
Batch: 760; loss: 0.72; acc: 0.81
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.81; acc: 0.75
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.89
Val Epoch over. val_loss: 0.4754614298510703; val_accuracy: 0.8512141719745223 

The current subspace-distance is: 0.0001237913966178894 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.65; acc: 0.86
Batch: 60; loss: 0.66; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.63; acc: 0.81
Batch: 160; loss: 0.36; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.76; acc: 0.8
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.66; acc: 0.81
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.44; acc: 0.86
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.83
Batch: 500; loss: 0.68; acc: 0.75
Batch: 520; loss: 0.59; acc: 0.81
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.78; acc: 0.77
Batch: 620; loss: 0.62; acc: 0.75
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.59; acc: 0.73
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.54; acc: 0.78
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.92
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.75; acc: 0.73
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.7
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.4761254404001175; val_accuracy: 0.8514132165605095 

The current subspace-distance is: 0.0001267768384423107 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.81; acc: 0.77
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.76; acc: 0.81
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.63; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.83
Batch: 360; loss: 0.57; acc: 0.8
Batch: 380; loss: 0.4; acc: 0.91
Batch: 400; loss: 0.67; acc: 0.75
Batch: 420; loss: 0.67; acc: 0.88
Batch: 440; loss: 0.5; acc: 0.8
Batch: 460; loss: 0.46; acc: 0.83
Batch: 480; loss: 0.59; acc: 0.88
Batch: 500; loss: 0.66; acc: 0.88
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.49; acc: 0.8
Batch: 600; loss: 0.58; acc: 0.81
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.6; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.8
Batch: 680; loss: 0.57; acc: 0.84
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.7; acc: 0.8
Batch: 760; loss: 0.65; acc: 0.83
Batch: 780; loss: 0.54; acc: 0.86
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.81; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.18; acc: 0.89
Val Epoch over. val_loss: 0.47122085388678653; val_accuracy: 0.8520103503184714 

The current subspace-distance is: 0.00012929753575008363 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.74; acc: 0.83
Batch: 60; loss: 0.48; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.61; acc: 0.81
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.47; acc: 0.81
Batch: 200; loss: 0.7; acc: 0.8
Batch: 220; loss: 0.45; acc: 0.83
Batch: 240; loss: 0.54; acc: 0.81
Batch: 260; loss: 0.52; acc: 0.83
Batch: 280; loss: 0.72; acc: 0.83
Batch: 300; loss: 0.37; acc: 0.84
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.69; acc: 0.83
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.85; acc: 0.75
Batch: 420; loss: 0.57; acc: 0.81
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.86; acc: 0.78
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.7; acc: 0.8
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.64; acc: 0.75
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.68; acc: 0.81
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.82; acc: 0.77
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.73
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.47594552226127335; val_accuracy: 0.8503184713375797 

The current subspace-distance is: 0.00013140177179593593 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.8
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.84
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.59; acc: 0.78
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.59; acc: 0.8
Batch: 200; loss: 0.64; acc: 0.83
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.62; acc: 0.8
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.59; acc: 0.81
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.64; acc: 0.75
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.71; acc: 0.81
Batch: 600; loss: 0.69; acc: 0.81
Batch: 620; loss: 0.67; acc: 0.8
Batch: 640; loss: 0.72; acc: 0.86
Batch: 660; loss: 0.89; acc: 0.72
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.91; acc: 0.73
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.89
Val Epoch over. val_loss: 0.472008762086273; val_accuracy: 0.8513136942675159 

The current subspace-distance is: 0.00013284815941005945 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.72; acc: 0.81
Batch: 20; loss: 0.82; acc: 0.78
Batch: 40; loss: 0.66; acc: 0.81
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.42; acc: 0.81
Batch: 100; loss: 0.74; acc: 0.84
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.76; acc: 0.77
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.81; acc: 0.73
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.56; acc: 0.81
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.72; acc: 0.8
Batch: 300; loss: 0.5; acc: 0.88
Batch: 320; loss: 0.68; acc: 0.78
Batch: 340; loss: 0.65; acc: 0.78
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.62; acc: 0.86
Batch: 440; loss: 0.74; acc: 0.8
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.52; acc: 0.81
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.54; acc: 0.8
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.75
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.7
Batch: 140; loss: 0.19; acc: 0.91
Val Epoch over. val_loss: 0.46986514605154656; val_accuracy: 0.8524084394904459 

The current subspace-distance is: 0.00013253708311822265 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.78; acc: 0.75
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.66; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.73; acc: 0.73
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.39; acc: 0.81
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.57; acc: 0.75
Batch: 400; loss: 0.37; acc: 0.84
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.59; acc: 0.8
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.56; acc: 0.83
Batch: 520; loss: 0.51; acc: 0.81
Batch: 540; loss: 0.51; acc: 0.83
Batch: 560; loss: 0.65; acc: 0.8
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.59; acc: 0.83
Batch: 620; loss: 0.57; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.81
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.59; acc: 0.8
Batch: 780; loss: 0.76; acc: 0.83
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.7
Batch: 140; loss: 0.18; acc: 0.89
Val Epoch over. val_loss: 0.47183674108830226; val_accuracy: 0.8513136942675159 

The current subspace-distance is: 0.00013322700397111475 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.56; acc: 0.75
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.69; acc: 0.84
Batch: 100; loss: 0.55; acc: 0.77
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.66; acc: 0.78
Batch: 180; loss: 0.88; acc: 0.77
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.6; acc: 0.83
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.56; acc: 0.8
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.68; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.45; acc: 0.8
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.51; acc: 0.91
Batch: 560; loss: 0.49; acc: 0.81
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.58; acc: 0.83
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.55; acc: 0.81
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.51; acc: 0.8
Batch: 740; loss: 0.46; acc: 0.84
Batch: 760; loss: 0.75; acc: 0.77
Batch: 780; loss: 0.72; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.91
Val Epoch over. val_loss: 0.4722359244041382; val_accuracy: 0.8534036624203821 

The current subspace-distance is: 0.00013319523714017123 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.4; acc: 0.81
Batch: 60; loss: 0.39; acc: 0.83
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.75
Batch: 140; loss: 0.49; acc: 0.86
Batch: 160; loss: 0.61; acc: 0.84
Batch: 180; loss: 0.63; acc: 0.8
Batch: 200; loss: 0.58; acc: 0.78
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.47; acc: 0.8
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.53; acc: 0.81
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.59; acc: 0.83
Batch: 360; loss: 0.76; acc: 0.81
Batch: 380; loss: 0.63; acc: 0.77
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.72; acc: 0.8
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.5; acc: 0.8
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.65; acc: 0.86
Batch: 540; loss: 0.6; acc: 0.86
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.47; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.69; acc: 0.81
Batch: 640; loss: 0.53; acc: 0.83
Batch: 660; loss: 0.64; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.59; acc: 0.83
Batch: 720; loss: 0.67; acc: 0.73
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.7
Batch: 140; loss: 0.19; acc: 0.89
Val Epoch over. val_loss: 0.470292583962155; val_accuracy: 0.8516122611464968 

The current subspace-distance is: 0.00013736468099523336 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.39; acc: 0.81
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.47; acc: 0.78
Batch: 160; loss: 0.49; acc: 0.86
Batch: 180; loss: 0.52; acc: 0.8
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.67; acc: 0.83
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.64; acc: 0.83
Batch: 300; loss: 0.39; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.72; acc: 0.8
Batch: 400; loss: 0.67; acc: 0.8
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.67; acc: 0.77
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.83
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.83
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.57; acc: 0.84
Batch: 680; loss: 0.55; acc: 0.77
Batch: 700; loss: 0.54; acc: 0.83
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.49; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.56; acc: 0.77
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.7
Batch: 140; loss: 0.19; acc: 0.89
Val Epoch over. val_loss: 0.470394617622825; val_accuracy: 0.8513136942675159 

The current subspace-distance is: 0.0001395873405272141 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.78; acc: 0.72
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.82; acc: 0.78
Batch: 140; loss: 0.77; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.75; acc: 0.81
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.53; acc: 0.77
Batch: 280; loss: 0.64; acc: 0.83
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.58; acc: 0.78
Batch: 500; loss: 0.72; acc: 0.83
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.57; acc: 0.81
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.37; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.84
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.48; acc: 0.81
Batch: 720; loss: 0.66; acc: 0.88
Batch: 740; loss: 0.53; acc: 0.81
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.7
Batch: 140; loss: 0.2; acc: 0.89
Val Epoch over. val_loss: 0.47233930277596614; val_accuracy: 0.8509156050955414 

The current subspace-distance is: 0.00014447988360188901 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.7; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.57; acc: 0.78
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.39; acc: 0.86
Batch: 160; loss: 0.5; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.52; acc: 0.78
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.44; acc: 0.8
Batch: 260; loss: 0.48; acc: 0.84
Batch: 280; loss: 0.4; acc: 0.81
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.72; acc: 0.8
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.55; acc: 0.8
Batch: 400; loss: 0.81; acc: 0.77
Batch: 420; loss: 0.46; acc: 0.81
Batch: 440; loss: 0.35; acc: 0.86
Batch: 460; loss: 0.61; acc: 0.8
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.8; acc: 0.7
Batch: 520; loss: 0.58; acc: 0.83
Batch: 540; loss: 0.76; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.47; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.86
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.86; acc: 0.75
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.92
Batch: 740; loss: 0.67; acc: 0.8
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.18; acc: 0.89
Val Epoch over. val_loss: 0.46928496468978326; val_accuracy: 0.8526074840764332 

The current subspace-distance is: 0.00014493759954348207 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.55; acc: 0.77
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.59; acc: 0.83
Batch: 160; loss: 0.86; acc: 0.75
Batch: 180; loss: 0.45; acc: 0.81
Batch: 200; loss: 0.56; acc: 0.78
Batch: 220; loss: 0.51; acc: 0.8
Batch: 240; loss: 0.77; acc: 0.78
Batch: 260; loss: 0.63; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.83
Batch: 300; loss: 0.65; acc: 0.77
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.5; acc: 0.84
Batch: 380; loss: 0.47; acc: 0.8
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.63; acc: 0.78
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.73; acc: 0.73
Batch: 500; loss: 0.68; acc: 0.78
Batch: 520; loss: 0.58; acc: 0.86
Batch: 540; loss: 0.61; acc: 0.77
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.8; acc: 0.83
Batch: 600; loss: 0.53; acc: 0.86
Batch: 620; loss: 0.61; acc: 0.88
Batch: 640; loss: 0.71; acc: 0.75
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.72; acc: 0.8
Batch: 720; loss: 0.69; acc: 0.73
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.69; acc: 0.83
Batch: 780; loss: 0.41; acc: 0.92
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.19; acc: 0.89
Val Epoch over. val_loss: 0.47007984985971146; val_accuracy: 0.852906050955414 

The current subspace-distance is: 0.0001484989479649812 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.68; acc: 0.8
Batch: 20; loss: 0.73; acc: 0.81
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.51; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.92
Batch: 100; loss: 0.69; acc: 0.73
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 1.0; acc: 0.72
Batch: 160; loss: 0.52; acc: 0.78
Batch: 180; loss: 0.49; acc: 0.81
Batch: 200; loss: 0.47; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.78
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.51; acc: 0.78
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.45; acc: 0.84
Batch: 380; loss: 0.67; acc: 0.83
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.64; acc: 0.78
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.59; acc: 0.78
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.59; acc: 0.78
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.84; acc: 0.8
Batch: 660; loss: 0.54; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.54; acc: 0.83
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.8; acc: 0.75
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.19; acc: 0.91
Val Epoch over. val_loss: 0.4717923574576712; val_accuracy: 0.8511146496815286 

The current subspace-distance is: 0.00014971758355386555 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 23633
elements in E: 4948900
fraction nonzero: 0.004775404635373517
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.29; acc: 0.12
Batch: 280; loss: 2.28; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.11
Batch: 320; loss: 2.27; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.29; acc: 0.16
Batch: 380; loss: 2.28; acc: 0.19
Batch: 400; loss: 2.27; acc: 0.22
Batch: 420; loss: 2.28; acc: 0.3
Batch: 440; loss: 2.28; acc: 0.2
Batch: 460; loss: 2.28; acc: 0.23
Batch: 480; loss: 2.27; acc: 0.28
Batch: 500; loss: 2.28; acc: 0.25
Batch: 520; loss: 2.26; acc: 0.36
Batch: 540; loss: 2.27; acc: 0.34
Batch: 560; loss: 2.24; acc: 0.41
Batch: 580; loss: 2.24; acc: 0.3
Batch: 600; loss: 2.24; acc: 0.3
Batch: 620; loss: 2.25; acc: 0.31
Batch: 640; loss: 2.23; acc: 0.3
Batch: 660; loss: 2.21; acc: 0.3
Batch: 680; loss: 2.22; acc: 0.2
Batch: 700; loss: 2.19; acc: 0.28
Batch: 720; loss: 2.16; acc: 0.34
Batch: 740; loss: 2.16; acc: 0.38
Batch: 760; loss: 2.1; acc: 0.44
Batch: 780; loss: 2.06; acc: 0.39
Train Epoch over. train_loss: 2.26; train_accuracy: 0.21 

Batch: 0; loss: 2.09; acc: 0.33
Batch: 20; loss: 2.13; acc: 0.23
Batch: 40; loss: 2.03; acc: 0.45
Batch: 60; loss: 2.04; acc: 0.41
Batch: 80; loss: 2.1; acc: 0.34
Batch: 100; loss: 2.08; acc: 0.38
Batch: 120; loss: 2.04; acc: 0.42
Batch: 140; loss: 2.09; acc: 0.31
Val Epoch over. val_loss: 2.0976988039198954; val_accuracy: 0.3166799363057325 

The current subspace-distance is: 6.146436135168187e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.1; acc: 0.27
Batch: 20; loss: 2.09; acc: 0.34
Batch: 40; loss: 1.94; acc: 0.34
Batch: 60; loss: 1.89; acc: 0.42
Batch: 80; loss: 1.69; acc: 0.56
Batch: 100; loss: 1.63; acc: 0.42
Batch: 120; loss: 1.58; acc: 0.45
Batch: 140; loss: 1.42; acc: 0.55
Batch: 160; loss: 1.33; acc: 0.61
Batch: 180; loss: 1.29; acc: 0.56
Batch: 200; loss: 1.43; acc: 0.5
Batch: 220; loss: 1.38; acc: 0.52
Batch: 240; loss: 1.17; acc: 0.59
Batch: 260; loss: 1.42; acc: 0.53
Batch: 280; loss: 1.42; acc: 0.52
Batch: 300; loss: 1.08; acc: 0.59
Batch: 320; loss: 1.33; acc: 0.52
Batch: 340; loss: 1.19; acc: 0.62
Batch: 360; loss: 0.88; acc: 0.72
Batch: 380; loss: 1.22; acc: 0.55
Batch: 400; loss: 1.32; acc: 0.52
Batch: 420; loss: 1.09; acc: 0.69
Batch: 440; loss: 1.0; acc: 0.69
Batch: 460; loss: 1.03; acc: 0.72
Batch: 480; loss: 1.12; acc: 0.64
Batch: 500; loss: 1.06; acc: 0.7
Batch: 520; loss: 0.79; acc: 0.75
Batch: 540; loss: 0.86; acc: 0.77
Batch: 560; loss: 1.18; acc: 0.58
Batch: 580; loss: 1.11; acc: 0.55
Batch: 600; loss: 0.73; acc: 0.77
Batch: 620; loss: 1.35; acc: 0.66
Batch: 640; loss: 0.87; acc: 0.75
Batch: 660; loss: 0.87; acc: 0.73
Batch: 680; loss: 0.77; acc: 0.73
Batch: 700; loss: 0.96; acc: 0.7
Batch: 720; loss: 0.96; acc: 0.7
Batch: 740; loss: 0.83; acc: 0.73
Batch: 760; loss: 0.85; acc: 0.78
Batch: 780; loss: 0.85; acc: 0.73
Train Epoch over. train_loss: 1.2; train_accuracy: 0.61 

Batch: 0; loss: 1.07; acc: 0.64
Batch: 20; loss: 1.32; acc: 0.61
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 1.1; acc: 0.61
Batch: 80; loss: 0.93; acc: 0.73
Batch: 100; loss: 1.15; acc: 0.66
Batch: 120; loss: 1.18; acc: 0.66
Batch: 140; loss: 0.93; acc: 0.69
Val Epoch over. val_loss: 1.0497579096229213; val_accuracy: 0.6696855095541401 

The current subspace-distance is: 1.6953357771853916e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.96; acc: 0.69
Batch: 20; loss: 0.74; acc: 0.83
Batch: 40; loss: 0.89; acc: 0.69
Batch: 60; loss: 0.95; acc: 0.73
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 1.08; acc: 0.7
Batch: 140; loss: 0.45; acc: 0.88
Batch: 160; loss: 1.01; acc: 0.66
Batch: 180; loss: 0.69; acc: 0.72
Batch: 200; loss: 1.12; acc: 0.58
Batch: 220; loss: 0.81; acc: 0.78
Batch: 240; loss: 0.64; acc: 0.75
Batch: 260; loss: 0.61; acc: 0.78
Batch: 280; loss: 0.75; acc: 0.8
Batch: 300; loss: 0.86; acc: 0.69
Batch: 320; loss: 0.79; acc: 0.78
Batch: 340; loss: 0.84; acc: 0.66
Batch: 360; loss: 0.63; acc: 0.81
Batch: 380; loss: 0.57; acc: 0.77
Batch: 400; loss: 0.78; acc: 0.73
Batch: 420; loss: 0.84; acc: 0.72
Batch: 440; loss: 0.71; acc: 0.78
Batch: 460; loss: 0.89; acc: 0.69
Batch: 480; loss: 1.01; acc: 0.75
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.89; acc: 0.72
Batch: 540; loss: 0.67; acc: 0.78
Batch: 560; loss: 0.7; acc: 0.75
Batch: 580; loss: 0.93; acc: 0.7
Batch: 600; loss: 1.33; acc: 0.59
Batch: 620; loss: 0.6; acc: 0.83
Batch: 640; loss: 0.8; acc: 0.72
Batch: 660; loss: 1.06; acc: 0.61
Batch: 680; loss: 0.91; acc: 0.72
Batch: 700; loss: 0.75; acc: 0.8
Batch: 720; loss: 0.83; acc: 0.75
Batch: 740; loss: 0.62; acc: 0.84
Batch: 760; loss: 0.74; acc: 0.8
Batch: 780; loss: 0.76; acc: 0.73
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 1.27; acc: 0.53
Batch: 20; loss: 1.77; acc: 0.45
Batch: 40; loss: 0.84; acc: 0.75
Batch: 60; loss: 1.33; acc: 0.55
Batch: 80; loss: 1.11; acc: 0.62
Batch: 100; loss: 1.42; acc: 0.59
Batch: 120; loss: 1.54; acc: 0.52
Batch: 140; loss: 1.34; acc: 0.59
Val Epoch over. val_loss: 1.3014670378842932; val_accuracy: 0.5908638535031847 

The current subspace-distance is: 2.4162192858057097e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.12; acc: 0.64
Batch: 20; loss: 0.58; acc: 0.75
Batch: 40; loss: 0.99; acc: 0.75
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 0.99; acc: 0.66
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.64; acc: 0.81
Batch: 160; loss: 1.31; acc: 0.58
Batch: 180; loss: 0.9; acc: 0.73
Batch: 200; loss: 0.74; acc: 0.81
Batch: 220; loss: 0.79; acc: 0.7
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.87; acc: 0.78
Batch: 280; loss: 0.61; acc: 0.84
Batch: 300; loss: 0.85; acc: 0.78
Batch: 320; loss: 1.11; acc: 0.69
Batch: 340; loss: 0.67; acc: 0.8
Batch: 360; loss: 0.82; acc: 0.75
Batch: 380; loss: 0.56; acc: 0.81
Batch: 400; loss: 0.58; acc: 0.8
Batch: 420; loss: 0.72; acc: 0.75
Batch: 440; loss: 0.57; acc: 0.81
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.62; acc: 0.78
Batch: 500; loss: 0.67; acc: 0.8
Batch: 520; loss: 0.84; acc: 0.81
Batch: 540; loss: 0.74; acc: 0.73
Batch: 560; loss: 0.85; acc: 0.77
Batch: 580; loss: 0.53; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.75
Batch: 620; loss: 1.04; acc: 0.64
Batch: 640; loss: 0.76; acc: 0.8
Batch: 660; loss: 0.98; acc: 0.75
Batch: 680; loss: 0.84; acc: 0.77
Batch: 700; loss: 0.79; acc: 0.72
Batch: 720; loss: 0.84; acc: 0.69
Batch: 740; loss: 0.51; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.58; acc: 0.77
Train Epoch over. train_loss: 0.78; train_accuracy: 0.76 

Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.7
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.72; acc: 0.72
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.88; acc: 0.73
Batch: 120; loss: 1.01; acc: 0.59
Batch: 140; loss: 0.72; acc: 0.77
Val Epoch over. val_loss: 0.7261025142517818; val_accuracy: 0.7680135350318471 

The current subspace-distance is: 3.023458157258574e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.69
Batch: 40; loss: 0.81; acc: 0.7
Batch: 60; loss: 0.71; acc: 0.81
Batch: 80; loss: 0.99; acc: 0.62
Batch: 100; loss: 0.88; acc: 0.72
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.91; acc: 0.73
Batch: 160; loss: 0.61; acc: 0.83
Batch: 180; loss: 0.76; acc: 0.77
Batch: 200; loss: 0.71; acc: 0.78
Batch: 220; loss: 1.26; acc: 0.64
Batch: 240; loss: 0.59; acc: 0.81
Batch: 260; loss: 0.65; acc: 0.77
Batch: 280; loss: 1.13; acc: 0.64
Batch: 300; loss: 0.68; acc: 0.75
Batch: 320; loss: 0.95; acc: 0.73
Batch: 340; loss: 0.59; acc: 0.83
Batch: 360; loss: 0.98; acc: 0.67
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.76; acc: 0.8
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 0.65; acc: 0.83
Batch: 460; loss: 0.86; acc: 0.72
Batch: 480; loss: 0.81; acc: 0.81
Batch: 500; loss: 0.72; acc: 0.75
Batch: 520; loss: 0.88; acc: 0.77
Batch: 540; loss: 0.83; acc: 0.77
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.67; acc: 0.73
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.91; acc: 0.7
Batch: 640; loss: 0.97; acc: 0.67
Batch: 660; loss: 0.63; acc: 0.77
Batch: 680; loss: 0.64; acc: 0.84
Batch: 700; loss: 0.72; acc: 0.84
Batch: 720; loss: 0.83; acc: 0.75
Batch: 740; loss: 0.71; acc: 0.8
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.72; train_accuracy: 0.78 

Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.77; acc: 0.73
Batch: 80; loss: 0.65; acc: 0.83
Batch: 100; loss: 1.03; acc: 0.73
Batch: 120; loss: 1.11; acc: 0.69
Batch: 140; loss: 0.45; acc: 0.83
Val Epoch over. val_loss: 0.848235869673407; val_accuracy: 0.7229299363057324 

The current subspace-distance is: 3.597127215471119e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 0.67; acc: 0.8
Batch: 40; loss: 0.66; acc: 0.78
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 1.1; acc: 0.62
Batch: 100; loss: 0.79; acc: 0.75
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.65; acc: 0.8
Batch: 180; loss: 1.29; acc: 0.75
Batch: 200; loss: 0.56; acc: 0.88
Batch: 220; loss: 0.53; acc: 0.8
Batch: 240; loss: 0.77; acc: 0.78
Batch: 260; loss: 0.63; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.66; acc: 0.78
Batch: 320; loss: 0.82; acc: 0.69
Batch: 340; loss: 0.47; acc: 0.83
Batch: 360; loss: 0.77; acc: 0.73
Batch: 380; loss: 0.89; acc: 0.78
Batch: 400; loss: 0.51; acc: 0.8
Batch: 420; loss: 0.56; acc: 0.86
Batch: 440; loss: 0.7; acc: 0.77
Batch: 460; loss: 0.7; acc: 0.77
Batch: 480; loss: 1.38; acc: 0.66
Batch: 500; loss: 0.62; acc: 0.77
Batch: 520; loss: 0.72; acc: 0.73
Batch: 540; loss: 0.48; acc: 0.92
Batch: 560; loss: 0.72; acc: 0.81
Batch: 580; loss: 0.66; acc: 0.81
Batch: 600; loss: 0.77; acc: 0.72
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.56; acc: 0.86
Batch: 660; loss: 0.63; acc: 0.8
Batch: 680; loss: 0.8; acc: 0.77
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.79; acc: 0.81
Batch: 780; loss: 0.64; acc: 0.84
Train Epoch over. train_loss: 0.66; train_accuracy: 0.8 

Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.9; acc: 0.67
Batch: 40; loss: 0.32; acc: 0.97
Batch: 60; loss: 0.63; acc: 0.78
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.7; acc: 0.75
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 0.4; acc: 0.88
Val Epoch over. val_loss: 0.6330706442047835; val_accuracy: 0.7973726114649682 

The current subspace-distance is: 4.1559625969966874e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 1.17; acc: 0.67
Batch: 40; loss: 0.53; acc: 0.78
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.73; acc: 0.75
Batch: 160; loss: 0.69; acc: 0.78
Batch: 180; loss: 0.84; acc: 0.72
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.44; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.64; acc: 0.75
Batch: 300; loss: 0.61; acc: 0.83
Batch: 320; loss: 0.63; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.86
Batch: 360; loss: 0.86; acc: 0.75
Batch: 380; loss: 0.7; acc: 0.8
Batch: 400; loss: 0.64; acc: 0.8
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.63; acc: 0.8
Batch: 460; loss: 0.55; acc: 0.81
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.43; acc: 0.83
Batch: 540; loss: 0.54; acc: 0.8
Batch: 560; loss: 0.65; acc: 0.78
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.76; acc: 0.73
Batch: 620; loss: 0.79; acc: 0.73
Batch: 640; loss: 1.01; acc: 0.66
Batch: 660; loss: 0.75; acc: 0.81
Batch: 680; loss: 0.48; acc: 0.81
Batch: 700; loss: 0.67; acc: 0.78
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.88; acc: 0.77
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.92; acc: 0.67
Train Epoch over. train_loss: 0.64; train_accuracy: 0.8 

Batch: 0; loss: 0.81; acc: 0.7
Batch: 20; loss: 1.16; acc: 0.64
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.76; acc: 0.83
Batch: 120; loss: 1.06; acc: 0.66
Batch: 140; loss: 0.67; acc: 0.7
Val Epoch over. val_loss: 0.6862437889264648; val_accuracy: 0.7911027070063694 

The current subspace-distance is: 4.717761112260632e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.78
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.6; acc: 0.84
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.57; acc: 0.86
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.73; acc: 0.75
Batch: 260; loss: 0.82; acc: 0.77
Batch: 280; loss: 0.75; acc: 0.84
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.87; acc: 0.66
Batch: 360; loss: 0.63; acc: 0.84
Batch: 380; loss: 0.73; acc: 0.86
Batch: 400; loss: 0.55; acc: 0.89
Batch: 420; loss: 0.38; acc: 0.84
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.67; acc: 0.78
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.68; acc: 0.81
Batch: 540; loss: 0.72; acc: 0.78
Batch: 560; loss: 0.71; acc: 0.77
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.67; acc: 0.8
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.63; acc: 0.77
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.68; acc: 0.72
Batch: 740; loss: 0.73; acc: 0.72
Batch: 760; loss: 0.92; acc: 0.8
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.62; train_accuracy: 0.81 

Batch: 0; loss: 0.66; acc: 0.78
Batch: 20; loss: 1.02; acc: 0.66
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.39; acc: 0.89
Val Epoch over. val_loss: 0.6832487746408791; val_accuracy: 0.7803542993630573 

The current subspace-distance is: 5.249523019301705e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.64; acc: 0.78
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.75; acc: 0.8
Batch: 180; loss: 0.71; acc: 0.73
Batch: 200; loss: 0.49; acc: 0.83
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.69; acc: 0.81
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.78; acc: 0.72
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.99; acc: 0.77
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.75; acc: 0.8
Batch: 420; loss: 0.92; acc: 0.73
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.83; acc: 0.72
Batch: 480; loss: 0.5; acc: 0.8
Batch: 500; loss: 0.7; acc: 0.78
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.69; acc: 0.75
Batch: 560; loss: 0.79; acc: 0.8
Batch: 580; loss: 0.72; acc: 0.8
Batch: 600; loss: 0.57; acc: 0.83
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.64; acc: 0.83
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.46; acc: 0.91
Batch: 720; loss: 0.92; acc: 0.73
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.66; acc: 0.78
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.61; train_accuracy: 0.81 

Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.62; acc: 0.78
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.64; acc: 0.75
Batch: 140; loss: 0.32; acc: 0.92
Val Epoch over. val_loss: 0.5512583852763389; val_accuracy: 0.8255374203821656 

The current subspace-distance is: 5.545817475649528e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.78
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 0.85; acc: 0.73
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.69; acc: 0.77
Batch: 200; loss: 0.75; acc: 0.73
Batch: 220; loss: 0.75; acc: 0.81
Batch: 240; loss: 0.55; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.73; acc: 0.78
Batch: 300; loss: 0.78; acc: 0.72
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.57; acc: 0.8
Batch: 360; loss: 0.57; acc: 0.81
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.65; acc: 0.77
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 0.66; acc: 0.78
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.58; acc: 0.84
Batch: 520; loss: 0.8; acc: 0.77
Batch: 540; loss: 0.52; acc: 0.81
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.43; acc: 0.92
Batch: 620; loss: 0.52; acc: 0.88
Batch: 640; loss: 0.61; acc: 0.78
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.86; acc: 0.81
Batch: 700; loss: 0.54; acc: 0.89
Batch: 720; loss: 0.73; acc: 0.78
Batch: 740; loss: 0.46; acc: 0.81
Batch: 760; loss: 1.26; acc: 0.64
Batch: 780; loss: 0.62; acc: 0.75
Train Epoch over. train_loss: 0.61; train_accuracy: 0.81 

Batch: 0; loss: 0.62; acc: 0.73
Batch: 20; loss: 0.69; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.77
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.61; acc: 0.83
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.38; acc: 0.84
Val Epoch over. val_loss: 0.5060141423515453; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 5.8766752772498876e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.6; acc: 0.83
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.65; acc: 0.78
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.55; acc: 0.81
Batch: 240; loss: 0.47; acc: 0.83
Batch: 260; loss: 0.62; acc: 0.83
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.68; acc: 0.84
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.63; acc: 0.86
Batch: 500; loss: 0.67; acc: 0.84
Batch: 520; loss: 0.67; acc: 0.83
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.78; acc: 0.77
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.6; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.53; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.24; acc: 0.94
Val Epoch over. val_loss: 0.45699702782236085; val_accuracy: 0.8644506369426752 

The current subspace-distance is: 6.296234641922638e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.68; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.8
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.88
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.78
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.41; acc: 0.84
Batch: 400; loss: 0.56; acc: 0.84
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.53; acc: 0.8
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.6; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.68; acc: 0.81
Batch: 600; loss: 0.65; acc: 0.83
Batch: 620; loss: 0.6; acc: 0.78
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.83; acc: 0.75
Batch: 680; loss: 0.47; acc: 0.8
Batch: 700; loss: 0.59; acc: 0.77
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.66; acc: 0.81
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.71; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.27; acc: 0.94
Val Epoch over. val_loss: 0.49522713263323354; val_accuracy: 0.8507165605095541 

The current subspace-distance is: 6.789744656998664e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.57; acc: 0.81
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.45; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.83
Batch: 200; loss: 0.56; acc: 0.8
Batch: 220; loss: 0.63; acc: 0.75
Batch: 240; loss: 0.46; acc: 0.83
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.81
Batch: 300; loss: 0.48; acc: 0.86
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.34; acc: 0.84
Batch: 360; loss: 0.86; acc: 0.72
Batch: 380; loss: 0.52; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.5; acc: 0.91
Batch: 480; loss: 0.42; acc: 0.91
Batch: 500; loss: 0.59; acc: 0.81
Batch: 520; loss: 0.52; acc: 0.8
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.53; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.57; acc: 0.84
Batch: 660; loss: 0.61; acc: 0.86
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.79; acc: 0.8
Batch: 760; loss: 0.61; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.86
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.65; acc: 0.81
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.49068377095802573; val_accuracy: 0.848328025477707 

The current subspace-distance is: 7.089976861607283e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.64; acc: 0.77
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.49; acc: 0.81
Batch: 200; loss: 0.63; acc: 0.8
Batch: 220; loss: 0.53; acc: 0.89
Batch: 240; loss: 0.54; acc: 0.8
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.53; acc: 0.81
Batch: 300; loss: 0.34; acc: 0.84
Batch: 320; loss: 0.52; acc: 0.8
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.68; acc: 0.78
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.59; acc: 0.84
Batch: 460; loss: 0.9; acc: 0.77
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.56; acc: 0.83
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.87; acc: 0.77
Batch: 640; loss: 0.6; acc: 0.78
Batch: 660; loss: 0.53; acc: 0.81
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.75; acc: 0.77
Batch: 760; loss: 0.66; acc: 0.78
Batch: 780; loss: 0.57; acc: 0.86
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

Batch: 0; loss: 0.91; acc: 0.7
Batch: 20; loss: 0.92; acc: 0.78
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.45; acc: 0.81
Val Epoch over. val_loss: 0.6194886024210863; val_accuracy: 0.8174761146496815 

The current subspace-distance is: 7.252212526509538e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.94; acc: 0.75
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.56; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.83
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.69; acc: 0.81
Batch: 260; loss: 0.59; acc: 0.81
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.55; acc: 0.88
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.48; acc: 0.81
Batch: 380; loss: 0.63; acc: 0.83
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.51; acc: 0.88
Batch: 460; loss: 0.64; acc: 0.83
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.84; acc: 0.8
Batch: 540; loss: 0.49; acc: 0.81
Batch: 560; loss: 0.67; acc: 0.8
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.56; acc: 0.83
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.74; acc: 0.75
Batch: 720; loss: 0.56; acc: 0.8
Batch: 740; loss: 0.79; acc: 0.81
Batch: 760; loss: 0.69; acc: 0.78
Batch: 780; loss: 0.63; acc: 0.81
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.66; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.22; acc: 0.89
Val Epoch over. val_loss: 0.4947622369049461; val_accuracy: 0.8459394904458599 

The current subspace-distance is: 7.671827188460156e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.66; acc: 0.83
Batch: 20; loss: 0.6; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.6; acc: 0.88
Batch: 80; loss: 0.85; acc: 0.8
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.53; acc: 0.83
Batch: 280; loss: 0.63; acc: 0.86
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.92; acc: 0.81
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.7; acc: 0.77
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.53; acc: 0.83
Batch: 420; loss: 0.51; acc: 0.89
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.61; acc: 0.8
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.48; acc: 0.81
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.51; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.58; acc: 0.78
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.68; acc: 0.77
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.23; acc: 0.97
Val Epoch over. val_loss: 0.4372599421033434; val_accuracy: 0.8683320063694268 

The current subspace-distance is: 7.899366755736992e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.8
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.6; acc: 0.84
Batch: 160; loss: 0.66; acc: 0.81
Batch: 180; loss: 0.8; acc: 0.73
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.84
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.91; acc: 0.78
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.75; acc: 0.81
Batch: 380; loss: 0.65; acc: 0.86
Batch: 400; loss: 0.67; acc: 0.75
Batch: 420; loss: 0.48; acc: 0.83
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.91
Batch: 520; loss: 0.72; acc: 0.8
Batch: 540; loss: 0.89; acc: 0.8
Batch: 560; loss: 0.58; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.66; acc: 0.78
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.67; acc: 0.84
Batch: 700; loss: 0.64; acc: 0.83
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 1.08; acc: 0.66
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.6454503012310927; val_accuracy: 0.8045382165605095 

The current subspace-distance is: 8.259269088739529e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.52; acc: 0.86
Batch: 180; loss: 0.46; acc: 0.91
Batch: 200; loss: 0.49; acc: 0.81
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.79; acc: 0.8
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.49; acc: 0.81
Batch: 360; loss: 0.61; acc: 0.8
Batch: 380; loss: 0.69; acc: 0.77
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.8
Batch: 500; loss: 0.78; acc: 0.77
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.65; acc: 0.83
Batch: 560; loss: 0.77; acc: 0.78
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.55; acc: 0.8
Batch: 620; loss: 0.61; acc: 0.75
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.57; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.72; acc: 0.78
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.56; acc: 0.78
Batch: 20; loss: 0.79; acc: 0.78
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.72; acc: 0.72
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.5723712127299825; val_accuracy: 0.8156847133757962 

The current subspace-distance is: 8.684669592184946e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.88; acc: 0.7
Batch: 180; loss: 0.8; acc: 0.8
Batch: 200; loss: 0.73; acc: 0.8
Batch: 220; loss: 0.66; acc: 0.77
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.6; acc: 0.81
Batch: 320; loss: 0.65; acc: 0.73
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.74; acc: 0.73
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.56; acc: 0.77
Batch: 440; loss: 0.5; acc: 0.83
Batch: 460; loss: 0.52; acc: 0.81
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.83
Batch: 520; loss: 0.55; acc: 0.89
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.57; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.52; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.8
Batch: 680; loss: 0.47; acc: 0.81
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.77; acc: 0.78
Batch: 740; loss: 0.66; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.95
Batch: 780; loss: 0.67; acc: 0.88
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.81; acc: 0.81
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.32; acc: 0.86
Val Epoch over. val_loss: 0.5166157433751283; val_accuracy: 0.8425557324840764 

The current subspace-distance is: 9.045554179465398e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.78; acc: 0.81
Batch: 20; loss: 0.51; acc: 0.78
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.67; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.47; acc: 0.83
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.48; acc: 0.89
Batch: 260; loss: 0.53; acc: 0.8
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.55; acc: 0.88
Batch: 320; loss: 0.52; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.81
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.48; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.7; acc: 0.8
Batch: 520; loss: 0.71; acc: 0.84
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.52; acc: 0.83
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.51; acc: 0.89
Batch: 720; loss: 0.6; acc: 0.81
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.81
Batch: 780; loss: 0.64; acc: 0.81
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.62; acc: 0.84
Batch: 20; loss: 0.7; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.47098677401330064; val_accuracy: 0.8544984076433121 

The current subspace-distance is: 9.207861148752272e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.55; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.65; acc: 0.83
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.64; acc: 0.8
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.64; acc: 0.81
Batch: 340; loss: 0.48; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.44; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.92
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.53; acc: 0.83
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.56; acc: 0.88
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.92
Batch: 740; loss: 0.63; acc: 0.83
Batch: 760; loss: 0.38; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.18; acc: 0.98
Val Epoch over. val_loss: 0.4129083956692629; val_accuracy: 0.8701234076433121 

The current subspace-distance is: 9.634482557885349e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.56; acc: 0.8
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.53; acc: 0.81
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.71; acc: 0.83
Batch: 380; loss: 0.84; acc: 0.73
Batch: 400; loss: 0.64; acc: 0.8
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.88
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.61; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.8
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.78
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.98
Val Epoch over. val_loss: 0.4237453984986445; val_accuracy: 0.8629578025477707 

The current subspace-distance is: 0.00010007579840021208 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.94
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.66; acc: 0.78
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.47; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.83
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.58; acc: 0.75
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.6; acc: 0.83
Batch: 540; loss: 0.52; acc: 0.83
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.84
Batch: 600; loss: 0.5; acc: 0.86
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.63; acc: 0.81
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.84
Batch: 700; loss: 0.58; acc: 0.83
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.66; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.4141186566869165; val_accuracy: 0.8689291401273885 

The current subspace-distance is: 0.0001037134206853807 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.4; acc: 0.94
Batch: 220; loss: 0.48; acc: 0.91
Batch: 240; loss: 0.57; acc: 0.78
Batch: 260; loss: 0.64; acc: 0.84
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.46; acc: 0.81
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.78; acc: 0.75
Batch: 380; loss: 0.42; acc: 0.83
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.83
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 0.51; acc: 0.91
Batch: 620; loss: 0.63; acc: 0.84
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.42; acc: 0.81
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.7; acc: 0.8
Batch: 740; loss: 0.46; acc: 0.84
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.46; acc: 0.78
Batch: 20; loss: 0.63; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.5; acc: 0.8
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.54; acc: 0.81
Batch: 120; loss: 0.42; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.98
Val Epoch over. val_loss: 0.4165493627167811; val_accuracy: 0.8669386942675159 

The current subspace-distance is: 0.00010727014159783721 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.49; acc: 0.81
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.59; acc: 0.83
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.48; acc: 0.81
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.81
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.83
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.4423294026570715; val_accuracy: 0.863953025477707 

The current subspace-distance is: 0.00010913075675489381 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.77
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.61; acc: 0.88
Batch: 100; loss: 0.81; acc: 0.8
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.48; acc: 0.8
Batch: 180; loss: 0.43; acc: 0.8
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.64; acc: 0.86
Batch: 240; loss: 0.54; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.56; acc: 0.83
Batch: 380; loss: 0.48; acc: 0.78
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.86
Batch: 440; loss: 0.36; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.56; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.83
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.55; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.81
Batch: 640; loss: 0.58; acc: 0.78
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.37; acc: 0.83
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.39779026085024427; val_accuracy: 0.8751990445859873 

The current subspace-distance is: 0.0001096761116059497 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.46; acc: 0.83
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.53; acc: 0.83
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.49; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.87; acc: 0.83
Batch: 460; loss: 0.44; acc: 0.83
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.58; acc: 0.83
Batch: 520; loss: 0.49; acc: 0.83
Batch: 540; loss: 0.65; acc: 0.81
Batch: 560; loss: 0.58; acc: 0.84
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.6; acc: 0.8
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.49; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.83
Batch: 760; loss: 0.56; acc: 0.8
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.98
Val Epoch over. val_loss: 0.41063387995692574; val_accuracy: 0.8683320063694268 

The current subspace-distance is: 0.00011235953570576385 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.55; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.69; acc: 0.81
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.32; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.5; acc: 0.83
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.53; acc: 0.81
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.51; acc: 0.77
Batch: 460; loss: 0.57; acc: 0.83
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.67; acc: 0.81
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.62; acc: 0.77
Batch: 720; loss: 0.66; acc: 0.83
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.6; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.3904599700668815; val_accuracy: 0.8800756369426752 

The current subspace-distance is: 0.00011510444892337546 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.81
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.94
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.55; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.6; acc: 0.78
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.65; acc: 0.83
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.92; acc: 0.8
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.81
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.58; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.81
Batch: 700; loss: 0.54; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3862681540239389; val_accuracy: 0.882265127388535 

The current subspace-distance is: 0.00011706288205459714 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.78
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.37; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.8
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.4; acc: 0.81
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.54; acc: 0.78
Batch: 340; loss: 0.59; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.92; acc: 0.77
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.5; acc: 0.89
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.62; acc: 0.81
Batch: 560; loss: 0.78; acc: 0.8
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.75; acc: 0.78
Batch: 680; loss: 0.57; acc: 0.88
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.56; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4051125191009728; val_accuracy: 0.8766918789808917 

The current subspace-distance is: 0.00011900180106749758 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.54; acc: 0.84
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.64; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.62; acc: 0.81
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.47; acc: 0.83
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.81
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.45; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.86
Batch: 500; loss: 0.59; acc: 0.83
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.53; acc: 0.8
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.8
Batch: 620; loss: 0.38; acc: 0.83
Batch: 640; loss: 0.42; acc: 0.92
Batch: 660; loss: 0.58; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.51; acc: 0.88
Batch: 780; loss: 0.55; acc: 0.83
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.38293020901786295; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 0.0001207709065056406 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.54; acc: 0.89
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.57; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.71; acc: 0.83
Batch: 560; loss: 0.73; acc: 0.78
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.63; acc: 0.8
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.57; acc: 0.84
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.33; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3803161338066599; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 0.0001207144814543426 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.65; acc: 0.8
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.7; acc: 0.81
Batch: 200; loss: 0.37; acc: 0.84
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.58; acc: 0.81
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.49; acc: 0.83
Batch: 320; loss: 0.43; acc: 0.83
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.52; acc: 0.81
Batch: 440; loss: 0.56; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.4; acc: 0.84
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.51; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.98
Val Epoch over. val_loss: 0.38608118374446393; val_accuracy: 0.8803742038216561 

The current subspace-distance is: 0.0001228230685228482 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.73; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.69; acc: 0.88
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.41; acc: 0.83
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.6; acc: 0.78
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.38458090356201124; val_accuracy: 0.8792794585987261 

The current subspace-distance is: 0.00012585626973304898 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.77
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.57; acc: 0.8
Batch: 100; loss: 0.58; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.89
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.45; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.52; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.47; acc: 0.81
Batch: 480; loss: 0.41; acc: 0.83
Batch: 500; loss: 0.46; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.41; acc: 0.84
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.66; acc: 0.86
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.69; acc: 0.81
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3832763869576393; val_accuracy: 0.8801751592356688 

The current subspace-distance is: 0.00012865020835306495 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.8
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.28; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.59; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.92
Batch: 180; loss: 0.66; acc: 0.8
Batch: 200; loss: 0.43; acc: 0.83
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.83
Batch: 260; loss: 0.61; acc: 0.81
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.55; acc: 0.81
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.53; acc: 0.89
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.54; acc: 0.86
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.32; acc: 0.84
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.56; acc: 0.8
Batch: 760; loss: 0.49; acc: 0.81
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.3982896531937988; val_accuracy: 0.8778861464968153 

The current subspace-distance is: 0.000130578875541687 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.55; acc: 0.84
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.62; acc: 0.81
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.84
Batch: 340; loss: 0.75; acc: 0.78
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.46; acc: 0.83
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.44; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.81
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.61; acc: 0.83
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.72; acc: 0.81
Batch: 720; loss: 0.7; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.92
Batch: 760; loss: 0.68; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3824759281839535; val_accuracy: 0.8803742038216561 

The current subspace-distance is: 0.00013219815446063876 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.81
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.4; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.57; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.58; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.56; acc: 0.84
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.56; acc: 0.75
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.51; acc: 0.81
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.44; acc: 0.83
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.49; acc: 0.81
Batch: 640; loss: 0.6; acc: 0.84
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.3829957793947238; val_accuracy: 0.8835589171974523 

The current subspace-distance is: 0.00013603392289951444 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.44; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.78
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.95
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.61; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.8
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.66; acc: 0.81
Batch: 780; loss: 0.56; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.38456936118898877; val_accuracy: 0.882265127388535 

The current subspace-distance is: 0.00013597494398709387 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.62; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.57; acc: 0.81
Batch: 220; loss: 0.46; acc: 0.8
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.58; acc: 0.84
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.63; acc: 0.84
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.82; acc: 0.73
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.81
Batch: 480; loss: 0.52; acc: 0.81
Batch: 500; loss: 0.53; acc: 0.89
Batch: 520; loss: 0.53; acc: 0.83
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.62; acc: 0.84
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.49; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.98
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.38529461527326303; val_accuracy: 0.8796775477707006 

The current subspace-distance is: 0.00013885957014281303 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.49; acc: 0.83
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.37; acc: 0.86
Batch: 260; loss: 0.47; acc: 0.83
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.5; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.68; acc: 0.83
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.49; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.76; acc: 0.81
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.73; acc: 0.78
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.37982152658662977; val_accuracy: 0.884156050955414 

The current subspace-distance is: 0.00014164854655973613 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.6; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.81
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.4; acc: 0.83
Batch: 200; loss: 0.64; acc: 0.83
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.86
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.75; acc: 0.81
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.51; acc: 0.83
Batch: 480; loss: 0.36; acc: 0.84
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.39; acc: 0.84
Batch: 600; loss: 0.64; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3788986246392226; val_accuracy: 0.882265127388535 

The current subspace-distance is: 0.0001429675321560353 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.49; acc: 0.81
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.75; acc: 0.8
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.45; acc: 0.83
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.83
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.42; acc: 0.84
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.8; acc: 0.81
Batch: 780; loss: 0.59; acc: 0.81
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3814711388508985; val_accuracy: 0.8799761146496815 

The current subspace-distance is: 0.0001449376723030582 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.75; acc: 0.81
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.78; acc: 0.81
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.83
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.91
Batch: 400; loss: 0.57; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.52; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.61; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.37866252281103924; val_accuracy: 0.883359872611465 

The current subspace-distance is: 0.0001483716769143939 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.55; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.83
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.95
Batch: 340; loss: 0.54; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.53; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.88
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.43; acc: 0.92
Batch: 520; loss: 0.59; acc: 0.86
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.61; acc: 0.77
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.55; acc: 0.86
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.83
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3788033981042303; val_accuracy: 0.8831608280254777 

The current subspace-distance is: 0.00014830140571575612 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.52; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.44; acc: 0.83
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.59; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.58; acc: 0.84
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.93; acc: 0.73
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.46; acc: 0.83
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.48; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3803747206167051; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 0.0001498267229180783 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.58; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.84
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.85; acc: 0.75
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.83
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.52; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.51; acc: 0.84
Batch: 640; loss: 0.46; acc: 0.75
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3795276446042547; val_accuracy: 0.8831608280254777 

The current subspace-distance is: 0.00015417141548823565 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.66; acc: 0.78
Batch: 80; loss: 0.49; acc: 0.83
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.49; acc: 0.8
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.51; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.66; acc: 0.84
Batch: 480; loss: 0.57; acc: 0.86
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.66; acc: 0.8
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.6; acc: 0.78
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.92
Batch: 720; loss: 0.44; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.8
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3785447154644948; val_accuracy: 0.883359872611465 

The current subspace-distance is: 0.00015741704555694014 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.58; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.98
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.27; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.74; acc: 0.84
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.64; acc: 0.8
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.63; acc: 0.84
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.67; acc: 0.84
Batch: 440; loss: 0.54; acc: 0.81
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.94
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.58; acc: 0.84
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.63; acc: 0.83
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.8
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.7; acc: 0.84
Batch: 760; loss: 0.64; acc: 0.8
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.37891792154805676; val_accuracy: 0.8839570063694268 

The current subspace-distance is: 0.00015986590005923063 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.65; acc: 0.81
Batch: 160; loss: 0.58; acc: 0.84
Batch: 180; loss: 0.54; acc: 0.84
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.7; acc: 0.8
Batch: 240; loss: 0.53; acc: 0.81
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.56; acc: 0.91
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.57; acc: 0.8
Batch: 400; loss: 0.28; acc: 0.86
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.55; acc: 0.81
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.42; acc: 0.83
Batch: 700; loss: 0.57; acc: 0.88
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.69; acc: 0.83
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3793478416409462; val_accuracy: 0.8826632165605095 

The current subspace-distance is: 0.0001617412781342864 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_110_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 25707
elements in E: 5398800
fraction nonzero: 0.00476161369193154
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.28; acc: 0.12
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.28; acc: 0.14
Batch: 320; loss: 2.28; acc: 0.23
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.28; acc: 0.23
Batch: 380; loss: 2.28; acc: 0.17
Batch: 400; loss: 2.28; acc: 0.12
Batch: 420; loss: 2.27; acc: 0.23
Batch: 440; loss: 2.27; acc: 0.16
Batch: 460; loss: 2.28; acc: 0.11
Batch: 480; loss: 2.28; acc: 0.16
Batch: 500; loss: 2.26; acc: 0.23
Batch: 520; loss: 2.27; acc: 0.19
Batch: 540; loss: 2.27; acc: 0.17
Batch: 560; loss: 2.25; acc: 0.27
Batch: 580; loss: 2.26; acc: 0.2
Batch: 600; loss: 2.24; acc: 0.28
Batch: 620; loss: 2.24; acc: 0.2
Batch: 640; loss: 2.24; acc: 0.14
Batch: 660; loss: 2.22; acc: 0.25
Batch: 680; loss: 2.22; acc: 0.25
Batch: 700; loss: 2.21; acc: 0.27
Batch: 720; loss: 2.16; acc: 0.33
Batch: 740; loss: 2.17; acc: 0.27
Batch: 760; loss: 2.16; acc: 0.17
Batch: 780; loss: 2.15; acc: 0.31
Train Epoch over. train_loss: 2.27; train_accuracy: 0.17 

Batch: 0; loss: 2.12; acc: 0.38
Batch: 20; loss: 2.13; acc: 0.34
Batch: 40; loss: 2.06; acc: 0.41
Batch: 60; loss: 2.1; acc: 0.39
Batch: 80; loss: 2.13; acc: 0.33
Batch: 100; loss: 2.08; acc: 0.44
Batch: 120; loss: 2.11; acc: 0.39
Batch: 140; loss: 2.12; acc: 0.34
Val Epoch over. val_loss: 2.138759764896077; val_accuracy: 0.321656050955414 

The current subspace-distance is: 6.138671778899152e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.15; acc: 0.33
Batch: 20; loss: 2.13; acc: 0.23
Batch: 40; loss: 2.02; acc: 0.42
Batch: 60; loss: 2.01; acc: 0.44
Batch: 80; loss: 1.86; acc: 0.48
Batch: 100; loss: 1.83; acc: 0.38
Batch: 120; loss: 1.7; acc: 0.45
Batch: 140; loss: 1.52; acc: 0.61
Batch: 160; loss: 1.43; acc: 0.55
Batch: 180; loss: 1.37; acc: 0.58
Batch: 200; loss: 1.28; acc: 0.59
Batch: 220; loss: 1.38; acc: 0.52
Batch: 240; loss: 1.03; acc: 0.69
Batch: 260; loss: 1.35; acc: 0.62
Batch: 280; loss: 1.13; acc: 0.7
Batch: 300; loss: 1.07; acc: 0.67
Batch: 320; loss: 1.31; acc: 0.53
Batch: 340; loss: 1.32; acc: 0.58
Batch: 360; loss: 1.07; acc: 0.66
Batch: 380; loss: 0.99; acc: 0.75
Batch: 400; loss: 1.31; acc: 0.56
Batch: 420; loss: 1.11; acc: 0.72
Batch: 440; loss: 0.89; acc: 0.73
Batch: 460; loss: 0.98; acc: 0.67
Batch: 480; loss: 0.87; acc: 0.69
Batch: 500; loss: 0.91; acc: 0.72
Batch: 520; loss: 0.72; acc: 0.77
Batch: 540; loss: 1.13; acc: 0.64
Batch: 560; loss: 0.75; acc: 0.7
Batch: 580; loss: 0.91; acc: 0.81
Batch: 600; loss: 0.83; acc: 0.75
Batch: 620; loss: 1.27; acc: 0.7
Batch: 640; loss: 1.03; acc: 0.78
Batch: 660; loss: 0.74; acc: 0.83
Batch: 680; loss: 0.65; acc: 0.8
Batch: 700; loss: 1.01; acc: 0.64
Batch: 720; loss: 0.7; acc: 0.75
Batch: 740; loss: 0.73; acc: 0.8
Batch: 760; loss: 1.04; acc: 0.72
Batch: 780; loss: 0.8; acc: 0.72
Train Epoch over. train_loss: 1.2; train_accuracy: 0.62 

Batch: 0; loss: 0.98; acc: 0.67
Batch: 20; loss: 1.15; acc: 0.62
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 1.06; acc: 0.66
Batch: 80; loss: 0.94; acc: 0.62
Batch: 100; loss: 1.03; acc: 0.75
Batch: 120; loss: 1.46; acc: 0.66
Batch: 140; loss: 0.54; acc: 0.8
Val Epoch over. val_loss: 0.9883771859536505; val_accuracy: 0.6852109872611465 

The current subspace-distance is: 1.9186541976523586e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.97; acc: 0.66
Batch: 20; loss: 0.82; acc: 0.75
Batch: 40; loss: 0.81; acc: 0.73
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.6; acc: 0.81
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.56; acc: 0.78
Batch: 160; loss: 0.83; acc: 0.75
Batch: 180; loss: 0.82; acc: 0.7
Batch: 200; loss: 0.65; acc: 0.81
Batch: 220; loss: 0.64; acc: 0.8
Batch: 240; loss: 0.9; acc: 0.7
Batch: 260; loss: 0.69; acc: 0.75
Batch: 280; loss: 0.73; acc: 0.75
Batch: 300; loss: 0.64; acc: 0.84
Batch: 320; loss: 0.72; acc: 0.81
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.57; acc: 0.8
Batch: 380; loss: 0.61; acc: 0.77
Batch: 400; loss: 0.61; acc: 0.8
Batch: 420; loss: 0.61; acc: 0.83
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.64; acc: 0.78
Batch: 480; loss: 0.76; acc: 0.77
Batch: 500; loss: 0.36; acc: 0.92
Batch: 520; loss: 0.76; acc: 0.72
Batch: 540; loss: 0.66; acc: 0.75
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.88; acc: 0.72
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.91; acc: 0.69
Batch: 700; loss: 0.85; acc: 0.8
Batch: 720; loss: 0.8; acc: 0.69
Batch: 740; loss: 0.53; acc: 0.81
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

Batch: 0; loss: 0.69; acc: 0.78
Batch: 20; loss: 1.17; acc: 0.56
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.85; acc: 0.77
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.97; acc: 0.75
Batch: 120; loss: 1.2; acc: 0.64
Batch: 140; loss: 0.54; acc: 0.83
Val Epoch over. val_loss: 0.7574119495738084; val_accuracy: 0.7682125796178344 

The current subspace-distance is: 2.6198737032245845e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.81
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.64; acc: 0.83
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.8; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.72
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.58; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.81
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 0.6; acc: 0.86
Batch: 240; loss: 0.91; acc: 0.7
Batch: 260; loss: 0.75; acc: 0.72
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.6; acc: 0.86
Batch: 320; loss: 0.55; acc: 0.81
Batch: 340; loss: 0.78; acc: 0.72
Batch: 360; loss: 0.64; acc: 0.8
Batch: 380; loss: 0.5; acc: 0.81
Batch: 400; loss: 0.47; acc: 0.89
Batch: 420; loss: 0.6; acc: 0.83
Batch: 440; loss: 0.62; acc: 0.88
Batch: 460; loss: 0.45; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.52; acc: 0.83
Batch: 520; loss: 0.61; acc: 0.83
Batch: 540; loss: 0.68; acc: 0.83
Batch: 560; loss: 0.66; acc: 0.77
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.71; acc: 0.73
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.57; acc: 0.8
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.87; acc: 0.72
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

Batch: 0; loss: 0.56; acc: 0.77
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.61; acc: 0.83
Batch: 120; loss: 0.9; acc: 0.69
Batch: 140; loss: 0.42; acc: 0.83
Val Epoch over. val_loss: 0.6501223839771976; val_accuracy: 0.7844347133757962 

The current subspace-distance is: 3.226079206797294e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.58; acc: 0.78
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.71; acc: 0.81
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 0.55; acc: 0.78
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.53; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.63; acc: 0.83
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.67; acc: 0.77
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.64; acc: 0.78
Batch: 360; loss: 0.68; acc: 0.8
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.45; acc: 0.83
Batch: 420; loss: 0.81; acc: 0.75
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.54; acc: 0.77
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.7; acc: 0.77
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.81; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.86; acc: 0.81
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.8; acc: 0.81
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.62; acc: 0.83
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.49; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.55; train_accuracy: 0.83 

Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 1.16; acc: 0.64
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.66; acc: 0.77
Batch: 120; loss: 1.02; acc: 0.72
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.582884569361711; val_accuracy: 0.8204617834394905 

The current subspace-distance is: 3.835998722934164e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.82; acc: 0.69
Batch: 40; loss: 0.57; acc: 0.78
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.7; acc: 0.8
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.52; acc: 0.75
Batch: 180; loss: 0.69; acc: 0.78
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.75; acc: 0.78
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.63; acc: 0.77
Batch: 380; loss: 0.72; acc: 0.75
Batch: 400; loss: 0.44; acc: 0.83
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.64; acc: 0.77
Batch: 500; loss: 0.6; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.81
Batch: 540; loss: 0.43; acc: 0.81
Batch: 560; loss: 0.9; acc: 0.78
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.57; acc: 0.8
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.57; acc: 0.75
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.57; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.99; acc: 0.7
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.91; acc: 0.69
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.5203186368012125; val_accuracy: 0.8417595541401274 

The current subspace-distance is: 4.4038595660822466e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.87; acc: 0.8
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.86
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.89; acc: 0.73
Batch: 160; loss: 0.64; acc: 0.81
Batch: 180; loss: 1.0; acc: 0.66
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.63; acc: 0.81
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.55; acc: 0.84
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.61; acc: 0.83
Batch: 380; loss: 0.58; acc: 0.81
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.81
Batch: 440; loss: 0.5; acc: 0.8
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.71; acc: 0.83
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.64; acc: 0.81
Batch: 620; loss: 0.51; acc: 0.78
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.56; acc: 0.86
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.53; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.61; acc: 0.78
Batch: 20; loss: 1.01; acc: 0.67
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.32; acc: 0.88
Val Epoch over. val_loss: 0.5251065821025023; val_accuracy: 0.8406648089171974 

The current subspace-distance is: 4.888943658443168e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.84
Batch: 60; loss: 0.49; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.83
Batch: 120; loss: 0.64; acc: 0.75
Batch: 140; loss: 0.56; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.58; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.67; acc: 0.83
Batch: 260; loss: 0.58; acc: 0.81
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.49; acc: 0.81
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.74; acc: 0.8
Batch: 360; loss: 0.61; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.53; acc: 0.89
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.59; acc: 0.78
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.77; acc: 0.7
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.53; acc: 0.88
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.65; acc: 0.78
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.69; acc: 0.77
Batch: 740; loss: 0.54; acc: 0.86
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.51; train_accuracy: 0.85 

Batch: 0; loss: 0.43; acc: 0.81
Batch: 20; loss: 0.96; acc: 0.67
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 1.16; acc: 0.64
Batch: 140; loss: 0.21; acc: 0.97
Val Epoch over. val_loss: 0.5672478221214501; val_accuracy: 0.8206608280254777 

The current subspace-distance is: 5.333883746061474e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.74; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.65; acc: 0.77
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.55; acc: 0.88
Batch: 300; loss: 0.55; acc: 0.89
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.7; acc: 0.8
Batch: 360; loss: 0.57; acc: 0.77
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.76; acc: 0.77
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.71; acc: 0.78
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.49; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.86
Batch: 560; loss: 0.66; acc: 0.8
Batch: 580; loss: 0.63; acc: 0.83
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.6; acc: 0.83
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.7; acc: 0.75
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.54; acc: 0.8
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.41; acc: 0.81
Val Epoch over. val_loss: 0.5480819740303003; val_accuracy: 0.8276273885350318 

The current subspace-distance is: 5.7206569181289524e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.54; acc: 0.84
Batch: 200; loss: 0.57; acc: 0.83
Batch: 220; loss: 0.56; acc: 0.83
Batch: 240; loss: 0.52; acc: 0.81
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.7; acc: 0.78
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.54; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.37; acc: 0.83
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.62; acc: 0.81
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.53; acc: 0.81
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4349764352960951; val_accuracy: 0.8625597133757962 

The current subspace-distance is: 6.132075213827193e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.83
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.56; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.5; acc: 0.83
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.81
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.53; acc: 0.84
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.58; acc: 0.83
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.77
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.84
Batch: 780; loss: 0.81; acc: 0.77
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.6; acc: 0.72
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4006810736883977; val_accuracy: 0.8784832802547771 

The current subspace-distance is: 6.523154297610745e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.92
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.43; acc: 0.83
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.58; acc: 0.78
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.67; acc: 0.83
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.55; acc: 0.81
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.56; acc: 0.78
Batch: 680; loss: 0.37; acc: 0.84
Batch: 700; loss: 0.58; acc: 0.88
Batch: 720; loss: 0.66; acc: 0.83
Batch: 740; loss: 0.59; acc: 0.86
Batch: 760; loss: 0.53; acc: 0.88
Batch: 780; loss: 0.51; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.39995758292401673; val_accuracy: 0.8782842356687898 

The current subspace-distance is: 6.908471550559625e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.5; acc: 0.8
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.55; acc: 0.8
Batch: 200; loss: 0.49; acc: 0.86
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.59; acc: 0.83
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.51; acc: 0.81
Batch: 380; loss: 0.44; acc: 0.83
Batch: 400; loss: 0.41; acc: 0.83
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.49; acc: 0.83
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.81
Batch: 600; loss: 0.42; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.83
Batch: 660; loss: 0.62; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.68; acc: 0.75
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.75; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.41171534255052067; val_accuracy: 0.8756966560509554 

The current subspace-distance is: 7.301520963665098e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.91
Batch: 40; loss: 0.32; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.8
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.59; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.57; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.81
Batch: 580; loss: 0.3; acc: 0.84
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.76; acc: 0.78
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.88
Batch: 760; loss: 0.51; acc: 0.81
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.81; acc: 0.69
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.4111388476601072; val_accuracy: 0.8752985668789809 

The current subspace-distance is: 7.603861740790308e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.68; acc: 0.77
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.67; acc: 0.78
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.74; acc: 0.7
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.4; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.63; acc: 0.75
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.51; acc: 0.83
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.8
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.68; acc: 0.81
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.65; acc: 0.75
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.34; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.52; acc: 0.83
Batch: 700; loss: 0.67; acc: 0.8
Batch: 720; loss: 0.44; acc: 0.83
Batch: 740; loss: 0.49; acc: 0.86
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.67; acc: 0.75
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.11; acc: 1.0
Val Epoch over. val_loss: 0.4020100822494288; val_accuracy: 0.876890923566879 

The current subspace-distance is: 7.976517372298986e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.89
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.68; acc: 0.77
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.73; acc: 0.78
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.58; acc: 0.81
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.56; acc: 0.89
Batch: 460; loss: 0.59; acc: 0.78
Batch: 480; loss: 0.33; acc: 0.86
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.55; acc: 0.86
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.57; acc: 0.86
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4023460987836692; val_accuracy: 0.8757961783439491 

The current subspace-distance is: 8.360570791410282e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.69; acc: 0.78
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.58; acc: 0.84
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.49; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.66; acc: 0.84
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.59; acc: 0.81
Batch: 400; loss: 0.58; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.74; acc: 0.81
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.79; acc: 0.8
Batch: 560; loss: 0.52; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.59; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.83; acc: 0.67
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.86; acc: 0.8
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.41829768060498934; val_accuracy: 0.8707205414012739 

The current subspace-distance is: 8.678483573021367e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.83
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.66; acc: 0.86
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.62; acc: 0.84
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.51; acc: 0.88
Batch: 340; loss: 0.61; acc: 0.84
Batch: 360; loss: 0.64; acc: 0.77
Batch: 380; loss: 0.65; acc: 0.78
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.68; acc: 0.75
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.86
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.43; acc: 0.91
Batch: 740; loss: 0.59; acc: 0.86
Batch: 760; loss: 0.83; acc: 0.83
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.82; acc: 0.66
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4147083059807492; val_accuracy: 0.8717157643312102 

The current subspace-distance is: 8.993053779704496e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.59; acc: 0.78
Batch: 180; loss: 0.74; acc: 0.73
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.66; acc: 0.78
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.71; acc: 0.8
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.44; acc: 0.8
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.49; acc: 0.83
Batch: 540; loss: 0.81; acc: 0.8
Batch: 560; loss: 0.52; acc: 0.81
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.62; acc: 0.84
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.83; acc: 0.69
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.81
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.4464183628179465; val_accuracy: 0.8589769108280255 

The current subspace-distance is: 9.236344340024516e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.44; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.86
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.59; acc: 0.83
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.84
Batch: 260; loss: 0.64; acc: 0.84
Batch: 280; loss: 0.62; acc: 0.81
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.83
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.62; acc: 0.77
Batch: 420; loss: 0.54; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.81
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.74; acc: 0.7
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.407615828713414; val_accuracy: 0.8755971337579618 

The current subspace-distance is: 9.446541662327945e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.6; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.61; acc: 0.81
Batch: 220; loss: 0.55; acc: 0.84
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.86
Batch: 320; loss: 0.72; acc: 0.8
Batch: 340; loss: 0.5; acc: 0.89
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.68; acc: 0.86
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.59; acc: 0.86
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.51; acc: 0.77
Batch: 780; loss: 0.4; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.68; acc: 0.73
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3728771466453364; val_accuracy: 0.8890326433121019 

The current subspace-distance is: 9.790027979761362e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.5; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.64; acc: 0.83
Batch: 380; loss: 0.61; acc: 0.84
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.74; acc: 0.84
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.59; acc: 0.8
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.69; acc: 0.7
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37693852537376865; val_accuracy: 0.8850517515923567 

The current subspace-distance is: 0.00010056495375465602 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.41; acc: 0.92
Batch: 180; loss: 0.51; acc: 0.81
Batch: 200; loss: 0.3; acc: 0.86
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.89
Batch: 320; loss: 0.5; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.55; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.57; acc: 0.78
Batch: 480; loss: 0.67; acc: 0.75
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.43; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.58; acc: 0.8
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.6; acc: 0.8
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.7; acc: 0.73
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37952914041508534; val_accuracy: 0.886046974522293 

The current subspace-distance is: 0.00010245925659546629 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.56; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.59; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.55; acc: 0.8
Batch: 240; loss: 0.71; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.58; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.66; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.81
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.47; acc: 0.81
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.73; acc: 0.72
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.38463787620614287; val_accuracy: 0.8824641719745223 

The current subspace-distance is: 0.00010364416084485129 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.43; acc: 0.83
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.2; acc: 0.97
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.57; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.86
Batch: 640; loss: 0.53; acc: 0.83
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.68; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3733918247803761; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 0.00010368241055402905 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.59; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.52; acc: 0.8
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.53; acc: 0.78
Batch: 240; loss: 0.62; acc: 0.81
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.69; acc: 0.77
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.58; acc: 0.78
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.83
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.84
Batch: 520; loss: 0.5; acc: 0.8
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.52; acc: 0.88
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.68; acc: 0.81
Batch: 660; loss: 0.45; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.45; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.63; acc: 0.75
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.37310091994560446; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 0.0001058305861079134 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.63; acc: 0.86
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.47; acc: 0.83
Batch: 560; loss: 0.47; acc: 0.88
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.52; acc: 0.81
Batch: 640; loss: 0.52; acc: 0.83
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.84
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.69; acc: 0.72
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.37772164797517144; val_accuracy: 0.8863455414012739 

The current subspace-distance is: 0.00010743094753706828 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.95
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.42; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.61; acc: 0.88
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.81
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.48; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.68; acc: 0.8
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.65; acc: 0.81
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.58; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.59; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.73; acc: 0.73
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3913517494680016; val_accuracy: 0.8800756369426752 

The current subspace-distance is: 0.00010958224447676912 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.61; acc: 0.8
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.48; acc: 0.84
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.49; acc: 0.81
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.56; acc: 0.83
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.64; acc: 0.8
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.5; acc: 0.81
Batch: 620; loss: 0.49; acc: 0.84
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.81
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.62; acc: 0.81
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.75
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37255556017729885; val_accuracy: 0.8871417197452229 

The current subspace-distance is: 0.00011138574336655438 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.74; acc: 0.78
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.57; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.45; acc: 0.81
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.63; acc: 0.83
Batch: 280; loss: 0.65; acc: 0.8
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.62; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.7; acc: 0.78
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.56; acc: 0.81
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.72; acc: 0.81
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.62; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.56; acc: 0.86
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.84
Batch: 780; loss: 0.53; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.67; acc: 0.7
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37589019071903956; val_accuracy: 0.8862460191082803 

The current subspace-distance is: 0.00011526082380441949 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.95; acc: 0.73
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.5; acc: 0.94
Batch: 240; loss: 0.51; acc: 0.81
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.64; acc: 0.83
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.54; acc: 0.84
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.84; acc: 0.78
Batch: 620; loss: 0.55; acc: 0.81
Batch: 640; loss: 0.45; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.56; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.54; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3720783176980201; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 0.00011804760288214311 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.59; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.97
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.59; acc: 0.84
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.72; acc: 0.83
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.8
Batch: 440; loss: 0.67; acc: 0.81
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.65; acc: 0.84
Batch: 560; loss: 0.71; acc: 0.81
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.65; acc: 0.81
Batch: 620; loss: 0.47; acc: 0.81
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.65; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.72
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.37618887258373246; val_accuracy: 0.8835589171974523 

The current subspace-distance is: 0.00011796072794822976 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.6; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.51; acc: 0.84
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.5; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.54; acc: 0.81
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.84
Batch: 420; loss: 0.66; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.6; acc: 0.77
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.39; acc: 0.86
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.69; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37511014729548414; val_accuracy: 0.8878383757961783 

The current subspace-distance is: 0.00011995872046099976 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.83
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.58; acc: 0.8
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.73; acc: 0.78
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.62; acc: 0.83
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.66; acc: 0.72
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3757056750974078; val_accuracy: 0.8872412420382165 

The current subspace-distance is: 0.00012236874317750335 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.72; acc: 0.83
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.38; acc: 0.92
Batch: 140; loss: 0.58; acc: 0.88
Batch: 160; loss: 0.42; acc: 0.83
Batch: 180; loss: 0.48; acc: 0.89
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.65; acc: 0.78
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.66; acc: 0.86
Batch: 300; loss: 0.56; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.89
Batch: 340; loss: 0.56; acc: 0.86
Batch: 360; loss: 0.5; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.59; acc: 0.81
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.49; acc: 0.81
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.49; acc: 0.81
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.57; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.7; acc: 0.83
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.57; acc: 0.83
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.68; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3731339373596155; val_accuracy: 0.8888335987261147 

The current subspace-distance is: 0.00012616936874110252 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.39; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.86
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.35; acc: 0.83
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.6; acc: 0.83
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.69; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37370816665660045; val_accuracy: 0.8877388535031847 

The current subspace-distance is: 0.00012736798089463264 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.54; acc: 0.78
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.65; acc: 0.8
Batch: 220; loss: 0.45; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.45; acc: 0.84
Batch: 380; loss: 0.56; acc: 0.78
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.66; acc: 0.78
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.56; acc: 0.81
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.52; acc: 0.83
Batch: 680; loss: 0.36; acc: 0.92
Batch: 700; loss: 0.63; acc: 0.8
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.63; acc: 0.84
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3743186499092989; val_accuracy: 0.8864450636942676 

The current subspace-distance is: 0.0001302771270275116 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.83
Batch: 60; loss: 0.56; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.54; acc: 0.84
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.84
Batch: 380; loss: 0.24; acc: 0.97
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.47; acc: 0.83
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.62; acc: 0.83
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.83
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.88
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.58; acc: 0.77
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.62; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.372188665732077; val_accuracy: 0.8876393312101911 

The current subspace-distance is: 0.00013050415145698935 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.61; acc: 0.77
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.8
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 0.47; acc: 0.8
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.53; acc: 0.78
Batch: 420; loss: 0.51; acc: 0.88
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.55; acc: 0.88
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.53; acc: 0.84
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.6; acc: 0.86
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.5; acc: 0.88
Batch: 780; loss: 0.53; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.67; acc: 0.75
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37241888387947325; val_accuracy: 0.8886345541401274 

The current subspace-distance is: 0.00013273864169605076 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.81
Batch: 20; loss: 0.55; acc: 0.86
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.42; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.39; acc: 0.84
Batch: 280; loss: 0.59; acc: 0.84
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.51; acc: 0.83
Batch: 400; loss: 0.72; acc: 0.83
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.83
Batch: 480; loss: 0.47; acc: 0.83
Batch: 500; loss: 0.54; acc: 0.8
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.59; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.59; acc: 0.83
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.64; acc: 0.8
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.67; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.68; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3737520869275567; val_accuracy: 0.8878383757961783 

The current subspace-distance is: 0.0001345607015537098 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.6; acc: 0.83
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.74; acc: 0.81
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.59; acc: 0.78
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.72; acc: 0.81
Batch: 600; loss: 0.61; acc: 0.81
Batch: 620; loss: 0.58; acc: 0.8
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.58; acc: 0.81
Batch: 680; loss: 0.51; acc: 0.8
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.65; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37051044803136474; val_accuracy: 0.8892316878980892 

The current subspace-distance is: 0.00013577527715824544 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.63; acc: 0.84
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.63; acc: 0.77
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.71; acc: 0.78
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.42; acc: 0.81
Batch: 380; loss: 0.51; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.48; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.86
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.65; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37222193537434195; val_accuracy: 0.8871417197452229 

The current subspace-distance is: 0.00013666157610714436 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.81
Batch: 80; loss: 0.74; acc: 0.81
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.83
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.66; acc: 0.77
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.63; acc: 0.81
Batch: 400; loss: 0.43; acc: 0.91
Batch: 420; loss: 0.6; acc: 0.81
Batch: 440; loss: 0.52; acc: 0.81
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.48; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.48; acc: 0.81
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.57; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.4; acc: 0.84
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.66; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3740360297879596; val_accuracy: 0.8865445859872612 

The current subspace-distance is: 0.00013739206769969314 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.65; acc: 0.81
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.55; acc: 0.88
Batch: 220; loss: 0.62; acc: 0.83
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.41; acc: 0.83
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.58; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.39; acc: 0.86
Batch: 620; loss: 0.46; acc: 0.81
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.62; acc: 0.84
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.65; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3709220053378943; val_accuracy: 0.8888335987261147 

The current subspace-distance is: 0.00013954164751339704 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.52; acc: 0.81
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.44; acc: 0.84
Batch: 380; loss: 0.69; acc: 0.78
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.53; acc: 0.88
Batch: 540; loss: 0.54; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.83
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.51; acc: 0.84
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.75; acc: 0.75
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.74; acc: 0.75
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.65; acc: 0.75
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.370816350220495; val_accuracy: 0.8889331210191083 

The current subspace-distance is: 0.00014045431453268975 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.39; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.59; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.53; acc: 0.86
Batch: 360; loss: 0.37; acc: 0.94
Batch: 380; loss: 0.53; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.67; acc: 0.77
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.53; acc: 0.89
Batch: 640; loss: 0.61; acc: 0.84
Batch: 660; loss: 0.61; acc: 0.77
Batch: 680; loss: 0.59; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.66; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37220827741607737; val_accuracy: 0.8883359872611465 

The current subspace-distance is: 0.00014259577437769622 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.6; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.83
Batch: 320; loss: 0.51; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.56; acc: 0.86
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.58; acc: 0.8
Batch: 500; loss: 0.65; acc: 0.77
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.56; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.66; acc: 0.75
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.37220126428421896; val_accuracy: 0.8888335987261147 

The current subspace-distance is: 0.0001442521606804803 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.73; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.8
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.94
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.54; acc: 0.81
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.68; acc: 0.81
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.61; acc: 0.78
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.44; acc: 0.91
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.4; acc: 0.84
Batch: 780; loss: 0.6; acc: 0.8
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37098978065950855; val_accuracy: 0.8883359872611465 

The current subspace-distance is: 0.0001465126988478005 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.5; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.81
Batch: 260; loss: 0.86; acc: 0.81
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.56; acc: 0.83
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.55; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.84
Batch: 620; loss: 0.64; acc: 0.83
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.43; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.68; acc: 0.8
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.6; acc: 0.8
Batch: 760; loss: 0.52; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.66; acc: 0.75
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37095388404692814; val_accuracy: 0.8885350318471338 

The current subspace-distance is: 0.0001491919538239017 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.6; acc: 0.86
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.83; acc: 0.75
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.59; acc: 0.83
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.51; acc: 0.81
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.5; acc: 0.83
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.61; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.92
Batch: 440; loss: 0.58; acc: 0.84
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.52; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.69; acc: 0.86
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.52; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.65; acc: 0.73
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37151179666731765; val_accuracy: 0.8890326433121019 

The current subspace-distance is: 0.00015144208737183362 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_120_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 27212
elements in E: 5848700
fraction nonzero: 0.004652657855591841
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.17
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.19
Batch: 260; loss: 2.28; acc: 0.2
Batch: 280; loss: 2.29; acc: 0.17
Batch: 300; loss: 2.27; acc: 0.27
Batch: 320; loss: 2.27; acc: 0.2
Batch: 340; loss: 2.28; acc: 0.22
Batch: 360; loss: 2.28; acc: 0.2
Batch: 380; loss: 2.27; acc: 0.17
Batch: 400; loss: 2.26; acc: 0.23
Batch: 420; loss: 2.26; acc: 0.25
Batch: 440; loss: 2.24; acc: 0.34
Batch: 460; loss: 2.25; acc: 0.33
Batch: 480; loss: 2.25; acc: 0.2
Batch: 500; loss: 2.25; acc: 0.27
Batch: 520; loss: 2.19; acc: 0.44
Batch: 540; loss: 2.2; acc: 0.3
Batch: 560; loss: 2.14; acc: 0.38
Batch: 580; loss: 2.15; acc: 0.34
Batch: 600; loss: 2.09; acc: 0.42
Batch: 620; loss: 2.08; acc: 0.34
Batch: 640; loss: 1.94; acc: 0.38
Batch: 660; loss: 1.86; acc: 0.44
Batch: 680; loss: 1.68; acc: 0.48
Batch: 700; loss: 1.51; acc: 0.55
Batch: 720; loss: 1.3; acc: 0.61
Batch: 740; loss: 1.28; acc: 0.53
Batch: 760; loss: 1.14; acc: 0.64
Batch: 780; loss: 1.18; acc: 0.59
Train Epoch over. train_loss: 2.11; train_accuracy: 0.28 

Batch: 0; loss: 1.65; acc: 0.56
Batch: 20; loss: 2.14; acc: 0.36
Batch: 40; loss: 1.26; acc: 0.62
Batch: 60; loss: 1.47; acc: 0.59
Batch: 80; loss: 1.72; acc: 0.52
Batch: 100; loss: 1.5; acc: 0.55
Batch: 120; loss: 1.66; acc: 0.61
Batch: 140; loss: 1.39; acc: 0.66
Val Epoch over. val_loss: 1.645578328211596; val_accuracy: 0.51671974522293 

The current subspace-distance is: 8.230730600189418e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.92; acc: 0.48
Batch: 20; loss: 1.28; acc: 0.5
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.0; acc: 0.7
Batch: 80; loss: 0.93; acc: 0.73
Batch: 100; loss: 0.94; acc: 0.67
Batch: 120; loss: 0.96; acc: 0.77
Batch: 140; loss: 1.05; acc: 0.64
Batch: 160; loss: 1.38; acc: 0.58
Batch: 180; loss: 0.9; acc: 0.73
Batch: 200; loss: 0.75; acc: 0.78
Batch: 220; loss: 0.74; acc: 0.73
Batch: 240; loss: 0.8; acc: 0.75
Batch: 260; loss: 1.08; acc: 0.66
Batch: 280; loss: 0.85; acc: 0.81
Batch: 300; loss: 0.79; acc: 0.77
Batch: 320; loss: 1.01; acc: 0.72
Batch: 340; loss: 0.71; acc: 0.81
Batch: 360; loss: 0.7; acc: 0.72
Batch: 380; loss: 0.78; acc: 0.78
Batch: 400; loss: 0.87; acc: 0.78
Batch: 420; loss: 1.15; acc: 0.66
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.94; acc: 0.72
Batch: 480; loss: 0.63; acc: 0.77
Batch: 500; loss: 0.85; acc: 0.69
Batch: 520; loss: 0.79; acc: 0.73
Batch: 540; loss: 0.87; acc: 0.75
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.66; acc: 0.86
Batch: 600; loss: 0.92; acc: 0.77
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.73; acc: 0.8
Batch: 660; loss: 0.52; acc: 0.8
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.79; acc: 0.78
Batch: 720; loss: 0.65; acc: 0.8
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.66; acc: 0.84
Batch: 780; loss: 0.66; acc: 0.81
Train Epoch over. train_loss: 0.81; train_accuracy: 0.75 

Batch: 0; loss: 0.87; acc: 0.77
Batch: 20; loss: 1.18; acc: 0.7
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 1.42; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.78
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 1.3; acc: 0.67
Batch: 140; loss: 0.78; acc: 0.73
Val Epoch over. val_loss: 0.9564189836857425; val_accuracy: 0.7439291401273885 

The current subspace-distance is: 1.9324952518218197e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.91; acc: 0.73
Batch: 20; loss: 0.75; acc: 0.78
Batch: 40; loss: 0.63; acc: 0.77
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.61; acc: 0.84
Batch: 220; loss: 0.54; acc: 0.84
Batch: 240; loss: 0.7; acc: 0.8
Batch: 260; loss: 0.41; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.55; acc: 0.81
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.56; acc: 0.86
Batch: 440; loss: 0.71; acc: 0.83
Batch: 460; loss: 0.6; acc: 0.75
Batch: 480; loss: 0.55; acc: 0.88
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.72; acc: 0.8
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.8; acc: 0.77
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.89
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.73; acc: 0.8
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.52; acc: 0.81
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.94; acc: 0.7
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.57; acc: 0.75
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.33; acc: 0.84
Val Epoch over. val_loss: 0.6075978878007573; val_accuracy: 0.8075238853503185 

The current subspace-distance is: 2.693416172405705e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.62; acc: 0.89
Batch: 60; loss: 0.56; acc: 0.78
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.47; acc: 0.83
Batch: 240; loss: 0.63; acc: 0.84
Batch: 260; loss: 0.55; acc: 0.8
Batch: 280; loss: 0.21; acc: 0.98
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.69; acc: 0.78
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.47; acc: 0.83
Batch: 440; loss: 0.44; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.92
Batch: 480; loss: 0.56; acc: 0.81
Batch: 500; loss: 0.52; acc: 0.91
Batch: 520; loss: 0.48; acc: 0.88
Batch: 540; loss: 0.51; acc: 0.88
Batch: 560; loss: 0.46; acc: 0.83
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.92
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.56; acc: 0.88
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.74; acc: 0.72
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.25; acc: 0.92
Val Epoch over. val_loss: 0.4880981647474751; val_accuracy: 0.8485270700636943 

The current subspace-distance is: 3.214316529920325e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.81
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.64; acc: 0.81
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.5; acc: 0.84
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.46; acc: 0.81
Batch: 300; loss: 0.54; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.57; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.68; acc: 0.8
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.59; acc: 0.78
Batch: 480; loss: 0.46; acc: 0.89
Batch: 500; loss: 0.61; acc: 0.83
Batch: 520; loss: 0.47; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.56; acc: 0.86
Batch: 640; loss: 0.76; acc: 0.8
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.65; acc: 0.81
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 0.54; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.425489584209433; val_accuracy: 0.8682324840764332 

The current subspace-distance is: 3.8271169614745304e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.84
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.67; acc: 0.75
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.8; acc: 0.8
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.6; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.78
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.88
Batch: 320; loss: 0.79; acc: 0.75
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.5; acc: 0.8
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.29; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.53; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.65; acc: 0.8
Batch: 500; loss: 0.56; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.85; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.91
Batch: 620; loss: 0.53; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.57; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.84
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.97
Val Epoch over. val_loss: 0.42262265475312616; val_accuracy: 0.8771894904458599 

The current subspace-distance is: 4.41578304162249e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.72; acc: 0.81
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.63; acc: 0.78
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.66; acc: 0.8
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.8
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.57; acc: 0.8
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.82; acc: 0.73
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.5; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.28; acc: 0.89
Val Epoch over. val_loss: 0.4625015067067116; val_accuracy: 0.8561902866242038 

The current subspace-distance is: 4.905962850898504e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.62; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.54; acc: 0.84
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.45; acc: 0.81
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.44; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.83
Batch: 520; loss: 0.7; acc: 0.84
Batch: 540; loss: 0.6; acc: 0.78
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.78; acc: 0.77
Batch: 620; loss: 0.58; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.83
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.52; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.44; acc: 0.83
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.85; acc: 0.73
Batch: 140; loss: 0.27; acc: 0.89
Val Epoch over. val_loss: 0.49324444657678057; val_accuracy: 0.8444466560509554 

The current subspace-distance is: 5.4030580940889195e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.61; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.74; acc: 0.86
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.67; acc: 0.77
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.55; acc: 0.83
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.81; acc: 0.81
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.75; acc: 0.73
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.55; acc: 0.83
Batch: 560; loss: 0.73; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.55; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.84
Batch: 720; loss: 0.52; acc: 0.81
Batch: 740; loss: 0.37; acc: 0.83
Batch: 760; loss: 0.49; acc: 0.84
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.71; acc: 0.78
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.55; acc: 0.81
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.24; acc: 0.89
Val Epoch over. val_loss: 0.4917231945759931; val_accuracy: 0.8530055732484076 

The current subspace-distance is: 5.804651300422847e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.81
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.61; acc: 0.78
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.79; acc: 0.73
Batch: 300; loss: 0.64; acc: 0.81
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.55; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.57; acc: 0.84
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.56; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.61; acc: 0.8
Batch: 700; loss: 0.58; acc: 0.83
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.83
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.3; acc: 0.86
Val Epoch over. val_loss: 0.4302322135134867; val_accuracy: 0.8665406050955414 

The current subspace-distance is: 6.18494741502218e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.67; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.91
Batch: 260; loss: 0.49; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.55; acc: 0.83
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.64; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.97
Val Epoch over. val_loss: 0.37679486242449206; val_accuracy: 0.88953025477707 

The current subspace-distance is: 6.564492650795728e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.81
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.59; acc: 0.83
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.46; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.85; acc: 0.81
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.77; acc: 0.75
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.54; acc: 0.88
Batch: 780; loss: 0.58; acc: 0.8
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.36235354864483427; val_accuracy: 0.8947054140127388 

The current subspace-distance is: 6.898015271872282e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.91
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.65; acc: 0.78
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.94
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.86
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.97
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.15; acc: 0.98
Batch: 740; loss: 0.59; acc: 0.86
Batch: 760; loss: 0.56; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.95
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.4044153384247403; val_accuracy: 0.8802746815286624 

The current subspace-distance is: 7.277602708199993e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.55; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.84
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.53; acc: 0.8
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.41; acc: 0.83
Batch: 620; loss: 0.62; acc: 0.83
Batch: 640; loss: 0.66; acc: 0.8
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.54; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.53; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.57; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.58; acc: 0.83
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.23; acc: 0.95
Val Epoch over. val_loss: 0.4209917381785478; val_accuracy: 0.8738057324840764 

The current subspace-distance is: 7.638119132025167e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.55; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.51; acc: 0.77
Batch: 160; loss: 0.42; acc: 0.94
Batch: 180; loss: 0.57; acc: 0.83
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.54; acc: 0.81
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.53; acc: 0.83
Batch: 540; loss: 0.5; acc: 0.83
Batch: 560; loss: 0.75; acc: 0.8
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.61; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.6; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.57; acc: 0.84
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.7; acc: 0.81
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3910255135054801; val_accuracy: 0.8865445859872612 

The current subspace-distance is: 7.71408376749605e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.61; acc: 0.78
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.46; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.84
Batch: 240; loss: 0.26; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.65; acc: 0.8
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.71; acc: 0.81
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.48; acc: 0.84
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.62; acc: 0.81
Batch: 680; loss: 0.4; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.22; acc: 0.97
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3417275069150955; val_accuracy: 0.9004777070063694 

The current subspace-distance is: 7.955157343531027e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.57; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.83
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.53; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.69; acc: 0.83
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.61; acc: 0.84
Batch: 380; loss: 0.51; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.55; acc: 0.86
Batch: 540; loss: 0.71; acc: 0.83
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.86
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.21; acc: 0.92
Val Epoch over. val_loss: 0.379180192093181; val_accuracy: 0.8891321656050956 

The current subspace-distance is: 8.183710451703519e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.58; acc: 0.84
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.59; acc: 0.81
Batch: 340; loss: 0.59; acc: 0.86
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.75; acc: 0.83
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.78; acc: 0.81
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.6; acc: 0.8
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.81
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.8
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.89 

Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.39870031538662637; val_accuracy: 0.8809713375796179 

The current subspace-distance is: 8.396998600801453e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.59; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.71; acc: 0.78
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.45; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.49; acc: 0.89
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.63; acc: 0.84
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.64; acc: 0.81
Batch: 740; loss: 0.49; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.36031977751642275; val_accuracy: 0.8945063694267515 

The current subspace-distance is: 8.780870120972395e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.55; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.14; acc: 0.98
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.57; acc: 0.89
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.98
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.91
Batch: 720; loss: 0.61; acc: 0.86
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3860355813507062; val_accuracy: 0.8851512738853503 

The current subspace-distance is: 9.013047383632511e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.6; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.66; acc: 0.86
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.89
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.51; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.34122648612139334; val_accuracy: 0.9013734076433121 

The current subspace-distance is: 9.252186282537878e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.52; acc: 0.88
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.66; acc: 0.84
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.49; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.46; acc: 0.8
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.51; acc: 0.83
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3331510623928848; val_accuracy: 0.9034633757961783 

The current subspace-distance is: 9.51446418184787e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.86
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.09; acc: 1.0
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3450974352230692; val_accuracy: 0.8983877388535032 

The current subspace-distance is: 9.658329508965835e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.86
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.47; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.54; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.5; acc: 0.81
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.45; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.6; acc: 0.77
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3371411712401232; val_accuracy: 0.9022691082802548 

The current subspace-distance is: 9.963748743757606e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.27; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.81
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.56; acc: 0.88
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.48; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.57; acc: 0.83
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3386862053992642; val_accuracy: 0.9006767515923567 

The current subspace-distance is: 0.0001006792881526053 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.84
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.6; acc: 0.84
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.57; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.81
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.63; acc: 0.83
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.55; acc: 0.84
Batch: 660; loss: 0.6; acc: 0.8
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.55; acc: 0.8
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3379770563856052; val_accuracy: 0.9025676751592356 

The current subspace-distance is: 0.00010285302414558828 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.55; acc: 0.81
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.46; acc: 0.83
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.5; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.94
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.59; acc: 0.83
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.62; acc: 0.84
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.57; acc: 0.83
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.33740878098045185; val_accuracy: 0.9020700636942676 

The current subspace-distance is: 0.00010523645323701203 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.58; acc: 0.81
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.65; acc: 0.84
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.55; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.55; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3404873784892498; val_accuracy: 0.9029657643312102 

The current subspace-distance is: 0.00010708046465879306 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.81
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.48; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.64; acc: 0.84
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.65; acc: 0.83
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.46; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.81
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3335940274795529; val_accuracy: 0.9058519108280255 

The current subspace-distance is: 0.00010998193465638906 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.42; acc: 0.81
Batch: 160; loss: 0.4; acc: 0.84
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.83
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.63; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.71; acc: 0.81
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.84
Batch: 540; loss: 0.55; acc: 0.83
Batch: 560; loss: 0.6; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.54; acc: 0.89
Batch: 720; loss: 0.53; acc: 0.88
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.53; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.33373540689706044; val_accuracy: 0.903562898089172 

The current subspace-distance is: 0.00011325540981488302 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.89
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.68; acc: 0.81
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.330692229614516; val_accuracy: 0.9032643312101911 

The current subspace-distance is: 0.00011582308070501313 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.53; acc: 0.84
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.92
Batch: 540; loss: 0.62; acc: 0.81
Batch: 560; loss: 0.71; acc: 0.81
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.55; acc: 0.86
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.33687661773270106; val_accuracy: 0.9025676751592356 

The current subspace-distance is: 0.00011786864342866465 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.26; acc: 0.97
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.54; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.65; acc: 0.83
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.46; acc: 0.81
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3313142156145375; val_accuracy: 0.9034633757961783 

The current subspace-distance is: 0.00011869204899994656 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.77; acc: 0.8
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.97
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.91
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.47; acc: 0.89
Batch: 420; loss: 0.81; acc: 0.83
Batch: 440; loss: 0.56; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.84
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.53; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.5; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.58; acc: 0.83
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.33095311207376465; val_accuracy: 0.9034633757961783 

The current subspace-distance is: 0.00012044244795106351 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.55; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.64; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.98
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3319745484953094; val_accuracy: 0.9060509554140127 

The current subspace-distance is: 0.00012560057803057134 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.58; acc: 0.84
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.83
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.66; acc: 0.84
Batch: 520; loss: 0.58; acc: 0.84
Batch: 540; loss: 0.52; acc: 0.86
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.83
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3321341061430752; val_accuracy: 0.9036624203821656 

The current subspace-distance is: 0.00012837207759730518 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.84
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.44; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.92
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.54; acc: 0.91
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.56; acc: 0.81
Batch: 680; loss: 0.33; acc: 0.94
Batch: 700; loss: 0.56; acc: 0.84
Batch: 720; loss: 0.46; acc: 0.91
Batch: 740; loss: 0.44; acc: 0.91
Batch: 760; loss: 0.64; acc: 0.86
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.33101825501508775; val_accuracy: 0.9034633757961783 

The current subspace-distance is: 0.0001297558774240315 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.54; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.7; acc: 0.81
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.53; acc: 0.84
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.55; acc: 0.8
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.97
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3361945971372021; val_accuracy: 0.9037619426751592 

The current subspace-distance is: 0.0001319002331001684 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.55; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.76; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.42; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.38; acc: 0.94
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.92
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.69; acc: 0.77
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.329275800876177; val_accuracy: 0.9053542993630573 

The current subspace-distance is: 0.00013526540715247393 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.54; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.62; acc: 0.86
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.61; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.56; acc: 0.77
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.56; acc: 0.8
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.71; acc: 0.84
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.62; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.59; acc: 0.78
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3300475105168713; val_accuracy: 0.9044585987261147 

The current subspace-distance is: 0.00013800831220578402 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.74; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.3; acc: 0.83
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.46; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.62; acc: 0.88
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.86
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.74; acc: 0.78
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.81
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.42; acc: 0.83
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.86
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.48; acc: 0.84
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.32889288530987537; val_accuracy: 0.9047571656050956 

The current subspace-distance is: 0.00013731421495322138 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.88
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.63; acc: 0.84
Batch: 280; loss: 0.62; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.62; acc: 0.88
Batch: 440; loss: 0.58; acc: 0.8
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.83
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3298996746255334; val_accuracy: 0.9047571656050956 

The current subspace-distance is: 0.00013696214591618627 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.55; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.51; acc: 0.8
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.45; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.97
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.55; acc: 0.81
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.62; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3287375654289677; val_accuracy: 0.9064490445859873 

The current subspace-distance is: 0.00013801094610244036 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.58; acc: 0.84
Batch: 180; loss: 0.61; acc: 0.8
Batch: 200; loss: 0.49; acc: 0.89
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.52; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.52; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3288206696795051; val_accuracy: 0.9049562101910829 

The current subspace-distance is: 0.00014162618026603013 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.49; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.48; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.58; acc: 0.86
Batch: 360; loss: 0.47; acc: 0.83
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.34; acc: 0.86
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.6; acc: 0.86
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.32949371099661867; val_accuracy: 0.9057523885350318 

The current subspace-distance is: 0.00014494708739221096 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.81
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.94
Batch: 200; loss: 0.4; acc: 0.92
Batch: 220; loss: 0.64; acc: 0.86
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.45; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.95
Batch: 660; loss: 0.48; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.84
Batch: 700; loss: 0.43; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3292950491189577; val_accuracy: 0.904359076433121 

The current subspace-distance is: 0.0001466074463678524 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.91
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.65; acc: 0.86
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.49; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.86
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.32921671573143857; val_accuracy: 0.9045581210191083 

The current subspace-distance is: 0.00015004364831838757 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.45; acc: 0.83
Batch: 400; loss: 0.76; acc: 0.81
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.55; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.52; acc: 0.83
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.58; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.55; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.32934821857388613; val_accuracy: 0.9057523885350318 

The current subspace-distance is: 0.0001507273263996467 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.51; acc: 0.86
Batch: 260; loss: 0.79; acc: 0.8
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.56; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.36; acc: 0.95
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.84
Batch: 520; loss: 0.51; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.53; acc: 0.89
Batch: 640; loss: 0.77; acc: 0.81
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.69; acc: 0.84
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.32844257513713687; val_accuracy: 0.9049562101910829 

The current subspace-distance is: 0.00015040051948744804 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.86
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.73; acc: 0.83
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.56; acc: 0.81
Batch: 400; loss: 0.43; acc: 0.83
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.67; acc: 0.78
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.61; acc: 0.8
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.5; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.84
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3288366199251573; val_accuracy: 0.9050557324840764 

The current subspace-distance is: 0.00015264669491443783 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_130_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 29716
elements in E: 6298600
fraction nonzero: 0.004717873813228336
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.06
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.16
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.28; acc: 0.28
Batch: 340; loss: 2.29; acc: 0.25
Batch: 360; loss: 2.29; acc: 0.23
Batch: 380; loss: 2.28; acc: 0.23
Batch: 400; loss: 2.28; acc: 0.27
Batch: 420; loss: 2.27; acc: 0.44
Batch: 440; loss: 2.28; acc: 0.27
Batch: 460; loss: 2.28; acc: 0.27
Batch: 480; loss: 2.28; acc: 0.25
Batch: 500; loss: 2.28; acc: 0.31
Batch: 520; loss: 2.26; acc: 0.27
Batch: 540; loss: 2.27; acc: 0.31
Batch: 560; loss: 2.26; acc: 0.34
Batch: 580; loss: 2.26; acc: 0.31
Batch: 600; loss: 2.26; acc: 0.31
Batch: 620; loss: 2.27; acc: 0.28
Batch: 640; loss: 2.24; acc: 0.34
Batch: 660; loss: 2.24; acc: 0.36
Batch: 680; loss: 2.24; acc: 0.27
Batch: 700; loss: 2.23; acc: 0.31
Batch: 720; loss: 2.22; acc: 0.39
Batch: 740; loss: 2.23; acc: 0.34
Batch: 760; loss: 2.2; acc: 0.45
Batch: 780; loss: 2.17; acc: 0.47
Train Epoch over. train_loss: 2.27; train_accuracy: 0.24 

Batch: 0; loss: 2.19; acc: 0.36
Batch: 20; loss: 2.22; acc: 0.34
Batch: 40; loss: 2.17; acc: 0.45
Batch: 60; loss: 2.19; acc: 0.39
Batch: 80; loss: 2.2; acc: 0.38
Batch: 100; loss: 2.2; acc: 0.39
Batch: 120; loss: 2.18; acc: 0.42
Batch: 140; loss: 2.2; acc: 0.34
Val Epoch over. val_loss: 2.200554155240393; val_accuracy: 0.3450437898089172 

The current subspace-distance is: 6.288187250902411e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.22; acc: 0.31
Batch: 20; loss: 2.16; acc: 0.42
Batch: 40; loss: 2.17; acc: 0.31
Batch: 60; loss: 2.14; acc: 0.44
Batch: 80; loss: 2.11; acc: 0.33
Batch: 100; loss: 2.16; acc: 0.41
Batch: 120; loss: 2.08; acc: 0.38
Batch: 140; loss: 2.05; acc: 0.55
Batch: 160; loss: 2.02; acc: 0.45
Batch: 180; loss: 1.99; acc: 0.45
Batch: 200; loss: 1.92; acc: 0.41
Batch: 220; loss: 1.78; acc: 0.47
Batch: 240; loss: 1.55; acc: 0.59
Batch: 260; loss: 1.42; acc: 0.64
Batch: 280; loss: 1.26; acc: 0.62
Batch: 300; loss: 1.19; acc: 0.66
Batch: 320; loss: 1.24; acc: 0.59
Batch: 340; loss: 0.96; acc: 0.75
Batch: 360; loss: 0.92; acc: 0.69
Batch: 380; loss: 0.66; acc: 0.84
Batch: 400; loss: 1.02; acc: 0.77
Batch: 420; loss: 0.77; acc: 0.8
Batch: 440; loss: 0.8; acc: 0.72
Batch: 460; loss: 0.91; acc: 0.72
Batch: 480; loss: 0.62; acc: 0.88
Batch: 500; loss: 0.79; acc: 0.77
Batch: 520; loss: 0.48; acc: 0.89
Batch: 540; loss: 0.66; acc: 0.83
Batch: 560; loss: 0.59; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.72; acc: 0.77
Batch: 620; loss: 0.97; acc: 0.73
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.58; acc: 0.77
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.9; acc: 0.66
Batch: 720; loss: 0.6; acc: 0.78
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.63; acc: 0.81
Batch: 780; loss: 0.54; acc: 0.83
Train Epoch over. train_loss: 1.18; train_accuracy: 0.65 

Batch: 0; loss: 1.02; acc: 0.69
Batch: 20; loss: 0.96; acc: 0.69
Batch: 40; loss: 0.69; acc: 0.77
Batch: 60; loss: 1.36; acc: 0.67
Batch: 80; loss: 1.11; acc: 0.7
Batch: 100; loss: 0.85; acc: 0.69
Batch: 120; loss: 1.24; acc: 0.66
Batch: 140; loss: 0.6; acc: 0.77
Val Epoch over. val_loss: 0.9684980374992274; val_accuracy: 0.7139729299363057 

The current subspace-distance is: 1.868575236585457e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.96; acc: 0.64
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.66; acc: 0.73
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.73; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.56; acc: 0.83
Batch: 180; loss: 0.56; acc: 0.86
Batch: 200; loss: 0.55; acc: 0.81
Batch: 220; loss: 0.68; acc: 0.75
Batch: 240; loss: 0.6; acc: 0.78
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.44; acc: 0.86
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.63; acc: 0.78
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.56; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.6; acc: 0.78
Batch: 540; loss: 0.87; acc: 0.77
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.93; acc: 0.75
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.8
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.78
Batch: 700; loss: 0.68; acc: 0.73
Batch: 720; loss: 0.74; acc: 0.78
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.8
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.61; acc: 0.77
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.37; acc: 0.88
Val Epoch over. val_loss: 0.5305124656030327; val_accuracy: 0.8324044585987261 

The current subspace-distance is: 2.7760033844970167e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.69; acc: 0.78
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.45; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.52; acc: 0.81
Batch: 240; loss: 0.54; acc: 0.77
Batch: 260; loss: 0.45; acc: 0.83
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.61; acc: 0.78
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.5; acc: 0.83
Batch: 440; loss: 0.44; acc: 0.94
Batch: 460; loss: 0.57; acc: 0.88
Batch: 480; loss: 0.65; acc: 0.77
Batch: 500; loss: 0.58; acc: 0.86
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.46; acc: 0.83
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.67; acc: 0.77
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.56; acc: 0.81
Batch: 720; loss: 0.6; acc: 0.78
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.54; acc: 0.81
Batch: 780; loss: 0.43; acc: 0.81
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.99; acc: 0.67
Batch: 40; loss: 0.62; acc: 0.86
Batch: 60; loss: 0.94; acc: 0.75
Batch: 80; loss: 0.68; acc: 0.78
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 1.08; acc: 0.72
Batch: 140; loss: 0.41; acc: 0.8
Val Epoch over. val_loss: 0.8022391714487865; val_accuracy: 0.761843152866242 

The current subspace-distance is: 3.434311656747013e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.92; acc: 0.7
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.54; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.67; acc: 0.84
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.51; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.46; acc: 0.89
Batch: 500; loss: 0.58; acc: 0.83
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.53; acc: 0.86
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.35307978632248893; val_accuracy: 0.8974920382165605 

The current subspace-distance is: 3.9847891457611695e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.37; acc: 0.84
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.81
Batch: 140; loss: 0.44; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.83
Batch: 180; loss: 0.63; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.88; acc: 0.73
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.54; acc: 0.83
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.72; acc: 0.83
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.67; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.4047376090648827; val_accuracy: 0.8813694267515924 

The current subspace-distance is: 4.867904863203876e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.69; acc: 0.8
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.58; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.42; acc: 0.88
Batch: 180; loss: 0.61; acc: 0.81
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.62; acc: 0.73
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.57; acc: 0.86
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.61; acc: 0.81
Batch: 620; loss: 0.61; acc: 0.84
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.42133955785613153; val_accuracy: 0.8798765923566879 

The current subspace-distance is: 5.684321149601601e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.51; acc: 0.81
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.55; acc: 0.88
Batch: 280; loss: 0.47; acc: 0.83
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.45; acc: 0.83
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.76; acc: 0.84
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.59; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.78; acc: 0.8
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.41986120943051236; val_accuracy: 0.8679339171974523 

The current subspace-distance is: 6.307626608759165e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.74; acc: 0.8
Batch: 100; loss: 0.47; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.55; acc: 0.88
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.62; acc: 0.81
Batch: 260; loss: 0.45; acc: 0.89
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.54; acc: 0.86
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.65; acc: 0.84
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.63; acc: 0.84
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.45; acc: 0.83
Batch: 520; loss: 0.3; acc: 0.86
Batch: 540; loss: 0.6; acc: 0.84
Batch: 560; loss: 0.56; acc: 0.78
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.55; acc: 0.83
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.4177666320732445; val_accuracy: 0.8744028662420382 

The current subspace-distance is: 6.753687921445817e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.57; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.61; acc: 0.86
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.84
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.53; acc: 0.78
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.48; acc: 0.81
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.79; acc: 0.84
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.36955578041494275; val_accuracy: 0.8880374203821656 

The current subspace-distance is: 6.881714216433465e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.53; acc: 0.81
Batch: 320; loss: 0.3; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.81
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.95
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.51; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.95
Batch: 780; loss: 0.46; acc: 0.81
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.33065287640709784; val_accuracy: 0.9019705414012739 

The current subspace-distance is: 7.49816172174178e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.86
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.43; acc: 0.81
Batch: 180; loss: 0.38; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.98
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.52; acc: 0.86
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.59; acc: 0.86
Batch: 600; loss: 0.43; acc: 0.94
Batch: 620; loss: 0.51; acc: 0.8
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.41; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.52; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.69; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.35095848902395577; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 7.998320506885648e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.81
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.5; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.52; acc: 0.86
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.6; acc: 0.8
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.26; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.59; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.63; acc: 0.75
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.73; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.3384903974973472; val_accuracy: 0.8974920382165605 

The current subspace-distance is: 8.354533201782033e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.46; acc: 0.8
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.81
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.56; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.67; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.387350279007368; val_accuracy: 0.8855493630573248 

The current subspace-distance is: 8.512201748089865e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.8
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.28; acc: 0.86
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.58; acc: 0.83
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.55; acc: 0.83
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.86
Batch: 700; loss: 0.47; acc: 0.81
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.54; acc: 0.81
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.42; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.3722643988432398; val_accuracy: 0.8869426751592356 

The current subspace-distance is: 8.745786908548325e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.6; acc: 0.81
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.38; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.83
Batch: 340; loss: 0.21; acc: 0.97
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.86
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.97
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.72; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.33071307425096536; val_accuracy: 0.9008757961783439 

The current subspace-distance is: 9.08255678950809e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.53; acc: 0.86
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.62; acc: 0.81
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.64; acc: 0.83
Batch: 300; loss: 0.42; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.55; acc: 0.89
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.84
Batch: 520; loss: 0.49; acc: 0.81
Batch: 540; loss: 0.66; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.81
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.59; acc: 0.86
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.34621642809954417; val_accuracy: 0.8995820063694268 

The current subspace-distance is: 9.380087431054562e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.65; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.65; acc: 0.77
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.67; acc: 0.81
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.49; acc: 0.77
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.5; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.68; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.75; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.3444749618981295; val_accuracy: 0.8985867834394905 

The current subspace-distance is: 9.798202518140897e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.95; acc: 0.75
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.5; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.52; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.4; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.51; acc: 0.91
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.38; acc: 0.84
Batch: 540; loss: 0.63; acc: 0.81
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.71; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3544193956123036; val_accuracy: 0.8974920382165605 

The current subspace-distance is: 0.00010067108814837411 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.16; acc: 0.98
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.84
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.48; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.61; acc: 0.84
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.78
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.38333300909229145; val_accuracy: 0.8851512738853503 

The current subspace-distance is: 0.00010185460996581241 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.83
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.44; acc: 0.83
Batch: 660; loss: 0.33; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.95
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3197799596911783; val_accuracy: 0.9065485668789809 

The current subspace-distance is: 0.0001053847445291467 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.86
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.54; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.84
Batch: 260; loss: 0.48; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.54; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.49; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.4; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.3218065034242193; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 0.00010695616947486997 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.44; acc: 0.83
Batch: 380; loss: 0.5; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.51; acc: 0.81
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.53; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.6; acc: 0.83
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.68; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3247078946156866; val_accuracy: 0.9047571656050956 

The current subspace-distance is: 0.00010991217277478427 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.62; acc: 0.86
Batch: 240; loss: 0.57; acc: 0.84
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.36; acc: 0.84
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.46; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.56; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.83
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.32; acc: 0.84
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.67; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3313430125831039; val_accuracy: 0.9013734076433121 

The current subspace-distance is: 0.00011255295248702168 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.46; acc: 0.81
Batch: 600; loss: 0.27; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.83
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.69; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.32313280400766686; val_accuracy: 0.9056528662420382 

The current subspace-distance is: 0.00011564099986571819 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.83
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.31757999107146717; val_accuracy: 0.9068471337579618 

The current subspace-distance is: 0.00011730877304216847 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.86
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.95
Batch: 420; loss: 0.43; acc: 0.94
Batch: 440; loss: 0.62; acc: 0.83
Batch: 460; loss: 0.43; acc: 0.81
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.48; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.83
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.68; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.32040393157939245; val_accuracy: 0.9059514331210191 

The current subspace-distance is: 0.00011828830611193553 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.47; acc: 0.8
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.84
Batch: 240; loss: 0.39; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.51; acc: 0.8
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.53; acc: 0.86
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.45; acc: 0.81
Batch: 720; loss: 0.67; acc: 0.81
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.52; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.68; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.94
Val Epoch over. val_loss: 0.32891787626561086; val_accuracy: 0.9020700636942676 

The current subspace-distance is: 0.00012026070908177644 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.81
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.89
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.51; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.72; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.84
Batch: 700; loss: 0.51; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.68; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.32125334489117763; val_accuracy: 0.9059514331210191 

The current subspace-distance is: 0.0001216276505147107 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.6; acc: 0.83
Batch: 360; loss: 0.41; acc: 0.84
Batch: 380; loss: 0.55; acc: 0.83
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.53; acc: 0.86
Batch: 560; loss: 0.43; acc: 0.91
Batch: 580; loss: 0.48; acc: 0.81
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.88
Batch: 720; loss: 0.49; acc: 0.78
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.53; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3158582801556891; val_accuracy: 0.908140923566879 

The current subspace-distance is: 0.00012514175614342093 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.57; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.56; acc: 0.83
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.78; acc: 0.78
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.41; acc: 0.83
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.69; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3163902648979691; val_accuracy: 0.9075437898089171 

The current subspace-distance is: 0.0001250153436558321 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.53; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.81
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.35; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.64; acc: 0.88
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.84
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.31556071231889116; val_accuracy: 0.9083399681528662 

The current subspace-distance is: 0.00012666441034525633 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.62; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.58; acc: 0.84
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.33; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.94
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.48; acc: 0.83
Batch: 660; loss: 0.44; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.69; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3171264682510856; val_accuracy: 0.9074442675159236 

The current subspace-distance is: 0.00012663810048252344 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.42; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.61; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.44; acc: 0.83
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.55; acc: 0.81
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.68; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3171446185772586; val_accuracy: 0.9071457006369427 

The current subspace-distance is: 0.00013015756849199533 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.52; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.84
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.81
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.31; acc: 0.84
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.7; acc: 0.84
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.31716970297371505; val_accuracy: 0.9069466560509554 

The current subspace-distance is: 0.0001301105075981468 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.69; acc: 0.8
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.86
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.5; acc: 0.81
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.42; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.3178672936217041; val_accuracy: 0.9072452229299363 

The current subspace-distance is: 0.00013142041279934347 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.59; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.95
Batch: 380; loss: 0.32; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.78
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.57; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.47; acc: 0.83
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.66; acc: 0.88
Batch: 780; loss: 0.43; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.31540844869461787; val_accuracy: 0.9090366242038217 

The current subspace-distance is: 0.00013470591511577368 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.81
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.5; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.89
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.47; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.73; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.31530539848052774; val_accuracy: 0.9080414012738853 

The current subspace-distance is: 0.00013906123058404773 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.86
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.52; acc: 0.86
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.89
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.59; acc: 0.81
Batch: 760; loss: 0.67; acc: 0.84
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3159804673995941; val_accuracy: 0.9088375796178344 

The current subspace-distance is: 0.0001404300273861736 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.51; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.63; acc: 0.81
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.53; acc: 0.81
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.5; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3153298221955633; val_accuracy: 0.908140923566879 

The current subspace-distance is: 0.00014049930905457586 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.56; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.92
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.5; acc: 0.83
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.88
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.46; acc: 0.89
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.62; acc: 0.84
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3149766618279135; val_accuracy: 0.908937101910828 

The current subspace-distance is: 0.00014272157568484545 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.62; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.6; acc: 0.75
Batch: 220; loss: 0.27; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.54; acc: 0.84
Batch: 280; loss: 0.65; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.94
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.49; acc: 0.81
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.54; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.31456266604601196; val_accuracy: 0.9085390127388535 

The current subspace-distance is: 0.00014347181422635913 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.6; acc: 0.86
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.69; acc: 0.78
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.95
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.56; acc: 0.86
Batch: 420; loss: 0.26; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.98
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.47; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3146751628370042; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 0.00014609828940592706 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.6; acc: 0.83
Batch: 180; loss: 0.6; acc: 0.8
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.83
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.31520197792038035; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 0.00014803162775933743 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.43; acc: 0.84
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.88
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.43; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.92
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.49; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.65; acc: 0.78
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.37; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.31419176247659003; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 0.00014793095760978758 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.42; acc: 0.83
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.63; acc: 0.84
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.5; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.69; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.31543727442147623; val_accuracy: 0.9080414012738853 

The current subspace-distance is: 0.00015070462541189045 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.46; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.57; acc: 0.88
Batch: 540; loss: 0.23; acc: 0.97
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.95
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.38; acc: 0.95
Batch: 780; loss: 0.42; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3160444145464593; val_accuracy: 0.908140923566879 

The current subspace-distance is: 0.00015163520583882928 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.56; acc: 0.83
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.41; acc: 0.83
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.83
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.45; acc: 0.83
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.63; acc: 0.86
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3161009340339406; val_accuracy: 0.9079418789808917 

The current subspace-distance is: 0.00015381879347842187 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.72; acc: 0.83
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.57; acc: 0.88
Batch: 440; loss: 0.48; acc: 0.89
Batch: 460; loss: 0.47; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.61; acc: 0.84
Batch: 720; loss: 0.5; acc: 0.84
Batch: 740; loss: 0.65; acc: 0.81
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.31471814039596324; val_accuracy: 0.9086385350318471 

The current subspace-distance is: 0.0001557589857839048 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.75; acc: 0.8
Batch: 160; loss: 0.4; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.66; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.51; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.56; acc: 0.86
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.4; acc: 0.84
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.65; acc: 0.77
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.55; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.71; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.3144421384782548; val_accuracy: 0.9086385350318471 

The current subspace-distance is: 0.00015818716201465577 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_140_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 31685
elements in E: 6748500
fraction nonzero: 0.004695117433503742
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.31; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.28; acc: 0.12
Batch: 280; loss: 2.28; acc: 0.09
Batch: 300; loss: 2.27; acc: 0.12
Batch: 320; loss: 2.27; acc: 0.22
Batch: 340; loss: 2.28; acc: 0.16
Batch: 360; loss: 2.28; acc: 0.16
Batch: 380; loss: 2.26; acc: 0.2
Batch: 400; loss: 2.26; acc: 0.25
Batch: 420; loss: 2.25; acc: 0.31
Batch: 440; loss: 2.24; acc: 0.25
Batch: 460; loss: 2.24; acc: 0.28
Batch: 480; loss: 2.23; acc: 0.2
Batch: 500; loss: 2.2; acc: 0.34
Batch: 520; loss: 2.16; acc: 0.3
Batch: 540; loss: 2.13; acc: 0.36
Batch: 560; loss: 2.0; acc: 0.47
Batch: 580; loss: 1.98; acc: 0.38
Batch: 600; loss: 1.71; acc: 0.45
Batch: 620; loss: 1.5; acc: 0.48
Batch: 640; loss: 1.16; acc: 0.61
Batch: 660; loss: 1.32; acc: 0.48
Batch: 680; loss: 1.07; acc: 0.62
Batch: 700; loss: 0.95; acc: 0.69
Batch: 720; loss: 0.81; acc: 0.72
Batch: 740; loss: 0.81; acc: 0.73
Batch: 760; loss: 0.82; acc: 0.72
Batch: 780; loss: 1.3; acc: 0.59
Train Epoch over. train_loss: 1.98; train_accuracy: 0.3 

Batch: 0; loss: 1.42; acc: 0.59
Batch: 20; loss: 1.92; acc: 0.52
Batch: 40; loss: 0.83; acc: 0.73
Batch: 60; loss: 1.09; acc: 0.62
Batch: 80; loss: 1.15; acc: 0.64
Batch: 100; loss: 0.94; acc: 0.67
Batch: 120; loss: 1.29; acc: 0.59
Batch: 140; loss: 1.41; acc: 0.58
Val Epoch over. val_loss: 1.336751246528261; val_accuracy: 0.6114649681528662 

The current subspace-distance is: 1.0013300197897479e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.41; acc: 0.61
Batch: 20; loss: 0.91; acc: 0.73
Batch: 40; loss: 1.13; acc: 0.69
Batch: 60; loss: 0.81; acc: 0.72
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.71; acc: 0.72
Batch: 120; loss: 0.85; acc: 0.72
Batch: 140; loss: 0.73; acc: 0.78
Batch: 160; loss: 0.54; acc: 0.77
Batch: 180; loss: 0.67; acc: 0.81
Batch: 200; loss: 0.51; acc: 0.81
Batch: 220; loss: 0.59; acc: 0.8
Batch: 240; loss: 0.68; acc: 0.8
Batch: 260; loss: 1.62; acc: 0.69
Batch: 280; loss: 0.6; acc: 0.8
Batch: 300; loss: 0.66; acc: 0.78
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 0.8; acc: 0.73
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.62; acc: 0.83
Batch: 400; loss: 0.79; acc: 0.75
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.6; acc: 0.78
Batch: 480; loss: 0.53; acc: 0.81
Batch: 500; loss: 0.68; acc: 0.8
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.53; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.54; acc: 0.8
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.84; acc: 0.81
Batch: 640; loss: 0.65; acc: 0.8
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.45; acc: 0.83
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 0.7; acc: 0.72
Batch: 780; loss: 0.72; acc: 0.83
Train Epoch over. train_loss: 0.64; train_accuracy: 0.8 

Batch: 0; loss: 0.64; acc: 0.77
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.95; acc: 0.77
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 1.01; acc: 0.7
Batch: 140; loss: 0.53; acc: 0.81
Val Epoch over. val_loss: 0.6425561571766616; val_accuracy: 0.7961783439490446 

The current subspace-distance is: 1.9585093468776904e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.56; acc: 0.77
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.81
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.72; acc: 0.81
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.74; acc: 0.8
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.58; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.55; acc: 0.84
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.81
Batch: 460; loss: 0.62; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.71; acc: 0.83
Batch: 600; loss: 0.49; acc: 0.89
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.57; acc: 0.8
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.57; acc: 0.81
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.78; acc: 0.77
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.57; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.35; acc: 0.89
Val Epoch over. val_loss: 0.4582262285480833; val_accuracy: 0.8589769108280255 

The current subspace-distance is: 2.552409023337532e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.58; acc: 0.84
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.95
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.8
Batch: 260; loss: 0.48; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.68; acc: 0.78
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.53; acc: 0.83
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.8; acc: 0.73
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.67; acc: 0.81
Batch: 780; loss: 0.38; acc: 0.84
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.73; acc: 0.72
Batch: 80; loss: 0.26; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.88
Val Epoch over. val_loss: 0.4162427480718133; val_accuracy: 0.8641520700636943 

The current subspace-distance is: 3.286181890871376e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.56; acc: 0.81
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.51; acc: 0.84
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.68; acc: 0.8
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.57; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.52; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.81
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.28; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.57; acc: 0.8
Batch: 640; loss: 0.75; acc: 0.75
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.47; acc: 0.83
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.17; acc: 0.98
Val Epoch over. val_loss: 0.4218704313229603; val_accuracy: 0.868531050955414 

The current subspace-distance is: 3.739331805263646e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.83
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.75; acc: 0.83
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.83
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.65; acc: 0.78
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 1.07; acc: 0.75
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.83
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.67; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.41; acc: 0.81
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.93; acc: 0.64
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.25; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.96; acc: 0.72
Batch: 140; loss: 0.23; acc: 0.94
Val Epoch over. val_loss: 0.44022515050734684; val_accuracy: 0.8675358280254777 

The current subspace-distance is: 4.2037820094265044e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.68; acc: 0.78
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.73; acc: 0.75
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.63; acc: 0.81
Batch: 380; loss: 0.68; acc: 0.83
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.55; acc: 0.8
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.53; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.42; acc: 0.84
Batch: 640; loss: 0.5; acc: 0.84
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.58; acc: 0.78
Batch: 20; loss: 0.74; acc: 0.75
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.9; acc: 0.78
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 1.13; acc: 0.66
Batch: 140; loss: 0.49; acc: 0.81
Val Epoch over. val_loss: 0.5452143969429526; val_accuracy: 0.8257364649681529 

The current subspace-distance is: 4.646616798709147e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.56; acc: 0.86
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.58; acc: 0.78
Batch: 220; loss: 0.39; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.49; acc: 0.81
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.44; acc: 0.84
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.57; acc: 0.84
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.44; acc: 0.83
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.86
Batch: 760; loss: 0.62; acc: 0.83
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.66; acc: 0.77
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.81
Batch: 120; loss: 1.11; acc: 0.7
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4881053755807269; val_accuracy: 0.8403662420382165 

The current subspace-distance is: 5.231918839854188e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.84
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.62; acc: 0.77
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.92
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.81
Batch: 260; loss: 0.44; acc: 0.84
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.83
Batch: 460; loss: 0.65; acc: 0.81
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.41; acc: 0.81
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.45; acc: 0.83
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.6; acc: 0.75
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.89; acc: 0.73
Batch: 140; loss: 0.42; acc: 0.83
Val Epoch over. val_loss: 0.47718942246049834; val_accuracy: 0.8459394904458599 

The current subspace-distance is: 5.625763151329011e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.83
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.95
Batch: 280; loss: 0.62; acc: 0.83
Batch: 300; loss: 0.59; acc: 0.81
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.30766377033321723; val_accuracy: 0.9050557324840764 

The current subspace-distance is: 6.125421350589022e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.49; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.81
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.83
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.98
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.2859241737966325; val_accuracy: 0.9107285031847133 

The current subspace-distance is: 6.551093247253448e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.56; acc: 0.81
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.37; acc: 0.8
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.65; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.6; acc: 0.86
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.4377715660698095; val_accuracy: 0.8642515923566879 

The current subspace-distance is: 6.897556158946827e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.95
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.57; acc: 0.84
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.98
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.47; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.98
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.81
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.73
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.325462081772127; val_accuracy: 0.8990843949044586 

The current subspace-distance is: 7.229347102111205e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.89
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.4; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.88
Batch: 620; loss: 0.62; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.34037587682532655; val_accuracy: 0.8956011146496815 

The current subspace-distance is: 7.44415883673355e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.4; acc: 0.81
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.39; acc: 0.83
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.65; acc: 0.78
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.58; acc: 0.83
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.47; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.56; acc: 0.86
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.78
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.27861369591040214; val_accuracy: 0.9138136942675159 

The current subspace-distance is: 7.806660141795874e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.62; acc: 0.83
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.84
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.16; acc: 0.98
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.54; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.274557953854655; val_accuracy: 0.9137141719745223 

The current subspace-distance is: 8.03086586529389e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.52; acc: 0.81
Batch: 300; loss: 0.39; acc: 0.86
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.44; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.49; acc: 0.89
Batch: 460; loss: 0.39; acc: 0.84
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.84
Batch: 700; loss: 0.48; acc: 0.81
Batch: 720; loss: 0.12; acc: 1.0
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.83
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2726167258658227; val_accuracy: 0.915406050955414 

The current subspace-distance is: 8.262194751296192e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.38; acc: 0.84
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.45; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.86
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.57; acc: 0.81
Batch: 520; loss: 0.38; acc: 0.86
Batch: 540; loss: 0.43; acc: 0.8
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.17; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.86
Batch: 740; loss: 0.41; acc: 0.92
Batch: 760; loss: 0.48; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3388125747916805; val_accuracy: 0.8940087579617835 

The current subspace-distance is: 8.580440771766007e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.5; acc: 0.77
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.83
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.27075174301388155; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 8.793757297098637e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.56; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.91
Batch: 520; loss: 0.42; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2878839580496405; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 9.087348007597029e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.49; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.4; acc: 0.81
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.84
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.51; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26036993594496116; val_accuracy: 0.9185907643312102 

The current subspace-distance is: 9.336257789982483e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.84
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.94
Batch: 180; loss: 0.35; acc: 0.94
Batch: 200; loss: 0.48; acc: 0.91
Batch: 220; loss: 0.48; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.7; acc: 0.88
Batch: 380; loss: 0.33; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.86
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.5; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.25969798701583957; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 9.647956903791055e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.38; acc: 0.84
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.47; acc: 0.83
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.36; acc: 0.84
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.88
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2638999844432636; val_accuracy: 0.919187898089172 

The current subspace-distance is: 9.871601650957018e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.86
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.65; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.84
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2614683383352058; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 0.0001012719512800686 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.26082942976503615; val_accuracy: 0.9183917197452229 

The current subspace-distance is: 0.00010417088924441487 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.81
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.59; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.53; acc: 0.84
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.57; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.38; acc: 0.84
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.61; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2540872241755959; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 0.00010697833204176277 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.38; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.97
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.09; acc: 1.0
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.84
Batch: 760; loss: 0.51; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.25594566639061944; val_accuracy: 0.9205812101910829 

The current subspace-distance is: 0.00010863485658774152 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.58; acc: 0.83
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.81
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.84
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2678982481170612; val_accuracy: 0.9163017515923567 

The current subspace-distance is: 0.00011160282883793116 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.74; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.86
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.260602591499971; val_accuracy: 0.9166998407643312 

The current subspace-distance is: 0.00011375922622391954 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.62; acc: 0.75
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.39; acc: 0.84
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.5; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2544670370733662; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 0.00011404597171349451 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.83
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.49; acc: 0.83
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.25033920324721914; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 0.00011693032138282433 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.84
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.62; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.51; acc: 0.89
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.88
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2535470690649406; val_accuracy: 0.9219745222929936 

The current subspace-distance is: 0.00011939950491068885 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.51; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.7; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.83
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.45; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.2564978326202198; val_accuracy: 0.9219745222929936 

The current subspace-distance is: 0.00012054872058797628 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.47; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.08; acc: 1.0
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.84
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2514483325990142; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 0.00012334019993431866 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.5; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.25011764884374704; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 0.00012702772801276296 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.42; acc: 0.81
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.2554269818126396; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 0.0001287391351070255 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.86
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.6; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.84
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2515262510081765; val_accuracy: 0.9244625796178344 

The current subspace-distance is: 0.00013021632912568748 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.69; acc: 0.84
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2492337484078802; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 0.00013387997751124203 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.95
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.49; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2493037926685658; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 0.00013688887702301145 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.45; acc: 0.81
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.53; acc: 0.84
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.59; acc: 0.83
Batch: 420; loss: 0.23; acc: 0.89
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.24940029526971708; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 0.00013948380365036428 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.25; acc: 0.84
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.84
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.81; acc: 0.81
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.51; acc: 0.78
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.24978037517826268; val_accuracy: 0.9235668789808917 

The current subspace-distance is: 0.00014142082363832742 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.49; acc: 0.91
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.44; acc: 0.8
Batch: 460; loss: 0.53; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.24889548493039076; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 0.00014377012848854065 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.49; acc: 0.83
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.48; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.52; acc: 0.81
Batch: 260; loss: 0.24; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.24882337405898008; val_accuracy: 0.9241640127388535 

The current subspace-distance is: 0.00014464231207966805 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.88
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.46; acc: 0.86
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.24921629167381365; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 0.00014719643513672054 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.86
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.84
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.24848342539778182; val_accuracy: 0.9233678343949044 

The current subspace-distance is: 0.00015051406808197498 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.88
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.24923758778222807; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 0.00015370214532595128 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.88
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.48; acc: 0.89
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.84
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2493211048518776; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 0.0001556884089950472 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.81
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.45; acc: 0.83
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.51; acc: 0.88
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.24784998510293899; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 0.00015896838158369064 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.6; acc: 0.84
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.83
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.84
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.24970344413712525; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 0.00016144079563673586 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.7; acc: 0.81
Batch: 160; loss: 0.25; acc: 0.89
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.86
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.94
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.73; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.44; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2483255225619313; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 0.00016250312910415232 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_150_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 33905
elements in E: 7198400
fraction nonzero: 0.004710074460991332
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.12
Batch: 260; loss: 2.28; acc: 0.19
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.27; acc: 0.19
Batch: 320; loss: 2.26; acc: 0.33
Batch: 340; loss: 2.27; acc: 0.31
Batch: 360; loss: 2.27; acc: 0.3
Batch: 380; loss: 2.26; acc: 0.33
Batch: 400; loss: 2.25; acc: 0.23
Batch: 420; loss: 2.24; acc: 0.36
Batch: 440; loss: 2.24; acc: 0.23
Batch: 460; loss: 2.24; acc: 0.23
Batch: 480; loss: 2.22; acc: 0.25
Batch: 500; loss: 2.22; acc: 0.17
Batch: 520; loss: 2.15; acc: 0.33
Batch: 540; loss: 2.12; acc: 0.38
Batch: 560; loss: 2.04; acc: 0.36
Batch: 580; loss: 2.03; acc: 0.34
Batch: 600; loss: 1.88; acc: 0.41
Batch: 620; loss: 1.91; acc: 0.36
Batch: 640; loss: 1.56; acc: 0.52
Batch: 660; loss: 1.52; acc: 0.48
Batch: 680; loss: 1.39; acc: 0.58
Batch: 700; loss: 1.04; acc: 0.69
Batch: 720; loss: 0.93; acc: 0.7
Batch: 740; loss: 0.97; acc: 0.64
Batch: 760; loss: 0.85; acc: 0.8
Batch: 780; loss: 0.81; acc: 0.77
Train Epoch over. train_loss: 2.02; train_accuracy: 0.32 

Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 1.34; acc: 0.48
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.72; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.7
Batch: 120; loss: 1.32; acc: 0.62
Batch: 140; loss: 1.01; acc: 0.58
Val Epoch over. val_loss: 0.9216884040528801; val_accuracy: 0.6890923566878981 

The current subspace-distance is: 9.143082934315316e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.67
Batch: 20; loss: 0.88; acc: 0.77
Batch: 40; loss: 0.89; acc: 0.73
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 0.72; acc: 0.72
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.75; acc: 0.78
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.8; acc: 0.73
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.7; acc: 0.77
Batch: 240; loss: 0.68; acc: 0.83
Batch: 260; loss: 1.08; acc: 0.69
Batch: 280; loss: 0.82; acc: 0.73
Batch: 300; loss: 0.98; acc: 0.78
Batch: 320; loss: 0.69; acc: 0.81
Batch: 340; loss: 0.85; acc: 0.73
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.72; acc: 0.83
Batch: 400; loss: 0.83; acc: 0.73
Batch: 420; loss: 0.77; acc: 0.75
Batch: 440; loss: 0.84; acc: 0.73
Batch: 460; loss: 0.84; acc: 0.77
Batch: 480; loss: 0.6; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.48; acc: 0.89
Batch: 540; loss: 0.76; acc: 0.7
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.62; acc: 0.84
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.96; acc: 0.7
Batch: 640; loss: 0.99; acc: 0.69
Batch: 660; loss: 0.7; acc: 0.77
Batch: 680; loss: 0.56; acc: 0.78
Batch: 700; loss: 0.74; acc: 0.73
Batch: 720; loss: 0.67; acc: 0.8
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.68; acc: 0.77
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.83; acc: 0.72
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 1.0; acc: 0.73
Batch: 80; loss: 0.55; acc: 0.77
Batch: 100; loss: 0.54; acc: 0.8
Batch: 120; loss: 1.16; acc: 0.67
Batch: 140; loss: 0.57; acc: 0.77
Val Epoch over. val_loss: 0.6475024427388124; val_accuracy: 0.7937898089171974 

The current subspace-distance is: 1.990741839108523e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.6; acc: 0.78
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.83
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.84
Batch: 160; loss: 0.67; acc: 0.78
Batch: 180; loss: 0.5; acc: 0.81
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.91
Batch: 240; loss: 0.75; acc: 0.81
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.52; acc: 0.81
Batch: 300; loss: 0.59; acc: 0.84
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.42; acc: 0.83
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.63; acc: 0.8
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.57; acc: 0.78
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.69; acc: 0.8
Batch: 600; loss: 0.39; acc: 0.84
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.57; acc: 0.84
Batch: 700; loss: 0.72; acc: 0.86
Batch: 720; loss: 0.62; acc: 0.8
Batch: 740; loss: 0.32; acc: 0.84
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.92
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4259964030734293; val_accuracy: 0.8661425159235668 

The current subspace-distance is: 2.71979170065606e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.81
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.39; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.5; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.91
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.48; acc: 0.8
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.53; acc: 0.81
Batch: 340; loss: 0.87; acc: 0.78
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.58; acc: 0.84
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.65; acc: 0.81
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.62; acc: 0.81
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.73; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.37757881607409494; val_accuracy: 0.8755971337579618 

The current subspace-distance is: 3.403146183700301e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.47; acc: 0.83
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.56; acc: 0.83
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.59; acc: 0.84
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.63; acc: 0.81
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.56; acc: 0.81
Batch: 380; loss: 0.14; acc: 0.98
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.63; acc: 0.83
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.95
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.55; acc: 0.83
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.86
Batch: 720; loss: 0.73; acc: 0.81
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.91
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.32771482247455863; val_accuracy: 0.8985867834394905 

The current subspace-distance is: 3.975466461270116e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.72; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.45; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.64; acc: 0.73
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.86
Batch: 500; loss: 0.56; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.81; acc: 0.88
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.57; acc: 0.84
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.43; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3440618610401062; val_accuracy: 0.8937101910828026 

The current subspace-distance is: 4.519143112702295e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.54; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.82; acc: 0.73
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.98
Batch: 360; loss: 0.51; acc: 0.78
Batch: 380; loss: 0.33; acc: 0.86
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.69; acc: 0.8
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.56; acc: 0.83
Batch: 740; loss: 0.41; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.86
Batch: 780; loss: 0.64; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.35; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.383283797841353; val_accuracy: 0.879578025477707 

The current subspace-distance is: 5.1317099860170856e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.43; acc: 0.89
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.5; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.59; acc: 0.81
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.71; acc: 0.83
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.3184747065708136; val_accuracy: 0.9008757961783439 

The current subspace-distance is: 5.68476170883514e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.53; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.86
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.62; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.56; acc: 0.81
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.43; acc: 0.81
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.48; acc: 0.92
Batch: 560; loss: 0.62; acc: 0.73
Batch: 580; loss: 0.53; acc: 0.81
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.353549968807181; val_accuracy: 0.8923168789808917 

The current subspace-distance is: 6.0271373513387516e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.58; acc: 0.8
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.53; acc: 0.84
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.98
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.47; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.34581769732343165; val_accuracy: 0.894406847133758 

The current subspace-distance is: 6.439102435251698e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.98
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.27039510723511884; val_accuracy: 0.9200835987261147 

The current subspace-distance is: 6.857039261376485e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.48; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.27; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26814360005460725; val_accuracy: 0.9193869426751592 

The current subspace-distance is: 7.215980440378189e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.83
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.84
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.84
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.95
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.59; acc: 0.83
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.1; acc: 1.0
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.31403768029372403; val_accuracy: 0.903562898089172 

The current subspace-distance is: 7.708649354754016e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.45; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.55; acc: 0.8
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.31282950318448105; val_accuracy: 0.9012738853503185 

The current subspace-distance is: 8.115525270113721e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.55; acc: 0.8
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.27701462449351694; val_accuracy: 0.9128184713375797 

The current subspace-distance is: 8.63615277921781e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.61; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.48; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.84
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.86
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.26572368894318105; val_accuracy: 0.9184912420382165 

The current subspace-distance is: 9.086056525120512e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.62; acc: 0.86
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.55; acc: 0.83
Batch: 380; loss: 0.48; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.27597729263791615; val_accuracy: 0.9141122611464968 

The current subspace-distance is: 9.289288573199883e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.42; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.45; acc: 0.89
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.5; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.22; acc: 0.97
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2771965358524945; val_accuracy: 0.914609872611465 

The current subspace-distance is: 9.856440738076344e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.56; acc: 0.84
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.97
Batch: 340; loss: 0.34; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.24; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2760662045923008; val_accuracy: 0.9142117834394905 

The current subspace-distance is: 9.987712110159919e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.86
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.48; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.08; acc: 1.0
Val Epoch over. val_loss: 0.2779109211294514; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 0.00010293898230884224 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.59; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.46; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2580308495623291; val_accuracy: 0.9201831210191083 

The current subspace-distance is: 0.00010791843669721857 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.6; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2570834905383693; val_accuracy: 0.9219745222929936 

The current subspace-distance is: 0.00010923137597274035 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.22; acc: 0.89
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.259226231509523; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 0.00011180995352333412 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.38; acc: 0.84
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.53; acc: 0.89
Batch: 620; loss: 0.67; acc: 0.84
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.25985111678197126; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 0.00011263584747212008 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.97
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.48; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2586567652927842; val_accuracy: 0.921875 

The current subspace-distance is: 0.00011454884224804118 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.98
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.89
Batch: 540; loss: 0.3; acc: 0.86
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.5; acc: 0.84
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25531458401471185; val_accuracy: 0.9212778662420382 

The current subspace-distance is: 0.0001166183064924553 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.55; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.86
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.36; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.25674615109896964; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 0.00011788055417127907 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.52; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.88
Batch: 780; loss: 0.51; acc: 0.84
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2585947111747257; val_accuracy: 0.9234673566878981 

The current subspace-distance is: 0.00011965224257437512 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2544138923667039; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 0.00012221101496834308 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.58; acc: 0.84
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2616608010688026; val_accuracy: 0.9213773885350318 

The current subspace-distance is: 0.00012433086521923542 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.54; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.91
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2534194500986368; val_accuracy: 0.9235668789808917 

The current subspace-distance is: 0.00012610007252078503 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.44; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.6; acc: 0.86
Batch: 560; loss: 0.52; acc: 0.81
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25151150099411135; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 0.00012756210344377905 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.83
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.49; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25214847542677715; val_accuracy: 0.9227707006369427 

The current subspace-distance is: 0.00012833016808144748 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.53; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.41; acc: 0.83
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2525448196561663; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 0.0001305610639974475 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.86
Batch: 180; loss: 0.36; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.97
Batch: 280; loss: 0.47; acc: 0.86
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.84
Batch: 560; loss: 0.22; acc: 0.89
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.46; acc: 0.86
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25224605066239075; val_accuracy: 0.9251592356687898 

The current subspace-distance is: 0.00013171460886951536 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.94
Batch: 200; loss: 0.4; acc: 0.84
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.86
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.24; acc: 0.89
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.4; acc: 0.84
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25320193032692573; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 0.00013405743811745197 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.5; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2518209614049477; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 0.0001356255088467151 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.83
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.54; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.86
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2532332367530674; val_accuracy: 0.9251592356687898 

The current subspace-distance is: 0.00013665622100234032 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.32; acc: 0.95
Batch: 240; loss: 0.6; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.84
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.1; acc: 1.0
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.48; acc: 0.83
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2524471562830316; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 0.0001377339067403227 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.52; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.4; acc: 0.84
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.6; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.88
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.84
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.57; acc: 0.84
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.47; acc: 0.88
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2526238246399696; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 0.0001405740185873583 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25061996433005973; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 0.00014283759810496122 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.22; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.88
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25085487221456637; val_accuracy: 0.923765923566879 

The current subspace-distance is: 0.00014579981507267803 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.55; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.59; acc: 0.83
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.83
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.84
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2502482563470769; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 0.00014789102715440094 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.64; acc: 0.84
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.7; acc: 0.86
Batch: 180; loss: 0.64; acc: 0.83
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.84
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2509086695825978; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 0.00014825581456534564 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.95
Batch: 340; loss: 0.53; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.35; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25027826238589684; val_accuracy: 0.9247611464968153 

The current subspace-distance is: 0.00015098488074727356 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.38; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.09; acc: 1.0
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2511695705615221; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 0.00015279799117706716 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.57; acc: 0.89
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.59; acc: 0.84
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.42; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2508517474553008; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 0.00015367662126664072 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.67; acc: 0.83
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.58; acc: 0.83
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.56; acc: 0.86
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.34; acc: 0.84
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2511264948992972; val_accuracy: 0.9244625796178344 

The current subspace-distance is: 0.00015570074901916087 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.57; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25064897765019895; val_accuracy: 0.9251592356687898 

The current subspace-distance is: 0.0001571508328197524 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.58; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.34; acc: 0.84
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.54; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25067797134731223; val_accuracy: 0.924562101910828 

The current subspace-distance is: 0.00015922872989904135 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_160_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 35747
elements in E: 7648300
fraction nonzero: 0.004673849090647595
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.19
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.3; acc: 0.06
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.2
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.28; acc: 0.25
Batch: 340; loss: 2.28; acc: 0.22
Batch: 360; loss: 2.28; acc: 0.2
Batch: 380; loss: 2.27; acc: 0.19
Batch: 400; loss: 2.26; acc: 0.25
Batch: 420; loss: 2.25; acc: 0.31
Batch: 440; loss: 2.26; acc: 0.19
Batch: 460; loss: 2.26; acc: 0.27
Batch: 480; loss: 2.26; acc: 0.22
Batch: 500; loss: 2.25; acc: 0.28
Batch: 520; loss: 2.23; acc: 0.34
Batch: 540; loss: 2.23; acc: 0.23
Batch: 560; loss: 2.21; acc: 0.27
Batch: 580; loss: 2.21; acc: 0.3
Batch: 600; loss: 2.18; acc: 0.39
Batch: 620; loss: 2.18; acc: 0.25
Batch: 640; loss: 2.14; acc: 0.38
Batch: 660; loss: 2.11; acc: 0.41
Batch: 680; loss: 2.05; acc: 0.38
Batch: 700; loss: 1.96; acc: 0.41
Batch: 720; loss: 1.8; acc: 0.45
Batch: 740; loss: 1.63; acc: 0.47
Batch: 760; loss: 1.54; acc: 0.52
Batch: 780; loss: 1.49; acc: 0.5
Train Epoch over. train_loss: 2.19; train_accuracy: 0.25 

Batch: 0; loss: 1.58; acc: 0.44
Batch: 20; loss: 1.73; acc: 0.44
Batch: 40; loss: 1.23; acc: 0.64
Batch: 60; loss: 1.26; acc: 0.61
Batch: 80; loss: 1.38; acc: 0.58
Batch: 100; loss: 1.49; acc: 0.52
Batch: 120; loss: 1.38; acc: 0.56
Batch: 140; loss: 1.54; acc: 0.45
Val Epoch over. val_loss: 1.48377057321512; val_accuracy: 0.47611464968152867 

The current subspace-distance is: 7.791210009600036e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.49; acc: 0.44
Batch: 20; loss: 1.5; acc: 0.55
Batch: 40; loss: 1.16; acc: 0.64
Batch: 60; loss: 1.21; acc: 0.53
Batch: 80; loss: 1.08; acc: 0.61
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.62
Batch: 140; loss: 0.86; acc: 0.69
Batch: 160; loss: 0.79; acc: 0.77
Batch: 180; loss: 1.03; acc: 0.64
Batch: 200; loss: 0.62; acc: 0.86
Batch: 220; loss: 0.89; acc: 0.67
Batch: 240; loss: 0.92; acc: 0.67
Batch: 260; loss: 1.01; acc: 0.64
Batch: 280; loss: 0.96; acc: 0.64
Batch: 300; loss: 0.84; acc: 0.78
Batch: 320; loss: 0.8; acc: 0.75
Batch: 340; loss: 0.75; acc: 0.72
Batch: 360; loss: 0.72; acc: 0.75
Batch: 380; loss: 0.79; acc: 0.75
Batch: 400; loss: 0.9; acc: 0.61
Batch: 420; loss: 0.84; acc: 0.72
Batch: 440; loss: 0.66; acc: 0.77
Batch: 460; loss: 0.75; acc: 0.83
Batch: 480; loss: 0.61; acc: 0.78
Batch: 500; loss: 0.78; acc: 0.7
Batch: 520; loss: 0.5; acc: 0.83
Batch: 540; loss: 0.58; acc: 0.78
Batch: 560; loss: 0.53; acc: 0.78
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 1.09; acc: 0.8
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.68; acc: 0.78
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.72; acc: 0.77
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.55; acc: 0.81
Batch: 780; loss: 0.53; acc: 0.81
Train Epoch over. train_loss: 0.8; train_accuracy: 0.74 

Batch: 0; loss: 1.09; acc: 0.64
Batch: 20; loss: 1.3; acc: 0.58
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 1.24; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.68; acc: 0.84
Batch: 120; loss: 1.18; acc: 0.69
Batch: 140; loss: 0.57; acc: 0.75
Val Epoch over. val_loss: 0.8107397664504447; val_accuracy: 0.7402468152866242 

The current subspace-distance is: 1.9735398382181302e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.8
Batch: 20; loss: 0.72; acc: 0.78
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.85; acc: 0.77
Batch: 180; loss: 0.5; acc: 0.8
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.71; acc: 0.75
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.63; acc: 0.83
Batch: 320; loss: 0.56; acc: 0.81
Batch: 340; loss: 0.89; acc: 0.69
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.58; acc: 0.78
Batch: 440; loss: 0.6; acc: 0.81
Batch: 460; loss: 0.48; acc: 0.84
Batch: 480; loss: 0.56; acc: 0.86
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.65; acc: 0.81
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.55; acc: 0.8
Batch: 580; loss: 0.57; acc: 0.81
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.54; acc: 0.81
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.69; acc: 0.78
Batch: 720; loss: 0.69; acc: 0.77
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.94; acc: 0.72
Batch: 20; loss: 0.86; acc: 0.73
Batch: 40; loss: 0.4; acc: 0.8
Batch: 60; loss: 0.94; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.75; acc: 0.73
Batch: 120; loss: 0.9; acc: 0.73
Batch: 140; loss: 0.3; acc: 0.95
Val Epoch over. val_loss: 0.641325161715222; val_accuracy: 0.8001592356687898 

The current subspace-distance is: 2.8275346267037094e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.72; acc: 0.75
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.48; acc: 0.91
Batch: 160; loss: 0.49; acc: 0.92
Batch: 180; loss: 0.79; acc: 0.75
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.92; acc: 0.7
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.5; acc: 0.8
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.92
Batch: 420; loss: 0.45; acc: 0.84
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.52; acc: 0.81
Batch: 540; loss: 0.59; acc: 0.81
Batch: 560; loss: 0.78; acc: 0.8
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.84
Batch: 620; loss: 0.56; acc: 0.83
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.64; acc: 0.81
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.89
Batch: 720; loss: 0.55; acc: 0.8
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.57; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.61; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 1.12; acc: 0.77
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.45210189823132413; val_accuracy: 0.8615644904458599 

The current subspace-distance is: 3.4899341699201614e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.83
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.5; acc: 0.78
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.78
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.83
Batch: 240; loss: 0.56; acc: 0.8
Batch: 260; loss: 0.53; acc: 0.86
Batch: 280; loss: 0.7; acc: 0.84
Batch: 300; loss: 0.53; acc: 0.84
Batch: 320; loss: 0.59; acc: 0.83
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.89; acc: 0.77
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.6; acc: 0.78
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.6; acc: 0.78
Batch: 520; loss: 0.33; acc: 0.86
Batch: 540; loss: 0.68; acc: 0.84
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 2.43; acc: 0.62
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.63; acc: 0.84
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.8
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3965239813847906; val_accuracy: 0.8775875796178344 

The current subspace-distance is: 4.052153599332087e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.67; acc: 0.84
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.57; acc: 0.8
Batch: 400; loss: 0.37; acc: 0.83
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.81
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.43; acc: 0.83
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.82; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.3; acc: 0.86
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.71; acc: 0.78
Batch: 700; loss: 0.28; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.72; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3531980934274045; val_accuracy: 0.8939092356687898 

The current subspace-distance is: 4.553440885501914e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.72; acc: 0.72
Batch: 200; loss: 0.41; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.55; acc: 0.8
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.62; acc: 0.81
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.86
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.56; acc: 0.86
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.83
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.81
Batch: 780; loss: 0.48; acc: 0.91
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.61; acc: 0.83
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 1.37; acc: 0.73
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.83
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.5187131862636585; val_accuracy: 0.839968152866242 

The current subspace-distance is: 5.1131941290805116e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.45; acc: 0.88
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.59; acc: 0.86
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.47; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.49; acc: 0.81
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.81
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.67; acc: 0.83
Batch: 640; loss: 0.43; acc: 0.81
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.81
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.53; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.74; acc: 0.81
Batch: 20; loss: 0.99; acc: 0.73
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.95; acc: 0.78
Batch: 80; loss: 0.61; acc: 0.86
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 1.01; acc: 0.75
Batch: 140; loss: 0.38; acc: 0.84
Val Epoch over. val_loss: 0.7103346208478235; val_accuracy: 0.7864251592356688 

The current subspace-distance is: 5.673523628502153e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.72
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.55; acc: 0.78
Batch: 180; loss: 0.64; acc: 0.78
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.97
Batch: 460; loss: 0.46; acc: 0.83
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.46; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.69; acc: 0.78
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.81
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.5; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.38810467867145115; val_accuracy: 0.87609474522293 

The current subspace-distance is: 6.079973536543548e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.31; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.58; acc: 0.8
Batch: 300; loss: 0.55; acc: 0.78
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.1; acc: 1.0
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 1.19; acc: 0.73
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.35895875143777034; val_accuracy: 0.8882364649681529 

The current subspace-distance is: 6.462209421442822e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.37; acc: 0.83
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.83
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.33; train_accuracy: 0.89 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.67; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3032736316513104; val_accuracy: 0.9067476114649682 

The current subspace-distance is: 6.847798067610711e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.48; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.84
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.64; acc: 0.84
Batch: 760; loss: 0.58; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.78; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.30365320679488456; val_accuracy: 0.90515525477707 

The current subspace-distance is: 7.193451892817393e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.37; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.3280672348893372; val_accuracy: 0.8967953821656051 

The current subspace-distance is: 7.581088721053675e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.95
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.43; acc: 0.92
Batch: 540; loss: 0.45; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.86
Batch: 620; loss: 0.57; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3592882465784717; val_accuracy: 0.8897292993630573 

The current subspace-distance is: 7.922331133158877e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.81
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.98
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.64; acc: 0.8
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.77; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.308098235137903; val_accuracy: 0.9053542993630573 

The current subspace-distance is: 8.203170727938414e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.55; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.32; acc: 0.86
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.81
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.44; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.24; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.28608857342012367; val_accuracy: 0.9125199044585988 

The current subspace-distance is: 8.564176096115261e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.54; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.58; acc: 0.84
Batch: 560; loss: 0.33; acc: 0.86
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.67; acc: 0.8
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.5; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.81; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.32064246075453273; val_accuracy: 0.9061504777070064 

The current subspace-distance is: 8.915356011129916e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.1; acc: 1.0
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.52; acc: 0.89
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.84
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.76; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.65; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.32808057949611336; val_accuracy: 0.8954020700636943 

The current subspace-distance is: 9.258443606086075e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.25; acc: 0.95
Batch: 180; loss: 0.61; acc: 0.78
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.35; acc: 0.94
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.84
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.98
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.35637511787520854; val_accuracy: 0.8924164012738853 

The current subspace-distance is: 9.599058830644935e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.49; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.43; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.84
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.49; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.49; acc: 0.81
Batch: 740; loss: 0.23; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2806616003393747; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 9.920020966092125e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.43; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.84
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.27801631440877156; val_accuracy: 0.9184912420382165 

The current subspace-distance is: 0.00010188362648477778 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.37; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.58; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2708788801482908; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 0.00010406339424662292 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2803024084657241; val_accuracy: 0.914609872611465 

The current subspace-distance is: 0.00010671379277482629 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.4; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.94
Batch: 220; loss: 0.3; acc: 0.95
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.81
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.84
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.34; acc: 0.94
Batch: 580; loss: 0.52; acc: 0.78
Batch: 600; loss: 0.61; acc: 0.86
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.5; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.32; acc: 0.86
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2788550015301651; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 0.00011042983533116058 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.51; acc: 0.81
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.98
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2827470704533492; val_accuracy: 0.915406050955414 

The current subspace-distance is: 0.00011543020809767768 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.19; acc: 0.97
Batch: 140; loss: 0.37; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.48; acc: 0.78
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.97
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.72; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2701601359732212; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 0.00011883633123943582 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.83
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.84
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.37; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.84
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.272448670237687; val_accuracy: 0.9179936305732485 

The current subspace-distance is: 0.00012138011516071856 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.13; acc: 0.98
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.57; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.56; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.27606929682052816; val_accuracy: 0.9175955414012739 

The current subspace-distance is: 0.00012305301788728684 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.84
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.65; acc: 0.86
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.26672579725361933; val_accuracy: 0.9215764331210191 

The current subspace-distance is: 0.00012465912732295692 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.52; acc: 0.78
Batch: 20; loss: 0.49; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.48; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.43; acc: 0.83
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.6; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.61; acc: 0.84
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2655162471257577; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 0.00012723455438390374 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.54; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.86
Batch: 220; loss: 0.16; acc: 0.98
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2625777552699208; val_accuracy: 0.9213773885350318 

The current subspace-distance is: 0.00012998786405660212 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.86
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.91
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.47; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.24; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.45; acc: 0.89
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.09; acc: 1.0
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2636675188306031; val_accuracy: 0.9217754777070064 

The current subspace-distance is: 0.00013272023352328688 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.97
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.32; acc: 0.86
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26399865409561024; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 0.0001334616245003417 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.33; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.6; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.97
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.86
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2640861790081498; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 0.00013517026673071086 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.86
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.84
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.44; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26519401789091196; val_accuracy: 0.9209792993630573 

The current subspace-distance is: 0.00013762184244114906 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.38; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.37; acc: 0.86
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2635419116634282; val_accuracy: 0.9211783439490446 

The current subspace-distance is: 0.00014212075620889664 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.83
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.46; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.46; acc: 0.84
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.86
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.59; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.91
Batch: 760; loss: 0.62; acc: 0.84
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2661930112180057; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 0.00014873257896397263 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.4; acc: 0.83
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.49; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.27; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26078704245103773; val_accuracy: 0.92078025477707 

The current subspace-distance is: 0.00015129796520341188 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.97
Batch: 60; loss: 0.51; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.56; acc: 0.86
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.6; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26225855623840527; val_accuracy: 0.9217754777070064 

The current subspace-distance is: 0.0001521919621154666 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.78
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.67; acc: 0.81
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.83
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.51; acc: 0.89
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.58; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.26185041415700866; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 0.0001535773917566985 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.12; acc: 0.98
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.49; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.53; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2585201814391051; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 0.00015647140389773995 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.42; acc: 0.88
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.59; acc: 0.88
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.37; acc: 0.84
Batch: 420; loss: 0.59; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25840545017390876; val_accuracy: 0.9222730891719745 

The current subspace-distance is: 0.0001584717392688617 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.5; acc: 0.83
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.95
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.55; acc: 0.86
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25852066616581126; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 0.0001609047467354685 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.84
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.51; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25726450248888344; val_accuracy: 0.9226711783439491 

The current subspace-distance is: 0.00016459949256386608 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.47; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2568457138244134; val_accuracy: 0.9226711783439491 

The current subspace-distance is: 0.0001662747818045318 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25725277522756795; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 0.000169368926435709 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.49; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.57; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.86
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25973828681477695; val_accuracy: 0.9227707006369427 

The current subspace-distance is: 0.000173294945852831 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.84
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.63; acc: 0.83
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.97
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.83
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2572960139602233; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 0.00017445720732212067 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.46; acc: 0.92
Batch: 260; loss: 0.38; acc: 0.83
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.39; acc: 0.84
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.81
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.88
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2576966508155226; val_accuracy: 0.9226711783439491 

The current subspace-distance is: 0.0001748512004269287 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.88
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.47; acc: 0.83
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.46; acc: 0.89
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.86
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2571302394198764; val_accuracy: 0.9230692675159236 

The current subspace-distance is: 0.00017860774823930115 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_170_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 37743
elements in E: 8098200
fraction nonzero: 0.004660665333036971
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.19
Batch: 160; loss: 2.29; acc: 0.17
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.27; acc: 0.3
Batch: 220; loss: 2.27; acc: 0.3
Batch: 240; loss: 2.27; acc: 0.22
Batch: 260; loss: 2.26; acc: 0.25
Batch: 280; loss: 2.26; acc: 0.19
Batch: 300; loss: 2.24; acc: 0.27
Batch: 320; loss: 2.25; acc: 0.23
Batch: 340; loss: 2.24; acc: 0.22
Batch: 360; loss: 2.22; acc: 0.25
Batch: 380; loss: 2.2; acc: 0.23
Batch: 400; loss: 2.15; acc: 0.25
Batch: 420; loss: 2.05; acc: 0.38
Batch: 440; loss: 1.96; acc: 0.41
Batch: 460; loss: 1.89; acc: 0.44
Batch: 480; loss: 1.66; acc: 0.52
Batch: 500; loss: 1.3; acc: 0.61
Batch: 520; loss: 1.23; acc: 0.67
Batch: 540; loss: 1.22; acc: 0.67
Batch: 560; loss: 0.84; acc: 0.73
Batch: 580; loss: 1.08; acc: 0.66
Batch: 600; loss: 0.87; acc: 0.69
Batch: 620; loss: 0.66; acc: 0.81
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.58; acc: 0.8
Batch: 680; loss: 0.78; acc: 0.73
Batch: 700; loss: 0.63; acc: 0.84
Batch: 720; loss: 0.48; acc: 0.91
Batch: 740; loss: 0.57; acc: 0.89
Batch: 760; loss: 0.81; acc: 0.75
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 1.69; train_accuracy: 0.43 

Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.91; acc: 0.67
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.89; acc: 0.75
Batch: 140; loss: 0.37; acc: 0.83
Val Epoch over. val_loss: 0.5470424576359949; val_accuracy: 0.8244426751592356 

The current subspace-distance is: 1.14042322820751e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.8
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.49; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.72; acc: 0.77
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.66; acc: 0.75
Batch: 280; loss: 0.54; acc: 0.78
Batch: 300; loss: 0.48; acc: 0.81
Batch: 320; loss: 0.7; acc: 0.77
Batch: 340; loss: 0.81; acc: 0.75
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.65; acc: 0.8
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.69; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.83
Batch: 620; loss: 0.89; acc: 0.78
Batch: 640; loss: 1.16; acc: 0.7
Batch: 660; loss: 0.38; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.81
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.8
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.45; acc: 0.8
Batch: 20; loss: 0.69; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.51; acc: 0.81
Batch: 100; loss: 0.79; acc: 0.8
Batch: 120; loss: 1.25; acc: 0.59
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.5523257270740096; val_accuracy: 0.8218550955414012 

The current subspace-distance is: 2.1544617993640713e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.49; acc: 0.81
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.58; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.81
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.65; acc: 0.8
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.81
Batch: 240; loss: 1.0; acc: 0.73
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.9; acc: 0.67
Batch: 300; loss: 0.52; acc: 0.88
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.8
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.8
Batch: 500; loss: 0.25; acc: 0.97
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.84
Batch: 580; loss: 0.47; acc: 0.83
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.78; acc: 0.8
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.49; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.78; acc: 0.83
Batch: 120; loss: 1.03; acc: 0.7
Batch: 140; loss: 0.29; acc: 0.91
Val Epoch over. val_loss: 0.556654621081747; val_accuracy: 0.8182722929936306 

The current subspace-distance is: 2.9092523618601263e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.53; acc: 0.81
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.32; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.63; acc: 0.78
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.52; acc: 0.72
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.69; acc: 0.84
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3333120742563609; val_accuracy: 0.8940087579617835 

The current subspace-distance is: 3.4836932172765955e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.4; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.46; acc: 0.75
Batch: 300; loss: 0.38; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.59; acc: 0.84
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.5; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.44; acc: 0.81
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.98
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.33; acc: 0.81
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.86; acc: 0.78
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3261993665034604; val_accuracy: 0.8981886942675159 

The current subspace-distance is: 4.156103022978641e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.57; acc: 0.84
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.66; acc: 0.73
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.76; acc: 0.83
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.54; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.81
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.65; acc: 0.84
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.81; acc: 0.73
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3379583968098756; val_accuracy: 0.8969944267515924 

The current subspace-distance is: 4.6913781261537224e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.61; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.56; acc: 0.8
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.83
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.46; acc: 0.8
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.9; acc: 0.75
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3618479057861741; val_accuracy: 0.89171974522293 

The current subspace-distance is: 5.2540955948643386e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.43; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.95
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.58; acc: 0.84
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.43; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.62; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2955803707194556; val_accuracy: 0.9106289808917197 

The current subspace-distance is: 5.5819808039814234e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.86
Batch: 680; loss: 0.38; acc: 0.84
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.308045580283187; val_accuracy: 0.9084394904458599 

The current subspace-distance is: 6.200654752319679e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.69; acc: 0.8
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.31; acc: 0.86
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.83
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.65; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.4; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2707359045981222; val_accuracy: 0.9210788216560509 

The current subspace-distance is: 6.614655285375193e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.2; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.89
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2362004442104868; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 6.999404286034405e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.81
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.61; acc: 0.84
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.61; acc: 0.86
Batch: 600; loss: 0.29; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.86
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.27687609034359073; val_accuracy: 0.9179936305732485 

The current subspace-distance is: 7.276178803294897e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.35; acc: 0.84
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.07; acc: 1.0
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.2497193462268752; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 7.669631304452196e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.37; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.5; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28449234725895584; val_accuracy: 0.9132165605095541 

The current subspace-distance is: 8.170169894583523e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.23442950743920865; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 8.592900849180296e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.54; acc: 0.89
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.38; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.36; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.23285083005287846; val_accuracy: 0.9312300955414012 

The current subspace-distance is: 8.98660728125833e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.57; acc: 0.83
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.84
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.6; acc: 0.86
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24035940882838835; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 9.338100062450394e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.38; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.47; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.8; acc: 0.72
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27348177671242674; val_accuracy: 0.9197850318471338 

The current subspace-distance is: 9.690428851172328e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.61; acc: 0.8
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23950234934640158; val_accuracy: 0.9244625796178344 

The current subspace-distance is: 9.88935207715258e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.49; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25564450277074885; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 0.00010213188215857372 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.86
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.84
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.08; acc: 1.0
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2253303042476534; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 0.00010457210009917617 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.86
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.86
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22460590783435447; val_accuracy: 0.9336186305732485 

The current subspace-distance is: 0.00010620585817378014 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.95
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.07; acc: 1.0
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22736552645968403; val_accuracy: 0.930234872611465 

The current subspace-distance is: 0.00010823864431586117 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.44; acc: 0.84
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.6; acc: 0.88
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.25546360972106075; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 0.00011055733921239153 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.07; acc: 1.0
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22172802008071524; val_accuracy: 0.9317277070063694 

The current subspace-distance is: 0.00011260290921200067 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.81
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.21; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2211428068127412; val_accuracy: 0.9328224522292994 

The current subspace-distance is: 0.00011488498421385884 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.84
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.43; acc: 0.86
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2222392588830108; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 0.0001176655205199495 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.5; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.22754821792292368; val_accuracy: 0.9308320063694268 

The current subspace-distance is: 0.00012013766536256298 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.1; acc: 1.0
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.57; acc: 0.88
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.2; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22190748833143598; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 0.00012137842713855207 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.53; acc: 0.81
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.07; acc: 1.0
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2242183474361137; val_accuracy: 0.9322253184713376 

The current subspace-distance is: 0.00012388548930175602 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.27; acc: 0.88
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.77
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2217850754286643; val_accuracy: 0.9306329617834395 

The current subspace-distance is: 0.00012539383897092193 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.35; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.91
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22173378361495816; val_accuracy: 0.9325238853503185 

The current subspace-distance is: 0.0001294512185268104 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.23; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.77
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22070976057843228; val_accuracy: 0.9335191082802548 

The current subspace-distance is: 0.00013113337627146393 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.09; acc: 1.0
Batch: 340; loss: 0.08; acc: 1.0
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.84
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22283685174740994; val_accuracy: 0.9323248407643312 

The current subspace-distance is: 0.00013362739991862327 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22043074192894493; val_accuracy: 0.9335191082802548 

The current subspace-distance is: 0.00013694609515368938 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22125715016725528; val_accuracy: 0.9314291401273885 

The current subspace-distance is: 0.00013855790894012898 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.94
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.12; acc: 0.98
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.86
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.75
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2236065191104059; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 0.00014060012472327799 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.06; acc: 1.0
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.86
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22001876472050597; val_accuracy: 0.933718152866242 

The current subspace-distance is: 0.00014350198034662753 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.41; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.84
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.5; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2213422795935611; val_accuracy: 0.9330214968152867 

The current subspace-distance is: 0.0001453197473892942 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.89
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.35; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.75
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2209314461144957; val_accuracy: 0.9317277070063694 

The current subspace-distance is: 0.00014852829917799681 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.34; acc: 0.94
Batch: 760; loss: 0.08; acc: 1.0
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21912625084992995; val_accuracy: 0.9333200636942676 

The current subspace-distance is: 0.00014852554886601865 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.39; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2191335575560191; val_accuracy: 0.9336186305732485 

The current subspace-distance is: 0.00015135672583710402 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.51; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.61; acc: 0.86
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.07; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2194246049543285; val_accuracy: 0.9336186305732485 

The current subspace-distance is: 0.00015304853150155395 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.44; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2204804880081848; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 0.00015571377298329026 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.86
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.88
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.77
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21865094221748743; val_accuracy: 0.9336186305732485 

The current subspace-distance is: 0.00015859540144447237 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.88
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21947396811169045; val_accuracy: 0.9335191082802548 

The current subspace-distance is: 0.00016127001435961574 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.51; acc: 0.86
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.27; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21984330991840667; val_accuracy: 0.9328224522292994 

The current subspace-distance is: 0.0001633092761039734 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.97
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2190733890992346; val_accuracy: 0.933718152866242 

The current subspace-distance is: 0.0001653914514463395 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.47; acc: 0.89
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.71; acc: 0.81
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22023969312097616; val_accuracy: 0.9342157643312102 

The current subspace-distance is: 0.00016611146565992385 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.44; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.58; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2203363157559637; val_accuracy: 0.932921974522293 

The current subspace-distance is: 0.00016780065197963268 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_180_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 40368
elements in E: 8548100
fraction nonzero: 0.0047224529427592095
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.16
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.28; acc: 0.11
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.27; acc: 0.12
Batch: 300; loss: 2.27; acc: 0.2
Batch: 320; loss: 2.26; acc: 0.31
Batch: 340; loss: 2.26; acc: 0.3
Batch: 360; loss: 2.26; acc: 0.33
Batch: 380; loss: 2.25; acc: 0.25
Batch: 400; loss: 2.24; acc: 0.39
Batch: 420; loss: 2.23; acc: 0.39
Batch: 440; loss: 2.22; acc: 0.48
Batch: 460; loss: 2.21; acc: 0.34
Batch: 480; loss: 2.2; acc: 0.28
Batch: 500; loss: 2.2; acc: 0.28
Batch: 520; loss: 2.12; acc: 0.47
Batch: 540; loss: 2.08; acc: 0.42
Batch: 560; loss: 1.98; acc: 0.5
Batch: 580; loss: 1.99; acc: 0.44
Batch: 600; loss: 1.78; acc: 0.47
Batch: 620; loss: 1.73; acc: 0.5
Batch: 640; loss: 1.26; acc: 0.66
Batch: 660; loss: 1.31; acc: 0.52
Batch: 680; loss: 1.1; acc: 0.67
Batch: 700; loss: 0.97; acc: 0.73
Batch: 720; loss: 0.74; acc: 0.75
Batch: 740; loss: 0.82; acc: 0.73
Batch: 760; loss: 0.95; acc: 0.78
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 1.98; train_accuracy: 0.34 

Batch: 0; loss: 0.79; acc: 0.66
Batch: 20; loss: 1.08; acc: 0.62
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.86; acc: 0.72
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.97; acc: 0.7
Batch: 140; loss: 0.62; acc: 0.69
Val Epoch over. val_loss: 0.7215544068889254; val_accuracy: 0.7608479299363057 

The current subspace-distance is: 1.0326261872251052e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.86; acc: 0.66
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.68; acc: 0.81
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 1.12; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.74; acc: 0.75
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.62; acc: 0.77
Batch: 240; loss: 0.53; acc: 0.81
Batch: 260; loss: 0.76; acc: 0.78
Batch: 280; loss: 0.5; acc: 0.8
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.66; acc: 0.83
Batch: 340; loss: 0.74; acc: 0.83
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.8
Batch: 400; loss: 0.8; acc: 0.73
Batch: 420; loss: 0.7; acc: 0.83
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.61; acc: 0.86
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.53; acc: 0.8
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.55; acc: 0.81
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.84
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.99; acc: 0.73
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.42; acc: 0.89
Batch: 60; loss: 0.92; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 1.0; acc: 0.67
Batch: 140; loss: 0.54; acc: 0.84
Val Epoch over. val_loss: 0.5333102049341627; val_accuracy: 0.82921974522293 

The current subspace-distance is: 2.095737545459997e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.42; acc: 0.81
Batch: 240; loss: 0.55; acc: 0.8
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.91
Batch: 440; loss: 0.5; acc: 0.81
Batch: 460; loss: 0.52; acc: 0.83
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.5; acc: 0.83
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.63; acc: 0.8
Batch: 740; loss: 0.45; acc: 0.81
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.51; acc: 0.8
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.44; acc: 0.88
Val Epoch over. val_loss: 0.4223002093802592; val_accuracy: 0.861265923566879 

The current subspace-distance is: 2.9464314138749614e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.81
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.6; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.83
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.8
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.38; acc: 0.92
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.61; acc: 0.8
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.8
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.347063683542856; val_accuracy: 0.8916202229299363 

The current subspace-distance is: 3.575108712539077e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.83
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.52; acc: 0.8
Batch: 480; loss: 0.35; acc: 0.94
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2606885640579424; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 4.090467336936854e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.66; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.2794626106027585; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 4.6620320063084364e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.64; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.49; acc: 0.88
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.06; acc: 1.0
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.86
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.95
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.98; acc: 0.77
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.75; acc: 0.83
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.29; acc: 0.88
Val Epoch over. val_loss: 0.4261602263446826; val_accuracy: 0.8615644904458599 

The current subspace-distance is: 5.206971036386676e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.98
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.63; acc: 0.83
Batch: 760; loss: 0.7; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.59; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.28807767865004813; val_accuracy: 0.9042595541401274 

The current subspace-distance is: 5.6072814913932234e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.8; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.3824529523967178; val_accuracy: 0.8828622611464968 

The current subspace-distance is: 6.042901077307761e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.62; acc: 0.78
Batch: 220; loss: 0.18; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.83
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.22440721089862714; val_accuracy: 0.9313296178343949 

The current subspace-distance is: 6.571618723683059e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.89
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20406931505841056; val_accuracy: 0.9361066878980892 

The current subspace-distance is: 6.900075095472857e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.06; acc: 1.0
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.52; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21987513414803583; val_accuracy: 0.9332205414012739 

The current subspace-distance is: 7.241264393087476e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.95
Batch: 500; loss: 0.36; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.57; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.21135712543110938; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 7.71953200455755e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.49; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.22309287656454524; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 8.038565283641219e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19939919309631274; val_accuracy: 0.9400875796178344 

The current subspace-distance is: 8.462566620437428e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.95
Batch: 680; loss: 0.35; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.07; acc: 1.0
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19658399425494444; val_accuracy: 0.9389928343949044 

The current subspace-distance is: 8.841221278999001e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.88
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.56; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.09; acc: 1.0
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.23329508840847926; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 9.159372712019831e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.86
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.97
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.43; acc: 0.88
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.45; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.21457124302151856; val_accuracy: 0.9334195859872612 

The current subspace-distance is: 9.49585300986655e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.55; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2029423658160647; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 9.855609823716804e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.06; acc: 1.0
Batch: 180; loss: 0.11; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.86
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.43; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.4; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20933714091398153; val_accuracy: 0.9353105095541401 

The current subspace-distance is: 0.00010306957847205922 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.49; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.98
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.191861234842592; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 0.00010576197382761165 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.3; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.08; acc: 1.0
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18713391434614826; val_accuracy: 0.943172770700637 

The current subspace-distance is: 0.00010936606850009412 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.1; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.98
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19409034662185962; val_accuracy: 0.9408837579617835 

The current subspace-distance is: 0.00011210698721697554 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.89
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19303407273284948; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 0.00011419316433602944 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19045478675016173; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 0.0001170593241113238 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.42; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18531116254770072; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 0.00011942417768295854 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.84
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18504111867421752; val_accuracy: 0.9443670382165605 

The current subspace-distance is: 0.00012341381807345897 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.34; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.35; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18876871167664316; val_accuracy: 0.9434713375796179 

The current subspace-distance is: 0.00012601460912264884 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19057754673965419; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 0.00012857209367211908 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.08; acc: 1.0
Batch: 220; loss: 0.26; acc: 0.86
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19024746200651121; val_accuracy: 0.9429737261146497 

The current subspace-distance is: 0.0001303924509556964 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18347331051044402; val_accuracy: 0.945859872611465 

The current subspace-distance is: 0.00013335971743799746 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.46; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.28; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.54; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18588308581880703; val_accuracy: 0.944765127388535 

The current subspace-distance is: 0.0001368651574011892 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.46; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.86
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.43; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18457889352824278; val_accuracy: 0.943968949044586 

The current subspace-distance is: 0.00013830815441906452 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.56; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18631050232679222; val_accuracy: 0.9437699044585988 

The current subspace-distance is: 0.000140842268592678 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.06; acc: 1.0
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18606500507919652; val_accuracy: 0.9451632165605095 

The current subspace-distance is: 0.0001434974547009915 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.186591158721857; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 0.00014494145580101758 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.06; acc: 1.0
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.42; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18436971520352516; val_accuracy: 0.9437699044585988 

The current subspace-distance is: 0.00014768063556402922 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18660058541472552; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 0.00014903195551596582 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.47; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.38; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18433405549093418; val_accuracy: 0.9453622611464968 

The current subspace-distance is: 0.0001504433312220499 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1843305911607803; val_accuracy: 0.9454617834394905 

The current subspace-distance is: 0.00015257518680300564 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.14; acc: 0.98
Batch: 580; loss: 0.22; acc: 0.97
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18507411497034085; val_accuracy: 0.9449641719745223 

The current subspace-distance is: 0.0001543005055282265 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.86
Batch: 360; loss: 0.12; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.53; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18335051165454708; val_accuracy: 0.9453622611464968 

The current subspace-distance is: 0.00015574861026834697 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.49; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.12; acc: 1.0
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.05; acc: 1.0
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18450899986894267; val_accuracy: 0.9442675159235668 

The current subspace-distance is: 0.00015917018754407763 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.98
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1841263370529102; val_accuracy: 0.9453622611464968 

The current subspace-distance is: 0.00015969353262335062 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18366446716200774; val_accuracy: 0.9461584394904459 

The current subspace-distance is: 0.0001608264137757942 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18347868394510003; val_accuracy: 0.9456608280254777 

The current subspace-distance is: 0.00016185667482204735 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.07; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.6; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18432108910789916; val_accuracy: 0.945859872611465 

The current subspace-distance is: 0.00016221129044424742 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.06; acc: 1.0
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.65; acc: 0.84
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.52; acc: 0.88
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18420713565721633; val_accuracy: 0.945859872611465 

The current subspace-distance is: 0.0001644660223973915 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.51; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.97
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.89
Batch: 780; loss: 0.07; acc: 1.0
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18440954330240844; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 0.00016677990788593888 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.51; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.97
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.18; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18343778210840408; val_accuracy: 0.9456608280254777 

The current subspace-distance is: 0.00016932556172832847 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_190_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 42405
elements in E: 8998000
fraction nonzero: 0.004712713936430318
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.19
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.31; acc: 0.05
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.27; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.11
Batch: 260; loss: 2.27; acc: 0.16
Batch: 280; loss: 2.27; acc: 0.11
Batch: 300; loss: 2.25; acc: 0.2
Batch: 320; loss: 2.24; acc: 0.25
Batch: 340; loss: 2.25; acc: 0.22
Batch: 360; loss: 2.24; acc: 0.28
Batch: 380; loss: 2.19; acc: 0.39
Batch: 400; loss: 2.18; acc: 0.42
Batch: 420; loss: 2.14; acc: 0.42
Batch: 440; loss: 2.07; acc: 0.47
Batch: 460; loss: 2.01; acc: 0.36
Batch: 480; loss: 1.83; acc: 0.36
Batch: 500; loss: 1.55; acc: 0.45
Batch: 520; loss: 1.35; acc: 0.64
Batch: 540; loss: 1.14; acc: 0.67
Batch: 560; loss: 1.2; acc: 0.62
Batch: 580; loss: 1.28; acc: 0.61
Batch: 600; loss: 0.92; acc: 0.67
Batch: 620; loss: 0.86; acc: 0.7
Batch: 640; loss: 0.8; acc: 0.73
Batch: 660; loss: 0.75; acc: 0.7
Batch: 680; loss: 0.87; acc: 0.75
Batch: 700; loss: 0.94; acc: 0.67
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.75; acc: 0.8
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.55; acc: 0.8
Train Epoch over. train_loss: 1.74; train_accuracy: 0.39 

Batch: 0; loss: 0.6; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.73
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.92; acc: 0.64
Batch: 140; loss: 0.36; acc: 0.84
Val Epoch over. val_loss: 0.5702199040894296; val_accuracy: 0.8167794585987261 

The current subspace-distance is: 1.1588655979721807e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.71; acc: 0.73
Batch: 20; loss: 0.68; acc: 0.8
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.83
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.65; acc: 0.83
Batch: 160; loss: 0.4; acc: 0.83
Batch: 180; loss: 0.63; acc: 0.84
Batch: 200; loss: 0.29; acc: 0.95
Batch: 220; loss: 0.48; acc: 0.88
Batch: 240; loss: 0.61; acc: 0.81
Batch: 260; loss: 0.74; acc: 0.75
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.6; acc: 0.84
Batch: 320; loss: 0.59; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.83
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.76; acc: 0.8
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.56; acc: 0.86
Batch: 460; loss: 0.6; acc: 0.83
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.83
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.83; acc: 0.81
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 0.38; acc: 0.83
Val Epoch over. val_loss: 0.49678634088130513; val_accuracy: 0.8283240445859873 

The current subspace-distance is: 2.077154567814432e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.51; acc: 0.81
Batch: 440; loss: 0.45; acc: 0.8
Batch: 460; loss: 0.42; acc: 0.81
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.86
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.55; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.81
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.37; acc: 0.84
Batch: 760; loss: 0.27; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.89; acc: 0.67
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.96; acc: 0.69
Batch: 140; loss: 0.56; acc: 0.81
Val Epoch over. val_loss: 0.6013313679938104; val_accuracy: 0.8099124203821656 

The current subspace-distance is: 2.8730313715641387e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.59; acc: 0.83
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.84
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.63; acc: 0.83
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.6; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.92
Val Epoch over. val_loss: 0.2905956856479311; val_accuracy: 0.9093351910828026 

The current subspace-distance is: 3.6741064832312986e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.51; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.48; acc: 0.8
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.94
Batch: 220; loss: 0.63; acc: 0.81
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.38; acc: 0.8
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.95
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.36; acc: 0.84
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.37; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.97
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.44; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.2; acc: 0.92
Val Epoch over. val_loss: 0.28845997235387755; val_accuracy: 0.9128184713375797 

The current subspace-distance is: 4.270565477781929e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.23; acc: 0.97
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.62; acc: 0.86
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.68; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.83
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.72; acc: 0.78
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.56; acc: 0.83
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.54; acc: 0.88
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.49; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.4365614170481445; val_accuracy: 0.8625597133757962 

The current subspace-distance is: 4.8075067752506584e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.73; acc: 0.8
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.8
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.49; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.89
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.39; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.84
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.28; acc: 0.86
Val Epoch over. val_loss: 0.3828835987076638; val_accuracy: 0.8769904458598726 

The current subspace-distance is: 5.253094059298746e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.86
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.84
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.73; acc: 0.83
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.52; acc: 0.88
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.28; acc: 0.91
Val Epoch over. val_loss: 0.359963652719358; val_accuracy: 0.8878383757961783 

The current subspace-distance is: 5.839522054884583e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 1.13; acc: 0.72
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.5762727846195743; val_accuracy: 0.8309116242038217 

The current subspace-distance is: 6.211234722286463e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.65; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.39; acc: 0.83
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.84
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.89
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.98
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.65; acc: 0.81
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.258601144193464; val_accuracy: 0.9188893312101911 

The current subspace-distance is: 6.669142021564767e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.88
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.06; acc: 1.0
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2137763709968822; val_accuracy: 0.9378980891719745 

The current subspace-distance is: 7.041252683848143e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.43; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2289086064905118; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 7.50925246393308e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.22907604647290175; val_accuracy: 0.9330214968152867 

The current subspace-distance is: 7.940921204863116e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.54; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.2584566454978506; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 8.244053606176749e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.95
Batch: 40; loss: 0.32; acc: 0.86
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2059867117720045; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 8.522006828570738e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.29; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.29; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.98
Batch: 760; loss: 0.31; acc: 0.83
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20815271053724227; val_accuracy: 0.9375995222929936 

The current subspace-distance is: 8.91313175088726e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.44; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.48; acc: 0.81
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.68; acc: 0.83
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.11; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.3; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2525456627937639; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 9.304934064857662e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.98
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21128656691426684; val_accuracy: 0.9365047770700637 

The current subspace-distance is: 9.499974112259224e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.45; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2009527320220212; val_accuracy: 0.9416799363057324 

The current subspace-distance is: 9.808255708776414e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.31; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21612940135465306; val_accuracy: 0.93859474522293 

The current subspace-distance is: 0.00010119855141965672 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19865129171473206; val_accuracy: 0.9427746815286624 

The current subspace-distance is: 0.00010378448496339843 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.98
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.41; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19995863218406204; val_accuracy: 0.9414808917197452 

The current subspace-distance is: 0.00010616557847242802 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19966031392668462; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 0.00010967250273097306 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.98
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.88
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.21073530657086403; val_accuracy: 0.9414808917197452 

The current subspace-distance is: 0.00011256704601692036 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.1; acc: 1.0
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19972430629904864; val_accuracy: 0.9413813694267515 

The current subspace-distance is: 0.00011595382966334 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.86
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19269057733427947; val_accuracy: 0.943172770700637 

The current subspace-distance is: 0.00011838028149213642 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.07; acc: 1.0
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.17; acc: 0.91
Batch: 380; loss: 0.08; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.98
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.56; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1954590729704708; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 0.00012113866250729188 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.84
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20118173624679542; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 0.0001231722708325833 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.98
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.86
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19187658707237548; val_accuracy: 0.9461584394904459 

The current subspace-distance is: 0.00012555139255709946 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.48; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.91
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.09; acc: 1.0
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19291988062630794; val_accuracy: 0.9457603503184714 

The current subspace-distance is: 0.00012756168143823743 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.05; acc: 1.0
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.98
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.27; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.193958690259487; val_accuracy: 0.9444665605095541 

The current subspace-distance is: 0.0001306288904743269 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.56; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18976455395388755; val_accuracy: 0.9454617834394905 

The current subspace-distance is: 0.0001328821963397786 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.92
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.91
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.18986495683906943; val_accuracy: 0.9455613057324841 

The current subspace-distance is: 0.000134594039991498 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.46; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.86
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18669880447304174; val_accuracy: 0.9470541401273885 

The current subspace-distance is: 0.00013685808517038822 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.91
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19024829025481158; val_accuracy: 0.9461584394904459 

The current subspace-distance is: 0.00013935529568698257 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.5; acc: 0.88
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.52; acc: 0.83
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1885497697219727; val_accuracy: 0.9465565286624203 

The current subspace-distance is: 0.00013987375132273883 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.07; acc: 1.0
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18853290013636753; val_accuracy: 0.9457603503184714 

The current subspace-distance is: 0.0001419404725311324 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.5; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19128927911163135; val_accuracy: 0.9459593949044586 

The current subspace-distance is: 0.00014315321459434927 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.45; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1871827716470524; val_accuracy: 0.9472531847133758 

The current subspace-distance is: 0.00014628557255491614 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.06; acc: 1.0
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18567459781173687; val_accuracy: 0.9477507961783439 

The current subspace-distance is: 0.0001475773169659078 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.07; acc: 1.0
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.05; acc: 1.0
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.38; acc: 0.84
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18598693241454234; val_accuracy: 0.9462579617834395 

The current subspace-distance is: 0.0001499971403973177 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.89
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.05; acc: 1.0
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18608118138115876; val_accuracy: 0.9462579617834395 

The current subspace-distance is: 0.00015115486166905612 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.94
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1857901866174048; val_accuracy: 0.9468550955414012 

The current subspace-distance is: 0.00015255383914336562 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.41; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18591523573846575; val_accuracy: 0.9461584394904459 

The current subspace-distance is: 0.00015527437790296972 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.14; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18537689313577238; val_accuracy: 0.9468550955414012 

The current subspace-distance is: 0.00015785200230311602 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18600410023692307; val_accuracy: 0.9472531847133758 

The current subspace-distance is: 0.00016093831800390035 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.21; acc: 0.97
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18687665690282348; val_accuracy: 0.9468550955414012 

The current subspace-distance is: 0.00016286886238958687 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.55; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18560879789055532; val_accuracy: 0.9462579617834395 

The current subspace-distance is: 0.00016398113803006709 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.54; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18591041722969645; val_accuracy: 0.9467555732484076 

The current subspace-distance is: 0.0001658940891502425 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.53; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.51; acc: 0.86
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.97
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1854481866025621; val_accuracy: 0.9467555732484076 

The current subspace-distance is: 0.00016747436893638223 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 53340
elements in E: 11247500
fraction nonzero: 0.004742387197154923
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.2
Batch: 160; loss: 2.29; acc: 0.06
Batch: 180; loss: 2.29; acc: 0.06
Batch: 200; loss: 2.28; acc: 0.22
Batch: 220; loss: 2.27; acc: 0.41
Batch: 240; loss: 2.27; acc: 0.36
Batch: 260; loss: 2.26; acc: 0.45
Batch: 280; loss: 2.26; acc: 0.31
Batch: 300; loss: 2.24; acc: 0.5
Batch: 320; loss: 2.23; acc: 0.41
Batch: 340; loss: 2.21; acc: 0.41
Batch: 360; loss: 2.19; acc: 0.34
Batch: 380; loss: 2.15; acc: 0.38
Batch: 400; loss: 2.09; acc: 0.34
Batch: 420; loss: 1.93; acc: 0.38
Batch: 440; loss: 1.69; acc: 0.55
Batch: 460; loss: 1.44; acc: 0.48
Batch: 480; loss: 1.21; acc: 0.59
Batch: 500; loss: 1.38; acc: 0.44
Batch: 520; loss: 1.11; acc: 0.67
Batch: 540; loss: 1.03; acc: 0.73
Batch: 560; loss: 0.8; acc: 0.78
Batch: 580; loss: 1.17; acc: 0.64
Batch: 600; loss: 0.84; acc: 0.7
Batch: 620; loss: 0.86; acc: 0.66
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.66; acc: 0.83
Batch: 700; loss: 1.04; acc: 0.7
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.73; acc: 0.78
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 1.65; train_accuracy: 0.46 

Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 0.83; acc: 0.75
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.94; acc: 0.75
Batch: 140; loss: 0.42; acc: 0.88
Val Epoch over. val_loss: 0.5759367264190297; val_accuracy: 0.8196656050955414 

The current subspace-distance is: 1.2237274859216996e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.77
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.65; acc: 0.77
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.49; acc: 0.81
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.7; acc: 0.73
Batch: 280; loss: 0.51; acc: 0.78
Batch: 300; loss: 0.53; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.61; acc: 0.81
Batch: 440; loss: 0.35; acc: 0.84
Batch: 460; loss: 0.69; acc: 0.8
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.62; acc: 0.81
Batch: 600; loss: 0.26; acc: 0.88
Batch: 620; loss: 0.72; acc: 0.84
Batch: 640; loss: 0.4; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.91
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

Batch: 0; loss: 0.61; acc: 0.75
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.92; acc: 0.77
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.88; acc: 0.77
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.4645654535882033; val_accuracy: 0.8518113057324841 

The current subspace-distance is: 2.201823917857837e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.84
Batch: 460; loss: 0.3; acc: 0.95
Batch: 480; loss: 0.51; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.56; acc: 0.83
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.39; acc: 0.91
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.8
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.35; acc: 0.86
Val Epoch over. val_loss: 0.3936713328407069; val_accuracy: 0.8675358280254777 

The current subspace-distance is: 3.118440872640349e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.29; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.8
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.58; acc: 0.84
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.38; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.46; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.55; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.25163778463366687; val_accuracy: 0.92296974522293 

The current subspace-distance is: 3.834720700979233e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.56; acc: 0.88
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.84
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.42; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.56; acc: 0.81
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.26979826253121064; val_accuracy: 0.915406050955414 

The current subspace-distance is: 4.5183722249930725e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.84
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.65; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.08; acc: 1.0
Batch: 660; loss: 0.34; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.26043984070894827; val_accuracy: 0.9235668789808917 

The current subspace-distance is: 5.0557853683130816e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.08; acc: 1.0
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.08; acc: 1.0
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.25134405038159363; val_accuracy: 0.9274482484076433 

The current subspace-distance is: 5.547197361011058e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.07; acc: 1.0
Batch: 600; loss: 0.25; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.94
Batch: 760; loss: 0.54; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.56; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2788707883494675; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 6.136457523098215e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.52; acc: 0.81
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2672788813520389; val_accuracy: 0.9188893312101911 

The current subspace-distance is: 6.703666440444067e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.34; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.95
Val Epoch over. val_loss: 0.19735898006304053; val_accuracy: 0.9405851910828026 

The current subspace-distance is: 7.118708163034171e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.18622663322907346; val_accuracy: 0.9444665605095541 

The current subspace-distance is: 7.602458208566532e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.08; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.29; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.23; acc: 0.97
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.86
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19480607207793338; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 8.090755000011995e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.38; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.22; acc: 0.88
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.84
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19947422841551957; val_accuracy: 0.9397890127388535 

The current subspace-distance is: 8.293776045320556e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.08; acc: 1.0
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.97
Batch: 540; loss: 0.34; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.18599334129007758; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 8.591860387241468e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.18; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.18148966551206674; val_accuracy: 0.944765127388535 

The current subspace-distance is: 8.90409282874316e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.88
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.06; acc: 1.0
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17584410784350837; val_accuracy: 0.946656050955414 

The current subspace-distance is: 9.269829752156511e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.4; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.51; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19258860531885913; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 9.65250947047025e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.12; acc: 1.0
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.41; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20109398995235467; val_accuracy: 0.939390923566879 

The current subspace-distance is: 9.992260311264545e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.83
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.33; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.18050357395676292; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 0.00010352691606385633 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.06; acc: 1.0
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.06; acc: 1.0
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.08; acc: 1.0
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.48; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.18857307015520752; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 0.00010718323028413579 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1762139805278201; val_accuracy: 0.9471536624203821 

The current subspace-distance is: 0.00011192376405233517 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.07; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17565486143538905; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 0.00011495978105813265 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.98
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.3; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17474103457988446; val_accuracy: 0.9471536624203821 

The current subspace-distance is: 0.00011863048712257296 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.18210279908339688; val_accuracy: 0.9472531847133758 

The current subspace-distance is: 0.0001218591642100364 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.07; acc: 1.0
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.07; acc: 1.0
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17381488099978987; val_accuracy: 0.9483479299363057 

The current subspace-distance is: 0.00012516428250819445 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.89
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.05; acc: 1.0
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.36; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1714624207300745; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 0.00012760379468090832 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.07; acc: 1.0
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.1; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.171245668296981; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 0.00013212185876909643 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.33; acc: 0.84
Batch: 720; loss: 0.25; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17559858933565722; val_accuracy: 0.9473527070063694 

The current subspace-distance is: 0.0001339517330052331 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.44; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17166674369649523; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 0.0001369993988191709 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.89
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.98
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.42; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17223624396286194; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 0.00014042877592146397 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.39; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.3; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17189501240185112; val_accuracy: 0.948546974522293 

The current subspace-distance is: 0.0001437983737559989 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.52; acc: 0.89
Batch: 280; loss: 0.06; acc: 1.0
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.53; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16988777549593312; val_accuracy: 0.9494426751592356 

The current subspace-distance is: 0.00014615368854720145 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.5; acc: 0.88
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17063387464376012; val_accuracy: 0.9488455414012739 

The current subspace-distance is: 0.00014877277135383338 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.92
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.07; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.98
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.17074872785882586; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 0.0001502726663602516 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.47; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.08; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.06; acc: 1.0
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1706114668090632; val_accuracy: 0.9492436305732485 

The current subspace-distance is: 0.00015155853179749101 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.22; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.44; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.31; acc: 0.86
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.17050465082476854; val_accuracy: 0.9490445859872612 

The current subspace-distance is: 0.00015347979206126183 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.92
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16917643947586133; val_accuracy: 0.949343152866242 

The current subspace-distance is: 0.000156286041601561 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.25; acc: 0.86
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1705669125981012; val_accuracy: 0.9490445859872612 

The current subspace-distance is: 0.00015875653480179608 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.91
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.98
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.16933294793792592; val_accuracy: 0.9483479299363057 

The current subspace-distance is: 0.0001600102987140417 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.32; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.84
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.16993350832230725; val_accuracy: 0.9488455414012739 

The current subspace-distance is: 0.00016194162890315056 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.86
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.89
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16840469300936742; val_accuracy: 0.9501393312101911 

The current subspace-distance is: 0.00016482078353874385 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.34; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.16898112335971965; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 0.00016635807696729898 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.88
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.92
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.32; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16820090401704144; val_accuracy: 0.9492436305732485 

The current subspace-distance is: 0.00016842552577145398 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.07; acc: 1.0
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16882858828754183; val_accuracy: 0.9497412420382165 

The current subspace-distance is: 0.00017056181968655437 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1685112657345784; val_accuracy: 0.9492436305732485 

The current subspace-distance is: 0.00017341948114335537 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.98
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.98
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16875904442588235; val_accuracy: 0.9492436305732485 

The current subspace-distance is: 0.00017630457296036184 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.97
Batch: 140; loss: 0.43; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1688656337606679; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 0.00017721118638291955 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.98
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.89
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.24; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.98
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.86
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.16842214995698565; val_accuracy: 0.9496417197452229 

The current subspace-distance is: 0.00017947578453458846 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.32; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1689331610776057; val_accuracy: 0.9491441082802548 

The current subspace-distance is: 0.00018239014025311917 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.51; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.45; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1686334295352553; val_accuracy: 0.9499402866242038 

The current subspace-distance is: 0.00018506126070860773 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_250_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 63973
elements in E: 13497000
fraction nonzero: 0.004739794028302585
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.17
Batch: 160; loss: 2.28; acc: 0.27
Batch: 180; loss: 2.29; acc: 0.2
Batch: 200; loss: 2.26; acc: 0.31
Batch: 220; loss: 2.25; acc: 0.39
Batch: 240; loss: 2.26; acc: 0.27
Batch: 260; loss: 2.24; acc: 0.28
Batch: 280; loss: 2.22; acc: 0.39
Batch: 300; loss: 2.17; acc: 0.38
Batch: 320; loss: 2.15; acc: 0.42
Batch: 340; loss: 2.06; acc: 0.41
Batch: 360; loss: 1.92; acc: 0.44
Batch: 380; loss: 1.69; acc: 0.39
Batch: 400; loss: 1.73; acc: 0.39
Batch: 420; loss: 1.41; acc: 0.52
Batch: 440; loss: 1.45; acc: 0.48
Batch: 460; loss: 1.58; acc: 0.5
Batch: 480; loss: 1.21; acc: 0.61
Batch: 500; loss: 0.7; acc: 0.78
Batch: 520; loss: 0.96; acc: 0.73
Batch: 540; loss: 0.89; acc: 0.77
Batch: 560; loss: 0.61; acc: 0.77
Batch: 580; loss: 0.92; acc: 0.7
Batch: 600; loss: 0.74; acc: 0.78
Batch: 620; loss: 0.58; acc: 0.84
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.61; acc: 0.73
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.63; acc: 0.78
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.58; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 1.51; train_accuracy: 0.5 

Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.89
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.41749057107290644; val_accuracy: 0.8711186305732485 

The current subspace-distance is: 1.36441012728028e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.52; acc: 0.78
Batch: 40; loss: 0.41; acc: 0.83
Batch: 60; loss: 0.55; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.47; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.71; acc: 0.77
Batch: 280; loss: 0.58; acc: 0.81
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.55; acc: 0.84
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.81; acc: 0.88
Batch: 640; loss: 0.31; acc: 0.84
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.34405147550022525; val_accuracy: 0.8910230891719745 

The current subspace-distance is: 2.4404786017839797e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.83
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.24350972691918635; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 3.293767076684162e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.98
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.94
Batch: 600; loss: 0.07; acc: 1.0
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.18160976953567212; val_accuracy: 0.943172770700637 

The current subspace-distance is: 3.9508009649580345e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.24703000236753445; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 4.5531473006121814e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.18727925967923395; val_accuracy: 0.941281847133758 

The current subspace-distance is: 5.15502251801081e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.88
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.1671581412576566; val_accuracy: 0.949343152866242 

The current subspace-distance is: 5.631454769172706e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.98
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.41; acc: 0.84
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.166880673900911; val_accuracy: 0.9475517515923567 

The current subspace-distance is: 6.116848817327991e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.2533240157897305; val_accuracy: 0.9243630573248408 

The current subspace-distance is: 6.641990330535918e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.91
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13992373702252747; val_accuracy: 0.959593949044586 

The current subspace-distance is: 7.10617023287341e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13039683532800264; val_accuracy: 0.9597929936305732 

The current subspace-distance is: 7.587292930111289e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.98
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.14267555614755412; val_accuracy: 0.956906847133758 

The current subspace-distance is: 7.982186798471957e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.28; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.23; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.13337402474016521; val_accuracy: 0.9611863057324841 

The current subspace-distance is: 8.392699965042993e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.98
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.21; acc: 0.89
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.14650050880517929; val_accuracy: 0.9572054140127388 

The current subspace-distance is: 8.772603905526921e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13071066034352705; val_accuracy: 0.9593949044585988 

The current subspace-distance is: 9.085488272830844e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.15; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12472382873581474; val_accuracy: 0.9623805732484076 

The current subspace-distance is: 9.40339159569703e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.07; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.06; acc: 1.0
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.13; acc: 0.92
Batch: 760; loss: 0.06; acc: 1.0
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12179684200009723; val_accuracy: 0.9628781847133758 

The current subspace-distance is: 9.701804083306342e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.02; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.95
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.07; acc: 1.0
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12815830323868876; val_accuracy: 0.9597929936305732 

The current subspace-distance is: 9.962681360775605e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.35; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.46; acc: 0.84
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1276236740267201; val_accuracy: 0.9609872611464968 

The current subspace-distance is: 0.00010306666808901355 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.02; acc: 0.98
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1379914433713172; val_accuracy: 0.9579020700636943 

The current subspace-distance is: 0.00010585416021058336 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.98
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12377963981525913; val_accuracy: 0.9629777070063694 

The current subspace-distance is: 0.00010932044096989557 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.41; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12217123106501665; val_accuracy: 0.9618829617834395 

The current subspace-distance is: 0.0001118942309403792 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11708313473470651; val_accuracy: 0.9629777070063694 

The current subspace-distance is: 0.0001162331536761485 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12656786235844253; val_accuracy: 0.9623805732484076 

The current subspace-distance is: 0.00011914283822989091 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12266073569323227; val_accuracy: 0.9636743630573248 

The current subspace-distance is: 0.00012155319564044476 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.07; acc: 1.0
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11385961980291992; val_accuracy: 0.9647691082802548 

The current subspace-distance is: 0.00012532647815532982 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11560276193413765; val_accuracy: 0.9650676751592356 

The current subspace-distance is: 0.00012808269821107388 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.97
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1157824682059941; val_accuracy: 0.9640724522292994 

The current subspace-distance is: 0.00013076716277282685 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11565160912692926; val_accuracy: 0.9645700636942676 

The current subspace-distance is: 0.00013425313227344304 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.25; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11739366693766254; val_accuracy: 0.9643710191082803 

The current subspace-distance is: 0.00013720872811973095 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11542246993749765; val_accuracy: 0.9657643312101911 

The current subspace-distance is: 0.00013894120638724416 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1153283463613053; val_accuracy: 0.9651671974522293 

The current subspace-distance is: 0.00014071367331780493 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.92
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11393109902407333; val_accuracy: 0.9652667197452229 

The current subspace-distance is: 0.00014369456039275974 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.29; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.25; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11463200172800926; val_accuracy: 0.9659633757961783 

The current subspace-distance is: 0.00014621191076003015 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.14; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.12; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1142006745075534; val_accuracy: 0.9661624203821656 

The current subspace-distance is: 0.00014841245138086379 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.24; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.07; acc: 1.0
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.07; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11544039757673148; val_accuracy: 0.9655652866242038 

The current subspace-distance is: 0.00014935295621398836 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.05; acc: 1.0
Batch: 140; loss: 0.14; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.94
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11461002989464504; val_accuracy: 0.9650676751592356 

The current subspace-distance is: 0.00015256866754498333 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.06; acc: 1.0
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.19; acc: 0.91
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.94
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11263424216229824; val_accuracy: 0.9656648089171974 

The current subspace-distance is: 0.0001560437522130087 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.98
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.11; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11372202136524164; val_accuracy: 0.9662619426751592 

The current subspace-distance is: 0.00015955721028149128 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.98
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.96 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11292342037247245; val_accuracy: 0.9658638535031847 

The current subspace-distance is: 0.00016204097482841462 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.04; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.94
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11278484513757715; val_accuracy: 0.9662619426751592 

The current subspace-distance is: 0.00016433297423645854 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.98
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.14; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11260721321176191; val_accuracy: 0.966062898089172 

The current subspace-distance is: 0.00016531730943825096 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.06; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11182833727520362; val_accuracy: 0.9659633757961783 

The current subspace-distance is: 0.00016735239478293806 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11263014682254215; val_accuracy: 0.9661624203821656 

The current subspace-distance is: 0.00016954727470874786 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.13; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11314450535377499; val_accuracy: 0.9658638535031847 

The current subspace-distance is: 0.00017157764523290098 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.06; acc: 1.0
Batch: 180; loss: 0.13; acc: 0.98
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11319582451395928; val_accuracy: 0.9656648089171974 

The current subspace-distance is: 0.00017376754840370268 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.4; acc: 0.94
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1124282086469755; val_accuracy: 0.9661624203821656 

The current subspace-distance is: 0.00017536163795739412 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11239111438915608; val_accuracy: 0.9659633757961783 

The current subspace-distance is: 0.00017811755242291838 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.97
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11265519426269516; val_accuracy: 0.9662619426751592 

The current subspace-distance is: 0.00018019576964434236 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.13; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.98
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11250028851780162; val_accuracy: 0.9661624203821656 

The current subspace-distance is: 0.00018296053167432547 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 74111
elements in E: 15746500
fraction nonzero: 0.0047065062077287015
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.17
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.17
Batch: 160; loss: 2.28; acc: 0.28
Batch: 180; loss: 2.28; acc: 0.2
Batch: 200; loss: 2.25; acc: 0.41
Batch: 220; loss: 2.24; acc: 0.33
Batch: 240; loss: 2.24; acc: 0.2
Batch: 260; loss: 2.21; acc: 0.33
Batch: 280; loss: 2.17; acc: 0.39
Batch: 300; loss: 2.02; acc: 0.44
Batch: 320; loss: 1.86; acc: 0.5
Batch: 340; loss: 1.54; acc: 0.47
Batch: 360; loss: 1.21; acc: 0.67
Batch: 380; loss: 1.07; acc: 0.69
Batch: 400; loss: 0.8; acc: 0.8
Batch: 420; loss: 0.61; acc: 0.78
Batch: 440; loss: 0.63; acc: 0.83
Batch: 460; loss: 0.74; acc: 0.8
Batch: 480; loss: 0.62; acc: 0.8
Batch: 500; loss: 0.54; acc: 0.8
Batch: 520; loss: 0.63; acc: 0.88
Batch: 540; loss: 0.49; acc: 0.81
Batch: 560; loss: 0.5; acc: 0.88
Batch: 580; loss: 0.81; acc: 0.81
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.84
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 1.29; train_accuracy: 0.57 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.3027586570116365; val_accuracy: 0.9033638535031847 

The current subspace-distance is: 1.33138892124407e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.83
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.81
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.49; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.62; acc: 0.89
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2410811770731097; val_accuracy: 0.9248606687898089 

The current subspace-distance is: 2.2346473997458816e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.89
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20388012282123233; val_accuracy: 0.9380971337579618 

The current subspace-distance is: 3.0232951758080162e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17414650456256167; val_accuracy: 0.9477507961783439 

The current subspace-distance is: 3.679787187138572e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.91
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.16693448272954886; val_accuracy: 0.9514331210191083 

The current subspace-distance is: 4.2830928578041494e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.88
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15845597416731963; val_accuracy: 0.9529259554140127 

The current subspace-distance is: 4.801467730430886e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.91
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2552340816777603; val_accuracy: 0.9274482484076433 

The current subspace-distance is: 5.280895493342541e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.91
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.46; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1574264797767636; val_accuracy: 0.9541202229299363 

The current subspace-distance is: 5.776343459729105e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.08; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20560725835288407; val_accuracy: 0.9368033439490446 

The current subspace-distance is: 6.226191180758178e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.23; acc: 0.97
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14235061950459602; val_accuracy: 0.9591958598726115 

The current subspace-distance is: 6.737151852576062e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.92
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1264711958207902; val_accuracy: 0.964968152866242 

The current subspace-distance is: 7.210516196209937e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13504060792030803; val_accuracy: 0.9617834394904459 

The current subspace-distance is: 7.661658310098574e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.07; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13335480904028674; val_accuracy: 0.9633757961783439 

The current subspace-distance is: 7.975485641509295e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13033470027386004; val_accuracy: 0.9634753184713376 

The current subspace-distance is: 8.329311094712466e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.91
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1380147201477722; val_accuracy: 0.9600915605095541 

The current subspace-distance is: 8.62903252709657e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.12225380646669941; val_accuracy: 0.9653662420382165 

The current subspace-distance is: 8.94938493729569e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.39; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12450634944400969; val_accuracy: 0.9645700636942676 

The current subspace-distance is: 9.26249340409413e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.06; acc: 1.0
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.21; acc: 0.97
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13230647652107438; val_accuracy: 0.9631767515923567 

The current subspace-distance is: 9.550230606691912e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.13795759675988725; val_accuracy: 0.9613853503184714 

The current subspace-distance is: 9.891731315292418e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.3; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.95
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.95
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1315460759837916; val_accuracy: 0.9633757961783439 

The current subspace-distance is: 0.00010168657900067046 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.04; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.23; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.02; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.07; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12238834209882529; val_accuracy: 0.9653662420382165 

The current subspace-distance is: 0.00010485920938663185 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.92
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12135827989809832; val_accuracy: 0.9669585987261147 

The current subspace-distance is: 0.00010714858944993466 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.91
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11745243823262537; val_accuracy: 0.9667595541401274 

The current subspace-distance is: 0.00010963259410345927 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.95
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1266326929923076; val_accuracy: 0.9646695859872612 

The current subspace-distance is: 0.00011242648906772956 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.02; acc: 0.98
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.04; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11620011484357202; val_accuracy: 0.96765525477707 

The current subspace-distance is: 0.00011505188012961298 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.06; acc: 1.0
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11334303640730821; val_accuracy: 0.9695461783439491 

The current subspace-distance is: 0.00011758018081309274 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.05; acc: 0.95
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11405472827565138; val_accuracy: 0.9680533439490446 

The current subspace-distance is: 0.00012013191735604778 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.31; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11934504019701557; val_accuracy: 0.9669585987261147 

The current subspace-distance is: 0.00012245986727066338 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.29; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.98
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11419981929242232; val_accuracy: 0.9678542993630573 

The current subspace-distance is: 0.00012490717926993966 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12002466970188602; val_accuracy: 0.9662619426751592 

The current subspace-distance is: 0.0001279816497117281 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.1; acc: 0.92
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11514253413696197; val_accuracy: 0.9671576433121019 

The current subspace-distance is: 0.00013053030124865472 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.02; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11246404913105783; val_accuracy: 0.9683519108280255 

The current subspace-distance is: 0.00013317566481418908 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.92
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1142784181246712; val_accuracy: 0.9680533439490446 

The current subspace-distance is: 0.00013532050070352852 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11444590081739578; val_accuracy: 0.9677547770700637 

The current subspace-distance is: 0.0001373856357531622 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.92
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11704104735403303; val_accuracy: 0.9671576433121019 

The current subspace-distance is: 0.00014005685807205737 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.92
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11460601908575957; val_accuracy: 0.9679538216560509 

The current subspace-distance is: 0.00014169748465064913 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.05; acc: 1.0
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.02; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11415961724083135; val_accuracy: 0.9674562101910829 

The current subspace-distance is: 0.0001443181827198714 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.07; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.92
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11165166352015392; val_accuracy: 0.9685509554140127 

The current subspace-distance is: 0.00014587237092200667 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.02; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.3; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1114811351771947; val_accuracy: 0.9685509554140127 

The current subspace-distance is: 0.00014696212019771338 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.45; acc: 0.94
Batch: 300; loss: 0.02; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.94
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11343607292243629; val_accuracy: 0.9684514331210191 

The current subspace-distance is: 0.0001488538400735706 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.94
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.04; acc: 0.97
Batch: 440; loss: 0.04; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.94
Batch: 760; loss: 0.04; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11233711339960432; val_accuracy: 0.9681528662420382 

The current subspace-distance is: 0.0001512506860308349 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11168001862658057; val_accuracy: 0.9680533439490446 

The current subspace-distance is: 0.00015360578254330903 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.43; acc: 0.91
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11055626342915426; val_accuracy: 0.9688495222929936 

The current subspace-distance is: 0.00015566876390948892 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.05; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11185157054643723; val_accuracy: 0.9686504777070064 

The current subspace-distance is: 0.0001581029500812292 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.21; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11193684400741462; val_accuracy: 0.9689490445859873 

The current subspace-distance is: 0.0001604147400939837 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.2; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11257304815919536; val_accuracy: 0.9685509554140127 

The current subspace-distance is: 0.00016225135186687112 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.94
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11078451431480943; val_accuracy: 0.9685509554140127 

The current subspace-distance is: 0.00016404784400947392 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.95
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.24; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11030009792299028; val_accuracy: 0.9691480891719745 

The current subspace-distance is: 0.00016623169358354062 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.19; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.95
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.07; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11109594988879884; val_accuracy: 0.9694466560509554 

The current subspace-distance is: 0.00016873730055522174 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.02; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.11102959330958925; val_accuracy: 0.9685509554140127 

The current subspace-distance is: 0.00017085055878851563 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_350_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 84756
elements in E: 17996000
fraction nonzero: 0.0047097132696154705
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.17
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.27; acc: 0.31
Batch: 160; loss: 2.25; acc: 0.39
Batch: 180; loss: 2.23; acc: 0.27
Batch: 200; loss: 2.16; acc: 0.53
Batch: 220; loss: 2.09; acc: 0.64
Batch: 240; loss: 1.97; acc: 0.47
Batch: 260; loss: 1.72; acc: 0.55
Batch: 280; loss: 1.49; acc: 0.53
Batch: 300; loss: 1.04; acc: 0.66
Batch: 320; loss: 1.25; acc: 0.55
Batch: 340; loss: 0.88; acc: 0.77
Batch: 360; loss: 0.63; acc: 0.78
Batch: 380; loss: 1.04; acc: 0.67
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.52; acc: 0.81
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.68; acc: 0.83
Batch: 540; loss: 0.47; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.63; acc: 0.78
Batch: 600; loss: 0.44; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 1.11; train_accuracy: 0.64 

Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.8
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.26878675984539047; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 1.563879595778417e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.83
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.59; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.56; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.92
Batch: 620; loss: 0.53; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.2561054060793227; val_accuracy: 0.9144108280254777 

The current subspace-distance is: 2.4162929548765533e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.08; acc: 1.0
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.22044714575835095; val_accuracy: 0.9347133757961783 

The current subspace-distance is: 3.1838033464737236e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.16; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.34; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.08; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.91
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1530073244053467; val_accuracy: 0.9505374203821656 

The current subspace-distance is: 3.8394355215132236e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.06; acc: 1.0
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14756620414317792; val_accuracy: 0.9572054140127388 

The current subspace-distance is: 4.398790406412445e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.14158999644646977; val_accuracy: 0.9559116242038217 

The current subspace-distance is: 4.900209023617208e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.91
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.1416769258345768; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 5.433182741398923e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.92
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.44; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1180367992277358; val_accuracy: 0.9643710191082803 

The current subspace-distance is: 5.865802086191252e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.98
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 1.11; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.86; acc: 0.77
Batch: 120; loss: 1.07; acc: 0.73
Batch: 140; loss: 0.51; acc: 0.81
Val Epoch over. val_loss: 0.7776599474203815; val_accuracy: 0.7881170382165605 

The current subspace-distance is: 6.325099093373865e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.84; acc: 0.78
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.04; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.98
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.11423077913606243; val_accuracy: 0.9656648089171974 

The current subspace-distance is: 6.757247319910675e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.08; acc: 1.0
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.15; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10365234016423013; val_accuracy: 0.9674562101910829 

The current subspace-distance is: 7.087002450134605e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.42; acc: 0.92
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.01; acc: 0.98
Val Epoch over. val_loss: 0.10544295839158593; val_accuracy: 0.9677547770700637 

The current subspace-distance is: 7.504170207539573e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.06; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.07; acc: 1.0
Batch: 300; loss: 0.08; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.11; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.95
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.16; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.10148827176374994; val_accuracy: 0.9684514331210191 

The current subspace-distance is: 7.878498581703752e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.02; acc: 0.98
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1297124152065842; val_accuracy: 0.9599920382165605 

The current subspace-distance is: 8.268724923254922e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.11; acc: 0.94
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.95
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10464025573555831; val_accuracy: 0.9681528662420382 

The current subspace-distance is: 8.586602052673697e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.94
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.28; acc: 0.95
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.02; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10611813064593419; val_accuracy: 0.9679538216560509 

The current subspace-distance is: 8.93844771781005e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.10216733481094337; val_accuracy: 0.9688495222929936 

The current subspace-distance is: 9.304657578468323e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.98
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11259744620057428; val_accuracy: 0.9656648089171974 

The current subspace-distance is: 9.624497761251405e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.06; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.92
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.10826480130006554; val_accuracy: 0.9674562101910829 

The current subspace-distance is: 9.962843614630401e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.28; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.89
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.12009241396359577; val_accuracy: 0.9629777070063694 

The current subspace-distance is: 0.000103082595160231 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.09934695679575774; val_accuracy: 0.9703423566878981 

The current subspace-distance is: 0.00010625510185491294 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.10064677870387484; val_accuracy: 0.9695461783439491 

The current subspace-distance is: 0.00010885654046433046 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.07; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.09855919718077988; val_accuracy: 0.9705414012738853 

The current subspace-distance is: 0.00011229111260036007 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.10139888040958696; val_accuracy: 0.9693471337579618 

The current subspace-distance is: 0.0001147294751717709 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.94
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.02; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10056357928047514; val_accuracy: 0.9696457006369427 

The current subspace-distance is: 0.00011710289254551753 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.22; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.01; acc: 0.98
Val Epoch over. val_loss: 0.09444761235907578; val_accuracy: 0.9723328025477707 

The current subspace-distance is: 0.00011914418428204954 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.95
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09796400363468061; val_accuracy: 0.970640923566879 

The current subspace-distance is: 0.00012245742254890501 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.01; acc: 1.0
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.03; acc: 0.97
Val Epoch over. val_loss: 0.09793002651945042; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 0.00012512356624938548 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.04; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.04; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0948392876014588; val_accuracy: 0.9710390127388535 

The current subspace-distance is: 0.000127568855532445 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.1; acc: 0.94
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.10005471335759589; val_accuracy: 0.9705414012738853 

The current subspace-distance is: 0.00012989158858545125 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.05; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09594297530070232; val_accuracy: 0.9715366242038217 

The current subspace-distance is: 0.0001316775887971744 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.01; acc: 1.0
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.03; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09410300369190562; val_accuracy: 0.9713375796178344 

The current subspace-distance is: 0.00013373815454542637 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.02; acc: 0.98
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.02; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.05; acc: 1.0
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09300609694639589; val_accuracy: 0.9722332802547771 

The current subspace-distance is: 0.00013662192213814706 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.0; acc: 1.0
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.02; acc: 0.98
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.02; acc: 0.98
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09441174815889376; val_accuracy: 0.9719347133757962 

The current subspace-distance is: 0.0001398073072778061 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.02; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.22; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09484310417323355; val_accuracy: 0.9716361464968153 

The current subspace-distance is: 0.00014177009870763868 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.02; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09419897751538617; val_accuracy: 0.971437101910828 

The current subspace-distance is: 0.0001439965417375788 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.02; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.94
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.0954486387692819; val_accuracy: 0.9703423566878981 

The current subspace-distance is: 0.0001461338106309995 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.39; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.02; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.44; acc: 0.92
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.97
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09246542155268087; val_accuracy: 0.971437101910828 

The current subspace-distance is: 0.00014756573364138603 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.95
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09504346502055029; val_accuracy: 0.9716361464968153 

The current subspace-distance is: 0.00014949288743082434 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.95
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.3; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.94
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09161302110381947; val_accuracy: 0.9726313694267515 

The current subspace-distance is: 0.00015190795238595456 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.1; acc: 0.94
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.97
Batch: 740; loss: 0.06; acc: 1.0
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.09341534419329303; val_accuracy: 0.9720342356687898 

The current subspace-distance is: 0.00015471820370294154 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.02; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09283818368604228; val_accuracy: 0.9717356687898089 

The current subspace-distance is: 0.0001569128653500229 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.97
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09283482285726602; val_accuracy: 0.9721337579617835 

The current subspace-distance is: 0.00015891519433353096 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.25; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09235119221696428; val_accuracy: 0.972531847133758 

The current subspace-distance is: 0.00016100854554679245 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.02; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.09328633349887125; val_accuracy: 0.9723328025477707 

The current subspace-distance is: 0.00016341944865416735 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09334507446949648; val_accuracy: 0.9726313694267515 

The current subspace-distance is: 0.00016484677325934172 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.02; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09262197723339317; val_accuracy: 0.9719347133757962 

The current subspace-distance is: 0.00016657140804454684 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.09278871455959453; val_accuracy: 0.9731289808917197 

The current subspace-distance is: 0.00016850511019583791 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.33; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.02; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.0933590709783469; val_accuracy: 0.972531847133758 

The current subspace-distance is: 0.0001697594707366079 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.02; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.09185873726560811; val_accuracy: 0.9724323248407644 

The current subspace-distance is: 0.00017162012227345258 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 95554
elements in E: 20245500
fraction nonzero: 0.004719764886024055
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.19
Batch: 80; loss: 2.28; acc: 0.27
Batch: 100; loss: 2.28; acc: 0.2
Batch: 120; loss: 2.24; acc: 0.38
Batch: 140; loss: 2.22; acc: 0.36
Batch: 160; loss: 2.15; acc: 0.47
Batch: 180; loss: 1.99; acc: 0.39
Batch: 200; loss: 1.59; acc: 0.59
Batch: 220; loss: 1.17; acc: 0.61
Batch: 240; loss: 1.3; acc: 0.47
Batch: 260; loss: 1.64; acc: 0.53
Batch: 280; loss: 0.7; acc: 0.81
Batch: 300; loss: 0.83; acc: 0.81
Batch: 320; loss: 0.83; acc: 0.75
Batch: 340; loss: 0.62; acc: 0.84
Batch: 360; loss: 0.64; acc: 0.77
Batch: 380; loss: 0.52; acc: 0.8
Batch: 400; loss: 0.47; acc: 0.83
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.42; acc: 0.81
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.67; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.59; acc: 0.86
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.19; acc: 0.91
Batch: 680; loss: 0.5; acc: 0.81
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.97; train_accuracy: 0.69 

Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.31832772279810756; val_accuracy: 0.8996815286624203 

The current subspace-distance is: 1.5881745639489964e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.98
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.97
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.44; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.79; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.83
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.89; acc: 0.77
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.91; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.36449942090044357; val_accuracy: 0.8779856687898089 

The current subspace-distance is: 2.4572118491050787e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.07; acc: 1.0
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.89
Batch: 720; loss: 0.43; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.2602388262274159; val_accuracy: 0.9181926751592356 

The current subspace-distance is: 3.181847569067031e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15164545667209442; val_accuracy: 0.95203025477707 

The current subspace-distance is: 3.783022839343175e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22686967525370183; val_accuracy: 0.9300358280254777 

The current subspace-distance is: 4.384067506180145e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.13504571049432657; val_accuracy: 0.959593949044586 

The current subspace-distance is: 4.920380160911009e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.89
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.1970228976955649; val_accuracy: 0.9392914012738853 

The current subspace-distance is: 5.469022289616987e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1310741772020983; val_accuracy: 0.9596934713375797 

The current subspace-distance is: 5.96307436353527e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.35; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.07; acc: 1.0
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.85; acc: 0.73
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.94; acc: 0.72
Batch: 140; loss: 0.43; acc: 0.84
Val Epoch over. val_loss: 0.49502270607052334; val_accuracy: 0.8461385350318471 

The current subspace-distance is: 6.428077176678926e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.12006030718137504; val_accuracy: 0.9647691082802548 

The current subspace-distance is: 6.941700121387839e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11168183543226996; val_accuracy: 0.9670581210191083 

The current subspace-distance is: 7.395487045869231e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.04; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.97
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10254938848046764; val_accuracy: 0.9691480891719745 

The current subspace-distance is: 7.821346662240103e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.14; acc: 0.98
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10737883044216948; val_accuracy: 0.9679538216560509 

The current subspace-distance is: 8.190938387997448e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.91
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11692014560815256; val_accuracy: 0.9644705414012739 

The current subspace-distance is: 8.523806172888726e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.94
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.83
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10077662243074767; val_accuracy: 0.9693471337579618 

The current subspace-distance is: 8.878804510459304e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.05; acc: 1.0
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10201553273115568; val_accuracy: 0.9701433121019108 

The current subspace-distance is: 9.215517638949677e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.01; acc: 1.0
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.11; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09885695464404858; val_accuracy: 0.9712380573248408 

The current subspace-distance is: 9.550671529723331e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.12; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.97
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10431658610802405; val_accuracy: 0.9693471337579618 

The current subspace-distance is: 9.850827336777002e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.04; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.04; acc: 0.97
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.98
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09829614244425183; val_accuracy: 0.9724323248407644 

The current subspace-distance is: 0.00010163133265450597 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.91
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.06; acc: 1.0
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.98
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10738106622141164; val_accuracy: 0.9695461783439491 

The current subspace-distance is: 0.00010476015449967235 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.01; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0938792324329839; val_accuracy: 0.9732285031847133 

The current subspace-distance is: 0.0001082785238395445 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0943951014923169; val_accuracy: 0.9721337579617835 

The current subspace-distance is: 0.00011158454435644671 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09572016505322828; val_accuracy: 0.9720342356687898 

The current subspace-distance is: 0.00011461248504929245 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09777841749408277; val_accuracy: 0.9711385350318471 

The current subspace-distance is: 0.0001176642399514094 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.02; acc: 0.98
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.05; acc: 1.0
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.14; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0951978957078829; val_accuracy: 0.9721337579617835 

The current subspace-distance is: 0.00012109825183870271 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09220325706413929; val_accuracy: 0.9743232484076433 

The current subspace-distance is: 0.00012324267299845815 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09682141960699372; val_accuracy: 0.9715366242038217 

The current subspace-distance is: 0.00012640478962566704 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.19; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09577780423291431; val_accuracy: 0.9717356687898089 

The current subspace-distance is: 0.00012953495024703443 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09267923538350636; val_accuracy: 0.9715366242038217 

The current subspace-distance is: 0.00013212620979174972 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09857295500707759; val_accuracy: 0.9710390127388535 

The current subspace-distance is: 0.00013482266513165087 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.02; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09197762599259401; val_accuracy: 0.9737261146496815 

The current subspace-distance is: 0.00013717044203076512 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.02; acc: 0.98
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09184448705885298; val_accuracy: 0.9735270700636943 

The current subspace-distance is: 0.00014040872338227928 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.97
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.16; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.02; acc: 0.98
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0912398787847109; val_accuracy: 0.9735270700636943 

The current subspace-distance is: 0.00014288736565504223 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09198026882282867; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 0.00014556753740180284 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.05; acc: 1.0
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0932603011658166; val_accuracy: 0.9730294585987261 

The current subspace-distance is: 0.00014816918701399118 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.44; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.95
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.02; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.92
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.92
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09283419243641387; val_accuracy: 0.9728304140127388 

The current subspace-distance is: 0.0001503217499703169 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.02; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.92
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0926434350523291; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 0.00015236609033308923 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.95
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.98
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.11; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09079343516892711; val_accuracy: 0.9740246815286624 

The current subspace-distance is: 0.00015484896721318364 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.97
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.02; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.04; acc: 0.97
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09150668547212912; val_accuracy: 0.9739251592356688 

The current subspace-distance is: 0.00015728530706837773 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.02; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.39; acc: 0.91
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09080213854819014; val_accuracy: 0.9739251592356688 

The current subspace-distance is: 0.00015900598373264074 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.05; acc: 0.97
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.01; acc: 1.0
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.17; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09070459620101722; val_accuracy: 0.9746218152866242 

The current subspace-distance is: 0.00016103133384604007 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.97
Batch: 340; loss: 0.06; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.02; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.02; acc: 0.98
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.03; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09033774066965576; val_accuracy: 0.9753184713375797 

The current subspace-distance is: 0.00016336320550180972 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0905016512790944; val_accuracy: 0.9742237261146497 

The current subspace-distance is: 0.0001653274812269956 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.16; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.02; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.92
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08969647063322034; val_accuracy: 0.9742237261146497 

The current subspace-distance is: 0.0001674599334364757 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.22; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0901596730880463; val_accuracy: 0.9745222929936306 

The current subspace-distance is: 0.00016961348592303693 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.01; acc: 1.0
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09152841070521575; val_accuracy: 0.9742237261146497 

The current subspace-distance is: 0.00017180340364575386 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.04; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09137341338595387; val_accuracy: 0.9747213375796179 

The current subspace-distance is: 0.00017372032743878663 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.01; acc: 1.0
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.02; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09112341472416356; val_accuracy: 0.9743232484076433 

The current subspace-distance is: 0.00017570606723893434 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.03; acc: 0.98
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09165356640858208; val_accuracy: 0.9745222929936306 

The current subspace-distance is: 0.0001782934705261141 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.07; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09053872755408335; val_accuracy: 0.9745222929936306 

The current subspace-distance is: 0.00018031107902061194 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_450_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 106127
elements in E: 22495000
fraction nonzero: 0.004717803956434763
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.19
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.28; acc: 0.08
Batch: 120; loss: 2.25; acc: 0.22
Batch: 140; loss: 2.22; acc: 0.23
Batch: 160; loss: 2.18; acc: 0.34
Batch: 180; loss: 1.97; acc: 0.36
Batch: 200; loss: 1.53; acc: 0.59
Batch: 220; loss: 1.39; acc: 0.59
Batch: 240; loss: 1.17; acc: 0.53
Batch: 260; loss: 1.01; acc: 0.61
Batch: 280; loss: 0.99; acc: 0.59
Batch: 300; loss: 0.76; acc: 0.72
Batch: 320; loss: 0.81; acc: 0.73
Batch: 340; loss: 0.74; acc: 0.8
Batch: 360; loss: 0.55; acc: 0.8
Batch: 380; loss: 0.84; acc: 0.7
Batch: 400; loss: 0.45; acc: 0.83
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.76; acc: 0.78
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.67; acc: 0.83
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.32; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 1.01; train_accuracy: 0.66 

Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.1; acc: 1.0
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3260440701132367; val_accuracy: 0.897890127388535 

The current subspace-distance is: 1.6323834643117152e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.48; acc: 0.86
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.07; acc: 1.0
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.63; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.22021040794955696; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 2.581939406809397e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.16; acc: 0.98
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.18192609264307721; val_accuracy: 0.9460589171974523 

The current subspace-distance is: 3.3911452192114666e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.07; acc: 1.0
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.13511490446936553; val_accuracy: 0.9599920382165605 

The current subspace-distance is: 4.0791859646560624e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.11; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.07; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.14917322687187773; val_accuracy: 0.9598925159235668 

The current subspace-distance is: 4.685292151407339e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.16; acc: 0.98
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.37; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.12729549225253664; val_accuracy: 0.9615843949044586 

The current subspace-distance is: 5.2038671128684655e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.3; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.05; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.86
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.24782641170320996; val_accuracy: 0.9266520700636943 

The current subspace-distance is: 5.753249570261687e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.12; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.98
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.46; acc: 0.8
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.12531721845838675; val_accuracy: 0.9625796178343949 

The current subspace-distance is: 6.221012881724164e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.25; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.04; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.92
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3473289351269698; val_accuracy: 0.8947054140127388 

The current subspace-distance is: 6.718578515574336e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.34; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.12; train_accuracy: 0.96 

Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.11059961973386966; val_accuracy: 0.9683519108280255 

The current subspace-distance is: 7.178659143391997e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.07; acc: 1.0
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.03; acc: 1.0
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09991876346765051; val_accuracy: 0.9716361464968153 

The current subspace-distance is: 7.62363852118142e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.01; acc: 1.0
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.01; acc: 1.0
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.94
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.1; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10127296415009317; val_accuracy: 0.9708399681528662 

The current subspace-distance is: 8.066209557000548e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.04; acc: 1.0
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.95
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.35; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09914060257327785; val_accuracy: 0.9709394904458599 

The current subspace-distance is: 8.435956988250837e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.09; acc: 0.94
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.33; acc: 0.81
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09983940994378868; val_accuracy: 0.971437101910828 

The current subspace-distance is: 8.829138823784888e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.04; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.0; acc: 1.0
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09919250535832089; val_accuracy: 0.970640923566879 

The current subspace-distance is: 9.191004210151732e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.91
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.06; acc: 1.0
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.02; acc: 0.98
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.02; acc: 0.98
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.02; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09910563623924164; val_accuracy: 0.9717356687898089 

The current subspace-distance is: 9.521590254735202e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.94
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10720021901711536; val_accuracy: 0.9684514331210191 

The current subspace-distance is: 9.85129299806431e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.06; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.37; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09837586425577; val_accuracy: 0.9721337579617835 

The current subspace-distance is: 0.00010182530240854248 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.03; acc: 0.98
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.03; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.10060252856676745; val_accuracy: 0.9707404458598726 

The current subspace-distance is: 0.00010518238559598103 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.95
Batch: 380; loss: 0.01; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.95
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.95
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.94
Train Epoch over. train_loss: 0.09; train_accuracy: 0.97 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.10232582733414736; val_accuracy: 0.9716361464968153 

The current subspace-distance is: 0.00010813750850502402 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.03; acc: 0.98
Batch: 120; loss: 0.02; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.04; acc: 1.0
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.04; acc: 0.97
Batch: 420; loss: 0.01; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.06; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.81
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09180716524837883; val_accuracy: 0.9732285031847133 

The current subspace-distance is: 0.00011132618237752467 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.02; acc: 0.98
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.02; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.02; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09599369719244871; val_accuracy: 0.9713375796178344 

The current subspace-distance is: 0.00011424646072555333 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.01; acc: 1.0
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09233301500700841; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 0.00011714280117303133 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.03; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.94
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09672930003826026; val_accuracy: 0.9730294585987261 

The current subspace-distance is: 0.00012028257333440706 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.06; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09166800422938007; val_accuracy: 0.9732285031847133 

The current subspace-distance is: 0.00012369889009278268 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.02; acc: 0.98
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.98
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09044878206150547; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 0.00012660626089200377 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.11; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.97
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.01; acc: 1.0
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09501779594334067; val_accuracy: 0.9723328025477707 

The current subspace-distance is: 0.00012961078027728945 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.01; acc: 1.0
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.91
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.33; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09453142534016044; val_accuracy: 0.9736265923566879 

The current subspace-distance is: 0.0001323148317169398 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.02; acc: 1.0
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09007883361380571; val_accuracy: 0.9740246815286624 

The current subspace-distance is: 0.00013463606592267752 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.02; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.94
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.97 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09234068127479522; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 0.0001369508681818843 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.04; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09012166987274103; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 0.00013944506645202637 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.01; acc: 1.0
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.03; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.04; acc: 0.98
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.02; acc: 1.0
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.06; acc: 0.95
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09096666824096328; val_accuracy: 0.9742237261146497 

The current subspace-distance is: 0.0001418828614987433 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.02; acc: 1.0
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.01; acc: 1.0
Batch: 380; loss: 0.02; acc: 1.0
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.01; acc: 1.0
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09218925160539758; val_accuracy: 0.9730294585987261 

The current subspace-distance is: 0.0001437277824152261 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.01; acc: 1.0
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.04; acc: 0.97
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09227774641031672; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 0.00014627412019763142 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.01; acc: 1.0
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09115141824742032; val_accuracy: 0.974422770700637 

The current subspace-distance is: 0.00014865290722809732 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.07; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.02; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.03; acc: 0.98
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.95
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09301119955007438; val_accuracy: 0.974422770700637 

The current subspace-distance is: 0.00015111695392988622 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.0915314518508448; val_accuracy: 0.9732285031847133 

The current subspace-distance is: 0.00015304239059332758 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.08; acc: 0.95
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.01; acc: 1.0
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.98
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.03; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.92
Batch: 480; loss: 0.05; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.03; acc: 0.98
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.01; acc: 1.0
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09127895111680791; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 0.00015572065603919327 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.02; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.01; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.09; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.14; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09071266620307211; val_accuracy: 0.9742237261146497 

The current subspace-distance is: 0.00015790938050486147 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.92
Batch: 160; loss: 0.01; acc: 1.0
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.09; acc: 0.94
Batch: 760; loss: 0.03; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.08; train_accuracy: 0.98 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0923901995893117; val_accuracy: 0.9740246815286624 

The current subspace-distance is: 0.00016058857727330178 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.04; acc: 0.97
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.97
Batch: 240; loss: 0.01; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.01; acc: 1.0
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.03; acc: 1.0
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.06; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.01; acc: 1.0
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09113570058326813; val_accuracy: 0.9736265923566879 

The current subspace-distance is: 0.00016264351143036038 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.03; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.05; acc: 0.97
Batch: 380; loss: 0.03; acc: 0.98
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.0; acc: 1.0
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09071081154238267; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 0.00016531556320842355 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.01; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.08; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.03; acc: 0.98
Batch: 360; loss: 0.03; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.03; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.02; acc: 1.0
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.01; acc: 1.0
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.83
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.08998927001835434; val_accuracy: 0.974422770700637 

The current subspace-distance is: 0.00016753116506151855 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.94
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.95
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.01; acc: 1.0
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.01; acc: 1.0
Batch: 660; loss: 0.01; acc: 1.0
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09016455142835902; val_accuracy: 0.9740246815286624 

The current subspace-distance is: 0.00017009572184178978 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.02; acc: 0.98
Batch: 20; loss: 0.03; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.02; acc: 1.0
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.07; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.01; acc: 1.0
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.01; acc: 1.0
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.03; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.03; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.02; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.02; acc: 0.98
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09024071447835987; val_accuracy: 0.9741242038216561 

The current subspace-distance is: 0.00017188352649100125 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.95
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.01; acc: 1.0
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.05; acc: 0.95
Batch: 520; loss: 0.02; acc: 0.98
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.07; acc: 0.95
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.03; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09096469466758382; val_accuracy: 0.974422770700637 

The current subspace-distance is: 0.00017396923794876784 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.95
Batch: 80; loss: 0.01; acc: 1.0
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.98
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.16; acc: 0.98
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.04; acc: 0.95
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09066014696553254; val_accuracy: 0.9738256369426752 

The current subspace-distance is: 0.00017634495452512056 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.07; acc: 0.97
Batch: 200; loss: 0.03; acc: 0.98
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.05; acc: 1.0
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.02; acc: 1.0
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.94
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.04; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.01; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.03; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.0909467788448759; val_accuracy: 0.9746218152866242 

The current subspace-distance is: 0.00017830563592724502 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.94
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.01; acc: 1.0
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.02; acc: 1.0
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.03; acc: 1.0
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.04; acc: 0.97
Batch: 600; loss: 0.01; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.02; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.09145637447382235; val_accuracy: 0.9748208598726115 

The current subspace-distance is: 0.00017998307885136455 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.98
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.02; acc: 1.0
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.06; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.01; acc: 1.0
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.04; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.07; train_accuracy: 0.98 

/home/llang/thesis-intrinsic-dimension/logging_helper.py:44: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax1 = plt.subplots()
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.03; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.09058576297892887; val_accuracy: 0.9740246815286624 

The current subspace-distance is: 0.00018168447422794998 

plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
plots/subspace_training/reg_lenet_3/2020-01-22 14:40:21/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
