model : reg_lenet
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 1
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : False
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 14:38:21
nonzero elements in E: 10406
elements in E: 2197600
fraction nonzero: 0.004735165635238442
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.35; acc: 0.11
Batch: 20; loss: 2.31; acc: 0.08
Batch: 40; loss: 2.33; acc: 0.14
Batch: 60; loss: 2.34; acc: 0.06
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.28; acc: 0.08
Batch: 120; loss: 2.32; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.19
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.31; acc: 0.16
Batch: 200; loss: 2.28; acc: 0.2
Batch: 220; loss: 2.3; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.17
Batch: 260; loss: 2.3; acc: 0.19
Batch: 280; loss: 2.3; acc: 0.16
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.26; acc: 0.2
Batch: 340; loss: 2.24; acc: 0.33
Batch: 360; loss: 2.27; acc: 0.19
Batch: 380; loss: 2.27; acc: 0.09
Batch: 400; loss: 2.24; acc: 0.3
Batch: 420; loss: 2.26; acc: 0.19
Batch: 440; loss: 2.26; acc: 0.17
Batch: 460; loss: 2.26; acc: 0.19
Batch: 480; loss: 2.23; acc: 0.22
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.2; acc: 0.31
Batch: 540; loss: 2.25; acc: 0.14
Batch: 560; loss: 2.25; acc: 0.17
Batch: 580; loss: 2.22; acc: 0.25
Batch: 600; loss: 2.19; acc: 0.28
Batch: 620; loss: 2.18; acc: 0.27
Batch: 640; loss: 2.22; acc: 0.25
Batch: 660; loss: 2.17; acc: 0.28
Batch: 680; loss: 2.22; acc: 0.19
Batch: 700; loss: 2.21; acc: 0.23
Batch: 720; loss: 2.18; acc: 0.22
Batch: 740; loss: 2.21; acc: 0.19
Batch: 760; loss: 2.21; acc: 0.16
Batch: 780; loss: 2.11; acc: 0.3
Train Epoch over. train_loss: 2.25; train_accuracy: 0.2 

Batch: 0; loss: 2.13; acc: 0.33
Batch: 20; loss: 2.18; acc: 0.25
Batch: 40; loss: 2.07; acc: 0.31
Batch: 60; loss: 2.08; acc: 0.33
Batch: 80; loss: 2.13; acc: 0.31
Batch: 100; loss: 2.14; acc: 0.23
Batch: 120; loss: 2.14; acc: 0.31
Batch: 140; loss: 2.14; acc: 0.3
Val Epoch over. val_loss: 2.1439401161898473; val_accuracy: 0.27517914012738853 

The current subspace-distance is: 7.183569778135279e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.14; acc: 0.33
Batch: 20; loss: 2.08; acc: 0.33
Batch: 40; loss: 2.19; acc: 0.2
Batch: 60; loss: 2.15; acc: 0.22
Batch: 80; loss: 2.08; acc: 0.28
Batch: 100; loss: 2.08; acc: 0.28
Batch: 120; loss: 2.08; acc: 0.33
Batch: 140; loss: 2.04; acc: 0.36
Batch: 160; loss: 2.13; acc: 0.2
Batch: 180; loss: 2.09; acc: 0.25
Batch: 200; loss: 2.04; acc: 0.25
Batch: 220; loss: 2.02; acc: 0.31
Batch: 240; loss: 1.96; acc: 0.41
Batch: 260; loss: 2.01; acc: 0.33
Batch: 280; loss: 2.04; acc: 0.27
Batch: 300; loss: 1.91; acc: 0.39
Batch: 320; loss: 2.07; acc: 0.28
Batch: 340; loss: 1.86; acc: 0.42
Batch: 360; loss: 1.96; acc: 0.34
Batch: 380; loss: 1.88; acc: 0.39
Batch: 400; loss: 2.02; acc: 0.3
Batch: 420; loss: 1.93; acc: 0.38
Batch: 440; loss: 1.87; acc: 0.36
Batch: 460; loss: 1.92; acc: 0.34
Batch: 480; loss: 1.93; acc: 0.36
Batch: 500; loss: 1.89; acc: 0.36
Batch: 520; loss: 1.74; acc: 0.47
Batch: 540; loss: 2.02; acc: 0.22
Batch: 560; loss: 1.8; acc: 0.39
Batch: 580; loss: 1.89; acc: 0.31
Batch: 600; loss: 1.83; acc: 0.42
Batch: 620; loss: 1.78; acc: 0.41
Batch: 640; loss: 1.83; acc: 0.3
Batch: 660; loss: 1.79; acc: 0.44
Batch: 680; loss: 1.8; acc: 0.36
Batch: 700; loss: 1.76; acc: 0.39
Batch: 720; loss: 1.91; acc: 0.42
Batch: 740; loss: 1.65; acc: 0.45
Batch: 760; loss: 1.69; acc: 0.36
Batch: 780; loss: 1.82; acc: 0.39
Train Epoch over. train_loss: 1.95; train_accuracy: 0.34 

Batch: 0; loss: 1.68; acc: 0.39
Batch: 20; loss: 1.79; acc: 0.36
Batch: 40; loss: 1.59; acc: 0.55
Batch: 60; loss: 1.54; acc: 0.48
Batch: 80; loss: 1.76; acc: 0.42
Batch: 100; loss: 1.85; acc: 0.34
Batch: 120; loss: 1.8; acc: 0.45
Batch: 140; loss: 1.58; acc: 0.47
Val Epoch over. val_loss: 1.7453908502675926; val_accuracy: 0.40535429936305734 

The current subspace-distance is: 1.5843739674892277e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.7; acc: 0.41
Batch: 20; loss: 1.68; acc: 0.41
Batch: 40; loss: 1.8; acc: 0.38
Batch: 60; loss: 1.61; acc: 0.39
Batch: 80; loss: 1.65; acc: 0.45
Batch: 100; loss: 1.68; acc: 0.45
Batch: 120; loss: 1.86; acc: 0.41
Batch: 140; loss: 1.63; acc: 0.39
Batch: 160; loss: 1.76; acc: 0.42
Batch: 180; loss: 1.76; acc: 0.41
Batch: 200; loss: 1.7; acc: 0.39
Batch: 220; loss: 1.55; acc: 0.5
Batch: 240; loss: 1.85; acc: 0.38
Batch: 260; loss: 1.81; acc: 0.34
Batch: 280; loss: 1.56; acc: 0.48
Batch: 300; loss: 1.6; acc: 0.47
Batch: 320; loss: 1.81; acc: 0.36
Batch: 340; loss: 1.76; acc: 0.34
Batch: 360; loss: 1.68; acc: 0.39
Batch: 380; loss: 1.65; acc: 0.42
Batch: 400; loss: 1.64; acc: 0.44
Batch: 420; loss: 1.56; acc: 0.45
Batch: 440; loss: 1.59; acc: 0.47
Batch: 460; loss: 1.86; acc: 0.33
Batch: 480; loss: 1.39; acc: 0.53
Batch: 500; loss: 1.71; acc: 0.48
Batch: 520; loss: 1.64; acc: 0.42
Batch: 540; loss: 1.49; acc: 0.58
Batch: 560; loss: 1.52; acc: 0.52
Batch: 580; loss: 1.42; acc: 0.61
Batch: 600; loss: 1.38; acc: 0.58
Batch: 620; loss: 1.43; acc: 0.52
Batch: 640; loss: 1.74; acc: 0.45
Batch: 660; loss: 1.54; acc: 0.47
Batch: 680; loss: 1.48; acc: 0.55
Batch: 700; loss: 1.55; acc: 0.52
Batch: 720; loss: 1.69; acc: 0.39
Batch: 740; loss: 1.34; acc: 0.59
Batch: 760; loss: 1.79; acc: 0.31
Batch: 780; loss: 1.58; acc: 0.48
Train Epoch over. train_loss: 1.62; train_accuracy: 0.45 

Batch: 0; loss: 1.45; acc: 0.45
Batch: 20; loss: 1.68; acc: 0.47
Batch: 40; loss: 1.35; acc: 0.59
Batch: 60; loss: 1.31; acc: 0.56
Batch: 80; loss: 1.47; acc: 0.44
Batch: 100; loss: 1.61; acc: 0.52
Batch: 120; loss: 1.63; acc: 0.47
Batch: 140; loss: 1.27; acc: 0.64
Val Epoch over. val_loss: 1.4868718575520121; val_accuracy: 0.48974920382165604 

The current subspace-distance is: 2.471276093274355e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.58; acc: 0.39
Batch: 20; loss: 1.43; acc: 0.56
Batch: 40; loss: 1.47; acc: 0.47
Batch: 60; loss: 1.48; acc: 0.58
Batch: 80; loss: 1.19; acc: 0.55
Batch: 100; loss: 1.54; acc: 0.52
Batch: 120; loss: 1.34; acc: 0.61
Batch: 140; loss: 1.56; acc: 0.52
Batch: 160; loss: 1.5; acc: 0.42
Batch: 180; loss: 1.52; acc: 0.45
Batch: 200; loss: 1.7; acc: 0.45
Batch: 220; loss: 1.78; acc: 0.41
Batch: 240; loss: 1.66; acc: 0.41
Batch: 260; loss: 1.74; acc: 0.47
Batch: 280; loss: 1.51; acc: 0.53
Batch: 300; loss: 1.38; acc: 0.56
Batch: 320; loss: 1.35; acc: 0.53
Batch: 340; loss: 1.47; acc: 0.45
Batch: 360; loss: 1.51; acc: 0.48
Batch: 380; loss: 1.54; acc: 0.52
Batch: 400; loss: 1.5; acc: 0.5
Batch: 420; loss: 1.7; acc: 0.52
Batch: 440; loss: 1.73; acc: 0.44
Batch: 460; loss: 1.46; acc: 0.42
Batch: 480; loss: 1.66; acc: 0.42
Batch: 500; loss: 1.56; acc: 0.47
Batch: 520; loss: 1.66; acc: 0.5
Batch: 540; loss: 1.48; acc: 0.5
Batch: 560; loss: 1.23; acc: 0.58
Batch: 580; loss: 1.57; acc: 0.47
Batch: 600; loss: 1.54; acc: 0.48
Batch: 620; loss: 1.52; acc: 0.52
Batch: 640; loss: 1.34; acc: 0.42
Batch: 660; loss: 1.46; acc: 0.5
Batch: 680; loss: 1.39; acc: 0.62
Batch: 700; loss: 1.46; acc: 0.56
Batch: 720; loss: 1.58; acc: 0.5
Batch: 740; loss: 1.5; acc: 0.47
Batch: 760; loss: 1.69; acc: 0.36
Batch: 780; loss: 1.6; acc: 0.38
Train Epoch over. train_loss: 1.51; train_accuracy: 0.49 

Batch: 0; loss: 1.58; acc: 0.42
Batch: 20; loss: 1.77; acc: 0.41
Batch: 40; loss: 1.38; acc: 0.56
Batch: 60; loss: 1.35; acc: 0.52
Batch: 80; loss: 1.7; acc: 0.45
Batch: 100; loss: 1.62; acc: 0.5
Batch: 120; loss: 1.58; acc: 0.5
Batch: 140; loss: 1.4; acc: 0.53
Val Epoch over. val_loss: 1.5591559144342022; val_accuracy: 0.4677547770700637 

The current subspace-distance is: 3.1287876481655985e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.4; acc: 0.53
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.45; acc: 0.52
Batch: 60; loss: 1.28; acc: 0.55
Batch: 80; loss: 1.58; acc: 0.44
Batch: 100; loss: 1.67; acc: 0.42
Batch: 120; loss: 1.46; acc: 0.56
Batch: 140; loss: 1.39; acc: 0.52
Batch: 160; loss: 1.65; acc: 0.39
Batch: 180; loss: 1.75; acc: 0.41
Batch: 200; loss: 1.83; acc: 0.36
Batch: 220; loss: 1.39; acc: 0.59
Batch: 240; loss: 1.45; acc: 0.47
Batch: 260; loss: 1.39; acc: 0.55
Batch: 280; loss: 1.52; acc: 0.47
Batch: 300; loss: 1.44; acc: 0.44
Batch: 320; loss: 1.39; acc: 0.55
Batch: 340; loss: 1.43; acc: 0.56
Batch: 360; loss: 1.46; acc: 0.56
Batch: 380; loss: 1.6; acc: 0.47
Batch: 400; loss: 1.43; acc: 0.52
Batch: 420; loss: 1.6; acc: 0.47
Batch: 440; loss: 1.47; acc: 0.47
Batch: 460; loss: 1.46; acc: 0.56
Batch: 480; loss: 1.25; acc: 0.56
Batch: 500; loss: 1.54; acc: 0.52
Batch: 520; loss: 1.48; acc: 0.47
Batch: 540; loss: 1.5; acc: 0.53
Batch: 560; loss: 1.45; acc: 0.55
Batch: 580; loss: 1.42; acc: 0.53
Batch: 600; loss: 1.36; acc: 0.53
Batch: 620; loss: 1.38; acc: 0.58
Batch: 640; loss: 1.61; acc: 0.41
Batch: 660; loss: 1.54; acc: 0.45
Batch: 680; loss: 1.44; acc: 0.55
Batch: 700; loss: 1.58; acc: 0.45
Batch: 720; loss: 1.52; acc: 0.48
Batch: 740; loss: 1.62; acc: 0.48
Batch: 760; loss: 1.22; acc: 0.55
Batch: 780; loss: 1.65; acc: 0.47
Train Epoch over. train_loss: 1.48; train_accuracy: 0.5 

Batch: 0; loss: 1.52; acc: 0.48
Batch: 20; loss: 1.86; acc: 0.38
Batch: 40; loss: 1.25; acc: 0.59
Batch: 60; loss: 1.2; acc: 0.62
Batch: 80; loss: 1.4; acc: 0.52
Batch: 100; loss: 1.49; acc: 0.48
Batch: 120; loss: 1.71; acc: 0.48
Batch: 140; loss: 1.42; acc: 0.5
Val Epoch over. val_loss: 1.502247512720193; val_accuracy: 0.4879578025477707 

The current subspace-distance is: 3.578679752536118e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.34; acc: 0.53
Batch: 20; loss: 1.51; acc: 0.52
Batch: 40; loss: 1.28; acc: 0.56
Batch: 60; loss: 1.6; acc: 0.53
Batch: 80; loss: 1.29; acc: 0.56
Batch: 100; loss: 1.6; acc: 0.44
Batch: 120; loss: 1.46; acc: 0.52
Batch: 140; loss: 1.64; acc: 0.44
Batch: 160; loss: 1.38; acc: 0.55
Batch: 180; loss: 1.43; acc: 0.52
Batch: 200; loss: 1.45; acc: 0.52
Batch: 220; loss: 1.25; acc: 0.55
Batch: 240; loss: 1.47; acc: 0.41
Batch: 260; loss: 1.48; acc: 0.56
Batch: 280; loss: 1.62; acc: 0.42
Batch: 300; loss: 1.44; acc: 0.58
Batch: 320; loss: 1.05; acc: 0.72
Batch: 340; loss: 1.52; acc: 0.53
Batch: 360; loss: 1.53; acc: 0.42
Batch: 380; loss: 1.36; acc: 0.47
Batch: 400; loss: 1.54; acc: 0.5
Batch: 420; loss: 1.29; acc: 0.59
Batch: 440; loss: 1.38; acc: 0.52
Batch: 460; loss: 1.33; acc: 0.53
Batch: 480; loss: 1.47; acc: 0.5
Batch: 500; loss: 1.46; acc: 0.58
Batch: 520; loss: 1.34; acc: 0.55
Batch: 540; loss: 1.3; acc: 0.56
Batch: 560; loss: 1.68; acc: 0.38
Batch: 580; loss: 1.62; acc: 0.47
Batch: 600; loss: 1.32; acc: 0.56
Batch: 620; loss: 1.34; acc: 0.58
Batch: 640; loss: 1.41; acc: 0.55
Batch: 660; loss: 1.42; acc: 0.47
Batch: 680; loss: 1.52; acc: 0.53
Batch: 700; loss: 1.44; acc: 0.47
Batch: 720; loss: 1.44; acc: 0.48
Batch: 740; loss: 1.58; acc: 0.53
Batch: 760; loss: 1.41; acc: 0.55
Batch: 780; loss: 1.51; acc: 0.38
Train Epoch over. train_loss: 1.45; train_accuracy: 0.51 

Batch: 0; loss: 1.33; acc: 0.55
Batch: 20; loss: 1.63; acc: 0.48
Batch: 40; loss: 1.23; acc: 0.58
Batch: 60; loss: 1.14; acc: 0.52
Batch: 80; loss: 1.35; acc: 0.56
Batch: 100; loss: 1.44; acc: 0.56
Batch: 120; loss: 1.61; acc: 0.5
Batch: 140; loss: 1.16; acc: 0.61
Val Epoch over. val_loss: 1.428098568870763; val_accuracy: 0.5221934713375797 

The current subspace-distance is: 3.988993194070645e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.58; acc: 0.47
Batch: 20; loss: 1.65; acc: 0.41
Batch: 40; loss: 1.56; acc: 0.48
Batch: 60; loss: 1.47; acc: 0.48
Batch: 80; loss: 1.48; acc: 0.5
Batch: 100; loss: 1.81; acc: 0.42
Batch: 120; loss: 1.51; acc: 0.5
Batch: 140; loss: 1.52; acc: 0.5
Batch: 160; loss: 1.47; acc: 0.47
Batch: 180; loss: 1.61; acc: 0.47
Batch: 200; loss: 1.43; acc: 0.48
Batch: 220; loss: 1.59; acc: 0.39
Batch: 240; loss: 1.51; acc: 0.44
Batch: 260; loss: 1.48; acc: 0.48
Batch: 280; loss: 1.08; acc: 0.62
Batch: 300; loss: 1.52; acc: 0.53
Batch: 320; loss: 1.72; acc: 0.44
Batch: 340; loss: 1.73; acc: 0.36
Batch: 360; loss: 1.41; acc: 0.47
Batch: 380; loss: 1.62; acc: 0.42
Batch: 400; loss: 1.4; acc: 0.56
Batch: 420; loss: 1.52; acc: 0.42
Batch: 440; loss: 1.6; acc: 0.47
Batch: 460; loss: 1.23; acc: 0.62
Batch: 480; loss: 1.53; acc: 0.52
Batch: 500; loss: 1.41; acc: 0.48
Batch: 520; loss: 1.6; acc: 0.55
Batch: 540; loss: 1.4; acc: 0.52
Batch: 560; loss: 1.55; acc: 0.47
Batch: 580; loss: 1.51; acc: 0.53
Batch: 600; loss: 1.58; acc: 0.48
Batch: 620; loss: 1.44; acc: 0.52
Batch: 640; loss: 1.54; acc: 0.47
Batch: 660; loss: 1.41; acc: 0.56
Batch: 680; loss: 1.28; acc: 0.62
Batch: 700; loss: 1.33; acc: 0.55
Batch: 720; loss: 1.41; acc: 0.47
Batch: 740; loss: 1.42; acc: 0.48
Batch: 760; loss: 1.71; acc: 0.41
Batch: 780; loss: 1.45; acc: 0.47
Train Epoch over. train_loss: 1.45; train_accuracy: 0.51 

Batch: 0; loss: 1.39; acc: 0.53
Batch: 20; loss: 1.59; acc: 0.5
Batch: 40; loss: 1.13; acc: 0.62
Batch: 60; loss: 1.09; acc: 0.58
Batch: 80; loss: 1.24; acc: 0.58
Batch: 100; loss: 1.29; acc: 0.61
Batch: 120; loss: 1.59; acc: 0.5
Batch: 140; loss: 1.19; acc: 0.58
Val Epoch over. val_loss: 1.3822211535872928; val_accuracy: 0.5347332802547771 

The current subspace-distance is: 4.639543840312399e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.41; acc: 0.55
Batch: 20; loss: 1.25; acc: 0.48
Batch: 40; loss: 1.42; acc: 0.47
Batch: 60; loss: 1.62; acc: 0.41
Batch: 80; loss: 1.56; acc: 0.42
Batch: 100; loss: 1.52; acc: 0.45
Batch: 120; loss: 1.47; acc: 0.5
Batch: 140; loss: 1.53; acc: 0.48
Batch: 160; loss: 1.47; acc: 0.47
Batch: 180; loss: 1.44; acc: 0.52
Batch: 200; loss: 1.39; acc: 0.55
Batch: 220; loss: 1.36; acc: 0.58
Batch: 240; loss: 1.61; acc: 0.42
Batch: 260; loss: 1.84; acc: 0.39
Batch: 280; loss: 1.4; acc: 0.52
Batch: 300; loss: 1.47; acc: 0.48
Batch: 320; loss: 1.32; acc: 0.59
Batch: 340; loss: 1.58; acc: 0.44
Batch: 360; loss: 1.31; acc: 0.58
Batch: 380; loss: 1.8; acc: 0.38
Batch: 400; loss: 1.79; acc: 0.42
Batch: 420; loss: 1.6; acc: 0.39
Batch: 440; loss: 1.67; acc: 0.41
Batch: 460; loss: 1.32; acc: 0.52
Batch: 480; loss: 1.28; acc: 0.59
Batch: 500; loss: 1.54; acc: 0.52
Batch: 520; loss: 1.57; acc: 0.42
Batch: 540; loss: 1.5; acc: 0.5
Batch: 560; loss: 1.21; acc: 0.64
Batch: 580; loss: 0.94; acc: 0.73
Batch: 600; loss: 1.48; acc: 0.53
Batch: 620; loss: 1.36; acc: 0.59
Batch: 640; loss: 1.53; acc: 0.47
Batch: 660; loss: 1.45; acc: 0.47
Batch: 680; loss: 1.42; acc: 0.55
Batch: 700; loss: 1.55; acc: 0.45
Batch: 720; loss: 1.42; acc: 0.44
Batch: 740; loss: 1.68; acc: 0.53
Batch: 760; loss: 1.67; acc: 0.5
Batch: 780; loss: 1.44; acc: 0.47
Train Epoch over. train_loss: 1.45; train_accuracy: 0.51 

Batch: 0; loss: 1.58; acc: 0.38
Batch: 20; loss: 1.63; acc: 0.47
Batch: 40; loss: 1.35; acc: 0.52
Batch: 60; loss: 1.24; acc: 0.53
Batch: 80; loss: 1.57; acc: 0.41
Batch: 100; loss: 1.45; acc: 0.53
Batch: 120; loss: 1.74; acc: 0.34
Batch: 140; loss: 1.23; acc: 0.56
Val Epoch over. val_loss: 1.5310119382894722; val_accuracy: 0.45591162420382164 

The current subspace-distance is: 5.186208363738842e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.41; acc: 0.5
Batch: 20; loss: 1.3; acc: 0.5
Batch: 40; loss: 1.39; acc: 0.55
Batch: 60; loss: 1.58; acc: 0.52
Batch: 80; loss: 1.37; acc: 0.44
Batch: 100; loss: 1.56; acc: 0.41
Batch: 120; loss: 1.57; acc: 0.47
Batch: 140; loss: 1.43; acc: 0.55
Batch: 160; loss: 1.36; acc: 0.61
Batch: 180; loss: 1.42; acc: 0.55
Batch: 200; loss: 1.34; acc: 0.55
Batch: 220; loss: 1.44; acc: 0.53
Batch: 240; loss: 1.47; acc: 0.48
Batch: 260; loss: 1.48; acc: 0.47
Batch: 280; loss: 1.38; acc: 0.55
Batch: 300; loss: 1.21; acc: 0.58
Batch: 320; loss: 1.44; acc: 0.56
Batch: 340; loss: 1.41; acc: 0.55
Batch: 360; loss: 1.42; acc: 0.52
Batch: 380; loss: 1.65; acc: 0.5
Batch: 400; loss: 1.49; acc: 0.47
Batch: 420; loss: 1.63; acc: 0.42
Batch: 440; loss: 1.66; acc: 0.39
Batch: 460; loss: 1.36; acc: 0.59
Batch: 480; loss: 1.52; acc: 0.42
Batch: 500; loss: 1.57; acc: 0.47
Batch: 520; loss: 1.3; acc: 0.61
Batch: 540; loss: 1.44; acc: 0.48
Batch: 560; loss: 1.6; acc: 0.41
Batch: 580; loss: 1.61; acc: 0.53
Batch: 600; loss: 1.42; acc: 0.5
Batch: 620; loss: 1.37; acc: 0.58
Batch: 640; loss: 1.5; acc: 0.48
Batch: 660; loss: 1.32; acc: 0.59
Batch: 680; loss: 1.32; acc: 0.61
Batch: 700; loss: 1.43; acc: 0.53
Batch: 720; loss: 1.24; acc: 0.48
Batch: 740; loss: 1.31; acc: 0.53
Batch: 760; loss: 1.24; acc: 0.61
Batch: 780; loss: 1.11; acc: 0.66
Train Epoch over. train_loss: 1.45; train_accuracy: 0.51 

Batch: 0; loss: 1.39; acc: 0.53
Batch: 20; loss: 1.58; acc: 0.5
Batch: 40; loss: 1.16; acc: 0.61
Batch: 60; loss: 1.13; acc: 0.59
Batch: 80; loss: 1.26; acc: 0.59
Batch: 100; loss: 1.32; acc: 0.58
Batch: 120; loss: 1.63; acc: 0.48
Batch: 140; loss: 1.16; acc: 0.53
Val Epoch over. val_loss: 1.37451177759535; val_accuracy: 0.5401074840764332 

The current subspace-distance is: 5.3559015213977545e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.42; acc: 0.55
Batch: 20; loss: 1.45; acc: 0.5
Batch: 40; loss: 1.33; acc: 0.56
Batch: 60; loss: 1.57; acc: 0.45
Batch: 80; loss: 1.49; acc: 0.44
Batch: 100; loss: 1.38; acc: 0.55
Batch: 120; loss: 1.12; acc: 0.59
Batch: 140; loss: 1.23; acc: 0.55
Batch: 160; loss: 1.41; acc: 0.55
Batch: 180; loss: 1.47; acc: 0.56
Batch: 200; loss: 1.4; acc: 0.59
Batch: 220; loss: 1.39; acc: 0.5
Batch: 240; loss: 1.45; acc: 0.59
Batch: 260; loss: 1.2; acc: 0.61
Batch: 280; loss: 1.67; acc: 0.39
Batch: 300; loss: 1.48; acc: 0.52
Batch: 320; loss: 1.41; acc: 0.5
Batch: 340; loss: 1.2; acc: 0.55
Batch: 360; loss: 1.38; acc: 0.55
Batch: 380; loss: 1.54; acc: 0.45
Batch: 400; loss: 1.82; acc: 0.44
Batch: 420; loss: 1.52; acc: 0.52
Batch: 440; loss: 1.63; acc: 0.48
Batch: 460; loss: 1.48; acc: 0.45
Batch: 480; loss: 1.26; acc: 0.53
Batch: 500; loss: 1.47; acc: 0.52
Batch: 520; loss: 1.4; acc: 0.58
Batch: 540; loss: 1.3; acc: 0.48
Batch: 560; loss: 1.53; acc: 0.47
Batch: 580; loss: 1.56; acc: 0.52
Batch: 600; loss: 1.46; acc: 0.52
Batch: 620; loss: 1.4; acc: 0.53
Batch: 640; loss: 1.2; acc: 0.67
Batch: 660; loss: 1.2; acc: 0.56
Batch: 680; loss: 1.57; acc: 0.48
Batch: 700; loss: 1.5; acc: 0.48
Batch: 720; loss: 1.53; acc: 0.55
Batch: 740; loss: 1.24; acc: 0.61
Batch: 760; loss: 1.55; acc: 0.47
Batch: 780; loss: 1.4; acc: 0.5
Train Epoch over. train_loss: 1.44; train_accuracy: 0.51 

Batch: 0; loss: 1.41; acc: 0.53
Batch: 20; loss: 1.74; acc: 0.52
Batch: 40; loss: 1.18; acc: 0.56
Batch: 60; loss: 1.13; acc: 0.59
Batch: 80; loss: 1.27; acc: 0.61
Batch: 100; loss: 1.37; acc: 0.56
Batch: 120; loss: 1.68; acc: 0.44
Batch: 140; loss: 1.28; acc: 0.52
Val Epoch over. val_loss: 1.4288796869812497; val_accuracy: 0.5173168789808917 

The current subspace-distance is: 5.843295366503298e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.23; acc: 0.67
Batch: 20; loss: 1.17; acc: 0.64
Batch: 40; loss: 1.57; acc: 0.41
Batch: 60; loss: 1.4; acc: 0.5
Batch: 80; loss: 1.66; acc: 0.48
Batch: 100; loss: 1.69; acc: 0.44
Batch: 120; loss: 1.33; acc: 0.53
Batch: 140; loss: 1.39; acc: 0.52
Batch: 160; loss: 1.76; acc: 0.42
Batch: 180; loss: 1.41; acc: 0.59
Batch: 200; loss: 1.27; acc: 0.53
Batch: 220; loss: 1.14; acc: 0.56
Batch: 240; loss: 1.35; acc: 0.48
Batch: 260; loss: 1.4; acc: 0.45
Batch: 280; loss: 1.42; acc: 0.48
Batch: 300; loss: 1.64; acc: 0.48
Batch: 320; loss: 1.36; acc: 0.53
Batch: 340; loss: 1.48; acc: 0.42
Batch: 360; loss: 1.44; acc: 0.52
Batch: 380; loss: 1.42; acc: 0.52
Batch: 400; loss: 1.35; acc: 0.55
Batch: 420; loss: 1.33; acc: 0.58
Batch: 440; loss: 1.49; acc: 0.48
Batch: 460; loss: 1.69; acc: 0.47
Batch: 480; loss: 1.69; acc: 0.42
Batch: 500; loss: 1.36; acc: 0.58
Batch: 520; loss: 1.86; acc: 0.41
Batch: 540; loss: 1.16; acc: 0.67
Batch: 560; loss: 1.19; acc: 0.58
Batch: 580; loss: 1.35; acc: 0.56
Batch: 600; loss: 1.41; acc: 0.5
Batch: 620; loss: 1.44; acc: 0.5
Batch: 640; loss: 1.36; acc: 0.55
Batch: 660; loss: 1.38; acc: 0.55
Batch: 680; loss: 1.51; acc: 0.5
Batch: 700; loss: 1.23; acc: 0.62
Batch: 720; loss: 1.55; acc: 0.42
Batch: 740; loss: 1.25; acc: 0.61
Batch: 760; loss: 1.32; acc: 0.53
Batch: 780; loss: 1.2; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.41; acc: 0.53
Batch: 20; loss: 1.57; acc: 0.47
Batch: 40; loss: 1.17; acc: 0.59
Batch: 60; loss: 1.13; acc: 0.55
Batch: 80; loss: 1.23; acc: 0.62
Batch: 100; loss: 1.36; acc: 0.58
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.16; acc: 0.61
Val Epoch over. val_loss: 1.375000992398353; val_accuracy: 0.5406050955414012 

The current subspace-distance is: 6.128376844571903e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.29; acc: 0.56
Batch: 20; loss: 1.36; acc: 0.52
Batch: 40; loss: 1.18; acc: 0.59
Batch: 60; loss: 1.07; acc: 0.64
Batch: 80; loss: 1.51; acc: 0.5
Batch: 100; loss: 1.26; acc: 0.62
Batch: 120; loss: 1.24; acc: 0.59
Batch: 140; loss: 1.5; acc: 0.47
Batch: 160; loss: 1.37; acc: 0.52
Batch: 180; loss: 1.28; acc: 0.62
Batch: 200; loss: 1.25; acc: 0.5
Batch: 220; loss: 1.52; acc: 0.47
Batch: 240; loss: 1.25; acc: 0.62
Batch: 260; loss: 1.5; acc: 0.45
Batch: 280; loss: 1.54; acc: 0.55
Batch: 300; loss: 1.56; acc: 0.47
Batch: 320; loss: 1.3; acc: 0.47
Batch: 340; loss: 1.53; acc: 0.53
Batch: 360; loss: 1.46; acc: 0.52
Batch: 380; loss: 1.54; acc: 0.56
Batch: 400; loss: 1.48; acc: 0.48
Batch: 420; loss: 1.37; acc: 0.59
Batch: 440; loss: 1.27; acc: 0.58
Batch: 460; loss: 1.39; acc: 0.48
Batch: 480; loss: 1.31; acc: 0.64
Batch: 500; loss: 1.41; acc: 0.48
Batch: 520; loss: 1.33; acc: 0.48
Batch: 540; loss: 1.29; acc: 0.56
Batch: 560; loss: 1.39; acc: 0.47
Batch: 580; loss: 1.51; acc: 0.38
Batch: 600; loss: 1.48; acc: 0.55
Batch: 620; loss: 1.21; acc: 0.56
Batch: 640; loss: 1.47; acc: 0.47
Batch: 660; loss: 1.26; acc: 0.59
Batch: 680; loss: 1.58; acc: 0.53
Batch: 700; loss: 1.42; acc: 0.58
Batch: 720; loss: 1.55; acc: 0.5
Batch: 740; loss: 1.19; acc: 0.59
Batch: 760; loss: 1.63; acc: 0.45
Batch: 780; loss: 1.27; acc: 0.53
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.61; acc: 0.48
Batch: 40; loss: 1.13; acc: 0.66
Batch: 60; loss: 1.08; acc: 0.62
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.18; acc: 0.58
Val Epoch over. val_loss: 1.3671589619035174; val_accuracy: 0.5490644904458599 

The current subspace-distance is: 6.283810216700658e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.37; acc: 0.55
Batch: 20; loss: 1.33; acc: 0.52
Batch: 40; loss: 1.56; acc: 0.48
Batch: 60; loss: 1.42; acc: 0.58
Batch: 80; loss: 1.34; acc: 0.55
Batch: 100; loss: 1.46; acc: 0.44
Batch: 120; loss: 1.2; acc: 0.55
Batch: 140; loss: 1.51; acc: 0.52
Batch: 160; loss: 1.44; acc: 0.47
Batch: 180; loss: 1.44; acc: 0.56
Batch: 200; loss: 1.31; acc: 0.56
Batch: 220; loss: 1.39; acc: 0.52
Batch: 240; loss: 1.39; acc: 0.48
Batch: 260; loss: 1.26; acc: 0.58
Batch: 280; loss: 1.31; acc: 0.55
Batch: 300; loss: 1.2; acc: 0.59
Batch: 320; loss: 1.27; acc: 0.59
Batch: 340; loss: 1.29; acc: 0.55
Batch: 360; loss: 1.41; acc: 0.44
Batch: 380; loss: 1.45; acc: 0.52
Batch: 400; loss: 1.36; acc: 0.58
Batch: 420; loss: 1.49; acc: 0.45
Batch: 440; loss: 1.45; acc: 0.53
Batch: 460; loss: 1.27; acc: 0.55
Batch: 480; loss: 1.08; acc: 0.67
Batch: 500; loss: 1.6; acc: 0.44
Batch: 520; loss: 1.17; acc: 0.64
Batch: 540; loss: 1.62; acc: 0.58
Batch: 560; loss: 1.49; acc: 0.42
Batch: 580; loss: 1.55; acc: 0.5
Batch: 600; loss: 1.55; acc: 0.52
Batch: 620; loss: 1.42; acc: 0.53
Batch: 640; loss: 1.2; acc: 0.53
Batch: 660; loss: 1.58; acc: 0.45
Batch: 680; loss: 1.6; acc: 0.53
Batch: 700; loss: 1.24; acc: 0.59
Batch: 720; loss: 1.31; acc: 0.61
Batch: 740; loss: 1.33; acc: 0.55
Batch: 760; loss: 1.33; acc: 0.61
Batch: 780; loss: 1.36; acc: 0.61
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.38; acc: 0.56
Batch: 20; loss: 1.6; acc: 0.48
Batch: 40; loss: 1.14; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.59
Batch: 100; loss: 1.34; acc: 0.64
Batch: 120; loss: 1.67; acc: 0.48
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.3718295932575395; val_accuracy: 0.541202229299363 

The current subspace-distance is: 6.710545858368278e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.27; acc: 0.5
Batch: 20; loss: 1.27; acc: 0.61
Batch: 40; loss: 1.3; acc: 0.59
Batch: 60; loss: 1.58; acc: 0.5
Batch: 80; loss: 1.26; acc: 0.61
Batch: 100; loss: 1.31; acc: 0.55
Batch: 120; loss: 1.13; acc: 0.64
Batch: 140; loss: 1.26; acc: 0.56
Batch: 160; loss: 1.42; acc: 0.5
Batch: 180; loss: 1.39; acc: 0.53
Batch: 200; loss: 1.6; acc: 0.42
Batch: 220; loss: 1.41; acc: 0.56
Batch: 240; loss: 1.51; acc: 0.5
Batch: 260; loss: 1.3; acc: 0.61
Batch: 280; loss: 1.19; acc: 0.64
Batch: 300; loss: 1.5; acc: 0.55
Batch: 320; loss: 1.37; acc: 0.48
Batch: 340; loss: 1.66; acc: 0.48
Batch: 360; loss: 1.31; acc: 0.52
Batch: 380; loss: 1.38; acc: 0.55
Batch: 400; loss: 1.29; acc: 0.55
Batch: 420; loss: 1.46; acc: 0.5
Batch: 440; loss: 1.36; acc: 0.62
Batch: 460; loss: 1.45; acc: 0.5
Batch: 480; loss: 1.64; acc: 0.5
Batch: 500; loss: 1.35; acc: 0.59
Batch: 520; loss: 1.3; acc: 0.56
Batch: 540; loss: 1.31; acc: 0.58
Batch: 560; loss: 1.44; acc: 0.52
Batch: 580; loss: 1.59; acc: 0.47
Batch: 600; loss: 1.28; acc: 0.59
Batch: 620; loss: 1.39; acc: 0.48
Batch: 640; loss: 1.45; acc: 0.5
Batch: 660; loss: 1.41; acc: 0.48
Batch: 680; loss: 1.47; acc: 0.45
Batch: 700; loss: 1.55; acc: 0.38
Batch: 720; loss: 1.31; acc: 0.64
Batch: 740; loss: 1.38; acc: 0.56
Batch: 760; loss: 1.54; acc: 0.48
Batch: 780; loss: 1.43; acc: 0.5
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.56; acc: 0.53
Batch: 40; loss: 1.14; acc: 0.64
Batch: 60; loss: 1.12; acc: 0.61
Batch: 80; loss: 1.21; acc: 0.64
Batch: 100; loss: 1.35; acc: 0.61
Batch: 120; loss: 1.68; acc: 0.52
Batch: 140; loss: 1.12; acc: 0.64
Val Epoch over. val_loss: 1.3594097479893144; val_accuracy: 0.5503582802547771 

The current subspace-distance is: 6.959804886719212e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.69; acc: 0.44
Batch: 20; loss: 1.79; acc: 0.45
Batch: 40; loss: 1.31; acc: 0.48
Batch: 60; loss: 1.25; acc: 0.62
Batch: 80; loss: 1.37; acc: 0.58
Batch: 100; loss: 1.27; acc: 0.53
Batch: 120; loss: 1.3; acc: 0.55
Batch: 140; loss: 1.42; acc: 0.55
Batch: 160; loss: 1.46; acc: 0.48
Batch: 180; loss: 1.32; acc: 0.48
Batch: 200; loss: 1.48; acc: 0.47
Batch: 220; loss: 1.35; acc: 0.5
Batch: 240; loss: 1.34; acc: 0.53
Batch: 260; loss: 1.55; acc: 0.47
Batch: 280; loss: 1.23; acc: 0.61
Batch: 300; loss: 1.4; acc: 0.47
Batch: 320; loss: 1.37; acc: 0.48
Batch: 340; loss: 1.4; acc: 0.62
Batch: 360; loss: 1.34; acc: 0.52
Batch: 380; loss: 1.26; acc: 0.64
Batch: 400; loss: 1.6; acc: 0.52
Batch: 420; loss: 1.41; acc: 0.45
Batch: 440; loss: 1.43; acc: 0.55
Batch: 460; loss: 1.43; acc: 0.58
Batch: 480; loss: 1.6; acc: 0.44
Batch: 500; loss: 1.55; acc: 0.48
Batch: 520; loss: 1.51; acc: 0.48
Batch: 540; loss: 1.27; acc: 0.59
Batch: 560; loss: 1.61; acc: 0.45
Batch: 580; loss: 1.33; acc: 0.55
Batch: 600; loss: 1.01; acc: 0.7
Batch: 620; loss: 1.74; acc: 0.38
Batch: 640; loss: 1.18; acc: 0.59
Batch: 660; loss: 1.22; acc: 0.53
Batch: 680; loss: 1.44; acc: 0.53
Batch: 700; loss: 1.43; acc: 0.55
Batch: 720; loss: 1.32; acc: 0.61
Batch: 740; loss: 1.38; acc: 0.53
Batch: 760; loss: 1.4; acc: 0.55
Batch: 780; loss: 1.51; acc: 0.55
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.48; acc: 0.5
Batch: 20; loss: 1.65; acc: 0.48
Batch: 40; loss: 1.17; acc: 0.59
Batch: 60; loss: 1.16; acc: 0.61
Batch: 80; loss: 1.43; acc: 0.5
Batch: 100; loss: 1.35; acc: 0.55
Batch: 120; loss: 1.68; acc: 0.47
Batch: 140; loss: 1.17; acc: 0.59
Val Epoch over. val_loss: 1.4306785096028807; val_accuracy: 0.5138335987261147 

The current subspace-distance is: 7.222149724839255e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.39; acc: 0.53
Batch: 20; loss: 1.39; acc: 0.53
Batch: 40; loss: 1.43; acc: 0.53
Batch: 60; loss: 1.48; acc: 0.48
Batch: 80; loss: 1.45; acc: 0.5
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.74; acc: 0.33
Batch: 140; loss: 1.33; acc: 0.59
Batch: 160; loss: 1.42; acc: 0.53
Batch: 180; loss: 1.38; acc: 0.53
Batch: 200; loss: 1.38; acc: 0.48
Batch: 220; loss: 1.14; acc: 0.59
Batch: 240; loss: 1.41; acc: 0.52
Batch: 260; loss: 1.49; acc: 0.47
Batch: 280; loss: 1.17; acc: 0.66
Batch: 300; loss: 1.37; acc: 0.59
Batch: 320; loss: 1.42; acc: 0.53
Batch: 340; loss: 1.37; acc: 0.53
Batch: 360; loss: 1.31; acc: 0.58
Batch: 380; loss: 1.33; acc: 0.55
Batch: 400; loss: 1.63; acc: 0.44
Batch: 420; loss: 1.38; acc: 0.47
Batch: 440; loss: 1.31; acc: 0.52
Batch: 460; loss: 1.29; acc: 0.52
Batch: 480; loss: 1.52; acc: 0.45
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.43; acc: 0.52
Batch: 540; loss: 1.18; acc: 0.58
Batch: 560; loss: 1.34; acc: 0.5
Batch: 580; loss: 1.59; acc: 0.42
Batch: 600; loss: 1.31; acc: 0.58
Batch: 620; loss: 1.58; acc: 0.48
Batch: 640; loss: 1.51; acc: 0.47
Batch: 660; loss: 1.43; acc: 0.48
Batch: 680; loss: 1.31; acc: 0.62
Batch: 700; loss: 1.56; acc: 0.45
Batch: 720; loss: 1.36; acc: 0.55
Batch: 740; loss: 1.47; acc: 0.48
Batch: 760; loss: 1.6; acc: 0.47
Batch: 780; loss: 1.38; acc: 0.52
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.49; acc: 0.47
Batch: 20; loss: 1.57; acc: 0.47
Batch: 40; loss: 1.22; acc: 0.61
Batch: 60; loss: 1.18; acc: 0.55
Batch: 80; loss: 1.3; acc: 0.59
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.76; acc: 0.53
Batch: 140; loss: 1.15; acc: 0.64
Val Epoch over. val_loss: 1.4083578290453382; val_accuracy: 0.5206011146496815 

The current subspace-distance is: 7.54168868297711e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.65; acc: 0.44
Batch: 40; loss: 1.43; acc: 0.52
Batch: 60; loss: 1.32; acc: 0.56
Batch: 80; loss: 1.4; acc: 0.5
Batch: 100; loss: 1.64; acc: 0.42
Batch: 120; loss: 1.4; acc: 0.5
Batch: 140; loss: 1.57; acc: 0.47
Batch: 160; loss: 1.61; acc: 0.53
Batch: 180; loss: 1.48; acc: 0.45
Batch: 200; loss: 1.36; acc: 0.48
Batch: 220; loss: 1.72; acc: 0.47
Batch: 240; loss: 1.53; acc: 0.58
Batch: 260; loss: 1.71; acc: 0.47
Batch: 280; loss: 1.61; acc: 0.47
Batch: 300; loss: 1.24; acc: 0.59
Batch: 320; loss: 1.48; acc: 0.47
Batch: 340; loss: 1.21; acc: 0.58
Batch: 360; loss: 1.39; acc: 0.56
Batch: 380; loss: 1.39; acc: 0.48
Batch: 400; loss: 1.31; acc: 0.56
Batch: 420; loss: 1.54; acc: 0.48
Batch: 440; loss: 1.36; acc: 0.53
Batch: 460; loss: 1.4; acc: 0.56
Batch: 480; loss: 1.32; acc: 0.56
Batch: 500; loss: 1.23; acc: 0.48
Batch: 520; loss: 1.35; acc: 0.55
Batch: 540; loss: 1.37; acc: 0.53
Batch: 560; loss: 1.75; acc: 0.36
Batch: 580; loss: 1.31; acc: 0.58
Batch: 600; loss: 1.48; acc: 0.48
Batch: 620; loss: 1.4; acc: 0.5
Batch: 640; loss: 1.38; acc: 0.53
Batch: 660; loss: 1.44; acc: 0.55
Batch: 680; loss: 1.46; acc: 0.56
Batch: 700; loss: 1.31; acc: 0.61
Batch: 720; loss: 1.65; acc: 0.38
Batch: 740; loss: 1.35; acc: 0.56
Batch: 760; loss: 1.31; acc: 0.56
Batch: 780; loss: 1.42; acc: 0.56
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.39; acc: 0.5
Batch: 20; loss: 1.67; acc: 0.42
Batch: 40; loss: 1.14; acc: 0.64
Batch: 60; loss: 1.13; acc: 0.62
Batch: 80; loss: 1.28; acc: 0.58
Batch: 100; loss: 1.35; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.52
Batch: 140; loss: 1.24; acc: 0.55
Val Epoch over. val_loss: 1.4236393764520148; val_accuracy: 0.5173168789808917 

The current subspace-distance is: 7.47443555155769e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.53; acc: 0.5
Batch: 20; loss: 1.13; acc: 0.69
Batch: 40; loss: 1.4; acc: 0.53
Batch: 60; loss: 1.38; acc: 0.58
Batch: 80; loss: 1.4; acc: 0.52
Batch: 100; loss: 1.48; acc: 0.48
Batch: 120; loss: 1.46; acc: 0.53
Batch: 140; loss: 1.33; acc: 0.53
Batch: 160; loss: 1.46; acc: 0.53
Batch: 180; loss: 1.55; acc: 0.42
Batch: 200; loss: 1.5; acc: 0.52
Batch: 220; loss: 1.18; acc: 0.66
Batch: 240; loss: 1.78; acc: 0.44
Batch: 260; loss: 1.58; acc: 0.41
Batch: 280; loss: 1.76; acc: 0.42
Batch: 300; loss: 1.45; acc: 0.5
Batch: 320; loss: 1.51; acc: 0.5
Batch: 340; loss: 1.2; acc: 0.59
Batch: 360; loss: 1.45; acc: 0.53
Batch: 380; loss: 1.28; acc: 0.59
Batch: 400; loss: 1.42; acc: 0.52
Batch: 420; loss: 1.52; acc: 0.42
Batch: 440; loss: 1.26; acc: 0.56
Batch: 460; loss: 1.42; acc: 0.59
Batch: 480; loss: 1.51; acc: 0.52
Batch: 500; loss: 1.38; acc: 0.52
Batch: 520; loss: 1.6; acc: 0.44
Batch: 540; loss: 1.27; acc: 0.55
Batch: 560; loss: 1.55; acc: 0.45
Batch: 580; loss: 1.56; acc: 0.48
Batch: 600; loss: 1.22; acc: 0.58
Batch: 620; loss: 1.46; acc: 0.48
Batch: 640; loss: 1.31; acc: 0.55
Batch: 660; loss: 1.44; acc: 0.53
Batch: 680; loss: 1.52; acc: 0.47
Batch: 700; loss: 1.46; acc: 0.48
Batch: 720; loss: 1.3; acc: 0.56
Batch: 740; loss: 1.39; acc: 0.48
Batch: 760; loss: 1.51; acc: 0.5
Batch: 780; loss: 1.43; acc: 0.52
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.33; acc: 0.58
Batch: 20; loss: 1.54; acc: 0.52
Batch: 40; loss: 1.14; acc: 0.62
Batch: 60; loss: 1.08; acc: 0.58
Batch: 80; loss: 1.23; acc: 0.62
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.63; acc: 0.52
Batch: 140; loss: 1.11; acc: 0.61
Val Epoch over. val_loss: 1.3589719849027646; val_accuracy: 0.5471735668789809 

The current subspace-distance is: 7.64525102567859e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.52; acc: 0.53
Batch: 20; loss: 1.37; acc: 0.44
Batch: 40; loss: 1.58; acc: 0.47
Batch: 60; loss: 1.57; acc: 0.48
Batch: 80; loss: 1.4; acc: 0.56
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.54; acc: 0.5
Batch: 140; loss: 1.46; acc: 0.52
Batch: 160; loss: 1.55; acc: 0.52
Batch: 180; loss: 1.38; acc: 0.61
Batch: 200; loss: 1.21; acc: 0.58
Batch: 220; loss: 1.4; acc: 0.55
Batch: 240; loss: 1.4; acc: 0.48
Batch: 260; loss: 1.45; acc: 0.45
Batch: 280; loss: 1.49; acc: 0.58
Batch: 300; loss: 1.3; acc: 0.61
Batch: 320; loss: 1.46; acc: 0.48
Batch: 340; loss: 1.62; acc: 0.42
Batch: 360; loss: 1.68; acc: 0.44
Batch: 380; loss: 1.31; acc: 0.62
Batch: 400; loss: 1.64; acc: 0.42
Batch: 420; loss: 1.57; acc: 0.48
Batch: 440; loss: 1.38; acc: 0.48
Batch: 460; loss: 1.35; acc: 0.52
Batch: 480; loss: 1.32; acc: 0.48
Batch: 500; loss: 1.25; acc: 0.61
Batch: 520; loss: 1.45; acc: 0.53
Batch: 540; loss: 1.61; acc: 0.41
Batch: 560; loss: 1.31; acc: 0.5
Batch: 580; loss: 1.41; acc: 0.5
Batch: 600; loss: 1.35; acc: 0.56
Batch: 620; loss: 1.32; acc: 0.52
Batch: 640; loss: 1.44; acc: 0.55
Batch: 660; loss: 1.62; acc: 0.47
Batch: 680; loss: 1.41; acc: 0.52
Batch: 700; loss: 1.42; acc: 0.55
Batch: 720; loss: 1.54; acc: 0.48
Batch: 740; loss: 1.29; acc: 0.53
Batch: 760; loss: 1.52; acc: 0.5
Batch: 780; loss: 1.26; acc: 0.62
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.34; acc: 0.58
Batch: 20; loss: 1.54; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.64
Batch: 60; loss: 1.07; acc: 0.58
Batch: 80; loss: 1.25; acc: 0.61
Batch: 100; loss: 1.31; acc: 0.62
Batch: 120; loss: 1.6; acc: 0.5
Batch: 140; loss: 1.12; acc: 0.62
Val Epoch over. val_loss: 1.3602120079052675; val_accuracy: 0.5420979299363057 

The current subspace-distance is: 7.803134940331802e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.45; acc: 0.5
Batch: 20; loss: 1.38; acc: 0.53
Batch: 40; loss: 1.25; acc: 0.64
Batch: 60; loss: 1.47; acc: 0.58
Batch: 80; loss: 1.62; acc: 0.42
Batch: 100; loss: 1.38; acc: 0.5
Batch: 120; loss: 1.5; acc: 0.5
Batch: 140; loss: 1.25; acc: 0.61
Batch: 160; loss: 1.21; acc: 0.56
Batch: 180; loss: 1.4; acc: 0.48
Batch: 200; loss: 1.23; acc: 0.61
Batch: 220; loss: 1.27; acc: 0.55
Batch: 240; loss: 1.43; acc: 0.53
Batch: 260; loss: 1.3; acc: 0.55
Batch: 280; loss: 1.08; acc: 0.62
Batch: 300; loss: 1.37; acc: 0.52
Batch: 320; loss: 1.25; acc: 0.56
Batch: 340; loss: 1.48; acc: 0.52
Batch: 360; loss: 1.55; acc: 0.44
Batch: 380; loss: 1.34; acc: 0.53
Batch: 400; loss: 1.31; acc: 0.56
Batch: 420; loss: 1.43; acc: 0.59
Batch: 440; loss: 1.4; acc: 0.56
Batch: 460; loss: 1.22; acc: 0.59
Batch: 480; loss: 1.22; acc: 0.55
Batch: 500; loss: 1.26; acc: 0.55
Batch: 520; loss: 1.27; acc: 0.55
Batch: 540; loss: 1.48; acc: 0.55
Batch: 560; loss: 1.52; acc: 0.48
Batch: 580; loss: 1.42; acc: 0.52
Batch: 600; loss: 1.41; acc: 0.5
Batch: 620; loss: 1.34; acc: 0.61
Batch: 640; loss: 1.42; acc: 0.55
Batch: 660; loss: 1.17; acc: 0.58
Batch: 680; loss: 1.51; acc: 0.48
Batch: 700; loss: 1.49; acc: 0.48
Batch: 720; loss: 1.57; acc: 0.45
Batch: 740; loss: 1.32; acc: 0.59
Batch: 760; loss: 1.36; acc: 0.55
Batch: 780; loss: 1.74; acc: 0.44
Train Epoch over. train_loss: 1.41; train_accuracy: 0.52 

Batch: 0; loss: 1.37; acc: 0.58
Batch: 20; loss: 1.52; acc: 0.55
Batch: 40; loss: 1.14; acc: 0.64
Batch: 60; loss: 1.09; acc: 0.62
Batch: 80; loss: 1.24; acc: 0.62
Batch: 100; loss: 1.34; acc: 0.53
Batch: 120; loss: 1.6; acc: 0.53
Batch: 140; loss: 1.13; acc: 0.58
Val Epoch over. val_loss: 1.3806097173387077; val_accuracy: 0.5307523885350318 

The current subspace-distance is: 8.119341509882361e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.74; acc: 0.42
Batch: 20; loss: 1.41; acc: 0.55
Batch: 40; loss: 1.43; acc: 0.55
Batch: 60; loss: 1.16; acc: 0.61
Batch: 80; loss: 1.67; acc: 0.39
Batch: 100; loss: 1.39; acc: 0.53
Batch: 120; loss: 1.7; acc: 0.45
Batch: 140; loss: 1.5; acc: 0.52
Batch: 160; loss: 1.25; acc: 0.53
Batch: 180; loss: 1.49; acc: 0.5
Batch: 200; loss: 1.23; acc: 0.55
Batch: 220; loss: 1.42; acc: 0.66
Batch: 240; loss: 1.34; acc: 0.52
Batch: 260; loss: 1.29; acc: 0.56
Batch: 280; loss: 1.52; acc: 0.5
Batch: 300; loss: 1.49; acc: 0.52
Batch: 320; loss: 1.42; acc: 0.52
Batch: 340; loss: 1.47; acc: 0.52
Batch: 360; loss: 1.4; acc: 0.56
Batch: 380; loss: 1.66; acc: 0.45
Batch: 400; loss: 1.32; acc: 0.53
Batch: 420; loss: 1.52; acc: 0.52
Batch: 440; loss: 1.55; acc: 0.47
Batch: 460; loss: 1.53; acc: 0.55
Batch: 480; loss: 1.44; acc: 0.41
Batch: 500; loss: 1.37; acc: 0.56
Batch: 520; loss: 1.33; acc: 0.64
Batch: 540; loss: 1.44; acc: 0.55
Batch: 560; loss: 1.27; acc: 0.59
Batch: 580; loss: 1.32; acc: 0.62
Batch: 600; loss: 1.41; acc: 0.61
Batch: 620; loss: 1.39; acc: 0.58
Batch: 640; loss: 1.34; acc: 0.55
Batch: 660; loss: 1.51; acc: 0.5
Batch: 680; loss: 1.49; acc: 0.5
Batch: 700; loss: 1.26; acc: 0.59
Batch: 720; loss: 1.3; acc: 0.56
Batch: 740; loss: 1.2; acc: 0.5
Batch: 760; loss: 1.45; acc: 0.5
Batch: 780; loss: 1.51; acc: 0.5
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.57; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.64
Batch: 60; loss: 1.07; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.62
Batch: 100; loss: 1.32; acc: 0.61
Batch: 120; loss: 1.64; acc: 0.47
Batch: 140; loss: 1.15; acc: 0.61
Val Epoch over. val_loss: 1.3586021327668694; val_accuracy: 0.5472730891719745 

The current subspace-distance is: 8.380782674066722e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.61; acc: 0.47
Batch: 20; loss: 1.48; acc: 0.5
Batch: 40; loss: 1.53; acc: 0.44
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.48; acc: 0.48
Batch: 100; loss: 1.32; acc: 0.62
Batch: 120; loss: 1.77; acc: 0.45
Batch: 140; loss: 1.4; acc: 0.58
Batch: 160; loss: 1.61; acc: 0.44
Batch: 180; loss: 1.35; acc: 0.61
Batch: 200; loss: 1.52; acc: 0.45
Batch: 220; loss: 1.47; acc: 0.55
Batch: 240; loss: 1.34; acc: 0.56
Batch: 260; loss: 1.57; acc: 0.47
Batch: 280; loss: 1.32; acc: 0.58
Batch: 300; loss: 1.3; acc: 0.58
Batch: 320; loss: 1.19; acc: 0.61
Batch: 340; loss: 1.41; acc: 0.48
Batch: 360; loss: 1.26; acc: 0.59
Batch: 380; loss: 1.4; acc: 0.47
Batch: 400; loss: 1.45; acc: 0.5
Batch: 420; loss: 1.52; acc: 0.48
Batch: 440; loss: 1.46; acc: 0.55
Batch: 460; loss: 1.38; acc: 0.53
Batch: 480; loss: 1.28; acc: 0.56
Batch: 500; loss: 1.28; acc: 0.52
Batch: 520; loss: 1.3; acc: 0.56
Batch: 540; loss: 1.57; acc: 0.45
Batch: 560; loss: 1.39; acc: 0.5
Batch: 580; loss: 1.45; acc: 0.5
Batch: 600; loss: 1.33; acc: 0.55
Batch: 620; loss: 1.36; acc: 0.48
Batch: 640; loss: 1.47; acc: 0.42
Batch: 660; loss: 1.55; acc: 0.53
Batch: 680; loss: 1.33; acc: 0.55
Batch: 700; loss: 1.27; acc: 0.56
Batch: 720; loss: 1.52; acc: 0.45
Batch: 740; loss: 1.58; acc: 0.47
Batch: 760; loss: 1.38; acc: 0.53
Batch: 780; loss: 1.27; acc: 0.53
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.54; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.62
Batch: 60; loss: 1.07; acc: 0.61
Batch: 80; loss: 1.21; acc: 0.59
Batch: 100; loss: 1.34; acc: 0.61
Batch: 120; loss: 1.66; acc: 0.52
Batch: 140; loss: 1.13; acc: 0.59
Val Epoch over. val_loss: 1.3521391662063114; val_accuracy: 0.5499601910828026 

The current subspace-distance is: 8.770979184191674e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.31; acc: 0.62
Batch: 20; loss: 1.41; acc: 0.44
Batch: 40; loss: 1.35; acc: 0.52
Batch: 60; loss: 1.31; acc: 0.56
Batch: 80; loss: 1.42; acc: 0.55
Batch: 100; loss: 1.23; acc: 0.62
Batch: 120; loss: 1.22; acc: 0.64
Batch: 140; loss: 1.46; acc: 0.52
Batch: 160; loss: 1.41; acc: 0.52
Batch: 180; loss: 1.4; acc: 0.47
Batch: 200; loss: 1.53; acc: 0.52
Batch: 220; loss: 1.4; acc: 0.55
Batch: 240; loss: 1.36; acc: 0.64
Batch: 260; loss: 1.26; acc: 0.62
Batch: 280; loss: 1.39; acc: 0.55
Batch: 300; loss: 1.42; acc: 0.5
Batch: 320; loss: 1.41; acc: 0.53
Batch: 340; loss: 1.29; acc: 0.61
Batch: 360; loss: 1.33; acc: 0.55
Batch: 380; loss: 1.44; acc: 0.53
Batch: 400; loss: 1.67; acc: 0.42
Batch: 420; loss: 1.51; acc: 0.52
Batch: 440; loss: 1.43; acc: 0.5
Batch: 460; loss: 1.35; acc: 0.53
Batch: 480; loss: 1.3; acc: 0.53
Batch: 500; loss: 1.11; acc: 0.69
Batch: 520; loss: 1.28; acc: 0.52
Batch: 540; loss: 1.59; acc: 0.47
Batch: 560; loss: 1.6; acc: 0.53
Batch: 580; loss: 1.39; acc: 0.52
Batch: 600; loss: 1.21; acc: 0.62
Batch: 620; loss: 1.31; acc: 0.53
Batch: 640; loss: 1.6; acc: 0.44
Batch: 660; loss: 1.32; acc: 0.58
Batch: 680; loss: 1.22; acc: 0.64
Batch: 700; loss: 1.41; acc: 0.52
Batch: 720; loss: 1.35; acc: 0.55
Batch: 740; loss: 1.52; acc: 0.53
Batch: 760; loss: 1.58; acc: 0.45
Batch: 780; loss: 1.56; acc: 0.52
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.37; acc: 0.56
Batch: 20; loss: 1.55; acc: 0.48
Batch: 40; loss: 1.14; acc: 0.61
Batch: 60; loss: 1.08; acc: 0.62
Batch: 80; loss: 1.22; acc: 0.62
Batch: 100; loss: 1.35; acc: 0.59
Batch: 120; loss: 1.67; acc: 0.47
Batch: 140; loss: 1.15; acc: 0.62
Val Epoch over. val_loss: 1.3573300428451247; val_accuracy: 0.5489649681528662 

The current subspace-distance is: 9.139395842794329e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.39; acc: 0.58
Batch: 20; loss: 1.46; acc: 0.47
Batch: 40; loss: 1.25; acc: 0.58
Batch: 60; loss: 1.4; acc: 0.5
Batch: 80; loss: 1.33; acc: 0.53
Batch: 100; loss: 1.35; acc: 0.61
Batch: 120; loss: 1.32; acc: 0.53
Batch: 140; loss: 1.54; acc: 0.5
Batch: 160; loss: 1.8; acc: 0.41
Batch: 180; loss: 1.22; acc: 0.62
Batch: 200; loss: 1.32; acc: 0.67
Batch: 220; loss: 1.39; acc: 0.55
Batch: 240; loss: 1.19; acc: 0.56
Batch: 260; loss: 1.31; acc: 0.61
Batch: 280; loss: 1.49; acc: 0.5
Batch: 300; loss: 1.41; acc: 0.56
Batch: 320; loss: 1.25; acc: 0.61
Batch: 340; loss: 1.25; acc: 0.58
Batch: 360; loss: 1.39; acc: 0.5
Batch: 380; loss: 1.46; acc: 0.47
Batch: 400; loss: 1.56; acc: 0.47
Batch: 420; loss: 1.33; acc: 0.52
Batch: 440; loss: 1.68; acc: 0.47
Batch: 460; loss: 1.38; acc: 0.56
Batch: 480; loss: 1.12; acc: 0.62
Batch: 500; loss: 1.38; acc: 0.48
Batch: 520; loss: 1.3; acc: 0.56
Batch: 540; loss: 1.37; acc: 0.53
Batch: 560; loss: 1.45; acc: 0.56
Batch: 580; loss: 1.22; acc: 0.55
Batch: 600; loss: 1.36; acc: 0.53
Batch: 620; loss: 1.42; acc: 0.53
Batch: 640; loss: 1.32; acc: 0.56
Batch: 660; loss: 1.51; acc: 0.53
Batch: 680; loss: 1.18; acc: 0.5
Batch: 700; loss: 1.44; acc: 0.47
Batch: 720; loss: 1.36; acc: 0.5
Batch: 740; loss: 1.58; acc: 0.48
Batch: 760; loss: 1.5; acc: 0.53
Batch: 780; loss: 1.54; acc: 0.41
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.56; acc: 0.5
Batch: 40; loss: 1.14; acc: 0.62
Batch: 60; loss: 1.08; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.62
Batch: 100; loss: 1.33; acc: 0.61
Batch: 120; loss: 1.66; acc: 0.47
Batch: 140; loss: 1.17; acc: 0.59
Val Epoch over. val_loss: 1.3637703619185526; val_accuracy: 0.5471735668789809 

The current subspace-distance is: 8.861154492478818e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.27; acc: 0.58
Batch: 20; loss: 1.43; acc: 0.5
Batch: 40; loss: 1.24; acc: 0.62
Batch: 60; loss: 1.33; acc: 0.58
Batch: 80; loss: 1.51; acc: 0.52
Batch: 100; loss: 1.43; acc: 0.45
Batch: 120; loss: 1.34; acc: 0.58
Batch: 140; loss: 1.37; acc: 0.58
Batch: 160; loss: 1.42; acc: 0.56
Batch: 180; loss: 1.17; acc: 0.53
Batch: 200; loss: 1.25; acc: 0.58
Batch: 220; loss: 1.36; acc: 0.55
Batch: 240; loss: 1.48; acc: 0.5
Batch: 260; loss: 1.51; acc: 0.48
Batch: 280; loss: 1.54; acc: 0.47
Batch: 300; loss: 1.49; acc: 0.47
Batch: 320; loss: 1.48; acc: 0.52
Batch: 340; loss: 1.67; acc: 0.41
Batch: 360; loss: 1.3; acc: 0.58
Batch: 380; loss: 1.4; acc: 0.48
Batch: 400; loss: 1.39; acc: 0.53
Batch: 420; loss: 1.26; acc: 0.59
Batch: 440; loss: 1.34; acc: 0.52
Batch: 460; loss: 1.41; acc: 0.5
Batch: 480; loss: 1.13; acc: 0.59
Batch: 500; loss: 1.54; acc: 0.41
Batch: 520; loss: 1.37; acc: 0.56
Batch: 540; loss: 1.12; acc: 0.66
Batch: 560; loss: 1.6; acc: 0.48
Batch: 580; loss: 1.25; acc: 0.55
Batch: 600; loss: 1.67; acc: 0.39
Batch: 620; loss: 1.4; acc: 0.52
Batch: 640; loss: 1.22; acc: 0.56
Batch: 660; loss: 1.25; acc: 0.56
Batch: 680; loss: 1.35; acc: 0.55
Batch: 700; loss: 1.18; acc: 0.58
Batch: 720; loss: 1.41; acc: 0.52
Batch: 740; loss: 1.4; acc: 0.53
Batch: 760; loss: 1.25; acc: 0.61
Batch: 780; loss: 1.48; acc: 0.45
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.56; acc: 0.5
Batch: 40; loss: 1.14; acc: 0.62
Batch: 60; loss: 1.07; acc: 0.61
Batch: 80; loss: 1.19; acc: 0.61
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.67; acc: 0.5
Batch: 140; loss: 1.18; acc: 0.56
Val Epoch over. val_loss: 1.3659385814788236; val_accuracy: 0.5432921974522293 

The current subspace-distance is: 9.305283310823143e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.43; acc: 0.53
Batch: 20; loss: 1.58; acc: 0.48
Batch: 40; loss: 1.45; acc: 0.53
Batch: 60; loss: 1.29; acc: 0.52
Batch: 80; loss: 1.32; acc: 0.59
Batch: 100; loss: 1.28; acc: 0.52
Batch: 120; loss: 1.45; acc: 0.55
Batch: 140; loss: 1.35; acc: 0.64
Batch: 160; loss: 1.61; acc: 0.48
Batch: 180; loss: 1.47; acc: 0.48
Batch: 200; loss: 1.26; acc: 0.55
Batch: 220; loss: 1.51; acc: 0.52
Batch: 240; loss: 1.41; acc: 0.5
Batch: 260; loss: 1.15; acc: 0.61
Batch: 280; loss: 1.47; acc: 0.45
Batch: 300; loss: 1.59; acc: 0.42
Batch: 320; loss: 1.53; acc: 0.5
Batch: 340; loss: 1.28; acc: 0.58
Batch: 360; loss: 1.51; acc: 0.48
Batch: 380; loss: 1.09; acc: 0.7
Batch: 400; loss: 1.26; acc: 0.59
Batch: 420; loss: 1.25; acc: 0.58
Batch: 440; loss: 1.58; acc: 0.44
Batch: 460; loss: 1.17; acc: 0.66
Batch: 480; loss: 1.37; acc: 0.47
Batch: 500; loss: 1.34; acc: 0.61
Batch: 520; loss: 1.31; acc: 0.58
Batch: 540; loss: 1.38; acc: 0.47
Batch: 560; loss: 1.5; acc: 0.52
Batch: 580; loss: 1.34; acc: 0.58
Batch: 600; loss: 1.57; acc: 0.55
Batch: 620; loss: 1.17; acc: 0.61
Batch: 640; loss: 1.48; acc: 0.55
Batch: 660; loss: 1.24; acc: 0.61
Batch: 680; loss: 1.28; acc: 0.56
Batch: 700; loss: 1.29; acc: 0.56
Batch: 720; loss: 1.48; acc: 0.55
Batch: 740; loss: 1.41; acc: 0.55
Batch: 760; loss: 1.46; acc: 0.56
Batch: 780; loss: 1.57; acc: 0.44
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.58
Batch: 20; loss: 1.53; acc: 0.56
Batch: 40; loss: 1.11; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.61
Batch: 80; loss: 1.25; acc: 0.59
Batch: 100; loss: 1.31; acc: 0.59
Batch: 120; loss: 1.61; acc: 0.53
Batch: 140; loss: 1.13; acc: 0.61
Val Epoch over. val_loss: 1.361902276421808; val_accuracy: 0.5446855095541401 

The current subspace-distance is: 9.311303438153118e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.47; acc: 0.5
Batch: 20; loss: 1.72; acc: 0.42
Batch: 40; loss: 1.46; acc: 0.48
Batch: 60; loss: 1.38; acc: 0.47
Batch: 80; loss: 1.48; acc: 0.44
Batch: 100; loss: 1.32; acc: 0.55
Batch: 120; loss: 1.58; acc: 0.45
Batch: 140; loss: 1.28; acc: 0.56
Batch: 160; loss: 1.36; acc: 0.59
Batch: 180; loss: 1.62; acc: 0.5
Batch: 200; loss: 1.4; acc: 0.53
Batch: 220; loss: 1.14; acc: 0.66
Batch: 240; loss: 1.39; acc: 0.41
Batch: 260; loss: 1.25; acc: 0.61
Batch: 280; loss: 1.53; acc: 0.47
Batch: 300; loss: 1.5; acc: 0.48
Batch: 320; loss: 1.6; acc: 0.48
Batch: 340; loss: 1.33; acc: 0.53
Batch: 360; loss: 1.16; acc: 0.62
Batch: 380; loss: 1.33; acc: 0.48
Batch: 400; loss: 1.61; acc: 0.48
Batch: 420; loss: 1.41; acc: 0.61
Batch: 440; loss: 1.42; acc: 0.53
Batch: 460; loss: 1.59; acc: 0.42
Batch: 480; loss: 1.34; acc: 0.53
Batch: 500; loss: 1.3; acc: 0.61
Batch: 520; loss: 1.43; acc: 0.55
Batch: 540; loss: 1.32; acc: 0.58
Batch: 560; loss: 1.45; acc: 0.48
Batch: 580; loss: 1.44; acc: 0.48
Batch: 600; loss: 1.53; acc: 0.48
Batch: 620; loss: 1.61; acc: 0.5
Batch: 640; loss: 1.53; acc: 0.53
Batch: 660; loss: 1.45; acc: 0.53
Batch: 680; loss: 1.52; acc: 0.42
Batch: 700; loss: 1.3; acc: 0.56
Batch: 720; loss: 1.17; acc: 0.67
Batch: 740; loss: 1.25; acc: 0.64
Batch: 760; loss: 1.38; acc: 0.53
Batch: 780; loss: 1.41; acc: 0.55
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.33; acc: 0.56
Batch: 20; loss: 1.52; acc: 0.48
Batch: 40; loss: 1.14; acc: 0.62
Batch: 60; loss: 1.07; acc: 0.59
Batch: 80; loss: 1.2; acc: 0.62
Batch: 100; loss: 1.36; acc: 0.58
Batch: 120; loss: 1.66; acc: 0.5
Batch: 140; loss: 1.13; acc: 0.58
Val Epoch over. val_loss: 1.3578520405824017; val_accuracy: 0.5464769108280255 

The current subspace-distance is: 9.491187665844336e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.34; acc: 0.58
Batch: 20; loss: 1.49; acc: 0.45
Batch: 40; loss: 1.36; acc: 0.55
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.32; acc: 0.55
Batch: 100; loss: 1.38; acc: 0.59
Batch: 120; loss: 1.15; acc: 0.66
Batch: 140; loss: 1.49; acc: 0.42
Batch: 160; loss: 1.47; acc: 0.47
Batch: 180; loss: 1.21; acc: 0.59
Batch: 200; loss: 1.38; acc: 0.53
Batch: 220; loss: 1.65; acc: 0.42
Batch: 240; loss: 1.34; acc: 0.59
Batch: 260; loss: 1.29; acc: 0.58
Batch: 280; loss: 1.63; acc: 0.39
Batch: 300; loss: 1.46; acc: 0.45
Batch: 320; loss: 1.28; acc: 0.5
Batch: 340; loss: 1.51; acc: 0.5
Batch: 360; loss: 1.58; acc: 0.48
Batch: 380; loss: 1.45; acc: 0.56
Batch: 400; loss: 1.64; acc: 0.42
Batch: 420; loss: 1.54; acc: 0.48
Batch: 440; loss: 1.36; acc: 0.47
Batch: 460; loss: 1.27; acc: 0.53
Batch: 480; loss: 1.33; acc: 0.59
Batch: 500; loss: 1.39; acc: 0.48
Batch: 520; loss: 1.38; acc: 0.52
Batch: 540; loss: 1.5; acc: 0.41
Batch: 560; loss: 1.36; acc: 0.53
Batch: 580; loss: 1.46; acc: 0.47
Batch: 600; loss: 1.28; acc: 0.64
Batch: 620; loss: 1.72; acc: 0.41
Batch: 640; loss: 1.27; acc: 0.56
Batch: 660; loss: 1.55; acc: 0.5
Batch: 680; loss: 1.52; acc: 0.53
Batch: 700; loss: 1.67; acc: 0.42
Batch: 720; loss: 1.24; acc: 0.58
Batch: 740; loss: 1.55; acc: 0.41
Batch: 760; loss: 1.47; acc: 0.52
Batch: 780; loss: 1.47; acc: 0.5
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.53; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.58
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.33; acc: 0.56
Batch: 120; loss: 1.62; acc: 0.53
Batch: 140; loss: 1.13; acc: 0.58
Val Epoch over. val_loss: 1.3543388858722274; val_accuracy: 0.5492635350318471 

The current subspace-distance is: 9.549813694320619e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.39; acc: 0.55
Batch: 20; loss: 1.45; acc: 0.5
Batch: 40; loss: 1.67; acc: 0.41
Batch: 60; loss: 1.36; acc: 0.5
Batch: 80; loss: 1.33; acc: 0.48
Batch: 100; loss: 1.42; acc: 0.47
Batch: 120; loss: 1.58; acc: 0.42
Batch: 140; loss: 1.33; acc: 0.5
Batch: 160; loss: 1.33; acc: 0.66
Batch: 180; loss: 1.29; acc: 0.53
Batch: 200; loss: 1.47; acc: 0.44
Batch: 220; loss: 1.48; acc: 0.48
Batch: 240; loss: 1.55; acc: 0.47
Batch: 260; loss: 1.25; acc: 0.61
Batch: 280; loss: 1.5; acc: 0.47
Batch: 300; loss: 1.36; acc: 0.56
Batch: 320; loss: 1.36; acc: 0.53
Batch: 340; loss: 1.26; acc: 0.61
Batch: 360; loss: 1.26; acc: 0.55
Batch: 380; loss: 1.7; acc: 0.44
Batch: 400; loss: 1.42; acc: 0.47
Batch: 420; loss: 1.4; acc: 0.52
Batch: 440; loss: 1.48; acc: 0.44
Batch: 460; loss: 1.49; acc: 0.48
Batch: 480; loss: 1.43; acc: 0.58
Batch: 500; loss: 1.35; acc: 0.55
Batch: 520; loss: 1.44; acc: 0.5
Batch: 540; loss: 1.32; acc: 0.58
Batch: 560; loss: 1.32; acc: 0.52
Batch: 580; loss: 1.39; acc: 0.59
Batch: 600; loss: 1.29; acc: 0.56
Batch: 620; loss: 1.51; acc: 0.56
Batch: 640; loss: 1.32; acc: 0.52
Batch: 660; loss: 1.64; acc: 0.52
Batch: 680; loss: 1.34; acc: 0.48
Batch: 700; loss: 1.31; acc: 0.53
Batch: 720; loss: 1.32; acc: 0.5
Batch: 740; loss: 1.3; acc: 0.59
Batch: 760; loss: 1.37; acc: 0.5
Batch: 780; loss: 1.29; acc: 0.53
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.37; acc: 0.59
Batch: 20; loss: 1.51; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 1.08; acc: 0.59
Batch: 80; loss: 1.27; acc: 0.55
Batch: 100; loss: 1.35; acc: 0.56
Batch: 120; loss: 1.64; acc: 0.53
Batch: 140; loss: 1.1; acc: 0.62
Val Epoch over. val_loss: 1.3620531391945614; val_accuracy: 0.5417993630573248 

The current subspace-distance is: 9.792225318960845e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.5; acc: 0.52
Batch: 20; loss: 1.53; acc: 0.52
Batch: 40; loss: 1.05; acc: 0.62
Batch: 60; loss: 1.52; acc: 0.58
Batch: 80; loss: 1.28; acc: 0.58
Batch: 100; loss: 1.26; acc: 0.61
Batch: 120; loss: 1.46; acc: 0.44
Batch: 140; loss: 1.68; acc: 0.44
Batch: 160; loss: 1.38; acc: 0.47
Batch: 180; loss: 1.49; acc: 0.5
Batch: 200; loss: 1.15; acc: 0.61
Batch: 220; loss: 1.29; acc: 0.59
Batch: 240; loss: 1.26; acc: 0.59
Batch: 260; loss: 1.51; acc: 0.52
Batch: 280; loss: 1.3; acc: 0.53
Batch: 300; loss: 1.48; acc: 0.47
Batch: 320; loss: 1.66; acc: 0.36
Batch: 340; loss: 1.49; acc: 0.58
Batch: 360; loss: 1.5; acc: 0.45
Batch: 380; loss: 1.51; acc: 0.39
Batch: 400; loss: 1.23; acc: 0.55
Batch: 420; loss: 1.55; acc: 0.5
Batch: 440; loss: 1.35; acc: 0.58
Batch: 460; loss: 1.45; acc: 0.48
Batch: 480; loss: 1.41; acc: 0.52
Batch: 500; loss: 1.65; acc: 0.45
Batch: 520; loss: 1.69; acc: 0.41
Batch: 540; loss: 1.48; acc: 0.55
Batch: 560; loss: 1.4; acc: 0.53
Batch: 580; loss: 1.4; acc: 0.55
Batch: 600; loss: 1.27; acc: 0.61
Batch: 620; loss: 1.48; acc: 0.56
Batch: 640; loss: 1.45; acc: 0.5
Batch: 660; loss: 1.39; acc: 0.53
Batch: 680; loss: 1.33; acc: 0.52
Batch: 700; loss: 1.51; acc: 0.56
Batch: 720; loss: 1.26; acc: 0.55
Batch: 740; loss: 1.35; acc: 0.53
Batch: 760; loss: 1.35; acc: 0.52
Batch: 780; loss: 1.54; acc: 0.5
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.54; acc: 0.52
Batch: 40; loss: 1.13; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.58
Batch: 80; loss: 1.26; acc: 0.58
Batch: 100; loss: 1.33; acc: 0.59
Batch: 120; loss: 1.65; acc: 0.5
Batch: 140; loss: 1.15; acc: 0.61
Val Epoch over. val_loss: 1.3580845609592025; val_accuracy: 0.5488654458598726 

The current subspace-distance is: 9.992098057409748e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.3; acc: 0.52
Batch: 20; loss: 1.38; acc: 0.47
Batch: 40; loss: 1.48; acc: 0.55
Batch: 60; loss: 1.33; acc: 0.56
Batch: 80; loss: 1.37; acc: 0.53
Batch: 100; loss: 1.35; acc: 0.61
Batch: 120; loss: 1.69; acc: 0.42
Batch: 140; loss: 1.31; acc: 0.59
Batch: 160; loss: 1.55; acc: 0.52
Batch: 180; loss: 1.39; acc: 0.52
Batch: 200; loss: 1.54; acc: 0.47
Batch: 220; loss: 1.37; acc: 0.55
Batch: 240; loss: 1.35; acc: 0.55
Batch: 260; loss: 1.27; acc: 0.59
Batch: 280; loss: 1.41; acc: 0.52
Batch: 300; loss: 1.35; acc: 0.55
Batch: 320; loss: 1.31; acc: 0.56
Batch: 340; loss: 1.3; acc: 0.48
Batch: 360; loss: 1.26; acc: 0.52
Batch: 380; loss: 1.61; acc: 0.44
Batch: 400; loss: 1.76; acc: 0.42
Batch: 420; loss: 1.5; acc: 0.39
Batch: 440; loss: 1.37; acc: 0.56
Batch: 460; loss: 1.34; acc: 0.5
Batch: 480; loss: 1.41; acc: 0.52
Batch: 500; loss: 1.16; acc: 0.61
Batch: 520; loss: 1.22; acc: 0.58
Batch: 540; loss: 1.48; acc: 0.52
Batch: 560; loss: 1.25; acc: 0.64
Batch: 580; loss: 1.34; acc: 0.59
Batch: 600; loss: 1.44; acc: 0.53
Batch: 620; loss: 1.78; acc: 0.41
Batch: 640; loss: 1.46; acc: 0.48
Batch: 660; loss: 1.32; acc: 0.53
Batch: 680; loss: 1.45; acc: 0.5
Batch: 700; loss: 1.34; acc: 0.56
Batch: 720; loss: 1.56; acc: 0.44
Batch: 740; loss: 1.33; acc: 0.53
Batch: 760; loss: 1.73; acc: 0.47
Batch: 780; loss: 1.57; acc: 0.45
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.55
Batch: 20; loss: 1.5; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.61
Batch: 80; loss: 1.24; acc: 0.58
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.65; acc: 0.5
Batch: 140; loss: 1.12; acc: 0.62
Val Epoch over. val_loss: 1.3496560496129808; val_accuracy: 0.5515525477707006 

The current subspace-distance is: 0.00010094018216477707 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.16; acc: 0.66
Batch: 20; loss: 1.36; acc: 0.52
Batch: 40; loss: 1.43; acc: 0.53
Batch: 60; loss: 1.49; acc: 0.48
Batch: 80; loss: 1.37; acc: 0.56
Batch: 100; loss: 1.54; acc: 0.44
Batch: 120; loss: 1.14; acc: 0.64
Batch: 140; loss: 1.55; acc: 0.41
Batch: 160; loss: 1.38; acc: 0.53
Batch: 180; loss: 1.07; acc: 0.61
Batch: 200; loss: 1.13; acc: 0.62
Batch: 220; loss: 1.24; acc: 0.59
Batch: 240; loss: 1.25; acc: 0.61
Batch: 260; loss: 1.53; acc: 0.42
Batch: 280; loss: 1.54; acc: 0.41
Batch: 300; loss: 1.36; acc: 0.41
Batch: 320; loss: 1.5; acc: 0.47
Batch: 340; loss: 1.64; acc: 0.42
Batch: 360; loss: 1.48; acc: 0.41
Batch: 380; loss: 1.41; acc: 0.5
Batch: 400; loss: 1.24; acc: 0.55
Batch: 420; loss: 1.3; acc: 0.55
Batch: 440; loss: 1.35; acc: 0.45
Batch: 460; loss: 1.5; acc: 0.52
Batch: 480; loss: 1.55; acc: 0.42
Batch: 500; loss: 1.36; acc: 0.52
Batch: 520; loss: 1.14; acc: 0.59
Batch: 540; loss: 1.62; acc: 0.36
Batch: 560; loss: 1.8; acc: 0.44
Batch: 580; loss: 1.59; acc: 0.48
Batch: 600; loss: 1.63; acc: 0.44
Batch: 620; loss: 1.49; acc: 0.52
Batch: 640; loss: 1.47; acc: 0.53
Batch: 660; loss: 1.22; acc: 0.59
Batch: 680; loss: 1.54; acc: 0.53
Batch: 700; loss: 1.31; acc: 0.55
Batch: 720; loss: 1.52; acc: 0.53
Batch: 740; loss: 1.5; acc: 0.55
Batch: 760; loss: 1.55; acc: 0.44
Batch: 780; loss: 1.36; acc: 0.47
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.5; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.66
Batch: 60; loss: 1.06; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.56
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.63; acc: 0.53
Batch: 140; loss: 1.12; acc: 0.59
Val Epoch over. val_loss: 1.3474432867803392; val_accuracy: 0.5513535031847133 

The current subspace-distance is: 0.00010358401050325483 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.76; acc: 0.47
Batch: 20; loss: 1.39; acc: 0.55
Batch: 40; loss: 1.45; acc: 0.47
Batch: 60; loss: 1.29; acc: 0.56
Batch: 80; loss: 1.34; acc: 0.61
Batch: 100; loss: 1.33; acc: 0.55
Batch: 120; loss: 1.22; acc: 0.66
Batch: 140; loss: 1.22; acc: 0.53
Batch: 160; loss: 1.54; acc: 0.53
Batch: 180; loss: 1.48; acc: 0.5
Batch: 200; loss: 1.52; acc: 0.55
Batch: 220; loss: 1.3; acc: 0.59
Batch: 240; loss: 1.53; acc: 0.45
Batch: 260; loss: 1.51; acc: 0.48
Batch: 280; loss: 1.21; acc: 0.59
Batch: 300; loss: 1.38; acc: 0.58
Batch: 320; loss: 1.45; acc: 0.48
Batch: 340; loss: 1.64; acc: 0.47
Batch: 360; loss: 1.5; acc: 0.42
Batch: 380; loss: 1.12; acc: 0.64
Batch: 400; loss: 1.37; acc: 0.53
Batch: 420; loss: 1.35; acc: 0.52
Batch: 440; loss: 1.4; acc: 0.61
Batch: 460; loss: 1.25; acc: 0.61
Batch: 480; loss: 1.41; acc: 0.5
Batch: 500; loss: 1.23; acc: 0.56
Batch: 520; loss: 1.23; acc: 0.59
Batch: 540; loss: 1.48; acc: 0.47
Batch: 560; loss: 1.59; acc: 0.53
Batch: 580; loss: 1.57; acc: 0.52
Batch: 600; loss: 1.48; acc: 0.45
Batch: 620; loss: 1.77; acc: 0.44
Batch: 640; loss: 1.55; acc: 0.5
Batch: 660; loss: 1.43; acc: 0.56
Batch: 680; loss: 1.39; acc: 0.53
Batch: 700; loss: 1.48; acc: 0.55
Batch: 720; loss: 1.3; acc: 0.59
Batch: 740; loss: 1.47; acc: 0.45
Batch: 760; loss: 1.44; acc: 0.5
Batch: 780; loss: 1.2; acc: 0.62
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.56
Batch: 20; loss: 1.52; acc: 0.52
Batch: 40; loss: 1.13; acc: 0.69
Batch: 60; loss: 1.07; acc: 0.59
Batch: 80; loss: 1.24; acc: 0.56
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.66; acc: 0.5
Batch: 140; loss: 1.12; acc: 0.61
Val Epoch over. val_loss: 1.3487372250313971; val_accuracy: 0.5505573248407644 

The current subspace-distance is: 0.00010503264638828114 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.11; acc: 0.59
Batch: 20; loss: 1.43; acc: 0.45
Batch: 40; loss: 1.46; acc: 0.45
Batch: 60; loss: 1.28; acc: 0.59
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.66; acc: 0.36
Batch: 120; loss: 1.32; acc: 0.53
Batch: 140; loss: 1.39; acc: 0.53
Batch: 160; loss: 1.23; acc: 0.52
Batch: 180; loss: 1.44; acc: 0.52
Batch: 200; loss: 1.4; acc: 0.56
Batch: 220; loss: 1.34; acc: 0.56
Batch: 240; loss: 1.17; acc: 0.56
Batch: 260; loss: 1.34; acc: 0.56
Batch: 280; loss: 1.44; acc: 0.48
Batch: 300; loss: 1.28; acc: 0.64
Batch: 320; loss: 1.29; acc: 0.58
Batch: 340; loss: 1.4; acc: 0.53
Batch: 360; loss: 1.52; acc: 0.47
Batch: 380; loss: 1.47; acc: 0.47
Batch: 400; loss: 1.38; acc: 0.56
Batch: 420; loss: 1.21; acc: 0.64
Batch: 440; loss: 1.4; acc: 0.45
Batch: 460; loss: 1.59; acc: 0.47
Batch: 480; loss: 1.45; acc: 0.56
Batch: 500; loss: 1.15; acc: 0.59
Batch: 520; loss: 1.45; acc: 0.61
Batch: 540; loss: 1.61; acc: 0.47
Batch: 560; loss: 1.2; acc: 0.53
Batch: 580; loss: 1.36; acc: 0.5
Batch: 600; loss: 1.55; acc: 0.45
Batch: 620; loss: 1.65; acc: 0.41
Batch: 640; loss: 1.23; acc: 0.64
Batch: 660; loss: 1.1; acc: 0.61
Batch: 680; loss: 1.36; acc: 0.52
Batch: 700; loss: 1.66; acc: 0.48
Batch: 720; loss: 1.19; acc: 0.67
Batch: 740; loss: 1.25; acc: 0.58
Batch: 760; loss: 1.33; acc: 0.59
Batch: 780; loss: 1.47; acc: 0.56
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.58
Batch: 20; loss: 1.51; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.69
Batch: 60; loss: 1.06; acc: 0.61
Batch: 80; loss: 1.24; acc: 0.55
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.12; acc: 0.64
Val Epoch over. val_loss: 1.3487041938077113; val_accuracy: 0.5501592356687898 

The current subspace-distance is: 0.00010910152195720002 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.27; acc: 0.59
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 1.25; acc: 0.59
Batch: 60; loss: 1.5; acc: 0.47
Batch: 80; loss: 1.59; acc: 0.47
Batch: 100; loss: 1.37; acc: 0.45
Batch: 120; loss: 1.39; acc: 0.47
Batch: 140; loss: 1.61; acc: 0.44
Batch: 160; loss: 1.17; acc: 0.58
Batch: 180; loss: 1.13; acc: 0.55
Batch: 200; loss: 1.21; acc: 0.56
Batch: 220; loss: 1.3; acc: 0.56
Batch: 240; loss: 1.24; acc: 0.61
Batch: 260; loss: 1.31; acc: 0.59
Batch: 280; loss: 1.19; acc: 0.5
Batch: 300; loss: 1.26; acc: 0.58
Batch: 320; loss: 1.52; acc: 0.48
Batch: 340; loss: 1.45; acc: 0.45
Batch: 360; loss: 1.27; acc: 0.58
Batch: 380; loss: 1.4; acc: 0.56
Batch: 400; loss: 1.09; acc: 0.61
Batch: 420; loss: 1.38; acc: 0.5
Batch: 440; loss: 1.37; acc: 0.61
Batch: 460; loss: 1.5; acc: 0.47
Batch: 480; loss: 1.51; acc: 0.48
Batch: 500; loss: 1.2; acc: 0.53
Batch: 520; loss: 1.38; acc: 0.5
Batch: 540; loss: 1.45; acc: 0.53
Batch: 560; loss: 1.37; acc: 0.56
Batch: 580; loss: 1.63; acc: 0.48
Batch: 600; loss: 1.34; acc: 0.52
Batch: 620; loss: 1.33; acc: 0.5
Batch: 640; loss: 1.23; acc: 0.55
Batch: 660; loss: 1.54; acc: 0.48
Batch: 680; loss: 1.59; acc: 0.47
Batch: 700; loss: 1.57; acc: 0.45
Batch: 720; loss: 1.46; acc: 0.5
Batch: 740; loss: 1.5; acc: 0.56
Batch: 760; loss: 1.68; acc: 0.48
Batch: 780; loss: 1.36; acc: 0.53
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.5; acc: 0.52
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 1.07; acc: 0.62
Batch: 80; loss: 1.23; acc: 0.56
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.52
Batch: 140; loss: 1.12; acc: 0.59
Val Epoch over. val_loss: 1.3472061476130395; val_accuracy: 0.5511544585987261 

The current subspace-distance is: 0.00011170424113515764 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.01; acc: 0.72
Batch: 20; loss: 1.28; acc: 0.66
Batch: 40; loss: 1.31; acc: 0.55
Batch: 60; loss: 1.24; acc: 0.56
Batch: 80; loss: 1.15; acc: 0.67
Batch: 100; loss: 1.23; acc: 0.64
Batch: 120; loss: 1.38; acc: 0.53
Batch: 140; loss: 1.05; acc: 0.64
Batch: 160; loss: 1.44; acc: 0.48
Batch: 180; loss: 1.48; acc: 0.55
Batch: 200; loss: 1.29; acc: 0.64
Batch: 220; loss: 1.58; acc: 0.47
Batch: 240; loss: 1.17; acc: 0.59
Batch: 260; loss: 1.32; acc: 0.56
Batch: 280; loss: 1.27; acc: 0.53
Batch: 300; loss: 1.71; acc: 0.44
Batch: 320; loss: 1.38; acc: 0.55
Batch: 340; loss: 1.46; acc: 0.48
Batch: 360; loss: 1.41; acc: 0.45
Batch: 380; loss: 1.67; acc: 0.44
Batch: 400; loss: 1.53; acc: 0.45
Batch: 420; loss: 1.61; acc: 0.44
Batch: 440; loss: 1.51; acc: 0.48
Batch: 460; loss: 1.53; acc: 0.44
Batch: 480; loss: 1.47; acc: 0.5
Batch: 500; loss: 1.29; acc: 0.56
Batch: 520; loss: 1.47; acc: 0.59
Batch: 540; loss: 1.28; acc: 0.58
Batch: 560; loss: 1.32; acc: 0.5
Batch: 580; loss: 1.36; acc: 0.59
Batch: 600; loss: 1.4; acc: 0.52
Batch: 620; loss: 1.44; acc: 0.53
Batch: 640; loss: 1.4; acc: 0.52
Batch: 660; loss: 1.44; acc: 0.5
Batch: 680; loss: 1.44; acc: 0.48
Batch: 700; loss: 1.33; acc: 0.5
Batch: 720; loss: 1.51; acc: 0.44
Batch: 740; loss: 1.23; acc: 0.58
Batch: 760; loss: 1.26; acc: 0.55
Batch: 780; loss: 1.33; acc: 0.58
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.58
Batch: 20; loss: 1.5; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.69
Batch: 60; loss: 1.07; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.55
Batch: 100; loss: 1.33; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.13; acc: 0.62
Val Epoch over. val_loss: 1.3490842459308114; val_accuracy: 0.5508558917197452 

The current subspace-distance is: 0.00011193941463716328 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.44; acc: 0.47
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 1.35; acc: 0.55
Batch: 60; loss: 1.38; acc: 0.56
Batch: 80; loss: 1.43; acc: 0.5
Batch: 100; loss: 1.16; acc: 0.59
Batch: 120; loss: 1.04; acc: 0.67
Batch: 140; loss: 1.43; acc: 0.53
Batch: 160; loss: 1.33; acc: 0.56
Batch: 180; loss: 1.61; acc: 0.45
Batch: 200; loss: 1.65; acc: 0.52
Batch: 220; loss: 1.29; acc: 0.48
Batch: 240; loss: 1.41; acc: 0.56
Batch: 260; loss: 1.41; acc: 0.53
Batch: 280; loss: 1.33; acc: 0.56
Batch: 300; loss: 1.24; acc: 0.58
Batch: 320; loss: 1.28; acc: 0.59
Batch: 340; loss: 1.57; acc: 0.42
Batch: 360; loss: 1.28; acc: 0.55
Batch: 380; loss: 1.67; acc: 0.5
Batch: 400; loss: 1.4; acc: 0.64
Batch: 420; loss: 1.37; acc: 0.58
Batch: 440; loss: 1.42; acc: 0.5
Batch: 460; loss: 1.41; acc: 0.55
Batch: 480; loss: 1.23; acc: 0.61
Batch: 500; loss: 1.43; acc: 0.58
Batch: 520; loss: 1.25; acc: 0.59
Batch: 540; loss: 1.25; acc: 0.59
Batch: 560; loss: 1.47; acc: 0.44
Batch: 580; loss: 1.5; acc: 0.47
Batch: 600; loss: 1.35; acc: 0.53
Batch: 620; loss: 1.53; acc: 0.5
Batch: 640; loss: 1.66; acc: 0.44
Batch: 660; loss: 1.37; acc: 0.55
Batch: 680; loss: 1.45; acc: 0.5
Batch: 700; loss: 1.38; acc: 0.47
Batch: 720; loss: 1.51; acc: 0.5
Batch: 740; loss: 1.31; acc: 0.55
Batch: 760; loss: 1.4; acc: 0.55
Batch: 780; loss: 1.33; acc: 0.58
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.56
Batch: 20; loss: 1.5; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.69
Batch: 60; loss: 1.06; acc: 0.61
Batch: 80; loss: 1.24; acc: 0.55
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.64
Val Epoch over. val_loss: 1.3491439416909674; val_accuracy: 0.5522492038216561 

The current subspace-distance is: 0.00011858160723932087 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.63; acc: 0.45
Batch: 20; loss: 1.52; acc: 0.5
Batch: 40; loss: 1.44; acc: 0.58
Batch: 60; loss: 1.16; acc: 0.67
Batch: 80; loss: 1.57; acc: 0.45
Batch: 100; loss: 1.27; acc: 0.5
Batch: 120; loss: 1.74; acc: 0.41
Batch: 140; loss: 1.34; acc: 0.53
Batch: 160; loss: 1.28; acc: 0.53
Batch: 180; loss: 1.54; acc: 0.47
Batch: 200; loss: 1.39; acc: 0.45
Batch: 220; loss: 1.62; acc: 0.48
Batch: 240; loss: 1.37; acc: 0.52
Batch: 260; loss: 1.36; acc: 0.53
Batch: 280; loss: 1.48; acc: 0.58
Batch: 300; loss: 1.56; acc: 0.47
Batch: 320; loss: 1.4; acc: 0.53
Batch: 340; loss: 1.31; acc: 0.58
Batch: 360; loss: 1.58; acc: 0.45
Batch: 380; loss: 1.29; acc: 0.56
Batch: 400; loss: 1.67; acc: 0.45
Batch: 420; loss: 1.35; acc: 0.59
Batch: 440; loss: 1.29; acc: 0.53
Batch: 460; loss: 1.17; acc: 0.58
Batch: 480; loss: 1.23; acc: 0.64
Batch: 500; loss: 1.4; acc: 0.61
Batch: 520; loss: 1.45; acc: 0.52
Batch: 540; loss: 1.38; acc: 0.55
Batch: 560; loss: 1.35; acc: 0.5
Batch: 580; loss: 1.21; acc: 0.69
Batch: 600; loss: 1.49; acc: 0.58
Batch: 620; loss: 1.33; acc: 0.58
Batch: 640; loss: 1.25; acc: 0.59
Batch: 660; loss: 1.49; acc: 0.47
Batch: 680; loss: 1.4; acc: 0.47
Batch: 700; loss: 1.32; acc: 0.53
Batch: 720; loss: 1.71; acc: 0.48
Batch: 740; loss: 1.21; acc: 0.64
Batch: 760; loss: 1.22; acc: 0.59
Batch: 780; loss: 1.33; acc: 0.55
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.55
Batch: 20; loss: 1.51; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.69
Batch: 60; loss: 1.06; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.56
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.14; acc: 0.58
Val Epoch over. val_loss: 1.3506083640323323; val_accuracy: 0.5509554140127388 

The current subspace-distance is: 0.00012153062561992556 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.33; acc: 0.52
Batch: 20; loss: 1.33; acc: 0.48
Batch: 40; loss: 1.41; acc: 0.48
Batch: 60; loss: 1.33; acc: 0.64
Batch: 80; loss: 1.27; acc: 0.59
Batch: 100; loss: 1.29; acc: 0.61
Batch: 120; loss: 1.49; acc: 0.47
Batch: 140; loss: 1.65; acc: 0.41
Batch: 160; loss: 1.56; acc: 0.45
Batch: 180; loss: 1.52; acc: 0.44
Batch: 200; loss: 1.52; acc: 0.5
Batch: 220; loss: 1.77; acc: 0.5
Batch: 240; loss: 1.34; acc: 0.59
Batch: 260; loss: 1.46; acc: 0.45
Batch: 280; loss: 1.47; acc: 0.48
Batch: 300; loss: 1.36; acc: 0.64
Batch: 320; loss: 1.36; acc: 0.56
Batch: 340; loss: 1.11; acc: 0.62
Batch: 360; loss: 1.46; acc: 0.47
Batch: 380; loss: 1.27; acc: 0.66
Batch: 400; loss: 1.31; acc: 0.58
Batch: 420; loss: 1.42; acc: 0.55
Batch: 440; loss: 1.52; acc: 0.5
Batch: 460; loss: 1.1; acc: 0.58
Batch: 480; loss: 1.25; acc: 0.59
Batch: 500; loss: 1.11; acc: 0.66
Batch: 520; loss: 1.23; acc: 0.55
Batch: 540; loss: 1.32; acc: 0.55
Batch: 560; loss: 1.66; acc: 0.47
Batch: 580; loss: 1.43; acc: 0.56
Batch: 600; loss: 1.44; acc: 0.47
Batch: 620; loss: 1.5; acc: 0.55
Batch: 640; loss: 1.15; acc: 0.62
Batch: 660; loss: 1.42; acc: 0.44
Batch: 680; loss: 1.75; acc: 0.39
Batch: 700; loss: 1.45; acc: 0.47
Batch: 720; loss: 1.27; acc: 0.53
Batch: 740; loss: 1.67; acc: 0.42
Batch: 760; loss: 1.49; acc: 0.44
Batch: 780; loss: 1.31; acc: 0.56
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.55
Batch: 20; loss: 1.51; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.34; acc: 0.61
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.12; acc: 0.61
Val Epoch over. val_loss: 1.3470512605776452; val_accuracy: 0.5491640127388535 

The current subspace-distance is: 0.00012257567141205072 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.53; acc: 0.44
Batch: 20; loss: 1.29; acc: 0.47
Batch: 40; loss: 1.58; acc: 0.5
Batch: 60; loss: 1.65; acc: 0.5
Batch: 80; loss: 1.47; acc: 0.5
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.25; acc: 0.61
Batch: 140; loss: 1.32; acc: 0.56
Batch: 160; loss: 1.47; acc: 0.48
Batch: 180; loss: 1.58; acc: 0.52
Batch: 200; loss: 1.25; acc: 0.52
Batch: 220; loss: 1.69; acc: 0.36
Batch: 240; loss: 1.55; acc: 0.47
Batch: 260; loss: 1.41; acc: 0.52
Batch: 280; loss: 1.28; acc: 0.58
Batch: 300; loss: 1.39; acc: 0.52
Batch: 320; loss: 1.59; acc: 0.44
Batch: 340; loss: 1.43; acc: 0.56
Batch: 360; loss: 1.37; acc: 0.53
Batch: 380; loss: 1.43; acc: 0.56
Batch: 400; loss: 1.39; acc: 0.47
Batch: 420; loss: 1.26; acc: 0.59
Batch: 440; loss: 1.34; acc: 0.53
Batch: 460; loss: 1.34; acc: 0.55
Batch: 480; loss: 1.42; acc: 0.5
Batch: 500; loss: 1.68; acc: 0.44
Batch: 520; loss: 1.33; acc: 0.53
Batch: 540; loss: 1.26; acc: 0.52
Batch: 560; loss: 1.23; acc: 0.53
Batch: 580; loss: 1.74; acc: 0.42
Batch: 600; loss: 1.34; acc: 0.53
Batch: 620; loss: 1.26; acc: 0.53
Batch: 640; loss: 1.18; acc: 0.61
Batch: 660; loss: 1.4; acc: 0.55
Batch: 680; loss: 1.25; acc: 0.62
Batch: 700; loss: 1.25; acc: 0.56
Batch: 720; loss: 1.32; acc: 0.47
Batch: 740; loss: 1.58; acc: 0.44
Batch: 760; loss: 1.24; acc: 0.59
Batch: 780; loss: 1.54; acc: 0.41
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.36; acc: 0.58
Batch: 20; loss: 1.5; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.58
Batch: 80; loss: 1.25; acc: 0.53
Batch: 100; loss: 1.33; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.64
Val Epoch over. val_loss: 1.3507986736905044; val_accuracy: 0.54796974522293 

The current subspace-distance is: 0.00012074349069735035 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.48; acc: 0.44
Batch: 20; loss: 1.23; acc: 0.59
Batch: 40; loss: 1.29; acc: 0.56
Batch: 60; loss: 1.26; acc: 0.64
Batch: 80; loss: 1.6; acc: 0.41
Batch: 100; loss: 1.36; acc: 0.61
Batch: 120; loss: 1.33; acc: 0.55
Batch: 140; loss: 1.43; acc: 0.53
Batch: 160; loss: 1.22; acc: 0.66
Batch: 180; loss: 1.25; acc: 0.55
Batch: 200; loss: 1.47; acc: 0.53
Batch: 220; loss: 1.34; acc: 0.67
Batch: 240; loss: 1.42; acc: 0.55
Batch: 260; loss: 1.52; acc: 0.52
Batch: 280; loss: 1.14; acc: 0.62
Batch: 300; loss: 1.5; acc: 0.52
Batch: 320; loss: 1.31; acc: 0.58
Batch: 340; loss: 1.67; acc: 0.48
Batch: 360; loss: 1.2; acc: 0.61
Batch: 380; loss: 1.38; acc: 0.55
Batch: 400; loss: 1.61; acc: 0.53
Batch: 420; loss: 1.08; acc: 0.56
Batch: 440; loss: 1.58; acc: 0.5
Batch: 460; loss: 1.29; acc: 0.58
Batch: 480; loss: 1.34; acc: 0.48
Batch: 500; loss: 1.63; acc: 0.38
Batch: 520; loss: 1.34; acc: 0.58
Batch: 540; loss: 1.53; acc: 0.34
Batch: 560; loss: 1.48; acc: 0.56
Batch: 580; loss: 1.45; acc: 0.59
Batch: 600; loss: 1.5; acc: 0.53
Batch: 620; loss: 1.63; acc: 0.41
Batch: 640; loss: 1.56; acc: 0.5
Batch: 660; loss: 1.32; acc: 0.53
Batch: 680; loss: 1.42; acc: 0.53
Batch: 700; loss: 1.34; acc: 0.5
Batch: 720; loss: 1.43; acc: 0.5
Batch: 740; loss: 1.36; acc: 0.58
Batch: 760; loss: 1.31; acc: 0.53
Batch: 780; loss: 1.32; acc: 0.52
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.49; acc: 0.52
Batch: 40; loss: 1.13; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.55
Batch: 100; loss: 1.34; acc: 0.61
Batch: 120; loss: 1.66; acc: 0.48
Batch: 140; loss: 1.12; acc: 0.62
Val Epoch over. val_loss: 1.3459637358689764; val_accuracy: 0.5515525477707006 

The current subspace-distance is: 0.00012479705037549138 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.41; acc: 0.48
Batch: 20; loss: 1.33; acc: 0.55
Batch: 40; loss: 1.59; acc: 0.45
Batch: 60; loss: 1.49; acc: 0.48
Batch: 80; loss: 1.39; acc: 0.58
Batch: 100; loss: 1.49; acc: 0.53
Batch: 120; loss: 1.3; acc: 0.62
Batch: 140; loss: 1.49; acc: 0.53
Batch: 160; loss: 1.36; acc: 0.62
Batch: 180; loss: 1.42; acc: 0.55
Batch: 200; loss: 1.34; acc: 0.53
Batch: 220; loss: 1.31; acc: 0.53
Batch: 240; loss: 1.53; acc: 0.52
Batch: 260; loss: 1.57; acc: 0.47
Batch: 280; loss: 1.2; acc: 0.58
Batch: 300; loss: 1.25; acc: 0.58
Batch: 320; loss: 1.35; acc: 0.56
Batch: 340; loss: 1.44; acc: 0.58
Batch: 360; loss: 1.32; acc: 0.5
Batch: 380; loss: 1.44; acc: 0.58
Batch: 400; loss: 1.36; acc: 0.55
Batch: 420; loss: 1.23; acc: 0.58
Batch: 440; loss: 1.67; acc: 0.45
Batch: 460; loss: 1.46; acc: 0.5
Batch: 480; loss: 1.36; acc: 0.53
Batch: 500; loss: 1.32; acc: 0.45
Batch: 520; loss: 1.34; acc: 0.55
Batch: 540; loss: 1.24; acc: 0.56
Batch: 560; loss: 1.48; acc: 0.47
Batch: 580; loss: 1.26; acc: 0.56
Batch: 600; loss: 1.31; acc: 0.61
Batch: 620; loss: 1.31; acc: 0.5
Batch: 640; loss: 1.33; acc: 0.56
Batch: 660; loss: 1.07; acc: 0.61
Batch: 680; loss: 1.33; acc: 0.52
Batch: 700; loss: 1.56; acc: 0.42
Batch: 720; loss: 1.36; acc: 0.55
Batch: 740; loss: 1.28; acc: 0.66
Batch: 760; loss: 1.14; acc: 0.55
Batch: 780; loss: 1.6; acc: 0.42
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.49; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.67
Batch: 60; loss: 1.05; acc: 0.58
Batch: 80; loss: 1.24; acc: 0.53
Batch: 100; loss: 1.33; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.12; acc: 0.64
Val Epoch over. val_loss: 1.3479671341598414; val_accuracy: 0.5485668789808917 

The current subspace-distance is: 0.00012158301251474768 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.23; acc: 0.56
Batch: 20; loss: 1.47; acc: 0.53
Batch: 40; loss: 1.34; acc: 0.52
Batch: 60; loss: 1.37; acc: 0.55
Batch: 80; loss: 1.47; acc: 0.52
Batch: 100; loss: 1.5; acc: 0.44
Batch: 120; loss: 1.69; acc: 0.48
Batch: 140; loss: 1.22; acc: 0.58
Batch: 160; loss: 1.21; acc: 0.59
Batch: 180; loss: 1.51; acc: 0.5
Batch: 200; loss: 1.22; acc: 0.55
Batch: 220; loss: 1.37; acc: 0.55
Batch: 240; loss: 1.63; acc: 0.53
Batch: 260; loss: 1.39; acc: 0.53
Batch: 280; loss: 1.39; acc: 0.55
Batch: 300; loss: 1.33; acc: 0.5
Batch: 320; loss: 1.44; acc: 0.5
Batch: 340; loss: 1.22; acc: 0.58
Batch: 360; loss: 1.42; acc: 0.58
Batch: 380; loss: 1.27; acc: 0.5
Batch: 400; loss: 1.38; acc: 0.53
Batch: 420; loss: 1.45; acc: 0.5
Batch: 440; loss: 1.26; acc: 0.53
Batch: 460; loss: 1.34; acc: 0.52
Batch: 480; loss: 1.27; acc: 0.64
Batch: 500; loss: 1.27; acc: 0.53
Batch: 520; loss: 1.35; acc: 0.59
Batch: 540; loss: 1.36; acc: 0.56
Batch: 560; loss: 1.13; acc: 0.61
Batch: 580; loss: 1.71; acc: 0.45
Batch: 600; loss: 1.6; acc: 0.41
Batch: 620; loss: 1.49; acc: 0.47
Batch: 640; loss: 1.26; acc: 0.56
Batch: 660; loss: 1.55; acc: 0.53
Batch: 680; loss: 1.48; acc: 0.55
Batch: 700; loss: 1.47; acc: 0.48
Batch: 720; loss: 1.58; acc: 0.5
Batch: 740; loss: 1.61; acc: 0.39
Batch: 760; loss: 1.43; acc: 0.55
Batch: 780; loss: 1.4; acc: 0.47
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.5; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.58
Batch: 80; loss: 1.24; acc: 0.55
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.62
Val Epoch over. val_loss: 1.348997086096721; val_accuracy: 0.5474721337579618 

The current subspace-distance is: 0.000124053331092 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.44; acc: 0.52
Batch: 20; loss: 1.43; acc: 0.59
Batch: 40; loss: 1.34; acc: 0.61
Batch: 60; loss: 1.29; acc: 0.61
Batch: 80; loss: 1.57; acc: 0.5
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 1.3; acc: 0.55
Batch: 140; loss: 1.15; acc: 0.59
Batch: 160; loss: 1.22; acc: 0.61
Batch: 180; loss: 1.24; acc: 0.64
Batch: 200; loss: 1.24; acc: 0.52
Batch: 220; loss: 1.34; acc: 0.55
Batch: 240; loss: 1.43; acc: 0.56
Batch: 260; loss: 1.25; acc: 0.56
Batch: 280; loss: 1.47; acc: 0.48
Batch: 300; loss: 1.36; acc: 0.56
Batch: 320; loss: 1.26; acc: 0.59
Batch: 340; loss: 1.24; acc: 0.59
Batch: 360; loss: 1.28; acc: 0.62
Batch: 380; loss: 1.52; acc: 0.47
Batch: 400; loss: 1.46; acc: 0.56
Batch: 420; loss: 1.38; acc: 0.48
Batch: 440; loss: 1.53; acc: 0.47
Batch: 460; loss: 1.28; acc: 0.58
Batch: 480; loss: 1.54; acc: 0.53
Batch: 500; loss: 1.35; acc: 0.52
Batch: 520; loss: 1.51; acc: 0.42
Batch: 540; loss: 1.32; acc: 0.56
Batch: 560; loss: 1.19; acc: 0.58
Batch: 580; loss: 1.24; acc: 0.64
Batch: 600; loss: 1.45; acc: 0.5
Batch: 620; loss: 1.52; acc: 0.48
Batch: 640; loss: 1.39; acc: 0.55
Batch: 660; loss: 1.28; acc: 0.58
Batch: 680; loss: 1.43; acc: 0.5
Batch: 700; loss: 1.37; acc: 0.55
Batch: 720; loss: 1.45; acc: 0.55
Batch: 740; loss: 1.42; acc: 0.5
Batch: 760; loss: 1.32; acc: 0.59
Batch: 780; loss: 1.17; acc: 0.61
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.5; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.66
Batch: 60; loss: 1.05; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.56
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.64
Val Epoch over. val_loss: 1.34708954308443; val_accuracy: 0.5507563694267515 

The current subspace-distance is: 0.00012497753778006881 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.53
Batch: 40; loss: 1.25; acc: 0.58
Batch: 60; loss: 1.21; acc: 0.64
Batch: 80; loss: 1.0; acc: 0.69
Batch: 100; loss: 1.44; acc: 0.52
Batch: 120; loss: 1.29; acc: 0.55
Batch: 140; loss: 1.49; acc: 0.52
Batch: 160; loss: 1.44; acc: 0.55
Batch: 180; loss: 1.53; acc: 0.56
Batch: 200; loss: 1.21; acc: 0.66
Batch: 220; loss: 1.47; acc: 0.47
Batch: 240; loss: 1.28; acc: 0.61
Batch: 260; loss: 1.35; acc: 0.52
Batch: 280; loss: 1.3; acc: 0.52
Batch: 300; loss: 1.26; acc: 0.56
Batch: 320; loss: 1.1; acc: 0.67
Batch: 340; loss: 1.31; acc: 0.53
Batch: 360; loss: 1.2; acc: 0.61
Batch: 380; loss: 1.26; acc: 0.55
Batch: 400; loss: 1.52; acc: 0.47
Batch: 420; loss: 1.4; acc: 0.52
Batch: 440; loss: 1.45; acc: 0.47
Batch: 460; loss: 1.24; acc: 0.59
Batch: 480; loss: 1.38; acc: 0.5
Batch: 500; loss: 1.25; acc: 0.55
Batch: 520; loss: 1.5; acc: 0.47
Batch: 540; loss: 1.4; acc: 0.53
Batch: 560; loss: 1.48; acc: 0.58
Batch: 580; loss: 1.34; acc: 0.5
Batch: 600; loss: 1.45; acc: 0.48
Batch: 620; loss: 1.25; acc: 0.53
Batch: 640; loss: 1.11; acc: 0.61
Batch: 660; loss: 1.29; acc: 0.58
Batch: 680; loss: 1.38; acc: 0.52
Batch: 700; loss: 1.45; acc: 0.48
Batch: 720; loss: 1.52; acc: 0.53
Batch: 740; loss: 1.07; acc: 0.59
Batch: 760; loss: 1.57; acc: 0.55
Batch: 780; loss: 1.4; acc: 0.52
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.55
Batch: 20; loss: 1.49; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.66
Batch: 60; loss: 1.06; acc: 0.62
Batch: 80; loss: 1.23; acc: 0.53
Batch: 100; loss: 1.34; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.12; acc: 0.62
Val Epoch over. val_loss: 1.3458088454167554; val_accuracy: 0.5493630573248408 

The current subspace-distance is: 0.00012411977513693273 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.18; acc: 0.67
Batch: 20; loss: 1.33; acc: 0.56
Batch: 40; loss: 1.54; acc: 0.5
Batch: 60; loss: 1.32; acc: 0.53
Batch: 80; loss: 1.46; acc: 0.41
Batch: 100; loss: 1.45; acc: 0.5
Batch: 120; loss: 1.24; acc: 0.62
Batch: 140; loss: 1.4; acc: 0.53
Batch: 160; loss: 1.28; acc: 0.56
Batch: 180; loss: 1.24; acc: 0.59
Batch: 200; loss: 1.39; acc: 0.5
Batch: 220; loss: 1.52; acc: 0.48
Batch: 240; loss: 1.44; acc: 0.52
Batch: 260; loss: 1.52; acc: 0.5
Batch: 280; loss: 1.3; acc: 0.66
Batch: 300; loss: 1.32; acc: 0.61
Batch: 320; loss: 1.46; acc: 0.53
Batch: 340; loss: 1.55; acc: 0.48
Batch: 360; loss: 1.72; acc: 0.47
Batch: 380; loss: 1.36; acc: 0.58
Batch: 400; loss: 1.66; acc: 0.44
Batch: 420; loss: 1.51; acc: 0.47
Batch: 440; loss: 1.46; acc: 0.5
Batch: 460; loss: 1.36; acc: 0.58
Batch: 480; loss: 1.53; acc: 0.56
Batch: 500; loss: 1.59; acc: 0.45
Batch: 520; loss: 1.45; acc: 0.5
Batch: 540; loss: 1.44; acc: 0.53
Batch: 560; loss: 1.55; acc: 0.47
Batch: 580; loss: 1.66; acc: 0.44
Batch: 600; loss: 1.42; acc: 0.53
Batch: 620; loss: 1.41; acc: 0.5
Batch: 640; loss: 1.12; acc: 0.59
Batch: 660; loss: 1.44; acc: 0.5
Batch: 680; loss: 1.12; acc: 0.66
Batch: 700; loss: 1.49; acc: 0.47
Batch: 720; loss: 1.32; acc: 0.56
Batch: 740; loss: 1.17; acc: 0.62
Batch: 760; loss: 1.2; acc: 0.58
Batch: 780; loss: 1.13; acc: 0.59
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.56
Batch: 20; loss: 1.49; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.69
Batch: 60; loss: 1.06; acc: 0.59
Batch: 80; loss: 1.24; acc: 0.53
Batch: 100; loss: 1.34; acc: 0.61
Batch: 120; loss: 1.65; acc: 0.5
Batch: 140; loss: 1.12; acc: 0.64
Val Epoch over. val_loss: 1.3471317454508156; val_accuracy: 0.5485668789808917 

The current subspace-distance is: 0.00012213511217851192 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.18; acc: 0.61
Batch: 20; loss: 1.52; acc: 0.5
Batch: 40; loss: 1.37; acc: 0.52
Batch: 60; loss: 1.72; acc: 0.41
Batch: 80; loss: 1.49; acc: 0.48
Batch: 100; loss: 1.3; acc: 0.62
Batch: 120; loss: 1.37; acc: 0.48
Batch: 140; loss: 1.43; acc: 0.47
Batch: 160; loss: 1.49; acc: 0.52
Batch: 180; loss: 1.43; acc: 0.55
Batch: 200; loss: 1.26; acc: 0.62
Batch: 220; loss: 1.35; acc: 0.58
Batch: 240; loss: 1.59; acc: 0.44
Batch: 260; loss: 1.37; acc: 0.52
Batch: 280; loss: 1.47; acc: 0.5
Batch: 300; loss: 1.24; acc: 0.61
Batch: 320; loss: 1.11; acc: 0.62
Batch: 340; loss: 1.49; acc: 0.55
Batch: 360; loss: 1.3; acc: 0.56
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.34; acc: 0.59
Batch: 420; loss: 1.46; acc: 0.55
Batch: 440; loss: 1.65; acc: 0.42
Batch: 460; loss: 1.14; acc: 0.55
Batch: 480; loss: 1.31; acc: 0.55
Batch: 500; loss: 1.46; acc: 0.5
Batch: 520; loss: 1.45; acc: 0.59
Batch: 540; loss: 1.17; acc: 0.5
Batch: 560; loss: 1.49; acc: 0.47
Batch: 580; loss: 1.59; acc: 0.45
Batch: 600; loss: 1.41; acc: 0.53
Batch: 620; loss: 1.28; acc: 0.53
Batch: 640; loss: 1.23; acc: 0.58
Batch: 660; loss: 1.38; acc: 0.55
Batch: 680; loss: 1.5; acc: 0.48
Batch: 700; loss: 1.5; acc: 0.47
Batch: 720; loss: 1.58; acc: 0.5
Batch: 740; loss: 1.28; acc: 0.61
Batch: 760; loss: 1.41; acc: 0.5
Batch: 780; loss: 1.53; acc: 0.45
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.55
Batch: 20; loss: 1.49; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.61
Batch: 80; loss: 1.24; acc: 0.53
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.12; acc: 0.61
Val Epoch over. val_loss: 1.3464784413386301; val_accuracy: 0.5494625796178344 

The current subspace-distance is: 0.00012445189349818975 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.33; acc: 0.56
Batch: 20; loss: 1.34; acc: 0.55
Batch: 40; loss: 1.43; acc: 0.59
Batch: 60; loss: 1.38; acc: 0.48
Batch: 80; loss: 1.35; acc: 0.52
Batch: 100; loss: 1.32; acc: 0.52
Batch: 120; loss: 1.35; acc: 0.61
Batch: 140; loss: 1.54; acc: 0.45
Batch: 160; loss: 1.51; acc: 0.45
Batch: 180; loss: 1.34; acc: 0.58
Batch: 200; loss: 1.43; acc: 0.48
Batch: 220; loss: 1.41; acc: 0.55
Batch: 240; loss: 1.57; acc: 0.52
Batch: 260; loss: 1.38; acc: 0.52
Batch: 280; loss: 1.15; acc: 0.64
Batch: 300; loss: 1.56; acc: 0.47
Batch: 320; loss: 1.56; acc: 0.5
Batch: 340; loss: 1.26; acc: 0.64
Batch: 360; loss: 1.53; acc: 0.48
Batch: 380; loss: 1.29; acc: 0.59
Batch: 400; loss: 1.46; acc: 0.53
Batch: 420; loss: 1.36; acc: 0.55
Batch: 440; loss: 1.4; acc: 0.52
Batch: 460; loss: 1.6; acc: 0.45
Batch: 480; loss: 1.5; acc: 0.5
Batch: 500; loss: 1.42; acc: 0.53
Batch: 520; loss: 1.37; acc: 0.53
Batch: 540; loss: 1.45; acc: 0.58
Batch: 560; loss: 1.51; acc: 0.48
Batch: 580; loss: 1.28; acc: 0.52
Batch: 600; loss: 1.39; acc: 0.59
Batch: 620; loss: 1.33; acc: 0.56
Batch: 640; loss: 1.25; acc: 0.53
Batch: 660; loss: 1.57; acc: 0.44
Batch: 680; loss: 1.43; acc: 0.5
Batch: 700; loss: 1.37; acc: 0.55
Batch: 720; loss: 1.53; acc: 0.48
Batch: 740; loss: 1.55; acc: 0.55
Batch: 760; loss: 1.26; acc: 0.52
Batch: 780; loss: 1.56; acc: 0.42
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.35; acc: 0.58
Batch: 20; loss: 1.5; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.56
Batch: 80; loss: 1.24; acc: 0.55
Batch: 100; loss: 1.34; acc: 0.59
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.62
Val Epoch over. val_loss: 1.348028381918646; val_accuracy: 0.5485668789808917 

The current subspace-distance is: 0.0001267797197215259 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.3; acc: 0.58
Batch: 20; loss: 1.33; acc: 0.52
Batch: 40; loss: 1.57; acc: 0.5
Batch: 60; loss: 1.41; acc: 0.56
Batch: 80; loss: 1.26; acc: 0.58
Batch: 100; loss: 1.38; acc: 0.56
Batch: 120; loss: 1.48; acc: 0.5
Batch: 140; loss: 1.35; acc: 0.5
Batch: 160; loss: 1.58; acc: 0.36
Batch: 180; loss: 1.38; acc: 0.55
Batch: 200; loss: 1.3; acc: 0.53
Batch: 220; loss: 1.36; acc: 0.55
Batch: 240; loss: 1.4; acc: 0.55
Batch: 260; loss: 1.51; acc: 0.38
Batch: 280; loss: 1.41; acc: 0.5
Batch: 300; loss: 1.32; acc: 0.56
Batch: 320; loss: 1.47; acc: 0.47
Batch: 340; loss: 1.24; acc: 0.61
Batch: 360; loss: 1.66; acc: 0.39
Batch: 380; loss: 1.54; acc: 0.47
Batch: 400; loss: 1.41; acc: 0.44
Batch: 420; loss: 1.71; acc: 0.44
Batch: 440; loss: 1.38; acc: 0.58
Batch: 460; loss: 1.25; acc: 0.52
Batch: 480; loss: 1.39; acc: 0.53
Batch: 500; loss: 1.25; acc: 0.61
Batch: 520; loss: 1.47; acc: 0.5
Batch: 540; loss: 1.44; acc: 0.52
Batch: 560; loss: 1.63; acc: 0.44
Batch: 580; loss: 1.47; acc: 0.47
Batch: 600; loss: 1.52; acc: 0.45
Batch: 620; loss: 1.31; acc: 0.55
Batch: 640; loss: 1.42; acc: 0.56
Batch: 660; loss: 1.34; acc: 0.58
Batch: 680; loss: 1.16; acc: 0.64
Batch: 700; loss: 1.4; acc: 0.62
Batch: 720; loss: 1.57; acc: 0.45
Batch: 740; loss: 1.5; acc: 0.55
Batch: 760; loss: 1.42; acc: 0.53
Batch: 780; loss: 1.48; acc: 0.5
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.5; acc: 0.53
Batch: 40; loss: 1.11; acc: 0.67
Batch: 60; loss: 1.05; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.56
Batch: 100; loss: 1.33; acc: 0.59
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.62
Val Epoch over. val_loss: 1.3476084265739294; val_accuracy: 0.5489649681528662 

The current subspace-distance is: 0.00012935265840496868 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.19; acc: 0.55
Batch: 20; loss: 1.54; acc: 0.48
Batch: 40; loss: 1.41; acc: 0.48
Batch: 60; loss: 1.55; acc: 0.48
Batch: 80; loss: 1.44; acc: 0.58
Batch: 100; loss: 1.33; acc: 0.61
Batch: 120; loss: 1.38; acc: 0.48
Batch: 140; loss: 1.18; acc: 0.61
Batch: 160; loss: 1.39; acc: 0.48
Batch: 180; loss: 1.54; acc: 0.45
Batch: 200; loss: 1.69; acc: 0.48
Batch: 220; loss: 1.48; acc: 0.53
Batch: 240; loss: 1.39; acc: 0.58
Batch: 260; loss: 1.12; acc: 0.67
Batch: 280; loss: 1.43; acc: 0.52
Batch: 300; loss: 1.65; acc: 0.52
Batch: 320; loss: 1.42; acc: 0.59
Batch: 340; loss: 1.44; acc: 0.5
Batch: 360; loss: 1.28; acc: 0.53
Batch: 380; loss: 1.36; acc: 0.48
Batch: 400; loss: 1.73; acc: 0.38
Batch: 420; loss: 1.32; acc: 0.58
Batch: 440; loss: 1.66; acc: 0.41
Batch: 460; loss: 1.5; acc: 0.48
Batch: 480; loss: 1.4; acc: 0.53
Batch: 500; loss: 1.53; acc: 0.44
Batch: 520; loss: 1.57; acc: 0.41
Batch: 540; loss: 1.55; acc: 0.47
Batch: 560; loss: 1.5; acc: 0.39
Batch: 580; loss: 1.64; acc: 0.47
Batch: 600; loss: 1.6; acc: 0.38
Batch: 620; loss: 1.24; acc: 0.59
Batch: 640; loss: 1.44; acc: 0.56
Batch: 660; loss: 1.34; acc: 0.62
Batch: 680; loss: 1.4; acc: 0.58
Batch: 700; loss: 1.72; acc: 0.41
Batch: 720; loss: 1.2; acc: 0.62
Batch: 740; loss: 1.22; acc: 0.59
Batch: 760; loss: 1.33; acc: 0.5
Batch: 780; loss: 1.07; acc: 0.67
Train Epoch over. train_loss: 1.4; train_accuracy: 0.53 

Batch: 0; loss: 1.34; acc: 0.56
Batch: 20; loss: 1.49; acc: 0.5
Batch: 40; loss: 1.12; acc: 0.67
Batch: 60; loss: 1.06; acc: 0.59
Batch: 80; loss: 1.22; acc: 0.56
Batch: 100; loss: 1.34; acc: 0.58
Batch: 120; loss: 1.65; acc: 0.48
Batch: 140; loss: 1.12; acc: 0.61
Val Epoch over. val_loss: 1.3448900086864544; val_accuracy: 0.5510549363057324 

The current subspace-distance is: 0.00013280774874147028 

plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 20835
elements in E: 4395200
fraction nonzero: 0.0047403986166727335
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.35; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.31; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.19
Batch: 100; loss: 2.26; acc: 0.14
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.25; acc: 0.22
Batch: 160; loss: 2.26; acc: 0.2
Batch: 180; loss: 2.27; acc: 0.14
Batch: 200; loss: 2.26; acc: 0.19
Batch: 220; loss: 2.27; acc: 0.09
Batch: 240; loss: 2.23; acc: 0.23
Batch: 260; loss: 2.23; acc: 0.25
Batch: 280; loss: 2.21; acc: 0.23
Batch: 300; loss: 2.23; acc: 0.22
Batch: 320; loss: 2.16; acc: 0.34
Batch: 340; loss: 2.12; acc: 0.39
Batch: 360; loss: 2.19; acc: 0.3
Batch: 380; loss: 2.23; acc: 0.16
Batch: 400; loss: 2.13; acc: 0.42
Batch: 420; loss: 2.17; acc: 0.31
Batch: 440; loss: 2.17; acc: 0.23
Batch: 460; loss: 2.13; acc: 0.3
Batch: 480; loss: 2.03; acc: 0.36
Batch: 500; loss: 2.07; acc: 0.38
Batch: 520; loss: 1.95; acc: 0.42
Batch: 540; loss: 2.09; acc: 0.36
Batch: 560; loss: 2.11; acc: 0.28
Batch: 580; loss: 2.02; acc: 0.3
Batch: 600; loss: 1.89; acc: 0.39
Batch: 620; loss: 1.91; acc: 0.41
Batch: 640; loss: 1.92; acc: 0.36
Batch: 660; loss: 1.84; acc: 0.38
Batch: 680; loss: 1.92; acc: 0.34
Batch: 700; loss: 1.82; acc: 0.38
Batch: 720; loss: 1.77; acc: 0.39
Batch: 740; loss: 1.84; acc: 0.36
Batch: 760; loss: 1.86; acc: 0.45
Batch: 780; loss: 1.66; acc: 0.45
Train Epoch over. train_loss: 2.09; train_accuracy: 0.3 

Batch: 0; loss: 1.67; acc: 0.48
Batch: 20; loss: 1.81; acc: 0.41
Batch: 40; loss: 1.58; acc: 0.52
Batch: 60; loss: 1.54; acc: 0.58
Batch: 80; loss: 1.61; acc: 0.52
Batch: 100; loss: 1.66; acc: 0.44
Batch: 120; loss: 1.77; acc: 0.44
Batch: 140; loss: 1.71; acc: 0.52
Val Epoch over. val_loss: 1.717549185843984; val_accuracy: 0.4462579617834395 

The current subspace-distance is: 1.1703164091159124e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.7; acc: 0.47
Batch: 20; loss: 1.62; acc: 0.48
Batch: 40; loss: 1.76; acc: 0.41
Batch: 60; loss: 1.75; acc: 0.44
Batch: 80; loss: 1.63; acc: 0.52
Batch: 100; loss: 1.54; acc: 0.44
Batch: 120; loss: 1.63; acc: 0.47
Batch: 140; loss: 1.6; acc: 0.48
Batch: 160; loss: 1.7; acc: 0.42
Batch: 180; loss: 1.54; acc: 0.5
Batch: 200; loss: 1.66; acc: 0.44
Batch: 220; loss: 1.38; acc: 0.5
Batch: 240; loss: 1.38; acc: 0.53
Batch: 260; loss: 1.43; acc: 0.61
Batch: 280; loss: 1.58; acc: 0.62
Batch: 300; loss: 1.3; acc: 0.62
Batch: 320; loss: 1.29; acc: 0.53
Batch: 340; loss: 1.21; acc: 0.66
Batch: 360; loss: 1.23; acc: 0.59
Batch: 380; loss: 1.1; acc: 0.69
Batch: 400; loss: 1.47; acc: 0.48
Batch: 420; loss: 1.34; acc: 0.53
Batch: 440; loss: 1.3; acc: 0.58
Batch: 460; loss: 1.1; acc: 0.64
Batch: 480; loss: 1.2; acc: 0.62
Batch: 500; loss: 1.27; acc: 0.59
Batch: 520; loss: 1.1; acc: 0.69
Batch: 540; loss: 1.48; acc: 0.47
Batch: 560; loss: 1.25; acc: 0.52
Batch: 580; loss: 1.24; acc: 0.61
Batch: 600; loss: 1.28; acc: 0.56
Batch: 620; loss: 1.06; acc: 0.62
Batch: 640; loss: 1.08; acc: 0.64
Batch: 660; loss: 1.33; acc: 0.52
Batch: 680; loss: 0.93; acc: 0.77
Batch: 700; loss: 1.03; acc: 0.67
Batch: 720; loss: 1.48; acc: 0.55
Batch: 740; loss: 0.86; acc: 0.72
Batch: 760; loss: 1.28; acc: 0.56
Batch: 780; loss: 1.13; acc: 0.62
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.21; acc: 0.56
Batch: 40; loss: 0.98; acc: 0.66
Batch: 60; loss: 1.06; acc: 0.58
Batch: 80; loss: 1.07; acc: 0.62
Batch: 100; loss: 1.19; acc: 0.61
Batch: 120; loss: 1.32; acc: 0.62
Batch: 140; loss: 0.81; acc: 0.75
Val Epoch over. val_loss: 1.1701512925184456; val_accuracy: 0.597531847133758 

The current subspace-distance is: 2.345885513932444e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.05; acc: 0.66
Batch: 20; loss: 1.18; acc: 0.56
Batch: 40; loss: 1.22; acc: 0.55
Batch: 60; loss: 1.07; acc: 0.67
Batch: 80; loss: 1.01; acc: 0.66
Batch: 100; loss: 1.16; acc: 0.59
Batch: 120; loss: 1.08; acc: 0.61
Batch: 140; loss: 1.1; acc: 0.64
Batch: 160; loss: 1.36; acc: 0.52
Batch: 180; loss: 1.1; acc: 0.61
Batch: 200; loss: 1.14; acc: 0.62
Batch: 220; loss: 1.11; acc: 0.64
Batch: 240; loss: 1.33; acc: 0.56
Batch: 260; loss: 1.37; acc: 0.56
Batch: 280; loss: 1.02; acc: 0.69
Batch: 300; loss: 0.91; acc: 0.72
Batch: 320; loss: 1.16; acc: 0.66
Batch: 340; loss: 1.21; acc: 0.62
Batch: 360; loss: 1.14; acc: 0.56
Batch: 380; loss: 1.11; acc: 0.66
Batch: 400; loss: 0.95; acc: 0.72
Batch: 420; loss: 1.21; acc: 0.64
Batch: 440; loss: 0.98; acc: 0.72
Batch: 460; loss: 1.27; acc: 0.59
Batch: 480; loss: 0.89; acc: 0.69
Batch: 500; loss: 1.06; acc: 0.67
Batch: 520; loss: 0.98; acc: 0.64
Batch: 540; loss: 1.34; acc: 0.62
Batch: 560; loss: 0.8; acc: 0.72
Batch: 580; loss: 0.97; acc: 0.72
Batch: 600; loss: 1.24; acc: 0.5
Batch: 620; loss: 1.09; acc: 0.69
Batch: 640; loss: 1.1; acc: 0.66
Batch: 660; loss: 1.02; acc: 0.7
Batch: 680; loss: 0.94; acc: 0.7
Batch: 700; loss: 1.15; acc: 0.56
Batch: 720; loss: 1.2; acc: 0.66
Batch: 740; loss: 0.94; acc: 0.66
Batch: 760; loss: 1.29; acc: 0.69
Batch: 780; loss: 1.05; acc: 0.67
Train Epoch over. train_loss: 1.1; train_accuracy: 0.64 

Batch: 0; loss: 1.17; acc: 0.59
Batch: 20; loss: 1.24; acc: 0.55
Batch: 40; loss: 1.07; acc: 0.64
Batch: 60; loss: 1.17; acc: 0.62
Batch: 80; loss: 1.03; acc: 0.61
Batch: 100; loss: 1.32; acc: 0.55
Batch: 120; loss: 1.8; acc: 0.48
Batch: 140; loss: 0.88; acc: 0.67
Val Epoch over. val_loss: 1.2164565324783325; val_accuracy: 0.5917595541401274 

The current subspace-distance is: 3.339851173222996e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.24; acc: 0.59
Batch: 20; loss: 0.96; acc: 0.62
Batch: 40; loss: 1.15; acc: 0.75
Batch: 60; loss: 1.23; acc: 0.59
Batch: 80; loss: 0.84; acc: 0.72
Batch: 100; loss: 1.16; acc: 0.59
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 1.07; acc: 0.66
Batch: 160; loss: 1.02; acc: 0.73
Batch: 180; loss: 0.89; acc: 0.75
Batch: 200; loss: 0.97; acc: 0.7
Batch: 220; loss: 1.07; acc: 0.62
Batch: 240; loss: 1.1; acc: 0.64
Batch: 260; loss: 1.03; acc: 0.61
Batch: 280; loss: 1.17; acc: 0.62
Batch: 300; loss: 0.72; acc: 0.77
Batch: 320; loss: 0.9; acc: 0.69
Batch: 340; loss: 0.86; acc: 0.69
Batch: 360; loss: 0.93; acc: 0.73
Batch: 380; loss: 0.88; acc: 0.7
Batch: 400; loss: 1.01; acc: 0.73
Batch: 420; loss: 1.05; acc: 0.62
Batch: 440; loss: 1.19; acc: 0.55
Batch: 460; loss: 0.9; acc: 0.67
Batch: 480; loss: 0.98; acc: 0.66
Batch: 500; loss: 1.09; acc: 0.7
Batch: 520; loss: 1.27; acc: 0.58
Batch: 540; loss: 1.14; acc: 0.67
Batch: 560; loss: 0.85; acc: 0.73
Batch: 580; loss: 1.08; acc: 0.73
Batch: 600; loss: 1.34; acc: 0.61
Batch: 620; loss: 1.27; acc: 0.64
Batch: 640; loss: 0.84; acc: 0.72
Batch: 660; loss: 1.02; acc: 0.67
Batch: 680; loss: 0.92; acc: 0.77
Batch: 700; loss: 1.15; acc: 0.64
Batch: 720; loss: 1.04; acc: 0.7
Batch: 740; loss: 0.85; acc: 0.72
Batch: 760; loss: 0.99; acc: 0.69
Batch: 780; loss: 1.13; acc: 0.66
Train Epoch over. train_loss: 1.01; train_accuracy: 0.67 

Batch: 0; loss: 1.12; acc: 0.62
Batch: 20; loss: 1.18; acc: 0.59
Batch: 40; loss: 0.82; acc: 0.78
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 1.14; acc: 0.66
Batch: 100; loss: 0.89; acc: 0.64
Batch: 120; loss: 1.43; acc: 0.55
Batch: 140; loss: 0.7; acc: 0.8
Val Epoch over. val_loss: 1.1209576631047924; val_accuracy: 0.6468949044585988 

The current subspace-distance is: 4.244232695782557e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.08; acc: 0.64
Batch: 20; loss: 0.91; acc: 0.75
Batch: 40; loss: 0.9; acc: 0.72
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 1.17; acc: 0.62
Batch: 100; loss: 1.0; acc: 0.67
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.94; acc: 0.67
Batch: 160; loss: 1.06; acc: 0.62
Batch: 180; loss: 1.08; acc: 0.67
Batch: 200; loss: 1.12; acc: 0.61
Batch: 220; loss: 0.81; acc: 0.78
Batch: 240; loss: 1.03; acc: 0.62
Batch: 260; loss: 0.86; acc: 0.67
Batch: 280; loss: 1.08; acc: 0.61
Batch: 300; loss: 0.85; acc: 0.8
Batch: 320; loss: 1.27; acc: 0.61
Batch: 340; loss: 1.28; acc: 0.55
Batch: 360; loss: 1.05; acc: 0.67
Batch: 380; loss: 0.97; acc: 0.69
Batch: 400; loss: 0.89; acc: 0.72
Batch: 420; loss: 0.84; acc: 0.77
Batch: 440; loss: 0.95; acc: 0.7
Batch: 460; loss: 0.98; acc: 0.64
Batch: 480; loss: 1.01; acc: 0.77
Batch: 500; loss: 1.16; acc: 0.66
Batch: 520; loss: 0.99; acc: 0.61
Batch: 540; loss: 0.74; acc: 0.72
Batch: 560; loss: 0.78; acc: 0.73
Batch: 580; loss: 0.89; acc: 0.7
Batch: 600; loss: 0.78; acc: 0.77
Batch: 620; loss: 1.01; acc: 0.66
Batch: 640; loss: 0.89; acc: 0.77
Batch: 660; loss: 0.97; acc: 0.64
Batch: 680; loss: 0.98; acc: 0.69
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.96; acc: 0.72
Batch: 740; loss: 1.04; acc: 0.67
Batch: 760; loss: 0.78; acc: 0.77
Batch: 780; loss: 0.99; acc: 0.73
Train Epoch over. train_loss: 0.99; train_accuracy: 0.68 

Batch: 0; loss: 1.03; acc: 0.66
Batch: 20; loss: 1.12; acc: 0.58
Batch: 40; loss: 0.94; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 0.99; acc: 0.62
Batch: 100; loss: 0.94; acc: 0.58
Batch: 120; loss: 1.37; acc: 0.56
Batch: 140; loss: 0.76; acc: 0.75
Val Epoch over. val_loss: 1.1471877648572253; val_accuracy: 0.6271894904458599 

The current subspace-distance is: 5.0562746764626354e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.17; acc: 0.64
Batch: 20; loss: 1.0; acc: 0.66
Batch: 40; loss: 1.29; acc: 0.59
Batch: 60; loss: 1.14; acc: 0.61
Batch: 80; loss: 1.04; acc: 0.75
Batch: 100; loss: 1.15; acc: 0.58
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 1.11; acc: 0.61
Batch: 160; loss: 0.95; acc: 0.62
Batch: 180; loss: 1.08; acc: 0.66
Batch: 200; loss: 0.85; acc: 0.7
Batch: 220; loss: 0.93; acc: 0.64
Batch: 240; loss: 0.82; acc: 0.77
Batch: 260; loss: 0.97; acc: 0.67
Batch: 280; loss: 1.08; acc: 0.64
Batch: 300; loss: 0.97; acc: 0.66
Batch: 320; loss: 1.04; acc: 0.69
Batch: 340; loss: 1.1; acc: 0.64
Batch: 360; loss: 1.03; acc: 0.69
Batch: 380; loss: 0.8; acc: 0.73
Batch: 400; loss: 1.0; acc: 0.75
Batch: 420; loss: 0.84; acc: 0.77
Batch: 440; loss: 0.8; acc: 0.78
Batch: 460; loss: 0.62; acc: 0.8
Batch: 480; loss: 0.86; acc: 0.7
Batch: 500; loss: 1.23; acc: 0.66
Batch: 520; loss: 0.84; acc: 0.78
Batch: 540; loss: 0.78; acc: 0.78
Batch: 560; loss: 1.1; acc: 0.61
Batch: 580; loss: 0.84; acc: 0.66
Batch: 600; loss: 0.94; acc: 0.72
Batch: 620; loss: 0.7; acc: 0.73
Batch: 640; loss: 0.93; acc: 0.7
Batch: 660; loss: 1.09; acc: 0.69
Batch: 680; loss: 0.97; acc: 0.7
Batch: 700; loss: 0.86; acc: 0.67
Batch: 720; loss: 0.84; acc: 0.67
Batch: 740; loss: 0.99; acc: 0.69
Batch: 760; loss: 1.07; acc: 0.67
Batch: 780; loss: 0.9; acc: 0.72
Train Epoch over. train_loss: 0.97; train_accuracy: 0.69 

Batch: 0; loss: 1.04; acc: 0.69
Batch: 20; loss: 1.07; acc: 0.64
Batch: 40; loss: 0.92; acc: 0.77
Batch: 60; loss: 1.0; acc: 0.66
Batch: 80; loss: 0.88; acc: 0.7
Batch: 100; loss: 0.95; acc: 0.67
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 0.65; acc: 0.81
Val Epoch over. val_loss: 1.036008182984249; val_accuracy: 0.6552547770700637 

The current subspace-distance is: 5.4013329645385966e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.06; acc: 0.7
Batch: 20; loss: 0.85; acc: 0.75
Batch: 40; loss: 1.17; acc: 0.61
Batch: 60; loss: 0.7; acc: 0.75
Batch: 80; loss: 0.83; acc: 0.78
Batch: 100; loss: 1.07; acc: 0.62
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 1.0; acc: 0.62
Batch: 160; loss: 0.8; acc: 0.77
Batch: 180; loss: 1.1; acc: 0.62
Batch: 200; loss: 1.19; acc: 0.64
Batch: 220; loss: 1.34; acc: 0.53
Batch: 240; loss: 1.02; acc: 0.64
Batch: 260; loss: 0.96; acc: 0.64
Batch: 280; loss: 0.89; acc: 0.72
Batch: 300; loss: 0.97; acc: 0.73
Batch: 320; loss: 1.1; acc: 0.64
Batch: 340; loss: 1.22; acc: 0.61
Batch: 360; loss: 1.06; acc: 0.69
Batch: 380; loss: 1.13; acc: 0.73
Batch: 400; loss: 1.02; acc: 0.64
Batch: 420; loss: 0.91; acc: 0.66
Batch: 440; loss: 1.14; acc: 0.62
Batch: 460; loss: 0.95; acc: 0.77
Batch: 480; loss: 1.1; acc: 0.66
Batch: 500; loss: 0.94; acc: 0.66
Batch: 520; loss: 1.19; acc: 0.67
Batch: 540; loss: 0.94; acc: 0.75
Batch: 560; loss: 0.85; acc: 0.75
Batch: 580; loss: 1.11; acc: 0.66
Batch: 600; loss: 1.1; acc: 0.67
Batch: 620; loss: 0.9; acc: 0.75
Batch: 640; loss: 0.94; acc: 0.72
Batch: 660; loss: 0.79; acc: 0.73
Batch: 680; loss: 0.94; acc: 0.72
Batch: 700; loss: 0.81; acc: 0.77
Batch: 720; loss: 0.88; acc: 0.75
Batch: 740; loss: 0.9; acc: 0.7
Batch: 760; loss: 1.14; acc: 0.64
Batch: 780; loss: 1.03; acc: 0.72
Train Epoch over. train_loss: 0.96; train_accuracy: 0.7 

Batch: 0; loss: 0.9; acc: 0.77
Batch: 20; loss: 0.83; acc: 0.78
Batch: 40; loss: 0.81; acc: 0.75
Batch: 60; loss: 0.94; acc: 0.62
Batch: 80; loss: 0.91; acc: 0.73
Batch: 100; loss: 0.86; acc: 0.7
Batch: 120; loss: 1.11; acc: 0.64
Batch: 140; loss: 0.57; acc: 0.84
Val Epoch over. val_loss: 0.9072072885598347; val_accuracy: 0.7125796178343949 

The current subspace-distance is: 5.9141075325896963e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.8; acc: 0.81
Batch: 40; loss: 1.0; acc: 0.7
Batch: 60; loss: 0.98; acc: 0.75
Batch: 80; loss: 1.09; acc: 0.67
Batch: 100; loss: 1.08; acc: 0.67
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 0.79; acc: 0.8
Batch: 160; loss: 1.01; acc: 0.67
Batch: 180; loss: 1.04; acc: 0.64
Batch: 200; loss: 0.85; acc: 0.75
Batch: 220; loss: 0.73; acc: 0.83
Batch: 240; loss: 0.93; acc: 0.72
Batch: 260; loss: 0.94; acc: 0.7
Batch: 280; loss: 0.97; acc: 0.7
Batch: 300; loss: 1.11; acc: 0.61
Batch: 320; loss: 0.79; acc: 0.72
Batch: 340; loss: 0.93; acc: 0.61
Batch: 360; loss: 0.73; acc: 0.8
Batch: 380; loss: 1.25; acc: 0.66
Batch: 400; loss: 0.89; acc: 0.7
Batch: 420; loss: 1.14; acc: 0.59
Batch: 440; loss: 1.05; acc: 0.66
Batch: 460; loss: 0.86; acc: 0.67
Batch: 480; loss: 0.97; acc: 0.69
Batch: 500; loss: 0.77; acc: 0.73
Batch: 520; loss: 0.98; acc: 0.66
Batch: 540; loss: 0.81; acc: 0.77
Batch: 560; loss: 1.01; acc: 0.7
Batch: 580; loss: 0.76; acc: 0.7
Batch: 600; loss: 1.18; acc: 0.59
Batch: 620; loss: 0.82; acc: 0.69
Batch: 640; loss: 1.07; acc: 0.67
Batch: 660; loss: 0.78; acc: 0.72
Batch: 680; loss: 0.96; acc: 0.67
Batch: 700; loss: 0.72; acc: 0.77
Batch: 720; loss: 0.67; acc: 0.84
Batch: 740; loss: 1.25; acc: 0.62
Batch: 760; loss: 0.94; acc: 0.7
Batch: 780; loss: 0.95; acc: 0.7
Train Epoch over. train_loss: 0.94; train_accuracy: 0.7 

Batch: 0; loss: 1.01; acc: 0.7
Batch: 20; loss: 0.83; acc: 0.8
Batch: 40; loss: 0.84; acc: 0.77
Batch: 60; loss: 0.92; acc: 0.62
Batch: 80; loss: 0.99; acc: 0.69
Batch: 100; loss: 0.88; acc: 0.67
Batch: 120; loss: 1.12; acc: 0.66
Batch: 140; loss: 0.62; acc: 0.72
Val Epoch over. val_loss: 0.9179993404704294; val_accuracy: 0.7006369426751592 

The current subspace-distance is: 6.422006845241413e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 0.79; acc: 0.75
Batch: 40; loss: 0.94; acc: 0.69
Batch: 60; loss: 1.09; acc: 0.67
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 1.04; acc: 0.62
Batch: 120; loss: 1.09; acc: 0.61
Batch: 140; loss: 0.97; acc: 0.67
Batch: 160; loss: 0.94; acc: 0.69
Batch: 180; loss: 0.82; acc: 0.73
Batch: 200; loss: 0.86; acc: 0.75
Batch: 220; loss: 0.94; acc: 0.75
Batch: 240; loss: 0.98; acc: 0.67
Batch: 260; loss: 1.0; acc: 0.62
Batch: 280; loss: 0.79; acc: 0.75
Batch: 300; loss: 1.07; acc: 0.62
Batch: 320; loss: 0.89; acc: 0.73
Batch: 340; loss: 0.79; acc: 0.77
Batch: 360; loss: 0.89; acc: 0.75
Batch: 380; loss: 1.44; acc: 0.58
Batch: 400; loss: 0.78; acc: 0.8
Batch: 420; loss: 1.09; acc: 0.64
Batch: 440; loss: 1.3; acc: 0.66
Batch: 460; loss: 0.79; acc: 0.75
Batch: 480; loss: 0.84; acc: 0.75
Batch: 500; loss: 1.03; acc: 0.73
Batch: 520; loss: 0.74; acc: 0.77
Batch: 540; loss: 0.7; acc: 0.78
Batch: 560; loss: 0.95; acc: 0.67
Batch: 580; loss: 1.16; acc: 0.62
Batch: 600; loss: 0.83; acc: 0.7
Batch: 620; loss: 1.13; acc: 0.59
Batch: 640; loss: 1.2; acc: 0.7
Batch: 660; loss: 0.91; acc: 0.62
Batch: 680; loss: 0.91; acc: 0.72
Batch: 700; loss: 0.83; acc: 0.66
Batch: 720; loss: 0.94; acc: 0.69
Batch: 740; loss: 0.7; acc: 0.77
Batch: 760; loss: 0.64; acc: 0.72
Batch: 780; loss: 0.74; acc: 0.81
Train Epoch over. train_loss: 0.93; train_accuracy: 0.7 

Batch: 0; loss: 0.83; acc: 0.78
Batch: 20; loss: 0.8; acc: 0.72
Batch: 40; loss: 0.76; acc: 0.75
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.86; acc: 0.75
Batch: 100; loss: 0.79; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.67
Batch: 140; loss: 0.62; acc: 0.81
Val Epoch over. val_loss: 0.8945997475059169; val_accuracy: 0.7175557324840764 

The current subspace-distance is: 6.673487951047719e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 0.77; acc: 0.73
Batch: 40; loss: 0.77; acc: 0.73
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.75; acc: 0.78
Batch: 100; loss: 0.62; acc: 0.83
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.81; acc: 0.7
Batch: 160; loss: 1.04; acc: 0.67
Batch: 180; loss: 0.88; acc: 0.66
Batch: 200; loss: 1.08; acc: 0.72
Batch: 220; loss: 0.89; acc: 0.72
Batch: 240; loss: 0.99; acc: 0.64
Batch: 260; loss: 0.78; acc: 0.75
Batch: 280; loss: 1.14; acc: 0.62
Batch: 300; loss: 0.89; acc: 0.7
Batch: 320; loss: 0.9; acc: 0.7
Batch: 340; loss: 0.91; acc: 0.67
Batch: 360; loss: 0.91; acc: 0.73
Batch: 380; loss: 0.92; acc: 0.7
Batch: 400; loss: 1.17; acc: 0.62
Batch: 420; loss: 0.75; acc: 0.77
Batch: 440; loss: 1.06; acc: 0.62
Batch: 460; loss: 1.23; acc: 0.67
Batch: 480; loss: 0.65; acc: 0.78
Batch: 500; loss: 0.93; acc: 0.72
Batch: 520; loss: 0.9; acc: 0.64
Batch: 540; loss: 1.0; acc: 0.7
Batch: 560; loss: 0.83; acc: 0.75
Batch: 580; loss: 1.07; acc: 0.66
Batch: 600; loss: 0.87; acc: 0.7
Batch: 620; loss: 0.98; acc: 0.7
Batch: 640; loss: 1.19; acc: 0.64
Batch: 660; loss: 0.75; acc: 0.73
Batch: 680; loss: 0.77; acc: 0.77
Batch: 700; loss: 1.12; acc: 0.62
Batch: 720; loss: 1.6; acc: 0.55
Batch: 740; loss: 0.68; acc: 0.78
Batch: 760; loss: 1.19; acc: 0.62
Batch: 780; loss: 1.02; acc: 0.69
Train Epoch over. train_loss: 0.92; train_accuracy: 0.71 

Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 0.95; acc: 0.72
Batch: 40; loss: 0.82; acc: 0.81
Batch: 60; loss: 0.8; acc: 0.81
Batch: 80; loss: 1.03; acc: 0.67
Batch: 100; loss: 0.99; acc: 0.7
Batch: 120; loss: 1.3; acc: 0.64
Batch: 140; loss: 0.64; acc: 0.78
Val Epoch over. val_loss: 0.9596970047161077; val_accuracy: 0.6968550955414012 

The current subspace-distance is: 7.280937279574573e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.83; acc: 0.73
Batch: 20; loss: 0.73; acc: 0.81
Batch: 40; loss: 0.87; acc: 0.69
Batch: 60; loss: 0.84; acc: 0.66
Batch: 80; loss: 1.18; acc: 0.59
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 0.89; acc: 0.72
Batch: 140; loss: 0.81; acc: 0.78
Batch: 160; loss: 1.02; acc: 0.69
Batch: 180; loss: 0.86; acc: 0.77
Batch: 200; loss: 0.76; acc: 0.72
Batch: 220; loss: 0.93; acc: 0.69
Batch: 240; loss: 0.64; acc: 0.77
Batch: 260; loss: 1.05; acc: 0.73
Batch: 280; loss: 0.79; acc: 0.73
Batch: 300; loss: 1.05; acc: 0.69
Batch: 320; loss: 0.88; acc: 0.73
Batch: 340; loss: 1.31; acc: 0.72
Batch: 360; loss: 0.77; acc: 0.77
Batch: 380; loss: 0.81; acc: 0.75
Batch: 400; loss: 0.88; acc: 0.7
Batch: 420; loss: 0.98; acc: 0.75
Batch: 440; loss: 0.78; acc: 0.78
Batch: 460; loss: 1.11; acc: 0.69
Batch: 480; loss: 1.51; acc: 0.59
Batch: 500; loss: 0.74; acc: 0.77
Batch: 520; loss: 1.06; acc: 0.67
Batch: 540; loss: 1.04; acc: 0.64
Batch: 560; loss: 0.79; acc: 0.73
Batch: 580; loss: 1.46; acc: 0.59
Batch: 600; loss: 0.76; acc: 0.77
Batch: 620; loss: 0.75; acc: 0.73
Batch: 640; loss: 0.87; acc: 0.7
Batch: 660; loss: 0.87; acc: 0.73
Batch: 680; loss: 0.82; acc: 0.73
Batch: 700; loss: 0.82; acc: 0.75
Batch: 720; loss: 0.78; acc: 0.77
Batch: 740; loss: 0.84; acc: 0.77
Batch: 760; loss: 0.69; acc: 0.8
Batch: 780; loss: 0.72; acc: 0.75
Train Epoch over. train_loss: 0.87; train_accuracy: 0.73 

Batch: 0; loss: 0.89; acc: 0.7
Batch: 20; loss: 0.87; acc: 0.72
Batch: 40; loss: 0.8; acc: 0.78
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.93; acc: 0.67
Batch: 100; loss: 0.9; acc: 0.75
Batch: 120; loss: 1.33; acc: 0.66
Batch: 140; loss: 0.57; acc: 0.84
Val Epoch over. val_loss: 0.9159167999294913; val_accuracy: 0.7018312101910829 

The current subspace-distance is: 7.581245881738141e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 0.77; acc: 0.72
Batch: 40; loss: 0.9; acc: 0.67
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 1.13; acc: 0.67
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 1.06; acc: 0.62
Batch: 160; loss: 0.73; acc: 0.77
Batch: 180; loss: 0.86; acc: 0.73
Batch: 200; loss: 0.92; acc: 0.67
Batch: 220; loss: 1.07; acc: 0.64
Batch: 240; loss: 0.83; acc: 0.77
Batch: 260; loss: 0.85; acc: 0.73
Batch: 280; loss: 1.04; acc: 0.66
Batch: 300; loss: 0.74; acc: 0.73
Batch: 320; loss: 0.67; acc: 0.83
Batch: 340; loss: 1.08; acc: 0.7
Batch: 360; loss: 0.96; acc: 0.66
Batch: 380; loss: 0.98; acc: 0.67
Batch: 400; loss: 0.75; acc: 0.77
Batch: 420; loss: 0.77; acc: 0.83
Batch: 440; loss: 1.05; acc: 0.7
Batch: 460; loss: 0.69; acc: 0.77
Batch: 480; loss: 0.84; acc: 0.73
Batch: 500; loss: 0.91; acc: 0.72
Batch: 520; loss: 0.65; acc: 0.78
Batch: 540; loss: 0.67; acc: 0.69
Batch: 560; loss: 0.83; acc: 0.77
Batch: 580; loss: 0.69; acc: 0.78
Batch: 600; loss: 0.83; acc: 0.73
Batch: 620; loss: 0.58; acc: 0.78
Batch: 640; loss: 1.0; acc: 0.7
Batch: 660; loss: 0.77; acc: 0.75
Batch: 680; loss: 0.78; acc: 0.7
Batch: 700; loss: 1.0; acc: 0.69
Batch: 720; loss: 0.9; acc: 0.73
Batch: 740; loss: 0.59; acc: 0.83
Batch: 760; loss: 1.01; acc: 0.62
Batch: 780; loss: 0.9; acc: 0.64
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.7; acc: 0.75
Batch: 40; loss: 0.69; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.92; acc: 0.73
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 1.09; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.83
Val Epoch over. val_loss: 0.8122573760664387; val_accuracy: 0.7428343949044586 

The current subspace-distance is: 8.162071753758937e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.12; acc: 0.73
Batch: 20; loss: 0.81; acc: 0.72
Batch: 40; loss: 0.85; acc: 0.72
Batch: 60; loss: 0.93; acc: 0.73
Batch: 80; loss: 0.85; acc: 0.75
Batch: 100; loss: 0.82; acc: 0.77
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.99; acc: 0.7
Batch: 160; loss: 1.26; acc: 0.7
Batch: 180; loss: 0.74; acc: 0.73
Batch: 200; loss: 0.84; acc: 0.73
Batch: 220; loss: 0.75; acc: 0.8
Batch: 240; loss: 0.89; acc: 0.77
Batch: 260; loss: 0.69; acc: 0.75
Batch: 280; loss: 0.76; acc: 0.73
Batch: 300; loss: 0.82; acc: 0.83
Batch: 320; loss: 0.93; acc: 0.67
Batch: 340; loss: 0.89; acc: 0.67
Batch: 360; loss: 1.02; acc: 0.69
Batch: 380; loss: 0.79; acc: 0.7
Batch: 400; loss: 0.77; acc: 0.73
Batch: 420; loss: 1.03; acc: 0.7
Batch: 440; loss: 0.84; acc: 0.7
Batch: 460; loss: 0.61; acc: 0.78
Batch: 480; loss: 0.85; acc: 0.7
Batch: 500; loss: 0.97; acc: 0.69
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 0.81; acc: 0.73
Batch: 560; loss: 1.02; acc: 0.66
Batch: 580; loss: 0.97; acc: 0.66
Batch: 600; loss: 1.07; acc: 0.64
Batch: 620; loss: 1.15; acc: 0.64
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.81; acc: 0.77
Batch: 680; loss: 1.0; acc: 0.7
Batch: 700; loss: 0.67; acc: 0.73
Batch: 720; loss: 0.95; acc: 0.64
Batch: 740; loss: 0.75; acc: 0.75
Batch: 760; loss: 0.64; acc: 0.78
Batch: 780; loss: 0.73; acc: 0.81
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.71; acc: 0.77
Batch: 40; loss: 0.73; acc: 0.75
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.9; acc: 0.72
Batch: 100; loss: 0.76; acc: 0.77
Batch: 120; loss: 1.11; acc: 0.69
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.8232217977760704; val_accuracy: 0.7405453821656051 

The current subspace-distance is: 8.555386739317328e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.92; acc: 0.67
Batch: 20; loss: 0.85; acc: 0.73
Batch: 40; loss: 0.73; acc: 0.73
Batch: 60; loss: 1.02; acc: 0.69
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.59; acc: 0.78
Batch: 120; loss: 0.85; acc: 0.78
Batch: 140; loss: 0.92; acc: 0.72
Batch: 160; loss: 0.86; acc: 0.75
Batch: 180; loss: 0.9; acc: 0.72
Batch: 200; loss: 1.03; acc: 0.7
Batch: 220; loss: 0.88; acc: 0.73
Batch: 240; loss: 1.01; acc: 0.67
Batch: 260; loss: 0.86; acc: 0.7
Batch: 280; loss: 0.73; acc: 0.78
Batch: 300; loss: 0.93; acc: 0.73
Batch: 320; loss: 0.92; acc: 0.69
Batch: 340; loss: 1.16; acc: 0.7
Batch: 360; loss: 1.04; acc: 0.78
Batch: 380; loss: 0.71; acc: 0.78
Batch: 400; loss: 0.61; acc: 0.8
Batch: 420; loss: 0.89; acc: 0.73
Batch: 440; loss: 0.95; acc: 0.72
Batch: 460; loss: 0.85; acc: 0.81
Batch: 480; loss: 1.04; acc: 0.72
Batch: 500; loss: 0.64; acc: 0.84
Batch: 520; loss: 1.02; acc: 0.69
Batch: 540; loss: 1.13; acc: 0.72
Batch: 560; loss: 0.65; acc: 0.84
Batch: 580; loss: 0.97; acc: 0.7
Batch: 600; loss: 0.83; acc: 0.7
Batch: 620; loss: 0.83; acc: 0.72
Batch: 640; loss: 1.01; acc: 0.72
Batch: 660; loss: 0.8; acc: 0.7
Batch: 680; loss: 0.96; acc: 0.69
Batch: 700; loss: 0.99; acc: 0.73
Batch: 720; loss: 0.58; acc: 0.78
Batch: 740; loss: 0.67; acc: 0.77
Batch: 760; loss: 0.82; acc: 0.72
Batch: 780; loss: 0.97; acc: 0.72
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.73; acc: 0.78
Batch: 60; loss: 0.78; acc: 0.72
Batch: 80; loss: 0.99; acc: 0.7
Batch: 100; loss: 0.83; acc: 0.75
Batch: 120; loss: 1.04; acc: 0.62
Batch: 140; loss: 0.55; acc: 0.83
Val Epoch over. val_loss: 0.8257081280848023; val_accuracy: 0.7376592356687898 

The current subspace-distance is: 8.968037582235411e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.03; acc: 0.62
Batch: 20; loss: 1.05; acc: 0.67
Batch: 40; loss: 0.8; acc: 0.75
Batch: 60; loss: 0.67; acc: 0.77
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 1.09; acc: 0.7
Batch: 160; loss: 0.83; acc: 0.75
Batch: 180; loss: 0.92; acc: 0.7
Batch: 200; loss: 0.98; acc: 0.67
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.82; acc: 0.69
Batch: 260; loss: 1.0; acc: 0.66
Batch: 280; loss: 0.83; acc: 0.7
Batch: 300; loss: 0.84; acc: 0.72
Batch: 320; loss: 0.97; acc: 0.67
Batch: 340; loss: 0.89; acc: 0.69
Batch: 360; loss: 0.98; acc: 0.73
Batch: 380; loss: 0.97; acc: 0.64
Batch: 400; loss: 0.73; acc: 0.77
Batch: 420; loss: 0.77; acc: 0.77
Batch: 440; loss: 0.69; acc: 0.73
Batch: 460; loss: 0.86; acc: 0.75
Batch: 480; loss: 0.9; acc: 0.69
Batch: 500; loss: 0.94; acc: 0.69
Batch: 520; loss: 1.0; acc: 0.7
Batch: 540; loss: 0.78; acc: 0.75
Batch: 560; loss: 0.88; acc: 0.73
Batch: 580; loss: 0.77; acc: 0.73
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 1.13; acc: 0.67
Batch: 640; loss: 0.63; acc: 0.86
Batch: 660; loss: 0.68; acc: 0.8
Batch: 680; loss: 0.84; acc: 0.73
Batch: 700; loss: 0.72; acc: 0.78
Batch: 720; loss: 1.0; acc: 0.66
Batch: 740; loss: 0.89; acc: 0.72
Batch: 760; loss: 1.01; acc: 0.67
Batch: 780; loss: 1.05; acc: 0.7
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

Batch: 0; loss: 0.92; acc: 0.73
Batch: 20; loss: 0.73; acc: 0.75
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 0.88; acc: 0.67
Batch: 80; loss: 1.02; acc: 0.67
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 1.05; acc: 0.64
Batch: 140; loss: 0.6; acc: 0.81
Val Epoch over. val_loss: 0.8648922885679136; val_accuracy: 0.7199442675159236 

The current subspace-distance is: 9.201231296174228e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.98; acc: 0.72
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.95; acc: 0.73
Batch: 60; loss: 0.83; acc: 0.75
Batch: 80; loss: 1.06; acc: 0.75
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 1.05; acc: 0.75
Batch: 140; loss: 0.79; acc: 0.73
Batch: 160; loss: 0.83; acc: 0.78
Batch: 180; loss: 0.99; acc: 0.69
Batch: 200; loss: 0.76; acc: 0.73
Batch: 220; loss: 0.87; acc: 0.69
Batch: 240; loss: 0.91; acc: 0.73
Batch: 260; loss: 0.9; acc: 0.69
Batch: 280; loss: 0.62; acc: 0.75
Batch: 300; loss: 0.87; acc: 0.77
Batch: 320; loss: 1.0; acc: 0.67
Batch: 340; loss: 0.8; acc: 0.75
Batch: 360; loss: 0.74; acc: 0.77
Batch: 380; loss: 0.92; acc: 0.69
Batch: 400; loss: 0.96; acc: 0.77
Batch: 420; loss: 1.09; acc: 0.62
Batch: 440; loss: 0.64; acc: 0.78
Batch: 460; loss: 0.73; acc: 0.8
Batch: 480; loss: 0.98; acc: 0.72
Batch: 500; loss: 0.7; acc: 0.75
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.96; acc: 0.64
Batch: 560; loss: 0.8; acc: 0.77
Batch: 580; loss: 0.96; acc: 0.73
Batch: 600; loss: 0.73; acc: 0.78
Batch: 620; loss: 0.86; acc: 0.69
Batch: 640; loss: 0.93; acc: 0.77
Batch: 660; loss: 0.9; acc: 0.75
Batch: 680; loss: 0.94; acc: 0.73
Batch: 700; loss: 0.7; acc: 0.73
Batch: 720; loss: 0.64; acc: 0.81
Batch: 740; loss: 0.89; acc: 0.72
Batch: 760; loss: 0.98; acc: 0.69
Batch: 780; loss: 0.6; acc: 0.81
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

Batch: 0; loss: 0.91; acc: 0.67
Batch: 20; loss: 0.81; acc: 0.69
Batch: 40; loss: 0.84; acc: 0.75
Batch: 60; loss: 0.84; acc: 0.77
Batch: 80; loss: 0.95; acc: 0.67
Batch: 100; loss: 0.89; acc: 0.72
Batch: 120; loss: 1.31; acc: 0.66
Batch: 140; loss: 0.54; acc: 0.8
Val Epoch over. val_loss: 0.9147728311408098; val_accuracy: 0.7063097133757962 

The current subspace-distance is: 9.388344187755138e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.83; acc: 0.75
Batch: 20; loss: 0.85; acc: 0.77
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 0.85; acc: 0.73
Batch: 100; loss: 0.96; acc: 0.72
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.96; acc: 0.73
Batch: 160; loss: 0.94; acc: 0.72
Batch: 180; loss: 1.04; acc: 0.67
Batch: 200; loss: 0.76; acc: 0.73
Batch: 220; loss: 1.05; acc: 0.7
Batch: 240; loss: 0.95; acc: 0.73
Batch: 260; loss: 1.05; acc: 0.67
Batch: 280; loss: 0.97; acc: 0.67
Batch: 300; loss: 1.19; acc: 0.59
Batch: 320; loss: 1.01; acc: 0.66
Batch: 340; loss: 0.86; acc: 0.72
Batch: 360; loss: 0.84; acc: 0.73
Batch: 380; loss: 0.8; acc: 0.66
Batch: 400; loss: 0.92; acc: 0.75
Batch: 420; loss: 0.9; acc: 0.69
Batch: 440; loss: 0.74; acc: 0.75
Batch: 460; loss: 0.93; acc: 0.62
Batch: 480; loss: 0.66; acc: 0.84
Batch: 500; loss: 0.73; acc: 0.78
Batch: 520; loss: 0.91; acc: 0.75
Batch: 540; loss: 0.92; acc: 0.66
Batch: 560; loss: 0.94; acc: 0.73
Batch: 580; loss: 0.78; acc: 0.77
Batch: 600; loss: 0.84; acc: 0.78
Batch: 620; loss: 0.96; acc: 0.67
Batch: 640; loss: 0.88; acc: 0.78
Batch: 660; loss: 0.91; acc: 0.72
Batch: 680; loss: 0.84; acc: 0.73
Batch: 700; loss: 0.88; acc: 0.67
Batch: 720; loss: 0.62; acc: 0.77
Batch: 740; loss: 0.64; acc: 0.75
Batch: 760; loss: 0.93; acc: 0.69
Batch: 780; loss: 1.0; acc: 0.66
Train Epoch over. train_loss: 0.86; train_accuracy: 0.73 

Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.7; acc: 0.8
Batch: 60; loss: 0.78; acc: 0.73
Batch: 80; loss: 0.88; acc: 0.72
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.66
Batch: 140; loss: 0.55; acc: 0.84
Val Epoch over. val_loss: 0.8620110996969187; val_accuracy: 0.7253184713375797 

The current subspace-distance is: 9.677118941908702e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.96; acc: 0.73
Batch: 20; loss: 0.84; acc: 0.72
Batch: 40; loss: 0.91; acc: 0.7
Batch: 60; loss: 0.82; acc: 0.72
Batch: 80; loss: 0.73; acc: 0.75
Batch: 100; loss: 0.98; acc: 0.7
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.69; acc: 0.77
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 1.07; acc: 0.64
Batch: 200; loss: 0.77; acc: 0.8
Batch: 220; loss: 0.78; acc: 0.78
Batch: 240; loss: 0.82; acc: 0.67
Batch: 260; loss: 0.98; acc: 0.75
Batch: 280; loss: 1.07; acc: 0.64
Batch: 300; loss: 0.88; acc: 0.67
Batch: 320; loss: 0.81; acc: 0.73
Batch: 340; loss: 0.8; acc: 0.77
Batch: 360; loss: 0.75; acc: 0.78
Batch: 380; loss: 0.7; acc: 0.78
Batch: 400; loss: 0.91; acc: 0.7
Batch: 420; loss: 1.15; acc: 0.64
Batch: 440; loss: 1.0; acc: 0.7
Batch: 460; loss: 0.93; acc: 0.75
Batch: 480; loss: 0.96; acc: 0.64
Batch: 500; loss: 0.71; acc: 0.83
Batch: 520; loss: 0.82; acc: 0.7
Batch: 540; loss: 0.65; acc: 0.77
Batch: 560; loss: 1.01; acc: 0.64
Batch: 580; loss: 0.94; acc: 0.67
Batch: 600; loss: 0.74; acc: 0.78
Batch: 620; loss: 0.88; acc: 0.73
Batch: 640; loss: 0.99; acc: 0.69
Batch: 660; loss: 1.14; acc: 0.66
Batch: 680; loss: 0.75; acc: 0.8
Batch: 700; loss: 0.9; acc: 0.7
Batch: 720; loss: 0.63; acc: 0.84
Batch: 740; loss: 0.87; acc: 0.66
Batch: 760; loss: 0.99; acc: 0.7
Batch: 780; loss: 0.87; acc: 0.77
Train Epoch over. train_loss: 0.85; train_accuracy: 0.73 

Batch: 0; loss: 0.91; acc: 0.73
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.75; acc: 0.8
Batch: 60; loss: 0.8; acc: 0.72
Batch: 80; loss: 0.91; acc: 0.72
Batch: 100; loss: 0.71; acc: 0.81
Batch: 120; loss: 0.97; acc: 0.69
Batch: 140; loss: 0.58; acc: 0.83
Val Epoch over. val_loss: 0.8507913109982849; val_accuracy: 0.7286027070063694 

The current subspace-distance is: 0.00010009563266066834 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.84; acc: 0.75
Batch: 40; loss: 1.07; acc: 0.69
Batch: 60; loss: 1.18; acc: 0.64
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.88; acc: 0.75
Batch: 140; loss: 0.8; acc: 0.72
Batch: 160; loss: 0.84; acc: 0.75
Batch: 180; loss: 0.86; acc: 0.77
Batch: 200; loss: 0.73; acc: 0.81
Batch: 220; loss: 0.82; acc: 0.73
Batch: 240; loss: 0.56; acc: 0.8
Batch: 260; loss: 1.07; acc: 0.69
Batch: 280; loss: 0.74; acc: 0.75
Batch: 300; loss: 0.84; acc: 0.7
Batch: 320; loss: 0.96; acc: 0.7
Batch: 340; loss: 1.06; acc: 0.7
Batch: 360; loss: 0.8; acc: 0.75
Batch: 380; loss: 0.66; acc: 0.8
Batch: 400; loss: 0.84; acc: 0.78
Batch: 420; loss: 0.96; acc: 0.72
Batch: 440; loss: 0.91; acc: 0.67
Batch: 460; loss: 0.87; acc: 0.69
Batch: 480; loss: 0.84; acc: 0.7
Batch: 500; loss: 0.85; acc: 0.7
Batch: 520; loss: 0.79; acc: 0.73
Batch: 540; loss: 0.75; acc: 0.77
Batch: 560; loss: 0.82; acc: 0.75
Batch: 580; loss: 0.89; acc: 0.72
Batch: 600; loss: 0.78; acc: 0.78
Batch: 620; loss: 1.02; acc: 0.7
Batch: 640; loss: 1.0; acc: 0.7
Batch: 660; loss: 0.81; acc: 0.7
Batch: 680; loss: 0.85; acc: 0.75
Batch: 700; loss: 0.87; acc: 0.75
Batch: 720; loss: 0.87; acc: 0.77
Batch: 740; loss: 0.72; acc: 0.73
Batch: 760; loss: 0.85; acc: 0.64
Batch: 780; loss: 0.65; acc: 0.73
Train Epoch over. train_loss: 0.85; train_accuracy: 0.73 

Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.69; acc: 0.72
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.8; acc: 0.73
Batch: 100; loss: 0.7; acc: 0.81
Batch: 120; loss: 0.94; acc: 0.73
Batch: 140; loss: 0.53; acc: 0.83
Val Epoch over. val_loss: 0.8220509415978838; val_accuracy: 0.7357683121019108 

The current subspace-distance is: 0.00010180856043007225 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.97; acc: 0.67
Batch: 40; loss: 1.04; acc: 0.66
Batch: 60; loss: 0.99; acc: 0.72
Batch: 80; loss: 1.18; acc: 0.69
Batch: 100; loss: 1.16; acc: 0.69
Batch: 120; loss: 1.18; acc: 0.7
Batch: 140; loss: 0.63; acc: 0.83
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.87; acc: 0.73
Batch: 200; loss: 0.49; acc: 0.86
Batch: 220; loss: 0.77; acc: 0.73
Batch: 240; loss: 1.06; acc: 0.75
Batch: 260; loss: 1.09; acc: 0.69
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.89; acc: 0.7
Batch: 320; loss: 0.68; acc: 0.83
Batch: 340; loss: 1.09; acc: 0.62
Batch: 360; loss: 1.05; acc: 0.67
Batch: 380; loss: 0.87; acc: 0.7
Batch: 400; loss: 0.79; acc: 0.77
Batch: 420; loss: 0.77; acc: 0.73
Batch: 440; loss: 0.86; acc: 0.75
Batch: 460; loss: 0.84; acc: 0.77
Batch: 480; loss: 0.78; acc: 0.81
Batch: 500; loss: 0.72; acc: 0.72
Batch: 520; loss: 0.86; acc: 0.78
Batch: 540; loss: 0.72; acc: 0.84
Batch: 560; loss: 1.17; acc: 0.64
Batch: 580; loss: 0.88; acc: 0.7
Batch: 600; loss: 0.72; acc: 0.78
Batch: 620; loss: 0.86; acc: 0.77
Batch: 640; loss: 0.86; acc: 0.72
Batch: 660; loss: 0.7; acc: 0.86
Batch: 680; loss: 0.79; acc: 0.72
Batch: 700; loss: 1.06; acc: 0.67
Batch: 720; loss: 1.01; acc: 0.67
Batch: 740; loss: 0.78; acc: 0.72
Batch: 760; loss: 0.72; acc: 0.77
Batch: 780; loss: 1.25; acc: 0.56
Train Epoch over. train_loss: 0.85; train_accuracy: 0.73 

Batch: 0; loss: 0.88; acc: 0.77
Batch: 20; loss: 0.7; acc: 0.75
Batch: 40; loss: 0.67; acc: 0.84
Batch: 60; loss: 0.76; acc: 0.72
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 0.93; acc: 0.72
Batch: 140; loss: 0.55; acc: 0.83
Val Epoch over. val_loss: 0.8305012164222207; val_accuracy: 0.7376592356687898 

The current subspace-distance is: 0.00010393535922048613 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.08; acc: 0.69
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 0.91; acc: 0.75
Batch: 60; loss: 0.84; acc: 0.67
Batch: 80; loss: 1.07; acc: 0.72
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 1.16; acc: 0.72
Batch: 160; loss: 0.85; acc: 0.67
Batch: 180; loss: 0.83; acc: 0.72
Batch: 200; loss: 0.65; acc: 0.78
Batch: 220; loss: 0.65; acc: 0.77
Batch: 240; loss: 0.83; acc: 0.73
Batch: 260; loss: 0.66; acc: 0.77
Batch: 280; loss: 1.01; acc: 0.7
Batch: 300; loss: 0.85; acc: 0.75
Batch: 320; loss: 0.94; acc: 0.66
Batch: 340; loss: 0.8; acc: 0.77
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.85; acc: 0.75
Batch: 400; loss: 0.74; acc: 0.72
Batch: 420; loss: 0.78; acc: 0.77
Batch: 440; loss: 0.81; acc: 0.72
Batch: 460; loss: 0.74; acc: 0.73
Batch: 480; loss: 0.83; acc: 0.72
Batch: 500; loss: 1.01; acc: 0.77
Batch: 520; loss: 0.77; acc: 0.75
Batch: 540; loss: 0.85; acc: 0.73
Batch: 560; loss: 0.81; acc: 0.77
Batch: 580; loss: 0.76; acc: 0.73
Batch: 600; loss: 1.01; acc: 0.67
Batch: 620; loss: 0.91; acc: 0.75
Batch: 640; loss: 0.83; acc: 0.7
Batch: 660; loss: 0.92; acc: 0.69
Batch: 680; loss: 0.89; acc: 0.72
Batch: 700; loss: 0.69; acc: 0.75
Batch: 720; loss: 0.86; acc: 0.77
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.74; acc: 0.75
Batch: 780; loss: 1.05; acc: 0.7
Train Epoch over. train_loss: 0.84; train_accuracy: 0.74 

Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.68; acc: 0.72
Batch: 40; loss: 0.65; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 0.7; acc: 0.84
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 0.48; acc: 0.86
Val Epoch over. val_loss: 0.7847350894645521; val_accuracy: 0.7535828025477707 

The current subspace-distance is: 0.0001060625581885688 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.84; acc: 0.77
Batch: 20; loss: 1.06; acc: 0.66
Batch: 40; loss: 1.03; acc: 0.69
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 1.0; acc: 0.73
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 0.82; acc: 0.7
Batch: 160; loss: 0.93; acc: 0.73
Batch: 180; loss: 0.74; acc: 0.7
Batch: 200; loss: 0.9; acc: 0.75
Batch: 220; loss: 0.79; acc: 0.72
Batch: 240; loss: 0.69; acc: 0.8
Batch: 260; loss: 0.89; acc: 0.69
Batch: 280; loss: 0.76; acc: 0.72
Batch: 300; loss: 0.76; acc: 0.77
Batch: 320; loss: 0.75; acc: 0.8
Batch: 340; loss: 1.01; acc: 0.7
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 0.73; acc: 0.78
Batch: 400; loss: 0.83; acc: 0.66
Batch: 420; loss: 0.85; acc: 0.77
Batch: 440; loss: 0.86; acc: 0.72
Batch: 460; loss: 0.6; acc: 0.81
Batch: 480; loss: 0.67; acc: 0.81
Batch: 500; loss: 0.85; acc: 0.73
Batch: 520; loss: 0.79; acc: 0.77
Batch: 540; loss: 0.88; acc: 0.69
Batch: 560; loss: 0.89; acc: 0.67
Batch: 580; loss: 0.79; acc: 0.7
Batch: 600; loss: 0.74; acc: 0.81
Batch: 620; loss: 0.78; acc: 0.75
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.96; acc: 0.78
Batch: 680; loss: 0.66; acc: 0.75
Batch: 700; loss: 0.76; acc: 0.77
Batch: 720; loss: 0.69; acc: 0.77
Batch: 740; loss: 0.7; acc: 0.77
Batch: 760; loss: 0.74; acc: 0.75
Batch: 780; loss: 0.62; acc: 0.78
Train Epoch over. train_loss: 0.84; train_accuracy: 0.74 

Batch: 0; loss: 0.84; acc: 0.81
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.81; acc: 0.75
Batch: 100; loss: 0.69; acc: 0.84
Batch: 120; loss: 0.95; acc: 0.7
Batch: 140; loss: 0.49; acc: 0.86
Val Epoch over. val_loss: 0.7826945324232624; val_accuracy: 0.7552746815286624 

The current subspace-distance is: 0.00010998440120602027 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.88; acc: 0.67
Batch: 20; loss: 0.72; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.77
Batch: 60; loss: 0.87; acc: 0.69
Batch: 80; loss: 0.68; acc: 0.81
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 0.93; acc: 0.73
Batch: 140; loss: 0.74; acc: 0.81
Batch: 160; loss: 1.16; acc: 0.66
Batch: 180; loss: 1.02; acc: 0.72
Batch: 200; loss: 0.96; acc: 0.64
Batch: 220; loss: 1.02; acc: 0.7
Batch: 240; loss: 0.97; acc: 0.78
Batch: 260; loss: 1.0; acc: 0.72
Batch: 280; loss: 0.69; acc: 0.75
Batch: 300; loss: 0.64; acc: 0.83
Batch: 320; loss: 0.79; acc: 0.72
Batch: 340; loss: 0.74; acc: 0.77
Batch: 360; loss: 0.88; acc: 0.73
Batch: 380; loss: 0.77; acc: 0.72
Batch: 400; loss: 1.37; acc: 0.58
Batch: 420; loss: 0.89; acc: 0.72
Batch: 440; loss: 1.07; acc: 0.75
Batch: 460; loss: 0.83; acc: 0.8
Batch: 480; loss: 0.75; acc: 0.78
Batch: 500; loss: 0.87; acc: 0.77
Batch: 520; loss: 0.53; acc: 0.8
Batch: 540; loss: 0.88; acc: 0.72
Batch: 560; loss: 1.17; acc: 0.64
Batch: 580; loss: 0.8; acc: 0.73
Batch: 600; loss: 0.72; acc: 0.77
Batch: 620; loss: 0.83; acc: 0.72
Batch: 640; loss: 0.79; acc: 0.72
Batch: 660; loss: 0.72; acc: 0.78
Batch: 680; loss: 0.72; acc: 0.77
Batch: 700; loss: 0.64; acc: 0.78
Batch: 720; loss: 0.67; acc: 0.83
Batch: 740; loss: 0.89; acc: 0.67
Batch: 760; loss: 0.87; acc: 0.72
Batch: 780; loss: 0.99; acc: 0.7
Train Epoch over. train_loss: 0.83; train_accuracy: 0.74 

Batch: 0; loss: 0.86; acc: 0.72
Batch: 20; loss: 0.69; acc: 0.72
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 0.75; acc: 0.8
Batch: 80; loss: 0.78; acc: 0.72
Batch: 100; loss: 0.71; acc: 0.8
Batch: 120; loss: 1.03; acc: 0.7
Batch: 140; loss: 0.47; acc: 0.86
Val Epoch over. val_loss: 0.7922857716964309; val_accuracy: 0.7505971337579618 

The current subspace-distance is: 0.0001117332503781654 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.8
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 0.75; acc: 0.72
Batch: 80; loss: 0.99; acc: 0.69
Batch: 100; loss: 0.84; acc: 0.7
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 1.11; acc: 0.67
Batch: 160; loss: 0.89; acc: 0.69
Batch: 180; loss: 0.83; acc: 0.77
Batch: 200; loss: 0.89; acc: 0.73
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 0.74; acc: 0.73
Batch: 260; loss: 0.93; acc: 0.64
Batch: 280; loss: 0.75; acc: 0.75
Batch: 300; loss: 1.06; acc: 0.69
Batch: 320; loss: 0.76; acc: 0.78
Batch: 340; loss: 0.83; acc: 0.73
Batch: 360; loss: 0.72; acc: 0.77
Batch: 380; loss: 0.72; acc: 0.77
Batch: 400; loss: 0.9; acc: 0.73
Batch: 420; loss: 0.8; acc: 0.73
Batch: 440; loss: 1.26; acc: 0.53
Batch: 460; loss: 0.7; acc: 0.75
Batch: 480; loss: 0.95; acc: 0.75
Batch: 500; loss: 0.69; acc: 0.8
Batch: 520; loss: 0.47; acc: 0.83
Batch: 540; loss: 0.7; acc: 0.77
Batch: 560; loss: 0.93; acc: 0.7
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.95; acc: 0.7
Batch: 620; loss: 0.76; acc: 0.84
Batch: 640; loss: 0.7; acc: 0.73
Batch: 660; loss: 0.93; acc: 0.72
Batch: 680; loss: 0.68; acc: 0.77
Batch: 700; loss: 1.16; acc: 0.69
Batch: 720; loss: 0.62; acc: 0.81
Batch: 740; loss: 0.97; acc: 0.64
Batch: 760; loss: 1.02; acc: 0.64
Batch: 780; loss: 0.64; acc: 0.72
Train Epoch over. train_loss: 0.83; train_accuracy: 0.74 

Batch: 0; loss: 0.84; acc: 0.8
Batch: 20; loss: 0.67; acc: 0.75
Batch: 40; loss: 0.65; acc: 0.78
Batch: 60; loss: 0.75; acc: 0.77
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.47; acc: 0.89
Val Epoch over. val_loss: 0.7851712327853889; val_accuracy: 0.756468949044586 

The current subspace-distance is: 0.00011421495582908392 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.85; acc: 0.72
Batch: 40; loss: 0.8; acc: 0.73
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 1.07; acc: 0.69
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 0.66; acc: 0.84
Batch: 160; loss: 0.85; acc: 0.8
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 1.01; acc: 0.69
Batch: 220; loss: 0.63; acc: 0.75
Batch: 240; loss: 0.73; acc: 0.8
Batch: 260; loss: 0.75; acc: 0.72
Batch: 280; loss: 0.87; acc: 0.77
Batch: 300; loss: 0.78; acc: 0.77
Batch: 320; loss: 0.87; acc: 0.69
Batch: 340; loss: 0.94; acc: 0.72
Batch: 360; loss: 0.76; acc: 0.73
Batch: 380; loss: 0.98; acc: 0.7
Batch: 400; loss: 0.82; acc: 0.69
Batch: 420; loss: 0.65; acc: 0.8
Batch: 440; loss: 0.59; acc: 0.84
Batch: 460; loss: 1.05; acc: 0.73
Batch: 480; loss: 0.62; acc: 0.77
Batch: 500; loss: 0.67; acc: 0.75
Batch: 520; loss: 0.98; acc: 0.64
Batch: 540; loss: 0.81; acc: 0.73
Batch: 560; loss: 1.19; acc: 0.69
Batch: 580; loss: 0.55; acc: 0.8
Batch: 600; loss: 0.88; acc: 0.77
Batch: 620; loss: 0.91; acc: 0.69
Batch: 640; loss: 0.57; acc: 0.75
Batch: 660; loss: 0.84; acc: 0.7
Batch: 680; loss: 0.73; acc: 0.78
Batch: 700; loss: 0.89; acc: 0.67
Batch: 720; loss: 0.99; acc: 0.72
Batch: 740; loss: 0.75; acc: 0.77
Batch: 760; loss: 0.81; acc: 0.73
Batch: 780; loss: 0.88; acc: 0.66
Train Epoch over. train_loss: 0.83; train_accuracy: 0.74 

Batch: 0; loss: 0.85; acc: 0.78
Batch: 20; loss: 0.65; acc: 0.75
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.78; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.88
Batch: 120; loss: 0.95; acc: 0.72
Batch: 140; loss: 0.49; acc: 0.86
Val Epoch over. val_loss: 0.7810314235034262; val_accuracy: 0.7558718152866242 

The current subspace-distance is: 0.0001164485584013164 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 1.15; acc: 0.56
Batch: 40; loss: 0.85; acc: 0.77
Batch: 60; loss: 0.83; acc: 0.77
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.71; acc: 0.78
Batch: 120; loss: 1.14; acc: 0.62
Batch: 140; loss: 0.73; acc: 0.8
Batch: 160; loss: 0.91; acc: 0.64
Batch: 180; loss: 0.82; acc: 0.8
Batch: 200; loss: 0.97; acc: 0.69
Batch: 220; loss: 1.23; acc: 0.64
Batch: 240; loss: 0.83; acc: 0.75
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.97; acc: 0.66
Batch: 300; loss: 0.82; acc: 0.69
Batch: 320; loss: 0.77; acc: 0.8
Batch: 340; loss: 0.92; acc: 0.77
Batch: 360; loss: 0.99; acc: 0.67
Batch: 380; loss: 0.52; acc: 0.8
Batch: 400; loss: 0.76; acc: 0.72
Batch: 420; loss: 0.84; acc: 0.69
Batch: 440; loss: 0.99; acc: 0.75
Batch: 460; loss: 0.76; acc: 0.69
Batch: 480; loss: 0.69; acc: 0.81
Batch: 500; loss: 1.18; acc: 0.69
Batch: 520; loss: 0.67; acc: 0.84
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.76; acc: 0.77
Batch: 580; loss: 0.78; acc: 0.75
Batch: 600; loss: 0.87; acc: 0.77
Batch: 620; loss: 0.6; acc: 0.8
Batch: 640; loss: 0.9; acc: 0.73
Batch: 660; loss: 0.74; acc: 0.75
Batch: 680; loss: 0.76; acc: 0.8
Batch: 700; loss: 0.82; acc: 0.7
Batch: 720; loss: 0.66; acc: 0.81
Batch: 740; loss: 0.9; acc: 0.78
Batch: 760; loss: 0.89; acc: 0.72
Batch: 780; loss: 1.03; acc: 0.69
Train Epoch over. train_loss: 0.83; train_accuracy: 0.74 

Batch: 0; loss: 0.88; acc: 0.77
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 0.65; acc: 0.86
Batch: 60; loss: 0.78; acc: 0.78
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 0.91; acc: 0.72
Batch: 140; loss: 0.5; acc: 0.84
Val Epoch over. val_loss: 0.791898052593705; val_accuracy: 0.7525875796178344 

The current subspace-distance is: 0.00011958198592765257 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.85; acc: 0.8
Batch: 20; loss: 0.95; acc: 0.75
Batch: 40; loss: 0.7; acc: 0.7
Batch: 60; loss: 0.94; acc: 0.69
Batch: 80; loss: 0.81; acc: 0.75
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 0.75; acc: 0.84
Batch: 140; loss: 0.72; acc: 0.78
Batch: 160; loss: 1.1; acc: 0.67
Batch: 180; loss: 0.97; acc: 0.73
Batch: 200; loss: 0.89; acc: 0.7
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.54; acc: 0.81
Batch: 260; loss: 0.67; acc: 0.81
Batch: 280; loss: 1.08; acc: 0.66
Batch: 300; loss: 1.1; acc: 0.7
Batch: 320; loss: 0.91; acc: 0.67
Batch: 340; loss: 0.74; acc: 0.77
Batch: 360; loss: 0.84; acc: 0.75
Batch: 380; loss: 0.79; acc: 0.72
Batch: 400; loss: 0.87; acc: 0.69
Batch: 420; loss: 0.7; acc: 0.8
Batch: 440; loss: 0.79; acc: 0.78
Batch: 460; loss: 0.65; acc: 0.78
Batch: 480; loss: 0.7; acc: 0.73
Batch: 500; loss: 0.8; acc: 0.77
Batch: 520; loss: 0.62; acc: 0.83
Batch: 540; loss: 0.94; acc: 0.67
Batch: 560; loss: 0.78; acc: 0.67
Batch: 580; loss: 1.03; acc: 0.72
Batch: 600; loss: 0.59; acc: 0.84
Batch: 620; loss: 0.84; acc: 0.7
Batch: 640; loss: 0.89; acc: 0.69
Batch: 660; loss: 1.15; acc: 0.59
Batch: 680; loss: 1.09; acc: 0.7
Batch: 700; loss: 0.6; acc: 0.83
Batch: 720; loss: 0.7; acc: 0.77
Batch: 740; loss: 0.93; acc: 0.77
Batch: 760; loss: 0.77; acc: 0.8
Batch: 780; loss: 1.19; acc: 0.61
Train Epoch over. train_loss: 0.83; train_accuracy: 0.74 

Batch: 0; loss: 0.85; acc: 0.8
Batch: 20; loss: 0.62; acc: 0.77
Batch: 40; loss: 0.66; acc: 0.78
Batch: 60; loss: 0.77; acc: 0.81
Batch: 80; loss: 0.75; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.81
Batch: 120; loss: 0.98; acc: 0.75
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.7729111926950467; val_accuracy: 0.7584593949044586 

The current subspace-distance is: 0.00012108452938264236 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.9; acc: 0.73
Batch: 20; loss: 0.66; acc: 0.83
Batch: 40; loss: 0.83; acc: 0.7
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.92; acc: 0.73
Batch: 100; loss: 0.88; acc: 0.77
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.84; acc: 0.78
Batch: 160; loss: 0.68; acc: 0.8
Batch: 180; loss: 0.79; acc: 0.7
Batch: 200; loss: 0.66; acc: 0.83
Batch: 220; loss: 0.81; acc: 0.69
Batch: 240; loss: 0.72; acc: 0.73
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 1.05; acc: 0.73
Batch: 300; loss: 0.78; acc: 0.8
Batch: 320; loss: 0.7; acc: 0.77
Batch: 340; loss: 0.82; acc: 0.73
Batch: 360; loss: 1.05; acc: 0.56
Batch: 380; loss: 0.81; acc: 0.7
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 0.88; acc: 0.67
Batch: 440; loss: 0.86; acc: 0.7
Batch: 460; loss: 0.61; acc: 0.81
Batch: 480; loss: 0.72; acc: 0.8
Batch: 500; loss: 0.75; acc: 0.72
Batch: 520; loss: 0.76; acc: 0.83
Batch: 540; loss: 0.87; acc: 0.75
Batch: 560; loss: 0.96; acc: 0.66
Batch: 580; loss: 0.81; acc: 0.8
Batch: 600; loss: 0.57; acc: 0.83
Batch: 620; loss: 1.03; acc: 0.72
Batch: 640; loss: 0.63; acc: 0.8
Batch: 660; loss: 0.9; acc: 0.66
Batch: 680; loss: 0.88; acc: 0.75
Batch: 700; loss: 0.96; acc: 0.72
Batch: 720; loss: 0.81; acc: 0.7
Batch: 740; loss: 0.77; acc: 0.78
Batch: 760; loss: 0.74; acc: 0.77
Batch: 780; loss: 0.8; acc: 0.77
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.85; acc: 0.78
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.79; acc: 0.8
Batch: 80; loss: 0.76; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.86
Batch: 120; loss: 0.93; acc: 0.75
Batch: 140; loss: 0.47; acc: 0.86
Val Epoch over. val_loss: 0.7739942333880504; val_accuracy: 0.7622412420382165 

The current subspace-distance is: 0.00012620972120203078 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.18; acc: 0.69
Batch: 20; loss: 0.81; acc: 0.77
Batch: 40; loss: 1.18; acc: 0.69
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.82; acc: 0.72
Batch: 100; loss: 0.91; acc: 0.72
Batch: 120; loss: 0.93; acc: 0.7
Batch: 140; loss: 0.76; acc: 0.78
Batch: 160; loss: 0.74; acc: 0.75
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.99; acc: 0.67
Batch: 220; loss: 0.97; acc: 0.75
Batch: 240; loss: 1.19; acc: 0.7
Batch: 260; loss: 0.65; acc: 0.8
Batch: 280; loss: 1.02; acc: 0.62
Batch: 300; loss: 0.9; acc: 0.72
Batch: 320; loss: 0.99; acc: 0.69
Batch: 340; loss: 0.66; acc: 0.86
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.6; acc: 0.8
Batch: 420; loss: 0.71; acc: 0.84
Batch: 440; loss: 0.74; acc: 0.8
Batch: 460; loss: 0.7; acc: 0.7
Batch: 480; loss: 0.89; acc: 0.73
Batch: 500; loss: 0.56; acc: 0.83
Batch: 520; loss: 0.95; acc: 0.69
Batch: 540; loss: 0.84; acc: 0.7
Batch: 560; loss: 0.89; acc: 0.73
Batch: 580; loss: 1.26; acc: 0.64
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.7; acc: 0.83
Batch: 660; loss: 0.82; acc: 0.7
Batch: 680; loss: 0.7; acc: 0.78
Batch: 700; loss: 0.97; acc: 0.69
Batch: 720; loss: 0.72; acc: 0.77
Batch: 740; loss: 0.93; acc: 0.67
Batch: 760; loss: 0.89; acc: 0.72
Batch: 780; loss: 0.54; acc: 0.8
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.84; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.8; acc: 0.8
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.96; acc: 0.75
Batch: 140; loss: 0.45; acc: 0.89
Val Epoch over. val_loss: 0.7665775302489093; val_accuracy: 0.7608479299363057 

The current subspace-distance is: 0.00012799554679077119 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.92; acc: 0.69
Batch: 20; loss: 0.9; acc: 0.69
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.91; acc: 0.72
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.82; acc: 0.73
Batch: 120; loss: 1.08; acc: 0.62
Batch: 140; loss: 1.12; acc: 0.59
Batch: 160; loss: 0.74; acc: 0.73
Batch: 180; loss: 0.93; acc: 0.77
Batch: 200; loss: 0.63; acc: 0.83
Batch: 220; loss: 0.71; acc: 0.73
Batch: 240; loss: 0.86; acc: 0.72
Batch: 260; loss: 0.97; acc: 0.7
Batch: 280; loss: 0.89; acc: 0.69
Batch: 300; loss: 1.08; acc: 0.7
Batch: 320; loss: 1.05; acc: 0.67
Batch: 340; loss: 0.7; acc: 0.78
Batch: 360; loss: 0.83; acc: 0.78
Batch: 380; loss: 0.93; acc: 0.67
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 1.0; acc: 0.69
Batch: 440; loss: 0.72; acc: 0.72
Batch: 460; loss: 0.98; acc: 0.7
Batch: 480; loss: 0.91; acc: 0.69
Batch: 500; loss: 0.87; acc: 0.72
Batch: 520; loss: 0.95; acc: 0.67
Batch: 540; loss: 1.29; acc: 0.61
Batch: 560; loss: 0.7; acc: 0.81
Batch: 580; loss: 0.81; acc: 0.81
Batch: 600; loss: 0.46; acc: 0.91
Batch: 620; loss: 0.94; acc: 0.75
Batch: 640; loss: 0.78; acc: 0.73
Batch: 660; loss: 0.71; acc: 0.86
Batch: 680; loss: 0.72; acc: 0.66
Batch: 700; loss: 0.79; acc: 0.73
Batch: 720; loss: 0.95; acc: 0.69
Batch: 740; loss: 0.73; acc: 0.83
Batch: 760; loss: 0.64; acc: 0.8
Batch: 780; loss: 0.8; acc: 0.75
Train Epoch over. train_loss: 0.82; train_accuracy: 0.74 

Batch: 0; loss: 0.82; acc: 0.8
Batch: 20; loss: 0.66; acc: 0.78
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.8; acc: 0.77
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.69; acc: 0.84
Batch: 120; loss: 0.96; acc: 0.72
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.7611802370305274; val_accuracy: 0.7648288216560509 

The current subspace-distance is: 0.00013143251999281347 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.83; acc: 0.75
Batch: 40; loss: 0.81; acc: 0.7
Batch: 60; loss: 0.78; acc: 0.78
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.73; acc: 0.77
Batch: 160; loss: 1.05; acc: 0.64
Batch: 180; loss: 0.88; acc: 0.83
Batch: 200; loss: 0.76; acc: 0.78
Batch: 220; loss: 0.79; acc: 0.72
Batch: 240; loss: 0.73; acc: 0.8
Batch: 260; loss: 1.04; acc: 0.77
Batch: 280; loss: 0.77; acc: 0.72
Batch: 300; loss: 0.86; acc: 0.77
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.68; acc: 0.83
Batch: 360; loss: 0.65; acc: 0.77
Batch: 380; loss: 1.29; acc: 0.66
Batch: 400; loss: 1.07; acc: 0.7
Batch: 420; loss: 0.83; acc: 0.73
Batch: 440; loss: 0.81; acc: 0.81
Batch: 460; loss: 0.67; acc: 0.8
Batch: 480; loss: 0.95; acc: 0.72
Batch: 500; loss: 0.77; acc: 0.78
Batch: 520; loss: 0.79; acc: 0.73
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.79; acc: 0.73
Batch: 580; loss: 0.79; acc: 0.8
Batch: 600; loss: 0.99; acc: 0.64
Batch: 620; loss: 0.82; acc: 0.69
Batch: 640; loss: 0.68; acc: 0.81
Batch: 660; loss: 0.75; acc: 0.81
Batch: 680; loss: 0.73; acc: 0.78
Batch: 700; loss: 0.72; acc: 0.78
Batch: 720; loss: 0.95; acc: 0.75
Batch: 740; loss: 0.7; acc: 0.78
Batch: 760; loss: 0.72; acc: 0.8
Batch: 780; loss: 0.87; acc: 0.67
Train Epoch over. train_loss: 0.81; train_accuracy: 0.75 

Batch: 0; loss: 0.79; acc: 0.81
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.78; acc: 0.8
Batch: 80; loss: 0.72; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.84
Batch: 120; loss: 0.98; acc: 0.73
Batch: 140; loss: 0.41; acc: 0.89
Val Epoch over. val_loss: 0.7519710808043267; val_accuracy: 0.7677149681528662 

The current subspace-distance is: 0.00013382562610786408 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.65; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.84
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.88; acc: 0.8
Batch: 80; loss: 1.01; acc: 0.62
Batch: 100; loss: 0.9; acc: 0.66
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.75; acc: 0.77
Batch: 160; loss: 0.53; acc: 0.91
Batch: 180; loss: 0.68; acc: 0.81
Batch: 200; loss: 0.53; acc: 0.81
Batch: 220; loss: 0.59; acc: 0.81
Batch: 240; loss: 0.67; acc: 0.8
Batch: 260; loss: 0.8; acc: 0.77
Batch: 280; loss: 0.84; acc: 0.77
Batch: 300; loss: 0.87; acc: 0.75
Batch: 320; loss: 1.15; acc: 0.67
Batch: 340; loss: 0.8; acc: 0.77
Batch: 360; loss: 0.73; acc: 0.78
Batch: 380; loss: 0.75; acc: 0.72
Batch: 400; loss: 0.65; acc: 0.8
Batch: 420; loss: 0.7; acc: 0.83
Batch: 440; loss: 0.87; acc: 0.66
Batch: 460; loss: 0.63; acc: 0.83
Batch: 480; loss: 0.85; acc: 0.72
Batch: 500; loss: 0.98; acc: 0.72
Batch: 520; loss: 0.76; acc: 0.72
Batch: 540; loss: 1.06; acc: 0.72
Batch: 560; loss: 0.78; acc: 0.78
Batch: 580; loss: 0.45; acc: 0.91
Batch: 600; loss: 0.9; acc: 0.73
Batch: 620; loss: 0.81; acc: 0.75
Batch: 640; loss: 0.81; acc: 0.81
Batch: 660; loss: 0.67; acc: 0.8
Batch: 680; loss: 0.73; acc: 0.73
Batch: 700; loss: 0.89; acc: 0.75
Batch: 720; loss: 1.05; acc: 0.69
Batch: 740; loss: 0.93; acc: 0.72
Batch: 760; loss: 0.93; acc: 0.69
Batch: 780; loss: 0.89; acc: 0.73
Train Epoch over. train_loss: 0.81; train_accuracy: 0.75 

Batch: 0; loss: 0.79; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.63; acc: 0.8
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.71; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.84
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.7532816276808453; val_accuracy: 0.7644307324840764 

The current subspace-distance is: 0.0001357559085590765 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.95; acc: 0.7
Batch: 20; loss: 0.84; acc: 0.78
Batch: 40; loss: 0.8; acc: 0.7
Batch: 60; loss: 0.7; acc: 0.81
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 0.95; acc: 0.8
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.95; acc: 0.77
Batch: 180; loss: 0.99; acc: 0.66
Batch: 200; loss: 1.05; acc: 0.72
Batch: 220; loss: 0.68; acc: 0.72
Batch: 240; loss: 0.84; acc: 0.7
Batch: 260; loss: 0.99; acc: 0.67
Batch: 280; loss: 0.89; acc: 0.75
Batch: 300; loss: 1.11; acc: 0.69
Batch: 320; loss: 0.74; acc: 0.75
Batch: 340; loss: 0.93; acc: 0.72
Batch: 360; loss: 0.86; acc: 0.75
Batch: 380; loss: 0.81; acc: 0.75
Batch: 400; loss: 0.75; acc: 0.8
Batch: 420; loss: 0.85; acc: 0.75
Batch: 440; loss: 0.79; acc: 0.8
Batch: 460; loss: 0.63; acc: 0.83
Batch: 480; loss: 0.76; acc: 0.8
Batch: 500; loss: 0.76; acc: 0.75
Batch: 520; loss: 0.64; acc: 0.77
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.7; acc: 0.77
Batch: 580; loss: 0.87; acc: 0.73
Batch: 600; loss: 0.65; acc: 0.75
Batch: 620; loss: 0.79; acc: 0.77
Batch: 640; loss: 0.98; acc: 0.67
Batch: 660; loss: 0.74; acc: 0.78
Batch: 680; loss: 0.62; acc: 0.78
Batch: 700; loss: 1.06; acc: 0.73
Batch: 720; loss: 0.81; acc: 0.78
Batch: 740; loss: 0.91; acc: 0.69
Batch: 760; loss: 0.9; acc: 0.69
Batch: 780; loss: 0.56; acc: 0.81
Train Epoch over. train_loss: 0.81; train_accuracy: 0.75 

Batch: 0; loss: 0.79; acc: 0.78
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.62; acc: 0.81
Batch: 60; loss: 0.78; acc: 0.78
Batch: 80; loss: 0.73; acc: 0.83
Batch: 100; loss: 0.69; acc: 0.83
Batch: 120; loss: 1.01; acc: 0.73
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.7509295219069074; val_accuracy: 0.7677149681528662 

The current subspace-distance is: 0.00013632593618240207 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.8; acc: 0.73
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 1.09; acc: 0.69
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.75; acc: 0.77
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.59; acc: 0.91
Batch: 200; loss: 1.02; acc: 0.7
Batch: 220; loss: 0.78; acc: 0.84
Batch: 240; loss: 0.87; acc: 0.73
Batch: 260; loss: 0.93; acc: 0.69
Batch: 280; loss: 0.98; acc: 0.72
Batch: 300; loss: 0.83; acc: 0.75
Batch: 320; loss: 0.81; acc: 0.69
Batch: 340; loss: 0.79; acc: 0.8
Batch: 360; loss: 0.84; acc: 0.72
Batch: 380; loss: 0.87; acc: 0.73
Batch: 400; loss: 0.87; acc: 0.8
Batch: 420; loss: 0.76; acc: 0.78
Batch: 440; loss: 0.94; acc: 0.7
Batch: 460; loss: 0.84; acc: 0.75
Batch: 480; loss: 0.62; acc: 0.75
Batch: 500; loss: 0.54; acc: 0.84
Batch: 520; loss: 0.66; acc: 0.78
Batch: 540; loss: 0.83; acc: 0.75
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.78; acc: 0.73
Batch: 600; loss: 1.02; acc: 0.69
Batch: 620; loss: 1.1; acc: 0.59
Batch: 640; loss: 0.74; acc: 0.75
Batch: 660; loss: 0.86; acc: 0.75
Batch: 680; loss: 0.62; acc: 0.78
Batch: 700; loss: 0.88; acc: 0.69
Batch: 720; loss: 0.63; acc: 0.8
Batch: 740; loss: 0.81; acc: 0.8
Batch: 760; loss: 0.75; acc: 0.77
Batch: 780; loss: 0.9; acc: 0.7
Train Epoch over. train_loss: 0.81; train_accuracy: 0.75 

Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.78; acc: 0.8
Batch: 80; loss: 0.72; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.83
Batch: 120; loss: 0.98; acc: 0.73
Batch: 140; loss: 0.39; acc: 0.89
Val Epoch over. val_loss: 0.7481097747945482; val_accuracy: 0.7689092356687898 

The current subspace-distance is: 0.00013986931298859417 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.89; acc: 0.69
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.72; acc: 0.77
Batch: 60; loss: 1.0; acc: 0.7
Batch: 80; loss: 0.97; acc: 0.73
Batch: 100; loss: 0.87; acc: 0.7
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.87; acc: 0.77
Batch: 160; loss: 0.53; acc: 0.86
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.7; acc: 0.78
Batch: 220; loss: 0.68; acc: 0.78
Batch: 240; loss: 0.74; acc: 0.77
Batch: 260; loss: 0.56; acc: 0.78
Batch: 280; loss: 0.72; acc: 0.75
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.95; acc: 0.7
Batch: 340; loss: 0.94; acc: 0.7
Batch: 360; loss: 0.78; acc: 0.75
Batch: 380; loss: 0.67; acc: 0.77
Batch: 400; loss: 0.58; acc: 0.83
Batch: 420; loss: 0.75; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 1.04; acc: 0.64
Batch: 500; loss: 0.77; acc: 0.77
Batch: 520; loss: 0.79; acc: 0.73
Batch: 540; loss: 0.96; acc: 0.75
Batch: 560; loss: 0.69; acc: 0.8
Batch: 580; loss: 1.15; acc: 0.67
Batch: 600; loss: 0.94; acc: 0.77
Batch: 620; loss: 0.74; acc: 0.78
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.73; acc: 0.78
Batch: 680; loss: 0.7; acc: 0.75
Batch: 700; loss: 0.75; acc: 0.78
Batch: 720; loss: 0.94; acc: 0.77
Batch: 740; loss: 0.82; acc: 0.77
Batch: 760; loss: 0.73; acc: 0.75
Batch: 780; loss: 0.7; acc: 0.78
Train Epoch over. train_loss: 0.81; train_accuracy: 0.75 

Batch: 0; loss: 0.77; acc: 0.8
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 0.78; acc: 0.78
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.98; acc: 0.72
Batch: 140; loss: 0.4; acc: 0.88
Val Epoch over. val_loss: 0.7487243666390705; val_accuracy: 0.7682125796178344 

The current subspace-distance is: 0.00014253228437155485 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.72; acc: 0.8
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 0.84; acc: 0.77
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.47; acc: 0.92
Batch: 160; loss: 0.81; acc: 0.72
Batch: 180; loss: 0.79; acc: 0.78
Batch: 200; loss: 0.79; acc: 0.73
Batch: 220; loss: 0.79; acc: 0.75
Batch: 240; loss: 1.0; acc: 0.7
Batch: 260; loss: 0.66; acc: 0.77
Batch: 280; loss: 0.91; acc: 0.72
Batch: 300; loss: 0.71; acc: 0.7
Batch: 320; loss: 0.8; acc: 0.75
Batch: 340; loss: 1.07; acc: 0.59
Batch: 360; loss: 1.21; acc: 0.56
Batch: 380; loss: 1.22; acc: 0.59
Batch: 400; loss: 0.83; acc: 0.75
Batch: 420; loss: 1.08; acc: 0.73
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.71; acc: 0.78
Batch: 480; loss: 0.83; acc: 0.73
Batch: 500; loss: 0.77; acc: 0.8
Batch: 520; loss: 0.95; acc: 0.69
Batch: 540; loss: 0.82; acc: 0.72
Batch: 560; loss: 0.6; acc: 0.84
Batch: 580; loss: 0.93; acc: 0.78
Batch: 600; loss: 0.84; acc: 0.75
Batch: 620; loss: 0.89; acc: 0.69
Batch: 640; loss: 0.49; acc: 0.81
Batch: 660; loss: 0.82; acc: 0.7
Batch: 680; loss: 0.97; acc: 0.69
Batch: 700; loss: 0.67; acc: 0.77
Batch: 720; loss: 1.14; acc: 0.7
Batch: 740; loss: 0.73; acc: 0.77
Batch: 760; loss: 0.74; acc: 0.75
Batch: 780; loss: 0.78; acc: 0.77
Train Epoch over. train_loss: 0.8; train_accuracy: 0.75 

Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.61; acc: 0.8
Batch: 60; loss: 0.78; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.83
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.37; acc: 0.91
Val Epoch over. val_loss: 0.7476833303263233; val_accuracy: 0.7680135350318471 

The current subspace-distance is: 0.00014478163211606443 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.75
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.84; acc: 0.66
Batch: 60; loss: 0.94; acc: 0.72
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 0.83; acc: 0.73
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.88; acc: 0.75
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.74; acc: 0.73
Batch: 200; loss: 0.79; acc: 0.75
Batch: 220; loss: 0.98; acc: 0.77
Batch: 240; loss: 0.81; acc: 0.72
Batch: 260; loss: 0.9; acc: 0.64
Batch: 280; loss: 0.69; acc: 0.77
Batch: 300; loss: 0.65; acc: 0.78
Batch: 320; loss: 0.68; acc: 0.77
Batch: 340; loss: 0.81; acc: 0.75
Batch: 360; loss: 0.6; acc: 0.88
Batch: 380; loss: 1.37; acc: 0.64
Batch: 400; loss: 0.58; acc: 0.84
Batch: 420; loss: 0.83; acc: 0.78
Batch: 440; loss: 0.71; acc: 0.77
Batch: 460; loss: 0.81; acc: 0.75
Batch: 480; loss: 0.9; acc: 0.67
Batch: 500; loss: 1.01; acc: 0.72
Batch: 520; loss: 0.88; acc: 0.78
Batch: 540; loss: 0.93; acc: 0.67
Batch: 560; loss: 0.72; acc: 0.75
Batch: 580; loss: 0.83; acc: 0.81
Batch: 600; loss: 0.84; acc: 0.73
Batch: 620; loss: 0.77; acc: 0.81
Batch: 640; loss: 0.88; acc: 0.8
Batch: 660; loss: 0.9; acc: 0.72
Batch: 680; loss: 0.86; acc: 0.77
Batch: 700; loss: 0.83; acc: 0.73
Batch: 720; loss: 0.8; acc: 0.7
Batch: 740; loss: 0.57; acc: 0.78
Batch: 760; loss: 1.28; acc: 0.67
Batch: 780; loss: 0.66; acc: 0.8
Train Epoch over. train_loss: 0.8; train_accuracy: 0.75 

Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.61; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.99; acc: 0.73
Batch: 140; loss: 0.38; acc: 0.91
Val Epoch over. val_loss: 0.7449899454405353; val_accuracy: 0.7688097133757962 

The current subspace-distance is: 0.00014683247718494385 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.88; acc: 0.78
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.72; acc: 0.73
Batch: 100; loss: 1.11; acc: 0.73
Batch: 120; loss: 0.9; acc: 0.73
Batch: 140; loss: 0.79; acc: 0.73
Batch: 160; loss: 0.85; acc: 0.73
Batch: 180; loss: 0.79; acc: 0.7
Batch: 200; loss: 0.89; acc: 0.77
Batch: 220; loss: 0.75; acc: 0.8
Batch: 240; loss: 0.74; acc: 0.81
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.87; acc: 0.72
Batch: 300; loss: 0.91; acc: 0.72
Batch: 320; loss: 0.94; acc: 0.72
Batch: 340; loss: 0.83; acc: 0.73
Batch: 360; loss: 1.03; acc: 0.7
Batch: 380; loss: 0.74; acc: 0.72
Batch: 400; loss: 1.35; acc: 0.66
Batch: 420; loss: 0.58; acc: 0.88
Batch: 440; loss: 0.6; acc: 0.86
Batch: 460; loss: 0.8; acc: 0.78
Batch: 480; loss: 0.57; acc: 0.8
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.59; acc: 0.8
Batch: 540; loss: 1.0; acc: 0.7
Batch: 560; loss: 0.72; acc: 0.72
Batch: 580; loss: 0.68; acc: 0.86
Batch: 600; loss: 0.72; acc: 0.75
Batch: 620; loss: 0.69; acc: 0.8
Batch: 640; loss: 0.98; acc: 0.7
Batch: 660; loss: 0.9; acc: 0.75
Batch: 680; loss: 0.86; acc: 0.73
Batch: 700; loss: 0.66; acc: 0.8
Batch: 720; loss: 1.36; acc: 0.59
Batch: 740; loss: 0.8; acc: 0.72
Batch: 760; loss: 0.78; acc: 0.75
Batch: 780; loss: 0.76; acc: 0.77
Train Epoch over. train_loss: 0.8; train_accuracy: 0.75 

Batch: 0; loss: 0.74; acc: 0.81
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.83
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.38; acc: 0.91
Val Epoch over. val_loss: 0.7434084684985458; val_accuracy: 0.7701035031847133 

The current subspace-distance is: 0.0001501416991231963 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.89; acc: 0.66
Batch: 20; loss: 0.87; acc: 0.75
Batch: 40; loss: 0.73; acc: 0.81
Batch: 60; loss: 0.82; acc: 0.7
Batch: 80; loss: 0.58; acc: 0.81
Batch: 100; loss: 0.6; acc: 0.83
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 1.07; acc: 0.62
Batch: 160; loss: 0.68; acc: 0.84
Batch: 180; loss: 0.97; acc: 0.69
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 1.13; acc: 0.7
Batch: 240; loss: 0.81; acc: 0.73
Batch: 260; loss: 0.64; acc: 0.75
Batch: 280; loss: 0.86; acc: 0.73
Batch: 300; loss: 0.96; acc: 0.66
Batch: 320; loss: 0.54; acc: 0.89
Batch: 340; loss: 0.68; acc: 0.75
Batch: 360; loss: 0.78; acc: 0.78
Batch: 380; loss: 0.69; acc: 0.78
Batch: 400; loss: 0.78; acc: 0.78
Batch: 420; loss: 0.97; acc: 0.67
Batch: 440; loss: 0.74; acc: 0.73
Batch: 460; loss: 0.73; acc: 0.75
Batch: 480; loss: 0.84; acc: 0.75
Batch: 500; loss: 0.61; acc: 0.81
Batch: 520; loss: 0.64; acc: 0.83
Batch: 540; loss: 0.94; acc: 0.7
Batch: 560; loss: 0.92; acc: 0.69
Batch: 580; loss: 0.82; acc: 0.78
Batch: 600; loss: 0.94; acc: 0.67
Batch: 620; loss: 1.13; acc: 0.66
Batch: 640; loss: 0.8; acc: 0.75
Batch: 660; loss: 1.14; acc: 0.67
Batch: 680; loss: 0.9; acc: 0.66
Batch: 700; loss: 0.88; acc: 0.78
Batch: 720; loss: 0.68; acc: 0.77
Batch: 740; loss: 1.02; acc: 0.72
Batch: 760; loss: 0.67; acc: 0.75
Batch: 780; loss: 0.97; acc: 0.7
Train Epoch over. train_loss: 0.8; train_accuracy: 0.75 

Batch: 0; loss: 0.73; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.69; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.83
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.7422042587760148; val_accuracy: 0.7688097133757962 

The current subspace-distance is: 0.00015264842659235 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.58; acc: 0.84
Batch: 20; loss: 0.82; acc: 0.72
Batch: 40; loss: 0.82; acc: 0.77
Batch: 60; loss: 1.04; acc: 0.69
Batch: 80; loss: 0.75; acc: 0.73
Batch: 100; loss: 0.75; acc: 0.75
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.63; acc: 0.77
Batch: 160; loss: 0.66; acc: 0.78
Batch: 180; loss: 0.95; acc: 0.77
Batch: 200; loss: 0.76; acc: 0.8
Batch: 220; loss: 1.11; acc: 0.7
Batch: 240; loss: 0.83; acc: 0.7
Batch: 260; loss: 0.93; acc: 0.72
Batch: 280; loss: 0.64; acc: 0.78
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 1.02; acc: 0.69
Batch: 340; loss: 0.61; acc: 0.8
Batch: 360; loss: 0.78; acc: 0.7
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.91; acc: 0.75
Batch: 420; loss: 0.8; acc: 0.8
Batch: 440; loss: 0.66; acc: 0.78
Batch: 460; loss: 0.94; acc: 0.72
Batch: 480; loss: 0.77; acc: 0.8
Batch: 500; loss: 0.67; acc: 0.78
Batch: 520; loss: 0.83; acc: 0.78
Batch: 540; loss: 0.77; acc: 0.81
Batch: 560; loss: 0.81; acc: 0.72
Batch: 580; loss: 0.84; acc: 0.75
Batch: 600; loss: 0.84; acc: 0.73
Batch: 620; loss: 0.66; acc: 0.8
Batch: 640; loss: 0.62; acc: 0.86
Batch: 660; loss: 0.85; acc: 0.72
Batch: 680; loss: 0.88; acc: 0.69
Batch: 700; loss: 0.94; acc: 0.7
Batch: 720; loss: 0.81; acc: 0.75
Batch: 740; loss: 1.15; acc: 0.66
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.67; acc: 0.77
Train Epoch over. train_loss: 0.8; train_accuracy: 0.75 

Batch: 0; loss: 0.72; acc: 0.81
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.69; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 1.01; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.7400573169349864; val_accuracy: 0.7686106687898089 

The current subspace-distance is: 0.00015310654998756945 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 0.97; acc: 0.7
Batch: 40; loss: 0.72; acc: 0.78
Batch: 60; loss: 0.66; acc: 0.84
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 0.85; acc: 0.73
Batch: 120; loss: 1.04; acc: 0.73
Batch: 140; loss: 0.81; acc: 0.7
Batch: 160; loss: 0.72; acc: 0.78
Batch: 180; loss: 0.78; acc: 0.81
Batch: 200; loss: 0.73; acc: 0.78
Batch: 220; loss: 0.8; acc: 0.7
Batch: 240; loss: 0.99; acc: 0.72
Batch: 260; loss: 0.81; acc: 0.77
Batch: 280; loss: 0.74; acc: 0.7
Batch: 300; loss: 0.77; acc: 0.73
Batch: 320; loss: 0.81; acc: 0.7
Batch: 340; loss: 1.1; acc: 0.66
Batch: 360; loss: 0.57; acc: 0.78
Batch: 380; loss: 0.74; acc: 0.8
Batch: 400; loss: 0.87; acc: 0.69
Batch: 420; loss: 0.7; acc: 0.78
Batch: 440; loss: 0.92; acc: 0.73
Batch: 460; loss: 0.86; acc: 0.75
Batch: 480; loss: 0.75; acc: 0.66
Batch: 500; loss: 0.8; acc: 0.78
Batch: 520; loss: 0.55; acc: 0.8
Batch: 540; loss: 1.02; acc: 0.72
Batch: 560; loss: 1.17; acc: 0.66
Batch: 580; loss: 0.78; acc: 0.78
Batch: 600; loss: 0.77; acc: 0.83
Batch: 620; loss: 1.04; acc: 0.62
Batch: 640; loss: 0.77; acc: 0.73
Batch: 660; loss: 0.74; acc: 0.73
Batch: 680; loss: 1.22; acc: 0.66
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.62; acc: 0.81
Batch: 740; loss: 0.97; acc: 0.7
Batch: 760; loss: 0.86; acc: 0.7
Batch: 780; loss: 0.61; acc: 0.81
Train Epoch over. train_loss: 0.8; train_accuracy: 0.75 

Batch: 0; loss: 0.73; acc: 0.8
Batch: 20; loss: 0.62; acc: 0.78
Batch: 40; loss: 0.6; acc: 0.83
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.81
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.37; acc: 0.91
Val Epoch over. val_loss: 0.7386352507172117; val_accuracy: 0.7708001592356688 

The current subspace-distance is: 0.00015514844562858343 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 1.03; acc: 0.66
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.79; acc: 0.75
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.85; acc: 0.7
Batch: 140; loss: 0.8; acc: 0.8
Batch: 160; loss: 0.71; acc: 0.75
Batch: 180; loss: 0.8; acc: 0.73
Batch: 200; loss: 0.71; acc: 0.8
Batch: 220; loss: 0.81; acc: 0.75
Batch: 240; loss: 0.75; acc: 0.78
Batch: 260; loss: 0.68; acc: 0.83
Batch: 280; loss: 0.62; acc: 0.83
Batch: 300; loss: 0.84; acc: 0.72
Batch: 320; loss: 0.92; acc: 0.69
Batch: 340; loss: 0.82; acc: 0.73
Batch: 360; loss: 0.92; acc: 0.72
Batch: 380; loss: 0.87; acc: 0.72
Batch: 400; loss: 0.97; acc: 0.72
Batch: 420; loss: 0.65; acc: 0.81
Batch: 440; loss: 0.85; acc: 0.72
Batch: 460; loss: 1.09; acc: 0.66
Batch: 480; loss: 0.77; acc: 0.78
Batch: 500; loss: 1.03; acc: 0.69
Batch: 520; loss: 1.11; acc: 0.75
Batch: 540; loss: 0.63; acc: 0.81
Batch: 560; loss: 0.76; acc: 0.73
Batch: 580; loss: 0.76; acc: 0.81
Batch: 600; loss: 0.98; acc: 0.67
Batch: 620; loss: 0.67; acc: 0.83
Batch: 640; loss: 0.77; acc: 0.78
Batch: 660; loss: 0.63; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.77
Batch: 700; loss: 0.66; acc: 0.8
Batch: 720; loss: 0.74; acc: 0.78
Batch: 740; loss: 0.75; acc: 0.78
Batch: 760; loss: 0.72; acc: 0.69
Batch: 780; loss: 0.97; acc: 0.7
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.72; acc: 0.81
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 0.99; acc: 0.72
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.737795420892679; val_accuracy: 0.7706011146496815 

The current subspace-distance is: 0.00015579805767629296 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.71; acc: 0.77
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.78; acc: 0.77
Batch: 80; loss: 1.21; acc: 0.66
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 1.02; acc: 0.75
Batch: 140; loss: 0.65; acc: 0.75
Batch: 160; loss: 0.71; acc: 0.73
Batch: 180; loss: 1.08; acc: 0.7
Batch: 200; loss: 0.47; acc: 0.83
Batch: 220; loss: 0.73; acc: 0.77
Batch: 240; loss: 0.99; acc: 0.72
Batch: 260; loss: 0.51; acc: 0.84
Batch: 280; loss: 0.82; acc: 0.69
Batch: 300; loss: 0.73; acc: 0.77
Batch: 320; loss: 0.84; acc: 0.72
Batch: 340; loss: 0.72; acc: 0.75
Batch: 360; loss: 0.94; acc: 0.75
Batch: 380; loss: 0.81; acc: 0.78
Batch: 400; loss: 0.83; acc: 0.73
Batch: 420; loss: 0.78; acc: 0.75
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.68; acc: 0.77
Batch: 480; loss: 0.74; acc: 0.78
Batch: 500; loss: 0.57; acc: 0.84
Batch: 520; loss: 0.97; acc: 0.72
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.59; acc: 0.81
Batch: 580; loss: 0.97; acc: 0.64
Batch: 600; loss: 0.94; acc: 0.72
Batch: 620; loss: 0.9; acc: 0.77
Batch: 640; loss: 0.76; acc: 0.77
Batch: 660; loss: 0.92; acc: 0.62
Batch: 680; loss: 0.9; acc: 0.72
Batch: 700; loss: 0.87; acc: 0.72
Batch: 720; loss: 0.86; acc: 0.73
Batch: 740; loss: 1.01; acc: 0.67
Batch: 760; loss: 0.8; acc: 0.75
Batch: 780; loss: 0.75; acc: 0.78
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.89
Val Epoch over. val_loss: 0.7387350989375144; val_accuracy: 0.7698049363057324 

The current subspace-distance is: 0.000156713867909275 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.78; acc: 0.72
Batch: 20; loss: 0.97; acc: 0.73
Batch: 40; loss: 0.77; acc: 0.8
Batch: 60; loss: 0.81; acc: 0.72
Batch: 80; loss: 0.74; acc: 0.77
Batch: 100; loss: 0.72; acc: 0.81
Batch: 120; loss: 0.91; acc: 0.72
Batch: 140; loss: 0.52; acc: 0.89
Batch: 160; loss: 0.8; acc: 0.78
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.87; acc: 0.75
Batch: 220; loss: 0.98; acc: 0.7
Batch: 240; loss: 0.73; acc: 0.75
Batch: 260; loss: 0.58; acc: 0.81
Batch: 280; loss: 0.73; acc: 0.7
Batch: 300; loss: 0.82; acc: 0.7
Batch: 320; loss: 0.59; acc: 0.8
Batch: 340; loss: 0.78; acc: 0.8
Batch: 360; loss: 0.94; acc: 0.7
Batch: 380; loss: 0.8; acc: 0.67
Batch: 400; loss: 0.85; acc: 0.73
Batch: 420; loss: 0.68; acc: 0.78
Batch: 440; loss: 0.91; acc: 0.73
Batch: 460; loss: 0.84; acc: 0.77
Batch: 480; loss: 0.79; acc: 0.72
Batch: 500; loss: 0.64; acc: 0.77
Batch: 520; loss: 0.75; acc: 0.75
Batch: 540; loss: 0.81; acc: 0.75
Batch: 560; loss: 0.74; acc: 0.8
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.59; acc: 0.83
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 0.93; acc: 0.72
Batch: 660; loss: 0.59; acc: 0.78
Batch: 680; loss: 0.99; acc: 0.72
Batch: 700; loss: 0.65; acc: 0.75
Batch: 720; loss: 0.81; acc: 0.73
Batch: 740; loss: 0.63; acc: 0.78
Batch: 760; loss: 0.55; acc: 0.77
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.71; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.76; acc: 0.78
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.99; acc: 0.75
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.7374041818889083; val_accuracy: 0.7708996815286624 

The current subspace-distance is: 0.00016080944624263793 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.82; acc: 0.72
Batch: 40; loss: 0.92; acc: 0.72
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.76; acc: 0.81
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.86; acc: 0.7
Batch: 160; loss: 0.69; acc: 0.8
Batch: 180; loss: 0.69; acc: 0.8
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 1.04; acc: 0.66
Batch: 240; loss: 0.52; acc: 0.86
Batch: 260; loss: 1.08; acc: 0.61
Batch: 280; loss: 0.73; acc: 0.86
Batch: 300; loss: 0.85; acc: 0.73
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.59; acc: 0.81
Batch: 360; loss: 0.56; acc: 0.78
Batch: 380; loss: 0.88; acc: 0.72
Batch: 400; loss: 0.96; acc: 0.77
Batch: 420; loss: 0.87; acc: 0.69
Batch: 440; loss: 0.78; acc: 0.78
Batch: 460; loss: 0.75; acc: 0.73
Batch: 480; loss: 0.66; acc: 0.78
Batch: 500; loss: 0.59; acc: 0.81
Batch: 520; loss: 0.72; acc: 0.73
Batch: 540; loss: 0.63; acc: 0.75
Batch: 560; loss: 0.75; acc: 0.8
Batch: 580; loss: 0.71; acc: 0.77
Batch: 600; loss: 0.83; acc: 0.7
Batch: 620; loss: 0.67; acc: 0.81
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 1.0; acc: 0.67
Batch: 680; loss: 0.62; acc: 0.84
Batch: 700; loss: 1.06; acc: 0.66
Batch: 720; loss: 1.0; acc: 0.62
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.87; acc: 0.66
Batch: 780; loss: 0.62; acc: 0.83
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.72; acc: 0.81
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.99; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.7370156357242803; val_accuracy: 0.7707006369426752 

The current subspace-distance is: 0.0001655292435316369 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.92; acc: 0.7
Batch: 60; loss: 0.81; acc: 0.75
Batch: 80; loss: 1.1; acc: 0.64
Batch: 100; loss: 0.93; acc: 0.69
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.68; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.7; acc: 0.84
Batch: 200; loss: 0.71; acc: 0.83
Batch: 220; loss: 0.73; acc: 0.8
Batch: 240; loss: 0.78; acc: 0.69
Batch: 260; loss: 0.6; acc: 0.78
Batch: 280; loss: 0.64; acc: 0.78
Batch: 300; loss: 0.74; acc: 0.75
Batch: 320; loss: 0.92; acc: 0.78
Batch: 340; loss: 0.71; acc: 0.75
Batch: 360; loss: 0.8; acc: 0.78
Batch: 380; loss: 0.88; acc: 0.7
Batch: 400; loss: 0.99; acc: 0.7
Batch: 420; loss: 0.61; acc: 0.77
Batch: 440; loss: 0.78; acc: 0.77
Batch: 460; loss: 0.68; acc: 0.78
Batch: 480; loss: 0.93; acc: 0.67
Batch: 500; loss: 0.77; acc: 0.77
Batch: 520; loss: 0.93; acc: 0.66
Batch: 540; loss: 0.92; acc: 0.73
Batch: 560; loss: 0.98; acc: 0.66
Batch: 580; loss: 0.74; acc: 0.75
Batch: 600; loss: 0.76; acc: 0.77
Batch: 620; loss: 0.91; acc: 0.69
Batch: 640; loss: 0.66; acc: 0.73
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.55; acc: 0.8
Batch: 700; loss: 0.61; acc: 0.84
Batch: 720; loss: 0.77; acc: 0.75
Batch: 740; loss: 0.63; acc: 0.84
Batch: 760; loss: 0.72; acc: 0.81
Batch: 780; loss: 0.74; acc: 0.67
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.71; acc: 0.81
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.59; acc: 0.83
Batch: 60; loss: 0.77; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.81
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.35; acc: 0.91
Val Epoch over. val_loss: 0.7354370879519517; val_accuracy: 0.7701035031847133 

The current subspace-distance is: 0.000167499587405473 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 1.07; acc: 0.73
Batch: 40; loss: 0.92; acc: 0.77
Batch: 60; loss: 0.93; acc: 0.73
Batch: 80; loss: 0.98; acc: 0.72
Batch: 100; loss: 0.94; acc: 0.69
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.73; acc: 0.8
Batch: 160; loss: 0.99; acc: 0.69
Batch: 180; loss: 0.81; acc: 0.77
Batch: 200; loss: 0.62; acc: 0.77
Batch: 220; loss: 0.6; acc: 0.81
Batch: 240; loss: 0.9; acc: 0.72
Batch: 260; loss: 0.82; acc: 0.77
Batch: 280; loss: 0.64; acc: 0.72
Batch: 300; loss: 0.9; acc: 0.72
Batch: 320; loss: 0.8; acc: 0.81
Batch: 340; loss: 0.93; acc: 0.72
Batch: 360; loss: 0.72; acc: 0.78
Batch: 380; loss: 0.74; acc: 0.72
Batch: 400; loss: 0.64; acc: 0.78
Batch: 420; loss: 0.94; acc: 0.77
Batch: 440; loss: 0.78; acc: 0.72
Batch: 460; loss: 0.66; acc: 0.78
Batch: 480; loss: 0.7; acc: 0.83
Batch: 500; loss: 0.9; acc: 0.7
Batch: 520; loss: 0.94; acc: 0.75
Batch: 540; loss: 0.66; acc: 0.77
Batch: 560; loss: 0.84; acc: 0.8
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.72; acc: 0.78
Batch: 620; loss: 0.72; acc: 0.86
Batch: 640; loss: 0.81; acc: 0.72
Batch: 660; loss: 0.88; acc: 0.69
Batch: 680; loss: 0.75; acc: 0.75
Batch: 700; loss: 0.93; acc: 0.62
Batch: 720; loss: 1.13; acc: 0.66
Batch: 740; loss: 0.85; acc: 0.7
Batch: 760; loss: 0.82; acc: 0.7
Batch: 780; loss: 0.77; acc: 0.73
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.71; acc: 0.81
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.78
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.35; acc: 0.91
Val Epoch over. val_loss: 0.7351894063554751; val_accuracy: 0.7705015923566879 

The current subspace-distance is: 0.00017078116070479155 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.91; acc: 0.7
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.8; acc: 0.77
Batch: 60; loss: 0.89; acc: 0.75
Batch: 80; loss: 0.99; acc: 0.66
Batch: 100; loss: 0.76; acc: 0.77
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 1.04; acc: 0.64
Batch: 160; loss: 0.72; acc: 0.75
Batch: 180; loss: 0.56; acc: 0.84
Batch: 200; loss: 0.77; acc: 0.75
Batch: 220; loss: 0.75; acc: 0.75
Batch: 240; loss: 1.2; acc: 0.67
Batch: 260; loss: 1.03; acc: 0.69
Batch: 280; loss: 0.62; acc: 0.8
Batch: 300; loss: 0.98; acc: 0.67
Batch: 320; loss: 0.85; acc: 0.72
Batch: 340; loss: 0.63; acc: 0.8
Batch: 360; loss: 0.82; acc: 0.78
Batch: 380; loss: 0.85; acc: 0.69
Batch: 400; loss: 0.96; acc: 0.7
Batch: 420; loss: 0.7; acc: 0.81
Batch: 440; loss: 0.57; acc: 0.77
Batch: 460; loss: 0.91; acc: 0.66
Batch: 480; loss: 0.93; acc: 0.69
Batch: 500; loss: 0.58; acc: 0.8
Batch: 520; loss: 0.99; acc: 0.72
Batch: 540; loss: 0.69; acc: 0.77
Batch: 560; loss: 0.71; acc: 0.73
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.81; acc: 0.77
Batch: 620; loss: 0.91; acc: 0.72
Batch: 640; loss: 0.83; acc: 0.7
Batch: 660; loss: 1.1; acc: 0.66
Batch: 680; loss: 0.69; acc: 0.8
Batch: 700; loss: 0.84; acc: 0.77
Batch: 720; loss: 0.76; acc: 0.8
Batch: 740; loss: 0.89; acc: 0.73
Batch: 760; loss: 0.89; acc: 0.72
Batch: 780; loss: 0.75; acc: 0.8
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.71; acc: 0.83
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 1.0; acc: 0.73
Batch: 140; loss: 0.35; acc: 0.91
Val Epoch over. val_loss: 0.733955129316658; val_accuracy: 0.7697054140127388 

The current subspace-distance is: 0.00017300277249887586 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.76; acc: 0.73
Batch: 20; loss: 0.97; acc: 0.69
Batch: 40; loss: 0.98; acc: 0.67
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.74; acc: 0.78
Batch: 100; loss: 0.79; acc: 0.7
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.7; acc: 0.78
Batch: 160; loss: 1.12; acc: 0.64
Batch: 180; loss: 0.77; acc: 0.77
Batch: 200; loss: 0.83; acc: 0.75
Batch: 220; loss: 0.68; acc: 0.78
Batch: 240; loss: 0.71; acc: 0.77
Batch: 260; loss: 0.8; acc: 0.73
Batch: 280; loss: 0.61; acc: 0.75
Batch: 300; loss: 0.78; acc: 0.77
Batch: 320; loss: 0.69; acc: 0.8
Batch: 340; loss: 0.69; acc: 0.72
Batch: 360; loss: 0.89; acc: 0.73
Batch: 380; loss: 0.89; acc: 0.67
Batch: 400; loss: 0.75; acc: 0.81
Batch: 420; loss: 1.17; acc: 0.66
Batch: 440; loss: 0.82; acc: 0.77
Batch: 460; loss: 0.79; acc: 0.78
Batch: 480; loss: 0.84; acc: 0.73
Batch: 500; loss: 0.61; acc: 0.84
Batch: 520; loss: 0.94; acc: 0.73
Batch: 540; loss: 0.79; acc: 0.81
Batch: 560; loss: 0.75; acc: 0.73
Batch: 580; loss: 0.78; acc: 0.73
Batch: 600; loss: 0.82; acc: 0.72
Batch: 620; loss: 0.59; acc: 0.84
Batch: 640; loss: 0.64; acc: 0.81
Batch: 660; loss: 0.79; acc: 0.75
Batch: 680; loss: 0.75; acc: 0.8
Batch: 700; loss: 0.77; acc: 0.75
Batch: 720; loss: 1.03; acc: 0.73
Batch: 740; loss: 0.78; acc: 0.73
Batch: 760; loss: 0.98; acc: 0.73
Batch: 780; loss: 1.0; acc: 0.72
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.7; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.99; acc: 0.73
Batch: 140; loss: 0.35; acc: 0.91
Val Epoch over. val_loss: 0.7339891897644967; val_accuracy: 0.7715963375796179 

The current subspace-distance is: 0.00017506851872894913 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.81; acc: 0.72
Batch: 40; loss: 1.07; acc: 0.67
Batch: 60; loss: 0.98; acc: 0.7
Batch: 80; loss: 0.83; acc: 0.73
Batch: 100; loss: 0.78; acc: 0.75
Batch: 120; loss: 0.9; acc: 0.77
Batch: 140; loss: 0.94; acc: 0.73
Batch: 160; loss: 0.73; acc: 0.84
Batch: 180; loss: 0.72; acc: 0.75
Batch: 200; loss: 0.82; acc: 0.77
Batch: 220; loss: 0.78; acc: 0.78
Batch: 240; loss: 0.77; acc: 0.69
Batch: 260; loss: 0.62; acc: 0.8
Batch: 280; loss: 0.89; acc: 0.7
Batch: 300; loss: 1.08; acc: 0.62
Batch: 320; loss: 0.87; acc: 0.73
Batch: 340; loss: 0.88; acc: 0.75
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 0.93; acc: 0.73
Batch: 400; loss: 0.98; acc: 0.67
Batch: 420; loss: 0.74; acc: 0.83
Batch: 440; loss: 0.95; acc: 0.73
Batch: 460; loss: 0.86; acc: 0.77
Batch: 480; loss: 1.03; acc: 0.72
Batch: 500; loss: 1.07; acc: 0.72
Batch: 520; loss: 0.8; acc: 0.66
Batch: 540; loss: 0.66; acc: 0.8
Batch: 560; loss: 0.77; acc: 0.75
Batch: 580; loss: 0.83; acc: 0.78
Batch: 600; loss: 0.72; acc: 0.72
Batch: 620; loss: 0.6; acc: 0.8
Batch: 640; loss: 0.6; acc: 0.84
Batch: 660; loss: 0.78; acc: 0.77
Batch: 680; loss: 1.08; acc: 0.62
Batch: 700; loss: 0.83; acc: 0.75
Batch: 720; loss: 0.87; acc: 0.7
Batch: 740; loss: 0.69; acc: 0.78
Batch: 760; loss: 0.87; acc: 0.77
Batch: 780; loss: 0.76; acc: 0.78
Train Epoch over. train_loss: 0.79; train_accuracy: 0.75 

Batch: 0; loss: 0.7; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 1.01; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.91
Val Epoch over. val_loss: 0.7323914944745933; val_accuracy: 0.7708001592356688 

The current subspace-distance is: 0.0001785152853699401 

plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 42071
elements in E: 8790400
fraction nonzero: 0.0047860165635238445
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.35; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.17
Batch: 40; loss: 2.31; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.26; acc: 0.17
Batch: 100; loss: 2.25; acc: 0.19
Batch: 120; loss: 2.24; acc: 0.27
Batch: 140; loss: 2.24; acc: 0.22
Batch: 160; loss: 2.24; acc: 0.25
Batch: 180; loss: 2.28; acc: 0.14
Batch: 200; loss: 2.24; acc: 0.22
Batch: 220; loss: 2.23; acc: 0.11
Batch: 240; loss: 2.19; acc: 0.25
Batch: 260; loss: 2.17; acc: 0.34
Batch: 280; loss: 2.14; acc: 0.41
Batch: 300; loss: 2.14; acc: 0.38
Batch: 320; loss: 2.04; acc: 0.41
Batch: 340; loss: 1.97; acc: 0.41
Batch: 360; loss: 2.02; acc: 0.39
Batch: 380; loss: 2.1; acc: 0.25
Batch: 400; loss: 1.92; acc: 0.36
Batch: 420; loss: 1.94; acc: 0.34
Batch: 440; loss: 1.89; acc: 0.3
Batch: 460; loss: 1.76; acc: 0.39
Batch: 480; loss: 1.62; acc: 0.42
Batch: 500; loss: 1.54; acc: 0.56
Batch: 520; loss: 1.44; acc: 0.44
Batch: 540; loss: 1.6; acc: 0.44
Batch: 560; loss: 1.58; acc: 0.5
Batch: 580; loss: 1.32; acc: 0.56
Batch: 600; loss: 1.15; acc: 0.58
Batch: 620; loss: 1.5; acc: 0.44
Batch: 640; loss: 1.18; acc: 0.66
Batch: 660; loss: 1.54; acc: 0.45
Batch: 680; loss: 1.29; acc: 0.61
Batch: 700; loss: 1.12; acc: 0.64
Batch: 720; loss: 1.17; acc: 0.67
Batch: 740; loss: 1.26; acc: 0.56
Batch: 760; loss: 1.68; acc: 0.39
Batch: 780; loss: 0.8; acc: 0.75
Train Epoch over. train_loss: 1.8; train_accuracy: 0.4 

Batch: 0; loss: 1.06; acc: 0.61
Batch: 20; loss: 1.13; acc: 0.55
Batch: 40; loss: 1.09; acc: 0.64
Batch: 60; loss: 1.05; acc: 0.59
Batch: 80; loss: 1.08; acc: 0.59
Batch: 100; loss: 0.96; acc: 0.61
Batch: 120; loss: 1.16; acc: 0.64
Batch: 140; loss: 0.92; acc: 0.69
Val Epoch over. val_loss: 1.117703114345575; val_accuracy: 0.6025079617834395 

The current subspace-distance is: 1.5341220205300488e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.66
Batch: 20; loss: 1.07; acc: 0.62
Batch: 40; loss: 1.09; acc: 0.66
Batch: 60; loss: 0.99; acc: 0.69
Batch: 80; loss: 0.94; acc: 0.67
Batch: 100; loss: 0.76; acc: 0.7
Batch: 120; loss: 0.96; acc: 0.67
Batch: 140; loss: 1.01; acc: 0.67
Batch: 160; loss: 1.01; acc: 0.64
Batch: 180; loss: 1.11; acc: 0.69
Batch: 200; loss: 1.04; acc: 0.61
Batch: 220; loss: 1.0; acc: 0.62
Batch: 240; loss: 0.92; acc: 0.66
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.97; acc: 0.66
Batch: 300; loss: 1.3; acc: 0.64
Batch: 320; loss: 0.76; acc: 0.8
Batch: 340; loss: 0.72; acc: 0.8
Batch: 360; loss: 1.1; acc: 0.66
Batch: 380; loss: 0.93; acc: 0.67
Batch: 400; loss: 0.92; acc: 0.67
Batch: 420; loss: 1.16; acc: 0.59
Batch: 440; loss: 0.9; acc: 0.69
Batch: 460; loss: 0.76; acc: 0.78
Batch: 480; loss: 0.82; acc: 0.7
Batch: 500; loss: 0.93; acc: 0.69
Batch: 520; loss: 0.68; acc: 0.81
Batch: 540; loss: 1.31; acc: 0.52
Batch: 560; loss: 0.97; acc: 0.72
Batch: 580; loss: 0.77; acc: 0.72
Batch: 600; loss: 1.08; acc: 0.64
Batch: 620; loss: 0.67; acc: 0.81
Batch: 640; loss: 0.66; acc: 0.78
Batch: 660; loss: 1.71; acc: 0.55
Batch: 680; loss: 0.96; acc: 0.7
Batch: 700; loss: 0.56; acc: 0.83
Batch: 720; loss: 0.72; acc: 0.77
Batch: 740; loss: 0.79; acc: 0.83
Batch: 760; loss: 0.8; acc: 0.77
Batch: 780; loss: 0.8; acc: 0.77
Train Epoch over. train_loss: 0.93; train_accuracy: 0.7 

Batch: 0; loss: 0.88; acc: 0.69
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.66; acc: 0.83
Batch: 60; loss: 0.84; acc: 0.67
Batch: 80; loss: 0.77; acc: 0.69
Batch: 100; loss: 0.71; acc: 0.81
Batch: 120; loss: 0.9; acc: 0.77
Batch: 140; loss: 0.47; acc: 0.84
Val Epoch over. val_loss: 0.8423506038583768; val_accuracy: 0.7175557324840764 

The current subspace-distance is: 2.6691632228903472e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.7
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 1.02; acc: 0.69
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.76; acc: 0.78
Batch: 100; loss: 1.08; acc: 0.66
Batch: 120; loss: 0.9; acc: 0.72
Batch: 140; loss: 0.68; acc: 0.78
Batch: 160; loss: 0.83; acc: 0.81
Batch: 180; loss: 1.23; acc: 0.61
Batch: 200; loss: 0.8; acc: 0.78
Batch: 220; loss: 0.61; acc: 0.81
Batch: 240; loss: 0.69; acc: 0.77
Batch: 260; loss: 1.14; acc: 0.66
Batch: 280; loss: 0.7; acc: 0.8
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.78; acc: 0.72
Batch: 340; loss: 0.9; acc: 0.73
Batch: 360; loss: 0.5; acc: 0.8
Batch: 380; loss: 0.84; acc: 0.69
Batch: 400; loss: 0.48; acc: 0.8
Batch: 420; loss: 0.72; acc: 0.78
Batch: 440; loss: 0.55; acc: 0.8
Batch: 460; loss: 0.8; acc: 0.69
Batch: 480; loss: 0.55; acc: 0.83
Batch: 500; loss: 0.59; acc: 0.8
Batch: 520; loss: 0.55; acc: 0.84
Batch: 540; loss: 0.6; acc: 0.8
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.59; acc: 0.8
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 1.25; acc: 0.55
Batch: 660; loss: 0.73; acc: 0.8
Batch: 680; loss: 0.85; acc: 0.73
Batch: 700; loss: 0.82; acc: 0.73
Batch: 720; loss: 0.98; acc: 0.73
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.96; acc: 0.67
Batch: 780; loss: 0.64; acc: 0.73
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

Batch: 0; loss: 0.64; acc: 0.84
Batch: 20; loss: 0.64; acc: 0.73
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 0.81; acc: 0.78
Batch: 80; loss: 0.58; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 0.38; acc: 0.83
Val Epoch over. val_loss: 0.6059413207754208; val_accuracy: 0.8003582802547771 

The current subspace-distance is: 3.648877464001998e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.67
Batch: 20; loss: 0.74; acc: 0.77
Batch: 40; loss: 0.63; acc: 0.78
Batch: 60; loss: 0.92; acc: 0.67
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.8
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.73; acc: 0.86
Batch: 160; loss: 0.82; acc: 0.78
Batch: 180; loss: 0.54; acc: 0.83
Batch: 200; loss: 0.53; acc: 0.77
Batch: 220; loss: 0.81; acc: 0.77
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.8; acc: 0.73
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.57; acc: 0.86
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 0.66; acc: 0.81
Batch: 440; loss: 0.67; acc: 0.78
Batch: 460; loss: 0.55; acc: 0.77
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.4; acc: 0.83
Batch: 520; loss: 1.15; acc: 0.66
Batch: 540; loss: 0.64; acc: 0.78
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.53; acc: 0.84
Batch: 600; loss: 0.77; acc: 0.77
Batch: 620; loss: 0.59; acc: 0.83
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.59; acc: 0.81
Batch: 700; loss: 0.74; acc: 0.77
Batch: 720; loss: 0.72; acc: 0.73
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.68; acc: 0.8
Train Epoch over. train_loss: 0.59; train_accuracy: 0.81 

Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.5032463870990048; val_accuracy: 0.8451433121019108 

The current subspace-distance is: 4.472298678592779e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.73; acc: 0.72
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.49; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.81
Batch: 200; loss: 0.58; acc: 0.81
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.77
Batch: 280; loss: 0.99; acc: 0.73
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.75; acc: 0.78
Batch: 340; loss: 0.74; acc: 0.83
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.61; acc: 0.84
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.78
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.53; acc: 0.8
Batch: 500; loss: 0.61; acc: 0.78
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.67; acc: 0.78
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.5; acc: 0.84
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.91; acc: 0.73
Batch: 700; loss: 0.48; acc: 0.86
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.48; acc: 0.78
Train Epoch over. train_loss: 0.55; train_accuracy: 0.83 

Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.76; acc: 0.8
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.82; acc: 0.75
Batch: 120; loss: 1.02; acc: 0.72
Batch: 140; loss: 0.61; acc: 0.8
Val Epoch over. val_loss: 0.8557152239380369; val_accuracy: 0.726015127388535 

The current subspace-distance is: 5.2732393669430166e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.9; acc: 0.77
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.61; acc: 0.84
Batch: 60; loss: 0.66; acc: 0.78
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.63; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.74; acc: 0.8
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.72; acc: 0.78
Batch: 340; loss: 0.61; acc: 0.8
Batch: 360; loss: 0.58; acc: 0.83
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.4; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.47; acc: 0.81
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.62; acc: 0.81
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.72; acc: 0.73
Batch: 580; loss: 0.38; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.81
Batch: 680; loss: 0.52; acc: 0.81
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.64; acc: 0.8
Batch: 760; loss: 0.56; acc: 0.8
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.53; train_accuracy: 0.83 

Batch: 0; loss: 0.73; acc: 0.8
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.63; acc: 0.86
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.52; acc: 0.92
Batch: 100; loss: 0.9; acc: 0.7
Batch: 120; loss: 1.1; acc: 0.73
Batch: 140; loss: 0.47; acc: 0.86
Val Epoch over. val_loss: 0.7814394505160629; val_accuracy: 0.7632364649681529 

The current subspace-distance is: 6.0663056501653045e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.75
Batch: 20; loss: 0.57; acc: 0.86
Batch: 40; loss: 0.69; acc: 0.78
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.64; acc: 0.84
Batch: 100; loss: 0.65; acc: 0.77
Batch: 120; loss: 0.42; acc: 0.81
Batch: 140; loss: 0.55; acc: 0.8
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.58; acc: 0.83
Batch: 220; loss: 0.71; acc: 0.77
Batch: 240; loss: 0.63; acc: 0.8
Batch: 260; loss: 0.78; acc: 0.77
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.94; acc: 0.72
Batch: 360; loss: 0.55; acc: 0.86
Batch: 380; loss: 0.52; acc: 0.83
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.78
Batch: 440; loss: 0.63; acc: 0.8
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.79; acc: 0.75
Batch: 500; loss: 0.63; acc: 0.8
Batch: 520; loss: 0.94; acc: 0.7
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.54; acc: 0.83
Batch: 600; loss: 0.6; acc: 0.77
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.83
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.51; acc: 0.84
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.73; acc: 0.8
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4672252805369675; val_accuracy: 0.856687898089172 

The current subspace-distance is: 6.635541649302468e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.78
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.69; acc: 0.83
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.68; acc: 0.8
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.6; acc: 0.83
Batch: 160; loss: 0.53; acc: 0.8
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.84
Batch: 280; loss: 0.48; acc: 0.83
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.86
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.53; acc: 0.81
Batch: 380; loss: 0.74; acc: 0.78
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.64; acc: 0.81
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.63; acc: 0.81
Batch: 520; loss: 0.99; acc: 0.73
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.67; acc: 0.78
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.64; acc: 0.83
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.61; acc: 0.8
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.6; acc: 0.77
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.43; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.81
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.5; acc: 0.78
Val Epoch over. val_loss: 0.6441758254151435; val_accuracy: 0.8104100318471338 

The current subspace-distance is: 7.254448428284377e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.6; acc: 0.78
Batch: 160; loss: 0.49; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.84
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.6; acc: 0.8
Batch: 260; loss: 0.46; acc: 0.83
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.64; acc: 0.84
Batch: 320; loss: 0.82; acc: 0.8
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.65; acc: 0.84
Batch: 380; loss: 0.89; acc: 0.69
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.54; acc: 0.8
Batch: 440; loss: 0.56; acc: 0.83
Batch: 460; loss: 0.54; acc: 0.83
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.83
Batch: 680; loss: 0.69; acc: 0.77
Batch: 700; loss: 0.72; acc: 0.75
Batch: 720; loss: 0.51; acc: 0.81
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4835421266449485; val_accuracy: 0.8473328025477707 

The current subspace-distance is: 7.737513078609481e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.53; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.78
Batch: 160; loss: 0.36; acc: 0.84
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.69; acc: 0.77
Batch: 220; loss: 0.56; acc: 0.81
Batch: 240; loss: 0.61; acc: 0.81
Batch: 260; loss: 0.53; acc: 0.83
Batch: 280; loss: 0.54; acc: 0.86
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.59; acc: 0.84
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.47; acc: 0.8
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.76; acc: 0.75
Batch: 460; loss: 0.66; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.5; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.5; acc: 0.81
Batch: 600; loss: 0.46; acc: 0.83
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.26; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.57; acc: 0.81
Batch: 720; loss: 0.75; acc: 0.77
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.7; acc: 0.78
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4180017755289746; val_accuracy: 0.8732085987261147 

The current subspace-distance is: 8.262258052127436e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.53; acc: 0.8
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.56; acc: 0.8
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.58; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.5; acc: 0.81
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.83; acc: 0.78
Batch: 480; loss: 0.83; acc: 0.72
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.5; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.71; acc: 0.81
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.97
Val Epoch over. val_loss: 0.40639626486286234; val_accuracy: 0.876890923566879 

The current subspace-distance is: 8.900833927327767e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.57; acc: 0.86
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.42; acc: 0.81
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.63; acc: 0.78
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.47; acc: 0.81
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.57; acc: 0.86
Batch: 380; loss: 0.59; acc: 0.8
Batch: 400; loss: 0.58; acc: 0.8
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.49; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.76; acc: 0.81
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.45; acc: 0.83
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.59; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4068801008212339; val_accuracy: 0.8737062101910829 

The current subspace-distance is: 9.180563210975379e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.52; acc: 0.81
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.95
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.84
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.53; acc: 0.81
Batch: 420; loss: 0.53; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.84
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.55; acc: 0.83
Batch: 560; loss: 0.51; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.77
Batch: 600; loss: 0.45; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.49; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.58; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3891010729560427; val_accuracy: 0.8815684713375797 

The current subspace-distance is: 9.519307786831632e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.84
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.47; acc: 0.81
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.69; acc: 0.75
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.66; acc: 0.84
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.83
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.64; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.4128428660570436; val_accuracy: 0.8703224522292994 

The current subspace-distance is: 9.95789814624004e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.81
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.8
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.59; acc: 0.83
Batch: 280; loss: 0.23; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.41; acc: 0.81
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.86
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.55; acc: 0.81
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.52; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.45; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.64; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.73; acc: 0.81
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.48033952608609654; val_accuracy: 0.8474323248407644 

The current subspace-distance is: 0.00010395089338999242 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.45; acc: 0.89
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.88
Batch: 320; loss: 0.57; acc: 0.78
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.83
Batch: 480; loss: 0.59; acc: 0.81
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.29; acc: 0.88
Batch: 620; loss: 0.7; acc: 0.84
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.56; acc: 0.77
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.89
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.94
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 0.94; acc: 0.73
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.48615581774787536; val_accuracy: 0.8436504777070064 

The current subspace-distance is: 0.0001083113020285964 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.62; acc: 0.86
Batch: 180; loss: 0.59; acc: 0.8
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.59; acc: 0.88
Batch: 260; loss: 0.7; acc: 0.83
Batch: 280; loss: 0.58; acc: 0.83
Batch: 300; loss: 0.74; acc: 0.77
Batch: 320; loss: 0.84; acc: 0.78
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.66; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.53; acc: 0.84
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.59; acc: 0.78
Batch: 580; loss: 0.48; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.4; acc: 0.81
Batch: 680; loss: 0.47; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.55; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4166980835662526; val_accuracy: 0.8759952229299363 

The current subspace-distance is: 0.0001123700276366435 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.38; acc: 0.86
Batch: 200; loss: 0.59; acc: 0.78
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.71; acc: 0.83
Batch: 260; loss: 0.17; acc: 0.98
Batch: 280; loss: 0.63; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.81
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.5; acc: 0.83
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.7; acc: 0.78
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.12; acc: 1.0
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.6; acc: 0.77
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.7; acc: 0.86
Batch: 120; loss: 0.83; acc: 0.75
Batch: 140; loss: 0.15; acc: 0.92
Val Epoch over. val_loss: 0.4187782599478011; val_accuracy: 0.8674363057324841 

The current subspace-distance is: 0.00011729640391422436 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.5; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.6; acc: 0.84
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.5; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.84
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.57; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.52; acc: 0.86
Batch: 600; loss: 0.59; acc: 0.86
Batch: 620; loss: 0.68; acc: 0.8
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3974002723101598; val_accuracy: 0.8777866242038217 

The current subspace-distance is: 0.00012027392949676141 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.77; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.61; acc: 0.77
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.65; acc: 0.78
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.53; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.58; acc: 0.78
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.84
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.8; acc: 0.81
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.83
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.95
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.7; acc: 0.75
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.89
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.75; acc: 0.83
Batch: 140; loss: 0.32; acc: 0.89
Val Epoch over. val_loss: 0.5117262841030291; val_accuracy: 0.8497213375796179 

The current subspace-distance is: 0.00012435924145393074 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.77; acc: 0.73
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.69; acc: 0.84
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.5; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.68; acc: 0.8
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.6; acc: 0.84
Batch: 400; loss: 0.26; acc: 0.86
Batch: 420; loss: 0.46; acc: 0.81
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.72; acc: 0.83
Batch: 560; loss: 0.64; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.45; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.55; acc: 0.86
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.71; acc: 0.78
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.37377307426397965; val_accuracy: 0.8859474522292994 

The current subspace-distance is: 0.00012840103590860963 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.55; acc: 0.8
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.27; acc: 0.86
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.84
Batch: 380; loss: 0.44; acc: 0.8
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.94
Batch: 440; loss: 0.56; acc: 0.84
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.46; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.47; acc: 0.81
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.47; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3658298093612027; val_accuracy: 0.8888335987261147 

The current subspace-distance is: 0.00013155884516891092 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.46; acc: 0.91
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.83
Batch: 220; loss: 0.65; acc: 0.8
Batch: 240; loss: 0.48; acc: 0.86
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.58; acc: 0.81
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.52; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.52; acc: 0.81
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.59; acc: 0.83
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.39; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3857557162357743; val_accuracy: 0.8835589171974523 

The current subspace-distance is: 0.00013491569552570581 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.84
Batch: 20; loss: 0.76; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.83
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.63; acc: 0.84
Batch: 120; loss: 0.44; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.8
Batch: 160; loss: 0.58; acc: 0.78
Batch: 180; loss: 0.49; acc: 0.81
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.49; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.48; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.55; acc: 0.83
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.83
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3920569484400901; val_accuracy: 0.8773885350318471 

The current subspace-distance is: 0.00013975963520351797 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.53; acc: 0.8
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.49; acc: 0.83
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.6; acc: 0.84
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.54; acc: 0.81
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.46; acc: 0.84
Batch: 360; loss: 0.43; acc: 0.83
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.83; acc: 0.77
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.88
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.83
Batch: 720; loss: 0.55; acc: 0.8
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.62; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.37993962028224; val_accuracy: 0.8832603503184714 

The current subspace-distance is: 0.00014302237832453102 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.81
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.55; acc: 0.86
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.58; acc: 0.84
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.83
Batch: 620; loss: 0.25; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.47; acc: 0.8
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.3738203756748491; val_accuracy: 0.8838574840764332 

The current subspace-distance is: 0.00014658710279036313 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.57; acc: 0.78
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.56; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.86
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.94
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.89
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.52; acc: 0.8
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.91
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.53; acc: 0.77
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.7; acc: 0.78
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.62; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.3765465927541636; val_accuracy: 0.8839570063694268 

The current subspace-distance is: 0.00014833523891866207 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.88
Batch: 280; loss: 0.75; acc: 0.8
Batch: 300; loss: 0.62; acc: 0.8
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.51; acc: 0.86
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.81; acc: 0.81
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.3651051954099327; val_accuracy: 0.8885350318471338 

The current subspace-distance is: 0.00015108897059690207 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.78
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.47; acc: 0.88
Batch: 240; loss: 0.79; acc: 0.75
Batch: 260; loss: 0.46; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.63; acc: 0.83
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.47; acc: 0.83
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.52; acc: 0.8
Batch: 700; loss: 0.43; acc: 0.84
Batch: 720; loss: 0.31; acc: 0.84
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.5; acc: 0.81
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.92
Val Epoch over. val_loss: 0.3691492932996932; val_accuracy: 0.8883359872611465 

The current subspace-distance is: 0.00015278345381375402 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.83
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.91
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.57; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.86
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.51; acc: 0.8
Batch: 520; loss: 0.58; acc: 0.77
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.4; acc: 0.91
Batch: 640; loss: 0.46; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.86
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.6; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.36477724676299245; val_accuracy: 0.8873407643312102 

The current subspace-distance is: 0.00015609897673130035 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.5; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.49; acc: 0.88
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.62; acc: 0.84
Batch: 420; loss: 0.57; acc: 0.81
Batch: 440; loss: 0.51; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.49; acc: 0.81
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.47; acc: 0.8
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.53; acc: 0.83
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.36396923575811324; val_accuracy: 0.8890326433121019 

The current subspace-distance is: 0.0001600123505340889 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.53; acc: 0.83
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.84
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.47; acc: 0.84
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.86
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.54; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.83
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.3650234383382615; val_accuracy: 0.8878383757961783 

The current subspace-distance is: 0.00016238870739471167 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.66; acc: 0.75
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.77
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.86
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.73; acc: 0.84
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.52; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.57; acc: 0.86
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.64; acc: 0.86
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.3614470304767038; val_accuracy: 0.8901273885350318 

The current subspace-distance is: 0.00016533852613065392 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.44; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.58; acc: 0.78
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.55; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.55; acc: 0.86
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.73
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3617479602812202; val_accuracy: 0.8884355095541401 

The current subspace-distance is: 0.00016793241957202554 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.59; acc: 0.8
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.66; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.49; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.61; acc: 0.81
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.57; acc: 0.83
Batch: 720; loss: 0.53; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.86
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.36039904879916246; val_accuracy: 0.8909235668789809 

The current subspace-distance is: 0.00016848815721459687 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.58; acc: 0.86
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.59; acc: 0.81
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.41; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.84
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3629487883892788; val_accuracy: 0.8865445859872612 

The current subspace-distance is: 0.00017105700680986047 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.98
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.58; acc: 0.81
Batch: 200; loss: 0.53; acc: 0.83
Batch: 220; loss: 0.73; acc: 0.81
Batch: 240; loss: 0.26; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.73; acc: 0.84
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.61; acc: 0.88
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.53; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.51; acc: 0.78
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.57; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.3641914578190275; val_accuracy: 0.8885350318471338 

The current subspace-distance is: 0.00017269888485316187 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.44; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.63; acc: 0.81
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.47; acc: 0.83
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 1.02; acc: 0.77
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.94
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.91
Batch: 660; loss: 0.46; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.88
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.4; acc: 0.81
Batch: 760; loss: 0.4; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.35949246281651176; val_accuracy: 0.8898288216560509 

The current subspace-distance is: 0.00017513480270281434 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.98
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.65; acc: 0.81
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.49; acc: 0.89
Batch: 280; loss: 0.38; acc: 0.84
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.54; acc: 0.8
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.95
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.49; acc: 0.89
Batch: 660; loss: 0.44; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.83
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.69; acc: 0.8
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.73
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.36149180618820675; val_accuracy: 0.8886345541401274 

The current subspace-distance is: 0.00017743016360327601 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.47; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.49; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.84
Batch: 180; loss: 0.58; acc: 0.84
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.55; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.53; acc: 0.84
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.55; acc: 0.8
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.81
Batch: 660; loss: 0.39; acc: 0.81
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.37; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.360271347271409; val_accuracy: 0.890625 

The current subspace-distance is: 0.00017991269123740494 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.52; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.83
Batch: 120; loss: 0.59; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.42; acc: 0.84
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.6; acc: 0.8
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.48; acc: 0.83
Batch: 560; loss: 0.5; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.53; acc: 0.81
Batch: 640; loss: 0.55; acc: 0.8
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.59; acc: 0.81
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.41; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.3584766481902189; val_accuracy: 0.8912221337579618 

The current subspace-distance is: 0.00018287645070813596 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.56; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.5; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.62; acc: 0.83
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.58; acc: 0.84
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.34; acc: 0.86
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3582254299882111; val_accuracy: 0.8915207006369427 

The current subspace-distance is: 0.00018586384248919785 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.78; acc: 0.81
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.56; acc: 0.81
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.88
Batch: 240; loss: 0.6; acc: 0.8
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.7; acc: 0.86
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.69; acc: 0.78
Batch: 620; loss: 0.65; acc: 0.88
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.88
Batch: 780; loss: 0.67; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3590997917826768; val_accuracy: 0.8908240445859873 

The current subspace-distance is: 0.00018611496489029378 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.95
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.29; acc: 0.86
Batch: 160; loss: 0.5; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.25; acc: 0.88
Batch: 280; loss: 0.53; acc: 0.81
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.52; acc: 0.81
Batch: 420; loss: 0.39; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.64; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.54; acc: 0.8
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.35938426890191; val_accuracy: 0.8900278662420382 

The current subspace-distance is: 0.00018812660709954798 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.7; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.54; acc: 0.88
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.52; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.35918188560160863; val_accuracy: 0.8910230891719745 

The current subspace-distance is: 0.00018923546303994954 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.84
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.24; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.6; acc: 0.8
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.53; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3588435110772491; val_accuracy: 0.8890326433121019 

The current subspace-distance is: 0.00019224119023419917 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.86
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.95
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.55; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.5; acc: 0.86
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.35807425666386916; val_accuracy: 0.8914211783439491 

The current subspace-distance is: 0.0001961129019036889 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.59; acc: 0.83
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.54; acc: 0.83
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.5; acc: 0.81
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.63; acc: 0.8
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3585695139351924; val_accuracy: 0.8909235668789809 

The current subspace-distance is: 0.00019797563436441123 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.86
Batch: 360; loss: 0.66; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.84
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.5; acc: 0.86
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.52; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.35880403173197606; val_accuracy: 0.8909235668789809 

The current subspace-distance is: 0.00020045056589879096 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.61; acc: 0.84
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.62; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.53; acc: 0.88
Batch: 400; loss: 0.51; acc: 0.83
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.42; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.86
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.41; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.68; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.35815539377130523; val_accuracy: 0.8926154458598726 

The current subspace-distance is: 0.00020273998961783946 

plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 62564
elements in E: 13185600
fraction nonzero: 0.004744873195000607
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.35; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.26; acc: 0.12
Batch: 80; loss: 2.24; acc: 0.16
Batch: 100; loss: 2.22; acc: 0.22
Batch: 120; loss: 2.2; acc: 0.22
Batch: 140; loss: 2.2; acc: 0.25
Batch: 160; loss: 2.19; acc: 0.27
Batch: 180; loss: 2.23; acc: 0.16
Batch: 200; loss: 2.18; acc: 0.25
Batch: 220; loss: 2.17; acc: 0.2
Batch: 240; loss: 2.08; acc: 0.28
Batch: 260; loss: 2.04; acc: 0.34
Batch: 280; loss: 2.0; acc: 0.28
Batch: 300; loss: 2.02; acc: 0.31
Batch: 320; loss: 1.83; acc: 0.41
Batch: 340; loss: 1.69; acc: 0.56
Batch: 360; loss: 1.77; acc: 0.34
Batch: 380; loss: 1.87; acc: 0.3
Batch: 400; loss: 1.6; acc: 0.55
Batch: 420; loss: 1.73; acc: 0.36
Batch: 440; loss: 1.71; acc: 0.3
Batch: 460; loss: 1.63; acc: 0.45
Batch: 480; loss: 1.49; acc: 0.52
Batch: 500; loss: 1.42; acc: 0.5
Batch: 520; loss: 1.23; acc: 0.56
Batch: 540; loss: 1.44; acc: 0.48
Batch: 560; loss: 1.42; acc: 0.52
Batch: 580; loss: 1.15; acc: 0.62
Batch: 600; loss: 1.48; acc: 0.56
Batch: 620; loss: 1.54; acc: 0.38
Batch: 640; loss: 1.07; acc: 0.69
Batch: 660; loss: 1.5; acc: 0.47
Batch: 680; loss: 1.45; acc: 0.52
Batch: 700; loss: 1.04; acc: 0.62
Batch: 720; loss: 1.03; acc: 0.64
Batch: 740; loss: 1.08; acc: 0.67
Batch: 760; loss: 1.07; acc: 0.69
Batch: 780; loss: 0.73; acc: 0.77
Train Epoch over. train_loss: 1.69; train_accuracy: 0.43 

Batch: 0; loss: 0.93; acc: 0.7
Batch: 20; loss: 0.96; acc: 0.62
Batch: 40; loss: 0.86; acc: 0.72
Batch: 60; loss: 0.96; acc: 0.66
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.87; acc: 0.69
Batch: 120; loss: 0.97; acc: 0.7
Batch: 140; loss: 0.74; acc: 0.72
Val Epoch over. val_loss: 0.9356968478792033; val_accuracy: 0.6696855095541401 

The current subspace-distance is: 1.7863461835077032e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.94; acc: 0.7
Batch: 20; loss: 0.73; acc: 0.78
Batch: 40; loss: 1.45; acc: 0.5
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.8; acc: 0.75
Batch: 100; loss: 0.8; acc: 0.7
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.91; acc: 0.73
Batch: 160; loss: 0.82; acc: 0.73
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.75; acc: 0.77
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.91; acc: 0.75
Batch: 300; loss: 0.68; acc: 0.69
Batch: 320; loss: 0.68; acc: 0.72
Batch: 340; loss: 0.41; acc: 0.89
Batch: 360; loss: 0.68; acc: 0.75
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.69; acc: 0.8
Batch: 420; loss: 0.48; acc: 0.83
Batch: 440; loss: 0.63; acc: 0.8
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.65; acc: 0.8
Batch: 540; loss: 0.87; acc: 0.67
Batch: 560; loss: 0.72; acc: 0.78
Batch: 580; loss: 0.62; acc: 0.77
Batch: 600; loss: 0.63; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.94
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.5; acc: 0.84
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.76; acc: 0.72
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.85; acc: 0.77
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

Batch: 0; loss: 0.82; acc: 0.69
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.56; acc: 0.78
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.78; acc: 0.8
Batch: 120; loss: 1.24; acc: 0.67
Batch: 140; loss: 0.45; acc: 0.8
Val Epoch over. val_loss: 0.8144861949477226; val_accuracy: 0.7392515923566879 

The current subspace-distance is: 3.132664642180316e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.52; acc: 0.78
Batch: 60; loss: 0.51; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.59; acc: 0.81
Batch: 160; loss: 0.58; acc: 0.86
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.81
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.6; acc: 0.81
Batch: 280; loss: 0.75; acc: 0.8
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.56; acc: 0.83
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.76; acc: 0.75
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.88
Batch: 480; loss: 0.51; acc: 0.88
Batch: 500; loss: 0.66; acc: 0.8
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.86
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.54; acc: 0.81
Batch: 660; loss: 0.54; acc: 0.84
Batch: 680; loss: 0.5; acc: 0.81
Batch: 700; loss: 0.47; acc: 0.89
Batch: 720; loss: 0.62; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.63; acc: 0.78
Batch: 780; loss: 0.44; acc: 0.81
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.87; acc: 0.78
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.45088987935120894; val_accuracy: 0.8568869426751592 

The current subspace-distance is: 4.148023435845971e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.84
Batch: 20; loss: 0.7; acc: 0.81
Batch: 40; loss: 0.6; acc: 0.77
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.44; acc: 0.83
Batch: 160; loss: 0.8; acc: 0.78
Batch: 180; loss: 0.33; acc: 0.83
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.58; acc: 0.8
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.83
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.58; acc: 0.83
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.49; acc: 0.8
Batch: 500; loss: 0.38; acc: 0.84
Batch: 520; loss: 0.67; acc: 0.78
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.88
Batch: 600; loss: 0.57; acc: 0.86
Batch: 620; loss: 0.77; acc: 0.77
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.48; acc: 0.89
Batch: 740; loss: 0.55; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.63; acc: 0.83
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.86; acc: 0.7
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.78
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 1.03; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.5503030362402558; val_accuracy: 0.8303144904458599 

The current subspace-distance is: 4.920620995108038e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.65; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.46; acc: 0.83
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.48; acc: 0.81
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.46; acc: 0.84
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.61; acc: 0.81
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.78
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.64; acc: 0.77
Batch: 120; loss: 1.12; acc: 0.7
Batch: 140; loss: 0.42; acc: 0.84
Val Epoch over. val_loss: 0.675214050491904; val_accuracy: 0.7926950636942676 

The current subspace-distance is: 5.640727613354102e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.8
Batch: 20; loss: 0.23; acc: 0.97
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.69; acc: 0.77
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.56; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.42; acc: 0.88
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.53; acc: 0.86
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.42; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.1; acc: 1.0
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.6; acc: 0.84
Batch: 520; loss: 0.55; acc: 0.75
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.57; acc: 0.8
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.81
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 1.23; acc: 0.67
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.49951837558275575; val_accuracy: 0.8407643312101911 

The current subspace-distance is: 6.269508594414219e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.84
Batch: 180; loss: 0.45; acc: 0.91
Batch: 200; loss: 0.6; acc: 0.83
Batch: 220; loss: 0.57; acc: 0.77
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.67; acc: 0.81
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.55; acc: 0.86
Batch: 360; loss: 0.45; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.84
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.49; acc: 0.86
Batch: 500; loss: 0.6; acc: 0.83
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.61; acc: 0.83
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.75
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.3793800818692347; val_accuracy: 0.884952229299363 

The current subspace-distance is: 6.999870674917474e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.71; acc: 0.81
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.52; acc: 0.86
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.8
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.48; acc: 0.83
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.45; acc: 0.81
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.42; acc: 0.83
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.83
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.95
Val Epoch over. val_loss: 0.41948535065552234; val_accuracy: 0.8682324840764332 

The current subspace-distance is: 7.641132106073201e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.45; acc: 0.84
Batch: 380; loss: 0.67; acc: 0.77
Batch: 400; loss: 0.19; acc: 0.97
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.47; acc: 0.83
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.8
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.35661288507425104; val_accuracy: 0.8854498407643312 

The current subspace-distance is: 8.117356628645211e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.52; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.61; acc: 0.77
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.5; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.92
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.97
Batch: 540; loss: 0.31; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.65; acc: 0.84
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.35; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.33936139039552893; val_accuracy: 0.8975915605095541 

The current subspace-distance is: 8.650987729197368e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.6; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.55; acc: 0.75
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.81
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2901066625194185; val_accuracy: 0.9133160828025477 

The current subspace-distance is: 9.12687464733608e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.5; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.53; acc: 0.81
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.91; acc: 0.75
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3086671442220545; val_accuracy: 0.90515525477707 

The current subspace-distance is: 9.546529327053577e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.52; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.81
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.4; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2785210060845515; val_accuracy: 0.9137141719745223 

The current subspace-distance is: 9.975050488719717e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.26; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.76; acc: 0.8
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.79; acc: 0.7
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.29091842299339116; val_accuracy: 0.9088375796178344 

The current subspace-distance is: 0.00010459090117365122 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.98
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.4; acc: 0.83
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.76; acc: 0.83
Batch: 540; loss: 0.33; acc: 0.81
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.86
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.58; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.33018100816922585; val_accuracy: 0.8973925159235668 

The current subspace-distance is: 0.00010873712744796649 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.46; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.75
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.3195712231574165; val_accuracy: 0.8985867834394905 

The current subspace-distance is: 0.0001129247757489793 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.49; acc: 0.89
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.53; acc: 0.91
Batch: 180; loss: 0.71; acc: 0.8
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.4; acc: 0.83
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.34; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.29012954626588305; val_accuracy: 0.9097332802547771 

The current subspace-distance is: 0.00011744799121515825 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.81
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.92
Batch: 520; loss: 0.57; acc: 0.81
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.57; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28866927945025406; val_accuracy: 0.9097332802547771 

The current subspace-distance is: 0.00012180634075775743 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.51; acc: 0.84
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.83
Batch: 360; loss: 0.5; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.43; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.48; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.27706340175999955; val_accuracy: 0.9159036624203821 

The current subspace-distance is: 0.00012493817484937608 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.52; acc: 0.86
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.97
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.45; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.84
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.77
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.28096967423038116; val_accuracy: 0.9120222929936306 

The current subspace-distance is: 0.00012932273966725916 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.86
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.35; acc: 0.84
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26527827164265; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 0.0001318049617111683 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.84
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2609440214267582; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 0.00013495466555468738 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.58; acc: 0.83
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.78
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.51; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.95
Batch: 540; loss: 0.37; acc: 0.88
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2654582201295598; val_accuracy: 0.9188893312101911 

The current subspace-distance is: 0.00013922335347160697 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.07; acc: 1.0
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.8
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2713119271834185; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 0.00014298403402790427 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.86
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.55; acc: 0.83
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.91
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.8; acc: 0.8
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.43; acc: 0.84
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2703006947353767; val_accuracy: 0.9178941082802548 

The current subspace-distance is: 0.00014552193169947714 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.84
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26510765213685433; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 0.00014871382154524326 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.51; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.86
Batch: 560; loss: 0.22; acc: 0.89
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.63; acc: 0.81
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2695100630639465; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 0.00015128620725590736 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.49; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.5; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.89
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.41; acc: 0.84
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.49; acc: 0.88
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2733350078913437; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 0.00015467582852579653 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.55; acc: 0.78
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2826642240308652; val_accuracy: 0.9123208598726115 

The current subspace-distance is: 0.00015797442756593227 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.61; acc: 0.81
Batch: 160; loss: 0.34; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.48; acc: 0.83
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.37; acc: 0.84
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2659394928509263; val_accuracy: 0.919187898089172 

The current subspace-distance is: 0.00016089905693661422 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.84
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.263470498951757; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 0.00016369477089028805 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.83
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.84
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26067050396921526; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 0.0001660315610934049 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.36; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.49; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26136413076595894; val_accuracy: 0.9206807324840764 

The current subspace-distance is: 0.00016895811131689698 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.86
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.86
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.26219623815861476; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 0.00017138391558546573 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.08; acc: 1.0
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.88
Batch: 340; loss: 0.45; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.56; acc: 0.81
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.4; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.26464174941751606; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 0.00017457523790653795 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.66; acc: 0.81
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.86
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.26284050894011357; val_accuracy: 0.9188893312101911 

The current subspace-distance is: 0.00017753856081981212 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.86
Batch: 220; loss: 0.5; acc: 0.84
Batch: 240; loss: 0.3; acc: 0.84
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.65; acc: 0.83
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.86
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.15; acc: 0.98
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.58; acc: 0.83
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.26171992332407623; val_accuracy: 0.9206807324840764 

The current subspace-distance is: 0.00018002017168328166 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.47; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.5; acc: 0.88
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.86
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.26355858560010886; val_accuracy: 0.919984076433121 

The current subspace-distance is: 0.00018235303286928684 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.21; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.83
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2610540541161777; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 0.00018518486467655748 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.98
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.1; acc: 1.0
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.51; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2642172853088683; val_accuracy: 0.9194864649681529 

The current subspace-distance is: 0.00018863363948184997 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.98
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.84
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.47; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.51; acc: 0.81
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2611754439344072; val_accuracy: 0.919984076433121 

The current subspace-distance is: 0.00019112623704131693 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.18; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2603226078638605; val_accuracy: 0.9209792993630573 

The current subspace-distance is: 0.00019399586017243564 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.63; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.57; acc: 0.81
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.06; acc: 1.0
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.52; acc: 0.86
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.37; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25933236949098337; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 0.00019775332475546747 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.98
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.53; acc: 0.84
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.86
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.18; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2608245809319293; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 0.00020019225485157222 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.49; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.42; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.260309106035597; val_accuracy: 0.9212778662420382 

The current subspace-distance is: 0.00020366521493997425 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.88
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.19; acc: 0.98
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.88
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25960623698344654; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 0.00020580428827088326 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.54; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25919939299962325; val_accuracy: 0.9213773885350318 

The current subspace-distance is: 0.0002078747347695753 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.52; acc: 0.88
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2597480972006822; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 0.00021064317843411118 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.43; acc: 0.83
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.97
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.84
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.35; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2595817118076382; val_accuracy: 0.9213773885350318 

The current subspace-distance is: 0.00021270313300192356 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.51; acc: 0.83
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.55; acc: 0.84
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.25984244489935554; val_accuracy: 0.9215764331210191 

The current subspace-distance is: 0.00021567390649579465 

plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 83970
elements in E: 17580800
fraction nonzero: 0.004776233163451038
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.35; acc: 0.11
Batch: 20; loss: 2.32; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.27; acc: 0.12
Batch: 80; loss: 2.24; acc: 0.19
Batch: 100; loss: 2.2; acc: 0.25
Batch: 120; loss: 2.19; acc: 0.34
Batch: 140; loss: 2.17; acc: 0.31
Batch: 160; loss: 2.17; acc: 0.27
Batch: 180; loss: 2.19; acc: 0.16
Batch: 200; loss: 2.11; acc: 0.22
Batch: 220; loss: 2.05; acc: 0.27
Batch: 240; loss: 1.97; acc: 0.33
Batch: 260; loss: 1.87; acc: 0.39
Batch: 280; loss: 1.82; acc: 0.41
Batch: 300; loss: 1.82; acc: 0.39
Batch: 320; loss: 1.55; acc: 0.45
Batch: 340; loss: 1.4; acc: 0.64
Batch: 360; loss: 1.55; acc: 0.52
Batch: 380; loss: 1.54; acc: 0.38
Batch: 400; loss: 1.36; acc: 0.55
Batch: 420; loss: 1.42; acc: 0.48
Batch: 440; loss: 1.35; acc: 0.55
Batch: 460; loss: 1.28; acc: 0.53
Batch: 480; loss: 1.08; acc: 0.62
Batch: 500; loss: 1.14; acc: 0.61
Batch: 520; loss: 0.98; acc: 0.67
Batch: 540; loss: 1.22; acc: 0.59
Batch: 560; loss: 1.28; acc: 0.56
Batch: 580; loss: 0.89; acc: 0.72
Batch: 600; loss: 1.04; acc: 0.62
Batch: 620; loss: 0.91; acc: 0.67
Batch: 640; loss: 1.43; acc: 0.53
Batch: 660; loss: 0.93; acc: 0.69
Batch: 680; loss: 1.01; acc: 0.62
Batch: 700; loss: 0.92; acc: 0.64
Batch: 720; loss: 0.83; acc: 0.78
Batch: 740; loss: 0.7; acc: 0.8
Batch: 760; loss: 0.85; acc: 0.69
Batch: 780; loss: 0.51; acc: 0.88
Train Epoch over. train_loss: 1.48; train_accuracy: 0.5 

Batch: 0; loss: 1.02; acc: 0.72
Batch: 20; loss: 0.88; acc: 0.64
Batch: 40; loss: 0.78; acc: 0.73
Batch: 60; loss: 0.99; acc: 0.73
Batch: 80; loss: 0.79; acc: 0.77
Batch: 100; loss: 0.75; acc: 0.73
Batch: 120; loss: 0.93; acc: 0.67
Batch: 140; loss: 0.68; acc: 0.72
Val Epoch over. val_loss: 0.9423957505043904; val_accuracy: 0.6876990445859873 

The current subspace-distance is: 2.0312738342909142e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.7
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 1.07; acc: 0.62
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.6; acc: 0.8
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.88; acc: 0.72
Batch: 160; loss: 0.78; acc: 0.72
Batch: 180; loss: 0.74; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.84
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.7; acc: 0.81
Batch: 260; loss: 0.5; acc: 0.81
Batch: 280; loss: 0.92; acc: 0.72
Batch: 300; loss: 0.54; acc: 0.83
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.9; acc: 0.69
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.69; acc: 0.77
Batch: 420; loss: 0.54; acc: 0.81
Batch: 440; loss: 0.71; acc: 0.77
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.81
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.65; acc: 0.77
Batch: 560; loss: 0.5; acc: 0.91
Batch: 580; loss: 0.73; acc: 0.73
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.68; acc: 0.84
Batch: 660; loss: 0.65; acc: 0.83
Batch: 680; loss: 0.44; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.67; acc: 0.8
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.59; acc: 0.8
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.55; train_accuracy: 0.83 

Batch: 0; loss: 0.33; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.37498458932824197; val_accuracy: 0.8840565286624203 

The current subspace-distance is: 3.265695704612881e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.54; acc: 0.83
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.42; acc: 0.86
Batch: 160; loss: 0.74; acc: 0.78
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.51; acc: 0.84
Batch: 340; loss: 0.37; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.83
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.13; acc: 1.0
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.54; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.51; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.30043081701940794; val_accuracy: 0.9046576433121019 

The current subspace-distance is: 4.3085434299428016e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.4; acc: 0.81
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.76; acc: 0.78
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.5; acc: 0.81
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.42772219448712223; val_accuracy: 0.8708200636942676 

The current subspace-distance is: 5.242976112640463e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.88
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.46; acc: 0.84
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.5; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.32; acc: 0.88
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.79; acc: 0.75
Batch: 40; loss: 0.57; acc: 0.88
Batch: 60; loss: 0.55; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.75; acc: 0.8
Batch: 120; loss: 1.23; acc: 0.69
Batch: 140; loss: 0.4; acc: 0.86
Val Epoch over. val_loss: 0.7790939483293302; val_accuracy: 0.7788614649681529 

The current subspace-distance is: 6.062883767299354e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.9; acc: 0.77
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.47; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.74; acc: 0.75
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.61; acc: 0.84
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.86
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.47; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.43851591452101996; val_accuracy: 0.8630573248407644 

The current subspace-distance is: 6.716643838444725e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.73; acc: 0.8
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.48; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.89
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.51; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.7; acc: 0.83
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.89
Val Epoch over. val_loss: 0.3365740900871101; val_accuracy: 0.8949044585987261 

The current subspace-distance is: 7.352771353907883e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.53; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.46; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.59; acc: 0.77
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.73; acc: 0.73
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.92
Val Epoch over. val_loss: 0.5269566730234274; val_accuracy: 0.839171974522293 

The current subspace-distance is: 7.941264630062506e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.83
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.37; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.76; acc: 0.77
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.84
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.61; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.58; acc: 0.86
Batch: 640; loss: 0.24; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.81
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.8
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.25250704975644495; val_accuracy: 0.923765923566879 

The current subspace-distance is: 8.522252028342336e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.54; acc: 0.86
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.86
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.49; acc: 0.88
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.45; acc: 0.81
Batch: 720; loss: 0.49; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.43710639868762086; val_accuracy: 0.8706210191082803 

The current subspace-distance is: 9.094746928894892e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.86
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.44; acc: 0.88
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2192167791828608; val_accuracy: 0.9365047770700637 

The current subspace-distance is: 9.593852155376226e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.83
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.56; acc: 0.84
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.88
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21415362262706847; val_accuracy: 0.9367038216560509 

The current subspace-distance is: 0.00010047887917608023 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.46; acc: 0.81
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.23117467360037147; val_accuracy: 0.929140127388535 

The current subspace-distance is: 0.00010543288226472214 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.55; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.54; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.31003509858136724; val_accuracy: 0.9052547770700637 

The current subspace-distance is: 0.00010933857993222773 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.32; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.299539225045473; val_accuracy: 0.90625 

The current subspace-distance is: 0.00011353512672940269 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.36; acc: 0.84
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.88
Batch: 440; loss: 0.11; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.88
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.1; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2391940430043989; val_accuracy: 0.9271496815286624 

The current subspace-distance is: 0.00011858964717248455 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.18; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.45; acc: 0.8
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21494328842800894; val_accuracy: 0.9369028662420382 

The current subspace-distance is: 0.0001229289046023041 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.63; acc: 0.83
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.224427584796005; val_accuracy: 0.9309315286624203 

The current subspace-distance is: 0.00012632978905458003 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.09; acc: 1.0
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.42; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20580294068641725; val_accuracy: 0.9360071656050956 

The current subspace-distance is: 0.00013000567560084164 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.45; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2201339933712771; val_accuracy: 0.9340167197452229 

The current subspace-distance is: 0.00013296003453433514 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.47; acc: 0.89
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20706338753366166; val_accuracy: 0.9374004777070064 

The current subspace-distance is: 0.00013663108984474093 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20066738883211355; val_accuracy: 0.93859474522293 

The current subspace-distance is: 0.0001400439505232498 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.38; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.44; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20362526643428075; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 0.0001440796913811937 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.07; acc: 1.0
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.86
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20288372298429727; val_accuracy: 0.9384952229299363 

The current subspace-distance is: 0.00014746925444342196 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.36; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.52; acc: 0.8
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20673424565488366; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 0.00015076930867508054 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20309923892947518; val_accuracy: 0.9375 

The current subspace-distance is: 0.00015409348998218775 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.98
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21252873252816262; val_accuracy: 0.9367038216560509 

The current subspace-distance is: 0.00015642277139704674 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.98
Batch: 580; loss: 0.37; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.21619009637054365; val_accuracy: 0.9341162420382165 

The current subspace-distance is: 0.00015955863636918366 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19826273166924524; val_accuracy: 0.9405851910828026 

The current subspace-distance is: 0.00016228342428803444 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.12; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.38; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20121480161502103; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 0.00016557169146835804 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.91
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19740700835634947; val_accuracy: 0.9400875796178344 

The current subspace-distance is: 0.00016842351760715246 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.06; acc: 1.0
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.43; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19578004989084924; val_accuracy: 0.9402866242038217 

The current subspace-distance is: 0.0001713259262032807 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.24; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19580660345163314; val_accuracy: 0.9403861464968153 

The current subspace-distance is: 0.00017403258243575692 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.88
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.11; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19612384675319788; val_accuracy: 0.9411823248407644 

The current subspace-distance is: 0.00017678271979093552 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.86
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19798774649478068; val_accuracy: 0.9387937898089171 

The current subspace-distance is: 0.000179332637344487 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.88
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.45; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.193688393398455; val_accuracy: 0.9411823248407644 

The current subspace-distance is: 0.000181636874913238 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.46; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.44; acc: 0.91
Batch: 500; loss: 0.51; acc: 0.88
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.55; acc: 0.84
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19509484844317862; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 0.00018406061280984432 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.98
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.53; acc: 0.84
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.49; acc: 0.91
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1941680142501737; val_accuracy: 0.9426751592356688 

The current subspace-distance is: 0.0001862235803855583 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19566127890424365; val_accuracy: 0.9408837579617835 

The current subspace-distance is: 0.00018886489851865917 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.98
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19542033827988206; val_accuracy: 0.940187101910828 

The current subspace-distance is: 0.0001912397419800982 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1926594820039667; val_accuracy: 0.9407842356687898 

The current subspace-distance is: 0.00019451213302090764 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19319764847398563; val_accuracy: 0.9405851910828026 

The current subspace-distance is: 0.00019747829355765134 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19287496356732525; val_accuracy: 0.9403861464968153 

The current subspace-distance is: 0.0001988964359043166 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.89
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.88
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.07; acc: 1.0
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1929166524131207; val_accuracy: 0.9415804140127388 

The current subspace-distance is: 0.00020142427820246667 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.91
Batch: 240; loss: 0.07; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.91
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19396057202937497; val_accuracy: 0.9399880573248408 

The current subspace-distance is: 0.00020411881268955767 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19228903175729095; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 0.00020623482123482972 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19367232857046612; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 0.00020851459703408182 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19191134642738444; val_accuracy: 0.941281847133758 

The current subspace-distance is: 0.0002106650499626994 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.88
Batch: 440; loss: 0.08; acc: 1.0
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.36; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.88
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.44; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19222948142582444; val_accuracy: 0.9410828025477707 

The current subspace-distance is: 0.00021259684581309557 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.05; acc: 1.0
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.86
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19270355263902883; val_accuracy: 0.9404856687898089 

The current subspace-distance is: 0.00021444463345687836 

plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 104602
elements in E: 21976000
fraction nonzero: 0.004759828904259192
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.35; acc: 0.11
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.25; acc: 0.17
Batch: 60; loss: 2.21; acc: 0.14
Batch: 80; loss: 2.15; acc: 0.28
Batch: 100; loss: 2.07; acc: 0.31
Batch: 120; loss: 1.97; acc: 0.53
Batch: 140; loss: 1.91; acc: 0.36
Batch: 160; loss: 1.92; acc: 0.34
Batch: 180; loss: 1.85; acc: 0.34
Batch: 200; loss: 1.67; acc: 0.5
Batch: 220; loss: 1.66; acc: 0.47
Batch: 240; loss: 1.55; acc: 0.48
Batch: 260; loss: 1.39; acc: 0.58
Batch: 280; loss: 1.39; acc: 0.52
Batch: 300; loss: 1.28; acc: 0.55
Batch: 320; loss: 0.99; acc: 0.7
Batch: 340; loss: 1.13; acc: 0.66
Batch: 360; loss: 1.12; acc: 0.64
Batch: 380; loss: 1.12; acc: 0.61
Batch: 400; loss: 1.0; acc: 0.7
Batch: 420; loss: 0.95; acc: 0.62
Batch: 440; loss: 0.81; acc: 0.73
Batch: 460; loss: 1.16; acc: 0.7
Batch: 480; loss: 0.79; acc: 0.81
Batch: 500; loss: 0.7; acc: 0.81
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.63; acc: 0.78
Batch: 560; loss: 0.8; acc: 0.72
Batch: 580; loss: 1.06; acc: 0.73
Batch: 600; loss: 0.53; acc: 0.81
Batch: 620; loss: 0.58; acc: 0.8
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 1.05; acc: 0.67
Batch: 700; loss: 0.6; acc: 0.77
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.46; acc: 0.89
Batch: 760; loss: 0.7; acc: 0.73
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 1.17; train_accuracy: 0.61 

Batch: 0; loss: 0.4; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.4; acc: 0.81
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.5082986114700888; val_accuracy: 0.839171974522293 

The current subspace-distance is: 2.136578768840991e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.62; acc: 0.8
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.39; acc: 0.83
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.68; acc: 0.81
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.57; acc: 0.81
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.6; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.34629889615591924; val_accuracy: 0.8951035031847133 

The current subspace-distance is: 3.362063580425456e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.81
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.86
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.35; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.37; acc: 0.81
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.45; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.82; acc: 0.75
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.39514105235505254; val_accuracy: 0.8734076433121019 

The current subspace-distance is: 4.313704994274303e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.64; acc: 0.81
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.2781182985017254; val_accuracy: 0.9144108280254777 

The current subspace-distance is: 5.110800339025445e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.97
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.3581491963593823; val_accuracy: 0.8936106687898089 

The current subspace-distance is: 5.823343599331565e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.44; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.25501962376248305; val_accuracy: 0.919984076433121 

The current subspace-distance is: 6.485992344096303e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.45; acc: 0.86
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.3; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20803684015182933; val_accuracy: 0.9349124203821656 

The current subspace-distance is: 7.078905764501542e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.13; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2855019061143991; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 7.649070175830275e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.47; acc: 0.84
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.34; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.84
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19145331284992254; val_accuracy: 0.9406847133757962 

The current subspace-distance is: 8.232527761720121e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.34; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.37; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1919825125224651; val_accuracy: 0.9414808917197452 

The current subspace-distance is: 8.830962906358764e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.63; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.05; acc: 1.0
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16899066589250686; val_accuracy: 0.9495421974522293 

The current subspace-distance is: 9.325178689323366e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.98
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.84
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.94
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16772027275744517; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 9.770182805368677e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.98
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.18; acc: 0.97
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.19; acc: 0.89
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17129337792373767; val_accuracy: 0.9462579617834395 

The current subspace-distance is: 0.00010231261694571003 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.47; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1832133641668186; val_accuracy: 0.9404856687898089 

The current subspace-distance is: 0.00010693362855818123 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.88
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.23219992061424408; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 0.00011116317182313651 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.94 

Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2250593096302573; val_accuracy: 0.9334195859872612 

The current subspace-distance is: 0.00011555198580026627 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.97
Batch: 260; loss: 0.23; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.31; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17088923532112388; val_accuracy: 0.9469546178343949 

The current subspace-distance is: 0.00011916876974282786 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.91
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.53; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.98
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1779725153449994; val_accuracy: 0.9437699044585988 

The current subspace-distance is: 0.00012334941129665822 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.05; acc: 1.0
Batch: 260; loss: 0.42; acc: 0.91
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.91
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16163231748019813; val_accuracy: 0.9509355095541401 

The current subspace-distance is: 0.00012745494314003736 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.33; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.84
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18063457841706124; val_accuracy: 0.943172770700637 

The current subspace-distance is: 0.00013085486716590822 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.05; acc: 1.0
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.36; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.14; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.05; acc: 1.0
Batch: 740; loss: 0.08; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15740417003346857; val_accuracy: 0.9516321656050956 

The current subspace-distance is: 0.00013471281272359192 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.91
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.37; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.86
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1533176006310305; val_accuracy: 0.953125 

The current subspace-distance is: 0.00013830186799168587 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15665481621577482; val_accuracy: 0.9508359872611465 

The current subspace-distance is: 0.00014166058099363 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.05; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.07; acc: 1.0
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.89
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15332356005147763; val_accuracy: 0.9506369426751592 

The current subspace-distance is: 0.00014519599790219218 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.98
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1554809129874038; val_accuracy: 0.9533240445859873 

The current subspace-distance is: 0.00014814974565524608 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.38; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.13; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15471725974967526; val_accuracy: 0.9513335987261147 

The current subspace-distance is: 0.00015191739657893777 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.92
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.33; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.15; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15612934838244868; val_accuracy: 0.9514331210191083 

The current subspace-distance is: 0.00015487179916817695 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.02; acc: 0.98
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1578467659130218; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 0.00015809816250111908 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.16; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15546800680221265; val_accuracy: 0.9508359872611465 

The current subspace-distance is: 0.00016067703836597502 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.07; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15367090989165244; val_accuracy: 0.9513335987261147 

The current subspace-distance is: 0.00016396779392380267 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.08; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.31; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.05; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15232490226151837; val_accuracy: 0.9507364649681529 

The current subspace-distance is: 0.0001669190969550982 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.91
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1496866981552285; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 0.00017014222976285964 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.05; acc: 1.0
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.98
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14920543812832254; val_accuracy: 0.9544187898089171 

The current subspace-distance is: 0.0001727673807181418 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.98
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.89
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14915451969785296; val_accuracy: 0.95421974522293 

The current subspace-distance is: 0.0001751868985593319 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.88
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14794841086029248; val_accuracy: 0.9539211783439491 

The current subspace-distance is: 0.00017795100575312972 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.01; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14784581124023266; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 0.0001807749504223466 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.52; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.91
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14861017377797964; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 0.0001832889101933688 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.35; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.89
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1506484819065993; val_accuracy: 0.9515326433121019 

The current subspace-distance is: 0.00018599974282551557 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.08; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.01; acc: 1.0
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14901702881903406; val_accuracy: 0.9541202229299363 

The current subspace-distance is: 0.00018897419795393944 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.15; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.06; acc: 1.0
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14855957970877362; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 0.00019207637524232268 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.08; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.05; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.91
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14728013499622133; val_accuracy: 0.9555135350318471 

The current subspace-distance is: 0.0001950540899997577 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.03; acc: 1.0
Batch: 80; loss: 0.36; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14694890085678952; val_accuracy: 0.9548168789808917 

The current subspace-distance is: 0.0001975904160644859 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.01; acc: 1.0
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.06; acc: 1.0
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.3; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14759731845586163; val_accuracy: 0.9537221337579618 

The current subspace-distance is: 0.0001998759398702532 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.148036049477234; val_accuracy: 0.9543192675159236 

The current subspace-distance is: 0.00020276664872653782 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.04; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.02; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.05; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14775142942074757; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 0.0002051886112894863 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.08; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.147447115178131; val_accuracy: 0.9535230891719745 

The current subspace-distance is: 0.0002077992248814553 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.18; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1470389597734828; val_accuracy: 0.9540207006369427 

The current subspace-distance is: 0.00021057338744867593 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.92
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14729794954798023; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 0.00021271852892823517 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.98
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.05; acc: 1.0
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.02; acc: 1.0
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.94
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1470446458952442; val_accuracy: 0.9537221337579618 

The current subspace-distance is: 0.00021539842418860644 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.04; acc: 1.0
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14706245845385418; val_accuracy: 0.9549164012738853 

The current subspace-distance is: 0.0002179876173613593 

plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
plots/subspace_training/reg_lenet/2020-01-22 14:38:21/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
