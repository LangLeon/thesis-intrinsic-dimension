model : lenet
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 2
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : True
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 20:45:30
nonzero elements in E: 2099
elements in E: 444260
fraction nonzero: 0.00472471075496331
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.32; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.32; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.12
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.32; acc: 0.03
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.3; acc: 0.05
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.31; acc: 0.11
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.17
Batch: 600; loss: 2.29; acc: 0.14
Batch: 620; loss: 2.3; acc: 0.06
Batch: 640; loss: 2.3; acc: 0.06
Batch: 660; loss: 2.31; acc: 0.06
Batch: 680; loss: 2.29; acc: 0.16
Batch: 700; loss: 2.29; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.12
Batch: 740; loss: 2.32; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.09
Batch: 780; loss: 2.3; acc: 0.14
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

1.0369095662099426e-06
2.0901774178128107e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.31; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.12
Val Epoch over. val_loss: 2.301108577448851; val_accuracy: 0.10250796178343949 

The current subspace-distance is: 2.0901774178128107e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.08
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.05
Batch: 160; loss: 2.31; acc: 0.11
Batch: 180; loss: 2.3; acc: 0.16
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.29; acc: 0.14
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.06
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.3; acc: 0.09
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.05
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.08
Batch: 460; loss: 2.29; acc: 0.17
Batch: 480; loss: 2.29; acc: 0.17
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.31; acc: 0.06
Batch: 540; loss: 2.29; acc: 0.17
Batch: 560; loss: 2.31; acc: 0.06
Batch: 580; loss: 2.29; acc: 0.12
Batch: 600; loss: 2.3; acc: 0.12
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.3; acc: 0.08
Batch: 660; loss: 2.29; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.05
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.08
Batch: 740; loss: 2.31; acc: 0.06
Batch: 760; loss: 2.29; acc: 0.17
Batch: 780; loss: 2.31; acc: 0.06
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

1.5821922261238797e-06
4.255565784205828e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.12
Val Epoch over. val_loss: 2.298509201426415; val_accuracy: 0.10141321656050956 

The current subspace-distance is: 4.255565784205828e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.3; acc: 0.06
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.19
Batch: 240; loss: 2.3; acc: 0.06
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.3; acc: 0.08
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.08
Batch: 360; loss: 2.28; acc: 0.17
Batch: 380; loss: 2.29; acc: 0.17
Batch: 400; loss: 2.29; acc: 0.09
Batch: 420; loss: 2.31; acc: 0.05
Batch: 440; loss: 2.31; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.12
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.17
Batch: 520; loss: 2.29; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.06
Batch: 580; loss: 2.29; acc: 0.22
Batch: 600; loss: 2.3; acc: 0.06
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.3; acc: 0.12
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.3; acc: 0.06
Batch: 700; loss: 2.29; acc: 0.08
Batch: 720; loss: 2.29; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.3; acc: 0.09
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

1.854049514804501e-06
4.082806128735683e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.296906285984501; val_accuracy: 0.10131369426751592 

The current subspace-distance is: 4.082806128735683e-07 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.3; acc: 0.06
Batch: 40; loss: 2.31; acc: 0.02
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.29; acc: 0.08
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.28; acc: 0.17
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.31; acc: 0.05
Batch: 220; loss: 2.31; acc: 0.08
Batch: 240; loss: 2.31; acc: 0.03
Batch: 260; loss: 2.3; acc: 0.06
Batch: 280; loss: 2.28; acc: 0.11
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.17
Batch: 400; loss: 2.29; acc: 0.09
Batch: 420; loss: 2.29; acc: 0.16
Batch: 440; loss: 2.3; acc: 0.05
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.31; acc: 0.05
Batch: 500; loss: 2.3; acc: 0.08
Batch: 520; loss: 2.3; acc: 0.08
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.31; acc: 0.06
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.3; acc: 0.14
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.31; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.09
Batch: 700; loss: 2.3; acc: 0.08
Batch: 720; loss: 2.29; acc: 0.08
Batch: 740; loss: 2.3; acc: 0.11
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.29; acc: 0.16
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

3.1122453947318718e-06
4.3409622207946086e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2963226555259366; val_accuracy: 0.10151273885350319 

The current subspace-distance is: 4.3409622207946086e-07 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.29; acc: 0.06
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.09
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.3; acc: 0.03
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.29; acc: 0.17
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.09
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.31; acc: 0.06
Batch: 320; loss: 2.28; acc: 0.17
Batch: 340; loss: 2.3; acc: 0.08
Batch: 360; loss: 2.29; acc: 0.17
Batch: 380; loss: 2.31; acc: 0.08
Batch: 400; loss: 2.31; acc: 0.06
Batch: 420; loss: 2.3; acc: 0.11
Batch: 440; loss: 2.29; acc: 0.14
Batch: 460; loss: 2.29; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.31; acc: 0.05
Batch: 520; loss: 2.3; acc: 0.09
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.3; acc: 0.09
Batch: 620; loss: 2.3; acc: 0.05
Batch: 640; loss: 2.29; acc: 0.09
Batch: 660; loss: 2.3; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.12
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.31; acc: 0.14
Batch: 760; loss: 2.29; acc: 0.14
Batch: 780; loss: 2.28; acc: 0.16
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.593866383904242e-06
8.014008017198648e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.29610276222229; val_accuracy: 0.10151273885350319 

The current subspace-distance is: 8.014008017198648e-07 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.06
Batch: 40; loss: 2.29; acc: 0.11
Batch: 60; loss: 2.29; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.09
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.02
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.3; acc: 0.08
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.31; acc: 0.0
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.06
Batch: 420; loss: 2.3; acc: 0.05
Batch: 440; loss: 2.29; acc: 0.06
Batch: 460; loss: 2.29; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.3; acc: 0.08
Batch: 520; loss: 2.3; acc: 0.08
Batch: 540; loss: 2.29; acc: 0.09
Batch: 560; loss: 2.28; acc: 0.19
Batch: 580; loss: 2.29; acc: 0.12
Batch: 600; loss: 2.3; acc: 0.05
Batch: 620; loss: 2.3; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.06
Batch: 660; loss: 2.3; acc: 0.05
Batch: 680; loss: 2.3; acc: 0.03
Batch: 700; loss: 2.29; acc: 0.08
Batch: 720; loss: 2.3; acc: 0.08
Batch: 740; loss: 2.29; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.08
Batch: 780; loss: 2.29; acc: 0.08
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.3547777345811483e-06
7.838704618734482e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.296006725092602; val_accuracy: 0.10151273885350319 

The current subspace-distance is: 7.838704618734482e-07 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.31; acc: 0.03
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.09
Batch: 220; loss: 2.3; acc: 0.11
Batch: 240; loss: 2.28; acc: 0.11
Batch: 260; loss: 2.29; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.31; acc: 0.08
Batch: 320; loss: 2.3; acc: 0.06
Batch: 340; loss: 2.3; acc: 0.08
Batch: 360; loss: 2.3; acc: 0.08
Batch: 380; loss: 2.29; acc: 0.05
Batch: 400; loss: 2.29; acc: 0.17
Batch: 420; loss: 2.29; acc: 0.09
Batch: 440; loss: 2.3; acc: 0.06
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.28; acc: 0.17
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.29; acc: 0.17
Batch: 540; loss: 2.31; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.05
Batch: 580; loss: 2.3; acc: 0.12
Batch: 600; loss: 2.3; acc: 0.14
Batch: 620; loss: 2.29; acc: 0.08
Batch: 640; loss: 2.31; acc: 0.05
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.3; acc: 0.05
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.06
Batch: 760; loss: 2.3; acc: 0.05
Batch: 780; loss: 2.3; acc: 0.06
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

1.975284021682455e-06
7.788886478010681e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2959413984019283; val_accuracy: 0.10161226114649681 

The current subspace-distance is: 7.788886478010681e-07 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.31; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.19
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.31; acc: 0.0
Batch: 200; loss: 2.28; acc: 0.17
Batch: 220; loss: 2.3; acc: 0.14
Batch: 240; loss: 2.3; acc: 0.08
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.06
Batch: 300; loss: 2.3; acc: 0.06
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.3; acc: 0.03
Batch: 440; loss: 2.29; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.3; acc: 0.08
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.29; acc: 0.12
Batch: 540; loss: 2.29; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.14
Batch: 580; loss: 2.29; acc: 0.22
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.3; acc: 0.08
Batch: 640; loss: 2.31; acc: 0.09
Batch: 660; loss: 2.3; acc: 0.05
Batch: 680; loss: 2.29; acc: 0.08
Batch: 700; loss: 2.27; acc: 0.25
Batch: 720; loss: 2.3; acc: 0.08
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.3; acc: 0.08
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

3.5463560834614327e-06
1.2105746236557025e-06
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2958944709437668; val_accuracy: 0.10161226114649681 

The current subspace-distance is: 1.2105746236557025e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.28; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.03
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.28; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.27; acc: 0.17
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.3; acc: 0.12
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.31; acc: 0.05
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.29; acc: 0.16
Batch: 440; loss: 2.3; acc: 0.09
Batch: 460; loss: 2.29; acc: 0.08
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.3; acc: 0.12
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.29; acc: 0.12
Batch: 580; loss: 2.3; acc: 0.09
Batch: 600; loss: 2.31; acc: 0.03
Batch: 620; loss: 2.3; acc: 0.08
Batch: 640; loss: 2.29; acc: 0.12
Batch: 660; loss: 2.3; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.16
Batch: 700; loss: 2.29; acc: 0.16
Batch: 720; loss: 2.31; acc: 0.08
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.05
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

3.8063710690039443e-06
1.0409570450065075e-06
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2958413628256245; val_accuracy: 0.1022093949044586 

The current subspace-distance is: 1.0409570450065075e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.28; acc: 0.16
Batch: 200; loss: 2.3; acc: 0.05
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.29; acc: 0.08
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.3; acc: 0.03
Batch: 340; loss: 2.3; acc: 0.05
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.06
Batch: 420; loss: 2.29; acc: 0.08
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.12
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.29; acc: 0.08
Batch: 520; loss: 2.3; acc: 0.06
Batch: 540; loss: 2.28; acc: 0.16
Batch: 560; loss: 2.3; acc: 0.11
Batch: 580; loss: 2.3; acc: 0.09
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.3; acc: 0.11
Batch: 660; loss: 2.3; acc: 0.14
Batch: 680; loss: 2.3; acc: 0.06
Batch: 700; loss: 2.31; acc: 0.05
Batch: 720; loss: 2.3; acc: 0.06
Batch: 740; loss: 2.3; acc: 0.06
Batch: 760; loss: 2.3; acc: 0.06
Batch: 780; loss: 2.29; acc: 0.08
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.563294856372522e-06
6.124789706518641e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2957494547412653; val_accuracy: 0.1022093949044586 

The current subspace-distance is: 6.124789706518641e-07 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.3; acc: 0.12
Batch: 20; loss: 2.29; acc: 0.16
Batch: 40; loss: 2.3; acc: 0.05
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.05
Batch: 100; loss: 2.29; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.28; acc: 0.09
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.09
Batch: 240; loss: 2.27; acc: 0.14
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.31; acc: 0.06
Batch: 300; loss: 2.29; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.29; acc: 0.16
Batch: 420; loss: 2.29; acc: 0.19
Batch: 440; loss: 2.3; acc: 0.09
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.3; acc: 0.08
Batch: 540; loss: 2.3; acc: 0.11
Batch: 560; loss: 2.31; acc: 0.03
Batch: 580; loss: 2.29; acc: 0.08
Batch: 600; loss: 2.29; acc: 0.09
Batch: 620; loss: 2.3; acc: 0.02
Batch: 640; loss: 2.31; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.08
Batch: 700; loss: 2.31; acc: 0.06
Batch: 720; loss: 2.3; acc: 0.08
Batch: 740; loss: 2.28; acc: 0.14
Batch: 760; loss: 2.3; acc: 0.16
Batch: 780; loss: 2.29; acc: 0.14
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.9235643523861654e-06
6.94809102697036e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2956968006814362; val_accuracy: 0.1022093949044586 

The current subspace-distance is: 6.94809102697036e-07 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 2.3; acc: 0.11
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.05
Batch: 60; loss: 2.31; acc: 0.08
Batch: 80; loss: 2.28; acc: 0.19
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.05
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.29; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.2
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.31; acc: 0.05
Batch: 320; loss: 2.29; acc: 0.14
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.3; acc: 0.05
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.29; acc: 0.11
Batch: 520; loss: 2.3; acc: 0.09
Batch: 540; loss: 2.29; acc: 0.11
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.3; acc: 0.06
Batch: 600; loss: 2.31; acc: 0.08
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.06
Batch: 660; loss: 2.3; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.12
Batch: 720; loss: 2.28; acc: 0.17
Batch: 740; loss: 2.31; acc: 0.09
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.3; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.5415333766432013e-06
5.916940608585719e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2956169896824345; val_accuracy: 0.1022093949044586 

The current subspace-distance is: 5.916940608585719e-07 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 2.31; acc: 0.05
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.05
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.29; acc: 0.06
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.06
Batch: 220; loss: 2.3; acc: 0.09
Batch: 240; loss: 2.3; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.31; acc: 0.08
Batch: 300; loss: 2.3; acc: 0.14
Batch: 320; loss: 2.31; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.14
Batch: 420; loss: 2.31; acc: 0.09
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.29; acc: 0.12
Batch: 520; loss: 2.3; acc: 0.11
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.08
Batch: 580; loss: 2.3; acc: 0.09
Batch: 600; loss: 2.3; acc: 0.09
Batch: 620; loss: 2.29; acc: 0.16
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.3; acc: 0.11
Batch: 680; loss: 2.3; acc: 0.06
Batch: 700; loss: 2.3; acc: 0.05
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.31; acc: 0.02
Batch: 760; loss: 2.3; acc: 0.09
Batch: 780; loss: 2.3; acc: 0.06
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

4.050605639349669e-06
7.944285016492358e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.295497857840957; val_accuracy: 0.10300557324840764 

The current subspace-distance is: 7.944285016492358e-07 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.22
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.29; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.06
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.28; acc: 0.17
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.06
Batch: 240; loss: 2.29; acc: 0.06
Batch: 260; loss: 2.29; acc: 0.11
Batch: 280; loss: 2.3; acc: 0.06
Batch: 300; loss: 2.29; acc: 0.16
Batch: 320; loss: 2.29; acc: 0.2
Batch: 340; loss: 2.29; acc: 0.16
Batch: 360; loss: 2.31; acc: 0.05
Batch: 380; loss: 2.32; acc: 0.06
Batch: 400; loss: 2.29; acc: 0.14
Batch: 420; loss: 2.3; acc: 0.08
Batch: 440; loss: 2.3; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.05
Batch: 480; loss: 2.3; acc: 0.03
Batch: 500; loss: 2.29; acc: 0.06
Batch: 520; loss: 2.29; acc: 0.09
Batch: 540; loss: 2.29; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.06
Batch: 580; loss: 2.32; acc: 0.03
Batch: 600; loss: 2.3; acc: 0.06
Batch: 620; loss: 2.3; acc: 0.03
Batch: 640; loss: 2.29; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.14
Batch: 740; loss: 2.29; acc: 0.11
Batch: 760; loss: 2.31; acc: 0.06
Batch: 780; loss: 2.3; acc: 0.09
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

3.2698549148335587e-06
7.705252187406586e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2953169285112125; val_accuracy: 0.1032046178343949 

The current subspace-distance is: 7.705252187406586e-07 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.31; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.05
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.31; acc: 0.06
Batch: 220; loss: 2.31; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.09
Batch: 260; loss: 2.29; acc: 0.08
Batch: 280; loss: 2.31; acc: 0.06
Batch: 300; loss: 2.3; acc: 0.08
Batch: 320; loss: 2.31; acc: 0.02
Batch: 340; loss: 2.3; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.2
Batch: 380; loss: 2.29; acc: 0.14
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.29; acc: 0.08
Batch: 440; loss: 2.29; acc: 0.11
Batch: 460; loss: 2.31; acc: 0.06
Batch: 480; loss: 2.31; acc: 0.08
Batch: 500; loss: 2.31; acc: 0.05
Batch: 520; loss: 2.29; acc: 0.12
Batch: 540; loss: 2.3; acc: 0.14
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.05
Batch: 600; loss: 2.28; acc: 0.14
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.28; acc: 0.17
Batch: 660; loss: 2.31; acc: 0.06
Batch: 680; loss: 2.31; acc: 0.05
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.3; acc: 0.08
Batch: 780; loss: 2.3; acc: 0.09
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.492682142474223e-06
5.971789391878701e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.12
Val Epoch over. val_loss: 2.295028337247812; val_accuracy: 0.1044984076433121 

The current subspace-distance is: 5.971789391878701e-07 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 2.31; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.3; acc: 0.06
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.31; acc: 0.09
Batch: 140; loss: 2.29; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.05
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.12
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.09
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.3; acc: 0.06
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.3; acc: 0.06
Batch: 520; loss: 2.28; acc: 0.17
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.06
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.14
Batch: 640; loss: 2.31; acc: 0.08
Batch: 660; loss: 2.3; acc: 0.12
Batch: 680; loss: 2.28; acc: 0.08
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.14
Batch: 760; loss: 2.29; acc: 0.05
Batch: 780; loss: 2.3; acc: 0.08
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

3.429897105888813e-06
7.603962330904324e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.31; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.12
Val Epoch over. val_loss: 2.2945956606773814; val_accuracy: 0.10529458598726114 

The current subspace-distance is: 7.603962330904324e-07 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.06
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.28; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.29; acc: 0.14
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.08
Batch: 240; loss: 2.3; acc: 0.08
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.28; acc: 0.19
Batch: 300; loss: 2.3; acc: 0.06
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.06
Batch: 380; loss: 2.29; acc: 0.11
Batch: 400; loss: 2.27; acc: 0.16
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.09
Batch: 480; loss: 2.31; acc: 0.06
Batch: 500; loss: 2.3; acc: 0.08
Batch: 520; loss: 2.29; acc: 0.05
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.29; acc: 0.08
Batch: 580; loss: 2.31; acc: 0.06
Batch: 600; loss: 2.3; acc: 0.11
Batch: 620; loss: 2.31; acc: 0.08
Batch: 640; loss: 2.3; acc: 0.08
Batch: 660; loss: 2.28; acc: 0.25
Batch: 680; loss: 2.28; acc: 0.19
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.08
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.28; acc: 0.08
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

2.7997664346912643e-06
1.0433417401145562e-06
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.28; acc: 0.12
Val Epoch over. val_loss: 2.2939268494867218; val_accuracy: 0.10658837579617834 

The current subspace-distance is: 1.0433417401145562e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.31; acc: 0.06
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.29; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.28; acc: 0.17
Batch: 140; loss: 2.29; acc: 0.17
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.3; acc: 0.08
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.3; acc: 0.06
Batch: 320; loss: 2.28; acc: 0.17
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.28; acc: 0.12
Batch: 380; loss: 2.29; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.09
Batch: 420; loss: 2.3; acc: 0.11
Batch: 440; loss: 2.3; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.16
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.3; acc: 0.11
Batch: 520; loss: 2.28; acc: 0.2
Batch: 540; loss: 2.3; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.28; acc: 0.11
Batch: 600; loss: 2.31; acc: 0.08
Batch: 620; loss: 2.29; acc: 0.08
Batch: 640; loss: 2.28; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.28; acc: 0.17
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.31; acc: 0.06
Train Epoch over. train_loss: 2.29; train_accuracy: 0.1 

2.5659508082753746e-06
8.592668336859788e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.28; acc: 0.14
Val Epoch over. val_loss: 2.292987528879931; val_accuracy: 0.10987261146496816 

The current subspace-distance is: 8.592668336859788e-07 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.31; acc: 0.05
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.29; acc: 0.05
Batch: 120; loss: 2.31; acc: 0.09
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.08
Batch: 200; loss: 2.28; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.09
Batch: 260; loss: 2.29; acc: 0.11
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.08
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.31; acc: 0.06
Batch: 440; loss: 2.3; acc: 0.11
Batch: 460; loss: 2.28; acc: 0.16
Batch: 480; loss: 2.31; acc: 0.08
Batch: 500; loss: 2.28; acc: 0.2
Batch: 520; loss: 2.29; acc: 0.06
Batch: 540; loss: 2.28; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.14
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.06
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.29; acc: 0.12
Batch: 660; loss: 2.28; acc: 0.12
Batch: 680; loss: 2.31; acc: 0.02
Batch: 700; loss: 2.29; acc: 0.11
Batch: 720; loss: 2.31; acc: 0.05
Batch: 740; loss: 2.3; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.05
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.29; train_accuracy: 0.11 

3.1103049877856392e-06
7.893659130786546e-07
Batch: 0; loss: 2.3; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.17
Batch: 140; loss: 2.28; acc: 0.14
Val Epoch over. val_loss: 2.2918166932027053; val_accuracy: 0.11564490445859872 

The current subspace-distance is: 7.893659130786546e-07 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.27; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.28; acc: 0.16
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.14
Batch: 320; loss: 2.3; acc: 0.12
Batch: 340; loss: 2.3; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.14
Batch: 400; loss: 2.28; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.05
Batch: 440; loss: 2.3; acc: 0.11
Batch: 460; loss: 2.29; acc: 0.08
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.31; acc: 0.09
Batch: 520; loss: 2.29; acc: 0.14
Batch: 540; loss: 2.3; acc: 0.14
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.09
Batch: 600; loss: 2.27; acc: 0.11
Batch: 620; loss: 2.29; acc: 0.16
Batch: 640; loss: 2.29; acc: 0.14
Batch: 660; loss: 2.29; acc: 0.16
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.08
Batch: 740; loss: 2.29; acc: 0.12
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.28; acc: 0.14
Train Epoch over. train_loss: 2.29; train_accuracy: 0.11 

3.482752617856022e-06
1.155433892563451e-06
Batch: 0; loss: 2.29; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.17
Val Epoch over. val_loss: 2.290618222230559; val_accuracy: 0.1191281847133758 

The current subspace-distance is: 1.155433892563451e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.28; acc: 0.08
Batch: 40; loss: 2.29; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.27; acc: 0.22
Batch: 100; loss: 2.29; acc: 0.16
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.29; acc: 0.16
Batch: 160; loss: 2.3; acc: 0.11
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.09
Batch: 260; loss: 2.28; acc: 0.12
Batch: 280; loss: 2.27; acc: 0.16
Batch: 300; loss: 2.29; acc: 0.25
Batch: 320; loss: 2.29; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.29; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.3; acc: 0.09
Batch: 420; loss: 2.31; acc: 0.09
Batch: 440; loss: 2.28; acc: 0.17
Batch: 460; loss: 2.28; acc: 0.17
Batch: 480; loss: 2.29; acc: 0.09
Batch: 500; loss: 2.28; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.2
Batch: 540; loss: 2.29; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.14
Batch: 580; loss: 2.3; acc: 0.08
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.28; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.05
Batch: 660; loss: 2.3; acc: 0.09
Batch: 680; loss: 2.28; acc: 0.17
Batch: 700; loss: 2.32; acc: 0.12
Batch: 720; loss: 2.28; acc: 0.12
Batch: 740; loss: 2.27; acc: 0.2
Batch: 760; loss: 2.29; acc: 0.08
Batch: 780; loss: 2.29; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

3.3969959076785017e-06
1.065447918335849e-06
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.19
Val Epoch over. val_loss: 2.290136511918086; val_accuracy: 0.12281050955414012 

The current subspace-distance is: 1.065447918335849e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.27
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.06
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.29; acc: 0.11
Batch: 220; loss: 2.3; acc: 0.14
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.16
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.14
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.27; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.16
Batch: 380; loss: 2.28; acc: 0.11
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.27; acc: 0.11
Batch: 460; loss: 2.27; acc: 0.16
Batch: 480; loss: 2.28; acc: 0.12
Batch: 500; loss: 2.28; acc: 0.16
Batch: 520; loss: 2.29; acc: 0.19
Batch: 540; loss: 2.3; acc: 0.11
Batch: 560; loss: 2.29; acc: 0.12
Batch: 580; loss: 2.3; acc: 0.09
Batch: 600; loss: 2.29; acc: 0.11
Batch: 620; loss: 2.29; acc: 0.08
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.17
Batch: 680; loss: 2.29; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.27; acc: 0.06
Batch: 740; loss: 2.29; acc: 0.12
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.28; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

3.575231858121697e-06
4.799492785423354e-07
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.19
Val Epoch over. val_loss: 2.289643468370863; val_accuracy: 0.12559713375796178 

The current subspace-distance is: 4.799492785423354e-07 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.29; acc: 0.19
Batch: 20; loss: 2.31; acc: 0.11
Batch: 40; loss: 2.28; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.27; acc: 0.23
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.08
Batch: 240; loss: 2.28; acc: 0.05
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.3; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.17
Batch: 320; loss: 2.32; acc: 0.06
Batch: 340; loss: 2.28; acc: 0.16
Batch: 360; loss: 2.28; acc: 0.2
Batch: 380; loss: 2.28; acc: 0.11
Batch: 400; loss: 2.28; acc: 0.19
Batch: 420; loss: 2.31; acc: 0.05
Batch: 440; loss: 2.3; acc: 0.11
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.28; acc: 0.08
Batch: 520; loss: 2.29; acc: 0.12
Batch: 540; loss: 2.27; acc: 0.19
Batch: 560; loss: 2.3; acc: 0.03
Batch: 580; loss: 2.3; acc: 0.16
Batch: 600; loss: 2.27; acc: 0.09
Batch: 620; loss: 2.28; acc: 0.19
Batch: 640; loss: 2.3; acc: 0.03
Batch: 660; loss: 2.29; acc: 0.2
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.05
Batch: 740; loss: 2.28; acc: 0.14
Batch: 760; loss: 2.29; acc: 0.16
Batch: 780; loss: 2.3; acc: 0.11
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

3.0295077522168867e-06
1.4141120345811942e-06
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.17
Batch: 140; loss: 2.28; acc: 0.17
Val Epoch over. val_loss: 2.2891299026027605; val_accuracy: 0.1282842356687898 

The current subspace-distance is: 1.4141120345811942e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.28; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.06
Batch: 80; loss: 2.3; acc: 0.09
Batch: 100; loss: 2.28; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.31; acc: 0.08
Batch: 180; loss: 2.29; acc: 0.16
Batch: 200; loss: 2.27; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.11
Batch: 240; loss: 2.29; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.29; acc: 0.06
Batch: 320; loss: 2.31; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.06
Batch: 380; loss: 2.28; acc: 0.16
Batch: 400; loss: 2.29; acc: 0.06
Batch: 420; loss: 2.29; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.09
Batch: 480; loss: 2.28; acc: 0.25
Batch: 500; loss: 2.28; acc: 0.16
Batch: 520; loss: 2.28; acc: 0.09
Batch: 540; loss: 2.29; acc: 0.06
Batch: 560; loss: 2.31; acc: 0.12
Batch: 580; loss: 2.28; acc: 0.11
Batch: 600; loss: 2.31; acc: 0.06
Batch: 620; loss: 2.3; acc: 0.11
Batch: 640; loss: 2.29; acc: 0.08
Batch: 660; loss: 2.28; acc: 0.11
Batch: 680; loss: 2.28; acc: 0.09
Batch: 700; loss: 2.31; acc: 0.11
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.09
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.3; acc: 0.08
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

3.6328456189949065e-06
4.7030775363055e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.09
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.19
Batch: 140; loss: 2.28; acc: 0.17
Val Epoch over. val_loss: 2.288588936921138; val_accuracy: 0.12977707006369427 

The current subspace-distance is: 4.7030775363055e-07 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.28; acc: 0.2
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.31; acc: 0.06
Batch: 200; loss: 2.28; acc: 0.16
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.08
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.3; acc: 0.06
Batch: 300; loss: 2.3; acc: 0.12
Batch: 320; loss: 2.27; acc: 0.09
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.29; acc: 0.08
Batch: 380; loss: 2.28; acc: 0.17
Batch: 400; loss: 2.31; acc: 0.11
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.27; acc: 0.16
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.08
Batch: 520; loss: 2.28; acc: 0.16
Batch: 540; loss: 2.29; acc: 0.09
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.28; acc: 0.19
Batch: 600; loss: 2.3; acc: 0.14
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.28; acc: 0.14
Batch: 660; loss: 2.29; acc: 0.06
Batch: 680; loss: 2.28; acc: 0.17
Batch: 700; loss: 2.3; acc: 0.06
Batch: 720; loss: 2.29; acc: 0.14
Batch: 740; loss: 2.27; acc: 0.12
Batch: 760; loss: 2.29; acc: 0.09
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

4.522268227447057e-06
1.1745255505957175e-06
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.17
Val Epoch over. val_loss: 2.2880109085398876; val_accuracy: 0.13306130573248406 

The current subspace-distance is: 1.1745255505957175e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.12
Batch: 40; loss: 2.27; acc: 0.22
Batch: 60; loss: 2.31; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.22
Batch: 180; loss: 2.3; acc: 0.08
Batch: 200; loss: 2.28; acc: 0.16
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.28; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.27; acc: 0.16
Batch: 300; loss: 2.3; acc: 0.12
Batch: 320; loss: 2.28; acc: 0.19
Batch: 340; loss: 2.29; acc: 0.16
Batch: 360; loss: 2.29; acc: 0.14
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.28; acc: 0.22
Batch: 420; loss: 2.3; acc: 0.06
Batch: 440; loss: 2.28; acc: 0.12
Batch: 460; loss: 2.29; acc: 0.05
Batch: 480; loss: 2.28; acc: 0.12
Batch: 500; loss: 2.29; acc: 0.25
Batch: 520; loss: 2.29; acc: 0.06
Batch: 540; loss: 2.29; acc: 0.11
Batch: 560; loss: 2.29; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.16
Batch: 600; loss: 2.28; acc: 0.23
Batch: 620; loss: 2.3; acc: 0.06
Batch: 640; loss: 2.28; acc: 0.16
Batch: 660; loss: 2.31; acc: 0.08
Batch: 680; loss: 2.3; acc: 0.12
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.08
Batch: 740; loss: 2.26; acc: 0.25
Batch: 760; loss: 2.28; acc: 0.12
Batch: 780; loss: 2.29; acc: 0.19
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

5.542724466067739e-06
1.3417045465757838e-06
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.17
Val Epoch over. val_loss: 2.2874003367818845; val_accuracy: 0.1321656050955414 

The current subspace-distance is: 1.3417045465757838e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.31; acc: 0.03
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.28; acc: 0.17
Batch: 60; loss: 2.29; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.3; acc: 0.06
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.3; acc: 0.19
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.17
Batch: 240; loss: 2.26; acc: 0.19
Batch: 260; loss: 2.29; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.16
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.27; acc: 0.14
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.28; acc: 0.2
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.27; acc: 0.19
Batch: 420; loss: 2.29; acc: 0.09
Batch: 440; loss: 2.28; acc: 0.17
Batch: 460; loss: 2.28; acc: 0.14
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.28; acc: 0.17
Batch: 520; loss: 2.28; acc: 0.17
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.12
Batch: 580; loss: 2.26; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.19
Batch: 620; loss: 2.29; acc: 0.11
Batch: 640; loss: 2.3; acc: 0.11
Batch: 660; loss: 2.28; acc: 0.16
Batch: 680; loss: 2.27; acc: 0.19
Batch: 700; loss: 2.29; acc: 0.17
Batch: 720; loss: 2.28; acc: 0.12
Batch: 740; loss: 2.26; acc: 0.27
Batch: 760; loss: 2.29; acc: 0.11
Batch: 780; loss: 2.28; acc: 0.17
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

3.6375251966092037e-06
9.966839797925786e-07
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.27; acc: 0.16
Val Epoch over. val_loss: 2.286748770695583; val_accuracy: 0.13654458598726116 

The current subspace-distance is: 9.966839797925786e-07 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.27; acc: 0.19
Batch: 20; loss: 2.3; acc: 0.17
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.17
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.31; acc: 0.14
Batch: 160; loss: 2.29; acc: 0.09
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.27; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.17
Batch: 300; loss: 2.3; acc: 0.16
Batch: 320; loss: 2.27; acc: 0.14
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.28; acc: 0.11
Batch: 380; loss: 2.31; acc: 0.06
Batch: 400; loss: 2.28; acc: 0.16
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.27; acc: 0.22
Batch: 460; loss: 2.29; acc: 0.16
Batch: 480; loss: 2.3; acc: 0.12
Batch: 500; loss: 2.31; acc: 0.08
Batch: 520; loss: 2.26; acc: 0.22
Batch: 540; loss: 2.28; acc: 0.19
Batch: 560; loss: 2.28; acc: 0.2
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.29; acc: 0.23
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.12
Batch: 680; loss: 2.3; acc: 0.11
Batch: 700; loss: 2.28; acc: 0.17
Batch: 720; loss: 2.3; acc: 0.09
Batch: 740; loss: 2.28; acc: 0.09
Batch: 760; loss: 2.28; acc: 0.19
Batch: 780; loss: 2.28; acc: 0.16
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

5.464416517497739e-06
1.3904106026529917e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2860401937156727; val_accuracy: 0.13624601910828024 

The current subspace-distance is: 1.3904106026529917e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.16
Batch: 60; loss: 2.28; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.09
Batch: 100; loss: 2.28; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.06
Batch: 140; loss: 2.28; acc: 0.25
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.29; acc: 0.19
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.3; acc: 0.14
Batch: 300; loss: 2.28; acc: 0.12
Batch: 320; loss: 2.28; acc: 0.17
Batch: 340; loss: 2.3; acc: 0.12
Batch: 360; loss: 2.31; acc: 0.12
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.3; acc: 0.16
Batch: 420; loss: 2.28; acc: 0.08
Batch: 440; loss: 2.3; acc: 0.06
Batch: 460; loss: 2.28; acc: 0.12
Batch: 480; loss: 2.28; acc: 0.09
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.29; acc: 0.08
Batch: 540; loss: 2.29; acc: 0.14
Batch: 560; loss: 2.3; acc: 0.17
Batch: 580; loss: 2.29; acc: 0.06
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.27; acc: 0.16
Batch: 640; loss: 2.28; acc: 0.19
Batch: 660; loss: 2.29; acc: 0.09
Batch: 680; loss: 2.29; acc: 0.14
Batch: 700; loss: 2.28; acc: 0.16
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.27; acc: 0.17
Batch: 760; loss: 2.28; acc: 0.2
Batch: 780; loss: 2.31; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

5.8324221754446626e-06
1.729468749545049e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2852946512258736; val_accuracy: 0.13435509554140126 

The current subspace-distance is: 1.729468749545049e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.27; acc: 0.19
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.27; acc: 0.2
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.28; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.22
Batch: 200; loss: 2.27; acc: 0.14
Batch: 220; loss: 2.31; acc: 0.09
Batch: 240; loss: 2.27; acc: 0.22
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.3; acc: 0.16
Batch: 300; loss: 2.3; acc: 0.16
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.28; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.19
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.29; acc: 0.17
Batch: 420; loss: 2.27; acc: 0.17
Batch: 440; loss: 2.3; acc: 0.06
Batch: 460; loss: 2.27; acc: 0.22
Batch: 480; loss: 2.31; acc: 0.06
Batch: 500; loss: 2.29; acc: 0.08
Batch: 520; loss: 2.29; acc: 0.11
Batch: 540; loss: 2.28; acc: 0.14
Batch: 560; loss: 2.29; acc: 0.2
Batch: 580; loss: 2.31; acc: 0.08
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.29; acc: 0.12
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.29; acc: 0.19
Batch: 700; loss: 2.29; acc: 0.11
Batch: 720; loss: 2.28; acc: 0.17
Batch: 740; loss: 2.26; acc: 0.23
Batch: 760; loss: 2.31; acc: 0.08
Batch: 780; loss: 2.32; acc: 0.08
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

3.715039611051907e-06
1.584097617524094e-06
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.14
Val Epoch over. val_loss: 2.2844938092930303; val_accuracy: 0.13724124203821655 

The current subspace-distance is: 1.584097617524094e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.19
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.06
Batch: 80; loss: 2.28; acc: 0.12
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.27; acc: 0.2
Batch: 140; loss: 2.28; acc: 0.16
Batch: 160; loss: 2.28; acc: 0.11
Batch: 180; loss: 2.28; acc: 0.19
Batch: 200; loss: 2.29; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.28; acc: 0.14
Batch: 280; loss: 2.27; acc: 0.2
Batch: 300; loss: 2.27; acc: 0.14
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.27; acc: 0.22
Batch: 360; loss: 2.29; acc: 0.16
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.28; acc: 0.11
Batch: 420; loss: 2.28; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.31; acc: 0.03
Batch: 480; loss: 2.28; acc: 0.12
Batch: 500; loss: 2.29; acc: 0.11
Batch: 520; loss: 2.27; acc: 0.19
Batch: 540; loss: 2.29; acc: 0.17
Batch: 560; loss: 2.28; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.09
Batch: 600; loss: 2.27; acc: 0.12
Batch: 620; loss: 2.27; acc: 0.12
Batch: 640; loss: 2.27; acc: 0.16
Batch: 660; loss: 2.29; acc: 0.16
Batch: 680; loss: 2.29; acc: 0.14
Batch: 700; loss: 2.29; acc: 0.2
Batch: 720; loss: 2.3; acc: 0.14
Batch: 740; loss: 2.27; acc: 0.14
Batch: 760; loss: 2.29; acc: 0.14
Batch: 780; loss: 2.28; acc: 0.14
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

4.946743956679711e-06
1.3276439858600497e-06
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.12
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.14
Val Epoch over. val_loss: 2.2841570422907544; val_accuracy: 0.1363455414012739 

The current subspace-distance is: 1.3276439858600497e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.28; acc: 0.16
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.31; acc: 0.11
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.06
Batch: 140; loss: 2.31; acc: 0.12
Batch: 160; loss: 2.3; acc: 0.16
Batch: 180; loss: 2.31; acc: 0.12
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.09
Batch: 260; loss: 2.27; acc: 0.2
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.27; acc: 0.23
Batch: 320; loss: 2.29; acc: 0.14
Batch: 340; loss: 2.26; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.14
Batch: 400; loss: 2.29; acc: 0.05
Batch: 420; loss: 2.27; acc: 0.22
Batch: 440; loss: 2.28; acc: 0.14
Batch: 460; loss: 2.28; acc: 0.14
Batch: 480; loss: 2.27; acc: 0.19
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.28; acc: 0.05
Batch: 540; loss: 2.27; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.16
Batch: 580; loss: 2.27; acc: 0.11
Batch: 600; loss: 2.29; acc: 0.11
Batch: 620; loss: 2.28; acc: 0.12
Batch: 640; loss: 2.31; acc: 0.08
Batch: 660; loss: 2.28; acc: 0.06
Batch: 680; loss: 2.28; acc: 0.19
Batch: 700; loss: 2.28; acc: 0.12
Batch: 720; loss: 2.27; acc: 0.2
Batch: 740; loss: 2.28; acc: 0.06
Batch: 760; loss: 2.29; acc: 0.19
Batch: 780; loss: 2.29; acc: 0.09
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

3.0350047381944023e-06
9.167224561679177e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.16
Val Epoch over. val_loss: 2.283812126536278; val_accuracy: 0.1373407643312102 

The current subspace-distance is: 9.167224561679177e-07 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.28; acc: 0.09
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.28; acc: 0.17
Batch: 60; loss: 2.29; acc: 0.23
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.09
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.11
Batch: 180; loss: 2.25; acc: 0.17
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.08
Batch: 240; loss: 2.28; acc: 0.09
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.17
Batch: 300; loss: 2.27; acc: 0.19
Batch: 320; loss: 2.29; acc: 0.12
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.27; acc: 0.14
Batch: 380; loss: 2.29; acc: 0.12
Batch: 400; loss: 2.29; acc: 0.09
Batch: 420; loss: 2.31; acc: 0.03
Batch: 440; loss: 2.31; acc: 0.11
Batch: 460; loss: 2.27; acc: 0.17
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.27; acc: 0.12
Batch: 520; loss: 2.29; acc: 0.11
Batch: 540; loss: 2.29; acc: 0.14
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.3; acc: 0.12
Batch: 620; loss: 2.27; acc: 0.14
Batch: 640; loss: 2.28; acc: 0.22
Batch: 660; loss: 2.27; acc: 0.2
Batch: 680; loss: 2.28; acc: 0.2
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.28; acc: 0.19
Batch: 740; loss: 2.29; acc: 0.16
Batch: 760; loss: 2.28; acc: 0.12
Batch: 780; loss: 2.29; acc: 0.14
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

4.113951490580803e-06
1.5631316045983112e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.14
Val Epoch over. val_loss: 2.2834536816663804; val_accuracy: 0.13594745222929935 

The current subspace-distance is: 1.5631316045983112e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.28; acc: 0.16
Batch: 20; loss: 2.29; acc: 0.12
Batch: 40; loss: 2.28; acc: 0.14
Batch: 60; loss: 2.28; acc: 0.17
Batch: 80; loss: 2.26; acc: 0.17
Batch: 100; loss: 2.27; acc: 0.08
Batch: 120; loss: 2.27; acc: 0.17
Batch: 140; loss: 2.28; acc: 0.09
Batch: 160; loss: 2.28; acc: 0.2
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.29; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.11
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.27; acc: 0.09
Batch: 320; loss: 2.27; acc: 0.11
Batch: 340; loss: 2.27; acc: 0.17
Batch: 360; loss: 2.26; acc: 0.2
Batch: 380; loss: 2.28; acc: 0.09
Batch: 400; loss: 2.28; acc: 0.11
Batch: 420; loss: 2.27; acc: 0.12
Batch: 440; loss: 2.29; acc: 0.17
Batch: 460; loss: 2.29; acc: 0.17
Batch: 480; loss: 2.28; acc: 0.14
Batch: 500; loss: 2.28; acc: 0.09
Batch: 520; loss: 2.29; acc: 0.08
Batch: 540; loss: 2.28; acc: 0.11
Batch: 560; loss: 2.28; acc: 0.12
Batch: 580; loss: 2.29; acc: 0.09
Batch: 600; loss: 2.29; acc: 0.09
Batch: 620; loss: 2.28; acc: 0.19
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.3; acc: 0.09
Batch: 680; loss: 2.3; acc: 0.08
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.28; acc: 0.09
Batch: 760; loss: 2.28; acc: 0.17
Batch: 780; loss: 2.28; acc: 0.19
Train Epoch over. train_loss: 2.29; train_accuracy: 0.13 

4.903920398646733e-06
9.395023994329676e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.14
Val Epoch over. val_loss: 2.283089176105086; val_accuracy: 0.13724124203821655 

The current subspace-distance is: 9.395023994329676e-07 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.19
Batch: 40; loss: 2.28; acc: 0.16
Batch: 60; loss: 2.31; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.28; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.16
Batch: 160; loss: 2.29; acc: 0.12
Batch: 180; loss: 2.27; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.11
Batch: 240; loss: 2.28; acc: 0.11
Batch: 260; loss: 2.29; acc: 0.12
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.3; acc: 0.06
Batch: 320; loss: 2.28; acc: 0.19
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.14
Batch: 380; loss: 2.29; acc: 0.11
Batch: 400; loss: 2.27; acc: 0.2
Batch: 420; loss: 2.26; acc: 0.17
Batch: 440; loss: 2.28; acc: 0.19
Batch: 460; loss: 2.29; acc: 0.14
Batch: 480; loss: 2.27; acc: 0.2
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.11
Batch: 540; loss: 2.3; acc: 0.16
Batch: 560; loss: 2.29; acc: 0.08
Batch: 580; loss: 2.29; acc: 0.16
Batch: 600; loss: 2.28; acc: 0.16
Batch: 620; loss: 2.31; acc: 0.06
Batch: 640; loss: 2.28; acc: 0.12
Batch: 660; loss: 2.29; acc: 0.17
Batch: 680; loss: 2.28; acc: 0.19
Batch: 700; loss: 2.29; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.11
Batch: 740; loss: 2.28; acc: 0.14
Batch: 760; loss: 2.28; acc: 0.2
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

2.8004944852000335e-06
8.158272635228059e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2827150290179405; val_accuracy: 0.136046974522293 

The current subspace-distance is: 8.158272635228059e-07 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.3; acc: 0.09
Batch: 20; loss: 2.28; acc: 0.11
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.27; acc: 0.19
Batch: 80; loss: 2.28; acc: 0.12
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.28; acc: 0.11
Batch: 160; loss: 2.27; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.27; acc: 0.16
Batch: 220; loss: 2.31; acc: 0.06
Batch: 240; loss: 2.29; acc: 0.2
Batch: 260; loss: 2.29; acc: 0.11
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.14
Batch: 320; loss: 2.25; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.09
Batch: 380; loss: 2.29; acc: 0.11
Batch: 400; loss: 2.27; acc: 0.12
Batch: 420; loss: 2.27; acc: 0.16
Batch: 440; loss: 2.29; acc: 0.14
Batch: 460; loss: 2.3; acc: 0.08
Batch: 480; loss: 2.31; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.27; acc: 0.11
Batch: 540; loss: 2.27; acc: 0.25
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.28; acc: 0.16
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.29; acc: 0.09
Batch: 640; loss: 2.26; acc: 0.14
Batch: 660; loss: 2.26; acc: 0.16
Batch: 680; loss: 2.27; acc: 0.2
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.28; acc: 0.16
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.27; acc: 0.14
Batch: 780; loss: 2.27; acc: 0.14
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

4.26365613748203e-06
9.155539260063961e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.14
Val Epoch over. val_loss: 2.2823316443497967; val_accuracy: 0.13395700636942676 

The current subspace-distance is: 9.155539260063961e-07 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.08
Batch: 40; loss: 2.27; acc: 0.19
Batch: 60; loss: 2.28; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.08
Batch: 100; loss: 2.29; acc: 0.2
Batch: 120; loss: 2.29; acc: 0.06
Batch: 140; loss: 2.27; acc: 0.19
Batch: 160; loss: 2.27; acc: 0.09
Batch: 180; loss: 2.28; acc: 0.17
Batch: 200; loss: 2.26; acc: 0.23
Batch: 220; loss: 2.27; acc: 0.12
Batch: 240; loss: 2.29; acc: 0.08
Batch: 260; loss: 2.32; acc: 0.03
Batch: 280; loss: 2.27; acc: 0.16
Batch: 300; loss: 2.28; acc: 0.22
Batch: 320; loss: 2.27; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.28; acc: 0.12
Batch: 380; loss: 2.27; acc: 0.12
Batch: 400; loss: 2.26; acc: 0.25
Batch: 420; loss: 2.31; acc: 0.09
Batch: 440; loss: 2.29; acc: 0.12
Batch: 460; loss: 2.26; acc: 0.2
Batch: 480; loss: 2.28; acc: 0.2
Batch: 500; loss: 2.27; acc: 0.22
Batch: 520; loss: 2.27; acc: 0.16
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.11
Batch: 580; loss: 2.25; acc: 0.22
Batch: 600; loss: 2.31; acc: 0.11
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.29; acc: 0.09
Batch: 660; loss: 2.28; acc: 0.12
Batch: 680; loss: 2.28; acc: 0.11
Batch: 700; loss: 2.27; acc: 0.16
Batch: 720; loss: 2.26; acc: 0.22
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.27; acc: 0.19
Batch: 780; loss: 2.27; acc: 0.16
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.3461810744483955e-06
1.1245957693972741e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.19
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2819428610953554; val_accuracy: 0.13335987261146498 

The current subspace-distance is: 1.1245957693972741e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.29; acc: 0.11
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.3; acc: 0.08
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.28; acc: 0.09
Batch: 100; loss: 2.29; acc: 0.14
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.27; acc: 0.17
Batch: 160; loss: 2.28; acc: 0.08
Batch: 180; loss: 2.27; acc: 0.14
Batch: 200; loss: 2.27; acc: 0.19
Batch: 220; loss: 2.28; acc: 0.08
Batch: 240; loss: 2.28; acc: 0.16
Batch: 260; loss: 2.3; acc: 0.06
Batch: 280; loss: 2.29; acc: 0.2
Batch: 300; loss: 2.27; acc: 0.16
Batch: 320; loss: 2.28; acc: 0.14
Batch: 340; loss: 2.27; acc: 0.23
Batch: 360; loss: 2.31; acc: 0.12
Batch: 380; loss: 2.29; acc: 0.06
Batch: 400; loss: 2.26; acc: 0.14
Batch: 420; loss: 2.28; acc: 0.08
Batch: 440; loss: 2.29; acc: 0.11
Batch: 460; loss: 2.31; acc: 0.06
Batch: 480; loss: 2.28; acc: 0.2
Batch: 500; loss: 2.29; acc: 0.2
Batch: 520; loss: 2.26; acc: 0.12
Batch: 540; loss: 2.31; acc: 0.08
Batch: 560; loss: 2.27; acc: 0.17
Batch: 580; loss: 2.3; acc: 0.14
Batch: 600; loss: 2.28; acc: 0.12
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.3; acc: 0.09
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.28; acc: 0.09
Batch: 700; loss: 2.27; acc: 0.16
Batch: 720; loss: 2.28; acc: 0.11
Batch: 740; loss: 2.31; acc: 0.11
Batch: 760; loss: 2.28; acc: 0.12
Batch: 780; loss: 2.27; acc: 0.17
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.336532927278313e-06
1.2204945960547775e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2815438941785486; val_accuracy: 0.13415605095541402 

The current subspace-distance is: 1.2204945960547775e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.29; acc: 0.17
Batch: 20; loss: 2.27; acc: 0.11
Batch: 40; loss: 2.27; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.28; acc: 0.2
Batch: 100; loss: 2.26; acc: 0.16
Batch: 120; loss: 2.27; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.11
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.09
Batch: 200; loss: 2.27; acc: 0.17
Batch: 220; loss: 2.27; acc: 0.23
Batch: 240; loss: 2.28; acc: 0.17
Batch: 260; loss: 2.28; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.12
Batch: 300; loss: 2.28; acc: 0.16
Batch: 320; loss: 2.29; acc: 0.12
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.28; acc: 0.27
Batch: 400; loss: 2.28; acc: 0.11
Batch: 420; loss: 2.27; acc: 0.22
Batch: 440; loss: 2.26; acc: 0.16
Batch: 460; loss: 2.3; acc: 0.08
Batch: 480; loss: 2.3; acc: 0.08
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.29; acc: 0.11
Batch: 540; loss: 2.31; acc: 0.14
Batch: 560; loss: 2.28; acc: 0.08
Batch: 580; loss: 2.31; acc: 0.06
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.28; acc: 0.16
Batch: 640; loss: 2.29; acc: 0.16
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.31; acc: 0.02
Batch: 740; loss: 2.29; acc: 0.08
Batch: 760; loss: 2.26; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.579929398256354e-06
1.100504960049875e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.31; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2811323229674323; val_accuracy: 0.13365843949044587 

The current subspace-distance is: 1.100504960049875e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 2.28; acc: 0.17
Batch: 20; loss: 2.29; acc: 0.14
Batch: 40; loss: 2.31; acc: 0.11
Batch: 60; loss: 2.28; acc: 0.11
Batch: 80; loss: 2.31; acc: 0.08
Batch: 100; loss: 2.28; acc: 0.2
Batch: 120; loss: 2.28; acc: 0.11
Batch: 140; loss: 2.28; acc: 0.14
Batch: 160; loss: 2.29; acc: 0.09
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.28; acc: 0.17
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.14
Batch: 320; loss: 2.3; acc: 0.09
Batch: 340; loss: 2.27; acc: 0.11
Batch: 360; loss: 2.28; acc: 0.09
Batch: 380; loss: 2.26; acc: 0.19
Batch: 400; loss: 2.29; acc: 0.16
Batch: 420; loss: 2.31; acc: 0.05
Batch: 440; loss: 2.28; acc: 0.16
Batch: 460; loss: 2.28; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.16
Batch: 500; loss: 2.28; acc: 0.08
Batch: 520; loss: 2.28; acc: 0.12
Batch: 540; loss: 2.28; acc: 0.11
Batch: 560; loss: 2.28; acc: 0.2
Batch: 580; loss: 2.28; acc: 0.11
Batch: 600; loss: 2.3; acc: 0.08
Batch: 620; loss: 2.28; acc: 0.14
Batch: 640; loss: 2.27; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.31; acc: 0.08
Batch: 700; loss: 2.28; acc: 0.17
Batch: 720; loss: 2.28; acc: 0.12
Batch: 740; loss: 2.28; acc: 0.12
Batch: 760; loss: 2.27; acc: 0.17
Batch: 780; loss: 2.27; acc: 0.16
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.829452452919213e-06
1.4457150427915622e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2807126197086016; val_accuracy: 0.1324641719745223 

The current subspace-distance is: 1.4457150427915622e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.33; acc: 0.02
Batch: 20; loss: 2.3; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.06
Batch: 60; loss: 2.28; acc: 0.17
Batch: 80; loss: 2.28; acc: 0.11
Batch: 100; loss: 2.28; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.29; acc: 0.12
Batch: 180; loss: 2.3; acc: 0.12
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.33; acc: 0.06
Batch: 260; loss: 2.27; acc: 0.17
Batch: 280; loss: 2.29; acc: 0.06
Batch: 300; loss: 2.29; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.12
Batch: 340; loss: 2.28; acc: 0.05
Batch: 360; loss: 2.29; acc: 0.14
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.3; acc: 0.12
Batch: 420; loss: 2.27; acc: 0.09
Batch: 440; loss: 2.28; acc: 0.17
Batch: 460; loss: 2.27; acc: 0.17
Batch: 480; loss: 2.27; acc: 0.16
Batch: 500; loss: 2.29; acc: 0.11
Batch: 520; loss: 2.28; acc: 0.06
Batch: 540; loss: 2.26; acc: 0.17
Batch: 560; loss: 2.28; acc: 0.11
Batch: 580; loss: 2.28; acc: 0.12
Batch: 600; loss: 2.28; acc: 0.11
Batch: 620; loss: 2.3; acc: 0.09
Batch: 640; loss: 2.26; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.29; acc: 0.2
Batch: 700; loss: 2.27; acc: 0.16
Batch: 720; loss: 2.27; acc: 0.2
Batch: 740; loss: 2.28; acc: 0.11
Batch: 760; loss: 2.29; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.05
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.2972391181829153e-06
9.648322247812757e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2805407912867843; val_accuracy: 0.13166799363057324 

The current subspace-distance is: 9.648322247812757e-07 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.32; acc: 0.06
Batch: 20; loss: 2.29; acc: 0.17
Batch: 40; loss: 2.28; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.28; acc: 0.16
Batch: 120; loss: 2.29; acc: 0.09
Batch: 140; loss: 2.3; acc: 0.11
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.27; acc: 0.17
Batch: 200; loss: 2.29; acc: 0.17
Batch: 220; loss: 2.3; acc: 0.11
Batch: 240; loss: 2.28; acc: 0.16
Batch: 260; loss: 2.3; acc: 0.08
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.08
Batch: 320; loss: 2.28; acc: 0.08
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.27; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.11
Batch: 400; loss: 2.28; acc: 0.14
Batch: 420; loss: 2.29; acc: 0.06
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.27; acc: 0.19
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.17
Batch: 540; loss: 2.31; acc: 0.08
Batch: 560; loss: 2.28; acc: 0.12
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.3; acc: 0.05
Batch: 620; loss: 2.29; acc: 0.09
Batch: 640; loss: 2.29; acc: 0.08
Batch: 660; loss: 2.28; acc: 0.14
Batch: 680; loss: 2.29; acc: 0.11
Batch: 700; loss: 2.28; acc: 0.06
Batch: 720; loss: 2.27; acc: 0.14
Batch: 740; loss: 2.29; acc: 0.09
Batch: 760; loss: 2.27; acc: 0.14
Batch: 780; loss: 2.27; acc: 0.08
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.1296740417019464e-06
2.369049525441369e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2803675718368237; val_accuracy: 0.1318670382165605 

The current subspace-distance is: 2.369049525441369e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.27; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.11
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.26; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.09
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.29; acc: 0.12
Batch: 180; loss: 2.29; acc: 0.14
Batch: 200; loss: 2.27; acc: 0.11
Batch: 220; loss: 2.31; acc: 0.08
Batch: 240; loss: 2.31; acc: 0.09
Batch: 260; loss: 2.27; acc: 0.16
Batch: 280; loss: 2.27; acc: 0.2
Batch: 300; loss: 2.27; acc: 0.19
Batch: 320; loss: 2.31; acc: 0.12
Batch: 340; loss: 2.29; acc: 0.08
Batch: 360; loss: 2.3; acc: 0.12
Batch: 380; loss: 2.29; acc: 0.06
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.29; acc: 0.08
Batch: 460; loss: 2.3; acc: 0.09
Batch: 480; loss: 2.3; acc: 0.09
Batch: 500; loss: 2.25; acc: 0.16
Batch: 520; loss: 2.28; acc: 0.2
Batch: 540; loss: 2.29; acc: 0.16
Batch: 560; loss: 2.28; acc: 0.17
Batch: 580; loss: 2.29; acc: 0.14
Batch: 600; loss: 2.3; acc: 0.11
Batch: 620; loss: 2.25; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.12
Batch: 660; loss: 2.28; acc: 0.09
Batch: 680; loss: 2.26; acc: 0.19
Batch: 700; loss: 2.31; acc: 0.05
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.29; acc: 0.08
Batch: 760; loss: 2.29; acc: 0.12
Batch: 780; loss: 2.31; acc: 0.16
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.824925897788489e-06
2.347791678403155e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.280193435158699; val_accuracy: 0.13166799363057324 

The current subspace-distance is: 2.347791678403155e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.06
Batch: 20; loss: 2.28; acc: 0.17
Batch: 40; loss: 2.33; acc: 0.05
Batch: 60; loss: 2.3; acc: 0.05
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.17
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.29; acc: 0.08
Batch: 240; loss: 2.27; acc: 0.08
Batch: 260; loss: 2.27; acc: 0.12
Batch: 280; loss: 2.27; acc: 0.14
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.26; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.26; acc: 0.11
Batch: 400; loss: 2.31; acc: 0.05
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.27; acc: 0.17
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.28; acc: 0.17
Batch: 500; loss: 2.29; acc: 0.16
Batch: 520; loss: 2.26; acc: 0.16
Batch: 540; loss: 2.29; acc: 0.16
Batch: 560; loss: 2.29; acc: 0.11
Batch: 580; loss: 2.3; acc: 0.11
Batch: 600; loss: 2.26; acc: 0.14
Batch: 620; loss: 2.29; acc: 0.14
Batch: 640; loss: 2.27; acc: 0.11
Batch: 660; loss: 2.3; acc: 0.08
Batch: 680; loss: 2.29; acc: 0.14
Batch: 700; loss: 2.26; acc: 0.16
Batch: 720; loss: 2.28; acc: 0.17
Batch: 740; loss: 2.29; acc: 0.11
Batch: 760; loss: 2.28; acc: 0.14
Batch: 780; loss: 2.29; acc: 0.11
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

4.091498340130784e-06
1.9280860215076245e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2800179499729425; val_accuracy: 0.13097133757961785 

The current subspace-distance is: 1.9280860215076245e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.28; acc: 0.11
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.27; acc: 0.14
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.28; acc: 0.11
Batch: 160; loss: 2.26; acc: 0.17
Batch: 180; loss: 2.27; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.3; acc: 0.09
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.27; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.06
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.27; acc: 0.16
Batch: 360; loss: 2.26; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.08
Batch: 400; loss: 2.27; acc: 0.17
Batch: 420; loss: 2.27; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.17
Batch: 460; loss: 2.28; acc: 0.09
Batch: 480; loss: 2.27; acc: 0.12
Batch: 500; loss: 2.28; acc: 0.12
Batch: 520; loss: 2.26; acc: 0.22
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.28; acc: 0.17
Batch: 580; loss: 2.29; acc: 0.05
Batch: 600; loss: 2.28; acc: 0.03
Batch: 620; loss: 2.29; acc: 0.06
Batch: 640; loss: 2.27; acc: 0.17
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.27; acc: 0.17
Batch: 700; loss: 2.3; acc: 0.06
Batch: 720; loss: 2.26; acc: 0.11
Batch: 740; loss: 2.29; acc: 0.09
Batch: 760; loss: 2.28; acc: 0.11
Batch: 780; loss: 2.27; acc: 0.09
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.942983312299475e-06
9.024818723446515e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.2798416219699154; val_accuracy: 0.13107085987261147 

The current subspace-distance is: 9.024818723446515e-07 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.19
Batch: 40; loss: 2.29; acc: 0.17
Batch: 60; loss: 2.29; acc: 0.08
Batch: 80; loss: 2.29; acc: 0.12
Batch: 100; loss: 2.26; acc: 0.23
Batch: 120; loss: 2.27; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.12
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.28; acc: 0.16
Batch: 200; loss: 2.31; acc: 0.06
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.27; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.19
Batch: 280; loss: 2.29; acc: 0.17
Batch: 300; loss: 2.29; acc: 0.11
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.26; acc: 0.19
Batch: 360; loss: 2.27; acc: 0.22
Batch: 380; loss: 2.26; acc: 0.11
Batch: 400; loss: 2.27; acc: 0.17
Batch: 420; loss: 2.29; acc: 0.11
Batch: 440; loss: 2.28; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.28; acc: 0.19
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.29; acc: 0.19
Batch: 540; loss: 2.27; acc: 0.12
Batch: 560; loss: 2.28; acc: 0.12
Batch: 580; loss: 2.28; acc: 0.12
Batch: 600; loss: 2.28; acc: 0.17
Batch: 620; loss: 2.26; acc: 0.09
Batch: 640; loss: 2.29; acc: 0.14
Batch: 660; loss: 2.26; acc: 0.19
Batch: 680; loss: 2.28; acc: 0.11
Batch: 700; loss: 2.3; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.09
Batch: 740; loss: 2.27; acc: 0.14
Batch: 760; loss: 2.29; acc: 0.12
Batch: 780; loss: 2.29; acc: 0.05
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.5647101412905613e-06
5.844106567565177e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.12
Val Epoch over. val_loss: 2.279663357765052; val_accuracy: 0.1305732484076433 

The current subspace-distance is: 5.844106567565177e-07 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.28; acc: 0.22
Batch: 40; loss: 2.27; acc: 0.16
Batch: 60; loss: 2.31; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.2
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.28; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.06
Batch: 160; loss: 2.27; acc: 0.19
Batch: 180; loss: 2.29; acc: 0.12
Batch: 200; loss: 2.27; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.28; acc: 0.08
Batch: 260; loss: 2.26; acc: 0.17
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.28; acc: 0.11
Batch: 320; loss: 2.28; acc: 0.08
Batch: 340; loss: 2.3; acc: 0.06
Batch: 360; loss: 2.31; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.02
Batch: 400; loss: 2.28; acc: 0.08
Batch: 420; loss: 2.28; acc: 0.19
Batch: 440; loss: 2.29; acc: 0.16
Batch: 460; loss: 2.29; acc: 0.12
Batch: 480; loss: 2.27; acc: 0.16
Batch: 500; loss: 2.31; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.22
Batch: 540; loss: 2.27; acc: 0.17
Batch: 560; loss: 2.27; acc: 0.17
Batch: 580; loss: 2.29; acc: 0.14
Batch: 600; loss: 2.31; acc: 0.12
Batch: 620; loss: 2.29; acc: 0.14
Batch: 640; loss: 2.28; acc: 0.11
Batch: 660; loss: 2.31; acc: 0.05
Batch: 680; loss: 2.27; acc: 0.12
Batch: 700; loss: 2.28; acc: 0.2
Batch: 720; loss: 2.3; acc: 0.08
Batch: 740; loss: 2.29; acc: 0.12
Batch: 760; loss: 2.28; acc: 0.16
Batch: 780; loss: 2.28; acc: 0.14
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.580771817723871e-06
1.5885076436461532e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.11
Val Epoch over. val_loss: 2.279482805045547; val_accuracy: 0.1305732484076433 

The current subspace-distance is: 1.5885076436461532e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.12
Batch: 20; loss: 2.28; acc: 0.12
Batch: 40; loss: 2.29; acc: 0.05
Batch: 60; loss: 2.28; acc: 0.08
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.26; acc: 0.17
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.29; acc: 0.14
Batch: 160; loss: 2.27; acc: 0.12
Batch: 180; loss: 2.28; acc: 0.09
Batch: 200; loss: 2.27; acc: 0.16
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.29; acc: 0.06
Batch: 260; loss: 2.26; acc: 0.17
Batch: 280; loss: 2.27; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.06
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.29; acc: 0.12
Batch: 360; loss: 2.28; acc: 0.19
Batch: 380; loss: 2.31; acc: 0.06
Batch: 400; loss: 2.27; acc: 0.12
Batch: 420; loss: 2.25; acc: 0.11
Batch: 440; loss: 2.27; acc: 0.14
Batch: 460; loss: 2.31; acc: 0.09
Batch: 480; loss: 2.27; acc: 0.14
Batch: 500; loss: 2.27; acc: 0.19
Batch: 520; loss: 2.28; acc: 0.16
Batch: 540; loss: 2.27; acc: 0.23
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.3; acc: 0.12
Batch: 600; loss: 2.3; acc: 0.11
Batch: 620; loss: 2.27; acc: 0.11
Batch: 640; loss: 2.28; acc: 0.14
Batch: 660; loss: 2.3; acc: 0.05
Batch: 680; loss: 2.28; acc: 0.09
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.29; acc: 0.12
Batch: 740; loss: 2.29; acc: 0.06
Batch: 760; loss: 2.26; acc: 0.19
Batch: 780; loss: 2.28; acc: 0.14
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.4803028938767966e-06
1.6884217757251463e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.11
Val Epoch over. val_loss: 2.2793014262132583; val_accuracy: 0.1304737261146497 

The current subspace-distance is: 1.6884217757251463e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.27; acc: 0.22
Batch: 20; loss: 2.26; acc: 0.14
Batch: 40; loss: 2.3; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.08
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.28; acc: 0.19
Batch: 120; loss: 2.27; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.09
Batch: 180; loss: 2.28; acc: 0.14
Batch: 200; loss: 2.26; acc: 0.16
Batch: 220; loss: 2.28; acc: 0.19
Batch: 240; loss: 2.29; acc: 0.09
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.25; acc: 0.17
Batch: 300; loss: 2.29; acc: 0.14
Batch: 320; loss: 2.27; acc: 0.17
Batch: 340; loss: 2.28; acc: 0.16
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.29; acc: 0.17
Batch: 400; loss: 2.28; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.29; acc: 0.06
Batch: 460; loss: 2.29; acc: 0.08
Batch: 480; loss: 2.28; acc: 0.09
Batch: 500; loss: 2.28; acc: 0.08
Batch: 520; loss: 2.27; acc: 0.19
Batch: 540; loss: 2.27; acc: 0.17
Batch: 560; loss: 2.3; acc: 0.08
Batch: 580; loss: 2.29; acc: 0.11
Batch: 600; loss: 2.28; acc: 0.11
Batch: 620; loss: 2.28; acc: 0.08
Batch: 640; loss: 2.28; acc: 0.09
Batch: 660; loss: 2.27; acc: 0.12
Batch: 680; loss: 2.29; acc: 0.06
Batch: 700; loss: 2.29; acc: 0.09
Batch: 720; loss: 2.27; acc: 0.17
Batch: 740; loss: 2.28; acc: 0.08
Batch: 760; loss: 2.27; acc: 0.17
Batch: 780; loss: 2.27; acc: 0.19
Train Epoch over. train_loss: 2.28; train_accuracy: 0.13 

3.4808861073543085e-06
1.6583107935730368e-06
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.26; acc: 0.14
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.11
Val Epoch over. val_loss: 2.2791165743663813; val_accuracy: 0.129578025477707 

The current subspace-distance is: 1.6583107935730368e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.27; acc: 0.12
Batch: 40; loss: 2.28; acc: 0.08
Batch: 60; loss: 2.28; acc: 0.23
Batch: 80; loss: 2.27; acc: 0.16
Batch: 100; loss: 2.27; acc: 0.09
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.12
Batch: 180; loss: 2.27; acc: 0.14
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.16
Batch: 260; loss: 2.3; acc: 0.11
Batch: 280; loss: 2.27; acc: 0.11
Batch: 300; loss: 2.29; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.08
Batch: 340; loss: 2.27; acc: 0.17
Batch: 360; loss: 2.31; acc: 0.09
Batch: 380; loss: 2.26; acc: 0.16
Batch: 400; loss: 2.27; acc: 0.19
Batch: 420; loss: 2.3; acc: 0.06
Batch: 440; loss: 2.29; acc: 0.09
Batch: 460; loss: 2.28; acc: 0.11
Batch: 480; loss: 2.29; acc: 0.08
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.28; acc: 0.08
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.28; acc: 0.12
Batch: 580; loss: 2.27; acc: 0.16
Batch: 600; loss: 2.27; acc: 0.09
Batch: 620; loss: 2.3; acc: 0.08
Batch: 640; loss: 2.25; acc: 0.27
Batch: 660; loss: 2.27; acc: 0.17
Batch: 680; loss: 2.26; acc: 0.17
Batch: 700; loss: 2.28; acc: 0.16
Batch: 720; loss: 2.26; acc: 0.14
Batch: 740; loss: 2.28; acc: 0.19
Batch: 760; loss: 2.29; acc: 0.11
Batch: 780; loss: 2.29; acc: 0.14
Train Epoch over. train_loss: 2.28; train_accuracy: 0.12 

3.0064691145526012e-06
7.57734937906207e-07
Batch: 0; loss: 2.29; acc: 0.08
Batch: 20; loss: 2.29; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.14
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.26; acc: 0.16
Batch: 100; loss: 2.31; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.27; acc: 0.11
Val Epoch over. val_loss: 2.2789285122209293; val_accuracy: 0.1301751592356688 

The current subspace-distance is: 7.57734937906207e-07 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_10_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 5254
elements in E: 1110650
fraction nonzero: 0.004730563183721244
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.32; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.32; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.12
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.03
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.3; acc: 0.05
Batch: 480; loss: 2.3; acc: 0.11
Batch: 500; loss: 2.3; acc: 0.09
Batch: 520; loss: 2.31; acc: 0.11
Batch: 540; loss: 2.3; acc: 0.09
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.17
Batch: 600; loss: 2.29; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.06
Batch: 640; loss: 2.3; acc: 0.06
Batch: 660; loss: 2.31; acc: 0.06
Batch: 680; loss: 2.28; acc: 0.17
Batch: 700; loss: 2.29; acc: 0.12
Batch: 720; loss: 2.3; acc: 0.12
Batch: 740; loss: 2.32; acc: 0.08
Batch: 760; loss: 2.31; acc: 0.09
Batch: 780; loss: 2.3; acc: 0.17
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

1.9918838916055392e-06
2.295590917356094e-07
Batch: 0; loss: 2.3; acc: 0.17
Batch: 20; loss: 2.3; acc: 0.16
Batch: 40; loss: 2.3; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.12
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.3; acc: 0.12
Val Epoch over. val_loss: 2.300754439299274; val_accuracy: 0.11106687898089172 

The current subspace-distance is: 2.295590917356094e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.31; acc: 0.12
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.05
Batch: 160; loss: 2.31; acc: 0.11
Batch: 180; loss: 2.3; acc: 0.17
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.16
Batch: 300; loss: 2.3; acc: 0.11
Batch: 320; loss: 2.3; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.14
Batch: 360; loss: 2.29; acc: 0.17
Batch: 380; loss: 2.29; acc: 0.19
Batch: 400; loss: 2.29; acc: 0.12
Batch: 420; loss: 2.29; acc: 0.16
Batch: 440; loss: 2.29; acc: 0.14
Batch: 460; loss: 2.29; acc: 0.2
Batch: 480; loss: 2.29; acc: 0.22
Batch: 500; loss: 2.3; acc: 0.12
Batch: 520; loss: 2.31; acc: 0.11
Batch: 540; loss: 2.29; acc: 0.22
Batch: 560; loss: 2.31; acc: 0.17
Batch: 580; loss: 2.29; acc: 0.16
Batch: 600; loss: 2.3; acc: 0.19
Batch: 620; loss: 2.3; acc: 0.16
Batch: 640; loss: 2.29; acc: 0.16
Batch: 660; loss: 2.29; acc: 0.17
Batch: 680; loss: 2.29; acc: 0.17
Batch: 700; loss: 2.31; acc: 0.12
Batch: 720; loss: 2.28; acc: 0.28
Batch: 740; loss: 2.3; acc: 0.09
Batch: 760; loss: 2.29; acc: 0.2
Batch: 780; loss: 2.3; acc: 0.12
Train Epoch over. train_loss: 2.3; train_accuracy: 0.13 

2.47762955041253e-06
8.638044164399616e-07
Batch: 0; loss: 2.29; acc: 0.23
Batch: 20; loss: 2.3; acc: 0.19
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.28; acc: 0.2
Batch: 100; loss: 2.3; acc: 0.14
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.29; acc: 0.17
Val Epoch over. val_loss: 2.2968839915694703; val_accuracy: 0.15416003184713375 

The current subspace-distance is: 8.638044164399616e-07 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.16
Batch: 20; loss: 2.29; acc: 0.11
Batch: 40; loss: 2.29; acc: 0.19
Batch: 60; loss: 2.3; acc: 0.06
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.19
Batch: 120; loss: 2.3; acc: 0.17
Batch: 140; loss: 2.3; acc: 0.14
Batch: 160; loss: 2.3; acc: 0.19
Batch: 180; loss: 2.29; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.09
Batch: 220; loss: 2.29; acc: 0.17
Batch: 240; loss: 2.29; acc: 0.19
Batch: 260; loss: 2.3; acc: 0.16
Batch: 280; loss: 2.29; acc: 0.14
Batch: 300; loss: 2.29; acc: 0.19
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.28; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.14
Batch: 380; loss: 2.29; acc: 0.23
Batch: 400; loss: 2.29; acc: 0.2
Batch: 420; loss: 2.3; acc: 0.11
Batch: 440; loss: 2.29; acc: 0.11
Batch: 460; loss: 2.3; acc: 0.19
Batch: 480; loss: 2.29; acc: 0.19
Batch: 500; loss: 2.28; acc: 0.2
Batch: 520; loss: 2.28; acc: 0.14
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.16
Batch: 580; loss: 2.28; acc: 0.23
Batch: 600; loss: 2.28; acc: 0.17
Batch: 620; loss: 2.29; acc: 0.22
Batch: 640; loss: 2.3; acc: 0.16
Batch: 660; loss: 2.29; acc: 0.14
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.28; acc: 0.31
Batch: 740; loss: 2.29; acc: 0.16
Batch: 760; loss: 2.3; acc: 0.12
Batch: 780; loss: 2.29; acc: 0.19
Train Epoch over. train_loss: 2.29; train_accuracy: 0.17 

3.728650426637614e-06
1.066249978975975e-06
Batch: 0; loss: 2.29; acc: 0.2
Batch: 20; loss: 2.29; acc: 0.23
Batch: 40; loss: 2.28; acc: 0.22
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.25
Batch: 100; loss: 2.29; acc: 0.17
Batch: 120; loss: 2.28; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.27
Val Epoch over. val_loss: 2.2864705711413342; val_accuracy: 0.192078025477707 

The current subspace-distance is: 1.066249978975975e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.22
Batch: 20; loss: 2.3; acc: 0.25
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.29; acc: 0.25
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.29; acc: 0.2
Batch: 120; loss: 2.27; acc: 0.28
Batch: 140; loss: 2.27; acc: 0.23
Batch: 160; loss: 2.26; acc: 0.27
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.29; acc: 0.14
Batch: 220; loss: 2.29; acc: 0.17
Batch: 240; loss: 2.29; acc: 0.11
Batch: 260; loss: 2.28; acc: 0.22
Batch: 280; loss: 2.26; acc: 0.31
Batch: 300; loss: 2.28; acc: 0.14
Batch: 320; loss: 2.26; acc: 0.33
Batch: 340; loss: 2.31; acc: 0.17
Batch: 360; loss: 2.28; acc: 0.17
Batch: 380; loss: 2.28; acc: 0.16
Batch: 400; loss: 2.26; acc: 0.22
Batch: 420; loss: 2.25; acc: 0.3
Batch: 440; loss: 2.27; acc: 0.16
Batch: 460; loss: 2.28; acc: 0.19
Batch: 480; loss: 2.28; acc: 0.23
Batch: 500; loss: 2.28; acc: 0.14
Batch: 520; loss: 2.29; acc: 0.16
Batch: 540; loss: 2.26; acc: 0.25
Batch: 560; loss: 2.27; acc: 0.14
Batch: 580; loss: 2.26; acc: 0.25
Batch: 600; loss: 2.27; acc: 0.17
Batch: 620; loss: 2.27; acc: 0.23
Batch: 640; loss: 2.28; acc: 0.14
Batch: 660; loss: 2.28; acc: 0.16
Batch: 680; loss: 2.27; acc: 0.22
Batch: 700; loss: 2.27; acc: 0.19
Batch: 720; loss: 2.26; acc: 0.3
Batch: 740; loss: 2.25; acc: 0.23
Batch: 760; loss: 2.26; acc: 0.28
Batch: 780; loss: 2.25; acc: 0.25
Train Epoch over. train_loss: 2.28; train_accuracy: 0.2 

6.670165021205321e-06
1.8510662584958482e-06
Batch: 0; loss: 2.27; acc: 0.17
Batch: 20; loss: 2.25; acc: 0.2
Batch: 40; loss: 2.26; acc: 0.17
Batch: 60; loss: 2.26; acc: 0.23
Batch: 80; loss: 2.25; acc: 0.27
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.26; acc: 0.22
Batch: 140; loss: 2.25; acc: 0.25
Val Epoch over. val_loss: 2.2639275963898675; val_accuracy: 0.22253184713375795 

The current subspace-distance is: 1.8510662584958482e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.24; acc: 0.28
Batch: 20; loss: 2.27; acc: 0.17
Batch: 40; loss: 2.25; acc: 0.19
Batch: 60; loss: 2.25; acc: 0.22
Batch: 80; loss: 2.25; acc: 0.28
Batch: 100; loss: 2.28; acc: 0.19
Batch: 120; loss: 2.24; acc: 0.19
Batch: 140; loss: 2.28; acc: 0.22
Batch: 160; loss: 2.25; acc: 0.28
Batch: 180; loss: 2.25; acc: 0.2
Batch: 200; loss: 2.22; acc: 0.19
Batch: 220; loss: 2.24; acc: 0.31
Batch: 240; loss: 2.25; acc: 0.28
Batch: 260; loss: 2.25; acc: 0.27
Batch: 280; loss: 2.23; acc: 0.28
Batch: 300; loss: 2.23; acc: 0.19
Batch: 320; loss: 2.24; acc: 0.27
Batch: 340; loss: 2.25; acc: 0.2
Batch: 360; loss: 2.22; acc: 0.27
Batch: 380; loss: 2.25; acc: 0.17
Batch: 400; loss: 2.24; acc: 0.12
Batch: 420; loss: 2.23; acc: 0.22
Batch: 440; loss: 2.24; acc: 0.2
Batch: 460; loss: 2.22; acc: 0.16
Batch: 480; loss: 2.23; acc: 0.17
Batch: 500; loss: 2.21; acc: 0.19
Batch: 520; loss: 2.2; acc: 0.19
Batch: 540; loss: 2.19; acc: 0.3
Batch: 560; loss: 2.18; acc: 0.23
Batch: 580; loss: 2.22; acc: 0.17
Batch: 600; loss: 2.14; acc: 0.25
Batch: 620; loss: 2.2; acc: 0.19
Batch: 640; loss: 2.21; acc: 0.25
Batch: 660; loss: 2.14; acc: 0.25
Batch: 680; loss: 2.19; acc: 0.14
Batch: 700; loss: 2.18; acc: 0.19
Batch: 720; loss: 2.14; acc: 0.23
Batch: 740; loss: 2.15; acc: 0.28
Batch: 760; loss: 2.11; acc: 0.25
Batch: 780; loss: 2.14; acc: 0.22
Train Epoch over. train_loss: 2.22; train_accuracy: 0.22 

6.940038929315051e-06
3.0406399673665874e-06
Batch: 0; loss: 2.18; acc: 0.28
Batch: 20; loss: 2.15; acc: 0.2
Batch: 40; loss: 2.16; acc: 0.3
Batch: 60; loss: 2.15; acc: 0.25
Batch: 80; loss: 2.13; acc: 0.25
Batch: 100; loss: 2.12; acc: 0.25
Batch: 120; loss: 2.15; acc: 0.25
Batch: 140; loss: 2.1; acc: 0.31
Val Epoch over. val_loss: 2.1543972795935953; val_accuracy: 0.23915207006369427 

The current subspace-distance is: 3.0406399673665874e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.13; acc: 0.28
Batch: 20; loss: 2.2; acc: 0.16
Batch: 40; loss: 2.14; acc: 0.27
Batch: 60; loss: 2.14; acc: 0.23
Batch: 80; loss: 2.17; acc: 0.25
Batch: 100; loss: 2.06; acc: 0.3
Batch: 120; loss: 2.13; acc: 0.27
Batch: 140; loss: 2.16; acc: 0.28
Batch: 160; loss: 2.17; acc: 0.25
Batch: 180; loss: 2.11; acc: 0.27
Batch: 200; loss: 2.15; acc: 0.27
Batch: 220; loss: 2.03; acc: 0.33
Batch: 240; loss: 2.06; acc: 0.3
Batch: 260; loss: 2.08; acc: 0.31
Batch: 280; loss: 2.14; acc: 0.2
Batch: 300; loss: 2.12; acc: 0.17
Batch: 320; loss: 2.05; acc: 0.27
Batch: 340; loss: 2.04; acc: 0.28
Batch: 360; loss: 2.0; acc: 0.3
Batch: 380; loss: 2.0; acc: 0.3
Batch: 400; loss: 2.03; acc: 0.28
Batch: 420; loss: 2.12; acc: 0.2
Batch: 440; loss: 1.95; acc: 0.34
Batch: 460; loss: 2.1; acc: 0.19
Batch: 480; loss: 2.1; acc: 0.23
Batch: 500; loss: 2.14; acc: 0.25
Batch: 520; loss: 1.89; acc: 0.28
Batch: 540; loss: 2.04; acc: 0.28
Batch: 560; loss: 1.96; acc: 0.23
Batch: 580; loss: 1.96; acc: 0.31
Batch: 600; loss: 2.05; acc: 0.31
Batch: 620; loss: 1.86; acc: 0.39
Batch: 640; loss: 2.08; acc: 0.17
Batch: 660; loss: 2.02; acc: 0.27
Batch: 680; loss: 1.94; acc: 0.31
Batch: 700; loss: 2.04; acc: 0.23
Batch: 720; loss: 1.85; acc: 0.39
Batch: 740; loss: 2.05; acc: 0.33
Batch: 760; loss: 1.99; acc: 0.23
Batch: 780; loss: 1.94; acc: 0.34
Train Epoch over. train_loss: 2.05; train_accuracy: 0.27 

1.0193789421464317e-05
3.858154741465114e-06
Batch: 0; loss: 2.06; acc: 0.31
Batch: 20; loss: 1.92; acc: 0.31
Batch: 40; loss: 1.86; acc: 0.41
Batch: 60; loss: 1.98; acc: 0.42
Batch: 80; loss: 1.92; acc: 0.39
Batch: 100; loss: 1.89; acc: 0.31
Batch: 120; loss: 1.9; acc: 0.28
Batch: 140; loss: 1.79; acc: 0.44
Val Epoch over. val_loss: 1.9476930328235504; val_accuracy: 0.31677945859872614 

The current subspace-distance is: 3.858154741465114e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.04; acc: 0.23
Batch: 20; loss: 1.98; acc: 0.3
Batch: 40; loss: 1.88; acc: 0.33
Batch: 60; loss: 2.03; acc: 0.27
Batch: 80; loss: 2.0; acc: 0.23
Batch: 100; loss: 1.96; acc: 0.33
Batch: 120; loss: 2.07; acc: 0.3
Batch: 140; loss: 1.86; acc: 0.31
Batch: 160; loss: 1.83; acc: 0.47
Batch: 180; loss: 1.95; acc: 0.3
Batch: 200; loss: 1.92; acc: 0.36
Batch: 220; loss: 1.91; acc: 0.38
Batch: 240; loss: 2.0; acc: 0.28
Batch: 260; loss: 1.83; acc: 0.45
Batch: 280; loss: 2.06; acc: 0.33
Batch: 300; loss: 1.93; acc: 0.38
Batch: 320; loss: 2.09; acc: 0.27
Batch: 340; loss: 1.96; acc: 0.39
Batch: 360; loss: 2.05; acc: 0.3
Batch: 380; loss: 2.09; acc: 0.27
Batch: 400; loss: 1.88; acc: 0.34
Batch: 420; loss: 2.03; acc: 0.31
Batch: 440; loss: 1.81; acc: 0.36
Batch: 460; loss: 1.91; acc: 0.28
Batch: 480; loss: 1.84; acc: 0.44
Batch: 500; loss: 1.91; acc: 0.23
Batch: 520; loss: 1.99; acc: 0.39
Batch: 540; loss: 2.05; acc: 0.27
Batch: 560; loss: 1.9; acc: 0.44
Batch: 580; loss: 1.96; acc: 0.31
Batch: 600; loss: 1.91; acc: 0.41
Batch: 620; loss: 1.82; acc: 0.34
Batch: 640; loss: 1.74; acc: 0.41
Batch: 660; loss: 1.85; acc: 0.33
Batch: 680; loss: 1.92; acc: 0.31
Batch: 700; loss: 1.78; acc: 0.39
Batch: 720; loss: 2.08; acc: 0.25
Batch: 740; loss: 2.12; acc: 0.23
Batch: 760; loss: 1.99; acc: 0.23
Batch: 780; loss: 1.94; acc: 0.28
Train Epoch over. train_loss: 1.94; train_accuracy: 0.34 

1.0725720130722038e-05
4.014527803519741e-06
Batch: 0; loss: 2.04; acc: 0.34
Batch: 20; loss: 1.87; acc: 0.39
Batch: 40; loss: 1.72; acc: 0.45
Batch: 60; loss: 1.88; acc: 0.39
Batch: 80; loss: 1.82; acc: 0.38
Batch: 100; loss: 1.79; acc: 0.41
Batch: 120; loss: 1.88; acc: 0.33
Batch: 140; loss: 1.71; acc: 0.47
Val Epoch over. val_loss: 1.8961914458851905; val_accuracy: 0.365843949044586 

The current subspace-distance is: 4.014527803519741e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.99; acc: 0.33
Batch: 20; loss: 1.95; acc: 0.3
Batch: 40; loss: 1.88; acc: 0.34
Batch: 60; loss: 2.1; acc: 0.27
Batch: 80; loss: 2.11; acc: 0.33
Batch: 100; loss: 2.08; acc: 0.34
Batch: 120; loss: 1.91; acc: 0.33
Batch: 140; loss: 2.02; acc: 0.3
Batch: 160; loss: 1.89; acc: 0.38
Batch: 180; loss: 1.85; acc: 0.34
Batch: 200; loss: 1.97; acc: 0.28
Batch: 220; loss: 1.83; acc: 0.38
Batch: 240; loss: 1.95; acc: 0.41
Batch: 260; loss: 1.98; acc: 0.33
Batch: 280; loss: 1.86; acc: 0.38
Batch: 300; loss: 1.79; acc: 0.39
Batch: 320; loss: 1.84; acc: 0.38
Batch: 340; loss: 1.79; acc: 0.39
Batch: 360; loss: 2.08; acc: 0.3
Batch: 380; loss: 2.14; acc: 0.27
Batch: 400; loss: 1.64; acc: 0.47
Batch: 420; loss: 1.96; acc: 0.28
Batch: 440; loss: 1.86; acc: 0.44
Batch: 460; loss: 1.85; acc: 0.33
Batch: 480; loss: 1.7; acc: 0.52
Batch: 500; loss: 1.91; acc: 0.38
Batch: 520; loss: 2.03; acc: 0.33
Batch: 540; loss: 1.82; acc: 0.36
Batch: 560; loss: 1.95; acc: 0.36
Batch: 580; loss: 1.93; acc: 0.31
Batch: 600; loss: 1.97; acc: 0.25
Batch: 620; loss: 1.94; acc: 0.3
Batch: 640; loss: 1.81; acc: 0.45
Batch: 660; loss: 1.81; acc: 0.39
Batch: 680; loss: 2.11; acc: 0.28
Batch: 700; loss: 1.82; acc: 0.36
Batch: 720; loss: 1.91; acc: 0.36
Batch: 740; loss: 1.89; acc: 0.38
Batch: 760; loss: 2.05; acc: 0.36
Batch: 780; loss: 1.86; acc: 0.39
Train Epoch over. train_loss: 1.91; train_accuracy: 0.35 

9.141419468505774e-06
4.484918463276699e-06
Batch: 0; loss: 2.02; acc: 0.36
Batch: 20; loss: 1.94; acc: 0.33
Batch: 40; loss: 1.66; acc: 0.47
Batch: 60; loss: 1.85; acc: 0.38
Batch: 80; loss: 1.77; acc: 0.47
Batch: 100; loss: 1.81; acc: 0.33
Batch: 120; loss: 1.86; acc: 0.36
Batch: 140; loss: 1.71; acc: 0.41
Val Epoch over. val_loss: 1.883778878078339; val_accuracy: 0.36494824840764334 

The current subspace-distance is: 4.484918463276699e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.84; acc: 0.42
Batch: 20; loss: 2.04; acc: 0.25
Batch: 40; loss: 1.81; acc: 0.33
Batch: 60; loss: 1.83; acc: 0.31
Batch: 80; loss: 1.87; acc: 0.27
Batch: 100; loss: 1.73; acc: 0.47
Batch: 120; loss: 1.85; acc: 0.42
Batch: 140; loss: 1.79; acc: 0.44
Batch: 160; loss: 1.78; acc: 0.42
Batch: 180; loss: 1.85; acc: 0.44
Batch: 200; loss: 1.79; acc: 0.42
Batch: 220; loss: 1.89; acc: 0.34
Batch: 240; loss: 1.8; acc: 0.39
Batch: 260; loss: 1.98; acc: 0.3
Batch: 280; loss: 1.89; acc: 0.31
Batch: 300; loss: 1.91; acc: 0.33
Batch: 320; loss: 2.01; acc: 0.3
Batch: 340; loss: 1.73; acc: 0.44
Batch: 360; loss: 1.81; acc: 0.47
Batch: 380; loss: 1.83; acc: 0.34
Batch: 400; loss: 1.82; acc: 0.44
Batch: 420; loss: 1.96; acc: 0.36
Batch: 440; loss: 1.8; acc: 0.39
Batch: 460; loss: 2.06; acc: 0.34
Batch: 480; loss: 2.12; acc: 0.25
Batch: 500; loss: 1.83; acc: 0.38
Batch: 520; loss: 1.85; acc: 0.36
Batch: 540; loss: 1.99; acc: 0.38
Batch: 560; loss: 1.85; acc: 0.41
Batch: 580; loss: 2.01; acc: 0.28
Batch: 600; loss: 2.07; acc: 0.31
Batch: 620; loss: 1.84; acc: 0.38
Batch: 640; loss: 1.91; acc: 0.44
Batch: 660; loss: 1.71; acc: 0.39
Batch: 680; loss: 1.79; acc: 0.39
Batch: 700; loss: 1.95; acc: 0.28
Batch: 720; loss: 1.78; acc: 0.38
Batch: 740; loss: 1.9; acc: 0.33
Batch: 760; loss: 2.05; acc: 0.28
Batch: 780; loss: 1.82; acc: 0.34
Train Epoch over. train_loss: 1.88; train_accuracy: 0.36 

9.747413969307672e-06
4.253611223248299e-06
Batch: 0; loss: 1.92; acc: 0.36
Batch: 20; loss: 1.96; acc: 0.27
Batch: 40; loss: 1.63; acc: 0.47
Batch: 60; loss: 1.78; acc: 0.38
Batch: 80; loss: 1.62; acc: 0.5
Batch: 100; loss: 1.82; acc: 0.33
Batch: 120; loss: 1.82; acc: 0.41
Batch: 140; loss: 1.78; acc: 0.34
Val Epoch over. val_loss: 1.8399684892338553; val_accuracy: 0.366640127388535 

The current subspace-distance is: 4.253611223248299e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.96; acc: 0.25
Batch: 20; loss: 1.92; acc: 0.45
Batch: 40; loss: 1.74; acc: 0.44
Batch: 60; loss: 1.95; acc: 0.25
Batch: 80; loss: 1.89; acc: 0.27
Batch: 100; loss: 1.79; acc: 0.38
Batch: 120; loss: 1.96; acc: 0.34
Batch: 140; loss: 1.95; acc: 0.3
Batch: 160; loss: 1.82; acc: 0.36
Batch: 180; loss: 2.0; acc: 0.3
Batch: 200; loss: 1.92; acc: 0.27
Batch: 220; loss: 1.93; acc: 0.27
Batch: 240; loss: 1.74; acc: 0.41
Batch: 260; loss: 1.7; acc: 0.42
Batch: 280; loss: 1.87; acc: 0.31
Batch: 300; loss: 1.72; acc: 0.41
Batch: 320; loss: 1.86; acc: 0.41
Batch: 340; loss: 1.81; acc: 0.39
Batch: 360; loss: 1.81; acc: 0.36
Batch: 380; loss: 1.92; acc: 0.25
Batch: 400; loss: 1.8; acc: 0.33
Batch: 420; loss: 1.59; acc: 0.5
Batch: 440; loss: 1.89; acc: 0.36
Batch: 460; loss: 1.88; acc: 0.33
Batch: 480; loss: 1.91; acc: 0.33
Batch: 500; loss: 1.88; acc: 0.39
Batch: 520; loss: 1.89; acc: 0.36
Batch: 540; loss: 1.78; acc: 0.42
Batch: 560; loss: 1.77; acc: 0.34
Batch: 580; loss: 1.93; acc: 0.3
Batch: 600; loss: 1.99; acc: 0.36
Batch: 620; loss: 1.9; acc: 0.31
Batch: 640; loss: 1.86; acc: 0.34
Batch: 660; loss: 1.6; acc: 0.48
Batch: 680; loss: 1.9; acc: 0.39
Batch: 700; loss: 1.91; acc: 0.36
Batch: 720; loss: 1.8; acc: 0.36
Batch: 740; loss: 1.87; acc: 0.38
Batch: 760; loss: 1.85; acc: 0.33
Batch: 780; loss: 2.04; acc: 0.2
Train Epoch over. train_loss: 1.86; train_accuracy: 0.36 

9.049181244336069e-06
4.6448894863715395e-06
Batch: 0; loss: 1.95; acc: 0.3
Batch: 20; loss: 1.99; acc: 0.25
Batch: 40; loss: 1.64; acc: 0.42
Batch: 60; loss: 1.75; acc: 0.42
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.91; acc: 0.25
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.78; acc: 0.39
Val Epoch over. val_loss: 1.8332754836720266; val_accuracy: 0.3560907643312102 

The current subspace-distance is: 4.6448894863715395e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 2.01; acc: 0.25
Batch: 20; loss: 1.8; acc: 0.3
Batch: 40; loss: 1.98; acc: 0.3
Batch: 60; loss: 1.81; acc: 0.42
Batch: 80; loss: 1.92; acc: 0.31
Batch: 100; loss: 1.61; acc: 0.53
Batch: 120; loss: 1.88; acc: 0.36
Batch: 140; loss: 2.06; acc: 0.31
Batch: 160; loss: 1.86; acc: 0.36
Batch: 180; loss: 1.82; acc: 0.33
Batch: 200; loss: 1.81; acc: 0.36
Batch: 220; loss: 1.79; acc: 0.39
Batch: 240; loss: 1.7; acc: 0.36
Batch: 260; loss: 1.82; acc: 0.33
Batch: 280; loss: 1.87; acc: 0.3
Batch: 300; loss: 1.7; acc: 0.47
Batch: 320; loss: 2.05; acc: 0.23
Batch: 340; loss: 1.82; acc: 0.27
Batch: 360; loss: 2.11; acc: 0.27
Batch: 380; loss: 1.87; acc: 0.3
Batch: 400; loss: 1.89; acc: 0.33
Batch: 420; loss: 1.92; acc: 0.31
Batch: 440; loss: 1.91; acc: 0.33
Batch: 460; loss: 1.75; acc: 0.39
Batch: 480; loss: 1.88; acc: 0.28
Batch: 500; loss: 1.85; acc: 0.27
Batch: 520; loss: 1.83; acc: 0.33
Batch: 540; loss: 1.77; acc: 0.34
Batch: 560; loss: 2.02; acc: 0.23
Batch: 580; loss: 1.79; acc: 0.44
Batch: 600; loss: 1.81; acc: 0.33
Batch: 620; loss: 1.88; acc: 0.39
Batch: 640; loss: 1.77; acc: 0.42
Batch: 660; loss: 1.8; acc: 0.31
Batch: 680; loss: 1.81; acc: 0.34
Batch: 700; loss: 1.82; acc: 0.31
Batch: 720; loss: 1.66; acc: 0.44
Batch: 740; loss: 1.82; acc: 0.45
Batch: 760; loss: 1.99; acc: 0.27
Batch: 780; loss: 1.81; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1036051546398085e-05
4.036010068375617e-06
Batch: 0; loss: 1.94; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.23
Batch: 40; loss: 1.63; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.31
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.78; acc: 0.38
Val Epoch over. val_loss: 1.8312555961548143; val_accuracy: 0.3564888535031847 

The current subspace-distance is: 4.036010068375617e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.77; acc: 0.41
Batch: 20; loss: 1.66; acc: 0.44
Batch: 40; loss: 1.81; acc: 0.33
Batch: 60; loss: 1.77; acc: 0.3
Batch: 80; loss: 1.85; acc: 0.31
Batch: 100; loss: 1.83; acc: 0.36
Batch: 120; loss: 2.03; acc: 0.28
Batch: 140; loss: 1.95; acc: 0.36
Batch: 160; loss: 2.08; acc: 0.27
Batch: 180; loss: 1.9; acc: 0.34
Batch: 200; loss: 1.89; acc: 0.33
Batch: 220; loss: 2.0; acc: 0.25
Batch: 240; loss: 1.73; acc: 0.52
Batch: 260; loss: 1.84; acc: 0.31
Batch: 280; loss: 1.76; acc: 0.38
Batch: 300; loss: 1.73; acc: 0.41
Batch: 320; loss: 1.9; acc: 0.28
Batch: 340; loss: 1.81; acc: 0.38
Batch: 360; loss: 1.71; acc: 0.42
Batch: 380; loss: 1.77; acc: 0.36
Batch: 400; loss: 1.85; acc: 0.34
Batch: 420; loss: 1.76; acc: 0.42
Batch: 440; loss: 1.89; acc: 0.36
Batch: 460; loss: 1.97; acc: 0.34
Batch: 480; loss: 1.88; acc: 0.34
Batch: 500; loss: 1.77; acc: 0.45
Batch: 520; loss: 1.75; acc: 0.44
Batch: 540; loss: 1.92; acc: 0.36
Batch: 560; loss: 1.8; acc: 0.39
Batch: 580; loss: 1.81; acc: 0.36
Batch: 600; loss: 1.89; acc: 0.38
Batch: 620; loss: 1.87; acc: 0.3
Batch: 640; loss: 1.76; acc: 0.42
Batch: 660; loss: 2.04; acc: 0.33
Batch: 680; loss: 1.89; acc: 0.27
Batch: 700; loss: 1.79; acc: 0.34
Batch: 720; loss: 1.98; acc: 0.34
Batch: 740; loss: 1.82; acc: 0.3
Batch: 760; loss: 1.71; acc: 0.5
Batch: 780; loss: 1.9; acc: 0.31
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0849375939869788e-05
4.693949449574575e-06
Batch: 0; loss: 1.95; acc: 0.31
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.55; acc: 0.47
Batch: 100; loss: 1.89; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.36
Val Epoch over. val_loss: 1.8306591708189364; val_accuracy: 0.35977308917197454 

The current subspace-distance is: 4.693949449574575e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 1.93; acc: 0.31
Batch: 40; loss: 2.06; acc: 0.28
Batch: 60; loss: 1.86; acc: 0.36
Batch: 80; loss: 2.02; acc: 0.3
Batch: 100; loss: 1.87; acc: 0.28
Batch: 120; loss: 1.91; acc: 0.41
Batch: 140; loss: 1.92; acc: 0.33
Batch: 160; loss: 1.91; acc: 0.3
Batch: 180; loss: 1.94; acc: 0.27
Batch: 200; loss: 1.77; acc: 0.38
Batch: 220; loss: 1.71; acc: 0.44
Batch: 240; loss: 1.89; acc: 0.31
Batch: 260; loss: 1.86; acc: 0.36
Batch: 280; loss: 1.82; acc: 0.39
Batch: 300; loss: 1.82; acc: 0.38
Batch: 320; loss: 1.96; acc: 0.34
Batch: 340; loss: 1.78; acc: 0.39
Batch: 360; loss: 1.86; acc: 0.3
Batch: 380; loss: 1.88; acc: 0.39
Batch: 400; loss: 1.96; acc: 0.33
Batch: 420; loss: 1.91; acc: 0.31
Batch: 440; loss: 1.79; acc: 0.34
Batch: 460; loss: 1.78; acc: 0.41
Batch: 480; loss: 1.71; acc: 0.5
Batch: 500; loss: 1.75; acc: 0.45
Batch: 520; loss: 1.71; acc: 0.33
Batch: 540; loss: 1.59; acc: 0.45
Batch: 560; loss: 1.8; acc: 0.41
Batch: 580; loss: 1.86; acc: 0.38
Batch: 600; loss: 2.0; acc: 0.22
Batch: 620; loss: 1.78; acc: 0.47
Batch: 640; loss: 1.88; acc: 0.42
Batch: 660; loss: 1.88; acc: 0.34
Batch: 680; loss: 1.81; acc: 0.33
Batch: 700; loss: 1.93; acc: 0.3
Batch: 720; loss: 1.82; acc: 0.36
Batch: 740; loss: 1.79; acc: 0.41
Batch: 760; loss: 1.8; acc: 0.36
Batch: 780; loss: 1.95; acc: 0.38
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.2999389582546428e-05
4.36589471064508e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.97; acc: 0.22
Batch: 40; loss: 1.63; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.55; acc: 0.47
Batch: 100; loss: 1.89; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.36
Val Epoch over. val_loss: 1.8306657797212054; val_accuracy: 0.3616640127388535 

The current subspace-distance is: 4.36589471064508e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.91; acc: 0.28
Batch: 20; loss: 1.83; acc: 0.45
Batch: 40; loss: 1.95; acc: 0.27
Batch: 60; loss: 1.97; acc: 0.34
Batch: 80; loss: 1.91; acc: 0.38
Batch: 100; loss: 1.97; acc: 0.31
Batch: 120; loss: 1.83; acc: 0.31
Batch: 140; loss: 1.72; acc: 0.44
Batch: 160; loss: 1.88; acc: 0.3
Batch: 180; loss: 1.99; acc: 0.28
Batch: 200; loss: 1.78; acc: 0.41
Batch: 220; loss: 1.83; acc: 0.47
Batch: 240; loss: 2.0; acc: 0.27
Batch: 260; loss: 1.9; acc: 0.33
Batch: 280; loss: 1.98; acc: 0.22
Batch: 300; loss: 1.95; acc: 0.3
Batch: 320; loss: 1.89; acc: 0.38
Batch: 340; loss: 1.88; acc: 0.31
Batch: 360; loss: 1.92; acc: 0.31
Batch: 380; loss: 1.87; acc: 0.33
Batch: 400; loss: 1.77; acc: 0.42
Batch: 420; loss: 1.86; acc: 0.3
Batch: 440; loss: 1.84; acc: 0.34
Batch: 460; loss: 1.94; acc: 0.28
Batch: 480; loss: 1.88; acc: 0.38
Batch: 500; loss: 1.8; acc: 0.39
Batch: 520; loss: 2.03; acc: 0.31
Batch: 540; loss: 1.78; acc: 0.36
Batch: 560; loss: 1.7; acc: 0.47
Batch: 580; loss: 1.82; acc: 0.34
Batch: 600; loss: 1.81; acc: 0.38
Batch: 620; loss: 1.81; acc: 0.41
Batch: 640; loss: 1.79; acc: 0.41
Batch: 660; loss: 1.97; acc: 0.33
Batch: 680; loss: 1.74; acc: 0.44
Batch: 700; loss: 1.92; acc: 0.28
Batch: 720; loss: 1.71; acc: 0.44
Batch: 740; loss: 1.67; acc: 0.42
Batch: 760; loss: 1.94; acc: 0.25
Batch: 780; loss: 1.83; acc: 0.38
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.198904081131332e-06
5.584614427789347e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.2
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.89; acc: 0.27
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.34
Val Epoch over. val_loss: 1.8298920780230479; val_accuracy: 0.3583797770700637 

The current subspace-distance is: 5.584614427789347e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 1.84; acc: 0.38
Batch: 40; loss: 1.78; acc: 0.33
Batch: 60; loss: 1.98; acc: 0.3
Batch: 80; loss: 1.92; acc: 0.3
Batch: 100; loss: 1.78; acc: 0.39
Batch: 120; loss: 1.85; acc: 0.3
Batch: 140; loss: 1.74; acc: 0.52
Batch: 160; loss: 1.89; acc: 0.36
Batch: 180; loss: 1.78; acc: 0.42
Batch: 200; loss: 1.9; acc: 0.33
Batch: 220; loss: 2.0; acc: 0.25
Batch: 240; loss: 1.93; acc: 0.39
Batch: 260; loss: 1.76; acc: 0.39
Batch: 280; loss: 1.73; acc: 0.42
Batch: 300; loss: 1.68; acc: 0.39
Batch: 320; loss: 1.92; acc: 0.38
Batch: 340; loss: 1.75; acc: 0.39
Batch: 360; loss: 1.86; acc: 0.39
Batch: 380; loss: 1.78; acc: 0.33
Batch: 400; loss: 1.85; acc: 0.33
Batch: 420; loss: 1.58; acc: 0.45
Batch: 440; loss: 1.93; acc: 0.34
Batch: 460; loss: 1.85; acc: 0.38
Batch: 480; loss: 1.89; acc: 0.36
Batch: 500; loss: 1.72; acc: 0.45
Batch: 520; loss: 1.74; acc: 0.38
Batch: 540; loss: 1.83; acc: 0.41
Batch: 560; loss: 1.89; acc: 0.38
Batch: 580; loss: 1.85; acc: 0.36
Batch: 600; loss: 1.92; acc: 0.31
Batch: 620; loss: 1.82; acc: 0.36
Batch: 640; loss: 1.99; acc: 0.33
Batch: 660; loss: 1.94; acc: 0.38
Batch: 680; loss: 1.87; acc: 0.31
Batch: 700; loss: 1.84; acc: 0.36
Batch: 720; loss: 2.0; acc: 0.25
Batch: 740; loss: 1.85; acc: 0.42
Batch: 760; loss: 1.74; acc: 0.39
Batch: 780; loss: 2.07; acc: 0.23
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0867965102079324e-05
4.5701863200520165e-06
Batch: 0; loss: 1.95; acc: 0.31
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.89; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.34
Val Epoch over. val_loss: 1.8314288771076568; val_accuracy: 0.35897691082802546 

The current subspace-distance is: 4.5701863200520165e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.71; acc: 0.36
Batch: 20; loss: 1.62; acc: 0.45
Batch: 40; loss: 1.99; acc: 0.31
Batch: 60; loss: 1.62; acc: 0.47
Batch: 80; loss: 1.87; acc: 0.31
Batch: 100; loss: 1.86; acc: 0.33
Batch: 120; loss: 1.8; acc: 0.44
Batch: 140; loss: 1.94; acc: 0.3
Batch: 160; loss: 1.77; acc: 0.38
Batch: 180; loss: 1.94; acc: 0.28
Batch: 200; loss: 1.97; acc: 0.3
Batch: 220; loss: 1.87; acc: 0.33
Batch: 240; loss: 1.79; acc: 0.38
Batch: 260; loss: 1.89; acc: 0.34
Batch: 280; loss: 1.73; acc: 0.39
Batch: 300; loss: 1.73; acc: 0.47
Batch: 320; loss: 1.91; acc: 0.39
Batch: 340; loss: 1.79; acc: 0.42
Batch: 360; loss: 1.86; acc: 0.33
Batch: 380; loss: 1.91; acc: 0.28
Batch: 400; loss: 2.03; acc: 0.27
Batch: 420; loss: 1.91; acc: 0.3
Batch: 440; loss: 1.93; acc: 0.33
Batch: 460; loss: 1.92; acc: 0.36
Batch: 480; loss: 1.81; acc: 0.39
Batch: 500; loss: 1.78; acc: 0.34
Batch: 520; loss: 1.88; acc: 0.3
Batch: 540; loss: 1.96; acc: 0.34
Batch: 560; loss: 1.82; acc: 0.39
Batch: 580; loss: 1.9; acc: 0.31
Batch: 600; loss: 1.9; acc: 0.28
Batch: 620; loss: 1.81; acc: 0.31
Batch: 640; loss: 1.81; acc: 0.39
Batch: 660; loss: 1.92; acc: 0.23
Batch: 680; loss: 1.88; acc: 0.36
Batch: 700; loss: 1.79; acc: 0.39
Batch: 720; loss: 1.9; acc: 0.38
Batch: 740; loss: 1.89; acc: 0.34
Batch: 760; loss: 1.85; acc: 0.36
Batch: 780; loss: 1.88; acc: 0.3
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.015870748233283e-05
4.5787937779095955e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8307874514039155; val_accuracy: 0.35818073248407645 

The current subspace-distance is: 4.5787937779095955e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.88; acc: 0.3
Batch: 20; loss: 1.9; acc: 0.28
Batch: 40; loss: 1.78; acc: 0.42
Batch: 60; loss: 1.81; acc: 0.44
Batch: 80; loss: 1.82; acc: 0.34
Batch: 100; loss: 1.81; acc: 0.34
Batch: 120; loss: 1.91; acc: 0.34
Batch: 140; loss: 1.88; acc: 0.31
Batch: 160; loss: 2.03; acc: 0.2
Batch: 180; loss: 1.87; acc: 0.36
Batch: 200; loss: 2.08; acc: 0.33
Batch: 220; loss: 1.94; acc: 0.34
Batch: 240; loss: 2.03; acc: 0.33
Batch: 260; loss: 1.83; acc: 0.36
Batch: 280; loss: 2.0; acc: 0.36
Batch: 300; loss: 1.74; acc: 0.42
Batch: 320; loss: 1.84; acc: 0.33
Batch: 340; loss: 1.92; acc: 0.28
Batch: 360; loss: 1.77; acc: 0.41
Batch: 380; loss: 1.92; acc: 0.31
Batch: 400; loss: 1.8; acc: 0.36
Batch: 420; loss: 2.07; acc: 0.34
Batch: 440; loss: 1.78; acc: 0.41
Batch: 460; loss: 1.97; acc: 0.3
Batch: 480; loss: 1.9; acc: 0.3
Batch: 500; loss: 1.78; acc: 0.38
Batch: 520; loss: 1.62; acc: 0.47
Batch: 540; loss: 1.74; acc: 0.39
Batch: 560; loss: 1.78; acc: 0.36
Batch: 580; loss: 1.69; acc: 0.53
Batch: 600; loss: 1.85; acc: 0.34
Batch: 620; loss: 1.94; acc: 0.28
Batch: 640; loss: 1.86; acc: 0.36
Batch: 660; loss: 1.88; acc: 0.33
Batch: 680; loss: 1.9; acc: 0.38
Batch: 700; loss: 2.08; acc: 0.27
Batch: 720; loss: 1.77; acc: 0.34
Batch: 740; loss: 1.91; acc: 0.28
Batch: 760; loss: 1.99; acc: 0.28
Batch: 780; loss: 1.86; acc: 0.39
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.374660294270143e-06
4.8614492698106915e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.97; acc: 0.22
Batch: 40; loss: 1.63; acc: 0.42
Batch: 60; loss: 1.73; acc: 0.41
Batch: 80; loss: 1.55; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.81; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.830670705266819; val_accuracy: 0.35957404458598724 

The current subspace-distance is: 4.8614492698106915e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.78; acc: 0.42
Batch: 20; loss: 1.72; acc: 0.44
Batch: 40; loss: 1.75; acc: 0.41
Batch: 60; loss: 1.94; acc: 0.36
Batch: 80; loss: 1.68; acc: 0.39
Batch: 100; loss: 1.7; acc: 0.42
Batch: 120; loss: 1.94; acc: 0.33
Batch: 140; loss: 1.84; acc: 0.39
Batch: 160; loss: 1.76; acc: 0.36
Batch: 180; loss: 1.93; acc: 0.34
Batch: 200; loss: 1.78; acc: 0.3
Batch: 220; loss: 1.76; acc: 0.36
Batch: 240; loss: 2.08; acc: 0.22
Batch: 260; loss: 1.93; acc: 0.41
Batch: 280; loss: 1.94; acc: 0.38
Batch: 300; loss: 1.91; acc: 0.36
Batch: 320; loss: 1.89; acc: 0.36
Batch: 340; loss: 1.99; acc: 0.39
Batch: 360; loss: 1.72; acc: 0.42
Batch: 380; loss: 1.9; acc: 0.3
Batch: 400; loss: 1.75; acc: 0.34
Batch: 420; loss: 1.81; acc: 0.33
Batch: 440; loss: 1.77; acc: 0.38
Batch: 460; loss: 1.91; acc: 0.36
Batch: 480; loss: 1.79; acc: 0.41
Batch: 500; loss: 1.8; acc: 0.33
Batch: 520; loss: 1.82; acc: 0.38
Batch: 540; loss: 1.9; acc: 0.34
Batch: 560; loss: 1.86; acc: 0.3
Batch: 580; loss: 1.85; acc: 0.39
Batch: 600; loss: 1.76; acc: 0.39
Batch: 620; loss: 1.94; acc: 0.34
Batch: 640; loss: 1.79; acc: 0.34
Batch: 660; loss: 1.94; acc: 0.3
Batch: 680; loss: 1.8; acc: 0.33
Batch: 700; loss: 1.97; acc: 0.23
Batch: 720; loss: 1.82; acc: 0.42
Batch: 740; loss: 2.01; acc: 0.28
Batch: 760; loss: 2.05; acc: 0.25
Batch: 780; loss: 1.7; acc: 0.47
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1066346814914141e-05
4.458344392332947e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.97; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.73; acc: 0.41
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.89; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.36
Batch: 140; loss: 1.77; acc: 0.34
Val Epoch over. val_loss: 1.831049421790299; val_accuracy: 0.35977308917197454 

The current subspace-distance is: 4.458344392332947e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.78; acc: 0.39
Batch: 20; loss: 1.94; acc: 0.33
Batch: 40; loss: 2.0; acc: 0.3
Batch: 60; loss: 1.84; acc: 0.39
Batch: 80; loss: 1.86; acc: 0.34
Batch: 100; loss: 1.94; acc: 0.36
Batch: 120; loss: 1.82; acc: 0.38
Batch: 140; loss: 1.79; acc: 0.34
Batch: 160; loss: 1.73; acc: 0.38
Batch: 180; loss: 1.82; acc: 0.44
Batch: 200; loss: 1.91; acc: 0.38
Batch: 220; loss: 1.77; acc: 0.3
Batch: 240; loss: 1.71; acc: 0.42
Batch: 260; loss: 1.67; acc: 0.41
Batch: 280; loss: 1.86; acc: 0.34
Batch: 300; loss: 1.92; acc: 0.33
Batch: 320; loss: 1.82; acc: 0.27
Batch: 340; loss: 1.81; acc: 0.34
Batch: 360; loss: 1.93; acc: 0.34
Batch: 380; loss: 1.85; acc: 0.31
Batch: 400; loss: 1.87; acc: 0.28
Batch: 420; loss: 1.76; acc: 0.38
Batch: 440; loss: 1.94; acc: 0.28
Batch: 460; loss: 1.68; acc: 0.41
Batch: 480; loss: 1.67; acc: 0.47
Batch: 500; loss: 1.85; acc: 0.39
Batch: 520; loss: 1.72; acc: 0.39
Batch: 540; loss: 1.87; acc: 0.36
Batch: 560; loss: 1.83; acc: 0.39
Batch: 580; loss: 1.84; acc: 0.38
Batch: 600; loss: 1.76; acc: 0.42
Batch: 620; loss: 1.86; acc: 0.42
Batch: 640; loss: 1.82; acc: 0.39
Batch: 660; loss: 1.9; acc: 0.34
Batch: 680; loss: 1.91; acc: 0.27
Batch: 700; loss: 1.61; acc: 0.55
Batch: 720; loss: 1.68; acc: 0.45
Batch: 740; loss: 1.81; acc: 0.31
Batch: 760; loss: 2.05; acc: 0.2
Batch: 780; loss: 1.96; acc: 0.33
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0828351150848903e-05
6.01734882366145e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.63; acc: 0.42
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.55; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.36
Val Epoch over. val_loss: 1.8307677590922944; val_accuracy: 0.36365445859872614 

The current subspace-distance is: 6.01734882366145e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.82; acc: 0.42
Batch: 20; loss: 1.76; acc: 0.41
Batch: 40; loss: 1.84; acc: 0.38
Batch: 60; loss: 1.88; acc: 0.41
Batch: 80; loss: 1.92; acc: 0.36
Batch: 100; loss: 1.86; acc: 0.36
Batch: 120; loss: 1.92; acc: 0.27
Batch: 140; loss: 1.85; acc: 0.31
Batch: 160; loss: 1.93; acc: 0.3
Batch: 180; loss: 1.69; acc: 0.41
Batch: 200; loss: 1.76; acc: 0.42
Batch: 220; loss: 1.81; acc: 0.39
Batch: 240; loss: 1.81; acc: 0.36
Batch: 260; loss: 1.74; acc: 0.41
Batch: 280; loss: 1.8; acc: 0.41
Batch: 300; loss: 1.62; acc: 0.44
Batch: 320; loss: 1.99; acc: 0.33
Batch: 340; loss: 1.76; acc: 0.41
Batch: 360; loss: 1.93; acc: 0.3
Batch: 380; loss: 1.77; acc: 0.38
Batch: 400; loss: 1.74; acc: 0.42
Batch: 420; loss: 1.63; acc: 0.42
Batch: 440; loss: 1.7; acc: 0.42
Batch: 460; loss: 1.74; acc: 0.42
Batch: 480; loss: 1.71; acc: 0.47
Batch: 500; loss: 1.77; acc: 0.44
Batch: 520; loss: 1.81; acc: 0.41
Batch: 540; loss: 1.95; acc: 0.33
Batch: 560; loss: 1.92; acc: 0.33
Batch: 580; loss: 1.78; acc: 0.42
Batch: 600; loss: 1.82; acc: 0.39
Batch: 620; loss: 1.85; acc: 0.34
Batch: 640; loss: 1.68; acc: 0.45
Batch: 660; loss: 1.99; acc: 0.28
Batch: 680; loss: 1.81; acc: 0.36
Batch: 700; loss: 1.9; acc: 0.3
Batch: 720; loss: 1.75; acc: 0.36
Batch: 740; loss: 1.84; acc: 0.3
Batch: 760; loss: 1.84; acc: 0.33
Batch: 780; loss: 1.89; acc: 0.3
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.497234714217484e-06
4.080909548065392e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.38
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.91; acc: 0.31
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8316011117522124; val_accuracy: 0.36017117834394907 

The current subspace-distance is: 4.080909548065392e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.85; acc: 0.36
Batch: 20; loss: 1.94; acc: 0.25
Batch: 40; loss: 1.89; acc: 0.34
Batch: 60; loss: 1.79; acc: 0.42
Batch: 80; loss: 1.72; acc: 0.42
Batch: 100; loss: 1.75; acc: 0.42
Batch: 120; loss: 1.93; acc: 0.28
Batch: 140; loss: 2.04; acc: 0.25
Batch: 160; loss: 1.75; acc: 0.41
Batch: 180; loss: 1.8; acc: 0.38
Batch: 200; loss: 1.97; acc: 0.27
Batch: 220; loss: 1.75; acc: 0.45
Batch: 240; loss: 1.9; acc: 0.36
Batch: 260; loss: 1.96; acc: 0.25
Batch: 280; loss: 1.89; acc: 0.34
Batch: 300; loss: 2.03; acc: 0.27
Batch: 320; loss: 1.83; acc: 0.47
Batch: 340; loss: 1.91; acc: 0.34
Batch: 360; loss: 2.02; acc: 0.31
Batch: 380; loss: 1.61; acc: 0.44
Batch: 400; loss: 1.82; acc: 0.41
Batch: 420; loss: 1.72; acc: 0.39
Batch: 440; loss: 1.84; acc: 0.27
Batch: 460; loss: 1.84; acc: 0.33
Batch: 480; loss: 1.7; acc: 0.47
Batch: 500; loss: 1.8; acc: 0.34
Batch: 520; loss: 1.89; acc: 0.33
Batch: 540; loss: 1.84; acc: 0.3
Batch: 560; loss: 1.96; acc: 0.31
Batch: 580; loss: 1.68; acc: 0.45
Batch: 600; loss: 1.79; acc: 0.42
Batch: 620; loss: 1.8; acc: 0.39
Batch: 640; loss: 1.86; acc: 0.34
Batch: 660; loss: 1.92; acc: 0.36
Batch: 680; loss: 1.88; acc: 0.33
Batch: 700; loss: 1.73; acc: 0.42
Batch: 720; loss: 1.88; acc: 0.25
Batch: 740; loss: 1.82; acc: 0.33
Batch: 760; loss: 1.85; acc: 0.27
Batch: 780; loss: 1.92; acc: 0.33
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0450564332131762e-05
3.482835154500208e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.42
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.91; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.8304917561780116; val_accuracy: 0.3609673566878981 

The current subspace-distance is: 3.482835154500208e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.8; acc: 0.42
Batch: 20; loss: 1.82; acc: 0.38
Batch: 40; loss: 1.79; acc: 0.41
Batch: 60; loss: 1.75; acc: 0.39
Batch: 80; loss: 1.81; acc: 0.38
Batch: 100; loss: 1.89; acc: 0.39
Batch: 120; loss: 1.86; acc: 0.44
Batch: 140; loss: 1.73; acc: 0.44
Batch: 160; loss: 1.7; acc: 0.39
Batch: 180; loss: 1.83; acc: 0.34
Batch: 200; loss: 1.99; acc: 0.33
Batch: 220; loss: 1.95; acc: 0.34
Batch: 240; loss: 1.82; acc: 0.34
Batch: 260; loss: 2.0; acc: 0.31
Batch: 280; loss: 1.85; acc: 0.39
Batch: 300; loss: 1.86; acc: 0.34
Batch: 320; loss: 1.87; acc: 0.38
Batch: 340; loss: 1.82; acc: 0.34
Batch: 360; loss: 1.82; acc: 0.44
Batch: 380; loss: 1.91; acc: 0.3
Batch: 400; loss: 1.97; acc: 0.3
Batch: 420; loss: 1.84; acc: 0.36
Batch: 440; loss: 2.06; acc: 0.3
Batch: 460; loss: 1.87; acc: 0.38
Batch: 480; loss: 1.84; acc: 0.38
Batch: 500; loss: 1.85; acc: 0.31
Batch: 520; loss: 1.81; acc: 0.3
Batch: 540; loss: 1.73; acc: 0.5
Batch: 560; loss: 1.81; acc: 0.33
Batch: 580; loss: 1.69; acc: 0.44
Batch: 600; loss: 1.79; acc: 0.41
Batch: 620; loss: 1.71; acc: 0.39
Batch: 640; loss: 1.8; acc: 0.39
Batch: 660; loss: 1.78; acc: 0.41
Batch: 680; loss: 1.9; acc: 0.3
Batch: 700; loss: 1.9; acc: 0.28
Batch: 720; loss: 1.76; acc: 0.36
Batch: 740; loss: 1.88; acc: 0.3
Batch: 760; loss: 1.91; acc: 0.33
Batch: 780; loss: 1.75; acc: 0.48
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.82243727776222e-06
4.440564225660637e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 1.99; acc: 0.23
Batch: 40; loss: 1.62; acc: 0.36
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.54; acc: 0.45
Batch: 100; loss: 1.91; acc: 0.31
Batch: 120; loss: 1.83; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8319532742166216; val_accuracy: 0.35628980891719747 

The current subspace-distance is: 4.440564225660637e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.95; acc: 0.34
Batch: 20; loss: 1.69; acc: 0.41
Batch: 40; loss: 1.74; acc: 0.44
Batch: 60; loss: 1.75; acc: 0.34
Batch: 80; loss: 1.83; acc: 0.38
Batch: 100; loss: 1.65; acc: 0.42
Batch: 120; loss: 1.78; acc: 0.47
Batch: 140; loss: 1.79; acc: 0.41
Batch: 160; loss: 1.98; acc: 0.36
Batch: 180; loss: 1.99; acc: 0.34
Batch: 200; loss: 1.91; acc: 0.23
Batch: 220; loss: 1.94; acc: 0.34
Batch: 240; loss: 1.94; acc: 0.36
Batch: 260; loss: 1.92; acc: 0.3
Batch: 280; loss: 1.96; acc: 0.31
Batch: 300; loss: 1.63; acc: 0.47
Batch: 320; loss: 1.85; acc: 0.31
Batch: 340; loss: 1.83; acc: 0.41
Batch: 360; loss: 1.88; acc: 0.33
Batch: 380; loss: 1.65; acc: 0.48
Batch: 400; loss: 1.91; acc: 0.34
Batch: 420; loss: 1.79; acc: 0.39
Batch: 440; loss: 1.77; acc: 0.34
Batch: 460; loss: 1.87; acc: 0.38
Batch: 480; loss: 1.66; acc: 0.47
Batch: 500; loss: 1.66; acc: 0.5
Batch: 520; loss: 2.06; acc: 0.31
Batch: 540; loss: 1.96; acc: 0.23
Batch: 560; loss: 1.96; acc: 0.28
Batch: 580; loss: 1.73; acc: 0.39
Batch: 600; loss: 1.84; acc: 0.33
Batch: 620; loss: 1.94; acc: 0.34
Batch: 640; loss: 1.75; acc: 0.45
Batch: 660; loss: 1.74; acc: 0.34
Batch: 680; loss: 1.81; acc: 0.41
Batch: 700; loss: 1.83; acc: 0.42
Batch: 720; loss: 1.88; acc: 0.33
Batch: 740; loss: 1.89; acc: 0.36
Batch: 760; loss: 1.75; acc: 0.34
Batch: 780; loss: 1.79; acc: 0.36
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.075007730833022e-05
4.047858965350315e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.73; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8305699688613795; val_accuracy: 0.35828025477707004 

The current subspace-distance is: 4.047858965350315e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.06; acc: 0.22
Batch: 20; loss: 1.75; acc: 0.39
Batch: 40; loss: 1.84; acc: 0.33
Batch: 60; loss: 1.93; acc: 0.31
Batch: 80; loss: 1.82; acc: 0.3
Batch: 100; loss: 1.75; acc: 0.45
Batch: 120; loss: 1.87; acc: 0.34
Batch: 140; loss: 1.86; acc: 0.38
Batch: 160; loss: 1.79; acc: 0.41
Batch: 180; loss: 1.79; acc: 0.38
Batch: 200; loss: 1.85; acc: 0.38
Batch: 220; loss: 1.95; acc: 0.34
Batch: 240; loss: 1.88; acc: 0.34
Batch: 260; loss: 1.78; acc: 0.36
Batch: 280; loss: 1.84; acc: 0.33
Batch: 300; loss: 1.85; acc: 0.39
Batch: 320; loss: 1.78; acc: 0.39
Batch: 340; loss: 1.78; acc: 0.44
Batch: 360; loss: 1.8; acc: 0.38
Batch: 380; loss: 1.75; acc: 0.41
Batch: 400; loss: 2.05; acc: 0.25
Batch: 420; loss: 1.91; acc: 0.34
Batch: 440; loss: 1.84; acc: 0.31
Batch: 460; loss: 1.77; acc: 0.41
Batch: 480; loss: 1.86; acc: 0.36
Batch: 500; loss: 1.74; acc: 0.41
Batch: 520; loss: 1.9; acc: 0.3
Batch: 540; loss: 1.92; acc: 0.34
Batch: 560; loss: 1.85; acc: 0.27
Batch: 580; loss: 1.86; acc: 0.36
Batch: 600; loss: 1.83; acc: 0.36
Batch: 620; loss: 1.8; acc: 0.39
Batch: 640; loss: 1.98; acc: 0.31
Batch: 660; loss: 1.74; acc: 0.38
Batch: 680; loss: 1.76; acc: 0.36
Batch: 700; loss: 1.93; acc: 0.36
Batch: 720; loss: 2.02; acc: 0.25
Batch: 740; loss: 1.99; acc: 0.25
Batch: 760; loss: 1.79; acc: 0.39
Batch: 780; loss: 1.78; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1100008123321459e-05
4.142017132835463e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.8304953780143884; val_accuracy: 0.3600716560509554 

The current subspace-distance is: 4.142017132835463e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.95; acc: 0.3
Batch: 20; loss: 1.75; acc: 0.41
Batch: 40; loss: 1.86; acc: 0.39
Batch: 60; loss: 1.87; acc: 0.36
Batch: 80; loss: 2.03; acc: 0.25
Batch: 100; loss: 1.65; acc: 0.44
Batch: 120; loss: 1.98; acc: 0.33
Batch: 140; loss: 1.86; acc: 0.36
Batch: 160; loss: 1.84; acc: 0.42
Batch: 180; loss: 1.97; acc: 0.33
Batch: 200; loss: 1.83; acc: 0.34
Batch: 220; loss: 1.91; acc: 0.34
Batch: 240; loss: 1.86; acc: 0.34
Batch: 260; loss: 1.88; acc: 0.36
Batch: 280; loss: 1.84; acc: 0.39
Batch: 300; loss: 1.9; acc: 0.38
Batch: 320; loss: 2.09; acc: 0.27
Batch: 340; loss: 1.94; acc: 0.33
Batch: 360; loss: 2.02; acc: 0.27
Batch: 380; loss: 1.73; acc: 0.45
Batch: 400; loss: 1.95; acc: 0.34
Batch: 420; loss: 1.89; acc: 0.3
Batch: 440; loss: 1.76; acc: 0.41
Batch: 460; loss: 1.76; acc: 0.44
Batch: 480; loss: 1.88; acc: 0.42
Batch: 500; loss: 1.84; acc: 0.34
Batch: 520; loss: 1.76; acc: 0.34
Batch: 540; loss: 1.98; acc: 0.31
Batch: 560; loss: 1.75; acc: 0.42
Batch: 580; loss: 1.98; acc: 0.31
Batch: 600; loss: 1.95; acc: 0.36
Batch: 620; loss: 1.89; acc: 0.38
Batch: 640; loss: 1.88; acc: 0.42
Batch: 660; loss: 1.8; acc: 0.44
Batch: 680; loss: 1.94; acc: 0.33
Batch: 700; loss: 1.86; acc: 0.28
Batch: 720; loss: 1.66; acc: 0.42
Batch: 740; loss: 2.04; acc: 0.27
Batch: 760; loss: 1.98; acc: 0.28
Batch: 780; loss: 1.75; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

8.57609757076716e-06
3.7437919218064053e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.27
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.76; acc: 0.36
Val Epoch over. val_loss: 1.8302822545835167; val_accuracy: 0.3606687898089172 

The current subspace-distance is: 3.7437919218064053e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.96; acc: 0.27
Batch: 20; loss: 1.87; acc: 0.41
Batch: 40; loss: 1.9; acc: 0.34
Batch: 60; loss: 1.94; acc: 0.3
Batch: 80; loss: 1.77; acc: 0.41
Batch: 100; loss: 1.73; acc: 0.28
Batch: 120; loss: 1.88; acc: 0.36
Batch: 140; loss: 1.72; acc: 0.48
Batch: 160; loss: 1.8; acc: 0.44
Batch: 180; loss: 1.87; acc: 0.34
Batch: 200; loss: 1.9; acc: 0.33
Batch: 220; loss: 1.84; acc: 0.36
Batch: 240; loss: 1.86; acc: 0.39
Batch: 260; loss: 1.76; acc: 0.38
Batch: 280; loss: 1.88; acc: 0.34
Batch: 300; loss: 1.79; acc: 0.36
Batch: 320; loss: 1.82; acc: 0.31
Batch: 340; loss: 1.93; acc: 0.31
Batch: 360; loss: 1.84; acc: 0.31
Batch: 380; loss: 1.71; acc: 0.34
Batch: 400; loss: 1.99; acc: 0.34
Batch: 420; loss: 1.87; acc: 0.33
Batch: 440; loss: 1.95; acc: 0.28
Batch: 460; loss: 1.89; acc: 0.36
Batch: 480; loss: 1.75; acc: 0.31
Batch: 500; loss: 1.98; acc: 0.22
Batch: 520; loss: 1.93; acc: 0.39
Batch: 540; loss: 1.79; acc: 0.27
Batch: 560; loss: 1.87; acc: 0.3
Batch: 580; loss: 1.95; acc: 0.3
Batch: 600; loss: 1.96; acc: 0.28
Batch: 620; loss: 1.82; acc: 0.38
Batch: 640; loss: 2.0; acc: 0.23
Batch: 660; loss: 1.7; acc: 0.47
Batch: 680; loss: 1.73; acc: 0.39
Batch: 700; loss: 1.66; acc: 0.5
Batch: 720; loss: 1.79; acc: 0.31
Batch: 740; loss: 2.0; acc: 0.28
Batch: 760; loss: 1.87; acc: 0.36
Batch: 780; loss: 1.9; acc: 0.28
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.431291800865438e-06
5.381419214245398e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.36
Val Epoch over. val_loss: 1.8303065322766638; val_accuracy: 0.35887738853503187 

The current subspace-distance is: 5.381419214245398e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.82; acc: 0.45
Batch: 20; loss: 1.89; acc: 0.34
Batch: 40; loss: 1.91; acc: 0.31
Batch: 60; loss: 1.91; acc: 0.33
Batch: 80; loss: 1.82; acc: 0.42
Batch: 100; loss: 1.95; acc: 0.36
Batch: 120; loss: 1.67; acc: 0.47
Batch: 140; loss: 1.67; acc: 0.42
Batch: 160; loss: 1.97; acc: 0.28
Batch: 180; loss: 1.71; acc: 0.36
Batch: 200; loss: 1.72; acc: 0.39
Batch: 220; loss: 1.79; acc: 0.44
Batch: 240; loss: 1.95; acc: 0.33
Batch: 260; loss: 2.03; acc: 0.27
Batch: 280; loss: 1.88; acc: 0.34
Batch: 300; loss: 1.8; acc: 0.42
Batch: 320; loss: 1.82; acc: 0.31
Batch: 340; loss: 1.76; acc: 0.42
Batch: 360; loss: 1.99; acc: 0.25
Batch: 380; loss: 1.78; acc: 0.42
Batch: 400; loss: 2.01; acc: 0.34
Batch: 420; loss: 1.97; acc: 0.33
Batch: 440; loss: 1.82; acc: 0.38
Batch: 460; loss: 2.18; acc: 0.22
Batch: 480; loss: 1.85; acc: 0.34
Batch: 500; loss: 1.83; acc: 0.39
Batch: 520; loss: 1.85; acc: 0.36
Batch: 540; loss: 1.76; acc: 0.36
Batch: 560; loss: 1.73; acc: 0.41
Batch: 580; loss: 2.14; acc: 0.27
Batch: 600; loss: 1.84; acc: 0.36
Batch: 620; loss: 1.7; acc: 0.41
Batch: 640; loss: 1.79; acc: 0.42
Batch: 660; loss: 1.78; acc: 0.42
Batch: 680; loss: 1.86; acc: 0.38
Batch: 700; loss: 1.91; acc: 0.36
Batch: 720; loss: 1.98; acc: 0.2
Batch: 740; loss: 1.88; acc: 0.36
Batch: 760; loss: 1.78; acc: 0.38
Batch: 780; loss: 1.77; acc: 0.38
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.642374607210513e-06
3.4419608709868044e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.63; acc: 0.39
Batch: 60; loss: 1.73; acc: 0.39
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.830342182687893; val_accuracy: 0.35927547770700635 

The current subspace-distance is: 3.4419608709868044e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.92; acc: 0.38
Batch: 20; loss: 1.81; acc: 0.39
Batch: 40; loss: 1.89; acc: 0.25
Batch: 60; loss: 1.8; acc: 0.36
Batch: 80; loss: 1.93; acc: 0.31
Batch: 100; loss: 1.87; acc: 0.3
Batch: 120; loss: 1.91; acc: 0.31
Batch: 140; loss: 1.79; acc: 0.36
Batch: 160; loss: 1.89; acc: 0.34
Batch: 180; loss: 1.94; acc: 0.27
Batch: 200; loss: 1.95; acc: 0.28
Batch: 220; loss: 1.94; acc: 0.33
Batch: 240; loss: 1.92; acc: 0.38
Batch: 260; loss: 1.84; acc: 0.34
Batch: 280; loss: 1.83; acc: 0.33
Batch: 300; loss: 2.05; acc: 0.33
Batch: 320; loss: 1.73; acc: 0.39
Batch: 340; loss: 1.78; acc: 0.38
Batch: 360; loss: 1.77; acc: 0.45
Batch: 380; loss: 1.89; acc: 0.36
Batch: 400; loss: 1.76; acc: 0.45
Batch: 420; loss: 1.73; acc: 0.42
Batch: 440; loss: 1.94; acc: 0.34
Batch: 460; loss: 1.96; acc: 0.33
Batch: 480; loss: 1.9; acc: 0.33
Batch: 500; loss: 1.84; acc: 0.33
Batch: 520; loss: 2.02; acc: 0.27
Batch: 540; loss: 1.71; acc: 0.44
Batch: 560; loss: 1.8; acc: 0.38
Batch: 580; loss: 1.94; acc: 0.28
Batch: 600; loss: 1.76; acc: 0.42
Batch: 620; loss: 1.71; acc: 0.5
Batch: 640; loss: 1.74; acc: 0.45
Batch: 660; loss: 1.62; acc: 0.36
Batch: 680; loss: 1.84; acc: 0.34
Batch: 700; loss: 1.75; acc: 0.42
Batch: 720; loss: 1.82; acc: 0.38
Batch: 740; loss: 1.89; acc: 0.34
Batch: 760; loss: 1.89; acc: 0.31
Batch: 780; loss: 1.9; acc: 0.34
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0759915312519297e-05
4.7990424718591385e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.2
Batch: 40; loss: 1.63; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.76; acc: 0.39
Val Epoch over. val_loss: 1.8295501371857468; val_accuracy: 0.36076831210191085 

The current subspace-distance is: 4.7990424718591385e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.91; acc: 0.42
Batch: 20; loss: 2.07; acc: 0.3
Batch: 40; loss: 2.0; acc: 0.25
Batch: 60; loss: 1.92; acc: 0.31
Batch: 80; loss: 1.97; acc: 0.28
Batch: 100; loss: 1.78; acc: 0.42
Batch: 120; loss: 1.84; acc: 0.41
Batch: 140; loss: 1.8; acc: 0.41
Batch: 160; loss: 1.83; acc: 0.36
Batch: 180; loss: 1.86; acc: 0.3
Batch: 200; loss: 1.89; acc: 0.33
Batch: 220; loss: 1.94; acc: 0.38
Batch: 240; loss: 1.95; acc: 0.27
Batch: 260; loss: 1.77; acc: 0.34
Batch: 280; loss: 1.8; acc: 0.34
Batch: 300; loss: 1.88; acc: 0.28
Batch: 320; loss: 1.99; acc: 0.33
Batch: 340; loss: 1.85; acc: 0.38
Batch: 360; loss: 2.04; acc: 0.33
Batch: 380; loss: 1.87; acc: 0.33
Batch: 400; loss: 1.67; acc: 0.44
Batch: 420; loss: 1.8; acc: 0.41
Batch: 440; loss: 1.93; acc: 0.39
Batch: 460; loss: 1.77; acc: 0.31
Batch: 480; loss: 1.83; acc: 0.39
Batch: 500; loss: 1.86; acc: 0.28
Batch: 520; loss: 1.61; acc: 0.47
Batch: 540; loss: 1.8; acc: 0.42
Batch: 560; loss: 1.89; acc: 0.34
Batch: 580; loss: 1.84; acc: 0.38
Batch: 600; loss: 1.86; acc: 0.3
Batch: 620; loss: 1.94; acc: 0.28
Batch: 640; loss: 1.9; acc: 0.38
Batch: 660; loss: 1.77; acc: 0.47
Batch: 680; loss: 1.73; acc: 0.38
Batch: 700; loss: 1.91; acc: 0.31
Batch: 720; loss: 1.76; acc: 0.41
Batch: 740; loss: 1.84; acc: 0.31
Batch: 760; loss: 1.75; acc: 0.47
Batch: 780; loss: 1.78; acc: 0.38
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.871573638520204e-06
3.890302195941331e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.73; acc: 0.39
Batch: 80; loss: 1.54; acc: 0.45
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.34
Val Epoch over. val_loss: 1.8303028132505477; val_accuracy: 0.357484076433121 

The current subspace-distance is: 3.890302195941331e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 2.03; acc: 0.3
Batch: 20; loss: 1.97; acc: 0.31
Batch: 40; loss: 1.67; acc: 0.42
Batch: 60; loss: 1.92; acc: 0.36
Batch: 80; loss: 1.93; acc: 0.33
Batch: 100; loss: 1.81; acc: 0.39
Batch: 120; loss: 1.95; acc: 0.3
Batch: 140; loss: 1.98; acc: 0.36
Batch: 160; loss: 1.97; acc: 0.33
Batch: 180; loss: 1.85; acc: 0.34
Batch: 200; loss: 1.85; acc: 0.42
Batch: 220; loss: 1.82; acc: 0.39
Batch: 240; loss: 1.76; acc: 0.33
Batch: 260; loss: 1.77; acc: 0.34
Batch: 280; loss: 1.86; acc: 0.33
Batch: 300; loss: 1.93; acc: 0.34
Batch: 320; loss: 1.96; acc: 0.36
Batch: 340; loss: 1.79; acc: 0.39
Batch: 360; loss: 1.82; acc: 0.39
Batch: 380; loss: 1.81; acc: 0.38
Batch: 400; loss: 1.89; acc: 0.34
Batch: 420; loss: 1.8; acc: 0.36
Batch: 440; loss: 1.8; acc: 0.5
Batch: 460; loss: 1.96; acc: 0.25
Batch: 480; loss: 1.91; acc: 0.33
Batch: 500; loss: 1.96; acc: 0.34
Batch: 520; loss: 2.05; acc: 0.31
Batch: 540; loss: 1.83; acc: 0.31
Batch: 560; loss: 1.75; acc: 0.41
Batch: 580; loss: 1.82; acc: 0.41
Batch: 600; loss: 1.96; acc: 0.39
Batch: 620; loss: 1.8; acc: 0.36
Batch: 640; loss: 1.82; acc: 0.33
Batch: 660; loss: 1.73; acc: 0.39
Batch: 680; loss: 1.79; acc: 0.42
Batch: 700; loss: 1.93; acc: 0.33
Batch: 720; loss: 1.68; acc: 0.47
Batch: 740; loss: 1.86; acc: 0.33
Batch: 760; loss: 1.93; acc: 0.25
Batch: 780; loss: 1.77; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1255725439696107e-05
3.886148988385685e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.34
Batch: 140; loss: 1.77; acc: 0.36
Val Epoch over. val_loss: 1.8303055634164507; val_accuracy: 0.35977308917197454 

The current subspace-distance is: 3.886148988385685e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.76; acc: 0.45
Batch: 20; loss: 1.71; acc: 0.45
Batch: 40; loss: 1.76; acc: 0.39
Batch: 60; loss: 1.97; acc: 0.3
Batch: 80; loss: 2.02; acc: 0.22
Batch: 100; loss: 2.01; acc: 0.23
Batch: 120; loss: 1.96; acc: 0.34
Batch: 140; loss: 1.78; acc: 0.5
Batch: 160; loss: 2.05; acc: 0.36
Batch: 180; loss: 1.99; acc: 0.31
Batch: 200; loss: 1.95; acc: 0.3
Batch: 220; loss: 1.73; acc: 0.47
Batch: 240; loss: 1.86; acc: 0.27
Batch: 260; loss: 1.9; acc: 0.3
Batch: 280; loss: 1.76; acc: 0.41
Batch: 300; loss: 2.0; acc: 0.25
Batch: 320; loss: 1.82; acc: 0.36
Batch: 340; loss: 1.87; acc: 0.44
Batch: 360; loss: 2.01; acc: 0.31
Batch: 380; loss: 1.77; acc: 0.36
Batch: 400; loss: 1.8; acc: 0.38
Batch: 420; loss: 1.89; acc: 0.38
Batch: 440; loss: 1.61; acc: 0.53
Batch: 460; loss: 1.79; acc: 0.42
Batch: 480; loss: 1.52; acc: 0.48
Batch: 500; loss: 1.74; acc: 0.31
Batch: 520; loss: 1.85; acc: 0.36
Batch: 540; loss: 1.75; acc: 0.36
Batch: 560; loss: 1.91; acc: 0.28
Batch: 580; loss: 1.82; acc: 0.39
Batch: 600; loss: 1.87; acc: 0.38
Batch: 620; loss: 2.11; acc: 0.27
Batch: 640; loss: 1.95; acc: 0.33
Batch: 660; loss: 1.9; acc: 0.34
Batch: 680; loss: 1.89; acc: 0.39
Batch: 700; loss: 2.09; acc: 0.23
Batch: 720; loss: 1.85; acc: 0.34
Batch: 740; loss: 1.82; acc: 0.38
Batch: 760; loss: 1.8; acc: 0.41
Batch: 780; loss: 1.92; acc: 0.36
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1507921044540126e-05
3.055952447539312e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8302112483674553; val_accuracy: 0.3590764331210191 

The current subspace-distance is: 3.055952447539312e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.9; acc: 0.25
Batch: 20; loss: 1.82; acc: 0.39
Batch: 40; loss: 2.0; acc: 0.28
Batch: 60; loss: 1.84; acc: 0.34
Batch: 80; loss: 1.84; acc: 0.39
Batch: 100; loss: 1.92; acc: 0.33
Batch: 120; loss: 1.73; acc: 0.44
Batch: 140; loss: 1.91; acc: 0.28
Batch: 160; loss: 1.87; acc: 0.3
Batch: 180; loss: 1.87; acc: 0.31
Batch: 200; loss: 1.68; acc: 0.47
Batch: 220; loss: 1.79; acc: 0.34
Batch: 240; loss: 1.9; acc: 0.36
Batch: 260; loss: 1.67; acc: 0.41
Batch: 280; loss: 1.68; acc: 0.41
Batch: 300; loss: 1.82; acc: 0.31
Batch: 320; loss: 1.78; acc: 0.41
Batch: 340; loss: 1.98; acc: 0.39
Batch: 360; loss: 1.76; acc: 0.39
Batch: 380; loss: 1.79; acc: 0.39
Batch: 400; loss: 1.99; acc: 0.23
Batch: 420; loss: 1.72; acc: 0.42
Batch: 440; loss: 1.83; acc: 0.45
Batch: 460; loss: 1.8; acc: 0.41
Batch: 480; loss: 1.81; acc: 0.33
Batch: 500; loss: 1.92; acc: 0.28
Batch: 520; loss: 1.87; acc: 0.33
Batch: 540; loss: 1.83; acc: 0.34
Batch: 560; loss: 1.85; acc: 0.36
Batch: 580; loss: 1.95; acc: 0.25
Batch: 600; loss: 1.82; acc: 0.34
Batch: 620; loss: 1.91; acc: 0.33
Batch: 640; loss: 1.63; acc: 0.48
Batch: 660; loss: 1.82; acc: 0.39
Batch: 680; loss: 1.95; acc: 0.33
Batch: 700; loss: 1.77; acc: 0.44
Batch: 720; loss: 1.71; acc: 0.44
Batch: 740; loss: 1.87; acc: 0.34
Batch: 760; loss: 1.87; acc: 0.36
Batch: 780; loss: 1.84; acc: 0.33
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.320478966401424e-06
3.81572817786946e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.830046418366159; val_accuracy: 0.3596735668789809 

The current subspace-distance is: 3.81572817786946e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.85; acc: 0.33
Batch: 20; loss: 1.61; acc: 0.42
Batch: 40; loss: 1.87; acc: 0.28
Batch: 60; loss: 1.89; acc: 0.33
Batch: 80; loss: 1.99; acc: 0.28
Batch: 100; loss: 1.83; acc: 0.44
Batch: 120; loss: 1.78; acc: 0.33
Batch: 140; loss: 1.71; acc: 0.44
Batch: 160; loss: 1.8; acc: 0.36
Batch: 180; loss: 1.97; acc: 0.33
Batch: 200; loss: 1.62; acc: 0.44
Batch: 220; loss: 1.98; acc: 0.33
Batch: 240; loss: 1.73; acc: 0.42
Batch: 260; loss: 1.88; acc: 0.3
Batch: 280; loss: 1.81; acc: 0.42
Batch: 300; loss: 1.98; acc: 0.3
Batch: 320; loss: 1.88; acc: 0.42
Batch: 340; loss: 1.79; acc: 0.25
Batch: 360; loss: 1.85; acc: 0.36
Batch: 380; loss: 1.94; acc: 0.31
Batch: 400; loss: 1.81; acc: 0.36
Batch: 420; loss: 1.9; acc: 0.38
Batch: 440; loss: 1.72; acc: 0.31
Batch: 460; loss: 1.84; acc: 0.42
Batch: 480; loss: 1.8; acc: 0.42
Batch: 500; loss: 1.9; acc: 0.28
Batch: 520; loss: 1.64; acc: 0.52
Batch: 540; loss: 1.77; acc: 0.41
Batch: 560; loss: 1.83; acc: 0.38
Batch: 580; loss: 1.8; acc: 0.42
Batch: 600; loss: 1.74; acc: 0.39
Batch: 620; loss: 1.77; acc: 0.41
Batch: 640; loss: 1.94; acc: 0.28
Batch: 660; loss: 1.98; acc: 0.25
Batch: 680; loss: 1.95; acc: 0.28
Batch: 700; loss: 1.74; acc: 0.44
Batch: 720; loss: 1.67; acc: 0.38
Batch: 740; loss: 1.91; acc: 0.34
Batch: 760; loss: 1.75; acc: 0.38
Batch: 780; loss: 1.78; acc: 0.38
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0227503480564337e-05
5.2497048272925895e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8302249369347932; val_accuracy: 0.3599721337579618 

The current subspace-distance is: 5.2497048272925895e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.86; acc: 0.38
Batch: 20; loss: 1.78; acc: 0.36
Batch: 40; loss: 1.79; acc: 0.42
Batch: 60; loss: 2.14; acc: 0.19
Batch: 80; loss: 1.92; acc: 0.34
Batch: 100; loss: 1.73; acc: 0.39
Batch: 120; loss: 2.01; acc: 0.38
Batch: 140; loss: 1.81; acc: 0.31
Batch: 160; loss: 2.0; acc: 0.23
Batch: 180; loss: 1.98; acc: 0.31
Batch: 200; loss: 1.79; acc: 0.41
Batch: 220; loss: 1.9; acc: 0.39
Batch: 240; loss: 1.91; acc: 0.31
Batch: 260; loss: 1.77; acc: 0.36
Batch: 280; loss: 1.73; acc: 0.44
Batch: 300; loss: 1.86; acc: 0.33
Batch: 320; loss: 1.96; acc: 0.25
Batch: 340; loss: 1.93; acc: 0.3
Batch: 360; loss: 1.79; acc: 0.36
Batch: 380; loss: 1.91; acc: 0.33
Batch: 400; loss: 1.87; acc: 0.38
Batch: 420; loss: 1.92; acc: 0.33
Batch: 440; loss: 1.81; acc: 0.39
Batch: 460; loss: 1.83; acc: 0.38
Batch: 480; loss: 1.88; acc: 0.31
Batch: 500; loss: 1.88; acc: 0.36
Batch: 520; loss: 1.79; acc: 0.39
Batch: 540; loss: 2.04; acc: 0.38
Batch: 560; loss: 1.93; acc: 0.39
Batch: 580; loss: 1.76; acc: 0.42
Batch: 600; loss: 1.92; acc: 0.27
Batch: 620; loss: 1.76; acc: 0.5
Batch: 640; loss: 1.8; acc: 0.39
Batch: 660; loss: 1.94; acc: 0.3
Batch: 680; loss: 1.75; acc: 0.36
Batch: 700; loss: 1.87; acc: 0.34
Batch: 720; loss: 1.73; acc: 0.42
Batch: 740; loss: 1.89; acc: 0.34
Batch: 760; loss: 2.01; acc: 0.27
Batch: 780; loss: 1.9; acc: 0.3
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0456967174832243e-05
4.347760295786429e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.39
Val Epoch over. val_loss: 1.8299922381237055; val_accuracy: 0.3603702229299363 

The current subspace-distance is: 4.347760295786429e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.75; acc: 0.36
Batch: 20; loss: 1.91; acc: 0.41
Batch: 40; loss: 2.09; acc: 0.28
Batch: 60; loss: 1.73; acc: 0.48
Batch: 80; loss: 1.89; acc: 0.36
Batch: 100; loss: 1.98; acc: 0.28
Batch: 120; loss: 1.66; acc: 0.52
Batch: 140; loss: 1.99; acc: 0.23
Batch: 160; loss: 1.92; acc: 0.27
Batch: 180; loss: 1.72; acc: 0.34
Batch: 200; loss: 1.84; acc: 0.41
Batch: 220; loss: 1.72; acc: 0.39
Batch: 240; loss: 2.04; acc: 0.34
Batch: 260; loss: 1.88; acc: 0.33
Batch: 280; loss: 1.96; acc: 0.28
Batch: 300; loss: 1.95; acc: 0.3
Batch: 320; loss: 1.96; acc: 0.31
Batch: 340; loss: 1.84; acc: 0.31
Batch: 360; loss: 1.81; acc: 0.41
Batch: 380; loss: 1.88; acc: 0.41
Batch: 400; loss: 1.96; acc: 0.39
Batch: 420; loss: 1.97; acc: 0.31
Batch: 440; loss: 1.73; acc: 0.45
Batch: 460; loss: 1.78; acc: 0.36
Batch: 480; loss: 1.7; acc: 0.5
Batch: 500; loss: 1.87; acc: 0.36
Batch: 520; loss: 2.13; acc: 0.17
Batch: 540; loss: 1.86; acc: 0.39
Batch: 560; loss: 1.65; acc: 0.45
Batch: 580; loss: 1.75; acc: 0.38
Batch: 600; loss: 1.88; acc: 0.34
Batch: 620; loss: 1.95; acc: 0.23
Batch: 640; loss: 1.72; acc: 0.42
Batch: 660; loss: 1.86; acc: 0.33
Batch: 680; loss: 1.9; acc: 0.36
Batch: 700; loss: 1.84; acc: 0.41
Batch: 720; loss: 1.84; acc: 0.33
Batch: 740; loss: 1.93; acc: 0.28
Batch: 760; loss: 1.88; acc: 0.36
Batch: 780; loss: 2.0; acc: 0.31
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.804373803490307e-06
5.708262960979482e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8301182901783355; val_accuracy: 0.35947452229299365 

The current subspace-distance is: 5.708262960979482e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.78; acc: 0.39
Batch: 20; loss: 1.77; acc: 0.39
Batch: 40; loss: 1.86; acc: 0.3
Batch: 60; loss: 1.76; acc: 0.39
Batch: 80; loss: 1.73; acc: 0.52
Batch: 100; loss: 1.78; acc: 0.34
Batch: 120; loss: 1.75; acc: 0.39
Batch: 140; loss: 1.84; acc: 0.33
Batch: 160; loss: 1.8; acc: 0.41
Batch: 180; loss: 1.74; acc: 0.45
Batch: 200; loss: 1.95; acc: 0.3
Batch: 220; loss: 1.79; acc: 0.39
Batch: 240; loss: 1.78; acc: 0.34
Batch: 260; loss: 1.82; acc: 0.42
Batch: 280; loss: 1.7; acc: 0.48
Batch: 300; loss: 1.88; acc: 0.28
Batch: 320; loss: 1.96; acc: 0.27
Batch: 340; loss: 1.85; acc: 0.41
Batch: 360; loss: 1.67; acc: 0.47
Batch: 380; loss: 1.82; acc: 0.36
Batch: 400; loss: 2.0; acc: 0.23
Batch: 420; loss: 2.0; acc: 0.38
Batch: 440; loss: 1.8; acc: 0.31
Batch: 460; loss: 1.81; acc: 0.38
Batch: 480; loss: 1.8; acc: 0.42
Batch: 500; loss: 1.84; acc: 0.39
Batch: 520; loss: 1.84; acc: 0.36
Batch: 540; loss: 1.7; acc: 0.45
Batch: 560; loss: 1.85; acc: 0.42
Batch: 580; loss: 1.85; acc: 0.34
Batch: 600; loss: 1.91; acc: 0.33
Batch: 620; loss: 1.86; acc: 0.39
Batch: 640; loss: 1.72; acc: 0.42
Batch: 660; loss: 1.97; acc: 0.28
Batch: 680; loss: 1.82; acc: 0.36
Batch: 700; loss: 1.75; acc: 0.44
Batch: 720; loss: 1.8; acc: 0.44
Batch: 740; loss: 2.06; acc: 0.31
Batch: 760; loss: 1.64; acc: 0.42
Batch: 780; loss: 1.92; acc: 0.31
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

8.515158697264269e-06
4.767296559293754e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8298423168765512; val_accuracy: 0.36027070063694266 

The current subspace-distance is: 4.767296559293754e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.71; acc: 0.38
Batch: 20; loss: 1.86; acc: 0.38
Batch: 40; loss: 1.83; acc: 0.44
Batch: 60; loss: 2.08; acc: 0.22
Batch: 80; loss: 1.9; acc: 0.39
Batch: 100; loss: 1.84; acc: 0.31
Batch: 120; loss: 1.96; acc: 0.3
Batch: 140; loss: 1.92; acc: 0.38
Batch: 160; loss: 1.82; acc: 0.45
Batch: 180; loss: 1.96; acc: 0.28
Batch: 200; loss: 1.91; acc: 0.36
Batch: 220; loss: 1.87; acc: 0.33
Batch: 240; loss: 1.86; acc: 0.22
Batch: 260; loss: 1.77; acc: 0.42
Batch: 280; loss: 1.87; acc: 0.33
Batch: 300; loss: 1.83; acc: 0.34
Batch: 320; loss: 1.84; acc: 0.36
Batch: 340; loss: 1.81; acc: 0.31
Batch: 360; loss: 1.85; acc: 0.22
Batch: 380; loss: 1.77; acc: 0.34
Batch: 400; loss: 1.82; acc: 0.38
Batch: 420; loss: 1.95; acc: 0.3
Batch: 440; loss: 1.71; acc: 0.38
Batch: 460; loss: 1.82; acc: 0.39
Batch: 480; loss: 1.8; acc: 0.42
Batch: 500; loss: 1.87; acc: 0.33
Batch: 520; loss: 1.76; acc: 0.34
Batch: 540; loss: 1.85; acc: 0.28
Batch: 560; loss: 1.64; acc: 0.44
Batch: 580; loss: 2.17; acc: 0.22
Batch: 600; loss: 1.77; acc: 0.45
Batch: 620; loss: 1.82; acc: 0.39
Batch: 640; loss: 1.8; acc: 0.41
Batch: 660; loss: 1.76; acc: 0.34
Batch: 680; loss: 1.84; acc: 0.31
Batch: 700; loss: 1.91; acc: 0.28
Batch: 720; loss: 1.96; acc: 0.3
Batch: 740; loss: 1.93; acc: 0.38
Batch: 760; loss: 1.66; acc: 0.45
Batch: 780; loss: 1.78; acc: 0.44
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.2267873898963444e-05
5.367818630475085e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8302404447725624; val_accuracy: 0.3603702229299363 

The current subspace-distance is: 5.367818630475085e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.9; acc: 0.33
Batch: 20; loss: 1.77; acc: 0.38
Batch: 40; loss: 1.94; acc: 0.34
Batch: 60; loss: 1.81; acc: 0.33
Batch: 80; loss: 1.83; acc: 0.41
Batch: 100; loss: 1.87; acc: 0.36
Batch: 120; loss: 1.72; acc: 0.38
Batch: 140; loss: 1.77; acc: 0.39
Batch: 160; loss: 1.92; acc: 0.28
Batch: 180; loss: 1.95; acc: 0.39
Batch: 200; loss: 1.89; acc: 0.36
Batch: 220; loss: 1.84; acc: 0.36
Batch: 240; loss: 1.94; acc: 0.31
Batch: 260; loss: 1.67; acc: 0.44
Batch: 280; loss: 2.06; acc: 0.28
Batch: 300; loss: 1.83; acc: 0.33
Batch: 320; loss: 1.8; acc: 0.36
Batch: 340; loss: 1.93; acc: 0.31
Batch: 360; loss: 1.98; acc: 0.34
Batch: 380; loss: 1.84; acc: 0.39
Batch: 400; loss: 1.77; acc: 0.38
Batch: 420; loss: 1.81; acc: 0.42
Batch: 440; loss: 2.08; acc: 0.31
Batch: 460; loss: 1.91; acc: 0.33
Batch: 480; loss: 1.79; acc: 0.44
Batch: 500; loss: 1.79; acc: 0.39
Batch: 520; loss: 1.97; acc: 0.36
Batch: 540; loss: 1.8; acc: 0.42
Batch: 560; loss: 1.91; acc: 0.31
Batch: 580; loss: 1.72; acc: 0.42
Batch: 600; loss: 1.96; acc: 0.25
Batch: 620; loss: 1.96; acc: 0.38
Batch: 640; loss: 1.84; acc: 0.42
Batch: 660; loss: 1.77; acc: 0.41
Batch: 680; loss: 1.9; acc: 0.34
Batch: 700; loss: 1.72; acc: 0.34
Batch: 720; loss: 1.83; acc: 0.3
Batch: 740; loss: 1.72; acc: 0.47
Batch: 760; loss: 2.04; acc: 0.28
Batch: 780; loss: 1.99; acc: 0.3
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0371481948823202e-05
5.140802841197001e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8300335505965408; val_accuracy: 0.361265923566879 

The current subspace-distance is: 5.140802841197001e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.62; acc: 0.55
Batch: 20; loss: 1.74; acc: 0.48
Batch: 40; loss: 1.71; acc: 0.47
Batch: 60; loss: 1.77; acc: 0.38
Batch: 80; loss: 1.9; acc: 0.34
Batch: 100; loss: 1.81; acc: 0.36
Batch: 120; loss: 1.78; acc: 0.36
Batch: 140; loss: 1.9; acc: 0.31
Batch: 160; loss: 1.86; acc: 0.36
Batch: 180; loss: 1.93; acc: 0.38
Batch: 200; loss: 1.81; acc: 0.34
Batch: 220; loss: 2.1; acc: 0.3
Batch: 240; loss: 1.75; acc: 0.42
Batch: 260; loss: 1.92; acc: 0.33
Batch: 280; loss: 1.71; acc: 0.48
Batch: 300; loss: 1.81; acc: 0.42
Batch: 320; loss: 1.76; acc: 0.42
Batch: 340; loss: 2.01; acc: 0.22
Batch: 360; loss: 1.78; acc: 0.39
Batch: 380; loss: 1.96; acc: 0.31
Batch: 400; loss: 1.84; acc: 0.33
Batch: 420; loss: 1.81; acc: 0.34
Batch: 440; loss: 1.82; acc: 0.31
Batch: 460; loss: 1.88; acc: 0.34
Batch: 480; loss: 1.88; acc: 0.41
Batch: 500; loss: 2.0; acc: 0.33
Batch: 520; loss: 1.97; acc: 0.25
Batch: 540; loss: 1.9; acc: 0.39
Batch: 560; loss: 1.94; acc: 0.36
Batch: 580; loss: 1.63; acc: 0.39
Batch: 600; loss: 1.73; acc: 0.42
Batch: 620; loss: 1.81; acc: 0.42
Batch: 640; loss: 1.75; acc: 0.36
Batch: 660; loss: 1.72; acc: 0.38
Batch: 680; loss: 1.82; acc: 0.39
Batch: 700; loss: 1.95; acc: 0.31
Batch: 720; loss: 1.74; acc: 0.41
Batch: 740; loss: 1.93; acc: 0.31
Batch: 760; loss: 1.87; acc: 0.34
Batch: 780; loss: 1.97; acc: 0.27
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1517126949911471e-05
5.837247044837568e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299432689217245; val_accuracy: 0.3613654458598726 

The current subspace-distance is: 5.837247044837568e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.98; acc: 0.27
Batch: 20; loss: 1.99; acc: 0.36
Batch: 40; loss: 1.85; acc: 0.38
Batch: 60; loss: 1.75; acc: 0.39
Batch: 80; loss: 1.87; acc: 0.36
Batch: 100; loss: 1.87; acc: 0.33
Batch: 120; loss: 1.81; acc: 0.36
Batch: 140; loss: 1.9; acc: 0.34
Batch: 160; loss: 1.78; acc: 0.41
Batch: 180; loss: 1.9; acc: 0.38
Batch: 200; loss: 1.83; acc: 0.33
Batch: 220; loss: 1.79; acc: 0.42
Batch: 240; loss: 1.93; acc: 0.3
Batch: 260; loss: 1.69; acc: 0.42
Batch: 280; loss: 1.78; acc: 0.39
Batch: 300; loss: 1.94; acc: 0.3
Batch: 320; loss: 1.76; acc: 0.41
Batch: 340; loss: 1.96; acc: 0.27
Batch: 360; loss: 1.82; acc: 0.34
Batch: 380; loss: 1.85; acc: 0.41
Batch: 400; loss: 1.81; acc: 0.39
Batch: 420; loss: 1.88; acc: 0.36
Batch: 440; loss: 1.95; acc: 0.25
Batch: 460; loss: 1.85; acc: 0.33
Batch: 480; loss: 1.86; acc: 0.38
Batch: 500; loss: 1.93; acc: 0.34
Batch: 520; loss: 1.85; acc: 0.38
Batch: 540; loss: 1.82; acc: 0.39
Batch: 560; loss: 1.89; acc: 0.3
Batch: 580; loss: 1.77; acc: 0.41
Batch: 600; loss: 1.78; acc: 0.45
Batch: 620; loss: 1.95; acc: 0.27
Batch: 640; loss: 1.98; acc: 0.3
Batch: 660; loss: 1.82; acc: 0.28
Batch: 680; loss: 1.75; acc: 0.39
Batch: 700; loss: 1.82; acc: 0.34
Batch: 720; loss: 1.97; acc: 0.34
Batch: 740; loss: 1.76; acc: 0.39
Batch: 760; loss: 1.83; acc: 0.41
Batch: 780; loss: 2.06; acc: 0.31
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.662537195254117e-06
3.5547238894650945e-06
Batch: 0; loss: 1.96; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8301575814083124; val_accuracy: 0.35927547770700635 

The current subspace-distance is: 3.5547238894650945e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.81; acc: 0.44
Batch: 20; loss: 1.74; acc: 0.38
Batch: 40; loss: 1.59; acc: 0.48
Batch: 60; loss: 1.91; acc: 0.36
Batch: 80; loss: 1.88; acc: 0.34
Batch: 100; loss: 1.89; acc: 0.36
Batch: 120; loss: 1.76; acc: 0.34
Batch: 140; loss: 1.76; acc: 0.39
Batch: 160; loss: 1.8; acc: 0.3
Batch: 180; loss: 1.97; acc: 0.3
Batch: 200; loss: 1.87; acc: 0.3
Batch: 220; loss: 1.92; acc: 0.3
Batch: 240; loss: 1.72; acc: 0.39
Batch: 260; loss: 1.69; acc: 0.44
Batch: 280; loss: 1.84; acc: 0.34
Batch: 300; loss: 1.81; acc: 0.42
Batch: 320; loss: 1.77; acc: 0.41
Batch: 340; loss: 1.68; acc: 0.42
Batch: 360; loss: 1.62; acc: 0.48
Batch: 380; loss: 1.86; acc: 0.31
Batch: 400; loss: 1.93; acc: 0.3
Batch: 420; loss: 1.77; acc: 0.39
Batch: 440; loss: 1.88; acc: 0.31
Batch: 460; loss: 1.84; acc: 0.39
Batch: 480; loss: 1.8; acc: 0.38
Batch: 500; loss: 1.83; acc: 0.36
Batch: 520; loss: 1.74; acc: 0.36
Batch: 540; loss: 1.89; acc: 0.38
Batch: 560; loss: 1.8; acc: 0.44
Batch: 580; loss: 1.74; acc: 0.38
Batch: 600; loss: 1.92; acc: 0.31
Batch: 620; loss: 1.68; acc: 0.44
Batch: 640; loss: 1.86; acc: 0.38
Batch: 660; loss: 1.75; acc: 0.44
Batch: 680; loss: 1.65; acc: 0.47
Batch: 700; loss: 1.87; acc: 0.34
Batch: 720; loss: 1.9; acc: 0.34
Batch: 740; loss: 1.91; acc: 0.36
Batch: 760; loss: 1.87; acc: 0.33
Batch: 780; loss: 1.84; acc: 0.39
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1267675290582702e-05
3.841501438728301e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8300431321381003; val_accuracy: 0.35977308917197454 

The current subspace-distance is: 3.841501438728301e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.85; acc: 0.31
Batch: 20; loss: 1.69; acc: 0.36
Batch: 40; loss: 1.76; acc: 0.44
Batch: 60; loss: 1.8; acc: 0.36
Batch: 80; loss: 1.78; acc: 0.42
Batch: 100; loss: 1.88; acc: 0.45
Batch: 120; loss: 1.79; acc: 0.45
Batch: 140; loss: 1.79; acc: 0.39
Batch: 160; loss: 1.78; acc: 0.41
Batch: 180; loss: 1.92; acc: 0.3
Batch: 200; loss: 1.77; acc: 0.39
Batch: 220; loss: 1.84; acc: 0.39
Batch: 240; loss: 1.86; acc: 0.42
Batch: 260; loss: 1.74; acc: 0.41
Batch: 280; loss: 1.79; acc: 0.31
Batch: 300; loss: 1.81; acc: 0.41
Batch: 320; loss: 1.7; acc: 0.45
Batch: 340; loss: 1.74; acc: 0.42
Batch: 360; loss: 1.79; acc: 0.42
Batch: 380; loss: 1.96; acc: 0.31
Batch: 400; loss: 1.85; acc: 0.31
Batch: 420; loss: 1.88; acc: 0.38
Batch: 440; loss: 1.97; acc: 0.34
Batch: 460; loss: 1.86; acc: 0.36
Batch: 480; loss: 1.89; acc: 0.28
Batch: 500; loss: 1.66; acc: 0.45
Batch: 520; loss: 1.87; acc: 0.34
Batch: 540; loss: 1.73; acc: 0.38
Batch: 560; loss: 1.9; acc: 0.34
Batch: 580; loss: 2.1; acc: 0.22
Batch: 600; loss: 2.02; acc: 0.27
Batch: 620; loss: 1.73; acc: 0.41
Batch: 640; loss: 1.79; acc: 0.39
Batch: 660; loss: 1.92; acc: 0.31
Batch: 680; loss: 1.77; acc: 0.42
Batch: 700; loss: 1.94; acc: 0.31
Batch: 720; loss: 1.79; acc: 0.36
Batch: 740; loss: 1.94; acc: 0.3
Batch: 760; loss: 1.85; acc: 0.33
Batch: 780; loss: 1.94; acc: 0.33
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.251052688341588e-06
3.90380864701001e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299995873384416; val_accuracy: 0.35947452229299365 

The current subspace-distance is: 3.90380864701001e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.79; acc: 0.41
Batch: 20; loss: 1.96; acc: 0.25
Batch: 40; loss: 1.9; acc: 0.33
Batch: 60; loss: 1.83; acc: 0.34
Batch: 80; loss: 1.89; acc: 0.34
Batch: 100; loss: 2.03; acc: 0.28
Batch: 120; loss: 1.83; acc: 0.34
Batch: 140; loss: 1.94; acc: 0.3
Batch: 160; loss: 2.0; acc: 0.25
Batch: 180; loss: 1.91; acc: 0.39
Batch: 200; loss: 1.93; acc: 0.33
Batch: 220; loss: 1.64; acc: 0.48
Batch: 240; loss: 1.95; acc: 0.33
Batch: 260; loss: 1.82; acc: 0.38
Batch: 280; loss: 1.95; acc: 0.23
Batch: 300; loss: 1.92; acc: 0.28
Batch: 320; loss: 1.7; acc: 0.39
Batch: 340; loss: 1.78; acc: 0.33
Batch: 360; loss: 1.98; acc: 0.36
Batch: 380; loss: 1.8; acc: 0.41
Batch: 400; loss: 1.77; acc: 0.42
Batch: 420; loss: 1.89; acc: 0.34
Batch: 440; loss: 1.84; acc: 0.33
Batch: 460; loss: 1.69; acc: 0.44
Batch: 480; loss: 1.97; acc: 0.3
Batch: 500; loss: 1.84; acc: 0.34
Batch: 520; loss: 1.9; acc: 0.33
Batch: 540; loss: 1.79; acc: 0.36
Batch: 560; loss: 1.86; acc: 0.27
Batch: 580; loss: 1.8; acc: 0.34
Batch: 600; loss: 1.79; acc: 0.36
Batch: 620; loss: 1.91; acc: 0.38
Batch: 640; loss: 1.86; acc: 0.36
Batch: 660; loss: 1.79; acc: 0.39
Batch: 680; loss: 1.81; acc: 0.34
Batch: 700; loss: 1.91; acc: 0.39
Batch: 720; loss: 1.92; acc: 0.31
Batch: 740; loss: 1.69; acc: 0.48
Batch: 760; loss: 1.67; acc: 0.45
Batch: 780; loss: 1.68; acc: 0.44
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0291662874806207e-05
4.975941919838078e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8300078021492927; val_accuracy: 0.3596735668789809 

The current subspace-distance is: 4.975941919838078e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.76; acc: 0.42
Batch: 20; loss: 1.76; acc: 0.45
Batch: 40; loss: 1.6; acc: 0.47
Batch: 60; loss: 1.73; acc: 0.42
Batch: 80; loss: 1.76; acc: 0.34
Batch: 100; loss: 1.71; acc: 0.38
Batch: 120; loss: 1.87; acc: 0.38
Batch: 140; loss: 1.81; acc: 0.34
Batch: 160; loss: 1.99; acc: 0.3
Batch: 180; loss: 1.94; acc: 0.36
Batch: 200; loss: 1.9; acc: 0.33
Batch: 220; loss: 1.85; acc: 0.41
Batch: 240; loss: 1.91; acc: 0.33
Batch: 260; loss: 1.84; acc: 0.45
Batch: 280; loss: 1.95; acc: 0.36
Batch: 300; loss: 1.94; acc: 0.41
Batch: 320; loss: 1.91; acc: 0.42
Batch: 340; loss: 1.82; acc: 0.41
Batch: 360; loss: 1.81; acc: 0.38
Batch: 380; loss: 1.84; acc: 0.31
Batch: 400; loss: 1.77; acc: 0.41
Batch: 420; loss: 1.8; acc: 0.34
Batch: 440; loss: 1.87; acc: 0.31
Batch: 460; loss: 1.8; acc: 0.36
Batch: 480; loss: 1.91; acc: 0.41
Batch: 500; loss: 1.74; acc: 0.45
Batch: 520; loss: 1.9; acc: 0.33
Batch: 540; loss: 1.83; acc: 0.33
Batch: 560; loss: 1.73; acc: 0.38
Batch: 580; loss: 1.74; acc: 0.38
Batch: 600; loss: 1.66; acc: 0.45
Batch: 620; loss: 1.68; acc: 0.45
Batch: 640; loss: 1.95; acc: 0.3
Batch: 660; loss: 1.84; acc: 0.31
Batch: 680; loss: 1.84; acc: 0.38
Batch: 700; loss: 1.88; acc: 0.38
Batch: 720; loss: 1.88; acc: 0.34
Batch: 740; loss: 1.89; acc: 0.36
Batch: 760; loss: 1.83; acc: 0.38
Batch: 780; loss: 1.77; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1828575225081295e-05
4.018567324237665e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8300036503251191; val_accuracy: 0.36017117834394907 

The current subspace-distance is: 4.018567324237665e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.9; acc: 0.28
Batch: 20; loss: 1.92; acc: 0.3
Batch: 40; loss: 1.55; acc: 0.48
Batch: 60; loss: 1.72; acc: 0.45
Batch: 80; loss: 1.78; acc: 0.36
Batch: 100; loss: 1.91; acc: 0.25
Batch: 120; loss: 1.87; acc: 0.34
Batch: 140; loss: 1.85; acc: 0.38
Batch: 160; loss: 1.77; acc: 0.44
Batch: 180; loss: 1.65; acc: 0.47
Batch: 200; loss: 2.1; acc: 0.25
Batch: 220; loss: 1.7; acc: 0.39
Batch: 240; loss: 1.76; acc: 0.36
Batch: 260; loss: 1.88; acc: 0.38
Batch: 280; loss: 1.83; acc: 0.36
Batch: 300; loss: 1.93; acc: 0.36
Batch: 320; loss: 1.77; acc: 0.44
Batch: 340; loss: 1.84; acc: 0.41
Batch: 360; loss: 1.72; acc: 0.41
Batch: 380; loss: 1.94; acc: 0.38
Batch: 400; loss: 1.93; acc: 0.25
Batch: 420; loss: 1.8; acc: 0.34
Batch: 440; loss: 1.76; acc: 0.39
Batch: 460; loss: 1.95; acc: 0.3
Batch: 480; loss: 1.81; acc: 0.36
Batch: 500; loss: 1.93; acc: 0.31
Batch: 520; loss: 1.81; acc: 0.36
Batch: 540; loss: 1.83; acc: 0.41
Batch: 560; loss: 1.76; acc: 0.36
Batch: 580; loss: 1.84; acc: 0.36
Batch: 600; loss: 1.68; acc: 0.39
Batch: 620; loss: 1.8; acc: 0.42
Batch: 640; loss: 1.92; acc: 0.33
Batch: 660; loss: 1.78; acc: 0.44
Batch: 680; loss: 1.87; acc: 0.33
Batch: 700; loss: 1.73; acc: 0.48
Batch: 720; loss: 1.82; acc: 0.33
Batch: 740; loss: 1.96; acc: 0.31
Batch: 760; loss: 1.93; acc: 0.28
Batch: 780; loss: 1.83; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0078982995764818e-05
3.8096175103419228e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299657174736073; val_accuracy: 0.35987261146496813 

The current subspace-distance is: 3.8096175103419228e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.89; acc: 0.33
Batch: 20; loss: 1.95; acc: 0.34
Batch: 40; loss: 1.89; acc: 0.33
Batch: 60; loss: 1.8; acc: 0.36
Batch: 80; loss: 1.65; acc: 0.5
Batch: 100; loss: 1.81; acc: 0.33
Batch: 120; loss: 1.75; acc: 0.41
Batch: 140; loss: 1.82; acc: 0.34
Batch: 160; loss: 1.89; acc: 0.3
Batch: 180; loss: 1.75; acc: 0.42
Batch: 200; loss: 1.99; acc: 0.3
Batch: 220; loss: 1.85; acc: 0.28
Batch: 240; loss: 2.03; acc: 0.25
Batch: 260; loss: 1.75; acc: 0.39
Batch: 280; loss: 1.75; acc: 0.45
Batch: 300; loss: 1.86; acc: 0.38
Batch: 320; loss: 1.97; acc: 0.28
Batch: 340; loss: 1.89; acc: 0.36
Batch: 360; loss: 1.96; acc: 0.34
Batch: 380; loss: 1.85; acc: 0.42
Batch: 400; loss: 1.77; acc: 0.41
Batch: 420; loss: 1.85; acc: 0.33
Batch: 440; loss: 1.61; acc: 0.45
Batch: 460; loss: 1.8; acc: 0.38
Batch: 480; loss: 1.75; acc: 0.42
Batch: 500; loss: 1.7; acc: 0.39
Batch: 520; loss: 1.7; acc: 0.42
Batch: 540; loss: 1.86; acc: 0.31
Batch: 560; loss: 1.79; acc: 0.38
Batch: 580; loss: 1.94; acc: 0.3
Batch: 600; loss: 1.78; acc: 0.41
Batch: 620; loss: 1.79; acc: 0.48
Batch: 640; loss: 1.78; acc: 0.36
Batch: 660; loss: 1.84; acc: 0.38
Batch: 680; loss: 2.0; acc: 0.28
Batch: 700; loss: 1.82; acc: 0.3
Batch: 720; loss: 1.75; acc: 0.48
Batch: 740; loss: 1.8; acc: 0.44
Batch: 760; loss: 1.88; acc: 0.33
Batch: 780; loss: 1.77; acc: 0.44
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.781604603631422e-06
4.979704044671962e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299677166969153; val_accuracy: 0.3600716560509554 

The current subspace-distance is: 4.979704044671962e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.68; acc: 0.48
Batch: 20; loss: 1.67; acc: 0.47
Batch: 40; loss: 1.81; acc: 0.33
Batch: 60; loss: 1.78; acc: 0.44
Batch: 80; loss: 1.66; acc: 0.47
Batch: 100; loss: 1.81; acc: 0.33
Batch: 120; loss: 1.98; acc: 0.28
Batch: 140; loss: 1.87; acc: 0.36
Batch: 160; loss: 1.92; acc: 0.33
Batch: 180; loss: 1.93; acc: 0.23
Batch: 200; loss: 1.84; acc: 0.36
Batch: 220; loss: 1.8; acc: 0.33
Batch: 240; loss: 1.95; acc: 0.27
Batch: 260; loss: 1.64; acc: 0.47
Batch: 280; loss: 1.88; acc: 0.34
Batch: 300; loss: 1.79; acc: 0.36
Batch: 320; loss: 1.78; acc: 0.38
Batch: 340; loss: 1.89; acc: 0.31
Batch: 360; loss: 1.6; acc: 0.45
Batch: 380; loss: 1.85; acc: 0.34
Batch: 400; loss: 1.96; acc: 0.27
Batch: 420; loss: 1.85; acc: 0.28
Batch: 440; loss: 1.89; acc: 0.3
Batch: 460; loss: 2.0; acc: 0.25
Batch: 480; loss: 1.83; acc: 0.36
Batch: 500; loss: 1.67; acc: 0.47
Batch: 520; loss: 1.76; acc: 0.42
Batch: 540; loss: 1.63; acc: 0.48
Batch: 560; loss: 1.68; acc: 0.42
Batch: 580; loss: 1.92; acc: 0.31
Batch: 600; loss: 1.71; acc: 0.38
Batch: 620; loss: 1.91; acc: 0.41
Batch: 640; loss: 1.76; acc: 0.45
Batch: 660; loss: 1.84; acc: 0.39
Batch: 680; loss: 1.72; acc: 0.47
Batch: 700; loss: 1.73; acc: 0.33
Batch: 720; loss: 1.67; acc: 0.41
Batch: 740; loss: 1.84; acc: 0.39
Batch: 760; loss: 1.75; acc: 0.42
Batch: 780; loss: 2.06; acc: 0.27
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

9.991299521061592e-06
4.637028723664116e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299993656243487; val_accuracy: 0.35987261146496813 

The current subspace-distance is: 4.637028723664116e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.93; acc: 0.25
Batch: 20; loss: 1.98; acc: 0.27
Batch: 40; loss: 1.84; acc: 0.36
Batch: 60; loss: 1.92; acc: 0.28
Batch: 80; loss: 1.72; acc: 0.39
Batch: 100; loss: 1.99; acc: 0.27
Batch: 120; loss: 1.8; acc: 0.42
Batch: 140; loss: 1.93; acc: 0.34
Batch: 160; loss: 1.79; acc: 0.38
Batch: 180; loss: 1.96; acc: 0.28
Batch: 200; loss: 1.83; acc: 0.34
Batch: 220; loss: 1.96; acc: 0.34
Batch: 240; loss: 1.81; acc: 0.47
Batch: 260; loss: 1.76; acc: 0.33
Batch: 280; loss: 1.9; acc: 0.34
Batch: 300; loss: 1.87; acc: 0.33
Batch: 320; loss: 1.84; acc: 0.36
Batch: 340; loss: 1.91; acc: 0.38
Batch: 360; loss: 1.88; acc: 0.34
Batch: 380; loss: 1.82; acc: 0.39
Batch: 400; loss: 1.85; acc: 0.38
Batch: 420; loss: 2.04; acc: 0.27
Batch: 440; loss: 1.82; acc: 0.34
Batch: 460; loss: 1.62; acc: 0.45
Batch: 480; loss: 1.83; acc: 0.27
Batch: 500; loss: 1.69; acc: 0.45
Batch: 520; loss: 1.84; acc: 0.41
Batch: 540; loss: 2.01; acc: 0.28
Batch: 560; loss: 1.77; acc: 0.39
Batch: 580; loss: 1.91; acc: 0.38
Batch: 600; loss: 1.89; acc: 0.28
Batch: 620; loss: 1.97; acc: 0.36
Batch: 640; loss: 1.79; acc: 0.34
Batch: 660; loss: 1.8; acc: 0.34
Batch: 680; loss: 2.03; acc: 0.33
Batch: 700; loss: 1.95; acc: 0.31
Batch: 720; loss: 1.83; acc: 0.38
Batch: 740; loss: 2.07; acc: 0.28
Batch: 760; loss: 2.21; acc: 0.2
Batch: 780; loss: 2.04; acc: 0.2
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.0698598089220468e-05
5.115572093927767e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299850445644112; val_accuracy: 0.3596735668789809 

The current subspace-distance is: 5.115572093927767e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.79; acc: 0.44
Batch: 20; loss: 1.99; acc: 0.33
Batch: 40; loss: 1.73; acc: 0.39
Batch: 60; loss: 1.54; acc: 0.58
Batch: 80; loss: 1.82; acc: 0.42
Batch: 100; loss: 1.78; acc: 0.31
Batch: 120; loss: 1.8; acc: 0.31
Batch: 140; loss: 1.79; acc: 0.44
Batch: 160; loss: 1.82; acc: 0.34
Batch: 180; loss: 2.02; acc: 0.3
Batch: 200; loss: 2.0; acc: 0.3
Batch: 220; loss: 1.88; acc: 0.31
Batch: 240; loss: 1.9; acc: 0.3
Batch: 260; loss: 1.72; acc: 0.44
Batch: 280; loss: 1.72; acc: 0.38
Batch: 300; loss: 1.93; acc: 0.33
Batch: 320; loss: 1.95; acc: 0.36
Batch: 340; loss: 1.84; acc: 0.38
Batch: 360; loss: 1.78; acc: 0.38
Batch: 380; loss: 1.92; acc: 0.39
Batch: 400; loss: 1.97; acc: 0.3
Batch: 420; loss: 1.65; acc: 0.41
Batch: 440; loss: 1.85; acc: 0.41
Batch: 460; loss: 1.78; acc: 0.45
Batch: 480; loss: 1.73; acc: 0.42
Batch: 500; loss: 1.86; acc: 0.36
Batch: 520; loss: 1.89; acc: 0.36
Batch: 540; loss: 1.96; acc: 0.34
Batch: 560; loss: 1.88; acc: 0.34
Batch: 580; loss: 1.79; acc: 0.41
Batch: 600; loss: 1.84; acc: 0.36
Batch: 620; loss: 1.92; acc: 0.3
Batch: 640; loss: 1.74; acc: 0.45
Batch: 660; loss: 1.77; acc: 0.41
Batch: 680; loss: 1.88; acc: 0.41
Batch: 700; loss: 1.78; acc: 0.42
Batch: 720; loss: 1.7; acc: 0.41
Batch: 740; loss: 1.86; acc: 0.34
Batch: 760; loss: 2.0; acc: 0.27
Batch: 780; loss: 1.82; acc: 0.39
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.1303197425149847e-05
4.1501930354570504e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.39
Batch: 60; loss: 1.74; acc: 0.39
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.3
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8300897733421082; val_accuracy: 0.35897691082802546 

The current subspace-distance is: 4.1501930354570504e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.75; acc: 0.5
Batch: 20; loss: 1.97; acc: 0.28
Batch: 40; loss: 1.76; acc: 0.36
Batch: 60; loss: 1.8; acc: 0.39
Batch: 80; loss: 1.82; acc: 0.36
Batch: 100; loss: 1.93; acc: 0.36
Batch: 120; loss: 1.78; acc: 0.42
Batch: 140; loss: 1.92; acc: 0.34
Batch: 160; loss: 1.82; acc: 0.34
Batch: 180; loss: 2.02; acc: 0.31
Batch: 200; loss: 1.8; acc: 0.39
Batch: 220; loss: 1.92; acc: 0.27
Batch: 240; loss: 1.89; acc: 0.34
Batch: 260; loss: 1.78; acc: 0.48
Batch: 280; loss: 1.88; acc: 0.33
Batch: 300; loss: 1.85; acc: 0.3
Batch: 320; loss: 1.95; acc: 0.28
Batch: 340; loss: 1.89; acc: 0.38
Batch: 360; loss: 1.84; acc: 0.34
Batch: 380; loss: 2.08; acc: 0.31
Batch: 400; loss: 1.74; acc: 0.39
Batch: 420; loss: 1.66; acc: 0.52
Batch: 440; loss: 2.0; acc: 0.28
Batch: 460; loss: 1.81; acc: 0.41
Batch: 480; loss: 1.79; acc: 0.38
Batch: 500; loss: 1.88; acc: 0.39
Batch: 520; loss: 1.94; acc: 0.25
Batch: 540; loss: 1.85; acc: 0.38
Batch: 560; loss: 1.95; acc: 0.31
Batch: 580; loss: 1.85; acc: 0.34
Batch: 600; loss: 1.72; acc: 0.42
Batch: 620; loss: 1.79; acc: 0.45
Batch: 640; loss: 1.79; acc: 0.3
Batch: 660; loss: 1.77; acc: 0.44
Batch: 680; loss: 2.13; acc: 0.22
Batch: 700; loss: 2.09; acc: 0.25
Batch: 720; loss: 1.97; acc: 0.31
Batch: 740; loss: 1.75; acc: 0.44
Batch: 760; loss: 1.8; acc: 0.38
Batch: 780; loss: 1.74; acc: 0.41
Train Epoch over. train_loss: 1.85; train_accuracy: 0.36 

1.026527115755016e-05
4.8209635679086205e-06
Batch: 0; loss: 1.95; acc: 0.33
Batch: 20; loss: 1.98; acc: 0.22
Batch: 40; loss: 1.62; acc: 0.41
Batch: 60; loss: 1.74; acc: 0.41
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.9; acc: 0.28
Batch: 120; loss: 1.82; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Val Epoch over. val_loss: 1.8299541723955968; val_accuracy: 0.3600716560509554 

The current subspace-distance is: 4.8209635679086205e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_25_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 10558
elements in E: 2221300
fraction nonzero: 0.004753072525097915
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.32; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.32; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.12
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.31; acc: 0.03
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.3; acc: 0.08
Batch: 420; loss: 2.3; acc: 0.12
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.29; acc: 0.05
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.31; acc: 0.11
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.14
Batch: 620; loss: 2.3; acc: 0.06
Batch: 640; loss: 2.29; acc: 0.06
Batch: 660; loss: 2.3; acc: 0.06
Batch: 680; loss: 2.28; acc: 0.16
Batch: 700; loss: 2.28; acc: 0.11
Batch: 720; loss: 2.3; acc: 0.12
Batch: 740; loss: 2.3; acc: 0.08
Batch: 760; loss: 2.3; acc: 0.11
Batch: 780; loss: 2.29; acc: 0.14
Train Epoch over. train_loss: 2.3; train_accuracy: 0.1 

2.933303676400101e-06
4.500341503899108e-07
Batch: 0; loss: 2.29; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.11
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.11
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.12
Val Epoch over. val_loss: 2.2904192247208517; val_accuracy: 0.10718550955414012 

The current subspace-distance is: 4.500341503899108e-07 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.09
Batch: 20; loss: 2.3; acc: 0.08
Batch: 40; loss: 2.29; acc: 0.12
Batch: 60; loss: 2.28; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.11
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.29; acc: 0.08
Batch: 160; loss: 2.3; acc: 0.11
Batch: 180; loss: 2.29; acc: 0.19
Batch: 200; loss: 2.28; acc: 0.12
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.28; acc: 0.22
Batch: 260; loss: 2.29; acc: 0.11
Batch: 280; loss: 2.28; acc: 0.16
Batch: 300; loss: 2.29; acc: 0.12
Batch: 320; loss: 2.29; acc: 0.14
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.28; acc: 0.22
Batch: 400; loss: 2.28; acc: 0.19
Batch: 420; loss: 2.29; acc: 0.16
Batch: 440; loss: 2.28; acc: 0.14
Batch: 460; loss: 2.28; acc: 0.23
Batch: 480; loss: 2.27; acc: 0.25
Batch: 500; loss: 2.28; acc: 0.23
Batch: 520; loss: 2.29; acc: 0.11
Batch: 540; loss: 2.27; acc: 0.19
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.27; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.16
Batch: 620; loss: 2.28; acc: 0.11
Batch: 640; loss: 2.28; acc: 0.2
Batch: 660; loss: 2.27; acc: 0.14
Batch: 680; loss: 2.28; acc: 0.14
Batch: 700; loss: 2.27; acc: 0.14
Batch: 720; loss: 2.27; acc: 0.14
Batch: 740; loss: 2.28; acc: 0.12
Batch: 760; loss: 2.27; acc: 0.17
Batch: 780; loss: 2.27; acc: 0.12
Train Epoch over. train_loss: 2.28; train_accuracy: 0.15 

4.186823389318306e-06
1.2422675581547082e-06
Batch: 0; loss: 2.27; acc: 0.17
Batch: 20; loss: 2.28; acc: 0.11
Batch: 40; loss: 2.27; acc: 0.09
Batch: 60; loss: 2.27; acc: 0.16
Batch: 80; loss: 2.24; acc: 0.25
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.29; acc: 0.08
Batch: 140; loss: 2.26; acc: 0.12
Val Epoch over. val_loss: 2.2677232247249335; val_accuracy: 0.1532643312101911 

The current subspace-distance is: 1.2422675581547082e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.27; acc: 0.16
Batch: 20; loss: 2.27; acc: 0.12
Batch: 40; loss: 2.26; acc: 0.22
Batch: 60; loss: 2.3; acc: 0.03
Batch: 80; loss: 2.26; acc: 0.19
Batch: 100; loss: 2.26; acc: 0.17
Batch: 120; loss: 2.27; acc: 0.14
Batch: 140; loss: 2.25; acc: 0.16
Batch: 160; loss: 2.24; acc: 0.2
Batch: 180; loss: 2.24; acc: 0.19
Batch: 200; loss: 2.25; acc: 0.2
Batch: 220; loss: 2.26; acc: 0.14
Batch: 240; loss: 2.22; acc: 0.23
Batch: 260; loss: 2.24; acc: 0.22
Batch: 280; loss: 2.22; acc: 0.25
Batch: 300; loss: 2.24; acc: 0.2
Batch: 320; loss: 2.19; acc: 0.23
Batch: 340; loss: 2.22; acc: 0.19
Batch: 360; loss: 2.19; acc: 0.33
Batch: 380; loss: 2.17; acc: 0.3
Batch: 400; loss: 2.22; acc: 0.16
Batch: 420; loss: 2.22; acc: 0.2
Batch: 440; loss: 2.24; acc: 0.16
Batch: 460; loss: 2.15; acc: 0.27
Batch: 480; loss: 2.18; acc: 0.23
Batch: 500; loss: 2.14; acc: 0.25
Batch: 520; loss: 2.21; acc: 0.25
Batch: 540; loss: 2.19; acc: 0.22
Batch: 560; loss: 2.08; acc: 0.3
Batch: 580; loss: 2.04; acc: 0.34
Batch: 600; loss: 2.14; acc: 0.23
Batch: 620; loss: 2.09; acc: 0.27
Batch: 640; loss: 2.1; acc: 0.28
Batch: 660; loss: 2.05; acc: 0.3
Batch: 680; loss: 2.1; acc: 0.19
Batch: 700; loss: 2.0; acc: 0.25
Batch: 720; loss: 1.85; acc: 0.38
Batch: 740; loss: 1.95; acc: 0.27
Batch: 760; loss: 1.98; acc: 0.3
Batch: 780; loss: 1.97; acc: 0.34
Train Epoch over. train_loss: 2.17; train_accuracy: 0.22 

8.395059012400452e-06
3.6354681469674688e-06
Batch: 0; loss: 1.87; acc: 0.34
Batch: 20; loss: 1.85; acc: 0.41
Batch: 40; loss: 1.69; acc: 0.39
Batch: 60; loss: 1.88; acc: 0.34
Batch: 80; loss: 1.72; acc: 0.42
Batch: 100; loss: 1.78; acc: 0.38
Batch: 120; loss: 1.86; acc: 0.34
Batch: 140; loss: 1.7; acc: 0.52
Val Epoch over. val_loss: 1.8518374892556744; val_accuracy: 0.354796974522293 

The current subspace-distance is: 3.6354681469674688e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.83; acc: 0.39
Batch: 20; loss: 1.86; acc: 0.34
Batch: 40; loss: 1.95; acc: 0.28
Batch: 60; loss: 1.89; acc: 0.31
Batch: 80; loss: 1.75; acc: 0.45
Batch: 100; loss: 1.65; acc: 0.38
Batch: 120; loss: 1.6; acc: 0.48
Batch: 140; loss: 1.78; acc: 0.38
Batch: 160; loss: 1.63; acc: 0.45
Batch: 180; loss: 1.7; acc: 0.44
Batch: 200; loss: 1.72; acc: 0.39
Batch: 220; loss: 1.73; acc: 0.36
Batch: 240; loss: 1.57; acc: 0.36
Batch: 260; loss: 1.61; acc: 0.42
Batch: 280; loss: 1.66; acc: 0.42
Batch: 300; loss: 1.48; acc: 0.44
Batch: 320; loss: 1.44; acc: 0.45
Batch: 340; loss: 1.56; acc: 0.48
Batch: 360; loss: 1.61; acc: 0.36
Batch: 380; loss: 1.52; acc: 0.5
Batch: 400; loss: 1.42; acc: 0.5
Batch: 420; loss: 1.41; acc: 0.5
Batch: 440; loss: 1.53; acc: 0.45
Batch: 460; loss: 1.43; acc: 0.48
Batch: 480; loss: 1.31; acc: 0.62
Batch: 500; loss: 1.51; acc: 0.47
Batch: 520; loss: 1.57; acc: 0.42
Batch: 540; loss: 1.48; acc: 0.5
Batch: 560; loss: 1.55; acc: 0.44
Batch: 580; loss: 1.41; acc: 0.55
Batch: 600; loss: 1.62; acc: 0.47
Batch: 620; loss: 1.49; acc: 0.55
Batch: 640; loss: 1.59; acc: 0.52
Batch: 660; loss: 1.49; acc: 0.52
Batch: 680; loss: 1.65; acc: 0.38
Batch: 700; loss: 1.71; acc: 0.41
Batch: 720; loss: 1.28; acc: 0.58
Batch: 740; loss: 1.46; acc: 0.53
Batch: 760; loss: 1.63; acc: 0.56
Batch: 780; loss: 1.22; acc: 0.53
Train Epoch over. train_loss: 1.59; train_accuracy: 0.44 

1.32517152451328e-05
5.139123913977528e-06
Batch: 0; loss: 1.67; acc: 0.44
Batch: 20; loss: 1.38; acc: 0.56
Batch: 40; loss: 1.23; acc: 0.53
Batch: 60; loss: 1.58; acc: 0.45
Batch: 80; loss: 1.3; acc: 0.47
Batch: 100; loss: 1.26; acc: 0.59
Batch: 120; loss: 1.44; acc: 0.42
Batch: 140; loss: 1.23; acc: 0.66
Val Epoch over. val_loss: 1.4123052294087257; val_accuracy: 0.5134355095541401 

The current subspace-distance is: 5.139123913977528e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.67; acc: 0.47
Batch: 20; loss: 1.75; acc: 0.44
Batch: 40; loss: 1.19; acc: 0.55
Batch: 60; loss: 1.57; acc: 0.42
Batch: 80; loss: 1.45; acc: 0.47
Batch: 100; loss: 1.47; acc: 0.38
Batch: 120; loss: 1.4; acc: 0.52
Batch: 140; loss: 1.24; acc: 0.56
Batch: 160; loss: 1.39; acc: 0.45
Batch: 180; loss: 1.55; acc: 0.45
Batch: 200; loss: 1.33; acc: 0.47
Batch: 220; loss: 1.31; acc: 0.52
Batch: 240; loss: 1.58; acc: 0.56
Batch: 260; loss: 1.34; acc: 0.52
Batch: 280; loss: 1.17; acc: 0.56
Batch: 300; loss: 1.37; acc: 0.52
Batch: 320; loss: 1.43; acc: 0.55
Batch: 340; loss: 1.39; acc: 0.56
Batch: 360; loss: 1.21; acc: 0.55
Batch: 380; loss: 1.31; acc: 0.66
Batch: 400; loss: 1.45; acc: 0.44
Batch: 420; loss: 1.53; acc: 0.55
Batch: 440; loss: 1.58; acc: 0.5
Batch: 460; loss: 1.16; acc: 0.61
Batch: 480; loss: 1.3; acc: 0.5
Batch: 500; loss: 1.26; acc: 0.58
Batch: 520; loss: 1.74; acc: 0.42
Batch: 540; loss: 1.44; acc: 0.48
Batch: 560; loss: 1.09; acc: 0.69
Batch: 580; loss: 1.29; acc: 0.56
Batch: 600; loss: 0.86; acc: 0.73
Batch: 620; loss: 1.06; acc: 0.64
Batch: 640; loss: 1.33; acc: 0.58
Batch: 660; loss: 1.42; acc: 0.55
Batch: 680; loss: 1.33; acc: 0.52
Batch: 700; loss: 1.25; acc: 0.56
Batch: 720; loss: 1.06; acc: 0.66
Batch: 740; loss: 1.22; acc: 0.58
Batch: 760; loss: 1.41; acc: 0.52
Batch: 780; loss: 1.11; acc: 0.66
Train Epoch over. train_loss: 1.38; train_accuracy: 0.53 

1.705257272988092e-05
5.662930107064312e-06
Batch: 0; loss: 1.43; acc: 0.5
Batch: 20; loss: 1.41; acc: 0.42
Batch: 40; loss: 1.13; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.13; acc: 0.67
Batch: 120; loss: 1.51; acc: 0.42
Batch: 140; loss: 1.27; acc: 0.58
Val Epoch over. val_loss: 1.2954325436786482; val_accuracy: 0.5596138535031847 

The current subspace-distance is: 5.662930107064312e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.29; acc: 0.58
Batch: 20; loss: 1.26; acc: 0.61
Batch: 40; loss: 1.09; acc: 0.67
Batch: 60; loss: 1.15; acc: 0.59
Batch: 80; loss: 1.24; acc: 0.61
Batch: 100; loss: 1.1; acc: 0.62
Batch: 120; loss: 1.26; acc: 0.55
Batch: 140; loss: 1.43; acc: 0.56
Batch: 160; loss: 1.47; acc: 0.52
Batch: 180; loss: 1.42; acc: 0.47
Batch: 200; loss: 1.27; acc: 0.62
Batch: 220; loss: 1.08; acc: 0.69
Batch: 240; loss: 1.35; acc: 0.64
Batch: 260; loss: 1.4; acc: 0.55
Batch: 280; loss: 1.29; acc: 0.56
Batch: 300; loss: 1.54; acc: 0.53
Batch: 320; loss: 1.29; acc: 0.59
Batch: 340; loss: 1.32; acc: 0.55
Batch: 360; loss: 1.33; acc: 0.59
Batch: 380; loss: 1.39; acc: 0.52
Batch: 400; loss: 1.23; acc: 0.56
Batch: 420; loss: 1.28; acc: 0.64
Batch: 440; loss: 1.37; acc: 0.45
Batch: 460; loss: 1.23; acc: 0.5
Batch: 480; loss: 1.23; acc: 0.55
Batch: 500; loss: 1.21; acc: 0.58
Batch: 520; loss: 1.14; acc: 0.62
Batch: 540; loss: 1.1; acc: 0.62
Batch: 560; loss: 1.17; acc: 0.56
Batch: 580; loss: 1.24; acc: 0.55
Batch: 600; loss: 1.03; acc: 0.66
Batch: 620; loss: 1.12; acc: 0.61
Batch: 640; loss: 1.41; acc: 0.55
Batch: 660; loss: 1.14; acc: 0.61
Batch: 680; loss: 1.07; acc: 0.67
Batch: 700; loss: 1.43; acc: 0.53
Batch: 720; loss: 1.4; acc: 0.5
Batch: 740; loss: 1.26; acc: 0.53
Batch: 760; loss: 1.42; acc: 0.52
Batch: 780; loss: 1.6; acc: 0.55
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.7376603864249773e-05
4.8678898565412965e-06
Batch: 0; loss: 1.4; acc: 0.45
Batch: 20; loss: 1.31; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.62
Batch: 60; loss: 1.37; acc: 0.62
Batch: 80; loss: 1.11; acc: 0.66
Batch: 100; loss: 1.06; acc: 0.67
Batch: 120; loss: 1.43; acc: 0.5
Batch: 140; loss: 1.21; acc: 0.55
Val Epoch over. val_loss: 1.26160417392755; val_accuracy: 0.5765326433121019 

The current subspace-distance is: 4.8678898565412965e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.46; acc: 0.52
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 1.05; acc: 0.62
Batch: 60; loss: 1.34; acc: 0.59
Batch: 80; loss: 1.4; acc: 0.62
Batch: 100; loss: 1.44; acc: 0.5
Batch: 120; loss: 1.5; acc: 0.48
Batch: 140; loss: 1.32; acc: 0.52
Batch: 160; loss: 1.21; acc: 0.66
Batch: 180; loss: 1.25; acc: 0.58
Batch: 200; loss: 1.35; acc: 0.53
Batch: 220; loss: 1.22; acc: 0.61
Batch: 240; loss: 1.39; acc: 0.53
Batch: 260; loss: 1.06; acc: 0.62
Batch: 280; loss: 1.41; acc: 0.56
Batch: 300; loss: 1.24; acc: 0.47
Batch: 320; loss: 1.52; acc: 0.48
Batch: 340; loss: 1.14; acc: 0.61
Batch: 360; loss: 1.03; acc: 0.66
Batch: 380; loss: 1.33; acc: 0.53
Batch: 400; loss: 1.22; acc: 0.69
Batch: 420; loss: 1.04; acc: 0.7
Batch: 440; loss: 1.26; acc: 0.52
Batch: 460; loss: 1.21; acc: 0.62
Batch: 480; loss: 1.19; acc: 0.67
Batch: 500; loss: 1.19; acc: 0.59
Batch: 520; loss: 1.23; acc: 0.58
Batch: 540; loss: 1.3; acc: 0.56
Batch: 560; loss: 1.16; acc: 0.61
Batch: 580; loss: 1.39; acc: 0.52
Batch: 600; loss: 1.31; acc: 0.59
Batch: 620; loss: 1.33; acc: 0.64
Batch: 640; loss: 0.9; acc: 0.69
Batch: 660; loss: 1.43; acc: 0.48
Batch: 680; loss: 1.31; acc: 0.55
Batch: 700; loss: 1.4; acc: 0.55
Batch: 720; loss: 1.47; acc: 0.42
Batch: 740; loss: 1.45; acc: 0.62
Batch: 760; loss: 1.41; acc: 0.52
Batch: 780; loss: 1.48; acc: 0.52
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.6345848052878864e-05
6.149532509880373e-06
Batch: 0; loss: 1.41; acc: 0.47
Batch: 20; loss: 1.42; acc: 0.47
Batch: 40; loss: 1.1; acc: 0.66
Batch: 60; loss: 1.32; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.66
Batch: 120; loss: 1.43; acc: 0.48
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.2694726681253712; val_accuracy: 0.5842953821656051 

The current subspace-distance is: 6.149532509880373e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.26; acc: 0.56
Batch: 20; loss: 1.2; acc: 0.64
Batch: 40; loss: 1.3; acc: 0.55
Batch: 60; loss: 1.05; acc: 0.61
Batch: 80; loss: 1.24; acc: 0.58
Batch: 100; loss: 1.53; acc: 0.52
Batch: 120; loss: 1.26; acc: 0.62
Batch: 140; loss: 1.32; acc: 0.55
Batch: 160; loss: 1.47; acc: 0.59
Batch: 180; loss: 1.33; acc: 0.55
Batch: 200; loss: 1.41; acc: 0.59
Batch: 220; loss: 1.24; acc: 0.64
Batch: 240; loss: 1.36; acc: 0.58
Batch: 260; loss: 1.4; acc: 0.53
Batch: 280; loss: 1.21; acc: 0.59
Batch: 300; loss: 1.12; acc: 0.64
Batch: 320; loss: 1.46; acc: 0.55
Batch: 340; loss: 1.5; acc: 0.53
Batch: 360; loss: 1.25; acc: 0.48
Batch: 380; loss: 1.31; acc: 0.59
Batch: 400; loss: 1.43; acc: 0.55
Batch: 420; loss: 1.36; acc: 0.5
Batch: 440; loss: 1.23; acc: 0.59
Batch: 460; loss: 1.31; acc: 0.53
Batch: 480; loss: 1.13; acc: 0.64
Batch: 500; loss: 1.41; acc: 0.59
Batch: 520; loss: 1.52; acc: 0.45
Batch: 540; loss: 1.35; acc: 0.61
Batch: 560; loss: 1.3; acc: 0.59
Batch: 580; loss: 1.5; acc: 0.53
Batch: 600; loss: 1.41; acc: 0.5
Batch: 620; loss: 1.11; acc: 0.66
Batch: 640; loss: 1.11; acc: 0.64
Batch: 660; loss: 1.21; acc: 0.55
Batch: 680; loss: 1.58; acc: 0.45
Batch: 700; loss: 1.54; acc: 0.52
Batch: 720; loss: 1.13; acc: 0.61
Batch: 740; loss: 1.16; acc: 0.66
Batch: 760; loss: 1.69; acc: 0.47
Batch: 780; loss: 1.59; acc: 0.39
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.5867566617089324e-05
5.369543487176998e-06
Batch: 0; loss: 1.39; acc: 0.42
Batch: 20; loss: 1.41; acc: 0.5
Batch: 40; loss: 1.1; acc: 0.62
Batch: 60; loss: 1.35; acc: 0.69
Batch: 80; loss: 1.05; acc: 0.64
Batch: 100; loss: 1.04; acc: 0.66
Batch: 120; loss: 1.45; acc: 0.47
Batch: 140; loss: 1.24; acc: 0.55
Val Epoch over. val_loss: 1.2581192065196432; val_accuracy: 0.5842953821656051 

The current subspace-distance is: 5.369543487176998e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.13; acc: 0.62
Batch: 20; loss: 1.1; acc: 0.59
Batch: 40; loss: 1.49; acc: 0.5
Batch: 60; loss: 1.27; acc: 0.64
Batch: 80; loss: 1.1; acc: 0.66
Batch: 100; loss: 1.31; acc: 0.58
Batch: 120; loss: 1.19; acc: 0.64
Batch: 140; loss: 1.28; acc: 0.62
Batch: 160; loss: 1.26; acc: 0.66
Batch: 180; loss: 1.53; acc: 0.5
Batch: 200; loss: 1.15; acc: 0.66
Batch: 220; loss: 1.29; acc: 0.61
Batch: 240; loss: 1.4; acc: 0.61
Batch: 260; loss: 1.14; acc: 0.62
Batch: 280; loss: 0.92; acc: 0.77
Batch: 300; loss: 1.42; acc: 0.61
Batch: 320; loss: 1.63; acc: 0.53
Batch: 340; loss: 1.4; acc: 0.55
Batch: 360; loss: 0.99; acc: 0.64
Batch: 380; loss: 1.47; acc: 0.53
Batch: 400; loss: 1.37; acc: 0.5
Batch: 420; loss: 1.59; acc: 0.53
Batch: 440; loss: 1.34; acc: 0.53
Batch: 460; loss: 1.27; acc: 0.58
Batch: 480; loss: 1.4; acc: 0.56
Batch: 500; loss: 1.34; acc: 0.62
Batch: 520; loss: 1.21; acc: 0.56
Batch: 540; loss: 1.31; acc: 0.58
Batch: 560; loss: 1.24; acc: 0.52
Batch: 580; loss: 1.53; acc: 0.45
Batch: 600; loss: 1.36; acc: 0.5
Batch: 620; loss: 1.14; acc: 0.61
Batch: 640; loss: 1.52; acc: 0.45
Batch: 660; loss: 1.46; acc: 0.53
Batch: 680; loss: 1.16; acc: 0.56
Batch: 700; loss: 1.47; acc: 0.53
Batch: 720; loss: 1.52; acc: 0.53
Batch: 740; loss: 1.19; acc: 0.61
Batch: 760; loss: 0.98; acc: 0.67
Batch: 780; loss: 1.21; acc: 0.58
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.789965244824998e-05
6.503254098788602e-06
Batch: 0; loss: 1.46; acc: 0.44
Batch: 20; loss: 1.39; acc: 0.55
Batch: 40; loss: 1.15; acc: 0.64
Batch: 60; loss: 1.37; acc: 0.67
Batch: 80; loss: 1.1; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.48; acc: 0.5
Batch: 140; loss: 1.17; acc: 0.55
Val Epoch over. val_loss: 1.2681788916041137; val_accuracy: 0.5963375796178344 

The current subspace-distance is: 6.503254098788602e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.21; acc: 0.61
Batch: 20; loss: 1.69; acc: 0.47
Batch: 40; loss: 1.15; acc: 0.69
Batch: 60; loss: 1.4; acc: 0.53
Batch: 80; loss: 1.55; acc: 0.61
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.2; acc: 0.58
Batch: 140; loss: 1.34; acc: 0.61
Batch: 160; loss: 1.1; acc: 0.64
Batch: 180; loss: 1.24; acc: 0.56
Batch: 200; loss: 1.18; acc: 0.59
Batch: 220; loss: 1.23; acc: 0.55
Batch: 240; loss: 1.05; acc: 0.64
Batch: 260; loss: 1.41; acc: 0.59
Batch: 280; loss: 1.35; acc: 0.52
Batch: 300; loss: 1.33; acc: 0.5
Batch: 320; loss: 1.08; acc: 0.67
Batch: 340; loss: 1.49; acc: 0.44
Batch: 360; loss: 1.24; acc: 0.58
Batch: 380; loss: 1.46; acc: 0.55
Batch: 400; loss: 0.98; acc: 0.66
Batch: 420; loss: 1.16; acc: 0.61
Batch: 440; loss: 1.2; acc: 0.58
Batch: 460; loss: 1.59; acc: 0.55
Batch: 480; loss: 1.25; acc: 0.62
Batch: 500; loss: 1.29; acc: 0.62
Batch: 520; loss: 1.38; acc: 0.52
Batch: 540; loss: 1.29; acc: 0.61
Batch: 560; loss: 1.31; acc: 0.56
Batch: 580; loss: 1.48; acc: 0.66
Batch: 600; loss: 1.57; acc: 0.41
Batch: 620; loss: 1.44; acc: 0.58
Batch: 640; loss: 1.64; acc: 0.41
Batch: 660; loss: 1.5; acc: 0.62
Batch: 680; loss: 1.1; acc: 0.61
Batch: 700; loss: 1.4; acc: 0.45
Batch: 720; loss: 1.42; acc: 0.56
Batch: 740; loss: 1.28; acc: 0.58
Batch: 760; loss: 1.33; acc: 0.55
Batch: 780; loss: 1.35; acc: 0.52
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.5035501746751834e-05
5.728308678953908e-06
Batch: 0; loss: 1.53; acc: 0.38
Batch: 20; loss: 1.61; acc: 0.45
Batch: 40; loss: 1.24; acc: 0.58
Batch: 60; loss: 1.42; acc: 0.64
Batch: 80; loss: 1.15; acc: 0.66
Batch: 100; loss: 1.24; acc: 0.52
Batch: 120; loss: 1.65; acc: 0.39
Batch: 140; loss: 1.4; acc: 0.56
Val Epoch over. val_loss: 1.370481209010835; val_accuracy: 0.5550358280254777 

The current subspace-distance is: 5.728308678953908e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.41; acc: 0.5
Batch: 20; loss: 1.2; acc: 0.58
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.24; acc: 0.64
Batch: 80; loss: 1.35; acc: 0.52
Batch: 100; loss: 1.27; acc: 0.58
Batch: 120; loss: 1.16; acc: 0.61
Batch: 140; loss: 1.54; acc: 0.53
Batch: 160; loss: 1.1; acc: 0.58
Batch: 180; loss: 1.27; acc: 0.59
Batch: 200; loss: 1.28; acc: 0.62
Batch: 220; loss: 1.19; acc: 0.59
Batch: 240; loss: 1.06; acc: 0.61
Batch: 260; loss: 1.29; acc: 0.59
Batch: 280; loss: 1.1; acc: 0.61
Batch: 300; loss: 1.16; acc: 0.58
Batch: 320; loss: 1.52; acc: 0.42
Batch: 340; loss: 1.26; acc: 0.62
Batch: 360; loss: 1.34; acc: 0.56
Batch: 380; loss: 1.11; acc: 0.61
Batch: 400; loss: 1.42; acc: 0.55
Batch: 420; loss: 1.28; acc: 0.56
Batch: 440; loss: 1.24; acc: 0.64
Batch: 460; loss: 1.16; acc: 0.69
Batch: 480; loss: 1.52; acc: 0.5
Batch: 500; loss: 0.97; acc: 0.62
Batch: 520; loss: 1.29; acc: 0.64
Batch: 540; loss: 1.31; acc: 0.61
Batch: 560; loss: 1.17; acc: 0.59
Batch: 580; loss: 1.28; acc: 0.67
Batch: 600; loss: 1.43; acc: 0.56
Batch: 620; loss: 1.06; acc: 0.64
Batch: 640; loss: 1.12; acc: 0.66
Batch: 660; loss: 1.38; acc: 0.55
Batch: 680; loss: 1.36; acc: 0.53
Batch: 700; loss: 1.59; acc: 0.48
Batch: 720; loss: 1.26; acc: 0.61
Batch: 740; loss: 1.36; acc: 0.59
Batch: 760; loss: 1.51; acc: 0.53
Batch: 780; loss: 1.34; acc: 0.53
Train Epoch over. train_loss: 1.29; train_accuracy: 0.58 

1.6329300706274807e-05
6.345928795781219e-06
Batch: 0; loss: 1.38; acc: 0.47
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.7
Batch: 100; loss: 1.06; acc: 0.66
Batch: 120; loss: 1.45; acc: 0.47
Batch: 140; loss: 1.21; acc: 0.58
Val Epoch over. val_loss: 1.2448240621074749; val_accuracy: 0.5922571656050956 

The current subspace-distance is: 6.345928795781219e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.33; acc: 0.56
Batch: 20; loss: 1.19; acc: 0.61
Batch: 40; loss: 1.56; acc: 0.44
Batch: 60; loss: 1.04; acc: 0.72
Batch: 80; loss: 1.35; acc: 0.56
Batch: 100; loss: 1.23; acc: 0.56
Batch: 120; loss: 1.14; acc: 0.64
Batch: 140; loss: 0.85; acc: 0.7
Batch: 160; loss: 1.34; acc: 0.53
Batch: 180; loss: 1.19; acc: 0.53
Batch: 200; loss: 1.24; acc: 0.62
Batch: 220; loss: 1.34; acc: 0.62
Batch: 240; loss: 1.14; acc: 0.62
Batch: 260; loss: 1.61; acc: 0.52
Batch: 280; loss: 1.23; acc: 0.59
Batch: 300; loss: 1.32; acc: 0.56
Batch: 320; loss: 1.46; acc: 0.52
Batch: 340; loss: 1.31; acc: 0.55
Batch: 360; loss: 1.33; acc: 0.56
Batch: 380; loss: 1.11; acc: 0.53
Batch: 400; loss: 1.26; acc: 0.59
Batch: 420; loss: 1.07; acc: 0.66
Batch: 440; loss: 1.13; acc: 0.67
Batch: 460; loss: 1.46; acc: 0.5
Batch: 480; loss: 1.22; acc: 0.56
Batch: 500; loss: 1.22; acc: 0.61
Batch: 520; loss: 1.24; acc: 0.55
Batch: 540; loss: 1.45; acc: 0.52
Batch: 560; loss: 1.16; acc: 0.66
Batch: 580; loss: 1.13; acc: 0.64
Batch: 600; loss: 1.23; acc: 0.59
Batch: 620; loss: 1.46; acc: 0.52
Batch: 640; loss: 1.26; acc: 0.56
Batch: 660; loss: 1.39; acc: 0.56
Batch: 680; loss: 1.35; acc: 0.59
Batch: 700; loss: 1.41; acc: 0.55
Batch: 720; loss: 1.34; acc: 0.62
Batch: 740; loss: 1.44; acc: 0.55
Batch: 760; loss: 1.32; acc: 0.61
Batch: 780; loss: 1.21; acc: 0.56
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.6098809282993898e-05
6.329932148219086e-06
Batch: 0; loss: 1.39; acc: 0.47
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.12; acc: 0.61
Batch: 60; loss: 1.33; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.7
Batch: 100; loss: 1.03; acc: 0.66
Batch: 120; loss: 1.46; acc: 0.47
Batch: 140; loss: 1.21; acc: 0.56
Val Epoch over. val_loss: 1.2480618137462882; val_accuracy: 0.5875796178343949 

The current subspace-distance is: 6.329932148219086e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.64; acc: 0.45
Batch: 20; loss: 1.38; acc: 0.52
Batch: 40; loss: 1.45; acc: 0.56
Batch: 60; loss: 1.39; acc: 0.53
Batch: 80; loss: 1.28; acc: 0.59
Batch: 100; loss: 1.22; acc: 0.59
Batch: 120; loss: 1.33; acc: 0.56
Batch: 140; loss: 1.49; acc: 0.52
Batch: 160; loss: 1.66; acc: 0.5
Batch: 180; loss: 1.24; acc: 0.64
Batch: 200; loss: 1.46; acc: 0.53
Batch: 220; loss: 1.23; acc: 0.56
Batch: 240; loss: 1.03; acc: 0.72
Batch: 260; loss: 1.21; acc: 0.61
Batch: 280; loss: 1.26; acc: 0.56
Batch: 300; loss: 1.26; acc: 0.52
Batch: 320; loss: 1.45; acc: 0.48
Batch: 340; loss: 1.18; acc: 0.69
Batch: 360; loss: 1.17; acc: 0.62
Batch: 380; loss: 1.62; acc: 0.58
Batch: 400; loss: 1.38; acc: 0.53
Batch: 420; loss: 1.33; acc: 0.53
Batch: 440; loss: 1.19; acc: 0.64
Batch: 460; loss: 1.44; acc: 0.5
Batch: 480; loss: 1.37; acc: 0.52
Batch: 500; loss: 1.3; acc: 0.55
Batch: 520; loss: 1.44; acc: 0.59
Batch: 540; loss: 1.26; acc: 0.61
Batch: 560; loss: 1.3; acc: 0.66
Batch: 580; loss: 1.32; acc: 0.69
Batch: 600; loss: 1.33; acc: 0.58
Batch: 620; loss: 1.17; acc: 0.64
Batch: 640; loss: 1.22; acc: 0.58
Batch: 660; loss: 1.18; acc: 0.61
Batch: 680; loss: 1.27; acc: 0.58
Batch: 700; loss: 1.07; acc: 0.62
Batch: 720; loss: 1.2; acc: 0.56
Batch: 740; loss: 1.12; acc: 0.67
Batch: 760; loss: 1.49; acc: 0.59
Batch: 780; loss: 1.45; acc: 0.52
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.4774430383113213e-05
4.5336619223235175e-06
Batch: 0; loss: 1.43; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.56
Batch: 40; loss: 1.14; acc: 0.59
Batch: 60; loss: 1.38; acc: 0.7
Batch: 80; loss: 1.08; acc: 0.64
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.44; acc: 0.48
Batch: 140; loss: 1.16; acc: 0.61
Val Epoch over. val_loss: 1.2547445342798902; val_accuracy: 0.5976313694267515 

The current subspace-distance is: 4.5336619223235175e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.45; acc: 0.52
Batch: 20; loss: 1.39; acc: 0.58
Batch: 40; loss: 1.31; acc: 0.58
Batch: 60; loss: 1.48; acc: 0.58
Batch: 80; loss: 1.41; acc: 0.64
Batch: 100; loss: 1.38; acc: 0.56
Batch: 120; loss: 1.32; acc: 0.62
Batch: 140; loss: 1.02; acc: 0.64
Batch: 160; loss: 1.4; acc: 0.56
Batch: 180; loss: 1.07; acc: 0.61
Batch: 200; loss: 1.31; acc: 0.62
Batch: 220; loss: 1.53; acc: 0.58
Batch: 240; loss: 1.2; acc: 0.58
Batch: 260; loss: 1.28; acc: 0.56
Batch: 280; loss: 1.55; acc: 0.44
Batch: 300; loss: 1.44; acc: 0.5
Batch: 320; loss: 1.79; acc: 0.42
Batch: 340; loss: 1.18; acc: 0.62
Batch: 360; loss: 1.42; acc: 0.53
Batch: 380; loss: 1.12; acc: 0.67
Batch: 400; loss: 1.18; acc: 0.59
Batch: 420; loss: 1.27; acc: 0.53
Batch: 440; loss: 1.03; acc: 0.7
Batch: 460; loss: 1.36; acc: 0.53
Batch: 480; loss: 0.96; acc: 0.64
Batch: 500; loss: 1.31; acc: 0.58
Batch: 520; loss: 1.42; acc: 0.42
Batch: 540; loss: 1.7; acc: 0.42
Batch: 560; loss: 1.35; acc: 0.52
Batch: 580; loss: 0.86; acc: 0.73
Batch: 600; loss: 1.1; acc: 0.64
Batch: 620; loss: 1.06; acc: 0.7
Batch: 640; loss: 1.1; acc: 0.69
Batch: 660; loss: 1.33; acc: 0.56
Batch: 680; loss: 1.22; acc: 0.59
Batch: 700; loss: 1.2; acc: 0.62
Batch: 720; loss: 1.42; acc: 0.56
Batch: 740; loss: 1.47; acc: 0.56
Batch: 760; loss: 1.27; acc: 0.56
Batch: 780; loss: 1.06; acc: 0.7
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.795708703866694e-05
4.987769898434635e-06
Batch: 0; loss: 1.39; acc: 0.47
Batch: 20; loss: 1.37; acc: 0.52
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.37; acc: 0.69
Batch: 80; loss: 1.06; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.64
Batch: 120; loss: 1.45; acc: 0.48
Batch: 140; loss: 1.16; acc: 0.61
Val Epoch over. val_loss: 1.2439564128590237; val_accuracy: 0.5976313694267515 

The current subspace-distance is: 4.987769898434635e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.2; acc: 0.61
Batch: 20; loss: 1.33; acc: 0.55
Batch: 40; loss: 0.97; acc: 0.69
Batch: 60; loss: 1.29; acc: 0.62
Batch: 80; loss: 1.3; acc: 0.59
Batch: 100; loss: 1.45; acc: 0.56
Batch: 120; loss: 1.19; acc: 0.59
Batch: 140; loss: 1.34; acc: 0.58
Batch: 160; loss: 1.46; acc: 0.56
Batch: 180; loss: 1.01; acc: 0.7
Batch: 200; loss: 1.19; acc: 0.61
Batch: 220; loss: 1.36; acc: 0.52
Batch: 240; loss: 1.28; acc: 0.53
Batch: 260; loss: 1.34; acc: 0.52
Batch: 280; loss: 1.37; acc: 0.62
Batch: 300; loss: 1.1; acc: 0.64
Batch: 320; loss: 1.51; acc: 0.48
Batch: 340; loss: 1.4; acc: 0.53
Batch: 360; loss: 1.43; acc: 0.53
Batch: 380; loss: 1.13; acc: 0.62
Batch: 400; loss: 1.21; acc: 0.52
Batch: 420; loss: 1.15; acc: 0.59
Batch: 440; loss: 1.04; acc: 0.69
Batch: 460; loss: 1.27; acc: 0.58
Batch: 480; loss: 1.41; acc: 0.48
Batch: 500; loss: 1.21; acc: 0.69
Batch: 520; loss: 1.08; acc: 0.66
Batch: 540; loss: 1.26; acc: 0.56
Batch: 560; loss: 1.19; acc: 0.66
Batch: 580; loss: 1.18; acc: 0.61
Batch: 600; loss: 1.22; acc: 0.61
Batch: 620; loss: 1.11; acc: 0.61
Batch: 640; loss: 1.35; acc: 0.55
Batch: 660; loss: 1.18; acc: 0.67
Batch: 680; loss: 1.27; acc: 0.56
Batch: 700; loss: 1.21; acc: 0.62
Batch: 720; loss: 1.44; acc: 0.48
Batch: 740; loss: 1.37; acc: 0.58
Batch: 760; loss: 1.04; acc: 0.64
Batch: 780; loss: 1.58; acc: 0.45
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.5685989637859166e-05
5.0091171033272985e-06
Batch: 0; loss: 1.4; acc: 0.48
Batch: 20; loss: 1.34; acc: 0.55
Batch: 40; loss: 1.14; acc: 0.59
Batch: 60; loss: 1.38; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.41; acc: 0.47
Batch: 140; loss: 1.16; acc: 0.58
Val Epoch over. val_loss: 1.2547554385130573; val_accuracy: 0.5912619426751592 

The current subspace-distance is: 5.0091171033272985e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.12; acc: 0.59
Batch: 20; loss: 1.2; acc: 0.56
Batch: 40; loss: 1.44; acc: 0.52
Batch: 60; loss: 1.26; acc: 0.61
Batch: 80; loss: 1.15; acc: 0.67
Batch: 100; loss: 1.21; acc: 0.64
Batch: 120; loss: 1.09; acc: 0.61
Batch: 140; loss: 1.38; acc: 0.56
Batch: 160; loss: 1.59; acc: 0.47
Batch: 180; loss: 1.51; acc: 0.48
Batch: 200; loss: 1.27; acc: 0.56
Batch: 220; loss: 1.47; acc: 0.48
Batch: 240; loss: 1.17; acc: 0.62
Batch: 260; loss: 1.22; acc: 0.55
Batch: 280; loss: 1.24; acc: 0.67
Batch: 300; loss: 1.28; acc: 0.56
Batch: 320; loss: 1.37; acc: 0.59
Batch: 340; loss: 1.39; acc: 0.61
Batch: 360; loss: 1.2; acc: 0.59
Batch: 380; loss: 1.38; acc: 0.62
Batch: 400; loss: 1.61; acc: 0.56
Batch: 420; loss: 1.44; acc: 0.53
Batch: 440; loss: 0.97; acc: 0.72
Batch: 460; loss: 1.39; acc: 0.64
Batch: 480; loss: 0.99; acc: 0.64
Batch: 500; loss: 1.51; acc: 0.42
Batch: 520; loss: 1.07; acc: 0.69
Batch: 540; loss: 1.33; acc: 0.52
Batch: 560; loss: 1.24; acc: 0.67
Batch: 580; loss: 1.2; acc: 0.53
Batch: 600; loss: 1.3; acc: 0.53
Batch: 620; loss: 1.07; acc: 0.66
Batch: 640; loss: 1.36; acc: 0.53
Batch: 660; loss: 1.55; acc: 0.55
Batch: 680; loss: 1.11; acc: 0.64
Batch: 700; loss: 1.18; acc: 0.62
Batch: 720; loss: 1.54; acc: 0.53
Batch: 740; loss: 1.18; acc: 0.64
Batch: 760; loss: 1.3; acc: 0.61
Batch: 780; loss: 1.42; acc: 0.55
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.4950022887205705e-05
5.961267561360728e-06
Batch: 0; loss: 1.4; acc: 0.47
Batch: 20; loss: 1.41; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 1.36; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.69
Batch: 100; loss: 1.06; acc: 0.69
Batch: 120; loss: 1.48; acc: 0.45
Batch: 140; loss: 1.26; acc: 0.55
Val Epoch over. val_loss: 1.2521079148456549; val_accuracy: 0.591062898089172 

The current subspace-distance is: 5.961267561360728e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.16; acc: 0.67
Batch: 20; loss: 1.18; acc: 0.64
Batch: 40; loss: 1.23; acc: 0.62
Batch: 60; loss: 1.23; acc: 0.59
Batch: 80; loss: 1.27; acc: 0.52
Batch: 100; loss: 1.08; acc: 0.64
Batch: 120; loss: 1.35; acc: 0.53
Batch: 140; loss: 1.39; acc: 0.55
Batch: 160; loss: 1.37; acc: 0.59
Batch: 180; loss: 1.2; acc: 0.61
Batch: 200; loss: 1.45; acc: 0.53
Batch: 220; loss: 1.28; acc: 0.56
Batch: 240; loss: 1.43; acc: 0.55
Batch: 260; loss: 1.09; acc: 0.73
Batch: 280; loss: 1.45; acc: 0.5
Batch: 300; loss: 1.23; acc: 0.53
Batch: 320; loss: 1.08; acc: 0.7
Batch: 340; loss: 1.54; acc: 0.47
Batch: 360; loss: 1.16; acc: 0.66
Batch: 380; loss: 1.27; acc: 0.58
Batch: 400; loss: 1.41; acc: 0.64
Batch: 420; loss: 1.43; acc: 0.52
Batch: 440; loss: 1.24; acc: 0.53
Batch: 460; loss: 1.11; acc: 0.64
Batch: 480; loss: 1.44; acc: 0.56
Batch: 500; loss: 1.23; acc: 0.59
Batch: 520; loss: 1.0; acc: 0.73
Batch: 540; loss: 1.24; acc: 0.61
Batch: 560; loss: 1.37; acc: 0.59
Batch: 580; loss: 1.05; acc: 0.67
Batch: 600; loss: 1.34; acc: 0.58
Batch: 620; loss: 1.37; acc: 0.55
Batch: 640; loss: 1.24; acc: 0.61
Batch: 660; loss: 1.23; acc: 0.61
Batch: 680; loss: 1.36; acc: 0.48
Batch: 700; loss: 1.25; acc: 0.59
Batch: 720; loss: 1.24; acc: 0.53
Batch: 740; loss: 1.32; acc: 0.52
Batch: 760; loss: 1.36; acc: 0.61
Batch: 780; loss: 1.38; acc: 0.52
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.536259696877096e-05
5.997811058477964e-06
Batch: 0; loss: 1.38; acc: 0.44
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.61
Batch: 60; loss: 1.33; acc: 0.69
Batch: 80; loss: 1.02; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.66
Batch: 120; loss: 1.44; acc: 0.44
Batch: 140; loss: 1.23; acc: 0.58
Val Epoch over. val_loss: 1.2481237661307025; val_accuracy: 0.587281050955414 

The current subspace-distance is: 5.997811058477964e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.23; acc: 0.61
Batch: 20; loss: 1.49; acc: 0.5
Batch: 40; loss: 1.1; acc: 0.56
Batch: 60; loss: 1.31; acc: 0.59
Batch: 80; loss: 1.31; acc: 0.56
Batch: 100; loss: 1.34; acc: 0.5
Batch: 120; loss: 1.35; acc: 0.55
Batch: 140; loss: 1.05; acc: 0.69
Batch: 160; loss: 1.5; acc: 0.47
Batch: 180; loss: 1.29; acc: 0.61
Batch: 200; loss: 1.31; acc: 0.62
Batch: 220; loss: 1.12; acc: 0.61
Batch: 240; loss: 1.69; acc: 0.45
Batch: 260; loss: 1.4; acc: 0.56
Batch: 280; loss: 1.8; acc: 0.36
Batch: 300; loss: 1.23; acc: 0.69
Batch: 320; loss: 1.18; acc: 0.59
Batch: 340; loss: 1.27; acc: 0.58
Batch: 360; loss: 1.25; acc: 0.64
Batch: 380; loss: 1.42; acc: 0.48
Batch: 400; loss: 1.18; acc: 0.61
Batch: 420; loss: 1.4; acc: 0.52
Batch: 440; loss: 1.16; acc: 0.67
Batch: 460; loss: 1.37; acc: 0.53
Batch: 480; loss: 1.41; acc: 0.53
Batch: 500; loss: 1.18; acc: 0.62
Batch: 520; loss: 1.38; acc: 0.55
Batch: 540; loss: 1.21; acc: 0.64
Batch: 560; loss: 1.24; acc: 0.58
Batch: 580; loss: 1.29; acc: 0.59
Batch: 600; loss: 1.35; acc: 0.58
Batch: 620; loss: 1.25; acc: 0.53
Batch: 640; loss: 1.21; acc: 0.59
Batch: 660; loss: 1.35; acc: 0.55
Batch: 680; loss: 1.28; acc: 0.58
Batch: 700; loss: 1.36; acc: 0.5
Batch: 720; loss: 1.13; acc: 0.59
Batch: 740; loss: 1.71; acc: 0.52
Batch: 760; loss: 1.27; acc: 0.5
Batch: 780; loss: 1.07; acc: 0.66
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.7093367205234244e-05
5.3172661864664406e-06
Batch: 0; loss: 1.4; acc: 0.47
Batch: 20; loss: 1.36; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.58
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.67
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 1.45; acc: 0.5
Batch: 140; loss: 1.17; acc: 0.59
Val Epoch over. val_loss: 1.2468338084828323; val_accuracy: 0.5942476114649682 

The current subspace-distance is: 5.3172661864664406e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.58; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.53
Batch: 40; loss: 1.62; acc: 0.48
Batch: 60; loss: 0.99; acc: 0.66
Batch: 80; loss: 1.2; acc: 0.59
Batch: 100; loss: 1.2; acc: 0.58
Batch: 120; loss: 1.61; acc: 0.5
Batch: 140; loss: 1.11; acc: 0.66
Batch: 160; loss: 1.4; acc: 0.56
Batch: 180; loss: 0.95; acc: 0.7
Batch: 200; loss: 1.19; acc: 0.58
Batch: 220; loss: 1.41; acc: 0.52
Batch: 240; loss: 0.95; acc: 0.69
Batch: 260; loss: 1.15; acc: 0.62
Batch: 280; loss: 1.18; acc: 0.62
Batch: 300; loss: 1.22; acc: 0.61
Batch: 320; loss: 1.17; acc: 0.67
Batch: 340; loss: 1.22; acc: 0.55
Batch: 360; loss: 1.09; acc: 0.64
Batch: 380; loss: 1.22; acc: 0.59
Batch: 400; loss: 1.21; acc: 0.62
Batch: 420; loss: 1.09; acc: 0.66
Batch: 440; loss: 1.35; acc: 0.48
Batch: 460; loss: 1.34; acc: 0.56
Batch: 480; loss: 1.08; acc: 0.61
Batch: 500; loss: 1.53; acc: 0.5
Batch: 520; loss: 1.27; acc: 0.5
Batch: 540; loss: 1.1; acc: 0.64
Batch: 560; loss: 1.17; acc: 0.61
Batch: 580; loss: 1.23; acc: 0.58
Batch: 600; loss: 1.14; acc: 0.62
Batch: 620; loss: 1.35; acc: 0.53
Batch: 640; loss: 1.54; acc: 0.52
Batch: 660; loss: 1.61; acc: 0.55
Batch: 680; loss: 1.33; acc: 0.56
Batch: 700; loss: 1.22; acc: 0.58
Batch: 720; loss: 1.17; acc: 0.69
Batch: 740; loss: 1.21; acc: 0.67
Batch: 760; loss: 1.39; acc: 0.58
Batch: 780; loss: 1.26; acc: 0.55
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.9527613403624855e-05
5.305789272824768e-06
Batch: 0; loss: 1.42; acc: 0.45
Batch: 20; loss: 1.36; acc: 0.53
Batch: 40; loss: 1.14; acc: 0.67
Batch: 60; loss: 1.36; acc: 0.69
Batch: 80; loss: 1.07; acc: 0.7
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.48
Batch: 140; loss: 1.13; acc: 0.61
Val Epoch over. val_loss: 1.2535766287214438; val_accuracy: 0.6024084394904459 

The current subspace-distance is: 5.305789272824768e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.04; acc: 0.66
Batch: 20; loss: 1.52; acc: 0.45
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.36; acc: 0.67
Batch: 80; loss: 1.48; acc: 0.53
Batch: 100; loss: 1.38; acc: 0.5
Batch: 120; loss: 1.5; acc: 0.45
Batch: 140; loss: 0.96; acc: 0.73
Batch: 160; loss: 1.17; acc: 0.56
Batch: 180; loss: 1.16; acc: 0.7
Batch: 200; loss: 1.1; acc: 0.66
Batch: 220; loss: 1.32; acc: 0.52
Batch: 240; loss: 1.18; acc: 0.67
Batch: 260; loss: 1.13; acc: 0.62
Batch: 280; loss: 1.32; acc: 0.64
Batch: 300; loss: 1.16; acc: 0.58
Batch: 320; loss: 1.54; acc: 0.47
Batch: 340; loss: 1.23; acc: 0.59
Batch: 360; loss: 1.59; acc: 0.48
Batch: 380; loss: 1.39; acc: 0.61
Batch: 400; loss: 1.42; acc: 0.48
Batch: 420; loss: 1.18; acc: 0.66
Batch: 440; loss: 1.26; acc: 0.61
Batch: 460; loss: 1.48; acc: 0.58
Batch: 480; loss: 1.5; acc: 0.53
Batch: 500; loss: 1.3; acc: 0.56
Batch: 520; loss: 1.63; acc: 0.45
Batch: 540; loss: 1.56; acc: 0.41
Batch: 560; loss: 1.29; acc: 0.56
Batch: 580; loss: 1.35; acc: 0.58
Batch: 600; loss: 1.19; acc: 0.61
Batch: 620; loss: 1.09; acc: 0.62
Batch: 640; loss: 1.04; acc: 0.67
Batch: 660; loss: 1.52; acc: 0.52
Batch: 680; loss: 0.97; acc: 0.66
Batch: 700; loss: 1.43; acc: 0.48
Batch: 720; loss: 1.17; acc: 0.59
Batch: 740; loss: 1.35; acc: 0.62
Batch: 760; loss: 1.18; acc: 0.55
Batch: 780; loss: 1.1; acc: 0.66
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.461891042708885e-05
6.237187335500494e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.35; acc: 0.58
Batch: 40; loss: 1.14; acc: 0.66
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.69
Batch: 100; loss: 0.99; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.48
Batch: 140; loss: 1.2; acc: 0.61
Val Epoch over. val_loss: 1.2543207156430385; val_accuracy: 0.5936504777070064 

The current subspace-distance is: 6.237187335500494e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.31; acc: 0.48
Batch: 20; loss: 1.2; acc: 0.62
Batch: 40; loss: 1.32; acc: 0.66
Batch: 60; loss: 1.15; acc: 0.61
Batch: 80; loss: 1.53; acc: 0.61
Batch: 100; loss: 1.11; acc: 0.62
Batch: 120; loss: 1.33; acc: 0.61
Batch: 140; loss: 1.26; acc: 0.58
Batch: 160; loss: 1.14; acc: 0.67
Batch: 180; loss: 1.36; acc: 0.58
Batch: 200; loss: 1.29; acc: 0.62
Batch: 220; loss: 1.06; acc: 0.7
Batch: 240; loss: 1.12; acc: 0.64
Batch: 260; loss: 1.36; acc: 0.53
Batch: 280; loss: 1.22; acc: 0.62
Batch: 300; loss: 1.42; acc: 0.48
Batch: 320; loss: 1.32; acc: 0.64
Batch: 340; loss: 1.49; acc: 0.52
Batch: 360; loss: 1.23; acc: 0.62
Batch: 380; loss: 1.13; acc: 0.62
Batch: 400; loss: 1.33; acc: 0.59
Batch: 420; loss: 1.11; acc: 0.64
Batch: 440; loss: 1.18; acc: 0.56
Batch: 460; loss: 0.98; acc: 0.61
Batch: 480; loss: 1.31; acc: 0.52
Batch: 500; loss: 1.38; acc: 0.55
Batch: 520; loss: 1.22; acc: 0.55
Batch: 540; loss: 1.32; acc: 0.55
Batch: 560; loss: 1.33; acc: 0.55
Batch: 580; loss: 1.17; acc: 0.69
Batch: 600; loss: 1.49; acc: 0.58
Batch: 620; loss: 1.17; acc: 0.58
Batch: 640; loss: 1.15; acc: 0.58
Batch: 660; loss: 1.58; acc: 0.47
Batch: 680; loss: 1.23; acc: 0.61
Batch: 700; loss: 1.25; acc: 0.55
Batch: 720; loss: 1.45; acc: 0.55
Batch: 740; loss: 1.37; acc: 0.52
Batch: 760; loss: 1.48; acc: 0.53
Batch: 780; loss: 1.01; acc: 0.61
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.6759646314312704e-05
7.4892423072014935e-06
Batch: 0; loss: 1.37; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.62
Batch: 60; loss: 1.34; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.46; acc: 0.47
Batch: 140; loss: 1.2; acc: 0.59
Val Epoch over. val_loss: 1.2455179744465337; val_accuracy: 0.5934514331210191 

The current subspace-distance is: 7.4892423072014935e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.87; acc: 0.77
Batch: 20; loss: 1.53; acc: 0.53
Batch: 40; loss: 0.8; acc: 0.75
Batch: 60; loss: 1.27; acc: 0.62
Batch: 80; loss: 1.33; acc: 0.58
Batch: 100; loss: 1.41; acc: 0.58
Batch: 120; loss: 1.32; acc: 0.61
Batch: 140; loss: 1.04; acc: 0.64
Batch: 160; loss: 1.34; acc: 0.56
Batch: 180; loss: 1.51; acc: 0.59
Batch: 200; loss: 1.22; acc: 0.62
Batch: 220; loss: 1.14; acc: 0.66
Batch: 240; loss: 1.24; acc: 0.58
Batch: 260; loss: 1.43; acc: 0.52
Batch: 280; loss: 1.52; acc: 0.58
Batch: 300; loss: 1.09; acc: 0.67
Batch: 320; loss: 1.32; acc: 0.59
Batch: 340; loss: 1.36; acc: 0.45
Batch: 360; loss: 1.47; acc: 0.58
Batch: 380; loss: 1.42; acc: 0.64
Batch: 400; loss: 1.31; acc: 0.48
Batch: 420; loss: 1.26; acc: 0.62
Batch: 440; loss: 1.62; acc: 0.52
Batch: 460; loss: 1.27; acc: 0.59
Batch: 480; loss: 1.22; acc: 0.59
Batch: 500; loss: 1.16; acc: 0.59
Batch: 520; loss: 1.47; acc: 0.61
Batch: 540; loss: 0.9; acc: 0.73
Batch: 560; loss: 1.12; acc: 0.59
Batch: 580; loss: 1.29; acc: 0.64
Batch: 600; loss: 1.21; acc: 0.59
Batch: 620; loss: 1.17; acc: 0.58
Batch: 640; loss: 1.39; acc: 0.58
Batch: 660; loss: 1.46; acc: 0.52
Batch: 680; loss: 1.34; acc: 0.56
Batch: 700; loss: 0.93; acc: 0.64
Batch: 720; loss: 1.45; acc: 0.52
Batch: 740; loss: 1.22; acc: 0.61
Batch: 760; loss: 1.45; acc: 0.53
Batch: 780; loss: 0.95; acc: 0.72
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.6182015315280296e-05
4.6715490498172585e-06
Batch: 0; loss: 1.37; acc: 0.48
Batch: 20; loss: 1.39; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.21; acc: 0.55
Val Epoch over. val_loss: 1.2444359910715916; val_accuracy: 0.5951433121019108 

The current subspace-distance is: 4.6715490498172585e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.16; acc: 0.61
Batch: 20; loss: 1.31; acc: 0.61
Batch: 40; loss: 1.06; acc: 0.67
Batch: 60; loss: 1.24; acc: 0.67
Batch: 80; loss: 1.4; acc: 0.55
Batch: 100; loss: 1.14; acc: 0.61
Batch: 120; loss: 1.49; acc: 0.56
Batch: 140; loss: 1.18; acc: 0.56
Batch: 160; loss: 1.1; acc: 0.61
Batch: 180; loss: 1.36; acc: 0.48
Batch: 200; loss: 0.99; acc: 0.59
Batch: 220; loss: 1.17; acc: 0.59
Batch: 240; loss: 1.59; acc: 0.59
Batch: 260; loss: 1.71; acc: 0.55
Batch: 280; loss: 1.38; acc: 0.52
Batch: 300; loss: 1.38; acc: 0.64
Batch: 320; loss: 1.28; acc: 0.59
Batch: 340; loss: 1.49; acc: 0.53
Batch: 360; loss: 1.2; acc: 0.64
Batch: 380; loss: 1.22; acc: 0.69
Batch: 400; loss: 1.59; acc: 0.48
Batch: 420; loss: 1.12; acc: 0.59
Batch: 440; loss: 0.98; acc: 0.64
Batch: 460; loss: 1.47; acc: 0.52
Batch: 480; loss: 1.08; acc: 0.66
Batch: 500; loss: 1.06; acc: 0.62
Batch: 520; loss: 1.54; acc: 0.5
Batch: 540; loss: 1.25; acc: 0.58
Batch: 560; loss: 1.13; acc: 0.69
Batch: 580; loss: 1.12; acc: 0.72
Batch: 600; loss: 1.45; acc: 0.61
Batch: 620; loss: 1.4; acc: 0.56
Batch: 640; loss: 1.33; acc: 0.53
Batch: 660; loss: 1.06; acc: 0.62
Batch: 680; loss: 1.02; acc: 0.67
Batch: 700; loss: 1.43; acc: 0.55
Batch: 720; loss: 1.01; acc: 0.67
Batch: 740; loss: 1.24; acc: 0.62
Batch: 760; loss: 1.39; acc: 0.53
Batch: 780; loss: 1.13; acc: 0.64
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.5757776054670103e-05
5.1043198254774325e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.38; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.69
Batch: 80; loss: 1.04; acc: 0.66
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.56
Val Epoch over. val_loss: 1.2421467866107916; val_accuracy: 0.5931528662420382 

The current subspace-distance is: 5.1043198254774325e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.15; acc: 0.7
Batch: 20; loss: 1.5; acc: 0.53
Batch: 40; loss: 1.09; acc: 0.56
Batch: 60; loss: 1.29; acc: 0.59
Batch: 80; loss: 1.24; acc: 0.61
Batch: 100; loss: 1.07; acc: 0.64
Batch: 120; loss: 1.09; acc: 0.61
Batch: 140; loss: 1.32; acc: 0.55
Batch: 160; loss: 1.14; acc: 0.67
Batch: 180; loss: 1.41; acc: 0.62
Batch: 200; loss: 1.25; acc: 0.69
Batch: 220; loss: 1.12; acc: 0.59
Batch: 240; loss: 1.19; acc: 0.56
Batch: 260; loss: 1.11; acc: 0.58
Batch: 280; loss: 1.34; acc: 0.61
Batch: 300; loss: 1.27; acc: 0.56
Batch: 320; loss: 1.18; acc: 0.61
Batch: 340; loss: 1.32; acc: 0.48
Batch: 360; loss: 1.3; acc: 0.52
Batch: 380; loss: 1.35; acc: 0.62
Batch: 400; loss: 1.27; acc: 0.55
Batch: 420; loss: 1.31; acc: 0.62
Batch: 440; loss: 1.23; acc: 0.55
Batch: 460; loss: 1.01; acc: 0.7
Batch: 480; loss: 1.43; acc: 0.55
Batch: 500; loss: 1.39; acc: 0.45
Batch: 520; loss: 1.25; acc: 0.58
Batch: 540; loss: 1.29; acc: 0.55
Batch: 560; loss: 1.13; acc: 0.69
Batch: 580; loss: 1.52; acc: 0.53
Batch: 600; loss: 1.24; acc: 0.58
Batch: 620; loss: 1.35; acc: 0.61
Batch: 640; loss: 1.25; acc: 0.55
Batch: 660; loss: 1.14; acc: 0.64
Batch: 680; loss: 1.24; acc: 0.56
Batch: 700; loss: 1.21; acc: 0.59
Batch: 720; loss: 1.33; acc: 0.5
Batch: 740; loss: 1.26; acc: 0.58
Batch: 760; loss: 1.13; acc: 0.7
Batch: 780; loss: 1.18; acc: 0.64
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.4718166312377434e-05
6.086541361582931e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.61
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.44
Batch: 140; loss: 1.19; acc: 0.58
Val Epoch over. val_loss: 1.2430210462801017; val_accuracy: 0.5927547770700637 

The current subspace-distance is: 6.086541361582931e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.15; acc: 0.66
Batch: 20; loss: 1.07; acc: 0.73
Batch: 40; loss: 1.1; acc: 0.72
Batch: 60; loss: 1.06; acc: 0.81
Batch: 80; loss: 1.51; acc: 0.56
Batch: 100; loss: 1.31; acc: 0.5
Batch: 120; loss: 1.56; acc: 0.53
Batch: 140; loss: 1.37; acc: 0.59
Batch: 160; loss: 1.32; acc: 0.61
Batch: 180; loss: 1.44; acc: 0.55
Batch: 200; loss: 1.31; acc: 0.55
Batch: 220; loss: 1.33; acc: 0.47
Batch: 240; loss: 1.19; acc: 0.55
Batch: 260; loss: 1.28; acc: 0.56
Batch: 280; loss: 1.29; acc: 0.59
Batch: 300; loss: 1.15; acc: 0.61
Batch: 320; loss: 1.01; acc: 0.66
Batch: 340; loss: 1.56; acc: 0.48
Batch: 360; loss: 1.37; acc: 0.53
Batch: 380; loss: 1.21; acc: 0.55
Batch: 400; loss: 1.36; acc: 0.56
Batch: 420; loss: 1.2; acc: 0.59
Batch: 440; loss: 1.37; acc: 0.61
Batch: 460; loss: 1.34; acc: 0.52
Batch: 480; loss: 1.26; acc: 0.59
Batch: 500; loss: 1.22; acc: 0.59
Batch: 520; loss: 1.26; acc: 0.55
Batch: 540; loss: 1.62; acc: 0.5
Batch: 560; loss: 1.08; acc: 0.7
Batch: 580; loss: 1.31; acc: 0.52
Batch: 600; loss: 1.32; acc: 0.61
Batch: 620; loss: 1.52; acc: 0.44
Batch: 640; loss: 1.37; acc: 0.5
Batch: 660; loss: 1.03; acc: 0.72
Batch: 680; loss: 1.23; acc: 0.58
Batch: 700; loss: 1.28; acc: 0.52
Batch: 720; loss: 1.31; acc: 0.55
Batch: 740; loss: 1.47; acc: 0.48
Batch: 760; loss: 1.65; acc: 0.55
Batch: 780; loss: 1.24; acc: 0.55
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.6800609955680557e-05
4.692636593972566e-06
Batch: 0; loss: 1.38; acc: 0.44
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.11; acc: 0.66
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.7
Batch: 100; loss: 1.03; acc: 0.7
Batch: 120; loss: 1.45; acc: 0.48
Batch: 140; loss: 1.18; acc: 0.58
Val Epoch over. val_loss: 1.2432916988233091; val_accuracy: 0.596437101910828 

The current subspace-distance is: 4.692636593972566e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.52; acc: 0.5
Batch: 20; loss: 1.23; acc: 0.53
Batch: 40; loss: 1.24; acc: 0.55
Batch: 60; loss: 1.27; acc: 0.59
Batch: 80; loss: 1.26; acc: 0.55
Batch: 100; loss: 1.12; acc: 0.7
Batch: 120; loss: 1.23; acc: 0.59
Batch: 140; loss: 1.24; acc: 0.62
Batch: 160; loss: 1.26; acc: 0.66
Batch: 180; loss: 1.33; acc: 0.52
Batch: 200; loss: 1.28; acc: 0.58
Batch: 220; loss: 1.19; acc: 0.64
Batch: 240; loss: 1.14; acc: 0.67
Batch: 260; loss: 1.26; acc: 0.62
Batch: 280; loss: 1.22; acc: 0.66
Batch: 300; loss: 1.11; acc: 0.62
Batch: 320; loss: 1.64; acc: 0.48
Batch: 340; loss: 1.34; acc: 0.56
Batch: 360; loss: 1.16; acc: 0.59
Batch: 380; loss: 1.1; acc: 0.67
Batch: 400; loss: 1.31; acc: 0.58
Batch: 420; loss: 0.97; acc: 0.64
Batch: 440; loss: 1.43; acc: 0.55
Batch: 460; loss: 1.31; acc: 0.61
Batch: 480; loss: 0.9; acc: 0.7
Batch: 500; loss: 1.29; acc: 0.62
Batch: 520; loss: 1.45; acc: 0.56
Batch: 540; loss: 1.39; acc: 0.58
Batch: 560; loss: 1.27; acc: 0.52
Batch: 580; loss: 1.31; acc: 0.52
Batch: 600; loss: 1.56; acc: 0.53
Batch: 620; loss: 1.34; acc: 0.5
Batch: 640; loss: 1.48; acc: 0.47
Batch: 660; loss: 1.4; acc: 0.58
Batch: 680; loss: 1.25; acc: 0.66
Batch: 700; loss: 1.49; acc: 0.52
Batch: 720; loss: 1.15; acc: 0.64
Batch: 740; loss: 1.57; acc: 0.61
Batch: 760; loss: 1.27; acc: 0.59
Batch: 780; loss: 1.2; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.5056175470817834e-05
6.009724984323839e-06
Batch: 0; loss: 1.37; acc: 0.48
Batch: 20; loss: 1.36; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.61
Batch: 60; loss: 1.34; acc: 0.67
Batch: 80; loss: 1.03; acc: 0.66
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.47
Batch: 140; loss: 1.19; acc: 0.56
Val Epoch over. val_loss: 1.2437109423291153; val_accuracy: 0.591062898089172 

The current subspace-distance is: 6.009724984323839e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.02; acc: 0.66
Batch: 20; loss: 1.2; acc: 0.55
Batch: 40; loss: 1.2; acc: 0.64
Batch: 60; loss: 1.15; acc: 0.61
Batch: 80; loss: 1.15; acc: 0.67
Batch: 100; loss: 1.44; acc: 0.59
Batch: 120; loss: 1.21; acc: 0.66
Batch: 140; loss: 0.96; acc: 0.66
Batch: 160; loss: 1.44; acc: 0.48
Batch: 180; loss: 0.95; acc: 0.69
Batch: 200; loss: 1.36; acc: 0.59
Batch: 220; loss: 1.22; acc: 0.66
Batch: 240; loss: 1.34; acc: 0.56
Batch: 260; loss: 1.31; acc: 0.62
Batch: 280; loss: 1.36; acc: 0.59
Batch: 300; loss: 1.16; acc: 0.66
Batch: 320; loss: 1.86; acc: 0.38
Batch: 340; loss: 1.17; acc: 0.67
Batch: 360; loss: 1.79; acc: 0.48
Batch: 380; loss: 1.28; acc: 0.56
Batch: 400; loss: 1.58; acc: 0.39
Batch: 420; loss: 1.29; acc: 0.56
Batch: 440; loss: 1.27; acc: 0.55
Batch: 460; loss: 1.36; acc: 0.55
Batch: 480; loss: 1.17; acc: 0.64
Batch: 500; loss: 1.55; acc: 0.48
Batch: 520; loss: 1.3; acc: 0.5
Batch: 540; loss: 1.46; acc: 0.52
Batch: 560; loss: 1.16; acc: 0.7
Batch: 580; loss: 1.6; acc: 0.41
Batch: 600; loss: 1.67; acc: 0.48
Batch: 620; loss: 1.11; acc: 0.7
Batch: 640; loss: 1.37; acc: 0.47
Batch: 660; loss: 1.12; acc: 0.67
Batch: 680; loss: 1.2; acc: 0.64
Batch: 700; loss: 1.57; acc: 0.52
Batch: 720; loss: 1.22; acc: 0.56
Batch: 740; loss: 1.26; acc: 0.62
Batch: 760; loss: 1.34; acc: 0.53
Batch: 780; loss: 1.18; acc: 0.64
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.819061981223058e-05
5.930033694312442e-06
Batch: 0; loss: 1.39; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.58
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.05; acc: 0.66
Batch: 100; loss: 1.02; acc: 0.67
Batch: 120; loss: 1.44; acc: 0.48
Batch: 140; loss: 1.16; acc: 0.61
Val Epoch over. val_loss: 1.2427959981238006; val_accuracy: 0.5977308917197452 

The current subspace-distance is: 5.930033694312442e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.4; acc: 0.53
Batch: 20; loss: 1.31; acc: 0.48
Batch: 40; loss: 1.25; acc: 0.58
Batch: 60; loss: 1.22; acc: 0.59
Batch: 80; loss: 1.17; acc: 0.62
Batch: 100; loss: 1.28; acc: 0.56
Batch: 120; loss: 1.04; acc: 0.64
Batch: 140; loss: 1.21; acc: 0.58
Batch: 160; loss: 1.13; acc: 0.64
Batch: 180; loss: 1.11; acc: 0.69
Batch: 200; loss: 1.3; acc: 0.56
Batch: 220; loss: 1.36; acc: 0.53
Batch: 240; loss: 1.39; acc: 0.47
Batch: 260; loss: 1.12; acc: 0.67
Batch: 280; loss: 1.37; acc: 0.53
Batch: 300; loss: 1.57; acc: 0.5
Batch: 320; loss: 1.49; acc: 0.53
Batch: 340; loss: 1.0; acc: 0.64
Batch: 360; loss: 1.09; acc: 0.72
Batch: 380; loss: 1.07; acc: 0.64
Batch: 400; loss: 1.21; acc: 0.66
Batch: 420; loss: 1.26; acc: 0.56
Batch: 440; loss: 1.52; acc: 0.52
Batch: 460; loss: 1.19; acc: 0.67
Batch: 480; loss: 1.39; acc: 0.53
Batch: 500; loss: 1.36; acc: 0.59
Batch: 520; loss: 1.7; acc: 0.45
Batch: 540; loss: 1.09; acc: 0.69
Batch: 560; loss: 1.06; acc: 0.64
Batch: 580; loss: 1.03; acc: 0.66
Batch: 600; loss: 1.52; acc: 0.52
Batch: 620; loss: 1.2; acc: 0.61
Batch: 640; loss: 1.03; acc: 0.69
Batch: 660; loss: 1.01; acc: 0.64
Batch: 680; loss: 1.46; acc: 0.55
Batch: 700; loss: 1.27; acc: 0.58
Batch: 720; loss: 1.13; acc: 0.62
Batch: 740; loss: 1.27; acc: 0.53
Batch: 760; loss: 1.42; acc: 0.5
Batch: 780; loss: 1.23; acc: 0.55
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.87424029718386e-05
5.2287691687524784e-06
Batch: 0; loss: 1.4; acc: 0.47
Batch: 20; loss: 1.38; acc: 0.53
Batch: 40; loss: 1.13; acc: 0.58
Batch: 60; loss: 1.37; acc: 0.67
Batch: 80; loss: 1.06; acc: 0.66
Batch: 100; loss: 1.05; acc: 0.66
Batch: 120; loss: 1.47; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.61
Val Epoch over. val_loss: 1.2464571367403505; val_accuracy: 0.5957404458598726 

The current subspace-distance is: 5.2287691687524784e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.31; acc: 0.62
Batch: 20; loss: 1.42; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.66
Batch: 60; loss: 1.21; acc: 0.56
Batch: 80; loss: 1.19; acc: 0.59
Batch: 100; loss: 1.31; acc: 0.61
Batch: 120; loss: 1.14; acc: 0.58
Batch: 140; loss: 1.16; acc: 0.61
Batch: 160; loss: 1.43; acc: 0.59
Batch: 180; loss: 1.39; acc: 0.56
Batch: 200; loss: 1.3; acc: 0.56
Batch: 220; loss: 1.31; acc: 0.56
Batch: 240; loss: 1.24; acc: 0.58
Batch: 260; loss: 1.09; acc: 0.64
Batch: 280; loss: 1.45; acc: 0.61
Batch: 300; loss: 1.29; acc: 0.55
Batch: 320; loss: 1.2; acc: 0.58
Batch: 340; loss: 1.38; acc: 0.48
Batch: 360; loss: 1.21; acc: 0.64
Batch: 380; loss: 1.23; acc: 0.61
Batch: 400; loss: 1.19; acc: 0.61
Batch: 420; loss: 1.15; acc: 0.56
Batch: 440; loss: 1.41; acc: 0.5
Batch: 460; loss: 1.23; acc: 0.61
Batch: 480; loss: 1.36; acc: 0.52
Batch: 500; loss: 1.61; acc: 0.66
Batch: 520; loss: 1.33; acc: 0.61
Batch: 540; loss: 1.21; acc: 0.66
Batch: 560; loss: 1.53; acc: 0.48
Batch: 580; loss: 1.18; acc: 0.59
Batch: 600; loss: 1.04; acc: 0.69
Batch: 620; loss: 1.14; acc: 0.64
Batch: 640; loss: 1.34; acc: 0.61
Batch: 660; loss: 1.52; acc: 0.53
Batch: 680; loss: 1.41; acc: 0.62
Batch: 700; loss: 1.34; acc: 0.53
Batch: 720; loss: 1.51; acc: 0.52
Batch: 740; loss: 1.51; acc: 0.53
Batch: 760; loss: 1.27; acc: 0.53
Batch: 780; loss: 1.08; acc: 0.61
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.573399276821874e-05
5.718328793591354e-06
Batch: 0; loss: 1.38; acc: 0.47
Batch: 20; loss: 1.35; acc: 0.55
Batch: 40; loss: 1.13; acc: 0.61
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.67
Batch: 100; loss: 1.02; acc: 0.7
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.19; acc: 0.58
Val Epoch over. val_loss: 1.2442112253729705; val_accuracy: 0.5928542993630573 

The current subspace-distance is: 5.718328793591354e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.11; acc: 0.62
Batch: 20; loss: 1.46; acc: 0.53
Batch: 40; loss: 1.35; acc: 0.58
Batch: 60; loss: 1.2; acc: 0.61
Batch: 80; loss: 1.43; acc: 0.5
Batch: 100; loss: 1.59; acc: 0.55
Batch: 120; loss: 1.29; acc: 0.58
Batch: 140; loss: 1.56; acc: 0.48
Batch: 160; loss: 1.12; acc: 0.67
Batch: 180; loss: 1.41; acc: 0.55
Batch: 200; loss: 1.66; acc: 0.44
Batch: 220; loss: 1.26; acc: 0.58
Batch: 240; loss: 1.05; acc: 0.67
Batch: 260; loss: 1.16; acc: 0.64
Batch: 280; loss: 1.19; acc: 0.62
Batch: 300; loss: 1.08; acc: 0.64
Batch: 320; loss: 1.45; acc: 0.5
Batch: 340; loss: 1.44; acc: 0.52
Batch: 360; loss: 1.21; acc: 0.58
Batch: 380; loss: 1.18; acc: 0.61
Batch: 400; loss: 1.48; acc: 0.58
Batch: 420; loss: 1.08; acc: 0.64
Batch: 440; loss: 1.2; acc: 0.64
Batch: 460; loss: 1.21; acc: 0.62
Batch: 480; loss: 1.26; acc: 0.59
Batch: 500; loss: 1.07; acc: 0.66
Batch: 520; loss: 1.3; acc: 0.72
Batch: 540; loss: 1.27; acc: 0.66
Batch: 560; loss: 1.3; acc: 0.53
Batch: 580; loss: 1.23; acc: 0.61
Batch: 600; loss: 1.32; acc: 0.55
Batch: 620; loss: 0.99; acc: 0.73
Batch: 640; loss: 1.23; acc: 0.55
Batch: 660; loss: 1.33; acc: 0.5
Batch: 680; loss: 1.25; acc: 0.5
Batch: 700; loss: 1.37; acc: 0.55
Batch: 720; loss: 1.01; acc: 0.7
Batch: 740; loss: 1.47; acc: 0.52
Batch: 760; loss: 1.3; acc: 0.58
Batch: 780; loss: 1.37; acc: 0.53
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.7798853150452487e-05
6.125694198999554e-06
Batch: 0; loss: 1.39; acc: 0.47
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.61
Batch: 60; loss: 1.35; acc: 0.69
Batch: 80; loss: 1.05; acc: 0.66
Batch: 100; loss: 1.02; acc: 0.66
Batch: 120; loss: 1.43; acc: 0.5
Batch: 140; loss: 1.15; acc: 0.58
Val Epoch over. val_loss: 1.245524450472206; val_accuracy: 0.5967356687898089 

The current subspace-distance is: 6.125694198999554e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.28; acc: 0.53
Batch: 20; loss: 1.39; acc: 0.58
Batch: 40; loss: 1.25; acc: 0.58
Batch: 60; loss: 1.14; acc: 0.66
Batch: 80; loss: 1.69; acc: 0.45
Batch: 100; loss: 1.23; acc: 0.59
Batch: 120; loss: 1.43; acc: 0.52
Batch: 140; loss: 1.05; acc: 0.61
Batch: 160; loss: 1.17; acc: 0.62
Batch: 180; loss: 1.21; acc: 0.61
Batch: 200; loss: 1.24; acc: 0.58
Batch: 220; loss: 1.25; acc: 0.64
Batch: 240; loss: 1.11; acc: 0.59
Batch: 260; loss: 1.39; acc: 0.48
Batch: 280; loss: 1.13; acc: 0.59
Batch: 300; loss: 1.5; acc: 0.48
Batch: 320; loss: 1.61; acc: 0.52
Batch: 340; loss: 1.08; acc: 0.62
Batch: 360; loss: 1.07; acc: 0.67
Batch: 380; loss: 1.22; acc: 0.64
Batch: 400; loss: 1.51; acc: 0.5
Batch: 420; loss: 1.36; acc: 0.56
Batch: 440; loss: 1.33; acc: 0.58
Batch: 460; loss: 1.13; acc: 0.69
Batch: 480; loss: 1.04; acc: 0.61
Batch: 500; loss: 1.43; acc: 0.48
Batch: 520; loss: 1.11; acc: 0.53
Batch: 540; loss: 1.19; acc: 0.66
Batch: 560; loss: 1.57; acc: 0.5
Batch: 580; loss: 1.29; acc: 0.58
Batch: 600; loss: 1.27; acc: 0.56
Batch: 620; loss: 1.42; acc: 0.58
Batch: 640; loss: 1.23; acc: 0.62
Batch: 660; loss: 1.44; acc: 0.53
Batch: 680; loss: 1.26; acc: 0.56
Batch: 700; loss: 1.24; acc: 0.53
Batch: 720; loss: 1.44; acc: 0.55
Batch: 740; loss: 0.89; acc: 0.75
Batch: 760; loss: 1.25; acc: 0.52
Batch: 780; loss: 1.08; acc: 0.67
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.6922742361202836e-05
6.200966254255036e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.2414434020686302; val_accuracy: 0.5968351910828026 

The current subspace-distance is: 6.200966254255036e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.09; acc: 0.66
Batch: 20; loss: 1.2; acc: 0.61
Batch: 40; loss: 1.32; acc: 0.62
Batch: 60; loss: 1.37; acc: 0.58
Batch: 80; loss: 1.3; acc: 0.62
Batch: 100; loss: 1.16; acc: 0.55
Batch: 120; loss: 1.04; acc: 0.64
Batch: 140; loss: 1.14; acc: 0.64
Batch: 160; loss: 0.99; acc: 0.69
Batch: 180; loss: 1.18; acc: 0.61
Batch: 200; loss: 1.2; acc: 0.61
Batch: 220; loss: 1.16; acc: 0.72
Batch: 240; loss: 1.53; acc: 0.53
Batch: 260; loss: 1.15; acc: 0.67
Batch: 280; loss: 1.55; acc: 0.5
Batch: 300; loss: 1.22; acc: 0.61
Batch: 320; loss: 1.13; acc: 0.66
Batch: 340; loss: 1.39; acc: 0.55
Batch: 360; loss: 0.9; acc: 0.75
Batch: 380; loss: 1.14; acc: 0.64
Batch: 400; loss: 1.74; acc: 0.47
Batch: 420; loss: 1.14; acc: 0.58
Batch: 440; loss: 1.45; acc: 0.58
Batch: 460; loss: 1.19; acc: 0.59
Batch: 480; loss: 1.29; acc: 0.59
Batch: 500; loss: 1.55; acc: 0.45
Batch: 520; loss: 1.33; acc: 0.52
Batch: 540; loss: 1.35; acc: 0.58
Batch: 560; loss: 1.27; acc: 0.56
Batch: 580; loss: 1.44; acc: 0.52
Batch: 600; loss: 1.39; acc: 0.56
Batch: 620; loss: 1.17; acc: 0.67
Batch: 640; loss: 1.03; acc: 0.66
Batch: 660; loss: 1.1; acc: 0.62
Batch: 680; loss: 1.09; acc: 0.66
Batch: 700; loss: 1.17; acc: 0.64
Batch: 720; loss: 1.29; acc: 0.53
Batch: 740; loss: 1.23; acc: 0.69
Batch: 760; loss: 1.24; acc: 0.58
Batch: 780; loss: 1.27; acc: 0.61
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.5832982171559706e-05
6.444381142500788e-06
Batch: 0; loss: 1.37; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.53
Batch: 40; loss: 1.11; acc: 0.62
Batch: 60; loss: 1.34; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.72
Batch: 120; loss: 1.44; acc: 0.48
Batch: 140; loss: 1.18; acc: 0.59
Val Epoch over. val_loss: 1.2413322359892973; val_accuracy: 0.5967356687898089 

The current subspace-distance is: 6.444381142500788e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.34; acc: 0.55
Batch: 20; loss: 1.1; acc: 0.62
Batch: 40; loss: 1.26; acc: 0.59
Batch: 60; loss: 1.25; acc: 0.69
Batch: 80; loss: 1.29; acc: 0.55
Batch: 100; loss: 1.19; acc: 0.62
Batch: 120; loss: 1.26; acc: 0.56
Batch: 140; loss: 1.18; acc: 0.64
Batch: 160; loss: 1.29; acc: 0.58
Batch: 180; loss: 1.42; acc: 0.55
Batch: 200; loss: 1.02; acc: 0.67
Batch: 220; loss: 1.38; acc: 0.69
Batch: 240; loss: 1.08; acc: 0.62
Batch: 260; loss: 1.34; acc: 0.59
Batch: 280; loss: 1.21; acc: 0.64
Batch: 300; loss: 1.5; acc: 0.61
Batch: 320; loss: 1.36; acc: 0.47
Batch: 340; loss: 1.17; acc: 0.58
Batch: 360; loss: 1.21; acc: 0.56
Batch: 380; loss: 1.29; acc: 0.53
Batch: 400; loss: 1.18; acc: 0.58
Batch: 420; loss: 1.39; acc: 0.56
Batch: 440; loss: 1.44; acc: 0.61
Batch: 460; loss: 1.3; acc: 0.58
Batch: 480; loss: 1.4; acc: 0.59
Batch: 500; loss: 1.31; acc: 0.52
Batch: 520; loss: 1.38; acc: 0.55
Batch: 540; loss: 1.2; acc: 0.69
Batch: 560; loss: 1.49; acc: 0.53
Batch: 580; loss: 1.21; acc: 0.59
Batch: 600; loss: 1.36; acc: 0.56
Batch: 620; loss: 1.26; acc: 0.66
Batch: 640; loss: 1.34; acc: 0.59
Batch: 660; loss: 1.29; acc: 0.61
Batch: 680; loss: 1.4; acc: 0.52
Batch: 700; loss: 1.21; acc: 0.5
Batch: 720; loss: 1.12; acc: 0.59
Batch: 740; loss: 1.21; acc: 0.52
Batch: 760; loss: 1.17; acc: 0.58
Batch: 780; loss: 1.46; acc: 0.5
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.778319892764557e-05
5.879839136468945e-06
Batch: 0; loss: 1.38; acc: 0.47
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 1.01; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.241594958457218; val_accuracy: 0.59484474522293 

The current subspace-distance is: 5.879839136468945e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.39; acc: 0.48
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 1.4; acc: 0.48
Batch: 60; loss: 1.48; acc: 0.58
Batch: 80; loss: 1.35; acc: 0.62
Batch: 100; loss: 1.32; acc: 0.61
Batch: 120; loss: 1.4; acc: 0.55
Batch: 140; loss: 1.27; acc: 0.61
Batch: 160; loss: 1.46; acc: 0.55
Batch: 180; loss: 1.31; acc: 0.59
Batch: 200; loss: 1.41; acc: 0.55
Batch: 220; loss: 1.52; acc: 0.58
Batch: 240; loss: 1.41; acc: 0.44
Batch: 260; loss: 1.21; acc: 0.66
Batch: 280; loss: 1.31; acc: 0.58
Batch: 300; loss: 1.13; acc: 0.66
Batch: 320; loss: 1.18; acc: 0.62
Batch: 340; loss: 1.35; acc: 0.61
Batch: 360; loss: 1.1; acc: 0.62
Batch: 380; loss: 1.05; acc: 0.67
Batch: 400; loss: 1.3; acc: 0.56
Batch: 420; loss: 1.15; acc: 0.64
Batch: 440; loss: 1.04; acc: 0.62
Batch: 460; loss: 1.36; acc: 0.48
Batch: 480; loss: 1.39; acc: 0.47
Batch: 500; loss: 1.06; acc: 0.69
Batch: 520; loss: 1.33; acc: 0.53
Batch: 540; loss: 1.45; acc: 0.56
Batch: 560; loss: 1.52; acc: 0.48
Batch: 580; loss: 1.1; acc: 0.62
Batch: 600; loss: 1.43; acc: 0.47
Batch: 620; loss: 1.14; acc: 0.62
Batch: 640; loss: 1.51; acc: 0.64
Batch: 660; loss: 1.35; acc: 0.53
Batch: 680; loss: 1.09; acc: 0.55
Batch: 700; loss: 1.4; acc: 0.61
Batch: 720; loss: 1.28; acc: 0.59
Batch: 740; loss: 1.13; acc: 0.61
Batch: 760; loss: 1.42; acc: 0.56
Batch: 780; loss: 1.09; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.6066371244960465e-05
5.318136118148686e-06
Batch: 0; loss: 1.38; acc: 0.47
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.62
Batch: 60; loss: 1.34; acc: 0.67
Batch: 80; loss: 1.03; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.7
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.19; acc: 0.59
Val Epoch over. val_loss: 1.2425449053952649; val_accuracy: 0.5954418789808917 

The current subspace-distance is: 5.318136118148686e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.2; acc: 0.64
Batch: 20; loss: 1.35; acc: 0.62
Batch: 40; loss: 1.29; acc: 0.5
Batch: 60; loss: 1.24; acc: 0.59
Batch: 80; loss: 1.25; acc: 0.66
Batch: 100; loss: 1.4; acc: 0.61
Batch: 120; loss: 1.21; acc: 0.67
Batch: 140; loss: 1.37; acc: 0.53
Batch: 160; loss: 1.12; acc: 0.7
Batch: 180; loss: 1.32; acc: 0.61
Batch: 200; loss: 1.28; acc: 0.55
Batch: 220; loss: 1.09; acc: 0.67
Batch: 240; loss: 1.26; acc: 0.58
Batch: 260; loss: 1.47; acc: 0.5
Batch: 280; loss: 1.49; acc: 0.48
Batch: 300; loss: 1.41; acc: 0.58
Batch: 320; loss: 1.41; acc: 0.55
Batch: 340; loss: 1.56; acc: 0.55
Batch: 360; loss: 0.93; acc: 0.73
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.37; acc: 0.59
Batch: 420; loss: 1.28; acc: 0.61
Batch: 440; loss: 1.24; acc: 0.48
Batch: 460; loss: 1.49; acc: 0.5
Batch: 480; loss: 1.14; acc: 0.64
Batch: 500; loss: 1.31; acc: 0.53
Batch: 520; loss: 1.52; acc: 0.5
Batch: 540; loss: 1.25; acc: 0.62
Batch: 560; loss: 0.94; acc: 0.7
Batch: 580; loss: 1.33; acc: 0.55
Batch: 600; loss: 1.06; acc: 0.64
Batch: 620; loss: 1.27; acc: 0.58
Batch: 640; loss: 1.06; acc: 0.66
Batch: 660; loss: 1.57; acc: 0.52
Batch: 680; loss: 1.25; acc: 0.56
Batch: 700; loss: 1.26; acc: 0.53
Batch: 720; loss: 1.44; acc: 0.52
Batch: 740; loss: 1.34; acc: 0.56
Batch: 760; loss: 1.45; acc: 0.56
Batch: 780; loss: 1.25; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.7384716556989588e-05
5.0158382691734005e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.59
Val Epoch over. val_loss: 1.2424399605981864; val_accuracy: 0.5944466560509554 

The current subspace-distance is: 5.0158382691734005e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.39; acc: 0.56
Batch: 20; loss: 1.19; acc: 0.7
Batch: 40; loss: 1.52; acc: 0.48
Batch: 60; loss: 1.46; acc: 0.52
Batch: 80; loss: 1.23; acc: 0.53
Batch: 100; loss: 1.42; acc: 0.47
Batch: 120; loss: 1.32; acc: 0.58
Batch: 140; loss: 1.34; acc: 0.58
Batch: 160; loss: 1.06; acc: 0.64
Batch: 180; loss: 1.1; acc: 0.73
Batch: 200; loss: 1.38; acc: 0.56
Batch: 220; loss: 1.63; acc: 0.59
Batch: 240; loss: 1.26; acc: 0.47
Batch: 260; loss: 1.27; acc: 0.52
Batch: 280; loss: 1.19; acc: 0.67
Batch: 300; loss: 1.34; acc: 0.58
Batch: 320; loss: 1.41; acc: 0.52
Batch: 340; loss: 1.04; acc: 0.7
Batch: 360; loss: 1.15; acc: 0.64
Batch: 380; loss: 1.14; acc: 0.58
Batch: 400; loss: 1.41; acc: 0.55
Batch: 420; loss: 1.37; acc: 0.55
Batch: 440; loss: 0.98; acc: 0.72
Batch: 460; loss: 1.43; acc: 0.53
Batch: 480; loss: 1.27; acc: 0.55
Batch: 500; loss: 1.3; acc: 0.59
Batch: 520; loss: 1.28; acc: 0.58
Batch: 540; loss: 1.13; acc: 0.61
Batch: 560; loss: 1.47; acc: 0.59
Batch: 580; loss: 1.24; acc: 0.55
Batch: 600; loss: 1.38; acc: 0.5
Batch: 620; loss: 1.38; acc: 0.55
Batch: 640; loss: 1.45; acc: 0.59
Batch: 660; loss: 1.37; acc: 0.55
Batch: 680; loss: 1.29; acc: 0.53
Batch: 700; loss: 1.18; acc: 0.69
Batch: 720; loss: 1.39; acc: 0.56
Batch: 740; loss: 1.52; acc: 0.53
Batch: 760; loss: 1.3; acc: 0.58
Batch: 780; loss: 1.22; acc: 0.59
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.75080458575394e-05
4.729457032226492e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.35; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.58
Val Epoch over. val_loss: 1.2422833222492484; val_accuracy: 0.5932523885350318 

The current subspace-distance is: 4.729457032226492e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.16; acc: 0.58
Batch: 20; loss: 1.37; acc: 0.58
Batch: 40; loss: 1.43; acc: 0.62
Batch: 60; loss: 1.59; acc: 0.47
Batch: 80; loss: 1.48; acc: 0.52
Batch: 100; loss: 1.65; acc: 0.48
Batch: 120; loss: 1.28; acc: 0.53
Batch: 140; loss: 1.39; acc: 0.56
Batch: 160; loss: 1.44; acc: 0.47
Batch: 180; loss: 1.02; acc: 0.66
Batch: 200; loss: 1.43; acc: 0.61
Batch: 220; loss: 1.36; acc: 0.56
Batch: 240; loss: 1.21; acc: 0.62
Batch: 260; loss: 1.2; acc: 0.59
Batch: 280; loss: 1.07; acc: 0.59
Batch: 300; loss: 1.16; acc: 0.58
Batch: 320; loss: 1.11; acc: 0.67
Batch: 340; loss: 1.68; acc: 0.52
Batch: 360; loss: 1.31; acc: 0.52
Batch: 380; loss: 1.13; acc: 0.61
Batch: 400; loss: 1.3; acc: 0.61
Batch: 420; loss: 1.38; acc: 0.62
Batch: 440; loss: 1.49; acc: 0.53
Batch: 460; loss: 1.26; acc: 0.52
Batch: 480; loss: 1.23; acc: 0.61
Batch: 500; loss: 1.39; acc: 0.56
Batch: 520; loss: 1.18; acc: 0.64
Batch: 540; loss: 1.29; acc: 0.59
Batch: 560; loss: 1.22; acc: 0.59
Batch: 580; loss: 1.28; acc: 0.58
Batch: 600; loss: 1.16; acc: 0.59
Batch: 620; loss: 1.13; acc: 0.69
Batch: 640; loss: 1.19; acc: 0.59
Batch: 660; loss: 1.18; acc: 0.52
Batch: 680; loss: 1.32; acc: 0.59
Batch: 700; loss: 1.37; acc: 0.59
Batch: 720; loss: 1.44; acc: 0.58
Batch: 740; loss: 1.35; acc: 0.56
Batch: 760; loss: 1.43; acc: 0.55
Batch: 780; loss: 1.31; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.864901241788175e-05
6.363798547681654e-06
Batch: 0; loss: 1.38; acc: 0.47
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.58
Batch: 60; loss: 1.36; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.66
Batch: 100; loss: 1.04; acc: 0.66
Batch: 120; loss: 1.45; acc: 0.5
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.2425416563726535; val_accuracy: 0.5942476114649682 

The current subspace-distance is: 6.363798547681654e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.24; acc: 0.55
Batch: 20; loss: 1.29; acc: 0.55
Batch: 40; loss: 1.21; acc: 0.61
Batch: 60; loss: 1.3; acc: 0.62
Batch: 80; loss: 1.32; acc: 0.56
Batch: 100; loss: 1.25; acc: 0.58
Batch: 120; loss: 1.5; acc: 0.52
Batch: 140; loss: 1.69; acc: 0.44
Batch: 160; loss: 1.49; acc: 0.5
Batch: 180; loss: 1.31; acc: 0.59
Batch: 200; loss: 1.08; acc: 0.7
Batch: 220; loss: 1.2; acc: 0.64
Batch: 240; loss: 1.34; acc: 0.58
Batch: 260; loss: 1.14; acc: 0.59
Batch: 280; loss: 1.34; acc: 0.61
Batch: 300; loss: 1.34; acc: 0.52
Batch: 320; loss: 1.52; acc: 0.62
Batch: 340; loss: 1.59; acc: 0.52
Batch: 360; loss: 1.28; acc: 0.56
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.36; acc: 0.48
Batch: 420; loss: 1.3; acc: 0.58
Batch: 440; loss: 1.27; acc: 0.53
Batch: 460; loss: 1.32; acc: 0.56
Batch: 480; loss: 1.55; acc: 0.47
Batch: 500; loss: 1.06; acc: 0.67
Batch: 520; loss: 1.02; acc: 0.66
Batch: 540; loss: 1.22; acc: 0.62
Batch: 560; loss: 1.4; acc: 0.56
Batch: 580; loss: 1.51; acc: 0.5
Batch: 600; loss: 1.39; acc: 0.53
Batch: 620; loss: 1.0; acc: 0.66
Batch: 640; loss: 1.38; acc: 0.5
Batch: 660; loss: 1.55; acc: 0.48
Batch: 680; loss: 1.37; acc: 0.56
Batch: 700; loss: 1.12; acc: 0.64
Batch: 720; loss: 1.32; acc: 0.55
Batch: 740; loss: 1.27; acc: 0.64
Batch: 760; loss: 1.28; acc: 0.56
Batch: 780; loss: 1.45; acc: 0.47
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.4375298633240163e-05
5.112842245580396e-06
Batch: 0; loss: 1.38; acc: 0.47
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.12; acc: 0.58
Batch: 60; loss: 1.35; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.67
Batch: 120; loss: 1.45; acc: 0.47
Batch: 140; loss: 1.19; acc: 0.59
Val Epoch over. val_loss: 1.2422038867215441; val_accuracy: 0.5940485668789809 

The current subspace-distance is: 5.112842245580396e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.16; acc: 0.61
Batch: 20; loss: 1.44; acc: 0.52
Batch: 40; loss: 1.14; acc: 0.62
Batch: 60; loss: 1.26; acc: 0.56
Batch: 80; loss: 1.39; acc: 0.53
Batch: 100; loss: 1.26; acc: 0.56
Batch: 120; loss: 1.16; acc: 0.61
Batch: 140; loss: 1.32; acc: 0.58
Batch: 160; loss: 1.37; acc: 0.52
Batch: 180; loss: 1.18; acc: 0.66
Batch: 200; loss: 1.45; acc: 0.59
Batch: 220; loss: 1.58; acc: 0.56
Batch: 240; loss: 1.3; acc: 0.58
Batch: 260; loss: 1.22; acc: 0.59
Batch: 280; loss: 1.33; acc: 0.56
Batch: 300; loss: 1.42; acc: 0.53
Batch: 320; loss: 1.27; acc: 0.64
Batch: 340; loss: 1.55; acc: 0.53
Batch: 360; loss: 1.18; acc: 0.59
Batch: 380; loss: 1.05; acc: 0.67
Batch: 400; loss: 1.33; acc: 0.53
Batch: 420; loss: 1.5; acc: 0.5
Batch: 440; loss: 1.12; acc: 0.67
Batch: 460; loss: 1.4; acc: 0.56
Batch: 480; loss: 1.11; acc: 0.61
Batch: 500; loss: 1.24; acc: 0.58
Batch: 520; loss: 1.39; acc: 0.5
Batch: 540; loss: 0.87; acc: 0.72
Batch: 560; loss: 1.18; acc: 0.67
Batch: 580; loss: 1.22; acc: 0.58
Batch: 600; loss: 1.13; acc: 0.69
Batch: 620; loss: 1.39; acc: 0.58
Batch: 640; loss: 1.43; acc: 0.52
Batch: 660; loss: 1.39; acc: 0.58
Batch: 680; loss: 1.31; acc: 0.56
Batch: 700; loss: 1.22; acc: 0.59
Batch: 720; loss: 1.41; acc: 0.59
Batch: 740; loss: 1.23; acc: 0.59
Batch: 760; loss: 1.18; acc: 0.59
Batch: 780; loss: 1.42; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.51840977196116e-05
4.374071522761369e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.35; acc: 0.53
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.67
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.47
Batch: 140; loss: 1.16; acc: 0.59
Val Epoch over. val_loss: 1.2420192899977325; val_accuracy: 0.5962380573248408 

The current subspace-distance is: 4.374071522761369e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.47; acc: 0.56
Batch: 20; loss: 1.54; acc: 0.52
Batch: 40; loss: 1.26; acc: 0.67
Batch: 60; loss: 1.33; acc: 0.58
Batch: 80; loss: 1.44; acc: 0.53
Batch: 100; loss: 1.54; acc: 0.53
Batch: 120; loss: 1.38; acc: 0.5
Batch: 140; loss: 1.62; acc: 0.58
Batch: 160; loss: 1.45; acc: 0.5
Batch: 180; loss: 1.18; acc: 0.61
Batch: 200; loss: 1.32; acc: 0.59
Batch: 220; loss: 1.18; acc: 0.61
Batch: 240; loss: 1.21; acc: 0.58
Batch: 260; loss: 1.25; acc: 0.58
Batch: 280; loss: 1.27; acc: 0.58
Batch: 300; loss: 1.57; acc: 0.56
Batch: 320; loss: 1.38; acc: 0.55
Batch: 340; loss: 1.36; acc: 0.53
Batch: 360; loss: 1.37; acc: 0.58
Batch: 380; loss: 1.27; acc: 0.59
Batch: 400; loss: 1.1; acc: 0.69
Batch: 420; loss: 1.34; acc: 0.53
Batch: 440; loss: 1.31; acc: 0.48
Batch: 460; loss: 1.33; acc: 0.55
Batch: 480; loss: 1.25; acc: 0.61
Batch: 500; loss: 1.1; acc: 0.66
Batch: 520; loss: 1.24; acc: 0.64
Batch: 540; loss: 1.46; acc: 0.48
Batch: 560; loss: 1.39; acc: 0.53
Batch: 580; loss: 1.27; acc: 0.58
Batch: 600; loss: 1.42; acc: 0.56
Batch: 620; loss: 1.24; acc: 0.62
Batch: 640; loss: 1.35; acc: 0.62
Batch: 660; loss: 1.29; acc: 0.61
Batch: 680; loss: 1.26; acc: 0.58
Batch: 700; loss: 1.28; acc: 0.58
Batch: 720; loss: 1.36; acc: 0.53
Batch: 740; loss: 1.26; acc: 0.66
Batch: 760; loss: 1.02; acc: 0.64
Batch: 780; loss: 1.43; acc: 0.52
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.605891520739533e-05
5.448775027616648e-06
Batch: 0; loss: 1.37; acc: 0.47
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.58
Batch: 60; loss: 1.36; acc: 0.66
Batch: 80; loss: 1.05; acc: 0.69
Batch: 100; loss: 1.04; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.47
Batch: 140; loss: 1.18; acc: 0.61
Val Epoch over. val_loss: 1.2427905585355818; val_accuracy: 0.5970342356687898 

The current subspace-distance is: 5.448775027616648e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.14; acc: 0.59
Batch: 20; loss: 1.35; acc: 0.59
Batch: 40; loss: 1.04; acc: 0.66
Batch: 60; loss: 1.44; acc: 0.55
Batch: 80; loss: 1.43; acc: 0.61
Batch: 100; loss: 1.12; acc: 0.59
Batch: 120; loss: 1.28; acc: 0.64
Batch: 140; loss: 1.2; acc: 0.62
Batch: 160; loss: 1.17; acc: 0.61
Batch: 180; loss: 1.36; acc: 0.56
Batch: 200; loss: 1.25; acc: 0.61
Batch: 220; loss: 1.25; acc: 0.59
Batch: 240; loss: 1.17; acc: 0.67
Batch: 260; loss: 1.26; acc: 0.66
Batch: 280; loss: 1.18; acc: 0.66
Batch: 300; loss: 1.43; acc: 0.58
Batch: 320; loss: 1.31; acc: 0.62
Batch: 340; loss: 1.26; acc: 0.61
Batch: 360; loss: 1.39; acc: 0.56
Batch: 380; loss: 1.5; acc: 0.5
Batch: 400; loss: 1.37; acc: 0.55
Batch: 420; loss: 1.49; acc: 0.55
Batch: 440; loss: 1.25; acc: 0.58
Batch: 460; loss: 1.36; acc: 0.59
Batch: 480; loss: 1.04; acc: 0.61
Batch: 500; loss: 1.25; acc: 0.58
Batch: 520; loss: 1.23; acc: 0.55
Batch: 540; loss: 1.47; acc: 0.53
Batch: 560; loss: 1.2; acc: 0.5
Batch: 580; loss: 1.19; acc: 0.66
Batch: 600; loss: 1.39; acc: 0.53
Batch: 620; loss: 1.34; acc: 0.58
Batch: 640; loss: 1.27; acc: 0.59
Batch: 660; loss: 1.28; acc: 0.53
Batch: 680; loss: 1.44; acc: 0.56
Batch: 700; loss: 1.37; acc: 0.62
Batch: 720; loss: 1.22; acc: 0.58
Batch: 740; loss: 1.32; acc: 0.61
Batch: 760; loss: 1.3; acc: 0.53
Batch: 780; loss: 1.07; acc: 0.69
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.689017517492175e-05
5.404008334153332e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.35; acc: 0.56
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.2412423001732795; val_accuracy: 0.5958399681528662 

The current subspace-distance is: 5.404008334153332e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.06; acc: 0.69
Batch: 20; loss: 1.08; acc: 0.66
Batch: 40; loss: 1.27; acc: 0.61
Batch: 60; loss: 1.28; acc: 0.62
Batch: 80; loss: 1.17; acc: 0.61
Batch: 100; loss: 1.18; acc: 0.58
Batch: 120; loss: 1.12; acc: 0.66
Batch: 140; loss: 1.37; acc: 0.56
Batch: 160; loss: 1.15; acc: 0.56
Batch: 180; loss: 1.19; acc: 0.66
Batch: 200; loss: 1.26; acc: 0.56
Batch: 220; loss: 1.21; acc: 0.66
Batch: 240; loss: 1.26; acc: 0.58
Batch: 260; loss: 1.25; acc: 0.62
Batch: 280; loss: 1.5; acc: 0.48
Batch: 300; loss: 1.23; acc: 0.66
Batch: 320; loss: 1.28; acc: 0.62
Batch: 340; loss: 1.12; acc: 0.62
Batch: 360; loss: 1.1; acc: 0.62
Batch: 380; loss: 1.59; acc: 0.53
Batch: 400; loss: 1.44; acc: 0.52
Batch: 420; loss: 1.35; acc: 0.52
Batch: 440; loss: 1.44; acc: 0.47
Batch: 460; loss: 1.22; acc: 0.56
Batch: 480; loss: 1.21; acc: 0.59
Batch: 500; loss: 1.25; acc: 0.66
Batch: 520; loss: 1.05; acc: 0.72
Batch: 540; loss: 1.24; acc: 0.58
Batch: 560; loss: 1.45; acc: 0.47
Batch: 580; loss: 1.51; acc: 0.56
Batch: 600; loss: 1.4; acc: 0.58
Batch: 620; loss: 1.14; acc: 0.58
Batch: 640; loss: 1.17; acc: 0.66
Batch: 660; loss: 1.23; acc: 0.58
Batch: 680; loss: 1.3; acc: 0.67
Batch: 700; loss: 1.2; acc: 0.56
Batch: 720; loss: 1.19; acc: 0.59
Batch: 740; loss: 1.1; acc: 0.66
Batch: 760; loss: 1.27; acc: 0.62
Batch: 780; loss: 1.26; acc: 0.59
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.7453028704039752e-05
5.654695087287109e-06
Batch: 0; loss: 1.38; acc: 0.48
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.55
Val Epoch over. val_loss: 1.241734830057545; val_accuracy: 0.59484474522293 

The current subspace-distance is: 5.654695087287109e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.35; acc: 0.5
Batch: 20; loss: 1.12; acc: 0.59
Batch: 40; loss: 1.62; acc: 0.42
Batch: 60; loss: 1.34; acc: 0.55
Batch: 80; loss: 1.45; acc: 0.55
Batch: 100; loss: 1.47; acc: 0.53
Batch: 120; loss: 1.64; acc: 0.5
Batch: 140; loss: 1.41; acc: 0.59
Batch: 160; loss: 1.52; acc: 0.5
Batch: 180; loss: 1.14; acc: 0.61
Batch: 200; loss: 1.19; acc: 0.62
Batch: 220; loss: 1.28; acc: 0.64
Batch: 240; loss: 1.57; acc: 0.55
Batch: 260; loss: 1.1; acc: 0.62
Batch: 280; loss: 1.07; acc: 0.55
Batch: 300; loss: 1.21; acc: 0.62
Batch: 320; loss: 1.22; acc: 0.61
Batch: 340; loss: 1.44; acc: 0.52
Batch: 360; loss: 1.48; acc: 0.45
Batch: 380; loss: 1.53; acc: 0.53
Batch: 400; loss: 1.5; acc: 0.53
Batch: 420; loss: 1.36; acc: 0.59
Batch: 440; loss: 1.38; acc: 0.56
Batch: 460; loss: 1.18; acc: 0.56
Batch: 480; loss: 1.22; acc: 0.64
Batch: 500; loss: 1.22; acc: 0.61
Batch: 520; loss: 1.1; acc: 0.62
Batch: 540; loss: 1.32; acc: 0.52
Batch: 560; loss: 1.07; acc: 0.72
Batch: 580; loss: 1.23; acc: 0.62
Batch: 600; loss: 1.34; acc: 0.62
Batch: 620; loss: 1.34; acc: 0.56
Batch: 640; loss: 1.29; acc: 0.59
Batch: 660; loss: 1.26; acc: 0.53
Batch: 680; loss: 1.24; acc: 0.56
Batch: 700; loss: 1.44; acc: 0.44
Batch: 720; loss: 1.24; acc: 0.62
Batch: 740; loss: 1.31; acc: 0.59
Batch: 760; loss: 1.07; acc: 0.69
Batch: 780; loss: 1.11; acc: 0.62
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.660108500800561e-05
5.459884960146155e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.7
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.59
Val Epoch over. val_loss: 1.2415373203860727; val_accuracy: 0.596437101910828 

The current subspace-distance is: 5.459884960146155e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.27; acc: 0.67
Batch: 20; loss: 0.97; acc: 0.7
Batch: 40; loss: 0.98; acc: 0.69
Batch: 60; loss: 1.28; acc: 0.56
Batch: 80; loss: 1.12; acc: 0.66
Batch: 100; loss: 1.04; acc: 0.64
Batch: 120; loss: 1.27; acc: 0.59
Batch: 140; loss: 1.51; acc: 0.53
Batch: 160; loss: 1.25; acc: 0.59
Batch: 180; loss: 1.25; acc: 0.55
Batch: 200; loss: 1.31; acc: 0.53
Batch: 220; loss: 1.04; acc: 0.67
Batch: 240; loss: 1.19; acc: 0.58
Batch: 260; loss: 1.31; acc: 0.61
Batch: 280; loss: 1.21; acc: 0.61
Batch: 300; loss: 1.59; acc: 0.53
Batch: 320; loss: 1.19; acc: 0.58
Batch: 340; loss: 1.22; acc: 0.61
Batch: 360; loss: 1.13; acc: 0.7
Batch: 380; loss: 1.41; acc: 0.47
Batch: 400; loss: 1.24; acc: 0.61
Batch: 420; loss: 1.02; acc: 0.62
Batch: 440; loss: 1.39; acc: 0.52
Batch: 460; loss: 1.12; acc: 0.69
Batch: 480; loss: 1.34; acc: 0.58
Batch: 500; loss: 1.29; acc: 0.58
Batch: 520; loss: 1.38; acc: 0.61
Batch: 540; loss: 1.05; acc: 0.67
Batch: 560; loss: 1.23; acc: 0.64
Batch: 580; loss: 1.5; acc: 0.53
Batch: 600; loss: 1.33; acc: 0.52
Batch: 620; loss: 1.16; acc: 0.61
Batch: 640; loss: 1.3; acc: 0.58
Batch: 660; loss: 1.26; acc: 0.61
Batch: 680; loss: 1.31; acc: 0.48
Batch: 700; loss: 1.34; acc: 0.56
Batch: 720; loss: 1.19; acc: 0.55
Batch: 740; loss: 1.08; acc: 0.69
Batch: 760; loss: 1.37; acc: 0.53
Batch: 780; loss: 1.2; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.679066008364316e-05
4.028499915875727e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.59
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.2412863407924677; val_accuracy: 0.5952428343949044 

The current subspace-distance is: 4.028499915875727e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.36; acc: 0.53
Batch: 20; loss: 1.23; acc: 0.5
Batch: 40; loss: 0.96; acc: 0.69
Batch: 60; loss: 1.36; acc: 0.61
Batch: 80; loss: 1.28; acc: 0.66
Batch: 100; loss: 1.47; acc: 0.47
Batch: 120; loss: 1.19; acc: 0.55
Batch: 140; loss: 1.23; acc: 0.59
Batch: 160; loss: 1.33; acc: 0.52
Batch: 180; loss: 1.03; acc: 0.67
Batch: 200; loss: 1.56; acc: 0.45
Batch: 220; loss: 1.28; acc: 0.58
Batch: 240; loss: 1.46; acc: 0.5
Batch: 260; loss: 1.15; acc: 0.61
Batch: 280; loss: 1.35; acc: 0.55
Batch: 300; loss: 1.29; acc: 0.58
Batch: 320; loss: 1.47; acc: 0.61
Batch: 340; loss: 1.38; acc: 0.62
Batch: 360; loss: 1.14; acc: 0.62
Batch: 380; loss: 1.2; acc: 0.64
Batch: 400; loss: 0.98; acc: 0.73
Batch: 420; loss: 1.06; acc: 0.61
Batch: 440; loss: 1.32; acc: 0.58
Batch: 460; loss: 1.48; acc: 0.52
Batch: 480; loss: 1.3; acc: 0.58
Batch: 500; loss: 1.44; acc: 0.55
Batch: 520; loss: 0.98; acc: 0.67
Batch: 540; loss: 1.48; acc: 0.56
Batch: 560; loss: 1.02; acc: 0.64
Batch: 580; loss: 1.39; acc: 0.56
Batch: 600; loss: 1.2; acc: 0.59
Batch: 620; loss: 1.56; acc: 0.45
Batch: 640; loss: 1.37; acc: 0.53
Batch: 660; loss: 1.15; acc: 0.61
Batch: 680; loss: 1.02; acc: 0.72
Batch: 700; loss: 1.02; acc: 0.7
Batch: 720; loss: 1.12; acc: 0.69
Batch: 740; loss: 1.38; acc: 0.55
Batch: 760; loss: 1.24; acc: 0.59
Batch: 780; loss: 1.49; acc: 0.52
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.7332302377326414e-05
5.817792953166645e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.58
Batch: 60; loss: 1.35; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.58
Val Epoch over. val_loss: 1.2414408132528802; val_accuracy: 0.595640923566879 

The current subspace-distance is: 5.817792953166645e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.56; acc: 0.55
Batch: 20; loss: 1.07; acc: 0.59
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.29; acc: 0.52
Batch: 80; loss: 1.03; acc: 0.67
Batch: 100; loss: 1.14; acc: 0.62
Batch: 120; loss: 1.13; acc: 0.59
Batch: 140; loss: 1.1; acc: 0.62
Batch: 160; loss: 1.32; acc: 0.55
Batch: 180; loss: 1.38; acc: 0.59
Batch: 200; loss: 1.61; acc: 0.59
Batch: 220; loss: 1.2; acc: 0.58
Batch: 240; loss: 1.43; acc: 0.58
Batch: 260; loss: 1.34; acc: 0.56
Batch: 280; loss: 1.49; acc: 0.53
Batch: 300; loss: 1.33; acc: 0.48
Batch: 320; loss: 1.46; acc: 0.53
Batch: 340; loss: 1.45; acc: 0.56
Batch: 360; loss: 1.52; acc: 0.53
Batch: 380; loss: 1.27; acc: 0.62
Batch: 400; loss: 1.39; acc: 0.55
Batch: 420; loss: 1.03; acc: 0.69
Batch: 440; loss: 0.84; acc: 0.73
Batch: 460; loss: 1.12; acc: 0.61
Batch: 480; loss: 1.23; acc: 0.62
Batch: 500; loss: 1.2; acc: 0.61
Batch: 520; loss: 1.1; acc: 0.56
Batch: 540; loss: 1.07; acc: 0.67
Batch: 560; loss: 1.4; acc: 0.61
Batch: 580; loss: 1.21; acc: 0.59
Batch: 600; loss: 1.24; acc: 0.61
Batch: 620; loss: 1.28; acc: 0.58
Batch: 640; loss: 1.13; acc: 0.61
Batch: 660; loss: 1.23; acc: 0.64
Batch: 680; loss: 1.49; acc: 0.58
Batch: 700; loss: 0.99; acc: 0.75
Batch: 720; loss: 1.25; acc: 0.61
Batch: 740; loss: 1.18; acc: 0.55
Batch: 760; loss: 1.02; acc: 0.67
Batch: 780; loss: 1.22; acc: 0.62
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

2.0822591977776028e-05
6.2465201153827365e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.45; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.56
Val Epoch over. val_loss: 1.241470006620808; val_accuracy: 0.5952428343949044 

The current subspace-distance is: 6.2465201153827365e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.01; acc: 0.7
Batch: 20; loss: 0.92; acc: 0.73
Batch: 40; loss: 1.26; acc: 0.58
Batch: 60; loss: 1.19; acc: 0.62
Batch: 80; loss: 1.24; acc: 0.61
Batch: 100; loss: 1.49; acc: 0.47
Batch: 120; loss: 1.25; acc: 0.64
Batch: 140; loss: 0.91; acc: 0.67
Batch: 160; loss: 1.11; acc: 0.64
Batch: 180; loss: 1.27; acc: 0.56
Batch: 200; loss: 1.29; acc: 0.55
Batch: 220; loss: 1.11; acc: 0.67
Batch: 240; loss: 1.15; acc: 0.59
Batch: 260; loss: 1.18; acc: 0.67
Batch: 280; loss: 1.06; acc: 0.75
Batch: 300; loss: 1.22; acc: 0.64
Batch: 320; loss: 1.45; acc: 0.59
Batch: 340; loss: 1.19; acc: 0.55
Batch: 360; loss: 1.22; acc: 0.61
Batch: 380; loss: 1.39; acc: 0.62
Batch: 400; loss: 1.39; acc: 0.56
Batch: 420; loss: 1.23; acc: 0.59
Batch: 440; loss: 1.21; acc: 0.62
Batch: 460; loss: 1.04; acc: 0.61
Batch: 480; loss: 1.59; acc: 0.52
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.23; acc: 0.59
Batch: 540; loss: 0.96; acc: 0.62
Batch: 560; loss: 1.4; acc: 0.62
Batch: 580; loss: 1.28; acc: 0.56
Batch: 600; loss: 1.13; acc: 0.66
Batch: 620; loss: 1.27; acc: 0.52
Batch: 640; loss: 1.43; acc: 0.47
Batch: 660; loss: 1.15; acc: 0.67
Batch: 680; loss: 0.89; acc: 0.7
Batch: 700; loss: 1.27; acc: 0.55
Batch: 720; loss: 1.09; acc: 0.59
Batch: 740; loss: 1.31; acc: 0.55
Batch: 760; loss: 1.05; acc: 0.67
Batch: 780; loss: 1.23; acc: 0.56
Train Epoch over. train_loss: 1.28; train_accuracy: 0.58 

1.9133309251628816e-05
4.922608695778763e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.03; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.58
Val Epoch over. val_loss: 1.2411093548604637; val_accuracy: 0.5958399681528662 

The current subspace-distance is: 4.922608695778763e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.27; acc: 0.53
Batch: 20; loss: 1.43; acc: 0.5
Batch: 40; loss: 1.08; acc: 0.59
Batch: 60; loss: 1.47; acc: 0.52
Batch: 80; loss: 1.05; acc: 0.64
Batch: 100; loss: 1.22; acc: 0.61
Batch: 120; loss: 1.43; acc: 0.45
Batch: 140; loss: 1.42; acc: 0.55
Batch: 160; loss: 1.47; acc: 0.55
Batch: 180; loss: 1.51; acc: 0.55
Batch: 200; loss: 1.33; acc: 0.48
Batch: 220; loss: 1.18; acc: 0.62
Batch: 240; loss: 1.14; acc: 0.61
Batch: 260; loss: 1.31; acc: 0.52
Batch: 280; loss: 1.57; acc: 0.45
Batch: 300; loss: 1.26; acc: 0.64
Batch: 320; loss: 1.18; acc: 0.67
Batch: 340; loss: 1.04; acc: 0.66
Batch: 360; loss: 1.45; acc: 0.61
Batch: 380; loss: 1.36; acc: 0.58
Batch: 400; loss: 1.41; acc: 0.5
Batch: 420; loss: 1.39; acc: 0.56
Batch: 440; loss: 1.28; acc: 0.61
Batch: 460; loss: 1.14; acc: 0.66
Batch: 480; loss: 1.11; acc: 0.64
Batch: 500; loss: 1.29; acc: 0.61
Batch: 520; loss: 1.25; acc: 0.61
Batch: 540; loss: 1.28; acc: 0.64
Batch: 560; loss: 1.3; acc: 0.59
Batch: 580; loss: 1.23; acc: 0.66
Batch: 600; loss: 1.25; acc: 0.58
Batch: 620; loss: 1.2; acc: 0.59
Batch: 640; loss: 1.15; acc: 0.59
Batch: 660; loss: 1.46; acc: 0.52
Batch: 680; loss: 1.25; acc: 0.53
Batch: 700; loss: 1.14; acc: 0.59
Batch: 720; loss: 1.07; acc: 0.59
Batch: 740; loss: 1.52; acc: 0.55
Batch: 760; loss: 1.52; acc: 0.48
Batch: 780; loss: 1.29; acc: 0.59
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.5849715055082925e-05
5.204176886763889e-06
Batch: 0; loss: 1.38; acc: 0.45
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.69
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.17; acc: 0.56
Val Epoch over. val_loss: 1.2412616181525455; val_accuracy: 0.5944466560509554 

The current subspace-distance is: 5.204176886763889e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.56
Batch: 20; loss: 1.37; acc: 0.53
Batch: 40; loss: 1.19; acc: 0.66
Batch: 60; loss: 1.05; acc: 0.67
Batch: 80; loss: 1.39; acc: 0.45
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.42; acc: 0.52
Batch: 140; loss: 1.16; acc: 0.61
Batch: 160; loss: 1.27; acc: 0.59
Batch: 180; loss: 1.42; acc: 0.56
Batch: 200; loss: 1.51; acc: 0.5
Batch: 220; loss: 1.4; acc: 0.5
Batch: 240; loss: 1.32; acc: 0.58
Batch: 260; loss: 0.99; acc: 0.69
Batch: 280; loss: 1.09; acc: 0.59
Batch: 300; loss: 1.23; acc: 0.64
Batch: 320; loss: 1.51; acc: 0.53
Batch: 340; loss: 1.57; acc: 0.42
Batch: 360; loss: 1.4; acc: 0.55
Batch: 380; loss: 1.23; acc: 0.62
Batch: 400; loss: 1.37; acc: 0.52
Batch: 420; loss: 1.13; acc: 0.55
Batch: 440; loss: 1.27; acc: 0.58
Batch: 460; loss: 1.12; acc: 0.69
Batch: 480; loss: 1.07; acc: 0.66
Batch: 500; loss: 1.19; acc: 0.59
Batch: 520; loss: 1.22; acc: 0.59
Batch: 540; loss: 1.24; acc: 0.66
Batch: 560; loss: 1.22; acc: 0.64
Batch: 580; loss: 1.06; acc: 0.59
Batch: 600; loss: 1.21; acc: 0.59
Batch: 620; loss: 1.54; acc: 0.47
Batch: 640; loss: 1.27; acc: 0.61
Batch: 660; loss: 1.25; acc: 0.59
Batch: 680; loss: 1.46; acc: 0.5
Batch: 700; loss: 1.24; acc: 0.62
Batch: 720; loss: 1.22; acc: 0.62
Batch: 740; loss: 1.49; acc: 0.52
Batch: 760; loss: 1.47; acc: 0.48
Batch: 780; loss: 1.3; acc: 0.58
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.545934719615616e-05
5.09780375068658e-06
Batch: 0; loss: 1.38; acc: 0.48
Batch: 20; loss: 1.37; acc: 0.56
Batch: 40; loss: 1.12; acc: 0.59
Batch: 60; loss: 1.34; acc: 0.67
Batch: 80; loss: 1.03; acc: 0.67
Batch: 100; loss: 1.02; acc: 0.67
Batch: 120; loss: 1.44; acc: 0.47
Batch: 140; loss: 1.19; acc: 0.56
Val Epoch over. val_loss: 1.242297459180188; val_accuracy: 0.5927547770700637 

The current subspace-distance is: 5.09780375068658e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.18; acc: 0.58
Batch: 20; loss: 1.21; acc: 0.64
Batch: 40; loss: 1.21; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.52
Batch: 80; loss: 1.47; acc: 0.53
Batch: 100; loss: 1.54; acc: 0.48
Batch: 120; loss: 1.15; acc: 0.58
Batch: 140; loss: 1.14; acc: 0.67
Batch: 160; loss: 1.32; acc: 0.53
Batch: 180; loss: 1.72; acc: 0.47
Batch: 200; loss: 1.33; acc: 0.66
Batch: 220; loss: 1.16; acc: 0.62
Batch: 240; loss: 1.15; acc: 0.61
Batch: 260; loss: 1.13; acc: 0.58
Batch: 280; loss: 1.03; acc: 0.7
Batch: 300; loss: 1.1; acc: 0.67
Batch: 320; loss: 1.54; acc: 0.5
Batch: 340; loss: 1.01; acc: 0.67
Batch: 360; loss: 1.33; acc: 0.56
Batch: 380; loss: 1.07; acc: 0.66
Batch: 400; loss: 1.43; acc: 0.56
Batch: 420; loss: 1.48; acc: 0.44
Batch: 440; loss: 1.37; acc: 0.55
Batch: 460; loss: 1.01; acc: 0.64
Batch: 480; loss: 0.97; acc: 0.66
Batch: 500; loss: 1.06; acc: 0.61
Batch: 520; loss: 1.27; acc: 0.59
Batch: 540; loss: 1.54; acc: 0.48
Batch: 560; loss: 1.24; acc: 0.58
Batch: 580; loss: 0.89; acc: 0.67
Batch: 600; loss: 1.03; acc: 0.7
Batch: 620; loss: 1.42; acc: 0.56
Batch: 640; loss: 1.01; acc: 0.7
Batch: 660; loss: 1.3; acc: 0.64
Batch: 680; loss: 1.76; acc: 0.42
Batch: 700; loss: 1.41; acc: 0.55
Batch: 720; loss: 1.41; acc: 0.53
Batch: 740; loss: 1.12; acc: 0.56
Batch: 760; loss: 1.22; acc: 0.61
Batch: 780; loss: 1.07; acc: 0.7
Train Epoch over. train_loss: 1.28; train_accuracy: 0.59 

1.6025598597479984e-05
6.106084128987277e-06
Batch: 0; loss: 1.37; acc: 0.48
Batch: 20; loss: 1.37; acc: 0.55
Batch: 40; loss: 1.11; acc: 0.61
Batch: 60; loss: 1.34; acc: 0.66
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.67
Batch: 120; loss: 1.44; acc: 0.45
Batch: 140; loss: 1.18; acc: 0.56
Val Epoch over. val_loss: 1.2413447962445059; val_accuracy: 0.5933519108280255 

The current subspace-distance is: 6.106084128987277e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 15565
elements in E: 3331950
fraction nonzero: 0.004671438647038521
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.32; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.31; acc: 0.12
Batch: 260; loss: 2.31; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.03
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.08
Batch: 420; loss: 2.29; acc: 0.12
Batch: 440; loss: 2.28; acc: 0.09
Batch: 460; loss: 2.29; acc: 0.05
Batch: 480; loss: 2.29; acc: 0.11
Batch: 500; loss: 2.29; acc: 0.09
Batch: 520; loss: 2.29; acc: 0.11
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.28; acc: 0.17
Batch: 600; loss: 2.28; acc: 0.14
Batch: 620; loss: 2.29; acc: 0.08
Batch: 640; loss: 2.28; acc: 0.08
Batch: 660; loss: 2.29; acc: 0.11
Batch: 680; loss: 2.28; acc: 0.19
Batch: 700; loss: 2.27; acc: 0.11
Batch: 720; loss: 2.29; acc: 0.17
Batch: 740; loss: 2.29; acc: 0.09
Batch: 760; loss: 2.29; acc: 0.06
Batch: 780; loss: 2.28; acc: 0.12
Train Epoch over. train_loss: 2.29; train_accuracy: 0.11 

3.5246291645307792e-06
1.2025402611470781e-06
Batch: 0; loss: 2.28; acc: 0.2
Batch: 20; loss: 2.28; acc: 0.2
Batch: 40; loss: 2.27; acc: 0.17
Batch: 60; loss: 2.27; acc: 0.14
Batch: 80; loss: 2.27; acc: 0.19
Batch: 100; loss: 2.28; acc: 0.16
Batch: 120; loss: 2.27; acc: 0.2
Batch: 140; loss: 2.27; acc: 0.23
Val Epoch over. val_loss: 2.2780628204345703; val_accuracy: 0.1787420382165605 

The current subspace-distance is: 1.2025402611470781e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.14
Batch: 20; loss: 2.28; acc: 0.17
Batch: 40; loss: 2.29; acc: 0.19
Batch: 60; loss: 2.27; acc: 0.25
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.27; acc: 0.2
Batch: 120; loss: 2.27; acc: 0.34
Batch: 140; loss: 2.28; acc: 0.23
Batch: 160; loss: 2.28; acc: 0.25
Batch: 180; loss: 2.27; acc: 0.27
Batch: 200; loss: 2.27; acc: 0.27
Batch: 220; loss: 2.26; acc: 0.31
Batch: 240; loss: 2.27; acc: 0.17
Batch: 260; loss: 2.27; acc: 0.27
Batch: 280; loss: 2.26; acc: 0.27
Batch: 300; loss: 2.27; acc: 0.27
Batch: 320; loss: 2.26; acc: 0.28
Batch: 340; loss: 2.26; acc: 0.27
Batch: 360; loss: 2.26; acc: 0.25
Batch: 380; loss: 2.25; acc: 0.28
Batch: 400; loss: 2.25; acc: 0.27
Batch: 420; loss: 2.24; acc: 0.28
Batch: 440; loss: 2.25; acc: 0.22
Batch: 460; loss: 2.26; acc: 0.23
Batch: 480; loss: 2.27; acc: 0.14
Batch: 500; loss: 2.21; acc: 0.38
Batch: 520; loss: 2.22; acc: 0.38
Batch: 540; loss: 2.25; acc: 0.2
Batch: 560; loss: 2.26; acc: 0.19
Batch: 580; loss: 2.22; acc: 0.28
Batch: 600; loss: 2.25; acc: 0.23
Batch: 620; loss: 2.19; acc: 0.3
Batch: 640; loss: 2.22; acc: 0.19
Batch: 660; loss: 2.16; acc: 0.31
Batch: 680; loss: 2.17; acc: 0.31
Batch: 700; loss: 2.21; acc: 0.27
Batch: 720; loss: 2.16; acc: 0.31
Batch: 740; loss: 2.19; acc: 0.22
Batch: 760; loss: 2.18; acc: 0.28
Batch: 780; loss: 2.09; acc: 0.41
Train Epoch over. train_loss: 2.24; train_accuracy: 0.26 

6.589657459699083e-06
3.0934631922718836e-06
Batch: 0; loss: 2.15; acc: 0.39
Batch: 20; loss: 2.17; acc: 0.22
Batch: 40; loss: 2.07; acc: 0.34
Batch: 60; loss: 2.08; acc: 0.39
Batch: 80; loss: 2.13; acc: 0.27
Batch: 100; loss: 2.07; acc: 0.34
Batch: 120; loss: 2.1; acc: 0.42
Batch: 140; loss: 2.12; acc: 0.36
Val Epoch over. val_loss: 2.143260410636853; val_accuracy: 0.2955812101910828 

The current subspace-distance is: 3.0934631922718836e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.2; acc: 0.27
Batch: 20; loss: 2.1; acc: 0.31
Batch: 40; loss: 2.12; acc: 0.27
Batch: 60; loss: 2.09; acc: 0.3
Batch: 80; loss: 2.1; acc: 0.27
Batch: 100; loss: 2.08; acc: 0.41
Batch: 120; loss: 2.1; acc: 0.31
Batch: 140; loss: 1.97; acc: 0.38
Batch: 160; loss: 1.86; acc: 0.45
Batch: 180; loss: 1.94; acc: 0.44
Batch: 200; loss: 1.83; acc: 0.41
Batch: 220; loss: 1.75; acc: 0.5
Batch: 240; loss: 1.74; acc: 0.52
Batch: 260; loss: 1.66; acc: 0.55
Batch: 280; loss: 1.45; acc: 0.58
Batch: 300; loss: 1.58; acc: 0.58
Batch: 320; loss: 1.65; acc: 0.5
Batch: 340; loss: 1.64; acc: 0.53
Batch: 360; loss: 1.51; acc: 0.53
Batch: 380; loss: 1.51; acc: 0.48
Batch: 400; loss: 1.49; acc: 0.53
Batch: 420; loss: 1.3; acc: 0.69
Batch: 440; loss: 1.32; acc: 0.58
Batch: 460; loss: 1.35; acc: 0.56
Batch: 480; loss: 1.08; acc: 0.66
Batch: 500; loss: 1.13; acc: 0.69
Batch: 520; loss: 1.23; acc: 0.55
Batch: 540; loss: 1.3; acc: 0.58
Batch: 560; loss: 1.1; acc: 0.69
Batch: 580; loss: 1.03; acc: 0.78
Batch: 600; loss: 1.04; acc: 0.66
Batch: 620; loss: 1.28; acc: 0.64
Batch: 640; loss: 1.36; acc: 0.64
Batch: 660; loss: 1.07; acc: 0.67
Batch: 680; loss: 0.99; acc: 0.72
Batch: 700; loss: 1.0; acc: 0.66
Batch: 720; loss: 0.72; acc: 0.8
Batch: 740; loss: 1.21; acc: 0.62
Batch: 760; loss: 1.34; acc: 0.56
Batch: 780; loss: 1.03; acc: 0.64
Train Epoch over. train_loss: 1.5; train_accuracy: 0.53 

1.4943889254936948e-05
6.985828349570511e-06
Batch: 0; loss: 1.03; acc: 0.64
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 0.83; acc: 0.73
Batch: 60; loss: 1.01; acc: 0.69
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.69
Batch: 120; loss: 1.36; acc: 0.55
Batch: 140; loss: 0.55; acc: 0.84
Val Epoch over. val_loss: 0.987465730138645; val_accuracy: 0.6813296178343949 

The current subspace-distance is: 6.985828349570511e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.08; acc: 0.61
Batch: 20; loss: 1.15; acc: 0.59
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.24; acc: 0.59
Batch: 80; loss: 1.19; acc: 0.59
Batch: 100; loss: 1.07; acc: 0.7
Batch: 120; loss: 1.06; acc: 0.67
Batch: 140; loss: 0.89; acc: 0.73
Batch: 160; loss: 1.12; acc: 0.67
Batch: 180; loss: 1.05; acc: 0.69
Batch: 200; loss: 1.28; acc: 0.58
Batch: 220; loss: 0.92; acc: 0.67
Batch: 240; loss: 1.13; acc: 0.67
Batch: 260; loss: 0.83; acc: 0.67
Batch: 280; loss: 1.28; acc: 0.62
Batch: 300; loss: 1.24; acc: 0.59
Batch: 320; loss: 0.96; acc: 0.73
Batch: 340; loss: 0.86; acc: 0.64
Batch: 360; loss: 0.83; acc: 0.75
Batch: 380; loss: 1.07; acc: 0.64
Batch: 400; loss: 0.86; acc: 0.72
Batch: 420; loss: 1.04; acc: 0.67
Batch: 440; loss: 1.06; acc: 0.64
Batch: 460; loss: 1.16; acc: 0.67
Batch: 480; loss: 0.99; acc: 0.66
Batch: 500; loss: 1.01; acc: 0.69
Batch: 520; loss: 1.15; acc: 0.61
Batch: 540; loss: 1.14; acc: 0.69
Batch: 560; loss: 1.07; acc: 0.66
Batch: 580; loss: 1.04; acc: 0.67
Batch: 600; loss: 0.99; acc: 0.72
Batch: 620; loss: 1.25; acc: 0.62
Batch: 640; loss: 0.9; acc: 0.8
Batch: 660; loss: 0.87; acc: 0.73
Batch: 680; loss: 0.93; acc: 0.69
Batch: 700; loss: 0.8; acc: 0.81
Batch: 720; loss: 0.93; acc: 0.69
Batch: 740; loss: 0.88; acc: 0.72
Batch: 760; loss: 1.1; acc: 0.62
Batch: 780; loss: 0.92; acc: 0.7
Train Epoch over. train_loss: 1.0; train_accuracy: 0.69 

1.6529664208064787e-05
6.093833235354396e-06
Batch: 0; loss: 0.94; acc: 0.67
Batch: 20; loss: 1.22; acc: 0.59
Batch: 40; loss: 0.81; acc: 0.72
Batch: 60; loss: 1.09; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.76; acc: 0.72
Batch: 120; loss: 1.21; acc: 0.59
Batch: 140; loss: 0.53; acc: 0.88
Val Epoch over. val_loss: 0.9290468223914978; val_accuracy: 0.7029259554140127 

The current subspace-distance is: 6.093833235354396e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.41; acc: 0.56
Batch: 20; loss: 1.27; acc: 0.61
Batch: 40; loss: 0.9; acc: 0.78
Batch: 60; loss: 1.33; acc: 0.61
Batch: 80; loss: 0.69; acc: 0.77
Batch: 100; loss: 1.11; acc: 0.58
Batch: 120; loss: 0.93; acc: 0.67
Batch: 140; loss: 0.83; acc: 0.8
Batch: 160; loss: 1.04; acc: 0.66
Batch: 180; loss: 0.73; acc: 0.83
Batch: 200; loss: 0.87; acc: 0.72
Batch: 220; loss: 0.69; acc: 0.78
Batch: 240; loss: 1.13; acc: 0.67
Batch: 260; loss: 0.92; acc: 0.7
Batch: 280; loss: 0.77; acc: 0.81
Batch: 300; loss: 1.03; acc: 0.69
Batch: 320; loss: 0.93; acc: 0.69
Batch: 340; loss: 0.91; acc: 0.72
Batch: 360; loss: 0.98; acc: 0.73
Batch: 380; loss: 1.0; acc: 0.7
Batch: 400; loss: 0.95; acc: 0.7
Batch: 420; loss: 1.02; acc: 0.7
Batch: 440; loss: 1.4; acc: 0.56
Batch: 460; loss: 0.92; acc: 0.77
Batch: 480; loss: 1.06; acc: 0.73
Batch: 500; loss: 0.98; acc: 0.69
Batch: 520; loss: 1.12; acc: 0.62
Batch: 540; loss: 1.22; acc: 0.58
Batch: 560; loss: 0.85; acc: 0.77
Batch: 580; loss: 1.07; acc: 0.62
Batch: 600; loss: 0.93; acc: 0.77
Batch: 620; loss: 1.01; acc: 0.66
Batch: 640; loss: 0.94; acc: 0.7
Batch: 660; loss: 0.97; acc: 0.7
Batch: 680; loss: 0.98; acc: 0.67
Batch: 700; loss: 1.01; acc: 0.7
Batch: 720; loss: 0.96; acc: 0.69
Batch: 740; loss: 0.85; acc: 0.73
Batch: 760; loss: 0.93; acc: 0.72
Batch: 780; loss: 0.8; acc: 0.73
Train Epoch over. train_loss: 0.98; train_accuracy: 0.7 

1.822100966819562e-05
6.994771865720395e-06
Batch: 0; loss: 0.95; acc: 0.69
Batch: 20; loss: 1.21; acc: 0.59
Batch: 40; loss: 0.79; acc: 0.72
Batch: 60; loss: 1.16; acc: 0.67
Batch: 80; loss: 0.8; acc: 0.77
Batch: 100; loss: 0.73; acc: 0.73
Batch: 120; loss: 1.32; acc: 0.55
Batch: 140; loss: 0.55; acc: 0.84
Val Epoch over. val_loss: 0.9551847804883483; val_accuracy: 0.6908837579617835 

The current subspace-distance is: 6.994771865720395e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.11; acc: 0.69
Batch: 20; loss: 0.89; acc: 0.69
Batch: 40; loss: 0.74; acc: 0.77
Batch: 60; loss: 0.87; acc: 0.7
Batch: 80; loss: 0.81; acc: 0.73
Batch: 100; loss: 0.82; acc: 0.69
Batch: 120; loss: 0.9; acc: 0.73
Batch: 140; loss: 0.99; acc: 0.69
Batch: 160; loss: 0.9; acc: 0.73
Batch: 180; loss: 1.02; acc: 0.66
Batch: 200; loss: 1.04; acc: 0.69
Batch: 220; loss: 0.7; acc: 0.83
Batch: 240; loss: 0.81; acc: 0.8
Batch: 260; loss: 1.04; acc: 0.69
Batch: 280; loss: 1.37; acc: 0.61
Batch: 300; loss: 1.18; acc: 0.67
Batch: 320; loss: 1.02; acc: 0.69
Batch: 340; loss: 0.95; acc: 0.64
Batch: 360; loss: 0.87; acc: 0.67
Batch: 380; loss: 1.03; acc: 0.64
Batch: 400; loss: 1.17; acc: 0.58
Batch: 420; loss: 1.05; acc: 0.64
Batch: 440; loss: 0.81; acc: 0.72
Batch: 460; loss: 1.2; acc: 0.53
Batch: 480; loss: 0.7; acc: 0.8
Batch: 500; loss: 1.14; acc: 0.69
Batch: 520; loss: 1.02; acc: 0.69
Batch: 540; loss: 1.11; acc: 0.69
Batch: 560; loss: 0.67; acc: 0.83
Batch: 580; loss: 0.83; acc: 0.72
Batch: 600; loss: 0.76; acc: 0.77
Batch: 620; loss: 0.84; acc: 0.72
Batch: 640; loss: 1.03; acc: 0.61
Batch: 660; loss: 1.04; acc: 0.66
Batch: 680; loss: 0.87; acc: 0.73
Batch: 700; loss: 1.06; acc: 0.62
Batch: 720; loss: 0.97; acc: 0.59
Batch: 740; loss: 1.23; acc: 0.64
Batch: 760; loss: 1.16; acc: 0.69
Batch: 780; loss: 1.39; acc: 0.58
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

1.8822929632733576e-05
6.980704711168073e-06
Batch: 0; loss: 0.93; acc: 0.7
Batch: 20; loss: 1.19; acc: 0.61
Batch: 40; loss: 0.73; acc: 0.77
Batch: 60; loss: 1.02; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.72; acc: 0.73
Batch: 120; loss: 1.21; acc: 0.64
Batch: 140; loss: 0.5; acc: 0.91
Val Epoch over. val_loss: 0.8944997447691146; val_accuracy: 0.7216361464968153 

The current subspace-distance is: 6.980704711168073e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.98; acc: 0.64
Batch: 20; loss: 0.97; acc: 0.69
Batch: 40; loss: 0.79; acc: 0.75
Batch: 60; loss: 0.99; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.72
Batch: 100; loss: 0.72; acc: 0.8
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 1.08; acc: 0.72
Batch: 160; loss: 1.03; acc: 0.62
Batch: 180; loss: 0.92; acc: 0.78
Batch: 200; loss: 0.96; acc: 0.69
Batch: 220; loss: 0.87; acc: 0.75
Batch: 240; loss: 0.96; acc: 0.7
Batch: 260; loss: 0.77; acc: 0.8
Batch: 280; loss: 1.08; acc: 0.66
Batch: 300; loss: 0.99; acc: 0.67
Batch: 320; loss: 1.22; acc: 0.59
Batch: 340; loss: 0.75; acc: 0.8
Batch: 360; loss: 0.83; acc: 0.78
Batch: 380; loss: 1.08; acc: 0.66
Batch: 400; loss: 0.93; acc: 0.64
Batch: 420; loss: 0.84; acc: 0.73
Batch: 440; loss: 0.95; acc: 0.73
Batch: 460; loss: 0.82; acc: 0.77
Batch: 480; loss: 1.03; acc: 0.78
Batch: 500; loss: 0.95; acc: 0.69
Batch: 520; loss: 0.83; acc: 0.75
Batch: 540; loss: 0.69; acc: 0.78
Batch: 560; loss: 0.78; acc: 0.73
Batch: 580; loss: 0.97; acc: 0.73
Batch: 600; loss: 0.76; acc: 0.81
Batch: 620; loss: 0.88; acc: 0.75
Batch: 640; loss: 0.77; acc: 0.78
Batch: 660; loss: 0.87; acc: 0.72
Batch: 680; loss: 1.1; acc: 0.67
Batch: 700; loss: 1.22; acc: 0.64
Batch: 720; loss: 1.07; acc: 0.66
Batch: 740; loss: 0.91; acc: 0.72
Batch: 760; loss: 1.14; acc: 0.59
Batch: 780; loss: 0.85; acc: 0.73
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

1.772535870259162e-05
6.762330940546235e-06
Batch: 0; loss: 0.96; acc: 0.73
Batch: 20; loss: 1.22; acc: 0.61
Batch: 40; loss: 0.68; acc: 0.78
Batch: 60; loss: 0.93; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.83
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.16; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.91
Val Epoch over. val_loss: 0.9029285860289434; val_accuracy: 0.7181528662420382 

The current subspace-distance is: 6.762330940546235e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.28; acc: 0.64
Batch: 20; loss: 1.2; acc: 0.66
Batch: 40; loss: 0.86; acc: 0.77
Batch: 60; loss: 1.02; acc: 0.7
Batch: 80; loss: 1.04; acc: 0.66
Batch: 100; loss: 1.01; acc: 0.69
Batch: 120; loss: 0.89; acc: 0.81
Batch: 140; loss: 1.03; acc: 0.67
Batch: 160; loss: 1.07; acc: 0.66
Batch: 180; loss: 1.05; acc: 0.72
Batch: 200; loss: 1.17; acc: 0.66
Batch: 220; loss: 0.89; acc: 0.69
Batch: 240; loss: 0.83; acc: 0.7
Batch: 260; loss: 1.01; acc: 0.69
Batch: 280; loss: 0.84; acc: 0.75
Batch: 300; loss: 0.89; acc: 0.64
Batch: 320; loss: 0.93; acc: 0.7
Batch: 340; loss: 1.11; acc: 0.58
Batch: 360; loss: 0.87; acc: 0.73
Batch: 380; loss: 1.03; acc: 0.67
Batch: 400; loss: 0.81; acc: 0.75
Batch: 420; loss: 0.75; acc: 0.78
Batch: 440; loss: 0.93; acc: 0.7
Batch: 460; loss: 0.97; acc: 0.69
Batch: 480; loss: 0.89; acc: 0.72
Batch: 500; loss: 0.92; acc: 0.73
Batch: 520; loss: 1.23; acc: 0.5
Batch: 540; loss: 1.02; acc: 0.62
Batch: 560; loss: 0.95; acc: 0.72
Batch: 580; loss: 0.94; acc: 0.67
Batch: 600; loss: 1.04; acc: 0.64
Batch: 620; loss: 0.96; acc: 0.73
Batch: 640; loss: 0.81; acc: 0.72
Batch: 660; loss: 0.81; acc: 0.72
Batch: 680; loss: 1.19; acc: 0.58
Batch: 700; loss: 1.04; acc: 0.66
Batch: 720; loss: 1.12; acc: 0.64
Batch: 740; loss: 1.18; acc: 0.67
Batch: 760; loss: 1.22; acc: 0.67
Batch: 780; loss: 0.84; acc: 0.72
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

1.803105988074094e-05
7.165217084548203e-06
Batch: 0; loss: 0.99; acc: 0.72
Batch: 20; loss: 1.17; acc: 0.64
Batch: 40; loss: 0.72; acc: 0.78
Batch: 60; loss: 0.96; acc: 0.67
Batch: 80; loss: 0.8; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.69
Batch: 120; loss: 1.15; acc: 0.64
Batch: 140; loss: 0.49; acc: 0.89
Val Epoch over. val_loss: 0.9290222567357834; val_accuracy: 0.7115843949044586 

The current subspace-distance is: 7.165217084548203e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.77
Batch: 20; loss: 0.95; acc: 0.64
Batch: 40; loss: 0.93; acc: 0.7
Batch: 60; loss: 0.73; acc: 0.8
Batch: 80; loss: 1.11; acc: 0.67
Batch: 100; loss: 1.04; acc: 0.73
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.92; acc: 0.73
Batch: 160; loss: 0.9; acc: 0.69
Batch: 180; loss: 1.03; acc: 0.62
Batch: 200; loss: 0.7; acc: 0.75
Batch: 220; loss: 1.04; acc: 0.67
Batch: 240; loss: 1.09; acc: 0.62
Batch: 260; loss: 0.86; acc: 0.69
Batch: 280; loss: 1.01; acc: 0.72
Batch: 300; loss: 1.19; acc: 0.62
Batch: 320; loss: 1.04; acc: 0.69
Batch: 340; loss: 0.82; acc: 0.75
Batch: 360; loss: 0.98; acc: 0.7
Batch: 380; loss: 1.0; acc: 0.66
Batch: 400; loss: 0.75; acc: 0.72
Batch: 420; loss: 0.99; acc: 0.7
Batch: 440; loss: 0.72; acc: 0.78
Batch: 460; loss: 0.87; acc: 0.72
Batch: 480; loss: 0.94; acc: 0.72
Batch: 500; loss: 0.87; acc: 0.67
Batch: 520; loss: 0.84; acc: 0.69
Batch: 540; loss: 0.97; acc: 0.69
Batch: 560; loss: 0.83; acc: 0.8
Batch: 580; loss: 1.04; acc: 0.69
Batch: 600; loss: 1.15; acc: 0.66
Batch: 620; loss: 1.11; acc: 0.67
Batch: 640; loss: 0.93; acc: 0.69
Batch: 660; loss: 1.12; acc: 0.61
Batch: 680; loss: 0.8; acc: 0.75
Batch: 700; loss: 1.07; acc: 0.66
Batch: 720; loss: 1.07; acc: 0.72
Batch: 740; loss: 1.16; acc: 0.64
Batch: 760; loss: 0.85; acc: 0.72
Batch: 780; loss: 0.96; acc: 0.73
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

1.7577587641426362e-05
5.4333368098014034e-06
Batch: 0; loss: 0.99; acc: 0.66
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.72; acc: 0.81
Batch: 60; loss: 1.0; acc: 0.7
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.75; acc: 0.73
Batch: 120; loss: 1.22; acc: 0.62
Batch: 140; loss: 0.49; acc: 0.89
Val Epoch over. val_loss: 0.9428073602497198; val_accuracy: 0.7089968152866242 

The current subspace-distance is: 5.4333368098014034e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.13; acc: 0.69
Batch: 20; loss: 1.17; acc: 0.55
Batch: 40; loss: 0.78; acc: 0.78
Batch: 60; loss: 1.04; acc: 0.64
Batch: 80; loss: 0.99; acc: 0.62
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 0.92; acc: 0.7
Batch: 140; loss: 1.31; acc: 0.58
Batch: 160; loss: 1.04; acc: 0.64
Batch: 180; loss: 1.0; acc: 0.7
Batch: 200; loss: 0.93; acc: 0.7
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.8; acc: 0.8
Batch: 260; loss: 1.02; acc: 0.73
Batch: 280; loss: 1.05; acc: 0.69
Batch: 300; loss: 0.96; acc: 0.72
Batch: 320; loss: 0.69; acc: 0.81
Batch: 340; loss: 0.89; acc: 0.73
Batch: 360; loss: 1.14; acc: 0.66
Batch: 380; loss: 0.92; acc: 0.75
Batch: 400; loss: 1.08; acc: 0.66
Batch: 420; loss: 1.04; acc: 0.69
Batch: 440; loss: 1.12; acc: 0.62
Batch: 460; loss: 0.97; acc: 0.69
Batch: 480; loss: 0.85; acc: 0.7
Batch: 500; loss: 1.01; acc: 0.7
Batch: 520; loss: 0.88; acc: 0.72
Batch: 540; loss: 0.87; acc: 0.7
Batch: 560; loss: 0.88; acc: 0.78
Batch: 580; loss: 1.06; acc: 0.7
Batch: 600; loss: 1.12; acc: 0.66
Batch: 620; loss: 0.84; acc: 0.77
Batch: 640; loss: 1.13; acc: 0.7
Batch: 660; loss: 1.06; acc: 0.67
Batch: 680; loss: 0.76; acc: 0.73
Batch: 700; loss: 1.06; acc: 0.69
Batch: 720; loss: 0.98; acc: 0.69
Batch: 740; loss: 0.97; acc: 0.66
Batch: 760; loss: 0.96; acc: 0.77
Batch: 780; loss: 0.85; acc: 0.72
Train Epoch over. train_loss: 0.97; train_accuracy: 0.7 

1.8614635337144136e-05
5.639665687340312e-06
Batch: 0; loss: 0.92; acc: 0.69
Batch: 20; loss: 1.23; acc: 0.66
Batch: 40; loss: 0.71; acc: 0.81
Batch: 60; loss: 0.92; acc: 0.69
Batch: 80; loss: 0.78; acc: 0.83
Batch: 100; loss: 0.82; acc: 0.66
Batch: 120; loss: 1.22; acc: 0.59
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.9227317021151257; val_accuracy: 0.7096934713375797 

The current subspace-distance is: 5.639665687340312e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.15; acc: 0.66
Batch: 20; loss: 0.78; acc: 0.77
Batch: 40; loss: 1.05; acc: 0.7
Batch: 60; loss: 0.74; acc: 0.81
Batch: 80; loss: 0.94; acc: 0.69
Batch: 100; loss: 0.92; acc: 0.73
Batch: 120; loss: 0.86; acc: 0.8
Batch: 140; loss: 1.05; acc: 0.66
Batch: 160; loss: 0.77; acc: 0.77
Batch: 180; loss: 1.04; acc: 0.67
Batch: 200; loss: 0.9; acc: 0.77
Batch: 220; loss: 0.77; acc: 0.78
Batch: 240; loss: 0.95; acc: 0.67
Batch: 260; loss: 0.76; acc: 0.73
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.88; acc: 0.72
Batch: 320; loss: 1.24; acc: 0.59
Batch: 340; loss: 0.91; acc: 0.72
Batch: 360; loss: 1.07; acc: 0.67
Batch: 380; loss: 0.88; acc: 0.7
Batch: 400; loss: 0.93; acc: 0.66
Batch: 420; loss: 0.94; acc: 0.72
Batch: 440; loss: 0.93; acc: 0.67
Batch: 460; loss: 0.94; acc: 0.73
Batch: 480; loss: 0.82; acc: 0.77
Batch: 500; loss: 1.0; acc: 0.72
Batch: 520; loss: 0.83; acc: 0.72
Batch: 540; loss: 0.66; acc: 0.8
Batch: 560; loss: 0.94; acc: 0.69
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 0.85; acc: 0.73
Batch: 620; loss: 1.01; acc: 0.77
Batch: 640; loss: 0.97; acc: 0.69
Batch: 660; loss: 0.87; acc: 0.72
Batch: 680; loss: 0.64; acc: 0.84
Batch: 700; loss: 1.02; acc: 0.66
Batch: 720; loss: 0.78; acc: 0.73
Batch: 740; loss: 0.85; acc: 0.75
Batch: 760; loss: 1.03; acc: 0.67
Batch: 780; loss: 1.18; acc: 0.69
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.834639988373965e-05
6.0585466599150095e-06
Batch: 0; loss: 0.89; acc: 0.75
Batch: 20; loss: 1.15; acc: 0.67
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.94; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.73
Batch: 120; loss: 1.23; acc: 0.64
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8918974879820636; val_accuracy: 0.7237261146496815 

The current subspace-distance is: 6.0585466599150095e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.91; acc: 0.72
Batch: 20; loss: 0.88; acc: 0.77
Batch: 40; loss: 1.24; acc: 0.66
Batch: 60; loss: 1.02; acc: 0.67
Batch: 80; loss: 0.78; acc: 0.8
Batch: 100; loss: 0.77; acc: 0.72
Batch: 120; loss: 1.0; acc: 0.69
Batch: 140; loss: 1.07; acc: 0.66
Batch: 160; loss: 1.25; acc: 0.66
Batch: 180; loss: 1.03; acc: 0.64
Batch: 200; loss: 0.96; acc: 0.72
Batch: 220; loss: 1.1; acc: 0.67
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 1.12; acc: 0.67
Batch: 280; loss: 0.88; acc: 0.73
Batch: 300; loss: 0.92; acc: 0.7
Batch: 320; loss: 0.92; acc: 0.73
Batch: 340; loss: 0.87; acc: 0.69
Batch: 360; loss: 0.93; acc: 0.7
Batch: 380; loss: 1.07; acc: 0.67
Batch: 400; loss: 0.95; acc: 0.75
Batch: 420; loss: 1.03; acc: 0.73
Batch: 440; loss: 0.96; acc: 0.72
Batch: 460; loss: 1.31; acc: 0.66
Batch: 480; loss: 1.04; acc: 0.66
Batch: 500; loss: 0.88; acc: 0.78
Batch: 520; loss: 1.0; acc: 0.73
Batch: 540; loss: 1.08; acc: 0.64
Batch: 560; loss: 0.84; acc: 0.73
Batch: 580; loss: 0.69; acc: 0.78
Batch: 600; loss: 0.64; acc: 0.81
Batch: 620; loss: 1.08; acc: 0.67
Batch: 640; loss: 1.05; acc: 0.66
Batch: 660; loss: 1.34; acc: 0.69
Batch: 680; loss: 1.06; acc: 0.67
Batch: 700; loss: 0.88; acc: 0.72
Batch: 720; loss: 0.96; acc: 0.72
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.86; acc: 0.78
Batch: 780; loss: 0.75; acc: 0.78
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9183788026566617e-05
6.337907962006284e-06
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 1.12; acc: 0.64
Batch: 40; loss: 0.7; acc: 0.8
Batch: 60; loss: 0.92; acc: 0.7
Batch: 80; loss: 0.73; acc: 0.78
Batch: 100; loss: 0.75; acc: 0.7
Batch: 120; loss: 1.19; acc: 0.61
Batch: 140; loss: 0.49; acc: 0.88
Val Epoch over. val_loss: 0.8953050902694654; val_accuracy: 0.7193471337579618 

The current subspace-distance is: 6.337907962006284e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.19; acc: 0.58
Batch: 20; loss: 1.03; acc: 0.62
Batch: 40; loss: 1.05; acc: 0.66
Batch: 60; loss: 0.81; acc: 0.75
Batch: 80; loss: 1.3; acc: 0.67
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.03; acc: 0.64
Batch: 140; loss: 1.22; acc: 0.69
Batch: 160; loss: 1.63; acc: 0.52
Batch: 180; loss: 1.18; acc: 0.58
Batch: 200; loss: 1.07; acc: 0.62
Batch: 220; loss: 0.85; acc: 0.69
Batch: 240; loss: 0.83; acc: 0.75
Batch: 260; loss: 1.23; acc: 0.66
Batch: 280; loss: 0.85; acc: 0.7
Batch: 300; loss: 1.1; acc: 0.66
Batch: 320; loss: 0.84; acc: 0.72
Batch: 340; loss: 1.01; acc: 0.69
Batch: 360; loss: 0.97; acc: 0.7
Batch: 380; loss: 0.99; acc: 0.59
Batch: 400; loss: 1.09; acc: 0.64
Batch: 420; loss: 1.07; acc: 0.62
Batch: 440; loss: 0.8; acc: 0.8
Batch: 460; loss: 0.94; acc: 0.72
Batch: 480; loss: 1.08; acc: 0.66
Batch: 500; loss: 0.92; acc: 0.72
Batch: 520; loss: 1.08; acc: 0.67
Batch: 540; loss: 0.98; acc: 0.67
Batch: 560; loss: 0.87; acc: 0.73
Batch: 580; loss: 1.1; acc: 0.69
Batch: 600; loss: 1.03; acc: 0.69
Batch: 620; loss: 0.94; acc: 0.69
Batch: 640; loss: 1.46; acc: 0.5
Batch: 660; loss: 0.82; acc: 0.73
Batch: 680; loss: 1.06; acc: 0.66
Batch: 700; loss: 0.76; acc: 0.77
Batch: 720; loss: 0.81; acc: 0.77
Batch: 740; loss: 0.98; acc: 0.7
Batch: 760; loss: 0.88; acc: 0.8
Batch: 780; loss: 1.15; acc: 0.61
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9116267139906995e-05
6.2806816458760295e-06
Batch: 0; loss: 0.9; acc: 0.72
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.92; acc: 0.69
Batch: 80; loss: 0.77; acc: 0.81
Batch: 100; loss: 0.74; acc: 0.7
Batch: 120; loss: 1.21; acc: 0.61
Batch: 140; loss: 0.52; acc: 0.91
Val Epoch over. val_loss: 0.8970250717014264; val_accuracy: 0.7234275477707006 

The current subspace-distance is: 6.2806816458760295e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.96; acc: 0.69
Batch: 20; loss: 0.92; acc: 0.73
Batch: 40; loss: 0.75; acc: 0.72
Batch: 60; loss: 1.22; acc: 0.62
Batch: 80; loss: 1.05; acc: 0.75
Batch: 100; loss: 1.11; acc: 0.67
Batch: 120; loss: 0.79; acc: 0.72
Batch: 140; loss: 0.79; acc: 0.73
Batch: 160; loss: 0.93; acc: 0.69
Batch: 180; loss: 0.89; acc: 0.72
Batch: 200; loss: 0.78; acc: 0.77
Batch: 220; loss: 1.08; acc: 0.67
Batch: 240; loss: 1.21; acc: 0.58
Batch: 260; loss: 1.0; acc: 0.67
Batch: 280; loss: 1.12; acc: 0.58
Batch: 300; loss: 1.19; acc: 0.52
Batch: 320; loss: 1.09; acc: 0.66
Batch: 340; loss: 1.01; acc: 0.69
Batch: 360; loss: 0.87; acc: 0.69
Batch: 380; loss: 0.87; acc: 0.66
Batch: 400; loss: 0.84; acc: 0.75
Batch: 420; loss: 0.94; acc: 0.67
Batch: 440; loss: 0.83; acc: 0.7
Batch: 460; loss: 1.15; acc: 0.58
Batch: 480; loss: 1.01; acc: 0.72
Batch: 500; loss: 0.94; acc: 0.62
Batch: 520; loss: 1.13; acc: 0.62
Batch: 540; loss: 1.0; acc: 0.66
Batch: 560; loss: 0.88; acc: 0.75
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 1.07; acc: 0.72
Batch: 620; loss: 0.8; acc: 0.72
Batch: 640; loss: 0.9; acc: 0.8
Batch: 660; loss: 0.85; acc: 0.69
Batch: 680; loss: 0.84; acc: 0.69
Batch: 700; loss: 1.14; acc: 0.66
Batch: 720; loss: 0.9; acc: 0.67
Batch: 740; loss: 1.18; acc: 0.64
Batch: 760; loss: 0.92; acc: 0.8
Batch: 780; loss: 1.0; acc: 0.67
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.90386545000365e-05
6.740742719557602e-06
Batch: 0; loss: 0.89; acc: 0.7
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.69; acc: 0.84
Batch: 60; loss: 0.93; acc: 0.7
Batch: 80; loss: 0.76; acc: 0.81
Batch: 100; loss: 0.74; acc: 0.7
Batch: 120; loss: 1.23; acc: 0.62
Batch: 140; loss: 0.51; acc: 0.91
Val Epoch over. val_loss: 0.896047072046122; val_accuracy: 0.7234275477707006 

The current subspace-distance is: 6.740742719557602e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.7; acc: 0.84
Batch: 20; loss: 1.1; acc: 0.67
Batch: 40; loss: 0.94; acc: 0.64
Batch: 60; loss: 0.83; acc: 0.69
Batch: 80; loss: 1.05; acc: 0.66
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.89; acc: 0.67
Batch: 160; loss: 0.93; acc: 0.67
Batch: 180; loss: 0.93; acc: 0.78
Batch: 200; loss: 0.86; acc: 0.73
Batch: 220; loss: 0.87; acc: 0.72
Batch: 240; loss: 0.89; acc: 0.67
Batch: 260; loss: 1.03; acc: 0.64
Batch: 280; loss: 0.77; acc: 0.75
Batch: 300; loss: 0.77; acc: 0.8
Batch: 320; loss: 0.94; acc: 0.75
Batch: 340; loss: 0.96; acc: 0.72
Batch: 360; loss: 1.22; acc: 0.67
Batch: 380; loss: 0.85; acc: 0.7
Batch: 400; loss: 0.88; acc: 0.69
Batch: 420; loss: 0.86; acc: 0.67
Batch: 440; loss: 0.78; acc: 0.78
Batch: 460; loss: 0.98; acc: 0.73
Batch: 480; loss: 1.04; acc: 0.69
Batch: 500; loss: 0.94; acc: 0.66
Batch: 520; loss: 0.72; acc: 0.72
Batch: 540; loss: 0.98; acc: 0.7
Batch: 560; loss: 1.06; acc: 0.66
Batch: 580; loss: 0.75; acc: 0.77
Batch: 600; loss: 0.91; acc: 0.72
Batch: 620; loss: 1.02; acc: 0.67
Batch: 640; loss: 0.96; acc: 0.66
Batch: 660; loss: 0.95; acc: 0.7
Batch: 680; loss: 0.96; acc: 0.73
Batch: 700; loss: 0.86; acc: 0.73
Batch: 720; loss: 1.16; acc: 0.62
Batch: 740; loss: 0.73; acc: 0.78
Batch: 760; loss: 0.8; acc: 0.7
Batch: 780; loss: 0.91; acc: 0.67
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.8795877622324042e-05
7.1630893216934055e-06
Batch: 0; loss: 0.88; acc: 0.72
Batch: 20; loss: 1.14; acc: 0.67
Batch: 40; loss: 0.69; acc: 0.83
Batch: 60; loss: 0.96; acc: 0.69
Batch: 80; loss: 0.76; acc: 0.8
Batch: 100; loss: 0.71; acc: 0.72
Batch: 120; loss: 1.24; acc: 0.62
Batch: 140; loss: 0.53; acc: 0.89
Val Epoch over. val_loss: 0.8975053273948135; val_accuracy: 0.7212380573248408 

The current subspace-distance is: 7.1630893216934055e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.89; acc: 0.78
Batch: 20; loss: 0.87; acc: 0.7
Batch: 40; loss: 0.78; acc: 0.73
Batch: 60; loss: 1.07; acc: 0.66
Batch: 80; loss: 0.79; acc: 0.72
Batch: 100; loss: 0.86; acc: 0.7
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 1.11; acc: 0.72
Batch: 160; loss: 0.94; acc: 0.67
Batch: 180; loss: 1.14; acc: 0.66
Batch: 200; loss: 0.83; acc: 0.73
Batch: 220; loss: 1.18; acc: 0.67
Batch: 240; loss: 0.96; acc: 0.72
Batch: 260; loss: 0.85; acc: 0.73
Batch: 280; loss: 0.89; acc: 0.67
Batch: 300; loss: 0.89; acc: 0.73
Batch: 320; loss: 1.01; acc: 0.66
Batch: 340; loss: 0.9; acc: 0.72
Batch: 360; loss: 1.01; acc: 0.64
Batch: 380; loss: 0.97; acc: 0.66
Batch: 400; loss: 1.42; acc: 0.59
Batch: 420; loss: 1.19; acc: 0.69
Batch: 440; loss: 0.73; acc: 0.78
Batch: 460; loss: 1.22; acc: 0.64
Batch: 480; loss: 1.16; acc: 0.7
Batch: 500; loss: 0.88; acc: 0.78
Batch: 520; loss: 0.79; acc: 0.8
Batch: 540; loss: 1.23; acc: 0.59
Batch: 560; loss: 0.84; acc: 0.77
Batch: 580; loss: 0.83; acc: 0.78
Batch: 600; loss: 0.98; acc: 0.67
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.81; acc: 0.77
Batch: 660; loss: 0.87; acc: 0.7
Batch: 680; loss: 0.81; acc: 0.69
Batch: 700; loss: 0.94; acc: 0.72
Batch: 720; loss: 1.17; acc: 0.72
Batch: 740; loss: 0.81; acc: 0.78
Batch: 760; loss: 0.71; acc: 0.72
Batch: 780; loss: 1.2; acc: 0.62
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.7103913705796003e-05
7.574722076242324e-06
Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 1.16; acc: 0.69
Batch: 40; loss: 0.7; acc: 0.8
Batch: 60; loss: 0.93; acc: 0.72
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.64
Batch: 140; loss: 0.52; acc: 0.88
Val Epoch over. val_loss: 0.8971481215042673; val_accuracy: 0.7241242038216561 

The current subspace-distance is: 7.574722076242324e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.83
Batch: 20; loss: 1.08; acc: 0.61
Batch: 40; loss: 0.94; acc: 0.75
Batch: 60; loss: 1.03; acc: 0.62
Batch: 80; loss: 0.81; acc: 0.73
Batch: 100; loss: 0.7; acc: 0.8
Batch: 120; loss: 0.79; acc: 0.8
Batch: 140; loss: 1.03; acc: 0.69
Batch: 160; loss: 1.07; acc: 0.73
Batch: 180; loss: 0.86; acc: 0.69
Batch: 200; loss: 1.1; acc: 0.7
Batch: 220; loss: 1.01; acc: 0.75
Batch: 240; loss: 0.98; acc: 0.7
Batch: 260; loss: 0.62; acc: 0.86
Batch: 280; loss: 0.96; acc: 0.67
Batch: 300; loss: 1.01; acc: 0.61
Batch: 320; loss: 0.86; acc: 0.72
Batch: 340; loss: 1.22; acc: 0.58
Batch: 360; loss: 0.86; acc: 0.78
Batch: 380; loss: 0.92; acc: 0.72
Batch: 400; loss: 0.8; acc: 0.75
Batch: 420; loss: 0.93; acc: 0.69
Batch: 440; loss: 0.89; acc: 0.73
Batch: 460; loss: 0.98; acc: 0.69
Batch: 480; loss: 1.02; acc: 0.7
Batch: 500; loss: 0.72; acc: 0.83
Batch: 520; loss: 0.9; acc: 0.73
Batch: 540; loss: 0.63; acc: 0.77
Batch: 560; loss: 0.87; acc: 0.72
Batch: 580; loss: 0.89; acc: 0.73
Batch: 600; loss: 0.96; acc: 0.72
Batch: 620; loss: 0.97; acc: 0.67
Batch: 640; loss: 0.96; acc: 0.72
Batch: 660; loss: 0.94; acc: 0.7
Batch: 680; loss: 1.16; acc: 0.66
Batch: 700; loss: 0.83; acc: 0.75
Batch: 720; loss: 0.96; acc: 0.73
Batch: 740; loss: 0.96; acc: 0.69
Batch: 760; loss: 0.9; acc: 0.69
Batch: 780; loss: 0.96; acc: 0.67
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.922764568007551e-05
7.668190846743528e-06
Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 1.1; acc: 0.69
Batch: 40; loss: 0.71; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.67
Batch: 80; loss: 0.76; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.69
Batch: 120; loss: 1.22; acc: 0.61
Batch: 140; loss: 0.52; acc: 0.89
Val Epoch over. val_loss: 0.8939210812377322; val_accuracy: 0.7250199044585988 

The current subspace-distance is: 7.668190846743528e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.94; acc: 0.69
Batch: 20; loss: 0.81; acc: 0.7
Batch: 40; loss: 0.94; acc: 0.73
Batch: 60; loss: 1.09; acc: 0.73
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.93; acc: 0.73
Batch: 120; loss: 0.87; acc: 0.72
Batch: 140; loss: 0.96; acc: 0.69
Batch: 160; loss: 0.84; acc: 0.73
Batch: 180; loss: 0.97; acc: 0.72
Batch: 200; loss: 1.08; acc: 0.61
Batch: 220; loss: 0.64; acc: 0.86
Batch: 240; loss: 1.01; acc: 0.67
Batch: 260; loss: 0.93; acc: 0.73
Batch: 280; loss: 0.91; acc: 0.64
Batch: 300; loss: 0.98; acc: 0.69
Batch: 320; loss: 0.78; acc: 0.78
Batch: 340; loss: 0.86; acc: 0.75
Batch: 360; loss: 1.05; acc: 0.69
Batch: 380; loss: 0.8; acc: 0.73
Batch: 400; loss: 0.7; acc: 0.78
Batch: 420; loss: 0.81; acc: 0.78
Batch: 440; loss: 0.92; acc: 0.75
Batch: 460; loss: 0.89; acc: 0.7
Batch: 480; loss: 0.7; acc: 0.78
Batch: 500; loss: 0.83; acc: 0.73
Batch: 520; loss: 1.08; acc: 0.67
Batch: 540; loss: 0.98; acc: 0.64
Batch: 560; loss: 1.17; acc: 0.61
Batch: 580; loss: 1.0; acc: 0.69
Batch: 600; loss: 0.75; acc: 0.81
Batch: 620; loss: 1.39; acc: 0.59
Batch: 640; loss: 0.82; acc: 0.72
Batch: 660; loss: 0.89; acc: 0.77
Batch: 680; loss: 0.94; acc: 0.73
Batch: 700; loss: 0.82; acc: 0.73
Batch: 720; loss: 0.9; acc: 0.67
Batch: 740; loss: 1.22; acc: 0.64
Batch: 760; loss: 1.01; acc: 0.64
Batch: 780; loss: 0.67; acc: 0.77
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9350627553649247e-05
6.594292699446669e-06
Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 1.14; acc: 0.66
Batch: 40; loss: 0.69; acc: 0.8
Batch: 60; loss: 0.92; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.83
Batch: 100; loss: 0.71; acc: 0.7
Batch: 120; loss: 1.23; acc: 0.58
Batch: 140; loss: 0.51; acc: 0.91
Val Epoch over. val_loss: 0.898115287920472; val_accuracy: 0.720640923566879 

The current subspace-distance is: 6.594292699446669e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.15; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 1.06; acc: 0.67
Batch: 60; loss: 0.87; acc: 0.73
Batch: 80; loss: 1.02; acc: 0.77
Batch: 100; loss: 0.89; acc: 0.7
Batch: 120; loss: 1.21; acc: 0.67
Batch: 140; loss: 1.0; acc: 0.72
Batch: 160; loss: 0.97; acc: 0.69
Batch: 180; loss: 0.81; acc: 0.77
Batch: 200; loss: 1.07; acc: 0.69
Batch: 220; loss: 0.99; acc: 0.7
Batch: 240; loss: 1.02; acc: 0.73
Batch: 260; loss: 0.89; acc: 0.7
Batch: 280; loss: 1.05; acc: 0.67
Batch: 300; loss: 0.91; acc: 0.72
Batch: 320; loss: 0.7; acc: 0.78
Batch: 340; loss: 0.83; acc: 0.72
Batch: 360; loss: 0.9; acc: 0.75
Batch: 380; loss: 0.93; acc: 0.69
Batch: 400; loss: 0.91; acc: 0.72
Batch: 420; loss: 1.01; acc: 0.72
Batch: 440; loss: 1.16; acc: 0.59
Batch: 460; loss: 0.99; acc: 0.69
Batch: 480; loss: 0.98; acc: 0.66
Batch: 500; loss: 0.91; acc: 0.73
Batch: 520; loss: 0.92; acc: 0.7
Batch: 540; loss: 1.0; acc: 0.7
Batch: 560; loss: 0.87; acc: 0.72
Batch: 580; loss: 0.92; acc: 0.73
Batch: 600; loss: 0.68; acc: 0.83
Batch: 620; loss: 1.15; acc: 0.64
Batch: 640; loss: 1.09; acc: 0.67
Batch: 660; loss: 1.13; acc: 0.64
Batch: 680; loss: 0.67; acc: 0.73
Batch: 700; loss: 0.88; acc: 0.7
Batch: 720; loss: 0.8; acc: 0.78
Batch: 740; loss: 0.83; acc: 0.8
Batch: 760; loss: 1.16; acc: 0.61
Batch: 780; loss: 0.85; acc: 0.73
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.752161369950045e-05
8.475195500068367e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.15; acc: 0.66
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.93; acc: 0.7
Batch: 80; loss: 0.75; acc: 0.78
Batch: 100; loss: 0.76; acc: 0.7
Batch: 120; loss: 1.29; acc: 0.58
Batch: 140; loss: 0.53; acc: 0.89
Val Epoch over. val_loss: 0.8999825169326393; val_accuracy: 0.7204418789808917 

The current subspace-distance is: 8.475195500068367e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.94; acc: 0.67
Batch: 20; loss: 1.05; acc: 0.69
Batch: 40; loss: 0.96; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.64
Batch: 80; loss: 1.49; acc: 0.53
Batch: 100; loss: 1.09; acc: 0.69
Batch: 120; loss: 1.21; acc: 0.69
Batch: 140; loss: 0.92; acc: 0.66
Batch: 160; loss: 1.2; acc: 0.61
Batch: 180; loss: 0.94; acc: 0.72
Batch: 200; loss: 0.88; acc: 0.81
Batch: 220; loss: 0.65; acc: 0.8
Batch: 240; loss: 1.14; acc: 0.56
Batch: 260; loss: 0.78; acc: 0.78
Batch: 280; loss: 1.02; acc: 0.62
Batch: 300; loss: 0.79; acc: 0.75
Batch: 320; loss: 1.19; acc: 0.61
Batch: 340; loss: 0.9; acc: 0.7
Batch: 360; loss: 1.09; acc: 0.67
Batch: 380; loss: 1.11; acc: 0.64
Batch: 400; loss: 0.93; acc: 0.73
Batch: 420; loss: 1.03; acc: 0.75
Batch: 440; loss: 0.82; acc: 0.67
Batch: 460; loss: 0.88; acc: 0.72
Batch: 480; loss: 1.11; acc: 0.69
Batch: 500; loss: 0.9; acc: 0.7
Batch: 520; loss: 0.99; acc: 0.67
Batch: 540; loss: 1.05; acc: 0.67
Batch: 560; loss: 1.05; acc: 0.64
Batch: 580; loss: 1.14; acc: 0.62
Batch: 600; loss: 0.91; acc: 0.62
Batch: 620; loss: 0.94; acc: 0.73
Batch: 640; loss: 0.83; acc: 0.77
Batch: 660; loss: 1.15; acc: 0.66
Batch: 680; loss: 0.9; acc: 0.72
Batch: 700; loss: 0.87; acc: 0.75
Batch: 720; loss: 0.73; acc: 0.69
Batch: 740; loss: 1.01; acc: 0.7
Batch: 760; loss: 0.85; acc: 0.69
Batch: 780; loss: 0.82; acc: 0.7
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.0742878405144438e-05
7.799837476341054e-06
Batch: 0; loss: 0.85; acc: 0.75
Batch: 20; loss: 1.09; acc: 0.66
Batch: 40; loss: 0.69; acc: 0.77
Batch: 60; loss: 0.92; acc: 0.69
Batch: 80; loss: 0.74; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.67
Batch: 120; loss: 1.23; acc: 0.64
Batch: 140; loss: 0.49; acc: 0.89
Val Epoch over. val_loss: 0.903693294449217; val_accuracy: 0.716062898089172 

The current subspace-distance is: 7.799837476341054e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.05; acc: 0.72
Batch: 20; loss: 0.93; acc: 0.67
Batch: 40; loss: 0.82; acc: 0.75
Batch: 60; loss: 0.77; acc: 0.73
Batch: 80; loss: 1.07; acc: 0.72
Batch: 100; loss: 0.88; acc: 0.73
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.75; acc: 0.73
Batch: 160; loss: 1.01; acc: 0.77
Batch: 180; loss: 0.85; acc: 0.72
Batch: 200; loss: 1.1; acc: 0.62
Batch: 220; loss: 1.09; acc: 0.75
Batch: 240; loss: 0.8; acc: 0.78
Batch: 260; loss: 0.63; acc: 0.77
Batch: 280; loss: 1.13; acc: 0.62
Batch: 300; loss: 0.9; acc: 0.73
Batch: 320; loss: 0.89; acc: 0.7
Batch: 340; loss: 1.17; acc: 0.69
Batch: 360; loss: 1.05; acc: 0.73
Batch: 380; loss: 0.89; acc: 0.62
Batch: 400; loss: 0.74; acc: 0.8
Batch: 420; loss: 0.84; acc: 0.73
Batch: 440; loss: 1.07; acc: 0.66
Batch: 460; loss: 0.79; acc: 0.73
Batch: 480; loss: 1.08; acc: 0.67
Batch: 500; loss: 1.2; acc: 0.64
Batch: 520; loss: 1.02; acc: 0.62
Batch: 540; loss: 0.75; acc: 0.77
Batch: 560; loss: 1.05; acc: 0.67
Batch: 580; loss: 0.82; acc: 0.8
Batch: 600; loss: 0.94; acc: 0.75
Batch: 620; loss: 0.96; acc: 0.72
Batch: 640; loss: 0.94; acc: 0.69
Batch: 660; loss: 1.12; acc: 0.59
Batch: 680; loss: 1.24; acc: 0.56
Batch: 700; loss: 0.89; acc: 0.75
Batch: 720; loss: 0.85; acc: 0.67
Batch: 740; loss: 1.01; acc: 0.69
Batch: 760; loss: 0.93; acc: 0.72
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9320996216265485e-05
7.129720415832708e-06
Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.69; acc: 0.84
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.7
Batch: 120; loss: 1.27; acc: 0.58
Batch: 140; loss: 0.51; acc: 0.89
Val Epoch over. val_loss: 0.8933550819849513; val_accuracy: 0.7226313694267515 

The current subspace-distance is: 7.129720415832708e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.89; acc: 0.75
Batch: 20; loss: 0.95; acc: 0.69
Batch: 40; loss: 0.89; acc: 0.7
Batch: 60; loss: 0.81; acc: 0.77
Batch: 80; loss: 0.86; acc: 0.73
Batch: 100; loss: 0.95; acc: 0.77
Batch: 120; loss: 1.15; acc: 0.67
Batch: 140; loss: 0.71; acc: 0.75
Batch: 160; loss: 0.85; acc: 0.72
Batch: 180; loss: 0.91; acc: 0.75
Batch: 200; loss: 1.19; acc: 0.67
Batch: 220; loss: 0.93; acc: 0.7
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 0.82; acc: 0.81
Batch: 280; loss: 0.94; acc: 0.67
Batch: 300; loss: 0.96; acc: 0.73
Batch: 320; loss: 1.05; acc: 0.69
Batch: 340; loss: 1.06; acc: 0.69
Batch: 360; loss: 1.28; acc: 0.64
Batch: 380; loss: 0.87; acc: 0.67
Batch: 400; loss: 0.83; acc: 0.7
Batch: 420; loss: 1.0; acc: 0.69
Batch: 440; loss: 1.02; acc: 0.66
Batch: 460; loss: 0.97; acc: 0.64
Batch: 480; loss: 0.98; acc: 0.69
Batch: 500; loss: 0.99; acc: 0.66
Batch: 520; loss: 1.14; acc: 0.69
Batch: 540; loss: 0.66; acc: 0.78
Batch: 560; loss: 0.83; acc: 0.7
Batch: 580; loss: 1.02; acc: 0.75
Batch: 600; loss: 0.81; acc: 0.75
Batch: 620; loss: 0.91; acc: 0.7
Batch: 640; loss: 0.78; acc: 0.75
Batch: 660; loss: 1.16; acc: 0.67
Batch: 680; loss: 1.14; acc: 0.59
Batch: 700; loss: 0.62; acc: 0.81
Batch: 720; loss: 0.85; acc: 0.67
Batch: 740; loss: 0.97; acc: 0.72
Batch: 760; loss: 1.08; acc: 0.66
Batch: 780; loss: 0.82; acc: 0.75
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.955635343620088e-05
6.678934823867166e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.15; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.92; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.25; acc: 0.58
Batch: 140; loss: 0.52; acc: 0.88
Val Epoch over. val_loss: 0.8980199561756887; val_accuracy: 0.721437101910828 

The current subspace-distance is: 6.678934823867166e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.13; acc: 0.7
Batch: 20; loss: 0.9; acc: 0.78
Batch: 40; loss: 0.99; acc: 0.61
Batch: 60; loss: 0.99; acc: 0.77
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.73; acc: 0.77
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.99; acc: 0.73
Batch: 160; loss: 0.93; acc: 0.7
Batch: 180; loss: 1.18; acc: 0.62
Batch: 200; loss: 0.6; acc: 0.78
Batch: 220; loss: 0.76; acc: 0.75
Batch: 240; loss: 0.87; acc: 0.75
Batch: 260; loss: 1.24; acc: 0.64
Batch: 280; loss: 0.98; acc: 0.7
Batch: 300; loss: 0.68; acc: 0.8
Batch: 320; loss: 0.99; acc: 0.72
Batch: 340; loss: 0.91; acc: 0.75
Batch: 360; loss: 0.86; acc: 0.7
Batch: 380; loss: 0.92; acc: 0.69
Batch: 400; loss: 1.2; acc: 0.64
Batch: 420; loss: 0.8; acc: 0.73
Batch: 440; loss: 0.79; acc: 0.77
Batch: 460; loss: 1.25; acc: 0.61
Batch: 480; loss: 0.88; acc: 0.72
Batch: 500; loss: 0.75; acc: 0.81
Batch: 520; loss: 1.29; acc: 0.61
Batch: 540; loss: 0.94; acc: 0.66
Batch: 560; loss: 0.94; acc: 0.78
Batch: 580; loss: 0.64; acc: 0.83
Batch: 600; loss: 1.15; acc: 0.62
Batch: 620; loss: 1.14; acc: 0.64
Batch: 640; loss: 1.12; acc: 0.64
Batch: 660; loss: 0.77; acc: 0.72
Batch: 680; loss: 0.81; acc: 0.72
Batch: 700; loss: 0.89; acc: 0.72
Batch: 720; loss: 0.63; acc: 0.78
Batch: 740; loss: 1.16; acc: 0.62
Batch: 760; loss: 0.9; acc: 0.67
Batch: 780; loss: 0.81; acc: 0.73
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.6809217413538136e-05
7.114638265193207e-06
Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.72
Batch: 80; loss: 0.74; acc: 0.81
Batch: 100; loss: 0.71; acc: 0.7
Batch: 120; loss: 1.25; acc: 0.59
Batch: 140; loss: 0.52; acc: 0.89
Val Epoch over. val_loss: 0.8965387494321082; val_accuracy: 0.7231289808917197 

The current subspace-distance is: 7.114638265193207e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.15; acc: 0.62
Batch: 20; loss: 1.16; acc: 0.67
Batch: 40; loss: 0.8; acc: 0.69
Batch: 60; loss: 1.03; acc: 0.61
Batch: 80; loss: 0.91; acc: 0.67
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 1.01; acc: 0.67
Batch: 140; loss: 0.95; acc: 0.67
Batch: 160; loss: 1.0; acc: 0.69
Batch: 180; loss: 0.95; acc: 0.73
Batch: 200; loss: 0.9; acc: 0.77
Batch: 220; loss: 0.98; acc: 0.7
Batch: 240; loss: 1.01; acc: 0.67
Batch: 260; loss: 0.96; acc: 0.64
Batch: 280; loss: 1.01; acc: 0.7
Batch: 300; loss: 1.03; acc: 0.7
Batch: 320; loss: 1.03; acc: 0.69
Batch: 340; loss: 0.84; acc: 0.73
Batch: 360; loss: 0.96; acc: 0.75
Batch: 380; loss: 0.82; acc: 0.73
Batch: 400; loss: 0.84; acc: 0.72
Batch: 420; loss: 0.66; acc: 0.75
Batch: 440; loss: 0.92; acc: 0.72
Batch: 460; loss: 0.88; acc: 0.62
Batch: 480; loss: 0.97; acc: 0.73
Batch: 500; loss: 0.87; acc: 0.73
Batch: 520; loss: 1.12; acc: 0.69
Batch: 540; loss: 0.8; acc: 0.75
Batch: 560; loss: 0.83; acc: 0.77
Batch: 580; loss: 1.12; acc: 0.66
Batch: 600; loss: 0.92; acc: 0.72
Batch: 620; loss: 1.1; acc: 0.73
Batch: 640; loss: 1.05; acc: 0.66
Batch: 660; loss: 0.9; acc: 0.72
Batch: 680; loss: 0.72; acc: 0.75
Batch: 700; loss: 1.07; acc: 0.69
Batch: 720; loss: 0.91; acc: 0.64
Batch: 740; loss: 0.98; acc: 0.75
Batch: 760; loss: 0.75; acc: 0.78
Batch: 780; loss: 1.33; acc: 0.61
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.7717164155328646e-05
7.364165867329575e-06
Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 1.13; acc: 0.69
Batch: 40; loss: 0.68; acc: 0.84
Batch: 60; loss: 0.91; acc: 0.67
Batch: 80; loss: 0.73; acc: 0.83
Batch: 100; loss: 0.72; acc: 0.69
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.53; acc: 0.89
Val Epoch over. val_loss: 0.8953082086933646; val_accuracy: 0.7219347133757962 

The current subspace-distance is: 7.364165867329575e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.86; acc: 0.67
Batch: 20; loss: 0.94; acc: 0.72
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 1.05; acc: 0.64
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.79; acc: 0.77
Batch: 120; loss: 1.06; acc: 0.7
Batch: 140; loss: 1.07; acc: 0.62
Batch: 160; loss: 1.03; acc: 0.64
Batch: 180; loss: 0.9; acc: 0.66
Batch: 200; loss: 1.09; acc: 0.58
Batch: 220; loss: 0.93; acc: 0.67
Batch: 240; loss: 0.87; acc: 0.72
Batch: 260; loss: 0.96; acc: 0.69
Batch: 280; loss: 1.01; acc: 0.66
Batch: 300; loss: 1.04; acc: 0.69
Batch: 320; loss: 0.84; acc: 0.67
Batch: 340; loss: 1.15; acc: 0.67
Batch: 360; loss: 1.21; acc: 0.55
Batch: 380; loss: 0.81; acc: 0.77
Batch: 400; loss: 0.91; acc: 0.69
Batch: 420; loss: 0.9; acc: 0.69
Batch: 440; loss: 1.02; acc: 0.77
Batch: 460; loss: 0.79; acc: 0.75
Batch: 480; loss: 0.93; acc: 0.69
Batch: 500; loss: 0.72; acc: 0.77
Batch: 520; loss: 1.12; acc: 0.59
Batch: 540; loss: 1.06; acc: 0.64
Batch: 560; loss: 0.97; acc: 0.72
Batch: 580; loss: 1.1; acc: 0.66
Batch: 600; loss: 1.01; acc: 0.73
Batch: 620; loss: 1.03; acc: 0.66
Batch: 640; loss: 0.89; acc: 0.72
Batch: 660; loss: 0.72; acc: 0.69
Batch: 680; loss: 0.83; acc: 0.73
Batch: 700; loss: 0.89; acc: 0.72
Batch: 720; loss: 0.86; acc: 0.73
Batch: 740; loss: 1.02; acc: 0.67
Batch: 760; loss: 1.02; acc: 0.72
Batch: 780; loss: 0.71; acc: 0.8
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.065006992779672e-05
6.448510248446837e-06
Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.92; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8950510750150984; val_accuracy: 0.7200437898089171 

The current subspace-distance is: 6.448510248446837e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 0.88; acc: 0.72
Batch: 40; loss: 0.93; acc: 0.75
Batch: 60; loss: 0.86; acc: 0.8
Batch: 80; loss: 1.02; acc: 0.64
Batch: 100; loss: 1.12; acc: 0.64
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 0.93; acc: 0.73
Batch: 160; loss: 0.75; acc: 0.8
Batch: 180; loss: 1.0; acc: 0.69
Batch: 200; loss: 0.87; acc: 0.77
Batch: 220; loss: 0.87; acc: 0.67
Batch: 240; loss: 0.83; acc: 0.73
Batch: 260; loss: 0.9; acc: 0.72
Batch: 280; loss: 1.02; acc: 0.72
Batch: 300; loss: 0.66; acc: 0.78
Batch: 320; loss: 0.86; acc: 0.7
Batch: 340; loss: 1.18; acc: 0.59
Batch: 360; loss: 0.88; acc: 0.72
Batch: 380; loss: 0.93; acc: 0.69
Batch: 400; loss: 0.88; acc: 0.73
Batch: 420; loss: 0.82; acc: 0.73
Batch: 440; loss: 0.87; acc: 0.7
Batch: 460; loss: 0.95; acc: 0.7
Batch: 480; loss: 0.92; acc: 0.75
Batch: 500; loss: 0.88; acc: 0.69
Batch: 520; loss: 1.09; acc: 0.58
Batch: 540; loss: 0.81; acc: 0.7
Batch: 560; loss: 0.88; acc: 0.73
Batch: 580; loss: 1.12; acc: 0.62
Batch: 600; loss: 0.94; acc: 0.73
Batch: 620; loss: 0.59; acc: 0.77
Batch: 640; loss: 1.05; acc: 0.62
Batch: 660; loss: 0.89; acc: 0.7
Batch: 680; loss: 0.93; acc: 0.77
Batch: 700; loss: 0.73; acc: 0.75
Batch: 720; loss: 0.95; acc: 0.7
Batch: 740; loss: 1.08; acc: 0.67
Batch: 760; loss: 0.85; acc: 0.69
Batch: 780; loss: 1.01; acc: 0.69
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.716193582979031e-05
6.900395874254173e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.92; acc: 0.67
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 1.28; acc: 0.59
Batch: 140; loss: 0.52; acc: 0.89
Val Epoch over. val_loss: 0.894271280545338; val_accuracy: 0.7211385350318471 

The current subspace-distance is: 6.900395874254173e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.81; acc: 0.75
Batch: 20; loss: 0.86; acc: 0.72
Batch: 40; loss: 1.1; acc: 0.61
Batch: 60; loss: 0.83; acc: 0.72
Batch: 80; loss: 0.84; acc: 0.7
Batch: 100; loss: 1.17; acc: 0.69
Batch: 120; loss: 0.96; acc: 0.72
Batch: 140; loss: 0.8; acc: 0.75
Batch: 160; loss: 1.08; acc: 0.73
Batch: 180; loss: 0.62; acc: 0.77
Batch: 200; loss: 0.87; acc: 0.72
Batch: 220; loss: 0.86; acc: 0.72
Batch: 240; loss: 1.03; acc: 0.62
Batch: 260; loss: 0.92; acc: 0.64
Batch: 280; loss: 1.22; acc: 0.62
Batch: 300; loss: 1.13; acc: 0.67
Batch: 320; loss: 1.19; acc: 0.61
Batch: 340; loss: 0.78; acc: 0.77
Batch: 360; loss: 1.12; acc: 0.66
Batch: 380; loss: 1.17; acc: 0.64
Batch: 400; loss: 0.87; acc: 0.77
Batch: 420; loss: 1.06; acc: 0.67
Batch: 440; loss: 0.8; acc: 0.7
Batch: 460; loss: 1.23; acc: 0.64
Batch: 480; loss: 0.88; acc: 0.75
Batch: 500; loss: 0.88; acc: 0.8
Batch: 520; loss: 0.87; acc: 0.7
Batch: 540; loss: 1.1; acc: 0.64
Batch: 560; loss: 1.01; acc: 0.7
Batch: 580; loss: 1.0; acc: 0.61
Batch: 600; loss: 1.3; acc: 0.58
Batch: 620; loss: 0.67; acc: 0.86
Batch: 640; loss: 1.01; acc: 0.75
Batch: 660; loss: 0.73; acc: 0.78
Batch: 680; loss: 0.8; acc: 0.72
Batch: 700; loss: 0.92; acc: 0.73
Batch: 720; loss: 0.97; acc: 0.69
Batch: 740; loss: 0.78; acc: 0.78
Batch: 760; loss: 0.82; acc: 0.75
Batch: 780; loss: 1.03; acc: 0.72
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.1304183974280022e-05
6.992866474320181e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.15; acc: 0.67
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.91; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.81
Batch: 100; loss: 0.75; acc: 0.69
Batch: 120; loss: 1.26; acc: 0.58
Batch: 140; loss: 0.51; acc: 0.91
Val Epoch over. val_loss: 0.8976847149763897; val_accuracy: 0.71875 

The current subspace-distance is: 6.992866474320181e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.05; acc: 0.64
Batch: 20; loss: 0.75; acc: 0.72
Batch: 40; loss: 0.72; acc: 0.77
Batch: 60; loss: 0.83; acc: 0.75
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 1.05; acc: 0.67
Batch: 120; loss: 0.79; acc: 0.84
Batch: 140; loss: 0.85; acc: 0.77
Batch: 160; loss: 0.87; acc: 0.72
Batch: 180; loss: 0.91; acc: 0.67
Batch: 200; loss: 1.0; acc: 0.67
Batch: 220; loss: 1.0; acc: 0.69
Batch: 240; loss: 1.3; acc: 0.69
Batch: 260; loss: 0.86; acc: 0.66
Batch: 280; loss: 0.9; acc: 0.69
Batch: 300; loss: 1.14; acc: 0.62
Batch: 320; loss: 1.23; acc: 0.66
Batch: 340; loss: 0.86; acc: 0.75
Batch: 360; loss: 0.87; acc: 0.73
Batch: 380; loss: 0.82; acc: 0.7
Batch: 400; loss: 1.17; acc: 0.66
Batch: 420; loss: 1.01; acc: 0.69
Batch: 440; loss: 1.03; acc: 0.7
Batch: 460; loss: 1.07; acc: 0.7
Batch: 480; loss: 1.03; acc: 0.62
Batch: 500; loss: 0.73; acc: 0.81
Batch: 520; loss: 1.29; acc: 0.55
Batch: 540; loss: 0.79; acc: 0.73
Batch: 560; loss: 0.81; acc: 0.72
Batch: 580; loss: 0.9; acc: 0.69
Batch: 600; loss: 1.02; acc: 0.7
Batch: 620; loss: 0.98; acc: 0.66
Batch: 640; loss: 1.0; acc: 0.67
Batch: 660; loss: 0.66; acc: 0.8
Batch: 680; loss: 0.96; acc: 0.69
Batch: 700; loss: 0.87; acc: 0.78
Batch: 720; loss: 1.14; acc: 0.62
Batch: 740; loss: 0.95; acc: 0.69
Batch: 760; loss: 1.17; acc: 0.61
Batch: 780; loss: 0.84; acc: 0.75
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.743653956509661e-05
6.893722456879914e-06
Batch: 0; loss: 0.84; acc: 0.7
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.76; acc: 0.7
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.51; acc: 0.89
Val Epoch over. val_loss: 0.8954856625408124; val_accuracy: 0.7200437898089171 

The current subspace-distance is: 6.893722456879914e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.12; acc: 0.66
Batch: 20; loss: 1.14; acc: 0.61
Batch: 40; loss: 0.95; acc: 0.64
Batch: 60; loss: 1.08; acc: 0.64
Batch: 80; loss: 0.86; acc: 0.72
Batch: 100; loss: 1.09; acc: 0.66
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 1.13; acc: 0.66
Batch: 160; loss: 1.0; acc: 0.69
Batch: 180; loss: 1.09; acc: 0.67
Batch: 200; loss: 0.79; acc: 0.75
Batch: 220; loss: 1.04; acc: 0.64
Batch: 240; loss: 0.7; acc: 0.77
Batch: 260; loss: 0.84; acc: 0.7
Batch: 280; loss: 0.94; acc: 0.73
Batch: 300; loss: 0.99; acc: 0.67
Batch: 320; loss: 1.03; acc: 0.69
Batch: 340; loss: 1.27; acc: 0.67
Batch: 360; loss: 0.85; acc: 0.73
Batch: 380; loss: 0.77; acc: 0.77
Batch: 400; loss: 0.75; acc: 0.81
Batch: 420; loss: 0.78; acc: 0.72
Batch: 440; loss: 0.83; acc: 0.73
Batch: 460; loss: 0.96; acc: 0.7
Batch: 480; loss: 1.1; acc: 0.69
Batch: 500; loss: 1.08; acc: 0.69
Batch: 520; loss: 1.0; acc: 0.7
Batch: 540; loss: 0.73; acc: 0.77
Batch: 560; loss: 1.17; acc: 0.67
Batch: 580; loss: 0.76; acc: 0.81
Batch: 600; loss: 0.82; acc: 0.73
Batch: 620; loss: 0.8; acc: 0.78
Batch: 640; loss: 0.95; acc: 0.72
Batch: 660; loss: 0.9; acc: 0.66
Batch: 680; loss: 0.88; acc: 0.7
Batch: 700; loss: 1.01; acc: 0.72
Batch: 720; loss: 0.84; acc: 0.67
Batch: 740; loss: 0.66; acc: 0.72
Batch: 760; loss: 0.9; acc: 0.69
Batch: 780; loss: 0.92; acc: 0.77
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.0084453353774734e-05
6.151895377115579e-06
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.84
Batch: 60; loss: 0.92; acc: 0.67
Batch: 80; loss: 0.73; acc: 0.83
Batch: 100; loss: 0.72; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8959212350617548; val_accuracy: 0.721437101910828 

The current subspace-distance is: 6.151895377115579e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.07; acc: 0.7
Batch: 20; loss: 1.15; acc: 0.59
Batch: 40; loss: 0.97; acc: 0.72
Batch: 60; loss: 1.21; acc: 0.67
Batch: 80; loss: 1.14; acc: 0.61
Batch: 100; loss: 1.09; acc: 0.62
Batch: 120; loss: 1.02; acc: 0.66
Batch: 140; loss: 1.06; acc: 0.67
Batch: 160; loss: 0.99; acc: 0.66
Batch: 180; loss: 1.0; acc: 0.66
Batch: 200; loss: 1.09; acc: 0.55
Batch: 220; loss: 0.92; acc: 0.73
Batch: 240; loss: 0.99; acc: 0.73
Batch: 260; loss: 0.83; acc: 0.78
Batch: 280; loss: 1.05; acc: 0.64
Batch: 300; loss: 0.89; acc: 0.75
Batch: 320; loss: 1.07; acc: 0.66
Batch: 340; loss: 0.92; acc: 0.75
Batch: 360; loss: 0.96; acc: 0.67
Batch: 380; loss: 0.77; acc: 0.81
Batch: 400; loss: 1.04; acc: 0.69
Batch: 420; loss: 0.79; acc: 0.8
Batch: 440; loss: 0.84; acc: 0.75
Batch: 460; loss: 1.04; acc: 0.69
Batch: 480; loss: 0.86; acc: 0.72
Batch: 500; loss: 0.82; acc: 0.75
Batch: 520; loss: 1.3; acc: 0.61
Batch: 540; loss: 1.08; acc: 0.67
Batch: 560; loss: 0.89; acc: 0.72
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 0.98; acc: 0.78
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 1.05; acc: 0.59
Batch: 660; loss: 0.99; acc: 0.62
Batch: 680; loss: 1.08; acc: 0.69
Batch: 700; loss: 0.93; acc: 0.67
Batch: 720; loss: 0.95; acc: 0.69
Batch: 740; loss: 0.88; acc: 0.72
Batch: 760; loss: 1.07; acc: 0.64
Batch: 780; loss: 0.88; acc: 0.72
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.8332755644223653e-05
6.6681441239779815e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.9; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.72; acc: 0.72
Batch: 120; loss: 1.25; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.895968235412221; val_accuracy: 0.720640923566879 

The current subspace-distance is: 6.6681441239779815e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.82; acc: 0.72
Batch: 20; loss: 1.11; acc: 0.66
Batch: 40; loss: 0.84; acc: 0.7
Batch: 60; loss: 1.02; acc: 0.69
Batch: 80; loss: 1.15; acc: 0.66
Batch: 100; loss: 1.01; acc: 0.77
Batch: 120; loss: 1.06; acc: 0.62
Batch: 140; loss: 0.97; acc: 0.7
Batch: 160; loss: 0.82; acc: 0.8
Batch: 180; loss: 0.95; acc: 0.66
Batch: 200; loss: 0.93; acc: 0.7
Batch: 220; loss: 1.02; acc: 0.66
Batch: 240; loss: 0.93; acc: 0.66
Batch: 260; loss: 1.1; acc: 0.66
Batch: 280; loss: 0.87; acc: 0.75
Batch: 300; loss: 1.17; acc: 0.64
Batch: 320; loss: 1.02; acc: 0.62
Batch: 340; loss: 0.72; acc: 0.78
Batch: 360; loss: 0.89; acc: 0.67
Batch: 380; loss: 1.13; acc: 0.64
Batch: 400; loss: 1.19; acc: 0.66
Batch: 420; loss: 1.11; acc: 0.67
Batch: 440; loss: 0.74; acc: 0.77
Batch: 460; loss: 0.77; acc: 0.78
Batch: 480; loss: 0.63; acc: 0.8
Batch: 500; loss: 0.89; acc: 0.7
Batch: 520; loss: 0.8; acc: 0.72
Batch: 540; loss: 0.88; acc: 0.72
Batch: 560; loss: 1.26; acc: 0.56
Batch: 580; loss: 1.04; acc: 0.69
Batch: 600; loss: 0.89; acc: 0.69
Batch: 620; loss: 1.19; acc: 0.62
Batch: 640; loss: 1.02; acc: 0.61
Batch: 660; loss: 1.3; acc: 0.73
Batch: 680; loss: 1.02; acc: 0.58
Batch: 700; loss: 0.84; acc: 0.77
Batch: 720; loss: 1.16; acc: 0.59
Batch: 740; loss: 0.97; acc: 0.67
Batch: 760; loss: 1.11; acc: 0.69
Batch: 780; loss: 1.19; acc: 0.62
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.758744110702537e-05
7.887691936048213e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8934272637792454; val_accuracy: 0.7220342356687898 

The current subspace-distance is: 7.887691936048213e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.92; acc: 0.69
Batch: 20; loss: 0.97; acc: 0.61
Batch: 40; loss: 0.99; acc: 0.7
Batch: 60; loss: 0.89; acc: 0.73
Batch: 80; loss: 0.85; acc: 0.75
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 1.11; acc: 0.67
Batch: 140; loss: 0.92; acc: 0.75
Batch: 160; loss: 0.67; acc: 0.84
Batch: 180; loss: 0.91; acc: 0.7
Batch: 200; loss: 0.95; acc: 0.7
Batch: 220; loss: 0.73; acc: 0.73
Batch: 240; loss: 0.81; acc: 0.78
Batch: 260; loss: 0.83; acc: 0.66
Batch: 280; loss: 0.85; acc: 0.72
Batch: 300; loss: 1.12; acc: 0.66
Batch: 320; loss: 0.92; acc: 0.73
Batch: 340; loss: 1.29; acc: 0.59
Batch: 360; loss: 0.81; acc: 0.72
Batch: 380; loss: 0.7; acc: 0.84
Batch: 400; loss: 1.05; acc: 0.75
Batch: 420; loss: 0.81; acc: 0.73
Batch: 440; loss: 0.94; acc: 0.73
Batch: 460; loss: 0.84; acc: 0.78
Batch: 480; loss: 0.98; acc: 0.7
Batch: 500; loss: 1.09; acc: 0.64
Batch: 520; loss: 1.11; acc: 0.7
Batch: 540; loss: 1.06; acc: 0.66
Batch: 560; loss: 1.08; acc: 0.66
Batch: 580; loss: 0.66; acc: 0.8
Batch: 600; loss: 1.33; acc: 0.64
Batch: 620; loss: 0.99; acc: 0.72
Batch: 640; loss: 0.81; acc: 0.78
Batch: 660; loss: 0.82; acc: 0.78
Batch: 680; loss: 0.88; acc: 0.77
Batch: 700; loss: 1.06; acc: 0.67
Batch: 720; loss: 0.92; acc: 0.73
Batch: 740; loss: 0.98; acc: 0.64
Batch: 760; loss: 0.96; acc: 0.7
Batch: 780; loss: 1.11; acc: 0.69
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9962735677836463e-05
6.508883416245226e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.8
Batch: 100; loss: 0.72; acc: 0.7
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.89
Val Epoch over. val_loss: 0.8935395961354493; val_accuracy: 0.7210390127388535 

The current subspace-distance is: 6.508883416245226e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.86; acc: 0.7
Batch: 20; loss: 0.83; acc: 0.78
Batch: 40; loss: 0.89; acc: 0.67
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 1.15; acc: 0.66
Batch: 100; loss: 0.82; acc: 0.75
Batch: 120; loss: 1.09; acc: 0.64
Batch: 140; loss: 1.07; acc: 0.62
Batch: 160; loss: 0.95; acc: 0.67
Batch: 180; loss: 1.0; acc: 0.58
Batch: 200; loss: 0.94; acc: 0.75
Batch: 220; loss: 1.1; acc: 0.61
Batch: 240; loss: 0.72; acc: 0.84
Batch: 260; loss: 0.85; acc: 0.73
Batch: 280; loss: 0.92; acc: 0.8
Batch: 300; loss: 1.1; acc: 0.61
Batch: 320; loss: 0.87; acc: 0.75
Batch: 340; loss: 0.79; acc: 0.75
Batch: 360; loss: 1.05; acc: 0.7
Batch: 380; loss: 0.81; acc: 0.72
Batch: 400; loss: 1.0; acc: 0.69
Batch: 420; loss: 0.83; acc: 0.75
Batch: 440; loss: 0.77; acc: 0.77
Batch: 460; loss: 0.79; acc: 0.75
Batch: 480; loss: 0.82; acc: 0.78
Batch: 500; loss: 0.77; acc: 0.73
Batch: 520; loss: 1.01; acc: 0.72
Batch: 540; loss: 1.12; acc: 0.66
Batch: 560; loss: 1.11; acc: 0.67
Batch: 580; loss: 1.0; acc: 0.77
Batch: 600; loss: 0.82; acc: 0.78
Batch: 620; loss: 1.06; acc: 0.69
Batch: 640; loss: 1.12; acc: 0.61
Batch: 660; loss: 0.92; acc: 0.75
Batch: 680; loss: 0.93; acc: 0.7
Batch: 700; loss: 0.95; acc: 0.75
Batch: 720; loss: 0.8; acc: 0.8
Batch: 740; loss: 0.7; acc: 0.81
Batch: 760; loss: 0.81; acc: 0.75
Batch: 780; loss: 0.92; acc: 0.75
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.922350020322483e-05
7.270617061294615e-06
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.7
Batch: 80; loss: 0.73; acc: 0.83
Batch: 100; loss: 0.71; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8943514176614725; val_accuracy: 0.7242237261146497 

The current subspace-distance is: 7.270617061294615e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.83; acc: 0.75
Batch: 20; loss: 0.81; acc: 0.72
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.7
Batch: 80; loss: 0.94; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.73
Batch: 120; loss: 1.16; acc: 0.66
Batch: 140; loss: 0.81; acc: 0.77
Batch: 160; loss: 1.13; acc: 0.64
Batch: 180; loss: 0.82; acc: 0.72
Batch: 200; loss: 0.9; acc: 0.73
Batch: 220; loss: 0.87; acc: 0.73
Batch: 240; loss: 0.95; acc: 0.75
Batch: 260; loss: 1.03; acc: 0.69
Batch: 280; loss: 1.02; acc: 0.7
Batch: 300; loss: 0.87; acc: 0.72
Batch: 320; loss: 0.83; acc: 0.69
Batch: 340; loss: 1.03; acc: 0.67
Batch: 360; loss: 1.11; acc: 0.64
Batch: 380; loss: 0.97; acc: 0.67
Batch: 400; loss: 0.97; acc: 0.7
Batch: 420; loss: 0.94; acc: 0.7
Batch: 440; loss: 0.74; acc: 0.69
Batch: 460; loss: 1.0; acc: 0.62
Batch: 480; loss: 0.91; acc: 0.62
Batch: 500; loss: 0.93; acc: 0.73
Batch: 520; loss: 0.94; acc: 0.67
Batch: 540; loss: 1.03; acc: 0.64
Batch: 560; loss: 1.21; acc: 0.61
Batch: 580; loss: 1.07; acc: 0.61
Batch: 600; loss: 1.15; acc: 0.67
Batch: 620; loss: 0.95; acc: 0.7
Batch: 640; loss: 0.9; acc: 0.78
Batch: 660; loss: 1.04; acc: 0.61
Batch: 680; loss: 0.82; acc: 0.78
Batch: 700; loss: 1.18; acc: 0.66
Batch: 720; loss: 0.75; acc: 0.72
Batch: 740; loss: 0.92; acc: 0.7
Batch: 760; loss: 1.08; acc: 0.66
Batch: 780; loss: 0.54; acc: 0.81
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.993653495446779e-05
6.267183380259667e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.68; acc: 0.8
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.74; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.892739712622515; val_accuracy: 0.7224323248407644 

The current subspace-distance is: 6.267183380259667e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.92; acc: 0.67
Batch: 20; loss: 0.92; acc: 0.7
Batch: 40; loss: 1.37; acc: 0.59
Batch: 60; loss: 0.82; acc: 0.67
Batch: 80; loss: 0.89; acc: 0.78
Batch: 100; loss: 1.07; acc: 0.7
Batch: 120; loss: 0.94; acc: 0.75
Batch: 140; loss: 0.91; acc: 0.7
Batch: 160; loss: 1.07; acc: 0.58
Batch: 180; loss: 0.87; acc: 0.75
Batch: 200; loss: 0.96; acc: 0.69
Batch: 220; loss: 0.95; acc: 0.7
Batch: 240; loss: 0.75; acc: 0.83
Batch: 260; loss: 1.04; acc: 0.64
Batch: 280; loss: 1.16; acc: 0.62
Batch: 300; loss: 1.05; acc: 0.61
Batch: 320; loss: 0.86; acc: 0.73
Batch: 340; loss: 1.02; acc: 0.66
Batch: 360; loss: 0.68; acc: 0.84
Batch: 380; loss: 1.11; acc: 0.64
Batch: 400; loss: 0.88; acc: 0.7
Batch: 420; loss: 0.91; acc: 0.66
Batch: 440; loss: 0.61; acc: 0.78
Batch: 460; loss: 1.01; acc: 0.75
Batch: 480; loss: 0.82; acc: 0.78
Batch: 500; loss: 1.01; acc: 0.72
Batch: 520; loss: 1.08; acc: 0.62
Batch: 540; loss: 1.0; acc: 0.75
Batch: 560; loss: 0.68; acc: 0.81
Batch: 580; loss: 0.91; acc: 0.7
Batch: 600; loss: 0.94; acc: 0.7
Batch: 620; loss: 0.81; acc: 0.7
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 0.98; acc: 0.73
Batch: 680; loss: 0.85; acc: 0.7
Batch: 700; loss: 0.77; acc: 0.72
Batch: 720; loss: 0.97; acc: 0.69
Batch: 740; loss: 0.96; acc: 0.66
Batch: 760; loss: 1.02; acc: 0.67
Batch: 780; loss: 0.89; acc: 0.7
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.87698478839593e-05
7.236963028844912e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.9; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8931763540407655; val_accuracy: 0.7215366242038217 

The current subspace-distance is: 7.236963028844912e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.03; acc: 0.77
Batch: 20; loss: 0.79; acc: 0.72
Batch: 40; loss: 1.09; acc: 0.61
Batch: 60; loss: 0.85; acc: 0.7
Batch: 80; loss: 0.9; acc: 0.72
Batch: 100; loss: 1.15; acc: 0.59
Batch: 120; loss: 1.41; acc: 0.62
Batch: 140; loss: 0.84; acc: 0.72
Batch: 160; loss: 0.92; acc: 0.69
Batch: 180; loss: 0.78; acc: 0.78
Batch: 200; loss: 1.21; acc: 0.7
Batch: 220; loss: 0.9; acc: 0.62
Batch: 240; loss: 0.9; acc: 0.78
Batch: 260; loss: 0.74; acc: 0.8
Batch: 280; loss: 0.9; acc: 0.7
Batch: 300; loss: 0.98; acc: 0.73
Batch: 320; loss: 0.94; acc: 0.75
Batch: 340; loss: 0.84; acc: 0.75
Batch: 360; loss: 0.73; acc: 0.8
Batch: 380; loss: 0.69; acc: 0.78
Batch: 400; loss: 1.17; acc: 0.56
Batch: 420; loss: 1.05; acc: 0.56
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.93; acc: 0.75
Batch: 480; loss: 1.07; acc: 0.69
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.79; acc: 0.73
Batch: 540; loss: 0.89; acc: 0.73
Batch: 560; loss: 0.8; acc: 0.72
Batch: 580; loss: 0.75; acc: 0.77
Batch: 600; loss: 0.98; acc: 0.69
Batch: 620; loss: 1.14; acc: 0.66
Batch: 640; loss: 1.4; acc: 0.59
Batch: 660; loss: 1.14; acc: 0.64
Batch: 680; loss: 0.94; acc: 0.69
Batch: 700; loss: 0.95; acc: 0.69
Batch: 720; loss: 0.88; acc: 0.7
Batch: 740; loss: 0.96; acc: 0.73
Batch: 760; loss: 0.7; acc: 0.77
Batch: 780; loss: 0.82; acc: 0.72
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.1124509657965973e-05
6.449336069636047e-06
Batch: 0; loss: 0.85; acc: 0.72
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 0.72; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.89
Val Epoch over. val_loss: 0.892800926782523; val_accuracy: 0.7232285031847133 

The current subspace-distance is: 6.449336069636047e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.07; acc: 0.67
Batch: 20; loss: 0.93; acc: 0.8
Batch: 40; loss: 1.07; acc: 0.66
Batch: 60; loss: 1.03; acc: 0.64
Batch: 80; loss: 1.03; acc: 0.61
Batch: 100; loss: 1.27; acc: 0.64
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.92; acc: 0.69
Batch: 160; loss: 0.9; acc: 0.69
Batch: 180; loss: 0.86; acc: 0.77
Batch: 200; loss: 0.86; acc: 0.75
Batch: 220; loss: 1.05; acc: 0.61
Batch: 240; loss: 0.85; acc: 0.73
Batch: 260; loss: 0.72; acc: 0.81
Batch: 280; loss: 0.82; acc: 0.73
Batch: 300; loss: 0.84; acc: 0.77
Batch: 320; loss: 0.74; acc: 0.72
Batch: 340; loss: 0.9; acc: 0.7
Batch: 360; loss: 1.16; acc: 0.61
Batch: 380; loss: 0.72; acc: 0.77
Batch: 400; loss: 1.12; acc: 0.67
Batch: 420; loss: 0.95; acc: 0.66
Batch: 440; loss: 1.15; acc: 0.7
Batch: 460; loss: 0.99; acc: 0.69
Batch: 480; loss: 0.91; acc: 0.7
Batch: 500; loss: 0.91; acc: 0.67
Batch: 520; loss: 0.97; acc: 0.78
Batch: 540; loss: 0.87; acc: 0.77
Batch: 560; loss: 0.72; acc: 0.77
Batch: 580; loss: 1.25; acc: 0.66
Batch: 600; loss: 0.81; acc: 0.75
Batch: 620; loss: 0.89; acc: 0.69
Batch: 640; loss: 1.09; acc: 0.7
Batch: 660; loss: 0.93; acc: 0.67
Batch: 680; loss: 0.94; acc: 0.72
Batch: 700; loss: 1.05; acc: 0.66
Batch: 720; loss: 1.11; acc: 0.61
Batch: 740; loss: 1.14; acc: 0.7
Batch: 760; loss: 0.89; acc: 0.72
Batch: 780; loss: 0.96; acc: 0.7
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9086877728113905e-05
6.2514545788872056e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.51; acc: 0.89
Val Epoch over. val_loss: 0.8936236384947589; val_accuracy: 0.721437101910828 

The current subspace-distance is: 6.2514545788872056e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 0.92; acc: 0.72
Batch: 40; loss: 0.7; acc: 0.77
Batch: 60; loss: 0.91; acc: 0.75
Batch: 80; loss: 1.04; acc: 0.67
Batch: 100; loss: 0.84; acc: 0.69
Batch: 120; loss: 0.94; acc: 0.67
Batch: 140; loss: 1.05; acc: 0.67
Batch: 160; loss: 1.11; acc: 0.67
Batch: 180; loss: 1.07; acc: 0.67
Batch: 200; loss: 1.04; acc: 0.75
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 1.08; acc: 0.67
Batch: 260; loss: 0.85; acc: 0.78
Batch: 280; loss: 1.13; acc: 0.67
Batch: 300; loss: 0.98; acc: 0.67
Batch: 320; loss: 1.1; acc: 0.66
Batch: 340; loss: 1.05; acc: 0.59
Batch: 360; loss: 1.03; acc: 0.67
Batch: 380; loss: 1.18; acc: 0.64
Batch: 400; loss: 1.07; acc: 0.67
Batch: 420; loss: 1.12; acc: 0.73
Batch: 440; loss: 1.17; acc: 0.59
Batch: 460; loss: 0.89; acc: 0.75
Batch: 480; loss: 1.06; acc: 0.69
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 1.13; acc: 0.62
Batch: 540; loss: 0.79; acc: 0.78
Batch: 560; loss: 1.06; acc: 0.62
Batch: 580; loss: 1.16; acc: 0.64
Batch: 600; loss: 0.9; acc: 0.64
Batch: 620; loss: 0.79; acc: 0.73
Batch: 640; loss: 1.01; acc: 0.62
Batch: 660; loss: 0.88; acc: 0.69
Batch: 680; loss: 1.18; acc: 0.67
Batch: 700; loss: 0.75; acc: 0.75
Batch: 720; loss: 0.87; acc: 0.72
Batch: 740; loss: 1.28; acc: 0.64
Batch: 760; loss: 1.14; acc: 0.7
Batch: 780; loss: 0.91; acc: 0.7
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.8051021470455453e-05
6.0290394685580395e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.67
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 1.27; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8930083549326393; val_accuracy: 0.7215366242038217 

The current subspace-distance is: 6.0290394685580395e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.83; acc: 0.72
Batch: 20; loss: 1.12; acc: 0.7
Batch: 40; loss: 0.65; acc: 0.8
Batch: 60; loss: 0.95; acc: 0.73
Batch: 80; loss: 0.99; acc: 0.69
Batch: 100; loss: 0.79; acc: 0.72
Batch: 120; loss: 1.04; acc: 0.72
Batch: 140; loss: 0.86; acc: 0.75
Batch: 160; loss: 0.71; acc: 0.78
Batch: 180; loss: 1.2; acc: 0.64
Batch: 200; loss: 0.92; acc: 0.69
Batch: 220; loss: 1.04; acc: 0.69
Batch: 240; loss: 0.71; acc: 0.7
Batch: 260; loss: 1.18; acc: 0.62
Batch: 280; loss: 0.94; acc: 0.72
Batch: 300; loss: 0.94; acc: 0.7
Batch: 320; loss: 0.88; acc: 0.7
Batch: 340; loss: 1.3; acc: 0.59
Batch: 360; loss: 0.98; acc: 0.67
Batch: 380; loss: 0.78; acc: 0.77
Batch: 400; loss: 0.89; acc: 0.72
Batch: 420; loss: 1.07; acc: 0.67
Batch: 440; loss: 0.73; acc: 0.73
Batch: 460; loss: 0.96; acc: 0.72
Batch: 480; loss: 1.0; acc: 0.64
Batch: 500; loss: 1.12; acc: 0.67
Batch: 520; loss: 0.9; acc: 0.67
Batch: 540; loss: 0.75; acc: 0.75
Batch: 560; loss: 0.97; acc: 0.67
Batch: 580; loss: 0.95; acc: 0.7
Batch: 600; loss: 0.59; acc: 0.8
Batch: 620; loss: 0.72; acc: 0.75
Batch: 640; loss: 0.91; acc: 0.7
Batch: 660; loss: 0.86; acc: 0.67
Batch: 680; loss: 0.99; acc: 0.72
Batch: 700; loss: 0.9; acc: 0.78
Batch: 720; loss: 0.9; acc: 0.7
Batch: 740; loss: 0.93; acc: 0.73
Batch: 760; loss: 0.88; acc: 0.77
Batch: 780; loss: 1.1; acc: 0.66
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.751643867464736e-05
6.400980055332184e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.12; acc: 0.66
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.8
Batch: 100; loss: 0.74; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8938135453470194; val_accuracy: 0.7215366242038217 

The current subspace-distance is: 6.400980055332184e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.86; acc: 0.7
Batch: 20; loss: 1.15; acc: 0.58
Batch: 40; loss: 1.06; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.62
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 1.13; acc: 0.66
Batch: 120; loss: 0.98; acc: 0.7
Batch: 140; loss: 0.94; acc: 0.67
Batch: 160; loss: 1.04; acc: 0.61
Batch: 180; loss: 0.84; acc: 0.77
Batch: 200; loss: 0.99; acc: 0.66
Batch: 220; loss: 1.0; acc: 0.69
Batch: 240; loss: 1.02; acc: 0.61
Batch: 260; loss: 0.72; acc: 0.81
Batch: 280; loss: 1.09; acc: 0.75
Batch: 300; loss: 1.1; acc: 0.69
Batch: 320; loss: 1.01; acc: 0.75
Batch: 340; loss: 0.97; acc: 0.72
Batch: 360; loss: 0.8; acc: 0.72
Batch: 380; loss: 1.1; acc: 0.67
Batch: 400; loss: 0.64; acc: 0.83
Batch: 420; loss: 0.84; acc: 0.72
Batch: 440; loss: 1.01; acc: 0.67
Batch: 460; loss: 0.85; acc: 0.72
Batch: 480; loss: 0.87; acc: 0.77
Batch: 500; loss: 0.9; acc: 0.69
Batch: 520; loss: 0.96; acc: 0.72
Batch: 540; loss: 1.06; acc: 0.64
Batch: 560; loss: 1.03; acc: 0.66
Batch: 580; loss: 0.66; acc: 0.78
Batch: 600; loss: 0.9; acc: 0.75
Batch: 620; loss: 1.01; acc: 0.61
Batch: 640; loss: 0.92; acc: 0.73
Batch: 660; loss: 1.19; acc: 0.64
Batch: 680; loss: 0.85; acc: 0.77
Batch: 700; loss: 0.83; acc: 0.77
Batch: 720; loss: 1.01; acc: 0.73
Batch: 740; loss: 0.93; acc: 0.69
Batch: 760; loss: 0.68; acc: 0.78
Batch: 780; loss: 1.05; acc: 0.66
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.924110620166175e-05
6.629867584706517e-06
Batch: 0; loss: 0.83; acc: 0.73
Batch: 20; loss: 1.14; acc: 0.66
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.92; acc: 0.67
Batch: 80; loss: 0.73; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 1.28; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.88
Val Epoch over. val_loss: 0.8941967136161343; val_accuracy: 0.7207404458598726 

The current subspace-distance is: 6.629867584706517e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.85; acc: 0.67
Batch: 20; loss: 0.98; acc: 0.75
Batch: 40; loss: 0.79; acc: 0.8
Batch: 60; loss: 1.08; acc: 0.72
Batch: 80; loss: 0.98; acc: 0.66
Batch: 100; loss: 0.87; acc: 0.72
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.94; acc: 0.69
Batch: 160; loss: 0.75; acc: 0.72
Batch: 180; loss: 1.08; acc: 0.66
Batch: 200; loss: 0.75; acc: 0.78
Batch: 220; loss: 0.98; acc: 0.73
Batch: 240; loss: 0.77; acc: 0.8
Batch: 260; loss: 0.85; acc: 0.81
Batch: 280; loss: 1.06; acc: 0.72
Batch: 300; loss: 0.97; acc: 0.7
Batch: 320; loss: 0.93; acc: 0.73
Batch: 340; loss: 1.0; acc: 0.73
Batch: 360; loss: 1.06; acc: 0.69
Batch: 380; loss: 1.16; acc: 0.67
Batch: 400; loss: 1.07; acc: 0.62
Batch: 420; loss: 0.85; acc: 0.7
Batch: 440; loss: 0.98; acc: 0.66
Batch: 460; loss: 0.7; acc: 0.77
Batch: 480; loss: 1.07; acc: 0.7
Batch: 500; loss: 1.12; acc: 0.67
Batch: 520; loss: 0.87; acc: 0.73
Batch: 540; loss: 1.05; acc: 0.66
Batch: 560; loss: 0.85; acc: 0.73
Batch: 580; loss: 0.78; acc: 0.8
Batch: 600; loss: 0.79; acc: 0.81
Batch: 620; loss: 0.81; acc: 0.7
Batch: 640; loss: 1.1; acc: 0.62
Batch: 660; loss: 0.84; acc: 0.75
Batch: 680; loss: 1.01; acc: 0.64
Batch: 700; loss: 1.14; acc: 0.73
Batch: 720; loss: 1.01; acc: 0.61
Batch: 740; loss: 1.1; acc: 0.64
Batch: 760; loss: 0.85; acc: 0.66
Batch: 780; loss: 0.75; acc: 0.77
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.010689968301449e-05
6.777315320505295e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.67
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8931362928858229; val_accuracy: 0.7218351910828026 

The current subspace-distance is: 6.777315320505295e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.84; acc: 0.77
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 0.82; acc: 0.8
Batch: 80; loss: 0.76; acc: 0.75
Batch: 100; loss: 0.94; acc: 0.66
Batch: 120; loss: 0.89; acc: 0.7
Batch: 140; loss: 1.15; acc: 0.61
Batch: 160; loss: 0.84; acc: 0.7
Batch: 180; loss: 0.93; acc: 0.7
Batch: 200; loss: 0.82; acc: 0.73
Batch: 220; loss: 1.09; acc: 0.62
Batch: 240; loss: 1.01; acc: 0.73
Batch: 260; loss: 0.93; acc: 0.64
Batch: 280; loss: 0.96; acc: 0.69
Batch: 300; loss: 0.81; acc: 0.78
Batch: 320; loss: 0.88; acc: 0.69
Batch: 340; loss: 0.67; acc: 0.84
Batch: 360; loss: 0.88; acc: 0.72
Batch: 380; loss: 1.04; acc: 0.7
Batch: 400; loss: 0.91; acc: 0.7
Batch: 420; loss: 0.94; acc: 0.7
Batch: 440; loss: 1.07; acc: 0.62
Batch: 460; loss: 1.03; acc: 0.77
Batch: 480; loss: 0.77; acc: 0.75
Batch: 500; loss: 0.82; acc: 0.67
Batch: 520; loss: 0.98; acc: 0.72
Batch: 540; loss: 0.79; acc: 0.72
Batch: 560; loss: 1.04; acc: 0.64
Batch: 580; loss: 1.13; acc: 0.59
Batch: 600; loss: 0.88; acc: 0.73
Batch: 620; loss: 0.84; acc: 0.78
Batch: 640; loss: 1.1; acc: 0.66
Batch: 660; loss: 0.86; acc: 0.78
Batch: 680; loss: 1.03; acc: 0.73
Batch: 700; loss: 0.76; acc: 0.77
Batch: 720; loss: 0.92; acc: 0.7
Batch: 740; loss: 0.79; acc: 0.78
Batch: 760; loss: 1.09; acc: 0.66
Batch: 780; loss: 1.0; acc: 0.62
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.035003126366064e-05
6.132371709099971e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.26; acc: 0.59
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8937578332272305; val_accuracy: 0.7216361464968153 

The current subspace-distance is: 6.132371709099971e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.91; acc: 0.72
Batch: 20; loss: 0.94; acc: 0.64
Batch: 40; loss: 1.26; acc: 0.59
Batch: 60; loss: 0.83; acc: 0.75
Batch: 80; loss: 0.98; acc: 0.66
Batch: 100; loss: 1.45; acc: 0.64
Batch: 120; loss: 1.2; acc: 0.53
Batch: 140; loss: 1.07; acc: 0.62
Batch: 160; loss: 1.13; acc: 0.62
Batch: 180; loss: 0.84; acc: 0.72
Batch: 200; loss: 1.2; acc: 0.62
Batch: 220; loss: 0.92; acc: 0.69
Batch: 240; loss: 1.2; acc: 0.64
Batch: 260; loss: 0.97; acc: 0.7
Batch: 280; loss: 0.83; acc: 0.72
Batch: 300; loss: 0.85; acc: 0.75
Batch: 320; loss: 0.65; acc: 0.81
Batch: 340; loss: 1.02; acc: 0.62
Batch: 360; loss: 0.96; acc: 0.72
Batch: 380; loss: 1.15; acc: 0.72
Batch: 400; loss: 1.29; acc: 0.62
Batch: 420; loss: 0.95; acc: 0.7
Batch: 440; loss: 1.01; acc: 0.7
Batch: 460; loss: 0.88; acc: 0.73
Batch: 480; loss: 0.75; acc: 0.7
Batch: 500; loss: 1.04; acc: 0.73
Batch: 520; loss: 0.95; acc: 0.73
Batch: 540; loss: 1.17; acc: 0.69
Batch: 560; loss: 0.86; acc: 0.67
Batch: 580; loss: 0.99; acc: 0.73
Batch: 600; loss: 1.02; acc: 0.72
Batch: 620; loss: 0.82; acc: 0.69
Batch: 640; loss: 1.04; acc: 0.67
Batch: 660; loss: 0.65; acc: 0.78
Batch: 680; loss: 1.02; acc: 0.7
Batch: 700; loss: 1.16; acc: 0.69
Batch: 720; loss: 0.75; acc: 0.8
Batch: 740; loss: 0.94; acc: 0.67
Batch: 760; loss: 0.71; acc: 0.8
Batch: 780; loss: 0.75; acc: 0.72
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.794310264813248e-05
6.918407507328084e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.67
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8933375568906213; val_accuracy: 0.7205414012738853 

The current subspace-distance is: 6.918407507328084e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.88; acc: 0.67
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.75; acc: 0.78
Batch: 60; loss: 1.04; acc: 0.62
Batch: 80; loss: 0.88; acc: 0.7
Batch: 100; loss: 0.72; acc: 0.75
Batch: 120; loss: 1.18; acc: 0.61
Batch: 140; loss: 0.99; acc: 0.7
Batch: 160; loss: 0.76; acc: 0.78
Batch: 180; loss: 0.94; acc: 0.67
Batch: 200; loss: 1.15; acc: 0.61
Batch: 220; loss: 0.86; acc: 0.73
Batch: 240; loss: 0.86; acc: 0.69
Batch: 260; loss: 1.08; acc: 0.7
Batch: 280; loss: 0.97; acc: 0.66
Batch: 300; loss: 1.21; acc: 0.59
Batch: 320; loss: 0.81; acc: 0.72
Batch: 340; loss: 0.89; acc: 0.7
Batch: 360; loss: 0.88; acc: 0.73
Batch: 380; loss: 0.92; acc: 0.66
Batch: 400; loss: 0.65; acc: 0.83
Batch: 420; loss: 0.88; acc: 0.73
Batch: 440; loss: 0.95; acc: 0.69
Batch: 460; loss: 0.91; acc: 0.75
Batch: 480; loss: 1.13; acc: 0.62
Batch: 500; loss: 0.88; acc: 0.75
Batch: 520; loss: 0.94; acc: 0.62
Batch: 540; loss: 0.72; acc: 0.72
Batch: 560; loss: 1.05; acc: 0.69
Batch: 580; loss: 1.04; acc: 0.72
Batch: 600; loss: 0.84; acc: 0.78
Batch: 620; loss: 0.72; acc: 0.81
Batch: 640; loss: 1.01; acc: 0.66
Batch: 660; loss: 1.08; acc: 0.62
Batch: 680; loss: 1.08; acc: 0.61
Batch: 700; loss: 0.92; acc: 0.72
Batch: 720; loss: 1.15; acc: 0.58
Batch: 740; loss: 0.84; acc: 0.72
Batch: 760; loss: 1.0; acc: 0.7
Batch: 780; loss: 0.83; acc: 0.67
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.9046457964577712e-05
7.332634140766459e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.74; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8930094585676861; val_accuracy: 0.7220342356687898 

The current subspace-distance is: 7.332634140766459e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.1; acc: 0.7
Batch: 20; loss: 0.97; acc: 0.77
Batch: 40; loss: 0.6; acc: 0.8
Batch: 60; loss: 0.92; acc: 0.77
Batch: 80; loss: 1.06; acc: 0.73
Batch: 100; loss: 1.02; acc: 0.64
Batch: 120; loss: 0.98; acc: 0.73
Batch: 140; loss: 0.99; acc: 0.62
Batch: 160; loss: 0.96; acc: 0.7
Batch: 180; loss: 1.12; acc: 0.7
Batch: 200; loss: 0.9; acc: 0.67
Batch: 220; loss: 0.64; acc: 0.77
Batch: 240; loss: 1.09; acc: 0.66
Batch: 260; loss: 0.85; acc: 0.69
Batch: 280; loss: 1.02; acc: 0.66
Batch: 300; loss: 0.98; acc: 0.69
Batch: 320; loss: 0.95; acc: 0.7
Batch: 340; loss: 0.89; acc: 0.73
Batch: 360; loss: 0.81; acc: 0.78
Batch: 380; loss: 1.21; acc: 0.56
Batch: 400; loss: 0.72; acc: 0.8
Batch: 420; loss: 0.85; acc: 0.72
Batch: 440; loss: 0.88; acc: 0.73
Batch: 460; loss: 0.97; acc: 0.66
Batch: 480; loss: 1.01; acc: 0.67
Batch: 500; loss: 1.11; acc: 0.67
Batch: 520; loss: 0.88; acc: 0.73
Batch: 540; loss: 1.02; acc: 0.73
Batch: 560; loss: 0.91; acc: 0.72
Batch: 580; loss: 0.98; acc: 0.7
Batch: 600; loss: 0.99; acc: 0.66
Batch: 620; loss: 0.91; acc: 0.72
Batch: 640; loss: 1.1; acc: 0.66
Batch: 660; loss: 0.71; acc: 0.83
Batch: 680; loss: 0.66; acc: 0.77
Batch: 700; loss: 0.6; acc: 0.84
Batch: 720; loss: 0.77; acc: 0.83
Batch: 740; loss: 1.05; acc: 0.64
Batch: 760; loss: 1.02; acc: 0.67
Batch: 780; loss: 0.9; acc: 0.69
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.8231354260933585e-05
7.746876690362114e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.59
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8933873522053858; val_accuracy: 0.7223328025477707 

The current subspace-distance is: 7.746876690362114e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.95; acc: 0.72
Batch: 20; loss: 0.8; acc: 0.77
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 0.84; acc: 0.75
Batch: 80; loss: 0.87; acc: 0.73
Batch: 100; loss: 0.98; acc: 0.69
Batch: 120; loss: 0.89; acc: 0.69
Batch: 140; loss: 0.8; acc: 0.7
Batch: 160; loss: 0.98; acc: 0.66
Batch: 180; loss: 0.98; acc: 0.7
Batch: 200; loss: 1.34; acc: 0.62
Batch: 220; loss: 0.77; acc: 0.8
Batch: 240; loss: 1.2; acc: 0.58
Batch: 260; loss: 0.98; acc: 0.72
Batch: 280; loss: 1.05; acc: 0.64
Batch: 300; loss: 0.82; acc: 0.7
Batch: 320; loss: 1.1; acc: 0.69
Batch: 340; loss: 1.26; acc: 0.62
Batch: 360; loss: 1.16; acc: 0.64
Batch: 380; loss: 1.24; acc: 0.66
Batch: 400; loss: 0.92; acc: 0.7
Batch: 420; loss: 0.74; acc: 0.75
Batch: 440; loss: 0.78; acc: 0.77
Batch: 460; loss: 1.09; acc: 0.56
Batch: 480; loss: 0.7; acc: 0.73
Batch: 500; loss: 0.9; acc: 0.73
Batch: 520; loss: 0.88; acc: 0.72
Batch: 540; loss: 0.87; acc: 0.77
Batch: 560; loss: 0.86; acc: 0.73
Batch: 580; loss: 0.71; acc: 0.73
Batch: 600; loss: 0.82; acc: 0.72
Batch: 620; loss: 0.8; acc: 0.77
Batch: 640; loss: 0.89; acc: 0.75
Batch: 660; loss: 0.91; acc: 0.72
Batch: 680; loss: 0.85; acc: 0.72
Batch: 700; loss: 0.85; acc: 0.73
Batch: 720; loss: 0.86; acc: 0.8
Batch: 740; loss: 1.25; acc: 0.58
Batch: 760; loss: 0.83; acc: 0.77
Batch: 780; loss: 0.77; acc: 0.72
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.176888483518269e-05
6.609773208765546e-06
slurmstepd: error: _is_a_lwp: open() /proc/223080/status failed: No such file or directory
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.7
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.89
Val Epoch over. val_loss: 0.8934757931596914; val_accuracy: 0.7228304140127388 

The current subspace-distance is: 6.609773208765546e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.69; acc: 0.8
Batch: 40; loss: 0.87; acc: 0.8
Batch: 60; loss: 0.91; acc: 0.73
Batch: 80; loss: 1.01; acc: 0.69
Batch: 100; loss: 0.98; acc: 0.64
Batch: 120; loss: 1.08; acc: 0.67
Batch: 140; loss: 0.85; acc: 0.77
Batch: 160; loss: 0.81; acc: 0.67
Batch: 180; loss: 0.99; acc: 0.67
Batch: 200; loss: 0.81; acc: 0.72
Batch: 220; loss: 0.79; acc: 0.77
Batch: 240; loss: 0.89; acc: 0.73
Batch: 260; loss: 0.84; acc: 0.72
Batch: 280; loss: 0.83; acc: 0.7
Batch: 300; loss: 0.95; acc: 0.67
Batch: 320; loss: 0.98; acc: 0.73
Batch: 340; loss: 0.82; acc: 0.7
Batch: 360; loss: 0.97; acc: 0.69
Batch: 380; loss: 0.87; acc: 0.67
Batch: 400; loss: 0.95; acc: 0.66
Batch: 420; loss: 1.1; acc: 0.66
Batch: 440; loss: 0.72; acc: 0.86
Batch: 460; loss: 0.75; acc: 0.77
Batch: 480; loss: 0.87; acc: 0.72
Batch: 500; loss: 0.92; acc: 0.73
Batch: 520; loss: 0.86; acc: 0.78
Batch: 540; loss: 0.98; acc: 0.69
Batch: 560; loss: 0.97; acc: 0.69
Batch: 580; loss: 1.08; acc: 0.66
Batch: 600; loss: 0.95; acc: 0.69
Batch: 620; loss: 0.8; acc: 0.78
Batch: 640; loss: 1.06; acc: 0.7
Batch: 660; loss: 1.16; acc: 0.66
Batch: 680; loss: 1.09; acc: 0.75
Batch: 700; loss: 0.59; acc: 0.83
Batch: 720; loss: 0.83; acc: 0.75
Batch: 740; loss: 1.08; acc: 0.61
Batch: 760; loss: 1.06; acc: 0.7
Batch: 780; loss: 0.9; acc: 0.7
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.803530176403001e-05
6.703641702188179e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.66
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.74; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8928578203650797; val_accuracy: 0.7222332802547771 

The current subspace-distance is: 6.703641702188179e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 1.31; acc: 0.58
Batch: 40; loss: 0.72; acc: 0.78
Batch: 60; loss: 0.91; acc: 0.77
Batch: 80; loss: 0.94; acc: 0.75
Batch: 100; loss: 1.02; acc: 0.62
Batch: 120; loss: 0.97; acc: 0.67
Batch: 140; loss: 1.04; acc: 0.66
Batch: 160; loss: 1.04; acc: 0.66
Batch: 180; loss: 0.9; acc: 0.7
Batch: 200; loss: 1.01; acc: 0.67
Batch: 220; loss: 0.88; acc: 0.75
Batch: 240; loss: 0.81; acc: 0.75
Batch: 260; loss: 0.96; acc: 0.67
Batch: 280; loss: 1.17; acc: 0.61
Batch: 300; loss: 0.97; acc: 0.67
Batch: 320; loss: 0.95; acc: 0.73
Batch: 340; loss: 0.91; acc: 0.7
Batch: 360; loss: 0.97; acc: 0.64
Batch: 380; loss: 1.02; acc: 0.69
Batch: 400; loss: 1.27; acc: 0.56
Batch: 420; loss: 1.13; acc: 0.61
Batch: 440; loss: 1.08; acc: 0.72
Batch: 460; loss: 1.04; acc: 0.75
Batch: 480; loss: 0.73; acc: 0.8
Batch: 500; loss: 0.89; acc: 0.72
Batch: 520; loss: 0.95; acc: 0.69
Batch: 540; loss: 0.94; acc: 0.61
Batch: 560; loss: 1.03; acc: 0.64
Batch: 580; loss: 0.67; acc: 0.83
Batch: 600; loss: 1.04; acc: 0.7
Batch: 620; loss: 1.14; acc: 0.62
Batch: 640; loss: 0.84; acc: 0.69
Batch: 660; loss: 1.01; acc: 0.59
Batch: 680; loss: 0.93; acc: 0.66
Batch: 700; loss: 0.84; acc: 0.72
Batch: 720; loss: 0.87; acc: 0.72
Batch: 740; loss: 1.17; acc: 0.7
Batch: 760; loss: 1.23; acc: 0.59
Batch: 780; loss: 0.92; acc: 0.72
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.0886549464194104e-05
5.1178253670514096e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.14; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.59
Batch: 140; loss: 0.51; acc: 0.89
Val Epoch over. val_loss: 0.8939189639440768; val_accuracy: 0.7213375796178344 

The current subspace-distance is: 5.1178253670514096e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.76; acc: 0.73
Batch: 20; loss: 1.16; acc: 0.69
Batch: 40; loss: 0.92; acc: 0.75
Batch: 60; loss: 1.03; acc: 0.69
Batch: 80; loss: 1.06; acc: 0.61
Batch: 100; loss: 0.79; acc: 0.75
Batch: 120; loss: 1.09; acc: 0.66
Batch: 140; loss: 0.98; acc: 0.67
Batch: 160; loss: 1.09; acc: 0.61
Batch: 180; loss: 1.1; acc: 0.67
Batch: 200; loss: 1.22; acc: 0.64
Batch: 220; loss: 1.23; acc: 0.61
Batch: 240; loss: 1.27; acc: 0.62
Batch: 260; loss: 0.69; acc: 0.77
Batch: 280; loss: 0.89; acc: 0.7
Batch: 300; loss: 1.32; acc: 0.61
Batch: 320; loss: 1.28; acc: 0.59
Batch: 340; loss: 1.04; acc: 0.69
Batch: 360; loss: 1.11; acc: 0.69
Batch: 380; loss: 1.07; acc: 0.73
Batch: 400; loss: 1.03; acc: 0.67
Batch: 420; loss: 0.64; acc: 0.81
Batch: 440; loss: 1.17; acc: 0.64
Batch: 460; loss: 0.85; acc: 0.81
Batch: 480; loss: 0.75; acc: 0.8
Batch: 500; loss: 0.97; acc: 0.7
Batch: 520; loss: 0.83; acc: 0.72
Batch: 540; loss: 0.89; acc: 0.66
Batch: 560; loss: 0.89; acc: 0.72
Batch: 580; loss: 0.68; acc: 0.8
Batch: 600; loss: 1.01; acc: 0.67
Batch: 620; loss: 1.25; acc: 0.62
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 0.89; acc: 0.78
Batch: 680; loss: 1.02; acc: 0.69
Batch: 700; loss: 0.95; acc: 0.67
Batch: 720; loss: 0.93; acc: 0.64
Batch: 740; loss: 1.0; acc: 0.66
Batch: 760; loss: 0.89; acc: 0.69
Batch: 780; loss: 0.89; acc: 0.7
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

1.795342905097641e-05
6.592897079826798e-06
Batch: 0; loss: 0.85; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.61
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8932219701967422; val_accuracy: 0.722531847133758 

The current subspace-distance is: 6.592897079826798e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.03; acc: 0.67
Batch: 20; loss: 0.92; acc: 0.69
Batch: 40; loss: 0.73; acc: 0.78
Batch: 60; loss: 1.01; acc: 0.75
Batch: 80; loss: 1.11; acc: 0.69
Batch: 100; loss: 1.31; acc: 0.59
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 0.8; acc: 0.77
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 0.93; acc: 0.75
Batch: 200; loss: 1.07; acc: 0.69
Batch: 220; loss: 0.76; acc: 0.8
Batch: 240; loss: 0.89; acc: 0.73
Batch: 260; loss: 0.78; acc: 0.73
Batch: 280; loss: 0.81; acc: 0.72
Batch: 300; loss: 0.69; acc: 0.78
Batch: 320; loss: 1.3; acc: 0.66
Batch: 340; loss: 0.85; acc: 0.75
Batch: 360; loss: 0.96; acc: 0.67
Batch: 380; loss: 1.11; acc: 0.61
Batch: 400; loss: 1.21; acc: 0.67
Batch: 420; loss: 1.17; acc: 0.66
Batch: 440; loss: 1.13; acc: 0.66
Batch: 460; loss: 1.23; acc: 0.64
Batch: 480; loss: 0.82; acc: 0.75
Batch: 500; loss: 0.73; acc: 0.73
Batch: 520; loss: 1.13; acc: 0.67
Batch: 540; loss: 1.01; acc: 0.66
Batch: 560; loss: 1.03; acc: 0.62
Batch: 580; loss: 0.82; acc: 0.72
Batch: 600; loss: 0.92; acc: 0.67
Batch: 620; loss: 0.72; acc: 0.75
Batch: 640; loss: 1.06; acc: 0.69
Batch: 660; loss: 1.05; acc: 0.69
Batch: 680; loss: 1.35; acc: 0.61
Batch: 700; loss: 0.96; acc: 0.67
Batch: 720; loss: 1.26; acc: 0.62
Batch: 740; loss: 0.74; acc: 0.77
Batch: 760; loss: 0.72; acc: 0.77
Batch: 780; loss: 0.93; acc: 0.73
Train Epoch over. train_loss: 0.95; train_accuracy: 0.7 

2.09805784834316e-05
6.681279955955688e-06
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 1.13; acc: 0.67
Batch: 40; loss: 0.67; acc: 0.83
Batch: 60; loss: 0.91; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 1.27; acc: 0.59
Batch: 140; loss: 0.5; acc: 0.88
Val Epoch over. val_loss: 0.8929890690335802; val_accuracy: 0.7227308917197452 

The current subspace-distance is: 6.681279955955688e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_75_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 21149
elements in E: 4442600
fraction nonzero: 0.0047605006077522175
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.06
Batch: 200; loss: 2.31; acc: 0.09
Batch: 220; loss: 2.29; acc: 0.16
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.31; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.09
Batch: 300; loss: 2.28; acc: 0.23
Batch: 320; loss: 2.29; acc: 0.14
Batch: 340; loss: 2.29; acc: 0.19
Batch: 360; loss: 2.3; acc: 0.08
Batch: 380; loss: 2.29; acc: 0.16
Batch: 400; loss: 2.29; acc: 0.11
Batch: 420; loss: 2.29; acc: 0.17
Batch: 440; loss: 2.28; acc: 0.19
Batch: 460; loss: 2.29; acc: 0.16
Batch: 480; loss: 2.29; acc: 0.25
Batch: 500; loss: 2.28; acc: 0.17
Batch: 520; loss: 2.29; acc: 0.16
Batch: 540; loss: 2.28; acc: 0.25
Batch: 560; loss: 2.29; acc: 0.22
Batch: 580; loss: 2.28; acc: 0.25
Batch: 600; loss: 2.28; acc: 0.33
Batch: 620; loss: 2.29; acc: 0.28
Batch: 640; loss: 2.27; acc: 0.3
Batch: 660; loss: 2.28; acc: 0.22
Batch: 680; loss: 2.27; acc: 0.22
Batch: 700; loss: 2.27; acc: 0.36
Batch: 720; loss: 2.29; acc: 0.22
Batch: 740; loss: 2.28; acc: 0.27
Batch: 760; loss: 2.27; acc: 0.3
Batch: 780; loss: 2.27; acc: 0.22
Train Epoch over. train_loss: 2.29; train_accuracy: 0.17 

4.261580215825234e-06
1.2091934422642225e-06
Batch: 0; loss: 2.27; acc: 0.28
Batch: 20; loss: 2.27; acc: 0.19
Batch: 40; loss: 2.26; acc: 0.23
Batch: 60; loss: 2.27; acc: 0.19
Batch: 80; loss: 2.27; acc: 0.3
Batch: 100; loss: 2.26; acc: 0.3
Batch: 120; loss: 2.27; acc: 0.3
Batch: 140; loss: 2.26; acc: 0.33
Val Epoch over. val_loss: 2.269936869858177; val_accuracy: 0.2606488853503185 

The current subspace-distance is: 1.2091934422642225e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.26; acc: 0.23
Batch: 20; loss: 2.26; acc: 0.38
Batch: 40; loss: 2.29; acc: 0.23
Batch: 60; loss: 2.26; acc: 0.25
Batch: 80; loss: 2.28; acc: 0.16
Batch: 100; loss: 2.27; acc: 0.19
Batch: 120; loss: 2.26; acc: 0.22
Batch: 140; loss: 2.26; acc: 0.19
Batch: 160; loss: 2.27; acc: 0.17
Batch: 180; loss: 2.25; acc: 0.3
Batch: 200; loss: 2.26; acc: 0.22
Batch: 220; loss: 2.24; acc: 0.2
Batch: 240; loss: 2.23; acc: 0.23
Batch: 260; loss: 2.25; acc: 0.19
Batch: 280; loss: 2.24; acc: 0.22
Batch: 300; loss: 2.21; acc: 0.34
Batch: 320; loss: 2.22; acc: 0.27
Batch: 340; loss: 2.23; acc: 0.25
Batch: 360; loss: 2.21; acc: 0.28
Batch: 380; loss: 2.19; acc: 0.16
Batch: 400; loss: 2.17; acc: 0.34
Batch: 420; loss: 2.14; acc: 0.38
Batch: 440; loss: 2.19; acc: 0.25
Batch: 460; loss: 2.18; acc: 0.25
Batch: 480; loss: 2.17; acc: 0.25
Batch: 500; loss: 2.08; acc: 0.36
Batch: 520; loss: 2.12; acc: 0.3
Batch: 540; loss: 2.07; acc: 0.28
Batch: 560; loss: 2.06; acc: 0.34
Batch: 580; loss: 1.97; acc: 0.34
Batch: 600; loss: 1.92; acc: 0.38
Batch: 620; loss: 1.74; acc: 0.58
Batch: 640; loss: 1.79; acc: 0.44
Batch: 660; loss: 1.66; acc: 0.52
Batch: 680; loss: 1.56; acc: 0.48
Batch: 700; loss: 1.53; acc: 0.52
Batch: 720; loss: 1.28; acc: 0.61
Batch: 740; loss: 1.44; acc: 0.53
Batch: 760; loss: 1.33; acc: 0.53
Batch: 780; loss: 1.02; acc: 0.73
Train Epoch over. train_loss: 2.05; train_accuracy: 0.32 

1.0549330909270793e-05
5.0055045903718565e-06
Batch: 0; loss: 1.37; acc: 0.55
Batch: 20; loss: 1.34; acc: 0.58
Batch: 40; loss: 1.0; acc: 0.67
Batch: 60; loss: 1.01; acc: 0.72
Batch: 80; loss: 1.07; acc: 0.7
Batch: 100; loss: 1.16; acc: 0.58
Batch: 120; loss: 1.4; acc: 0.61
Batch: 140; loss: 0.95; acc: 0.66
Val Epoch over. val_loss: 1.2650713829477882; val_accuracy: 0.5916600318471338 

The current subspace-distance is: 5.0055045903718565e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.67; acc: 0.5
Batch: 20; loss: 1.37; acc: 0.66
Batch: 40; loss: 1.42; acc: 0.52
Batch: 60; loss: 1.23; acc: 0.58
Batch: 80; loss: 0.95; acc: 0.69
Batch: 100; loss: 1.2; acc: 0.62
Batch: 120; loss: 0.99; acc: 0.66
Batch: 140; loss: 0.97; acc: 0.67
Batch: 160; loss: 0.92; acc: 0.61
Batch: 180; loss: 0.95; acc: 0.66
Batch: 200; loss: 0.99; acc: 0.69
Batch: 220; loss: 0.98; acc: 0.7
Batch: 240; loss: 1.23; acc: 0.61
Batch: 260; loss: 1.05; acc: 0.64
Batch: 280; loss: 0.86; acc: 0.72
Batch: 300; loss: 0.99; acc: 0.66
Batch: 320; loss: 1.0; acc: 0.67
Batch: 340; loss: 1.16; acc: 0.58
Batch: 360; loss: 1.03; acc: 0.62
Batch: 380; loss: 1.07; acc: 0.67
Batch: 400; loss: 0.89; acc: 0.73
Batch: 420; loss: 0.81; acc: 0.73
Batch: 440; loss: 1.02; acc: 0.7
Batch: 460; loss: 1.02; acc: 0.69
Batch: 480; loss: 0.94; acc: 0.64
Batch: 500; loss: 0.77; acc: 0.75
Batch: 520; loss: 1.06; acc: 0.59
Batch: 540; loss: 1.11; acc: 0.58
Batch: 560; loss: 0.7; acc: 0.8
Batch: 580; loss: 0.72; acc: 0.73
Batch: 600; loss: 0.96; acc: 0.69
Batch: 620; loss: 0.77; acc: 0.72
Batch: 640; loss: 0.79; acc: 0.75
Batch: 660; loss: 0.78; acc: 0.75
Batch: 680; loss: 0.94; acc: 0.7
Batch: 700; loss: 0.77; acc: 0.75
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.79; acc: 0.78
Batch: 760; loss: 1.28; acc: 0.61
Batch: 780; loss: 0.97; acc: 0.67
Train Epoch over. train_loss: 0.96; train_accuracy: 0.68 

1.774627344275359e-05
5.8750988500833046e-06
Batch: 0; loss: 1.02; acc: 0.66
Batch: 20; loss: 1.12; acc: 0.61
Batch: 40; loss: 0.58; acc: 0.8
Batch: 60; loss: 0.98; acc: 0.81
Batch: 80; loss: 0.68; acc: 0.8
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 1.24; acc: 0.66
Batch: 140; loss: 0.58; acc: 0.88
Val Epoch over. val_loss: 0.8550501995405574; val_accuracy: 0.7312898089171974 

The current subspace-distance is: 5.8750988500833046e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.02; acc: 0.72
Batch: 20; loss: 0.93; acc: 0.72
Batch: 40; loss: 0.9; acc: 0.72
Batch: 60; loss: 1.16; acc: 0.61
Batch: 80; loss: 0.83; acc: 0.77
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.81; acc: 0.81
Batch: 160; loss: 1.11; acc: 0.66
Batch: 180; loss: 0.82; acc: 0.7
Batch: 200; loss: 1.08; acc: 0.67
Batch: 220; loss: 0.71; acc: 0.73
Batch: 240; loss: 0.97; acc: 0.73
Batch: 260; loss: 0.76; acc: 0.69
Batch: 280; loss: 0.94; acc: 0.75
Batch: 300; loss: 0.82; acc: 0.8
Batch: 320; loss: 0.97; acc: 0.7
Batch: 340; loss: 0.9; acc: 0.72
Batch: 360; loss: 0.98; acc: 0.67
Batch: 380; loss: 0.71; acc: 0.7
Batch: 400; loss: 0.67; acc: 0.77
Batch: 420; loss: 0.98; acc: 0.7
Batch: 440; loss: 1.0; acc: 0.61
Batch: 460; loss: 0.78; acc: 0.73
Batch: 480; loss: 0.83; acc: 0.69
Batch: 500; loss: 0.71; acc: 0.73
Batch: 520; loss: 0.74; acc: 0.8
Batch: 540; loss: 0.88; acc: 0.7
Batch: 560; loss: 0.82; acc: 0.77
Batch: 580; loss: 1.01; acc: 0.64
Batch: 600; loss: 0.9; acc: 0.69
Batch: 620; loss: 0.93; acc: 0.73
Batch: 640; loss: 0.64; acc: 0.86
Batch: 660; loss: 0.6; acc: 0.88
Batch: 680; loss: 0.86; acc: 0.72
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.86; acc: 0.64
Batch: 760; loss: 0.97; acc: 0.7
Batch: 780; loss: 1.01; acc: 0.7
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

1.878519651654642e-05
6.47334036329994e-06
Batch: 0; loss: 1.34; acc: 0.55
Batch: 20; loss: 1.02; acc: 0.69
Batch: 40; loss: 0.86; acc: 0.73
Batch: 60; loss: 1.43; acc: 0.62
Batch: 80; loss: 1.03; acc: 0.72
Batch: 100; loss: 0.88; acc: 0.7
Batch: 120; loss: 1.4; acc: 0.62
Batch: 140; loss: 0.8; acc: 0.7
Val Epoch over. val_loss: 1.0865298205879843; val_accuracy: 0.6563495222929936 

The current subspace-distance is: 6.47334036329994e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.92; acc: 0.55
Batch: 20; loss: 0.92; acc: 0.66
Batch: 40; loss: 0.73; acc: 0.75
Batch: 60; loss: 1.01; acc: 0.72
Batch: 80; loss: 0.79; acc: 0.77
Batch: 100; loss: 1.05; acc: 0.62
Batch: 120; loss: 0.72; acc: 0.73
Batch: 140; loss: 0.73; acc: 0.8
Batch: 160; loss: 0.87; acc: 0.73
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.73; acc: 0.75
Batch: 220; loss: 0.78; acc: 0.78
Batch: 240; loss: 0.71; acc: 0.8
Batch: 260; loss: 0.52; acc: 0.88
Batch: 280; loss: 0.59; acc: 0.83
Batch: 300; loss: 0.77; acc: 0.75
Batch: 320; loss: 0.81; acc: 0.73
Batch: 340; loss: 0.84; acc: 0.75
Batch: 360; loss: 0.6; acc: 0.78
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.73; acc: 0.73
Batch: 420; loss: 1.01; acc: 0.7
Batch: 440; loss: 0.83; acc: 0.7
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.8; acc: 0.75
Batch: 500; loss: 0.7; acc: 0.81
Batch: 520; loss: 0.81; acc: 0.75
Batch: 540; loss: 1.05; acc: 0.64
Batch: 560; loss: 0.55; acc: 0.81
Batch: 580; loss: 1.08; acc: 0.69
Batch: 600; loss: 0.61; acc: 0.77
Batch: 620; loss: 0.6; acc: 0.78
Batch: 640; loss: 0.92; acc: 0.67
Batch: 660; loss: 0.67; acc: 0.73
Batch: 680; loss: 0.72; acc: 0.75
Batch: 700; loss: 0.76; acc: 0.78
Batch: 720; loss: 0.67; acc: 0.78
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.69; acc: 0.78
Batch: 780; loss: 0.53; acc: 0.83
Train Epoch over. train_loss: 0.78; train_accuracy: 0.75 

1.8784208805300295e-05
6.150159606477246e-06
Batch: 0; loss: 1.2; acc: 0.67
Batch: 20; loss: 0.99; acc: 0.72
Batch: 40; loss: 0.78; acc: 0.75
Batch: 60; loss: 1.44; acc: 0.67
Batch: 80; loss: 0.96; acc: 0.72
Batch: 100; loss: 0.96; acc: 0.72
Batch: 120; loss: 1.37; acc: 0.64
Batch: 140; loss: 0.66; acc: 0.72
Val Epoch over. val_loss: 1.0824734693879534; val_accuracy: 0.6647093949044586 

The current subspace-distance is: 6.150159606477246e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.24; acc: 0.67
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.78; acc: 0.78
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.81
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.81; acc: 0.73
Batch: 160; loss: 0.92; acc: 0.7
Batch: 180; loss: 0.8; acc: 0.7
Batch: 200; loss: 0.86; acc: 0.75
Batch: 220; loss: 0.71; acc: 0.75
Batch: 240; loss: 0.68; acc: 0.8
Batch: 260; loss: 0.77; acc: 0.7
Batch: 280; loss: 0.94; acc: 0.69
Batch: 300; loss: 1.0; acc: 0.67
Batch: 320; loss: 0.86; acc: 0.75
Batch: 340; loss: 0.67; acc: 0.81
Batch: 360; loss: 0.62; acc: 0.81
Batch: 380; loss: 0.57; acc: 0.83
Batch: 400; loss: 0.59; acc: 0.84
Batch: 420; loss: 0.64; acc: 0.73
Batch: 440; loss: 0.62; acc: 0.8
Batch: 460; loss: 0.66; acc: 0.77
Batch: 480; loss: 0.76; acc: 0.8
Batch: 500; loss: 0.83; acc: 0.72
Batch: 520; loss: 0.65; acc: 0.84
Batch: 540; loss: 0.57; acc: 0.8
Batch: 560; loss: 0.99; acc: 0.67
Batch: 580; loss: 0.56; acc: 0.8
Batch: 600; loss: 0.67; acc: 0.72
Batch: 620; loss: 0.53; acc: 0.8
Batch: 640; loss: 0.85; acc: 0.69
Batch: 660; loss: 0.79; acc: 0.72
Batch: 680; loss: 0.67; acc: 0.8
Batch: 700; loss: 0.97; acc: 0.7
Batch: 720; loss: 0.6; acc: 0.83
Batch: 740; loss: 0.93; acc: 0.67
Batch: 760; loss: 0.82; acc: 0.73
Batch: 780; loss: 0.88; acc: 0.77
Train Epoch over. train_loss: 0.74; train_accuracy: 0.77 

1.900596726045478e-05
6.9037769208080135e-06
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 0.77; acc: 0.77
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 1.06; acc: 0.77
Batch: 80; loss: 0.61; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.83
Batch: 120; loss: 0.93; acc: 0.66
Batch: 140; loss: 0.51; acc: 0.77
Val Epoch over. val_loss: 0.7552068406229566; val_accuracy: 0.7691082802547771 

The current subspace-distance is: 6.9037769208080135e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.85; acc: 0.69
Batch: 20; loss: 0.83; acc: 0.75
Batch: 40; loss: 0.6; acc: 0.78
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.87; acc: 0.67
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 0.93; acc: 0.73
Batch: 140; loss: 0.81; acc: 0.72
Batch: 160; loss: 0.66; acc: 0.77
Batch: 180; loss: 0.72; acc: 0.77
Batch: 200; loss: 0.72; acc: 0.78
Batch: 220; loss: 0.79; acc: 0.73
Batch: 240; loss: 0.67; acc: 0.73
Batch: 260; loss: 0.72; acc: 0.78
Batch: 280; loss: 0.82; acc: 0.69
Batch: 300; loss: 0.75; acc: 0.7
Batch: 320; loss: 0.86; acc: 0.75
Batch: 340; loss: 0.66; acc: 0.8
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.91; acc: 0.73
Batch: 400; loss: 0.6; acc: 0.78
Batch: 420; loss: 0.7; acc: 0.78
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.64; acc: 0.83
Batch: 480; loss: 0.52; acc: 0.81
Batch: 500; loss: 0.67; acc: 0.78
Batch: 520; loss: 0.72; acc: 0.73
Batch: 540; loss: 0.72; acc: 0.81
Batch: 560; loss: 0.68; acc: 0.78
Batch: 580; loss: 0.79; acc: 0.75
Batch: 600; loss: 0.7; acc: 0.77
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.57; acc: 0.78
Batch: 660; loss: 0.85; acc: 0.7
Batch: 680; loss: 0.74; acc: 0.77
Batch: 700; loss: 0.85; acc: 0.77
Batch: 720; loss: 0.71; acc: 0.75
Batch: 740; loss: 0.67; acc: 0.75
Batch: 760; loss: 0.69; acc: 0.8
Batch: 780; loss: 0.61; acc: 0.75
Train Epoch over. train_loss: 0.72; train_accuracy: 0.77 

1.996206265175715e-05
6.571574431291083e-06
Batch: 0; loss: 0.83; acc: 0.7
Batch: 20; loss: 0.91; acc: 0.67
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.75; acc: 0.8
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.69; acc: 0.83
Batch: 120; loss: 0.79; acc: 0.69
Batch: 140; loss: 0.48; acc: 0.81
Val Epoch over. val_loss: 0.7015291534032032; val_accuracy: 0.7797571656050956 

The current subspace-distance is: 6.571574431291083e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 1.2; acc: 0.67
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.86; acc: 0.78
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 1.17; acc: 0.67
Batch: 180; loss: 0.74; acc: 0.73
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.63; acc: 0.78
Batch: 240; loss: 0.9; acc: 0.75
Batch: 260; loss: 0.73; acc: 0.77
Batch: 280; loss: 0.57; acc: 0.78
Batch: 300; loss: 0.5; acc: 0.8
Batch: 320; loss: 0.76; acc: 0.77
Batch: 340; loss: 0.8; acc: 0.78
Batch: 360; loss: 0.67; acc: 0.81
Batch: 380; loss: 0.86; acc: 0.73
Batch: 400; loss: 0.49; acc: 0.81
Batch: 420; loss: 0.53; acc: 0.81
Batch: 440; loss: 0.55; acc: 0.83
Batch: 460; loss: 0.65; acc: 0.81
Batch: 480; loss: 0.83; acc: 0.73
Batch: 500; loss: 0.78; acc: 0.75
Batch: 520; loss: 0.81; acc: 0.72
Batch: 540; loss: 0.81; acc: 0.75
Batch: 560; loss: 0.77; acc: 0.72
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.61; acc: 0.8
Batch: 620; loss: 0.71; acc: 0.77
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.73; acc: 0.78
Batch: 680; loss: 1.01; acc: 0.72
Batch: 700; loss: 0.59; acc: 0.83
Batch: 720; loss: 0.7; acc: 0.8
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 1.19; acc: 0.72
Batch: 780; loss: 0.67; acc: 0.81
Train Epoch over. train_loss: 0.72; train_accuracy: 0.77 

1.8212351278634742e-05
5.78110666538123e-06
Batch: 0; loss: 0.94; acc: 0.67
Batch: 20; loss: 0.91; acc: 0.72
Batch: 40; loss: 0.51; acc: 0.89
Batch: 60; loss: 1.06; acc: 0.72
Batch: 80; loss: 0.6; acc: 0.83
Batch: 100; loss: 0.85; acc: 0.73
Batch: 120; loss: 1.07; acc: 0.66
Batch: 140; loss: 0.52; acc: 0.78
Val Epoch over. val_loss: 0.8645933126188388; val_accuracy: 0.7183519108280255 

The current subspace-distance is: 5.78110666538123e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 0.78; acc: 0.78
Batch: 40; loss: 0.78; acc: 0.72
Batch: 60; loss: 0.67; acc: 0.73
Batch: 80; loss: 0.57; acc: 0.75
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.7; acc: 0.72
Batch: 140; loss: 0.79; acc: 0.7
Batch: 160; loss: 0.73; acc: 0.75
Batch: 180; loss: 0.76; acc: 0.81
Batch: 200; loss: 0.65; acc: 0.77
Batch: 220; loss: 0.67; acc: 0.83
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.85; acc: 0.73
Batch: 300; loss: 0.91; acc: 0.7
Batch: 320; loss: 1.14; acc: 0.72
Batch: 340; loss: 0.61; acc: 0.86
Batch: 360; loss: 0.55; acc: 0.84
Batch: 380; loss: 0.77; acc: 0.81
Batch: 400; loss: 0.66; acc: 0.8
Batch: 420; loss: 0.68; acc: 0.72
Batch: 440; loss: 0.79; acc: 0.69
Batch: 460; loss: 0.89; acc: 0.7
Batch: 480; loss: 0.91; acc: 0.75
Batch: 500; loss: 0.65; acc: 0.86
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 1.03; acc: 0.69
Batch: 560; loss: 0.58; acc: 0.75
Batch: 580; loss: 0.67; acc: 0.8
Batch: 600; loss: 0.94; acc: 0.62
Batch: 620; loss: 0.68; acc: 0.8
Batch: 640; loss: 0.75; acc: 0.7
Batch: 660; loss: 0.75; acc: 0.75
Batch: 680; loss: 0.63; acc: 0.81
Batch: 700; loss: 0.83; acc: 0.77
Batch: 720; loss: 0.71; acc: 0.73
Batch: 740; loss: 0.74; acc: 0.8
Batch: 760; loss: 0.57; acc: 0.83
Batch: 780; loss: 0.79; acc: 0.78
Train Epoch over. train_loss: 0.72; train_accuracy: 0.77 

2.0973675418645144e-05
7.0564556153840385e-06
Batch: 0; loss: 0.99; acc: 0.69
Batch: 20; loss: 0.96; acc: 0.66
Batch: 40; loss: 0.61; acc: 0.81
Batch: 60; loss: 1.1; acc: 0.72
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.79; acc: 0.75
Batch: 120; loss: 1.1; acc: 0.61
Batch: 140; loss: 0.57; acc: 0.84
Val Epoch over. val_loss: 0.8465489150991865; val_accuracy: 0.729796974522293 

The current subspace-distance is: 7.0564556153840385e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.76; acc: 0.8
Batch: 20; loss: 0.8; acc: 0.77
Batch: 40; loss: 0.75; acc: 0.78
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.76; acc: 0.72
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.67
Batch: 140; loss: 0.69; acc: 0.77
Batch: 160; loss: 0.62; acc: 0.77
Batch: 180; loss: 0.72; acc: 0.77
Batch: 200; loss: 0.8; acc: 0.7
Batch: 220; loss: 0.66; acc: 0.75
Batch: 240; loss: 0.58; acc: 0.81
Batch: 260; loss: 0.79; acc: 0.8
Batch: 280; loss: 0.65; acc: 0.8
Batch: 300; loss: 0.62; acc: 0.8
Batch: 320; loss: 0.58; acc: 0.81
Batch: 340; loss: 0.52; acc: 0.86
Batch: 360; loss: 0.74; acc: 0.77
Batch: 380; loss: 0.68; acc: 0.78
Batch: 400; loss: 0.7; acc: 0.75
Batch: 420; loss: 0.73; acc: 0.8
Batch: 440; loss: 0.7; acc: 0.8
Batch: 460; loss: 0.79; acc: 0.78
Batch: 480; loss: 0.63; acc: 0.8
Batch: 500; loss: 0.72; acc: 0.77
Batch: 520; loss: 0.68; acc: 0.77
Batch: 540; loss: 0.78; acc: 0.78
Batch: 560; loss: 0.78; acc: 0.75
Batch: 580; loss: 0.98; acc: 0.73
Batch: 600; loss: 0.84; acc: 0.77
Batch: 620; loss: 0.68; acc: 0.72
Batch: 640; loss: 0.78; acc: 0.72
Batch: 660; loss: 0.64; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.55; acc: 0.83
Batch: 740; loss: 0.66; acc: 0.75
Batch: 760; loss: 0.67; acc: 0.83
Batch: 780; loss: 0.74; acc: 0.73
Train Epoch over. train_loss: 0.72; train_accuracy: 0.77 

1.879947740235366e-05
6.596475941478275e-06
Batch: 0; loss: 0.77; acc: 0.77
Batch: 20; loss: 1.03; acc: 0.67
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.91; acc: 0.8
Batch: 80; loss: 0.49; acc: 0.81
Batch: 100; loss: 0.71; acc: 0.8
Batch: 120; loss: 0.99; acc: 0.7
Batch: 140; loss: 0.45; acc: 0.81
Val Epoch over. val_loss: 0.7162158680949241; val_accuracy: 0.7716958598726115 

The current subspace-distance is: 6.596475941478275e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.76; acc: 0.73
Batch: 20; loss: 0.7; acc: 0.77
Batch: 40; loss: 0.68; acc: 0.75
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.68; acc: 0.8
Batch: 160; loss: 0.7; acc: 0.81
Batch: 180; loss: 0.74; acc: 0.81
Batch: 200; loss: 0.65; acc: 0.81
Batch: 220; loss: 0.69; acc: 0.78
Batch: 240; loss: 0.69; acc: 0.81
Batch: 260; loss: 0.51; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.72; acc: 0.78
Batch: 320; loss: 0.74; acc: 0.77
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.78; acc: 0.73
Batch: 380; loss: 0.7; acc: 0.81
Batch: 400; loss: 0.86; acc: 0.73
Batch: 420; loss: 0.73; acc: 0.77
Batch: 440; loss: 0.62; acc: 0.77
Batch: 460; loss: 0.58; acc: 0.81
Batch: 480; loss: 0.86; acc: 0.66
Batch: 500; loss: 0.64; acc: 0.73
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.75; acc: 0.83
Batch: 560; loss: 0.63; acc: 0.73
Batch: 580; loss: 0.73; acc: 0.75
Batch: 600; loss: 0.65; acc: 0.78
Batch: 620; loss: 0.66; acc: 0.83
Batch: 640; loss: 0.64; acc: 0.83
Batch: 660; loss: 0.56; acc: 0.88
Batch: 680; loss: 0.64; acc: 0.78
Batch: 700; loss: 0.81; acc: 0.8
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.61; acc: 0.81
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.85; acc: 0.73
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.1155798094696365e-05
7.292143891390879e-06
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.81; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.7; acc: 0.81
Batch: 120; loss: 0.87; acc: 0.67
Batch: 140; loss: 0.38; acc: 0.83
Val Epoch over. val_loss: 0.6518995026304464; val_accuracy: 0.7964769108280255 

The current subspace-distance is: 7.292143891390879e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.67; acc: 0.81
Batch: 20; loss: 0.67; acc: 0.81
Batch: 40; loss: 0.83; acc: 0.67
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 0.71; acc: 0.77
Batch: 160; loss: 0.9; acc: 0.67
Batch: 180; loss: 0.67; acc: 0.78
Batch: 200; loss: 0.6; acc: 0.78
Batch: 220; loss: 0.68; acc: 0.73
Batch: 240; loss: 0.72; acc: 0.77
Batch: 260; loss: 0.89; acc: 0.75
Batch: 280; loss: 0.75; acc: 0.8
Batch: 300; loss: 0.71; acc: 0.78
Batch: 320; loss: 0.79; acc: 0.77
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.61; acc: 0.81
Batch: 380; loss: 0.89; acc: 0.78
Batch: 400; loss: 0.77; acc: 0.78
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.88; acc: 0.69
Batch: 480; loss: 0.59; acc: 0.83
Batch: 500; loss: 0.54; acc: 0.8
Batch: 520; loss: 0.64; acc: 0.78
Batch: 540; loss: 0.69; acc: 0.75
Batch: 560; loss: 0.88; acc: 0.75
Batch: 580; loss: 0.68; acc: 0.73
Batch: 600; loss: 0.54; acc: 0.8
Batch: 620; loss: 1.06; acc: 0.69
Batch: 640; loss: 0.79; acc: 0.77
Batch: 660; loss: 0.86; acc: 0.75
Batch: 680; loss: 0.5; acc: 0.81
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.74; acc: 0.72
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.57; acc: 0.81
Batch: 780; loss: 0.55; acc: 0.75
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.0112362108193338e-05
6.793381544412114e-06
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 0.81; acc: 0.75
Batch: 40; loss: 0.44; acc: 0.84
Batch: 60; loss: 0.87; acc: 0.81
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 0.86; acc: 0.67
Batch: 140; loss: 0.37; acc: 0.86
Val Epoch over. val_loss: 0.648817911554294; val_accuracy: 0.798765923566879 

The current subspace-distance is: 6.793381544412114e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.79; acc: 0.77
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.75; acc: 0.75
Batch: 60; loss: 0.62; acc: 0.78
Batch: 80; loss: 0.89; acc: 0.73
Batch: 100; loss: 0.84; acc: 0.73
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.62; acc: 0.72
Batch: 160; loss: 1.03; acc: 0.64
Batch: 180; loss: 0.84; acc: 0.73
Batch: 200; loss: 0.68; acc: 0.83
Batch: 220; loss: 0.71; acc: 0.83
Batch: 240; loss: 0.61; acc: 0.83
Batch: 260; loss: 0.98; acc: 0.66
Batch: 280; loss: 0.57; acc: 0.73
Batch: 300; loss: 0.89; acc: 0.7
Batch: 320; loss: 0.6; acc: 0.77
Batch: 340; loss: 0.73; acc: 0.8
Batch: 360; loss: 0.57; acc: 0.78
Batch: 380; loss: 0.89; acc: 0.69
Batch: 400; loss: 0.84; acc: 0.73
Batch: 420; loss: 0.97; acc: 0.7
Batch: 440; loss: 0.58; acc: 0.83
Batch: 460; loss: 0.81; acc: 0.75
Batch: 480; loss: 0.62; acc: 0.8
Batch: 500; loss: 0.63; acc: 0.83
Batch: 520; loss: 0.51; acc: 0.81
Batch: 540; loss: 0.54; acc: 0.89
Batch: 560; loss: 0.66; acc: 0.8
Batch: 580; loss: 0.65; acc: 0.88
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.62; acc: 0.75
Batch: 640; loss: 0.95; acc: 0.75
Batch: 660; loss: 0.65; acc: 0.77
Batch: 680; loss: 0.68; acc: 0.8
Batch: 700; loss: 0.63; acc: 0.8
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 1.05; acc: 0.69
Batch: 760; loss: 0.6; acc: 0.81
Batch: 780; loss: 0.52; acc: 0.86
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.1504070900846273e-05
6.71203997626435e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.82; acc: 0.73
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.84; acc: 0.83
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 0.83; acc: 0.69
Batch: 140; loss: 0.38; acc: 0.84
Val Epoch over. val_loss: 0.6557441807476578; val_accuracy: 0.7967754777070064 

The current subspace-distance is: 6.71203997626435e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.87; acc: 0.67
Batch: 40; loss: 0.69; acc: 0.8
Batch: 60; loss: 0.57; acc: 0.78
Batch: 80; loss: 0.71; acc: 0.81
Batch: 100; loss: 0.73; acc: 0.78
Batch: 120; loss: 0.76; acc: 0.81
Batch: 140; loss: 0.55; acc: 0.81
Batch: 160; loss: 0.95; acc: 0.69
Batch: 180; loss: 0.6; acc: 0.81
Batch: 200; loss: 0.64; acc: 0.84
Batch: 220; loss: 0.92; acc: 0.7
Batch: 240; loss: 0.77; acc: 0.8
Batch: 260; loss: 0.66; acc: 0.8
Batch: 280; loss: 0.75; acc: 0.72
Batch: 300; loss: 0.52; acc: 0.8
Batch: 320; loss: 0.79; acc: 0.72
Batch: 340; loss: 0.69; acc: 0.75
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.79; acc: 0.8
Batch: 400; loss: 0.53; acc: 0.84
Batch: 420; loss: 0.66; acc: 0.77
Batch: 440; loss: 0.68; acc: 0.78
Batch: 460; loss: 0.92; acc: 0.72
Batch: 480; loss: 0.84; acc: 0.78
Batch: 500; loss: 0.83; acc: 0.73
Batch: 520; loss: 0.72; acc: 0.75
Batch: 540; loss: 0.72; acc: 0.73
Batch: 560; loss: 0.75; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.62; acc: 0.8
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.7; acc: 0.75
Batch: 680; loss: 0.7; acc: 0.78
Batch: 700; loss: 0.51; acc: 0.75
Batch: 720; loss: 0.69; acc: 0.78
Batch: 740; loss: 0.72; acc: 0.73
Batch: 760; loss: 0.55; acc: 0.8
Batch: 780; loss: 0.64; acc: 0.78
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

1.8860628188122064e-05
7.118424946384039e-06
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.82; acc: 0.7
Batch: 140; loss: 0.36; acc: 0.88
Val Epoch over. val_loss: 0.654829137454367; val_accuracy: 0.7946855095541401 

The current subspace-distance is: 7.118424946384039e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.91; acc: 0.73
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 0.87; acc: 0.73
Batch: 100; loss: 0.8; acc: 0.8
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.92; acc: 0.77
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.57; acc: 0.81
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.65; acc: 0.83
Batch: 240; loss: 0.7; acc: 0.8
Batch: 260; loss: 0.67; acc: 0.78
Batch: 280; loss: 0.58; acc: 0.81
Batch: 300; loss: 0.48; acc: 0.89
Batch: 320; loss: 0.59; acc: 0.84
Batch: 340; loss: 0.7; acc: 0.73
Batch: 360; loss: 0.98; acc: 0.67
Batch: 380; loss: 0.67; acc: 0.83
Batch: 400; loss: 0.5; acc: 0.8
Batch: 420; loss: 0.77; acc: 0.73
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.53; acc: 0.84
Batch: 480; loss: 0.72; acc: 0.75
Batch: 500; loss: 0.65; acc: 0.77
Batch: 520; loss: 0.52; acc: 0.89
Batch: 540; loss: 0.68; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.8
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.67; acc: 0.77
Batch: 620; loss: 0.74; acc: 0.78
Batch: 640; loss: 0.77; acc: 0.77
Batch: 660; loss: 0.71; acc: 0.75
Batch: 680; loss: 0.62; acc: 0.84
Batch: 700; loss: 0.75; acc: 0.78
Batch: 720; loss: 0.84; acc: 0.75
Batch: 740; loss: 0.79; acc: 0.73
Batch: 760; loss: 0.52; acc: 0.83
Batch: 780; loss: 0.65; acc: 0.78
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.0562343706842512e-05
6.275183295656461e-06
Batch: 0; loss: 0.68; acc: 0.77
Batch: 20; loss: 0.77; acc: 0.77
Batch: 40; loss: 0.47; acc: 0.81
Batch: 60; loss: 0.89; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.63; acc: 0.81
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 0.35; acc: 0.84
Val Epoch over. val_loss: 0.6443342068202936; val_accuracy: 0.799562101910828 

The current subspace-distance is: 6.275183295656461e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.7; acc: 0.8
Batch: 20; loss: 0.77; acc: 0.7
Batch: 40; loss: 0.84; acc: 0.73
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.59; acc: 0.78
Batch: 100; loss: 0.64; acc: 0.81
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.93; acc: 0.69
Batch: 160; loss: 1.03; acc: 0.77
Batch: 180; loss: 0.72; acc: 0.83
Batch: 200; loss: 0.6; acc: 0.83
Batch: 220; loss: 0.65; acc: 0.73
Batch: 240; loss: 0.71; acc: 0.72
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.62; acc: 0.78
Batch: 300; loss: 0.66; acc: 0.73
Batch: 320; loss: 0.93; acc: 0.75
Batch: 340; loss: 0.62; acc: 0.75
Batch: 360; loss: 0.77; acc: 0.8
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 1.04; acc: 0.64
Batch: 420; loss: 0.83; acc: 0.75
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.88; acc: 0.83
Batch: 480; loss: 0.79; acc: 0.77
Batch: 500; loss: 0.71; acc: 0.78
Batch: 520; loss: 0.55; acc: 0.81
Batch: 540; loss: 1.0; acc: 0.7
Batch: 560; loss: 0.57; acc: 0.78
Batch: 580; loss: 0.66; acc: 0.8
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.66; acc: 0.81
Batch: 640; loss: 0.71; acc: 0.73
Batch: 660; loss: 0.81; acc: 0.81
Batch: 680; loss: 0.71; acc: 0.78
Batch: 700; loss: 0.64; acc: 0.72
Batch: 720; loss: 1.08; acc: 0.75
Batch: 740; loss: 0.52; acc: 0.8
Batch: 760; loss: 0.5; acc: 0.81
Batch: 780; loss: 0.79; acc: 0.73
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

1.983668698812835e-05
7.172421192080947e-06
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.83; acc: 0.78
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.85; acc: 0.67
Batch: 140; loss: 0.35; acc: 0.88
Val Epoch over. val_loss: 0.6446984563094036; val_accuracy: 0.8001592356687898 

The current subspace-distance is: 7.172421192080947e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.81
Batch: 20; loss: 0.75; acc: 0.75
Batch: 40; loss: 0.7; acc: 0.77
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.61; acc: 0.83
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.71; acc: 0.78
Batch: 160; loss: 0.87; acc: 0.73
Batch: 180; loss: 0.69; acc: 0.77
Batch: 200; loss: 0.8; acc: 0.77
Batch: 220; loss: 0.63; acc: 0.83
Batch: 240; loss: 0.71; acc: 0.77
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 1.01; acc: 0.7
Batch: 300; loss: 0.7; acc: 0.8
Batch: 320; loss: 0.79; acc: 0.73
Batch: 340; loss: 0.72; acc: 0.81
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 0.74; acc: 0.72
Batch: 400; loss: 0.62; acc: 0.8
Batch: 420; loss: 0.96; acc: 0.77
Batch: 440; loss: 0.77; acc: 0.77
Batch: 460; loss: 0.66; acc: 0.73
Batch: 480; loss: 0.83; acc: 0.73
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.96; acc: 0.7
Batch: 540; loss: 0.53; acc: 0.81
Batch: 560; loss: 0.68; acc: 0.81
Batch: 580; loss: 0.62; acc: 0.88
Batch: 600; loss: 0.66; acc: 0.77
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.54; acc: 0.83
Batch: 660; loss: 0.83; acc: 0.7
Batch: 680; loss: 0.73; acc: 0.78
Batch: 700; loss: 0.85; acc: 0.75
Batch: 720; loss: 0.72; acc: 0.81
Batch: 740; loss: 0.5; acc: 0.89
Batch: 760; loss: 0.83; acc: 0.69
Batch: 780; loss: 0.84; acc: 0.72
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

1.948887438629754e-05
7.266461580002215e-06
Batch: 0; loss: 0.77; acc: 0.75
Batch: 20; loss: 0.82; acc: 0.73
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.81; acc: 0.81
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.72; acc: 0.8
Batch: 120; loss: 0.79; acc: 0.7
Batch: 140; loss: 0.36; acc: 0.89
Val Epoch over. val_loss: 0.6760049968198606; val_accuracy: 0.7895103503184714 

The current subspace-distance is: 7.266461580002215e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.88; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.84; acc: 0.75
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.64; acc: 0.78
Batch: 160; loss: 0.83; acc: 0.81
Batch: 180; loss: 0.77; acc: 0.77
Batch: 200; loss: 0.71; acc: 0.73
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.81; acc: 0.73
Batch: 260; loss: 0.63; acc: 0.75
Batch: 280; loss: 0.8; acc: 0.75
Batch: 300; loss: 0.85; acc: 0.77
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.93; acc: 0.8
Batch: 380; loss: 0.59; acc: 0.8
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.63; acc: 0.83
Batch: 440; loss: 0.95; acc: 0.72
Batch: 460; loss: 0.65; acc: 0.78
Batch: 480; loss: 0.63; acc: 0.77
Batch: 500; loss: 0.49; acc: 0.81
Batch: 520; loss: 0.55; acc: 0.83
Batch: 540; loss: 0.61; acc: 0.8
Batch: 560; loss: 0.82; acc: 0.73
Batch: 580; loss: 0.59; acc: 0.81
Batch: 600; loss: 0.64; acc: 0.77
Batch: 620; loss: 0.77; acc: 0.73
Batch: 640; loss: 0.79; acc: 0.75
Batch: 660; loss: 0.49; acc: 0.83
Batch: 680; loss: 0.86; acc: 0.78
Batch: 700; loss: 0.62; acc: 0.77
Batch: 720; loss: 0.72; acc: 0.78
Batch: 740; loss: 0.84; acc: 0.75
Batch: 760; loss: 0.8; acc: 0.72
Batch: 780; loss: 0.59; acc: 0.77
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.108502849296201e-05
6.787149231968215e-06
Batch: 0; loss: 0.79; acc: 0.73
Batch: 20; loss: 0.84; acc: 0.72
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.85; acc: 0.78
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.67; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.69
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6710230588533317; val_accuracy: 0.7881170382165605 

The current subspace-distance is: 6.787149231968215e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.83; acc: 0.77
Batch: 40; loss: 0.74; acc: 0.72
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.84; acc: 0.78
Batch: 160; loss: 0.79; acc: 0.75
Batch: 180; loss: 0.71; acc: 0.78
Batch: 200; loss: 0.82; acc: 0.72
Batch: 220; loss: 0.61; acc: 0.77
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.57; acc: 0.8
Batch: 280; loss: 0.71; acc: 0.73
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.73; acc: 0.81
Batch: 360; loss: 0.77; acc: 0.78
Batch: 380; loss: 0.65; acc: 0.75
Batch: 400; loss: 0.75; acc: 0.72
Batch: 420; loss: 0.38; acc: 0.83
Batch: 440; loss: 0.79; acc: 0.77
Batch: 460; loss: 0.79; acc: 0.81
Batch: 480; loss: 0.64; acc: 0.78
Batch: 500; loss: 0.7; acc: 0.8
Batch: 520; loss: 0.61; acc: 0.75
Batch: 540; loss: 0.42; acc: 0.83
Batch: 560; loss: 0.83; acc: 0.73
Batch: 580; loss: 0.85; acc: 0.77
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.96; acc: 0.75
Batch: 640; loss: 0.63; acc: 0.75
Batch: 660; loss: 0.86; acc: 0.66
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.62; acc: 0.75
Batch: 740; loss: 0.66; acc: 0.83
Batch: 760; loss: 0.92; acc: 0.72
Batch: 780; loss: 0.68; acc: 0.8
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.044675056822598e-05
6.3964312175812665e-06
Batch: 0; loss: 0.8; acc: 0.72
Batch: 20; loss: 0.83; acc: 0.72
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.87; acc: 0.75
Batch: 80; loss: 0.43; acc: 0.89
Batch: 100; loss: 0.7; acc: 0.81
Batch: 120; loss: 0.81; acc: 0.69
Batch: 140; loss: 0.37; acc: 0.89
Val Epoch over. val_loss: 0.6708037638740175; val_accuracy: 0.7914012738853503 

The current subspace-distance is: 6.3964312175812665e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.77
Batch: 20; loss: 0.98; acc: 0.73
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.75; acc: 0.69
Batch: 120; loss: 0.94; acc: 0.67
Batch: 140; loss: 0.59; acc: 0.84
Batch: 160; loss: 0.65; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.89
Batch: 200; loss: 0.6; acc: 0.81
Batch: 220; loss: 0.57; acc: 0.83
Batch: 240; loss: 0.47; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.92
Batch: 280; loss: 0.66; acc: 0.77
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.84; acc: 0.75
Batch: 340; loss: 0.63; acc: 0.81
Batch: 360; loss: 0.82; acc: 0.77
Batch: 380; loss: 0.55; acc: 0.8
Batch: 400; loss: 0.7; acc: 0.8
Batch: 420; loss: 0.92; acc: 0.78
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.81; acc: 0.77
Batch: 480; loss: 0.73; acc: 0.81
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.6; acc: 0.78
Batch: 540; loss: 0.94; acc: 0.72
Batch: 560; loss: 0.62; acc: 0.83
Batch: 580; loss: 0.67; acc: 0.81
Batch: 600; loss: 0.55; acc: 0.8
Batch: 620; loss: 0.51; acc: 0.81
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 1.07; acc: 0.73
Batch: 680; loss: 0.57; acc: 0.86
Batch: 700; loss: 0.56; acc: 0.77
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.77; acc: 0.77
Batch: 760; loss: 0.61; acc: 0.78
Batch: 780; loss: 0.56; acc: 0.81
Train Epoch over. train_loss: 0.69; train_accuracy: 0.78 

2.081260936392937e-05
7.46373962101643e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.71; acc: 0.73
Batch: 40; loss: 0.45; acc: 0.84
Batch: 60; loss: 0.86; acc: 0.8
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.79; acc: 0.69
Batch: 140; loss: 0.36; acc: 0.88
Val Epoch over. val_loss: 0.6508935145132101; val_accuracy: 0.7932921974522293 

The current subspace-distance is: 7.46373962101643e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.92; acc: 0.7
Batch: 20; loss: 0.81; acc: 0.7
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.77; acc: 0.69
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.42; acc: 0.83
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 0.56; acc: 0.81
Batch: 200; loss: 0.66; acc: 0.75
Batch: 220; loss: 0.57; acc: 0.81
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.62; acc: 0.81
Batch: 280; loss: 0.92; acc: 0.73
Batch: 300; loss: 0.63; acc: 0.8
Batch: 320; loss: 0.51; acc: 0.81
Batch: 340; loss: 0.74; acc: 0.73
Batch: 360; loss: 0.72; acc: 0.81
Batch: 380; loss: 0.47; acc: 0.8
Batch: 400; loss: 0.63; acc: 0.78
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.58; acc: 0.83
Batch: 480; loss: 0.65; acc: 0.8
Batch: 500; loss: 0.93; acc: 0.77
Batch: 520; loss: 0.68; acc: 0.8
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.78; acc: 0.86
Batch: 580; loss: 0.55; acc: 0.81
Batch: 600; loss: 0.85; acc: 0.78
Batch: 620; loss: 0.88; acc: 0.72
Batch: 640; loss: 1.03; acc: 0.7
Batch: 660; loss: 0.88; acc: 0.72
Batch: 680; loss: 0.99; acc: 0.72
Batch: 700; loss: 0.56; acc: 0.81
Batch: 720; loss: 0.77; acc: 0.75
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.74; acc: 0.72
Batch: 780; loss: 0.39; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.9817684005829506e-05
7.68598783906782e-06
Batch: 0; loss: 0.72; acc: 0.75
Batch: 20; loss: 0.78; acc: 0.72
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.84; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.8; acc: 0.72
Batch: 140; loss: 0.35; acc: 0.86
Val Epoch over. val_loss: 0.6443279079950539; val_accuracy: 0.8000597133757962 

The current subspace-distance is: 7.68598783906782e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.86
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.52; acc: 0.78
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.8; acc: 0.77
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.59; acc: 0.86
Batch: 180; loss: 0.94; acc: 0.69
Batch: 200; loss: 0.6; acc: 0.81
Batch: 220; loss: 0.6; acc: 0.81
Batch: 240; loss: 0.47; acc: 0.89
Batch: 260; loss: 0.52; acc: 0.81
Batch: 280; loss: 0.67; acc: 0.77
Batch: 300; loss: 0.64; acc: 0.77
Batch: 320; loss: 0.6; acc: 0.86
Batch: 340; loss: 0.65; acc: 0.81
Batch: 360; loss: 0.93; acc: 0.75
Batch: 380; loss: 0.61; acc: 0.77
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.68; acc: 0.83
Batch: 440; loss: 0.96; acc: 0.66
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.77; acc: 0.81
Batch: 500; loss: 0.78; acc: 0.78
Batch: 520; loss: 0.81; acc: 0.81
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.58; acc: 0.8
Batch: 580; loss: 0.75; acc: 0.72
Batch: 600; loss: 0.59; acc: 0.83
Batch: 620; loss: 0.94; acc: 0.73
Batch: 640; loss: 0.67; acc: 0.77
Batch: 660; loss: 0.79; acc: 0.78
Batch: 680; loss: 0.78; acc: 0.81
Batch: 700; loss: 0.57; acc: 0.83
Batch: 720; loss: 0.79; acc: 0.75
Batch: 740; loss: 0.64; acc: 0.77
Batch: 760; loss: 0.88; acc: 0.72
Batch: 780; loss: 0.46; acc: 0.83
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

2.218753070337698e-05
8.057850209297612e-06
Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.85; acc: 0.8
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.83; acc: 0.7
Batch: 140; loss: 0.36; acc: 0.84
Val Epoch over. val_loss: 0.6364152427691563; val_accuracy: 0.7997611464968153 

The current subspace-distance is: 8.057850209297612e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.83
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.74; acc: 0.78
Batch: 80; loss: 0.87; acc: 0.77
Batch: 100; loss: 0.63; acc: 0.86
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.68; acc: 0.83
Batch: 160; loss: 0.62; acc: 0.75
Batch: 180; loss: 0.64; acc: 0.78
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.54; acc: 0.8
Batch: 240; loss: 0.68; acc: 0.78
Batch: 260; loss: 0.83; acc: 0.72
Batch: 280; loss: 0.83; acc: 0.69
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.74; acc: 0.78
Batch: 340; loss: 0.6; acc: 0.8
Batch: 360; loss: 0.59; acc: 0.83
Batch: 380; loss: 0.63; acc: 0.77
Batch: 400; loss: 0.86; acc: 0.73
Batch: 420; loss: 0.69; acc: 0.78
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.6; acc: 0.78
Batch: 480; loss: 0.65; acc: 0.84
Batch: 500; loss: 0.63; acc: 0.83
Batch: 520; loss: 0.69; acc: 0.8
Batch: 540; loss: 0.63; acc: 0.81
Batch: 560; loss: 0.92; acc: 0.7
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.84; acc: 0.7
Batch: 620; loss: 1.08; acc: 0.7
Batch: 640; loss: 0.74; acc: 0.77
Batch: 660; loss: 0.76; acc: 0.73
Batch: 680; loss: 0.48; acc: 0.89
Batch: 700; loss: 0.81; acc: 0.69
Batch: 720; loss: 0.45; acc: 0.86
Batch: 740; loss: 0.71; acc: 0.8
Batch: 760; loss: 0.67; acc: 0.78
Batch: 780; loss: 0.6; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

2.1193631255300716e-05
6.71241969030234e-06
Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.79; acc: 0.75
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.86; acc: 0.81
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.84
Val Epoch over. val_loss: 0.6347149307750592; val_accuracy: 0.802547770700637 

The current subspace-distance is: 6.71241969030234e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.88; acc: 0.64
Batch: 20; loss: 0.84; acc: 0.75
Batch: 40; loss: 0.63; acc: 0.78
Batch: 60; loss: 0.63; acc: 0.78
Batch: 80; loss: 0.67; acc: 0.8
Batch: 100; loss: 0.6; acc: 0.73
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.81; acc: 0.72
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.58; acc: 0.81
Batch: 200; loss: 0.81; acc: 0.8
Batch: 220; loss: 0.64; acc: 0.83
Batch: 240; loss: 0.88; acc: 0.77
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.82; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.77
Batch: 320; loss: 0.69; acc: 0.72
Batch: 340; loss: 0.59; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.68; acc: 0.75
Batch: 400; loss: 0.67; acc: 0.84
Batch: 420; loss: 0.68; acc: 0.8
Batch: 440; loss: 0.76; acc: 0.73
Batch: 460; loss: 0.7; acc: 0.77
Batch: 480; loss: 0.84; acc: 0.7
Batch: 500; loss: 0.79; acc: 0.77
Batch: 520; loss: 0.88; acc: 0.78
Batch: 540; loss: 0.81; acc: 0.77
Batch: 560; loss: 0.59; acc: 0.75
Batch: 580; loss: 0.92; acc: 0.66
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.92; acc: 0.78
Batch: 640; loss: 0.7; acc: 0.75
Batch: 660; loss: 0.69; acc: 0.78
Batch: 680; loss: 0.57; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.77
Batch: 720; loss: 0.73; acc: 0.73
Batch: 740; loss: 0.86; acc: 0.78
Batch: 760; loss: 0.48; acc: 0.81
Batch: 780; loss: 0.77; acc: 0.7
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

1.954325125552714e-05
7.020186330919387e-06
Batch: 0; loss: 0.7; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.75
Batch: 40; loss: 0.42; acc: 0.83
Batch: 60; loss: 0.86; acc: 0.8
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6338657879146041; val_accuracy: 0.8050358280254777 

The current subspace-distance is: 7.020186330919387e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.6; acc: 0.8
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.6; acc: 0.81
Batch: 100; loss: 0.52; acc: 0.81
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.7; acc: 0.81
Batch: 160; loss: 0.76; acc: 0.83
Batch: 180; loss: 0.73; acc: 0.78
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.87; acc: 0.72
Batch: 240; loss: 0.78; acc: 0.78
Batch: 260; loss: 0.74; acc: 0.77
Batch: 280; loss: 0.73; acc: 0.8
Batch: 300; loss: 0.86; acc: 0.77
Batch: 320; loss: 0.67; acc: 0.75
Batch: 340; loss: 0.98; acc: 0.69
Batch: 360; loss: 0.68; acc: 0.8
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.74; acc: 0.8
Batch: 420; loss: 0.37; acc: 0.94
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.61; acc: 0.8
Batch: 480; loss: 0.69; acc: 0.84
Batch: 500; loss: 0.74; acc: 0.77
Batch: 520; loss: 0.79; acc: 0.7
Batch: 540; loss: 0.65; acc: 0.8
Batch: 560; loss: 0.58; acc: 0.83
Batch: 580; loss: 0.8; acc: 0.73
Batch: 600; loss: 1.03; acc: 0.69
Batch: 620; loss: 0.84; acc: 0.75
Batch: 640; loss: 0.74; acc: 0.78
Batch: 660; loss: 0.74; acc: 0.78
Batch: 680; loss: 0.55; acc: 0.88
Batch: 700; loss: 0.68; acc: 0.78
Batch: 720; loss: 0.8; acc: 0.81
Batch: 740; loss: 0.74; acc: 0.75
Batch: 760; loss: 0.78; acc: 0.77
Batch: 780; loss: 0.62; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.9449973478913307e-05
6.887209565320518e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.73
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.81; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.81
Batch: 120; loss: 0.76; acc: 0.72
Batch: 140; loss: 0.35; acc: 0.89
Val Epoch over. val_loss: 0.6373325111759696; val_accuracy: 0.7999601910828026 

The current subspace-distance is: 6.887209565320518e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.64; acc: 0.78
Batch: 60; loss: 0.7; acc: 0.83
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.79; acc: 0.77
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.61; acc: 0.81
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.67; acc: 0.8
Batch: 280; loss: 0.83; acc: 0.77
Batch: 300; loss: 0.63; acc: 0.83
Batch: 320; loss: 0.69; acc: 0.75
Batch: 340; loss: 0.81; acc: 0.75
Batch: 360; loss: 0.67; acc: 0.81
Batch: 380; loss: 0.54; acc: 0.78
Batch: 400; loss: 0.73; acc: 0.77
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.81; acc: 0.75
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.57; acc: 0.8
Batch: 500; loss: 0.8; acc: 0.75
Batch: 520; loss: 0.62; acc: 0.81
Batch: 540; loss: 0.79; acc: 0.78
Batch: 560; loss: 0.71; acc: 0.7
Batch: 580; loss: 0.8; acc: 0.69
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.85; acc: 0.78
Batch: 640; loss: 1.02; acc: 0.73
Batch: 660; loss: 0.71; acc: 0.77
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.59; acc: 0.8
Batch: 720; loss: 0.47; acc: 0.8
Batch: 740; loss: 0.96; acc: 0.75
Batch: 760; loss: 0.76; acc: 0.75
Batch: 780; loss: 0.52; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.1567544536083005e-05
7.821038707334083e-06
Batch: 0; loss: 0.71; acc: 0.73
Batch: 20; loss: 0.74; acc: 0.73
Batch: 40; loss: 0.44; acc: 0.84
Batch: 60; loss: 0.87; acc: 0.8
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6381603324679053; val_accuracy: 0.802547770700637 

The current subspace-distance is: 7.821038707334083e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.81
Batch: 20; loss: 0.66; acc: 0.75
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.82; acc: 0.72
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.74; acc: 0.77
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.66; acc: 0.78
Batch: 220; loss: 0.54; acc: 0.88
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.77; acc: 0.7
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.64; acc: 0.81
Batch: 320; loss: 0.74; acc: 0.72
Batch: 340; loss: 0.48; acc: 0.83
Batch: 360; loss: 0.87; acc: 0.75
Batch: 380; loss: 0.54; acc: 0.86
Batch: 400; loss: 0.64; acc: 0.81
Batch: 420; loss: 1.01; acc: 0.67
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.88; acc: 0.7
Batch: 480; loss: 0.68; acc: 0.73
Batch: 500; loss: 0.6; acc: 0.83
Batch: 520; loss: 0.61; acc: 0.81
Batch: 540; loss: 0.68; acc: 0.75
Batch: 560; loss: 0.62; acc: 0.84
Batch: 580; loss: 0.9; acc: 0.7
Batch: 600; loss: 0.83; acc: 0.7
Batch: 620; loss: 0.49; acc: 0.92
Batch: 640; loss: 0.77; acc: 0.8
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.71; acc: 0.8
Batch: 700; loss: 0.7; acc: 0.78
Batch: 720; loss: 0.72; acc: 0.8
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.67; acc: 0.77
Batch: 780; loss: 0.69; acc: 0.84
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

2.001559732889291e-05
7.12133942215587e-06
Batch: 0; loss: 0.7; acc: 0.75
Batch: 20; loss: 0.76; acc: 0.75
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.84; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6329423438781386; val_accuracy: 0.8016520700636943 

The current subspace-distance is: 7.12133942215587e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.77; acc: 0.73
Batch: 40; loss: 0.58; acc: 0.8
Batch: 60; loss: 0.48; acc: 0.86
Batch: 80; loss: 0.65; acc: 0.72
Batch: 100; loss: 0.73; acc: 0.75
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.73; acc: 0.69
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.69; acc: 0.81
Batch: 220; loss: 0.67; acc: 0.81
Batch: 240; loss: 0.68; acc: 0.77
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.63; acc: 0.78
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.8; acc: 0.73
Batch: 340; loss: 0.73; acc: 0.75
Batch: 360; loss: 0.54; acc: 0.75
Batch: 380; loss: 0.66; acc: 0.73
Batch: 400; loss: 0.89; acc: 0.72
Batch: 420; loss: 0.7; acc: 0.86
Batch: 440; loss: 0.72; acc: 0.77
Batch: 460; loss: 0.66; acc: 0.75
Batch: 480; loss: 0.83; acc: 0.75
Batch: 500; loss: 0.45; acc: 0.92
Batch: 520; loss: 0.97; acc: 0.7
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.7; acc: 0.75
Batch: 600; loss: 1.09; acc: 0.69
Batch: 620; loss: 0.72; acc: 0.77
Batch: 640; loss: 0.63; acc: 0.83
Batch: 660; loss: 0.54; acc: 0.81
Batch: 680; loss: 1.03; acc: 0.66
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.77
Batch: 740; loss: 0.66; acc: 0.77
Batch: 760; loss: 0.93; acc: 0.69
Batch: 780; loss: 0.65; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

2.109704291797243e-05
6.577777185157174e-06
Batch: 0; loss: 0.71; acc: 0.75
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.84
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.81; acc: 0.7
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.63286327964561; val_accuracy: 0.8048367834394905 

The current subspace-distance is: 6.577777185157174e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 0.94; acc: 0.7
Batch: 40; loss: 0.87; acc: 0.73
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.65; acc: 0.83
Batch: 200; loss: 0.74; acc: 0.8
Batch: 220; loss: 0.91; acc: 0.72
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.61; acc: 0.84
Batch: 280; loss: 0.81; acc: 0.73
Batch: 300; loss: 0.83; acc: 0.77
Batch: 320; loss: 0.76; acc: 0.75
Batch: 340; loss: 0.65; acc: 0.83
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.49; acc: 0.8
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.58; acc: 0.81
Batch: 480; loss: 0.77; acc: 0.75
Batch: 500; loss: 0.8; acc: 0.78
Batch: 520; loss: 0.7; acc: 0.77
Batch: 540; loss: 0.57; acc: 0.81
Batch: 560; loss: 0.67; acc: 0.81
Batch: 580; loss: 0.59; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.92
Batch: 620; loss: 0.67; acc: 0.81
Batch: 640; loss: 0.48; acc: 0.81
Batch: 660; loss: 0.6; acc: 0.83
Batch: 680; loss: 0.64; acc: 0.83
Batch: 700; loss: 0.61; acc: 0.8
Batch: 720; loss: 0.77; acc: 0.73
Batch: 740; loss: 0.78; acc: 0.77
Batch: 760; loss: 0.82; acc: 0.75
Batch: 780; loss: 0.63; acc: 0.77
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

1.88124249689281e-05
7.503635970351752e-06
Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.82; acc: 0.73
Batch: 40; loss: 0.44; acc: 0.81
Batch: 60; loss: 0.87; acc: 0.81
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.85; acc: 0.7
Batch: 140; loss: 0.35; acc: 0.84
Val Epoch over. val_loss: 0.641438571415889; val_accuracy: 0.8015525477707006 

The current subspace-distance is: 7.503635970351752e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.85; acc: 0.77
Batch: 20; loss: 0.77; acc: 0.77
Batch: 40; loss: 0.6; acc: 0.84
Batch: 60; loss: 0.82; acc: 0.8
Batch: 80; loss: 0.6; acc: 0.84
Batch: 100; loss: 0.72; acc: 0.73
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.96; acc: 0.72
Batch: 160; loss: 0.73; acc: 0.75
Batch: 180; loss: 0.67; acc: 0.83
Batch: 200; loss: 0.67; acc: 0.78
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.6; acc: 0.8
Batch: 280; loss: 0.55; acc: 0.89
Batch: 300; loss: 0.89; acc: 0.7
Batch: 320; loss: 0.67; acc: 0.75
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.68; acc: 0.81
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.73; acc: 0.75
Batch: 420; loss: 0.62; acc: 0.78
Batch: 440; loss: 0.85; acc: 0.73
Batch: 460; loss: 0.56; acc: 0.77
Batch: 480; loss: 0.83; acc: 0.72
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.88; acc: 0.78
Batch: 540; loss: 0.76; acc: 0.77
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.62; acc: 0.88
Batch: 600; loss: 0.6; acc: 0.78
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.69; acc: 0.75
Batch: 660; loss: 0.78; acc: 0.7
Batch: 680; loss: 0.74; acc: 0.73
Batch: 700; loss: 0.7; acc: 0.81
Batch: 720; loss: 0.65; acc: 0.77
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.64; acc: 0.78
Batch: 780; loss: 0.61; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.78 

2.1125737475813366e-05
6.663380190730095e-06
Batch: 0; loss: 0.7; acc: 0.77
Batch: 20; loss: 0.77; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.84; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.81
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6305391820752697; val_accuracy: 0.8059315286624203 

The current subspace-distance is: 6.663380190730095e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.84; acc: 0.78
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.83; acc: 0.75
Batch: 100; loss: 0.56; acc: 0.81
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.78; acc: 0.78
Batch: 160; loss: 0.47; acc: 0.88
Batch: 180; loss: 0.54; acc: 0.81
Batch: 200; loss: 0.88; acc: 0.73
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.72; acc: 0.78
Batch: 260; loss: 0.71; acc: 0.72
Batch: 280; loss: 0.68; acc: 0.8
Batch: 300; loss: 0.99; acc: 0.67
Batch: 320; loss: 1.05; acc: 0.59
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 0.75; acc: 0.75
Batch: 400; loss: 0.81; acc: 0.77
Batch: 420; loss: 0.51; acc: 0.84
Batch: 440; loss: 0.67; acc: 0.83
Batch: 460; loss: 0.59; acc: 0.8
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.61; acc: 0.84
Batch: 520; loss: 0.53; acc: 0.84
Batch: 540; loss: 0.6; acc: 0.84
Batch: 560; loss: 0.81; acc: 0.7
Batch: 580; loss: 0.64; acc: 0.84
Batch: 600; loss: 0.57; acc: 0.78
Batch: 620; loss: 1.0; acc: 0.75
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.99; acc: 0.7
Batch: 680; loss: 0.54; acc: 0.8
Batch: 700; loss: 0.73; acc: 0.77
Batch: 720; loss: 0.73; acc: 0.73
Batch: 740; loss: 0.7; acc: 0.77
Batch: 760; loss: 0.74; acc: 0.78
Batch: 780; loss: 0.76; acc: 0.73
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.2189129595062695e-05
6.895264050399419e-06
Batch: 0; loss: 0.71; acc: 0.72
Batch: 20; loss: 0.78; acc: 0.72
Batch: 40; loss: 0.42; acc: 0.83
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.8; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6309973646880714; val_accuracy: 0.8037420382165605 

The current subspace-distance is: 6.895264050399419e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.87; acc: 0.73
Batch: 40; loss: 0.95; acc: 0.77
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.81
Batch: 100; loss: 0.62; acc: 0.78
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.68; acc: 0.8
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.54; acc: 0.83
Batch: 200; loss: 0.57; acc: 0.83
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.59; acc: 0.8
Batch: 260; loss: 0.66; acc: 0.78
Batch: 280; loss: 0.68; acc: 0.77
Batch: 300; loss: 0.71; acc: 0.78
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.67; acc: 0.78
Batch: 360; loss: 0.57; acc: 0.8
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.91; acc: 0.73
Batch: 420; loss: 0.5; acc: 0.86
Batch: 440; loss: 0.75; acc: 0.67
Batch: 460; loss: 0.54; acc: 0.83
Batch: 480; loss: 0.73; acc: 0.78
Batch: 500; loss: 0.78; acc: 0.73
Batch: 520; loss: 0.84; acc: 0.75
Batch: 540; loss: 0.63; acc: 0.77
Batch: 560; loss: 0.71; acc: 0.77
Batch: 580; loss: 0.64; acc: 0.72
Batch: 600; loss: 0.98; acc: 0.66
Batch: 620; loss: 0.64; acc: 0.8
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.56; acc: 0.8
Batch: 680; loss: 0.69; acc: 0.78
Batch: 700; loss: 0.79; acc: 0.78
Batch: 720; loss: 0.7; acc: 0.78
Batch: 740; loss: 0.66; acc: 0.8
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.73; acc: 0.73
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.9935465388698503e-05
6.662030955340015e-06
Batch: 0; loss: 0.71; acc: 0.73
Batch: 20; loss: 0.75; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.82; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6291151542192811; val_accuracy: 0.8049363057324841 

The current subspace-distance is: 6.662030955340015e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.68; acc: 0.73
Batch: 20; loss: 0.73; acc: 0.77
Batch: 40; loss: 0.72; acc: 0.73
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.99; acc: 0.72
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.86; acc: 0.78
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.61; acc: 0.8
Batch: 200; loss: 0.58; acc: 0.8
Batch: 220; loss: 0.58; acc: 0.78
Batch: 240; loss: 0.65; acc: 0.8
Batch: 260; loss: 0.66; acc: 0.75
Batch: 280; loss: 0.58; acc: 0.8
Batch: 300; loss: 0.85; acc: 0.73
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.42; acc: 0.83
Batch: 360; loss: 0.49; acc: 0.83
Batch: 380; loss: 0.65; acc: 0.81
Batch: 400; loss: 0.7; acc: 0.73
Batch: 420; loss: 0.85; acc: 0.69
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.85; acc: 0.77
Batch: 480; loss: 0.6; acc: 0.8
Batch: 500; loss: 0.49; acc: 0.81
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.87; acc: 0.8
Batch: 560; loss: 1.02; acc: 0.7
Batch: 580; loss: 0.6; acc: 0.84
Batch: 600; loss: 0.69; acc: 0.81
Batch: 620; loss: 0.64; acc: 0.84
Batch: 640; loss: 0.75; acc: 0.8
Batch: 660; loss: 0.68; acc: 0.75
Batch: 680; loss: 0.62; acc: 0.81
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.7; acc: 0.8
Batch: 740; loss: 0.77; acc: 0.8
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.71; acc: 0.75
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.0785428205272183e-05
6.635099907725817e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.42; acc: 0.83
Batch: 60; loss: 0.83; acc: 0.8
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.79; acc: 0.72
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6319635705013943; val_accuracy: 0.8026472929936306 

The current subspace-distance is: 6.635099907725817e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.75; acc: 0.78
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.8
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 0.76; acc: 0.73
Batch: 180; loss: 0.57; acc: 0.83
Batch: 200; loss: 0.67; acc: 0.8
Batch: 220; loss: 0.84; acc: 0.77
Batch: 240; loss: 0.74; acc: 0.78
Batch: 260; loss: 0.53; acc: 0.83
Batch: 280; loss: 0.61; acc: 0.77
Batch: 300; loss: 0.49; acc: 0.88
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.77; acc: 0.72
Batch: 360; loss: 0.61; acc: 0.83
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.67; acc: 0.77
Batch: 420; loss: 0.67; acc: 0.8
Batch: 440; loss: 0.52; acc: 0.88
Batch: 460; loss: 0.77; acc: 0.75
Batch: 480; loss: 0.68; acc: 0.75
Batch: 500; loss: 0.57; acc: 0.81
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.67; acc: 0.78
Batch: 560; loss: 0.65; acc: 0.75
Batch: 580; loss: 0.63; acc: 0.89
Batch: 600; loss: 0.78; acc: 0.77
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.65; acc: 0.81
Batch: 680; loss: 0.55; acc: 0.81
Batch: 700; loss: 1.01; acc: 0.73
Batch: 720; loss: 0.59; acc: 0.78
Batch: 740; loss: 0.63; acc: 0.78
Batch: 760; loss: 0.7; acc: 0.78
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.107184991473332e-05
7.126958280423423e-06
Batch: 0; loss: 0.72; acc: 0.75
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.81; acc: 0.8
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.8; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6315709948539734; val_accuracy: 0.805234872611465 

The current subspace-distance is: 7.126958280423423e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.75
Batch: 20; loss: 0.71; acc: 0.78
Batch: 40; loss: 0.76; acc: 0.81
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.88; acc: 0.8
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.95; acc: 0.72
Batch: 160; loss: 0.52; acc: 0.89
Batch: 180; loss: 0.71; acc: 0.73
Batch: 200; loss: 0.74; acc: 0.84
Batch: 220; loss: 0.62; acc: 0.77
Batch: 240; loss: 0.48; acc: 0.81
Batch: 260; loss: 0.88; acc: 0.73
Batch: 280; loss: 0.56; acc: 0.8
Batch: 300; loss: 0.87; acc: 0.77
Batch: 320; loss: 0.85; acc: 0.72
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.86
Batch: 380; loss: 0.81; acc: 0.73
Batch: 400; loss: 0.69; acc: 0.78
Batch: 420; loss: 0.86; acc: 0.73
Batch: 440; loss: 0.6; acc: 0.83
Batch: 460; loss: 0.62; acc: 0.77
Batch: 480; loss: 0.62; acc: 0.78
Batch: 500; loss: 0.85; acc: 0.7
Batch: 520; loss: 0.67; acc: 0.83
Batch: 540; loss: 0.79; acc: 0.78
Batch: 560; loss: 0.5; acc: 0.89
Batch: 580; loss: 0.74; acc: 0.75
Batch: 600; loss: 0.72; acc: 0.72
Batch: 620; loss: 0.69; acc: 0.73
Batch: 640; loss: 0.63; acc: 0.86
Batch: 660; loss: 0.63; acc: 0.8
Batch: 680; loss: 0.81; acc: 0.8
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.81; acc: 0.72
Batch: 740; loss: 0.82; acc: 0.72
Batch: 760; loss: 0.72; acc: 0.77
Batch: 780; loss: 0.64; acc: 0.78
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.8350403479416855e-05
7.28106897440739e-06
Batch: 0; loss: 0.71; acc: 0.73
Batch: 20; loss: 0.79; acc: 0.72
Batch: 40; loss: 0.42; acc: 0.83
Batch: 60; loss: 0.83; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.64; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6318730295273909; val_accuracy: 0.803343949044586 

The current subspace-distance is: 7.28106897440739e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.71; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.66; acc: 0.77
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.96; acc: 0.7
Batch: 100; loss: 0.93; acc: 0.77
Batch: 120; loss: 1.01; acc: 0.69
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.65; acc: 0.72
Batch: 180; loss: 0.6; acc: 0.81
Batch: 200; loss: 0.85; acc: 0.73
Batch: 220; loss: 0.86; acc: 0.73
Batch: 240; loss: 0.57; acc: 0.84
Batch: 260; loss: 0.7; acc: 0.83
Batch: 280; loss: 1.03; acc: 0.7
Batch: 300; loss: 1.11; acc: 0.73
Batch: 320; loss: 0.62; acc: 0.8
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.66; acc: 0.83
Batch: 380; loss: 0.52; acc: 0.84
Batch: 400; loss: 0.65; acc: 0.77
Batch: 420; loss: 0.58; acc: 0.77
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.81; acc: 0.73
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.63; acc: 0.8
Batch: 540; loss: 0.62; acc: 0.83
Batch: 560; loss: 0.81; acc: 0.72
Batch: 580; loss: 0.67; acc: 0.83
Batch: 600; loss: 0.71; acc: 0.81
Batch: 620; loss: 0.77; acc: 0.72
Batch: 640; loss: 0.74; acc: 0.8
Batch: 660; loss: 0.91; acc: 0.67
Batch: 680; loss: 0.68; acc: 0.75
Batch: 700; loss: 0.69; acc: 0.81
Batch: 720; loss: 0.8; acc: 0.77
Batch: 740; loss: 0.79; acc: 0.72
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.6; acc: 0.73
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.849261752795428e-05
6.56305746815633e-06
Batch: 0; loss: 0.73; acc: 0.72
Batch: 20; loss: 0.74; acc: 0.73
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.6313367403426747; val_accuracy: 0.8045382165605095 

The current subspace-distance is: 6.56305746815633e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.59; acc: 0.78
Batch: 40; loss: 0.7; acc: 0.75
Batch: 60; loss: 0.82; acc: 0.77
Batch: 80; loss: 0.53; acc: 0.88
Batch: 100; loss: 0.83; acc: 0.81
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.77; acc: 0.73
Batch: 160; loss: 0.83; acc: 0.73
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.98; acc: 0.73
Batch: 240; loss: 0.62; acc: 0.86
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.48; acc: 0.81
Batch: 340; loss: 0.64; acc: 0.72
Batch: 360; loss: 0.71; acc: 0.77
Batch: 380; loss: 0.74; acc: 0.69
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.82; acc: 0.69
Batch: 440; loss: 1.06; acc: 0.69
Batch: 460; loss: 0.69; acc: 0.77
Batch: 480; loss: 0.55; acc: 0.81
Batch: 500; loss: 0.84; acc: 0.77
Batch: 520; loss: 0.69; acc: 0.78
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.84; acc: 0.77
Batch: 600; loss: 0.61; acc: 0.84
Batch: 620; loss: 0.69; acc: 0.78
Batch: 640; loss: 0.81; acc: 0.78
Batch: 660; loss: 0.74; acc: 0.77
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.82; acc: 0.73
Batch: 720; loss: 0.72; acc: 0.8
Batch: 740; loss: 0.67; acc: 0.8
Batch: 760; loss: 0.76; acc: 0.73
Batch: 780; loss: 0.73; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.0019566363771446e-05
6.631752967223292e-06
Batch: 0; loss: 0.73; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.75
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.85; acc: 0.8
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.67; acc: 0.83
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.6365032051778903; val_accuracy: 0.8021496815286624 

The current subspace-distance is: 6.631752967223292e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.57; acc: 0.81
Batch: 40; loss: 0.66; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.72
Batch: 80; loss: 1.0; acc: 0.69
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.65; acc: 0.72
Batch: 160; loss: 1.08; acc: 0.75
Batch: 180; loss: 0.8; acc: 0.78
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.6; acc: 0.8
Batch: 240; loss: 0.93; acc: 0.7
Batch: 260; loss: 0.61; acc: 0.72
Batch: 280; loss: 0.98; acc: 0.77
Batch: 300; loss: 0.55; acc: 0.81
Batch: 320; loss: 0.73; acc: 0.81
Batch: 340; loss: 0.87; acc: 0.72
Batch: 360; loss: 0.84; acc: 0.72
Batch: 380; loss: 0.86; acc: 0.73
Batch: 400; loss: 0.75; acc: 0.78
Batch: 420; loss: 0.77; acc: 0.72
Batch: 440; loss: 0.83; acc: 0.75
Batch: 460; loss: 0.8; acc: 0.73
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.65; acc: 0.77
Batch: 520; loss: 0.49; acc: 0.88
Batch: 540; loss: 0.72; acc: 0.84
Batch: 560; loss: 0.75; acc: 0.8
Batch: 580; loss: 1.12; acc: 0.72
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.79; acc: 0.75
Batch: 660; loss: 0.74; acc: 0.67
Batch: 680; loss: 0.94; acc: 0.7
Batch: 700; loss: 0.71; acc: 0.81
Batch: 720; loss: 0.57; acc: 0.84
Batch: 740; loss: 0.78; acc: 0.77
Batch: 760; loss: 0.67; acc: 0.83
Batch: 780; loss: 0.83; acc: 0.78
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.80534570972668e-05
6.893300451338291e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.73
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.91
Val Epoch over. val_loss: 0.6307308228722044; val_accuracy: 0.8064291401273885 

The current subspace-distance is: 6.893300451338291e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.84; acc: 0.73
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.75
Batch: 80; loss: 0.72; acc: 0.81
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.77; acc: 0.67
Batch: 160; loss: 0.63; acc: 0.8
Batch: 180; loss: 0.74; acc: 0.83
Batch: 200; loss: 0.56; acc: 0.8
Batch: 220; loss: 0.81; acc: 0.72
Batch: 240; loss: 0.63; acc: 0.8
Batch: 260; loss: 0.75; acc: 0.7
Batch: 280; loss: 0.67; acc: 0.8
Batch: 300; loss: 0.65; acc: 0.8
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 1.02; acc: 0.66
Batch: 360; loss: 0.77; acc: 0.75
Batch: 380; loss: 0.52; acc: 0.81
Batch: 400; loss: 0.87; acc: 0.7
Batch: 420; loss: 0.66; acc: 0.83
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.85; acc: 0.75
Batch: 480; loss: 0.58; acc: 0.8
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.71; acc: 0.77
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.66; acc: 0.73
Batch: 580; loss: 0.66; acc: 0.8
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.57; acc: 0.78
Batch: 640; loss: 0.66; acc: 0.81
Batch: 660; loss: 0.6; acc: 0.78
Batch: 680; loss: 0.7; acc: 0.83
Batch: 700; loss: 0.64; acc: 0.8
Batch: 720; loss: 0.68; acc: 0.78
Batch: 740; loss: 0.69; acc: 0.73
Batch: 760; loss: 0.64; acc: 0.84
Batch: 780; loss: 0.82; acc: 0.69
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.0369938283693045e-05
6.729614597134059e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.75
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.83; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.8
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6316178922250772; val_accuracy: 0.8042396496815286 

The current subspace-distance is: 6.729614597134059e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.66; acc: 0.77
Batch: 20; loss: 0.82; acc: 0.72
Batch: 40; loss: 0.69; acc: 0.75
Batch: 60; loss: 0.72; acc: 0.73
Batch: 80; loss: 0.75; acc: 0.81
Batch: 100; loss: 0.66; acc: 0.8
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.82; acc: 0.73
Batch: 160; loss: 0.63; acc: 0.78
Batch: 180; loss: 0.7; acc: 0.73
Batch: 200; loss: 0.7; acc: 0.81
Batch: 220; loss: 0.68; acc: 0.78
Batch: 240; loss: 0.77; acc: 0.7
Batch: 260; loss: 0.63; acc: 0.83
Batch: 280; loss: 0.8; acc: 0.77
Batch: 300; loss: 0.78; acc: 0.8
Batch: 320; loss: 0.78; acc: 0.69
Batch: 340; loss: 0.65; acc: 0.78
Batch: 360; loss: 0.7; acc: 0.78
Batch: 380; loss: 0.82; acc: 0.75
Batch: 400; loss: 0.8; acc: 0.78
Batch: 420; loss: 0.49; acc: 0.8
Batch: 440; loss: 0.7; acc: 0.78
Batch: 460; loss: 0.81; acc: 0.78
Batch: 480; loss: 0.69; acc: 0.81
Batch: 500; loss: 0.72; acc: 0.75
Batch: 520; loss: 0.66; acc: 0.78
Batch: 540; loss: 0.81; acc: 0.78
Batch: 560; loss: 0.8; acc: 0.75
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.64; acc: 0.81
Batch: 620; loss: 0.56; acc: 0.86
Batch: 640; loss: 0.74; acc: 0.77
Batch: 660; loss: 0.66; acc: 0.78
Batch: 680; loss: 0.75; acc: 0.81
Batch: 700; loss: 0.75; acc: 0.81
Batch: 720; loss: 1.02; acc: 0.67
Batch: 740; loss: 0.51; acc: 0.83
Batch: 760; loss: 0.87; acc: 0.75
Batch: 780; loss: 0.79; acc: 0.75
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.2266765881795436e-05
6.824541742389556e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.67; acc: 0.81
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.6307986121458612; val_accuracy: 0.8035429936305732 

The current subspace-distance is: 6.824541742389556e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.61; acc: 0.81
Batch: 20; loss: 0.74; acc: 0.83
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.82; acc: 0.69
Batch: 100; loss: 0.64; acc: 0.8
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.86; acc: 0.81
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.63; acc: 0.81
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.85; acc: 0.77
Batch: 300; loss: 0.69; acc: 0.77
Batch: 320; loss: 0.85; acc: 0.7
Batch: 340; loss: 0.57; acc: 0.88
Batch: 360; loss: 0.64; acc: 0.84
Batch: 380; loss: 0.83; acc: 0.7
Batch: 400; loss: 0.98; acc: 0.66
Batch: 420; loss: 0.52; acc: 0.83
Batch: 440; loss: 0.81; acc: 0.73
Batch: 460; loss: 0.77; acc: 0.81
Batch: 480; loss: 0.87; acc: 0.73
Batch: 500; loss: 0.77; acc: 0.77
Batch: 520; loss: 0.65; acc: 0.73
Batch: 540; loss: 0.84; acc: 0.7
Batch: 560; loss: 0.56; acc: 0.8
Batch: 580; loss: 0.59; acc: 0.77
Batch: 600; loss: 0.6; acc: 0.8
Batch: 620; loss: 0.66; acc: 0.77
Batch: 640; loss: 0.81; acc: 0.73
Batch: 660; loss: 0.6; acc: 0.81
Batch: 680; loss: 0.56; acc: 0.78
Batch: 700; loss: 0.63; acc: 0.73
Batch: 720; loss: 0.88; acc: 0.73
Batch: 740; loss: 0.76; acc: 0.75
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.64; acc: 0.81
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.03895106096752e-05
8.200858246709686e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.82; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.6300584382502137; val_accuracy: 0.8066281847133758 

The current subspace-distance is: 8.200858246709686e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.55; acc: 0.86
Batch: 20; loss: 0.67; acc: 0.72
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.75; acc: 0.7
Batch: 120; loss: 0.83; acc: 0.75
Batch: 140; loss: 0.73; acc: 0.73
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.58; acc: 0.77
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.74; acc: 0.8
Batch: 240; loss: 0.96; acc: 0.77
Batch: 260; loss: 0.55; acc: 0.83
Batch: 280; loss: 0.91; acc: 0.77
Batch: 300; loss: 0.7; acc: 0.84
Batch: 320; loss: 0.7; acc: 0.84
Batch: 340; loss: 0.88; acc: 0.75
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.86; acc: 0.69
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 0.61; acc: 0.86
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.52; acc: 0.88
Batch: 480; loss: 0.85; acc: 0.72
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.61; acc: 0.78
Batch: 560; loss: 0.84; acc: 0.81
Batch: 580; loss: 1.12; acc: 0.72
Batch: 600; loss: 0.85; acc: 0.72
Batch: 620; loss: 0.71; acc: 0.77
Batch: 640; loss: 0.59; acc: 0.77
Batch: 660; loss: 0.77; acc: 0.72
Batch: 680; loss: 0.63; acc: 0.78
Batch: 700; loss: 0.83; acc: 0.78
Batch: 720; loss: 0.85; acc: 0.78
Batch: 740; loss: 0.62; acc: 0.83
Batch: 760; loss: 0.82; acc: 0.72
Batch: 780; loss: 0.83; acc: 0.69
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

1.903528936963994e-05
7.135243777156575e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6297247252266878; val_accuracy: 0.8061305732484076 

The current subspace-distance is: 7.135243777156575e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.78
Batch: 40; loss: 0.85; acc: 0.72
Batch: 60; loss: 0.64; acc: 0.78
Batch: 80; loss: 0.93; acc: 0.67
Batch: 100; loss: 0.86; acc: 0.7
Batch: 120; loss: 0.82; acc: 0.72
Batch: 140; loss: 0.79; acc: 0.77
Batch: 160; loss: 0.74; acc: 0.78
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.72; acc: 0.86
Batch: 240; loss: 0.77; acc: 0.75
Batch: 260; loss: 0.6; acc: 0.81
Batch: 280; loss: 0.62; acc: 0.77
Batch: 300; loss: 0.65; acc: 0.81
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.76; acc: 0.8
Batch: 360; loss: 0.76; acc: 0.77
Batch: 380; loss: 0.86; acc: 0.72
Batch: 400; loss: 0.69; acc: 0.72
Batch: 420; loss: 1.01; acc: 0.77
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.66; acc: 0.75
Batch: 480; loss: 0.76; acc: 0.69
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.47; acc: 0.84
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.59; acc: 0.81
Batch: 580; loss: 0.83; acc: 0.72
Batch: 600; loss: 0.79; acc: 0.72
Batch: 620; loss: 0.57; acc: 0.78
Batch: 640; loss: 0.65; acc: 0.8
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.69; acc: 0.83
Batch: 700; loss: 0.9; acc: 0.69
Batch: 720; loss: 0.64; acc: 0.8
Batch: 740; loss: 0.89; acc: 0.75
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.042247615463566e-05
6.727032086928375e-06
Batch: 0; loss: 0.73; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.6306029120638112; val_accuracy: 0.8057324840764332 

The current subspace-distance is: 6.727032086928375e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.53; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.7; acc: 0.77
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.62; acc: 0.81
Batch: 120; loss: 0.88; acc: 0.78
Batch: 140; loss: 0.86; acc: 0.83
Batch: 160; loss: 0.62; acc: 0.84
Batch: 180; loss: 0.85; acc: 0.72
Batch: 200; loss: 0.78; acc: 0.72
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.87; acc: 0.7
Batch: 280; loss: 0.55; acc: 0.81
Batch: 300; loss: 0.84; acc: 0.75
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.58; acc: 0.81
Batch: 360; loss: 0.79; acc: 0.8
Batch: 380; loss: 0.68; acc: 0.72
Batch: 400; loss: 0.5; acc: 0.88
Batch: 420; loss: 0.65; acc: 0.77
Batch: 440; loss: 0.68; acc: 0.81
Batch: 460; loss: 0.55; acc: 0.84
Batch: 480; loss: 0.59; acc: 0.81
Batch: 500; loss: 0.89; acc: 0.75
Batch: 520; loss: 0.56; acc: 0.81
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.62; acc: 0.84
Batch: 580; loss: 0.7; acc: 0.78
Batch: 600; loss: 0.48; acc: 0.88
Batch: 620; loss: 0.62; acc: 0.78
Batch: 640; loss: 0.72; acc: 0.81
Batch: 660; loss: 0.69; acc: 0.77
Batch: 680; loss: 0.7; acc: 0.86
Batch: 700; loss: 0.62; acc: 0.86
Batch: 720; loss: 0.82; acc: 0.72
Batch: 740; loss: 0.55; acc: 0.77
Batch: 760; loss: 0.69; acc: 0.8
Batch: 780; loss: 0.98; acc: 0.72
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

1.901924770209007e-05
6.924044555489672e-06
Batch: 0; loss: 0.72; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.6295973364334957; val_accuracy: 0.8058320063694268 

The current subspace-distance is: 6.924044555489672e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.8; acc: 0.7
Batch: 20; loss: 0.81; acc: 0.72
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 0.68; acc: 0.81
Batch: 80; loss: 0.57; acc: 0.84
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.67; acc: 0.78
Batch: 160; loss: 0.53; acc: 0.81
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.72; acc: 0.78
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.6; acc: 0.8
Batch: 260; loss: 0.6; acc: 0.78
Batch: 280; loss: 0.67; acc: 0.8
Batch: 300; loss: 0.73; acc: 0.75
Batch: 320; loss: 0.55; acc: 0.86
Batch: 340; loss: 0.83; acc: 0.81
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.66; acc: 0.75
Batch: 400; loss: 0.61; acc: 0.77
Batch: 420; loss: 0.65; acc: 0.81
Batch: 440; loss: 0.52; acc: 0.83
Batch: 460; loss: 0.86; acc: 0.72
Batch: 480; loss: 0.52; acc: 0.81
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.75; acc: 0.75
Batch: 560; loss: 0.55; acc: 0.84
Batch: 580; loss: 0.73; acc: 0.73
Batch: 600; loss: 0.84; acc: 0.75
Batch: 620; loss: 0.8; acc: 0.8
Batch: 640; loss: 0.77; acc: 0.77
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.59; acc: 0.77
Batch: 700; loss: 0.48; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.73; acc: 0.78
Batch: 760; loss: 0.78; acc: 0.72
Batch: 780; loss: 0.65; acc: 0.81
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

1.7760623450158164e-05
6.47058550384827e-06
Batch: 0; loss: 0.72; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.42; acc: 0.83
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.6303984036870823; val_accuracy: 0.8049363057324841 

The current subspace-distance is: 6.47058550384827e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.97; acc: 0.64
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.82; acc: 0.73
Batch: 60; loss: 0.68; acc: 0.81
Batch: 80; loss: 0.64; acc: 0.81
Batch: 100; loss: 0.59; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.62; acc: 0.81
Batch: 160; loss: 0.53; acc: 0.86
Batch: 180; loss: 0.74; acc: 0.77
Batch: 200; loss: 0.93; acc: 0.72
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.99; acc: 0.67
Batch: 260; loss: 0.53; acc: 0.83
Batch: 280; loss: 0.91; acc: 0.73
Batch: 300; loss: 0.44; acc: 0.89
Batch: 320; loss: 0.61; acc: 0.78
Batch: 340; loss: 0.89; acc: 0.67
Batch: 360; loss: 0.82; acc: 0.72
Batch: 380; loss: 0.75; acc: 0.78
Batch: 400; loss: 0.81; acc: 0.77
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.7; acc: 0.8
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.74; acc: 0.75
Batch: 520; loss: 0.59; acc: 0.86
Batch: 540; loss: 0.62; acc: 0.78
Batch: 560; loss: 0.63; acc: 0.75
Batch: 580; loss: 0.58; acc: 0.83
Batch: 600; loss: 0.66; acc: 0.75
Batch: 620; loss: 0.58; acc: 0.8
Batch: 640; loss: 0.63; acc: 0.84
Batch: 660; loss: 0.69; acc: 0.8
Batch: 680; loss: 0.81; acc: 0.72
Batch: 700; loss: 0.65; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.92
Batch: 740; loss: 0.74; acc: 0.81
Batch: 760; loss: 0.66; acc: 0.8
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.0195117031107657e-05
5.714831331715686e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.77; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.83; acc: 0.8
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.630066931342623; val_accuracy: 0.805234872611465 

The current subspace-distance is: 5.714831331715686e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.8
Batch: 40; loss: 0.61; acc: 0.8
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.52; acc: 0.8
Batch: 100; loss: 0.64; acc: 0.81
Batch: 120; loss: 0.75; acc: 0.7
Batch: 140; loss: 0.62; acc: 0.83
Batch: 160; loss: 0.76; acc: 0.77
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.7; acc: 0.83
Batch: 220; loss: 0.61; acc: 0.86
Batch: 240; loss: 0.61; acc: 0.77
Batch: 260; loss: 0.61; acc: 0.78
Batch: 280; loss: 0.61; acc: 0.8
Batch: 300; loss: 0.61; acc: 0.78
Batch: 320; loss: 0.69; acc: 0.73
Batch: 340; loss: 0.5; acc: 0.88
Batch: 360; loss: 0.54; acc: 0.8
Batch: 380; loss: 0.78; acc: 0.73
Batch: 400; loss: 0.66; acc: 0.75
Batch: 420; loss: 0.65; acc: 0.81
Batch: 440; loss: 0.69; acc: 0.75
Batch: 460; loss: 0.56; acc: 0.8
Batch: 480; loss: 0.85; acc: 0.7
Batch: 500; loss: 0.57; acc: 0.78
Batch: 520; loss: 0.47; acc: 0.8
Batch: 540; loss: 0.59; acc: 0.83
Batch: 560; loss: 0.56; acc: 0.86
Batch: 580; loss: 0.67; acc: 0.8
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.75; acc: 0.8
Batch: 680; loss: 0.67; acc: 0.84
Batch: 700; loss: 0.51; acc: 0.86
Batch: 720; loss: 0.6; acc: 0.8
Batch: 740; loss: 0.65; acc: 0.75
Batch: 760; loss: 0.63; acc: 0.83
Batch: 780; loss: 0.8; acc: 0.72
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.026613219641149e-05
6.812733317929087e-06
Batch: 0; loss: 0.73; acc: 0.72
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.66; acc: 0.83
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.6307593541350335; val_accuracy: 0.8050358280254777 

The current subspace-distance is: 6.812733317929087e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 1.01; acc: 0.67
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.69; acc: 0.75
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.76; acc: 0.75
Batch: 160; loss: 0.58; acc: 0.8
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.95; acc: 0.7
Batch: 220; loss: 0.64; acc: 0.81
Batch: 240; loss: 0.57; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.87; acc: 0.7
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.6; acc: 0.84
Batch: 340; loss: 0.79; acc: 0.72
Batch: 360; loss: 0.79; acc: 0.7
Batch: 380; loss: 1.04; acc: 0.72
Batch: 400; loss: 0.8; acc: 0.77
Batch: 420; loss: 0.8; acc: 0.77
Batch: 440; loss: 0.77; acc: 0.75
Batch: 460; loss: 0.56; acc: 0.81
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.61; acc: 0.77
Batch: 520; loss: 0.87; acc: 0.8
Batch: 540; loss: 0.43; acc: 0.81
Batch: 560; loss: 0.65; acc: 0.78
Batch: 580; loss: 0.7; acc: 0.8
Batch: 600; loss: 0.79; acc: 0.72
Batch: 620; loss: 0.73; acc: 0.72
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.64; acc: 0.81
Batch: 680; loss: 0.71; acc: 0.78
Batch: 700; loss: 0.64; acc: 0.75
Batch: 720; loss: 0.66; acc: 0.8
Batch: 740; loss: 0.88; acc: 0.69
Batch: 760; loss: 0.75; acc: 0.75
Batch: 780; loss: 0.53; acc: 0.83
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

1.9897839592886157e-05
6.870141532999696e-06
Batch: 0; loss: 0.72; acc: 0.75
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.82; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.34; acc: 0.88
Val Epoch over. val_loss: 0.6295637230204928; val_accuracy: 0.8047372611464968 

The current subspace-distance is: 6.870141532999696e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.61; acc: 0.77
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.56; acc: 0.78
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 0.98; acc: 0.66
Batch: 180; loss: 0.94; acc: 0.72
Batch: 200; loss: 0.9; acc: 0.73
Batch: 220; loss: 0.78; acc: 0.78
Batch: 240; loss: 0.5; acc: 0.81
Batch: 260; loss: 0.51; acc: 0.84
Batch: 280; loss: 0.48; acc: 0.81
Batch: 300; loss: 0.85; acc: 0.77
Batch: 320; loss: 0.89; acc: 0.75
Batch: 340; loss: 0.61; acc: 0.78
Batch: 360; loss: 0.47; acc: 0.83
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.87; acc: 0.78
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.6; acc: 0.81
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.63; acc: 0.77
Batch: 540; loss: 0.67; acc: 0.73
Batch: 560; loss: 0.6; acc: 0.86
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.74; acc: 0.78
Batch: 620; loss: 1.07; acc: 0.72
Batch: 640; loss: 0.67; acc: 0.8
Batch: 660; loss: 0.81; acc: 0.83
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.7; acc: 0.77
Batch: 720; loss: 0.58; acc: 0.75
Batch: 740; loss: 0.91; acc: 0.75
Batch: 760; loss: 0.73; acc: 0.81
Batch: 780; loss: 0.76; acc: 0.73
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.0198756828904152e-05
7.761805136397015e-06
Batch: 0; loss: 0.72; acc: 0.72
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.82; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.6303143942621863; val_accuracy: 0.8046377388535032 

The current subspace-distance is: 7.761805136397015e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.78
Batch: 40; loss: 0.84; acc: 0.69
Batch: 60; loss: 0.84; acc: 0.78
Batch: 80; loss: 0.91; acc: 0.67
Batch: 100; loss: 0.99; acc: 0.77
Batch: 120; loss: 0.84; acc: 0.7
Batch: 140; loss: 0.58; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.85; acc: 0.7
Batch: 200; loss: 0.61; acc: 0.83
Batch: 220; loss: 0.57; acc: 0.86
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.47; acc: 0.83
Batch: 280; loss: 0.54; acc: 0.8
Batch: 300; loss: 0.56; acc: 0.77
Batch: 320; loss: 0.89; acc: 0.75
Batch: 340; loss: 0.7; acc: 0.75
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.65; acc: 0.84
Batch: 400; loss: 0.58; acc: 0.8
Batch: 420; loss: 0.69; acc: 0.75
Batch: 440; loss: 0.97; acc: 0.75
Batch: 460; loss: 1.1; acc: 0.72
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.65; acc: 0.78
Batch: 520; loss: 0.68; acc: 0.81
Batch: 540; loss: 1.03; acc: 0.75
Batch: 560; loss: 0.74; acc: 0.77
Batch: 580; loss: 0.57; acc: 0.81
Batch: 600; loss: 0.85; acc: 0.67
Batch: 620; loss: 0.76; acc: 0.78
Batch: 640; loss: 0.63; acc: 0.78
Batch: 660; loss: 0.68; acc: 0.78
Batch: 680; loss: 0.9; acc: 0.77
Batch: 700; loss: 0.79; acc: 0.77
Batch: 720; loss: 1.1; acc: 0.69
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.37; acc: 0.84
Batch: 780; loss: 0.67; acc: 0.8
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

1.9570463337004185e-05
6.601106179005001e-06
Batch: 0; loss: 0.72; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.73
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.629198231989411; val_accuracy: 0.8069267515923567 

The current subspace-distance is: 6.601106179005001e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 26230
elements in E: 5553250
fraction nonzero: 0.0047233601944807095
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.11
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.11
Batch: 340; loss: 2.29; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.08
Batch: 420; loss: 2.29; acc: 0.14
Batch: 440; loss: 2.28; acc: 0.11
Batch: 460; loss: 2.29; acc: 0.06
Batch: 480; loss: 2.29; acc: 0.14
Batch: 500; loss: 2.28; acc: 0.09
Batch: 520; loss: 2.3; acc: 0.11
Batch: 540; loss: 2.29; acc: 0.08
Batch: 560; loss: 2.29; acc: 0.12
Batch: 580; loss: 2.27; acc: 0.19
Batch: 600; loss: 2.27; acc: 0.2
Batch: 620; loss: 2.29; acc: 0.08
Batch: 640; loss: 2.27; acc: 0.14
Batch: 660; loss: 2.28; acc: 0.16
Batch: 680; loss: 2.27; acc: 0.17
Batch: 700; loss: 2.26; acc: 0.22
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.28; acc: 0.14
Batch: 760; loss: 2.27; acc: 0.19
Batch: 780; loss: 2.26; acc: 0.22
Train Epoch over. train_loss: 2.29; train_accuracy: 0.12 

4.516932222031755e-06
1.2857268529842258e-06
Batch: 0; loss: 2.27; acc: 0.19
Batch: 20; loss: 2.26; acc: 0.16
Batch: 40; loss: 2.26; acc: 0.17
Batch: 60; loss: 2.26; acc: 0.17
Batch: 80; loss: 2.25; acc: 0.3
Batch: 100; loss: 2.27; acc: 0.17
Batch: 120; loss: 2.28; acc: 0.19
Batch: 140; loss: 2.27; acc: 0.19
Val Epoch over. val_loss: 2.2647874157899506; val_accuracy: 0.192078025477707 

The current subspace-distance is: 1.2857268529842258e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.26; acc: 0.14
Batch: 20; loss: 2.26; acc: 0.17
Batch: 40; loss: 2.27; acc: 0.16
Batch: 60; loss: 2.25; acc: 0.23
Batch: 80; loss: 2.26; acc: 0.17
Batch: 100; loss: 2.26; acc: 0.08
Batch: 120; loss: 2.26; acc: 0.16
Batch: 140; loss: 2.25; acc: 0.28
Batch: 160; loss: 2.25; acc: 0.11
Batch: 180; loss: 2.23; acc: 0.2
Batch: 200; loss: 2.23; acc: 0.12
Batch: 220; loss: 2.21; acc: 0.22
Batch: 240; loss: 2.2; acc: 0.28
Batch: 260; loss: 2.21; acc: 0.19
Batch: 280; loss: 2.21; acc: 0.19
Batch: 300; loss: 2.15; acc: 0.28
Batch: 320; loss: 2.15; acc: 0.27
Batch: 340; loss: 2.14; acc: 0.3
Batch: 360; loss: 2.12; acc: 0.33
Batch: 380; loss: 2.05; acc: 0.38
Batch: 400; loss: 2.0; acc: 0.42
Batch: 420; loss: 1.95; acc: 0.44
Batch: 440; loss: 1.94; acc: 0.36
Batch: 460; loss: 1.9; acc: 0.34
Batch: 480; loss: 1.63; acc: 0.47
Batch: 500; loss: 1.44; acc: 0.64
Batch: 520; loss: 1.32; acc: 0.61
Batch: 540; loss: 1.21; acc: 0.66
Batch: 560; loss: 1.03; acc: 0.69
Batch: 580; loss: 1.06; acc: 0.62
Batch: 600; loss: 0.89; acc: 0.73
Batch: 620; loss: 0.87; acc: 0.75
Batch: 640; loss: 1.09; acc: 0.61
Batch: 660; loss: 1.04; acc: 0.7
Batch: 680; loss: 0.9; acc: 0.7
Batch: 700; loss: 0.8; acc: 0.77
Batch: 720; loss: 0.82; acc: 0.73
Batch: 740; loss: 0.89; acc: 0.7
Batch: 760; loss: 0.84; acc: 0.72
Batch: 780; loss: 0.77; acc: 0.8
Train Epoch over. train_loss: 1.71; train_accuracy: 0.43 

1.3012861018069088e-05
7.008674856479047e-06
Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 0.81; acc: 0.7
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.87; acc: 0.73
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.9; acc: 0.73
Batch: 120; loss: 1.04; acc: 0.64
Batch: 140; loss: 0.59; acc: 0.8
Val Epoch over. val_loss: 0.8102551000133441; val_accuracy: 0.7483081210191083 

The current subspace-distance is: 7.008674856479047e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.18; acc: 0.64
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.7; acc: 0.72
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.9; acc: 0.73
Batch: 100; loss: 0.57; acc: 0.8
Batch: 120; loss: 0.9; acc: 0.72
Batch: 140; loss: 0.52; acc: 0.84
Batch: 160; loss: 0.6; acc: 0.75
Batch: 180; loss: 0.72; acc: 0.8
Batch: 200; loss: 0.99; acc: 0.61
Batch: 220; loss: 0.74; acc: 0.8
Batch: 240; loss: 0.75; acc: 0.72
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.65; acc: 0.83
Batch: 300; loss: 1.14; acc: 0.66
Batch: 320; loss: 0.86; acc: 0.72
Batch: 340; loss: 0.75; acc: 0.73
Batch: 360; loss: 0.72; acc: 0.77
Batch: 380; loss: 0.71; acc: 0.77
Batch: 400; loss: 0.74; acc: 0.8
Batch: 420; loss: 0.69; acc: 0.73
Batch: 440; loss: 0.62; acc: 0.84
Batch: 460; loss: 0.54; acc: 0.83
Batch: 480; loss: 0.56; acc: 0.84
Batch: 500; loss: 0.54; acc: 0.83
Batch: 520; loss: 0.72; acc: 0.8
Batch: 540; loss: 1.12; acc: 0.69
Batch: 560; loss: 0.99; acc: 0.77
Batch: 580; loss: 0.58; acc: 0.81
Batch: 600; loss: 0.66; acc: 0.83
Batch: 620; loss: 0.66; acc: 0.81
Batch: 640; loss: 0.86; acc: 0.75
Batch: 660; loss: 0.61; acc: 0.86
Batch: 680; loss: 0.73; acc: 0.81
Batch: 700; loss: 0.75; acc: 0.78
Batch: 720; loss: 0.64; acc: 0.77
Batch: 740; loss: 0.73; acc: 0.77
Batch: 760; loss: 0.78; acc: 0.73
Batch: 780; loss: 0.68; acc: 0.78
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

1.870996675279457e-05
6.65685229250812e-06
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.7; acc: 0.81
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.88; acc: 0.75
Batch: 140; loss: 0.34; acc: 0.94
Val Epoch over. val_loss: 0.6110225886486138; val_accuracy: 0.8092157643312102 

The current subspace-distance is: 6.65685229250812e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.77
Batch: 20; loss: 0.66; acc: 0.73
Batch: 40; loss: 0.72; acc: 0.83
Batch: 60; loss: 0.86; acc: 0.66
Batch: 80; loss: 0.93; acc: 0.75
Batch: 100; loss: 0.62; acc: 0.8
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 1.07; acc: 0.73
Batch: 180; loss: 0.63; acc: 0.8
Batch: 200; loss: 0.69; acc: 0.77
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.6; acc: 0.73
Batch: 260; loss: 0.55; acc: 0.81
Batch: 280; loss: 0.66; acc: 0.73
Batch: 300; loss: 0.6; acc: 0.88
Batch: 320; loss: 0.8; acc: 0.78
Batch: 340; loss: 0.72; acc: 0.78
Batch: 360; loss: 0.65; acc: 0.8
Batch: 380; loss: 0.75; acc: 0.73
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.64; acc: 0.83
Batch: 440; loss: 0.84; acc: 0.77
Batch: 460; loss: 0.62; acc: 0.81
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.44; acc: 0.81
Batch: 520; loss: 0.63; acc: 0.89
Batch: 540; loss: 0.7; acc: 0.73
Batch: 560; loss: 0.76; acc: 0.84
Batch: 580; loss: 0.79; acc: 0.73
Batch: 600; loss: 0.63; acc: 0.78
Batch: 620; loss: 0.71; acc: 0.77
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.49; acc: 0.81
Batch: 700; loss: 0.54; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.89
Batch: 740; loss: 0.72; acc: 0.77
Batch: 760; loss: 0.79; acc: 0.75
Batch: 780; loss: 0.81; acc: 0.72
Train Epoch over. train_loss: 0.65; train_accuracy: 0.79 

2.0359166228445247e-05
7.51005745769362e-06
Batch: 0; loss: 0.85; acc: 0.77
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.75
Batch: 80; loss: 0.57; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 0.81; acc: 0.64
Batch: 140; loss: 0.33; acc: 0.88
Val Epoch over. val_loss: 0.7085835274997031; val_accuracy: 0.7750796178343949 

The current subspace-distance is: 7.51005745769362e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.05; acc: 0.66
Batch: 20; loss: 0.94; acc: 0.78
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.57; acc: 0.84
Batch: 100; loss: 0.7; acc: 0.73
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.66; acc: 0.78
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.61; acc: 0.81
Batch: 200; loss: 0.63; acc: 0.78
Batch: 220; loss: 0.67; acc: 0.77
Batch: 240; loss: 0.65; acc: 0.84
Batch: 260; loss: 0.49; acc: 0.8
Batch: 280; loss: 0.5; acc: 0.77
Batch: 300; loss: 0.57; acc: 0.81
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.54; acc: 0.77
Batch: 360; loss: 0.57; acc: 0.77
Batch: 380; loss: 0.68; acc: 0.8
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.92; acc: 0.75
Batch: 440; loss: 0.65; acc: 0.75
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.67; acc: 0.78
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.78; acc: 0.75
Batch: 540; loss: 0.77; acc: 0.73
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.82; acc: 0.7
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.6; acc: 0.84
Batch: 660; loss: 0.5; acc: 0.83
Batch: 680; loss: 0.68; acc: 0.81
Batch: 700; loss: 0.63; acc: 0.8
Batch: 720; loss: 0.54; acc: 0.88
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.7; acc: 0.8
Batch: 780; loss: 0.61; acc: 0.83
Train Epoch over. train_loss: 0.64; train_accuracy: 0.8 

1.936447551997844e-05
6.853853847132996e-06
Batch: 0; loss: 0.95; acc: 0.67
Batch: 20; loss: 0.88; acc: 0.62
Batch: 40; loss: 0.36; acc: 0.94
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 1.18; acc: 0.64
Batch: 140; loss: 0.4; acc: 0.88
Val Epoch over. val_loss: 0.7610054150888115; val_accuracy: 0.7530851910828026 

The current subspace-distance is: 6.853853847132996e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.69
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.67; acc: 0.77
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.59; acc: 0.88
Batch: 160; loss: 0.67; acc: 0.83
Batch: 180; loss: 0.72; acc: 0.8
Batch: 200; loss: 0.54; acc: 0.78
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.78
Batch: 260; loss: 0.66; acc: 0.75
Batch: 280; loss: 0.76; acc: 0.77
Batch: 300; loss: 0.74; acc: 0.78
Batch: 320; loss: 0.9; acc: 0.7
Batch: 340; loss: 0.74; acc: 0.75
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.62; acc: 0.86
Batch: 420; loss: 0.63; acc: 0.8
Batch: 440; loss: 0.68; acc: 0.75
Batch: 460; loss: 0.68; acc: 0.8
Batch: 480; loss: 0.68; acc: 0.77
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.58; acc: 0.8
Batch: 620; loss: 0.63; acc: 0.78
Batch: 640; loss: 0.67; acc: 0.8
Batch: 660; loss: 0.65; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.91; acc: 0.77
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.77; acc: 0.77
Batch: 760; loss: 0.81; acc: 0.66
Batch: 780; loss: 0.81; acc: 0.77
Train Epoch over. train_loss: 0.63; train_accuracy: 0.8 

1.966461059055291e-05
6.401370683306595e-06
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.68; acc: 0.72
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.64; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.59; acc: 0.78
Batch: 120; loss: 1.0; acc: 0.62
Batch: 140; loss: 0.29; acc: 0.91
Val Epoch over. val_loss: 0.6060639252518393; val_accuracy: 0.7991640127388535 

The current subspace-distance is: 6.401370683306595e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.7
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.52; acc: 0.84
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.64; acc: 0.81
Batch: 100; loss: 0.79; acc: 0.78
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.68; acc: 0.77
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.73; acc: 0.78
Batch: 200; loss: 0.81; acc: 0.77
Batch: 220; loss: 0.8; acc: 0.77
Batch: 240; loss: 0.52; acc: 0.88
Batch: 260; loss: 0.71; acc: 0.73
Batch: 280; loss: 0.64; acc: 0.72
Batch: 300; loss: 0.6; acc: 0.78
Batch: 320; loss: 0.62; acc: 0.75
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.88; acc: 0.78
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.59; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.69; acc: 0.77
Batch: 500; loss: 0.58; acc: 0.8
Batch: 520; loss: 0.58; acc: 0.78
Batch: 540; loss: 0.86; acc: 0.78
Batch: 560; loss: 0.73; acc: 0.77
Batch: 580; loss: 0.76; acc: 0.73
Batch: 600; loss: 0.76; acc: 0.77
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.45; acc: 0.83
Batch: 680; loss: 0.75; acc: 0.81
Batch: 700; loss: 0.49; acc: 0.8
Batch: 720; loss: 0.72; acc: 0.75
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.6; acc: 0.8
Batch: 780; loss: 0.64; acc: 0.8
Train Epoch over. train_loss: 0.63; train_accuracy: 0.8 

2.073496398224961e-05
8.069331670412794e-06
Batch: 0; loss: 0.81; acc: 0.75
Batch: 20; loss: 0.99; acc: 0.7
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.81; acc: 0.77
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.72; acc: 0.77
Batch: 120; loss: 1.1; acc: 0.7
Batch: 140; loss: 0.34; acc: 0.89
Val Epoch over. val_loss: 0.815187675558078; val_accuracy: 0.7561703821656051 

The current subspace-distance is: 8.069331670412794e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.1; acc: 0.69
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.55; acc: 0.78
Batch: 80; loss: 0.54; acc: 0.81
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.79; acc: 0.83
Batch: 140; loss: 0.67; acc: 0.75
Batch: 160; loss: 0.85; acc: 0.73
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.74; acc: 0.8
Batch: 220; loss: 0.76; acc: 0.7
Batch: 240; loss: 0.66; acc: 0.8
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.64; acc: 0.78
Batch: 300; loss: 0.66; acc: 0.78
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.68; acc: 0.75
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.84; acc: 0.69
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.5; acc: 0.78
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.7; acc: 0.78
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.65; acc: 0.77
Batch: 520; loss: 0.73; acc: 0.75
Batch: 540; loss: 0.77; acc: 0.75
Batch: 560; loss: 0.63; acc: 0.8
Batch: 580; loss: 0.52; acc: 0.77
Batch: 600; loss: 0.64; acc: 0.78
Batch: 620; loss: 0.52; acc: 0.8
Batch: 640; loss: 0.64; acc: 0.8
Batch: 660; loss: 0.5; acc: 0.84
Batch: 680; loss: 0.99; acc: 0.7
Batch: 700; loss: 0.55; acc: 0.81
Batch: 720; loss: 0.66; acc: 0.84
Batch: 740; loss: 0.84; acc: 0.83
Batch: 760; loss: 0.98; acc: 0.72
Batch: 780; loss: 0.52; acc: 0.81
Train Epoch over. train_loss: 0.62; train_accuracy: 0.8 

1.9729290215764195e-05
7.191108124970924e-06
Batch: 0; loss: 0.81; acc: 0.77
Batch: 20; loss: 1.0; acc: 0.67
Batch: 40; loss: 0.38; acc: 0.94
Batch: 60; loss: 0.88; acc: 0.64
Batch: 80; loss: 0.68; acc: 0.78
Batch: 100; loss: 0.69; acc: 0.73
Batch: 120; loss: 1.14; acc: 0.66
Batch: 140; loss: 0.34; acc: 0.91
Val Epoch over. val_loss: 0.7934029369976869; val_accuracy: 0.7388535031847133 

The current subspace-distance is: 7.191108124970924e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.84; acc: 0.72
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.89
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.68; acc: 0.73
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.74; acc: 0.78
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.64; acc: 0.8
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.74; acc: 0.77
Batch: 240; loss: 0.58; acc: 0.83
Batch: 260; loss: 0.67; acc: 0.73
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.6; acc: 0.77
Batch: 320; loss: 0.58; acc: 0.83
Batch: 340; loss: 0.6; acc: 0.8
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.74; acc: 0.73
Batch: 400; loss: 0.57; acc: 0.8
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.68; acc: 0.77
Batch: 480; loss: 0.67; acc: 0.77
Batch: 500; loss: 0.56; acc: 0.81
Batch: 520; loss: 0.5; acc: 0.86
Batch: 540; loss: 0.68; acc: 0.83
Batch: 560; loss: 0.62; acc: 0.84
Batch: 580; loss: 0.77; acc: 0.78
Batch: 600; loss: 0.75; acc: 0.8
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.73; acc: 0.72
Batch: 660; loss: 0.63; acc: 0.8
Batch: 680; loss: 0.74; acc: 0.8
Batch: 700; loss: 0.95; acc: 0.75
Batch: 720; loss: 0.89; acc: 0.7
Batch: 740; loss: 0.63; acc: 0.78
Batch: 760; loss: 0.53; acc: 0.88
Batch: 780; loss: 0.86; acc: 0.77
Train Epoch over. train_loss: 0.62; train_accuracy: 0.8 

2.0603341909009032e-05
7.973560059326701e-06
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.7; acc: 0.73
Batch: 40; loss: 0.47; acc: 0.91
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.84; acc: 0.69
Batch: 140; loss: 0.35; acc: 0.86
Val Epoch over. val_loss: 0.6218968090737701; val_accuracy: 0.7977707006369427 

The current subspace-distance is: 7.973560059326701e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.73
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.65; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 0.54; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.67; acc: 0.73
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.55; acc: 0.81
Batch: 200; loss: 0.61; acc: 0.73
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.76; acc: 0.8
Batch: 280; loss: 0.63; acc: 0.83
Batch: 300; loss: 0.75; acc: 0.73
Batch: 320; loss: 0.71; acc: 0.81
Batch: 340; loss: 0.47; acc: 0.8
Batch: 360; loss: 0.58; acc: 0.84
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.53; acc: 0.81
Batch: 420; loss: 0.59; acc: 0.78
Batch: 440; loss: 0.66; acc: 0.78
Batch: 460; loss: 0.64; acc: 0.78
Batch: 480; loss: 0.59; acc: 0.84
Batch: 500; loss: 0.6; acc: 0.8
Batch: 520; loss: 0.55; acc: 0.86
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.69; acc: 0.77
Batch: 580; loss: 0.81; acc: 0.77
Batch: 600; loss: 0.8; acc: 0.73
Batch: 620; loss: 0.37; acc: 0.94
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.66; acc: 0.77
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.58; acc: 0.77
Batch: 740; loss: 0.61; acc: 0.8
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.65; acc: 0.78
Train Epoch over. train_loss: 0.61; train_accuracy: 0.81 

2.1230029233265668e-05
7.473935966118006e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 0.35; acc: 0.94
Batch: 60; loss: 0.74; acc: 0.77
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.93; acc: 0.69
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.5646876615893309; val_accuracy: 0.8193670382165605 

The current subspace-distance is: 7.473935966118006e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.81; acc: 0.73
Batch: 20; loss: 0.75; acc: 0.73
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.78; acc: 0.75
Batch: 100; loss: 0.54; acc: 0.81
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.61; acc: 0.78
Batch: 160; loss: 0.52; acc: 0.75
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.61; acc: 0.83
Batch: 220; loss: 0.48; acc: 0.81
Batch: 240; loss: 0.62; acc: 0.86
Batch: 260; loss: 0.52; acc: 0.81
Batch: 280; loss: 0.63; acc: 0.73
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.69; acc: 0.75
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.62; acc: 0.81
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.59; acc: 0.78
Batch: 420; loss: 0.57; acc: 0.84
Batch: 440; loss: 0.54; acc: 0.78
Batch: 460; loss: 0.42; acc: 0.83
Batch: 480; loss: 0.6; acc: 0.8
Batch: 500; loss: 0.56; acc: 0.77
Batch: 520; loss: 0.74; acc: 0.73
Batch: 540; loss: 0.46; acc: 0.91
Batch: 560; loss: 0.72; acc: 0.73
Batch: 580; loss: 0.59; acc: 0.88
Batch: 600; loss: 0.6; acc: 0.8
Batch: 620; loss: 0.49; acc: 0.83
Batch: 640; loss: 0.52; acc: 0.88
Batch: 660; loss: 0.61; acc: 0.8
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.85; acc: 0.77
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.6; acc: 0.8
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.77; acc: 0.78
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.1602249034913257e-05
7.438457032549195e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.97
Val Epoch over. val_loss: 0.5160180808632238; val_accuracy: 0.832703025477707 

The current subspace-distance is: 7.438457032549195e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.81; acc: 0.75
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.56; acc: 0.8
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.56; acc: 0.8
Batch: 160; loss: 0.74; acc: 0.78
Batch: 180; loss: 0.57; acc: 0.81
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.55; acc: 0.84
Batch: 260; loss: 0.7; acc: 0.77
Batch: 280; loss: 0.62; acc: 0.8
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.66; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.79; acc: 0.7
Batch: 400; loss: 0.58; acc: 0.8
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.86
Batch: 460; loss: 0.65; acc: 0.77
Batch: 480; loss: 0.51; acc: 0.83
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.54; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.55; acc: 0.78
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.58; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.58; acc: 0.8
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.1159459720365703e-05
7.194792942755157e-06
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.8
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.24; acc: 0.95
Val Epoch over. val_loss: 0.5167227061880622; val_accuracy: 0.8350915605095541 

The current subspace-distance is: 7.194792942755157e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.04; acc: 0.69
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.58; acc: 0.84
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.58; acc: 0.84
Batch: 100; loss: 0.82; acc: 0.72
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.91; acc: 0.7
Batch: 160; loss: 0.81; acc: 0.73
Batch: 180; loss: 0.82; acc: 0.77
Batch: 200; loss: 0.5; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.88; acc: 0.73
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.67; acc: 0.77
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.57; acc: 0.84
Batch: 360; loss: 0.49; acc: 0.81
Batch: 380; loss: 0.52; acc: 0.84
Batch: 400; loss: 0.6; acc: 0.75
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.85; acc: 0.7
Batch: 460; loss: 0.63; acc: 0.73
Batch: 480; loss: 0.48; acc: 0.84
Batch: 500; loss: 0.59; acc: 0.84
Batch: 520; loss: 0.54; acc: 0.8
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.89
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.78; acc: 0.77
Batch: 660; loss: 0.7; acc: 0.75
Batch: 680; loss: 0.8; acc: 0.73
Batch: 700; loss: 0.48; acc: 0.86
Batch: 720; loss: 0.56; acc: 0.78
Batch: 740; loss: 0.53; acc: 0.86
Batch: 760; loss: 0.54; acc: 0.86
Batch: 780; loss: 0.65; acc: 0.73
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.137289266102016e-05
8.691023140272591e-06
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.8
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.63; acc: 0.78
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.85; acc: 0.75
Batch: 140; loss: 0.27; acc: 0.94
Val Epoch over. val_loss: 0.5264197619287831; val_accuracy: 0.8339968152866242 

The current subspace-distance is: 8.691023140272591e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.82; acc: 0.75
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.66; acc: 0.81
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.72; acc: 0.78
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.63; acc: 0.86
Batch: 160; loss: 0.68; acc: 0.8
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.61; acc: 0.89
Batch: 220; loss: 0.64; acc: 0.75
Batch: 240; loss: 0.64; acc: 0.83
Batch: 260; loss: 0.73; acc: 0.73
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.78; acc: 0.75
Batch: 340; loss: 0.6; acc: 0.83
Batch: 360; loss: 0.71; acc: 0.8
Batch: 380; loss: 0.59; acc: 0.8
Batch: 400; loss: 0.4; acc: 0.84
Batch: 420; loss: 0.55; acc: 0.83
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.94; acc: 0.8
Batch: 480; loss: 0.68; acc: 0.78
Batch: 500; loss: 0.56; acc: 0.8
Batch: 520; loss: 0.63; acc: 0.75
Batch: 540; loss: 0.56; acc: 0.8
Batch: 560; loss: 0.58; acc: 0.77
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.53; acc: 0.84
Batch: 620; loss: 0.6; acc: 0.81
Batch: 640; loss: 0.63; acc: 0.81
Batch: 660; loss: 0.63; acc: 0.78
Batch: 680; loss: 0.43; acc: 0.91
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.55; acc: 0.81
Batch: 740; loss: 0.76; acc: 0.81
Batch: 760; loss: 0.59; acc: 0.8
Batch: 780; loss: 0.6; acc: 0.8
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.005472379096318e-05
7.298611762962537e-06
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.78
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.77
Batch: 140; loss: 0.28; acc: 0.92
Val Epoch over. val_loss: 0.5371074036807771; val_accuracy: 0.8290207006369427 

The current subspace-distance is: 7.298611762962537e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.78; acc: 0.78
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.61; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.86
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.61; acc: 0.84
Batch: 180; loss: 0.57; acc: 0.8
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.54; acc: 0.81
Batch: 260; loss: 0.65; acc: 0.8
Batch: 280; loss: 0.45; acc: 0.8
Batch: 300; loss: 0.47; acc: 0.81
Batch: 320; loss: 0.72; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.73; acc: 0.77
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.56; acc: 0.78
Batch: 420; loss: 0.41; acc: 0.83
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.69; acc: 0.73
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.66; acc: 0.77
Batch: 580; loss: 0.44; acc: 0.83
Batch: 600; loss: 0.57; acc: 0.81
Batch: 620; loss: 0.58; acc: 0.8
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.61; acc: 0.78
Batch: 680; loss: 0.68; acc: 0.77
Batch: 700; loss: 0.54; acc: 0.75
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.66; acc: 0.8
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.106965439452324e-05
7.722896043560468e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.8
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.26; acc: 0.94
Val Epoch over. val_loss: 0.5201042125559157; val_accuracy: 0.8282245222929936 

The current subspace-distance is: 7.722896043560468e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.58; acc: 0.77
Batch: 40; loss: 0.56; acc: 0.75
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.72; acc: 0.8
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.59; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.49; acc: 0.81
Batch: 280; loss: 0.53; acc: 0.86
Batch: 300; loss: 0.6; acc: 0.77
Batch: 320; loss: 0.64; acc: 0.77
Batch: 340; loss: 0.57; acc: 0.81
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.45; acc: 0.81
Batch: 400; loss: 0.82; acc: 0.72
Batch: 420; loss: 0.83; acc: 0.77
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.88; acc: 0.75
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.76; acc: 0.8
Batch: 520; loss: 0.56; acc: 0.81
Batch: 540; loss: 0.83; acc: 0.73
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.58; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.78
Batch: 620; loss: 0.66; acc: 0.78
Batch: 640; loss: 0.6; acc: 0.78
Batch: 660; loss: 0.6; acc: 0.78
Batch: 680; loss: 0.48; acc: 0.8
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.8; acc: 0.77
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.81
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.220023816335015e-05
8.907964001991786e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.98
Val Epoch over. val_loss: 0.510734171149837; val_accuracy: 0.8384753184713376 

The current subspace-distance is: 8.907964001991786e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.58; acc: 0.83
Batch: 160; loss: 0.77; acc: 0.78
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.86; acc: 0.69
Batch: 220; loss: 0.67; acc: 0.7
Batch: 240; loss: 0.58; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.8
Batch: 280; loss: 0.61; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.55; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.55; acc: 0.8
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.78; acc: 0.73
Batch: 440; loss: 0.63; acc: 0.78
Batch: 460; loss: 0.65; acc: 0.78
Batch: 480; loss: 0.86; acc: 0.73
Batch: 500; loss: 0.54; acc: 0.78
Batch: 520; loss: 0.45; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.81
Batch: 560; loss: 0.61; acc: 0.77
Batch: 580; loss: 0.69; acc: 0.84
Batch: 600; loss: 0.57; acc: 0.75
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.51; acc: 0.81
Batch: 680; loss: 0.74; acc: 0.8
Batch: 700; loss: 0.66; acc: 0.81
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.61; acc: 0.86
Batch: 780; loss: 0.6; acc: 0.81
Train Epoch over. train_loss: 0.58; train_accuracy: 0.82 

2.2715985323884524e-05
9.47757507674396e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.94
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.22; acc: 0.95
Val Epoch over. val_loss: 0.5099172009404298; val_accuracy: 0.8373805732484076 

The current subspace-distance is: 9.47757507674396e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.86; acc: 0.84
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.55; acc: 0.84
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.85; acc: 0.78
Batch: 200; loss: 0.81; acc: 0.86
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.55; acc: 0.81
Batch: 320; loss: 0.36; acc: 0.84
Batch: 340; loss: 0.41; acc: 0.84
Batch: 360; loss: 0.84; acc: 0.77
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.47; acc: 0.83
Batch: 420; loss: 0.59; acc: 0.77
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.83
Batch: 520; loss: 0.59; acc: 0.84
Batch: 540; loss: 0.61; acc: 0.83
Batch: 560; loss: 0.72; acc: 0.75
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.74; acc: 0.77
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.7; acc: 0.78
Batch: 680; loss: 0.67; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.8
Batch: 740; loss: 0.56; acc: 0.81
Batch: 760; loss: 0.72; acc: 0.8
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.138287527486682e-05
8.183621503121685e-06
Batch: 0; loss: 0.45; acc: 0.91
Batch: 20; loss: 0.54; acc: 0.75
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.94
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.23; acc: 0.97
Val Epoch over. val_loss: 0.5276837211315799; val_accuracy: 0.8352906050955414 

The current subspace-distance is: 8.183621503121685e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.62; acc: 0.81
Batch: 160; loss: 0.55; acc: 0.83
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.62; acc: 0.78
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.51; acc: 0.78
Batch: 280; loss: 0.56; acc: 0.81
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.56; acc: 0.75
Batch: 360; loss: 0.73; acc: 0.83
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.61; acc: 0.83
Batch: 460; loss: 0.83; acc: 0.78
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.72; acc: 0.8
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.8
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.49; acc: 0.8
Batch: 620; loss: 0.83; acc: 0.75
Batch: 640; loss: 0.57; acc: 0.8
Batch: 660; loss: 0.68; acc: 0.81
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.59; acc: 0.86
Batch: 720; loss: 0.49; acc: 0.84
Batch: 740; loss: 0.63; acc: 0.83
Batch: 760; loss: 0.61; acc: 0.86
Batch: 780; loss: 0.56; acc: 0.83
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.304132067365572e-05
9.03589079825906e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.68; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.81; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.97
Val Epoch over. val_loss: 0.5029677236156099; val_accuracy: 0.8419585987261147 

The current subspace-distance is: 9.03589079825906e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.8
Batch: 20; loss: 0.69; acc: 0.78
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.76; acc: 0.83
Batch: 120; loss: 0.94; acc: 0.77
Batch: 140; loss: 0.66; acc: 0.8
Batch: 160; loss: 0.65; acc: 0.77
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.58; acc: 0.88
Batch: 220; loss: 0.62; acc: 0.78
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.48; acc: 0.89
Batch: 280; loss: 0.63; acc: 0.78
Batch: 300; loss: 0.5; acc: 0.88
Batch: 320; loss: 0.86; acc: 0.78
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.58; acc: 0.86
Batch: 400; loss: 0.76; acc: 0.8
Batch: 420; loss: 0.7; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.71; acc: 0.73
Batch: 480; loss: 0.68; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.66; acc: 0.77
Batch: 540; loss: 0.71; acc: 0.73
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.55; acc: 0.83
Batch: 620; loss: 0.57; acc: 0.81
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 1.05; acc: 0.7
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.55; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.59; acc: 0.84
Batch: 760; loss: 0.51; acc: 0.81
Batch: 780; loss: 0.57; acc: 0.8
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.0754261640831828e-05
7.294482657016488e-06
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.5032473009103423; val_accuracy: 0.8404657643312102 

The current subspace-distance is: 7.294482657016488e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.68; acc: 0.77
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.51; acc: 0.8
Batch: 160; loss: 0.64; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.64; acc: 0.8
Batch: 220; loss: 0.5; acc: 0.84
Batch: 240; loss: 0.53; acc: 0.81
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.68; acc: 0.75
Batch: 300; loss: 0.62; acc: 0.83
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.81; acc: 0.73
Batch: 360; loss: 0.51; acc: 0.83
Batch: 380; loss: 0.44; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.94
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.46; acc: 0.81
Batch: 500; loss: 0.64; acc: 0.8
Batch: 520; loss: 0.77; acc: 0.8
Batch: 540; loss: 0.77; acc: 0.78
Batch: 560; loss: 0.95; acc: 0.77
Batch: 580; loss: 0.46; acc: 0.89
Batch: 600; loss: 0.7; acc: 0.8
Batch: 620; loss: 0.71; acc: 0.83
Batch: 640; loss: 0.72; acc: 0.83
Batch: 660; loss: 0.6; acc: 0.8
Batch: 680; loss: 0.81; acc: 0.81
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.75; acc: 0.75
Batch: 740; loss: 0.49; acc: 0.91
Batch: 760; loss: 0.55; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.81
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.1510490114451386e-05
7.236355486384127e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.8
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.5017940964858243; val_accuracy: 0.8444466560509554 

The current subspace-distance is: 7.236355486384127e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.86
Batch: 40; loss: 0.54; acc: 0.84
Batch: 60; loss: 0.48; acc: 0.81
Batch: 80; loss: 0.76; acc: 0.8
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.63; acc: 0.83
Batch: 180; loss: 0.83; acc: 0.73
Batch: 200; loss: 0.51; acc: 0.86
Batch: 220; loss: 0.68; acc: 0.81
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.54; acc: 0.84
Batch: 300; loss: 0.6; acc: 0.78
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.65; acc: 0.78
Batch: 360; loss: 0.77; acc: 0.78
Batch: 380; loss: 0.58; acc: 0.78
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.82; acc: 0.77
Batch: 440; loss: 0.61; acc: 0.83
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.49; acc: 0.8
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.67; acc: 0.81
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.6; acc: 0.8
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.55; acc: 0.75
Batch: 620; loss: 0.52; acc: 0.86
Batch: 640; loss: 0.45; acc: 0.83
Batch: 660; loss: 0.67; acc: 0.77
Batch: 680; loss: 0.81; acc: 0.8
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.2490807168651372e-05
7.09392497810768e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.5012743038356684; val_accuracy: 0.8424562101910829 

The current subspace-distance is: 7.09392497810768e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.95; acc: 0.69
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.74; acc: 0.81
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.86; acc: 0.75
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.61; acc: 0.78
Batch: 240; loss: 0.62; acc: 0.84
Batch: 260; loss: 0.84; acc: 0.78
Batch: 280; loss: 0.61; acc: 0.81
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.7; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.86
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.83
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.39; acc: 0.92
Batch: 520; loss: 0.62; acc: 0.81
Batch: 540; loss: 0.62; acc: 0.83
Batch: 560; loss: 0.84; acc: 0.8
Batch: 580; loss: 0.52; acc: 0.86
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.97; acc: 0.67
Batch: 640; loss: 0.62; acc: 0.84
Batch: 660; loss: 0.81; acc: 0.8
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.57; acc: 0.8
Batch: 760; loss: 0.72; acc: 0.75
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.2621770767727867e-05
7.291830570466118e-06
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.86; acc: 0.81
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.5092790388757256; val_accuracy: 0.8396695859872612 

The current subspace-distance is: 7.291830570466118e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.67; acc: 0.75
Batch: 20; loss: 0.74; acc: 0.78
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.85; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.8
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.64; acc: 0.83
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.58; acc: 0.83
Batch: 220; loss: 0.54; acc: 0.84
Batch: 240; loss: 0.77; acc: 0.78
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.58; acc: 0.78
Batch: 300; loss: 0.68; acc: 0.73
Batch: 320; loss: 0.52; acc: 0.8
Batch: 340; loss: 0.75; acc: 0.75
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.48; acc: 0.83
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.56; acc: 0.83
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.62; acc: 0.77
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.57; acc: 0.86
Batch: 540; loss: 0.88; acc: 0.77
Batch: 560; loss: 0.58; acc: 0.81
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.79; acc: 0.72
Batch: 640; loss: 0.58; acc: 0.78
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.63; acc: 0.8
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.65; acc: 0.8
Batch: 760; loss: 0.49; acc: 0.88
Batch: 780; loss: 0.83; acc: 0.8
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.1894195015192963e-05
8.252070983871818e-06
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.81
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.5043789776647167; val_accuracy: 0.8455414012738853 

The current subspace-distance is: 8.252070983871818e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.63; acc: 0.78
Batch: 160; loss: 0.8; acc: 0.72
Batch: 180; loss: 0.64; acc: 0.77
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.58; acc: 0.77
Batch: 260; loss: 0.61; acc: 0.78
Batch: 280; loss: 0.67; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.81
Batch: 320; loss: 0.7; acc: 0.75
Batch: 340; loss: 0.65; acc: 0.8
Batch: 360; loss: 0.51; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.57; acc: 0.83
Batch: 420; loss: 0.53; acc: 0.83
Batch: 440; loss: 0.76; acc: 0.8
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.49; acc: 0.8
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.6; acc: 0.78
Batch: 580; loss: 0.72; acc: 0.84
Batch: 600; loss: 0.66; acc: 0.84
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.7; acc: 0.77
Batch: 660; loss: 0.57; acc: 0.81
Batch: 680; loss: 0.52; acc: 0.88
Batch: 700; loss: 0.62; acc: 0.84
Batch: 720; loss: 0.55; acc: 0.89
Batch: 740; loss: 0.54; acc: 0.8
Batch: 760; loss: 0.55; acc: 0.8
Batch: 780; loss: 0.52; acc: 0.83
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.139760908903554e-05
8.44842452352168e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.81; acc: 0.8
Batch: 140; loss: 0.18; acc: 0.97
Val Epoch over. val_loss: 0.5015637099173418; val_accuracy: 0.8442476114649682 

The current subspace-distance is: 8.44842452352168e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.66; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.89
Batch: 100; loss: 0.47; acc: 0.78
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.42; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.8; acc: 0.8
Batch: 200; loss: 0.53; acc: 0.78
Batch: 220; loss: 0.8; acc: 0.8
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.92
Batch: 280; loss: 0.61; acc: 0.84
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.66; acc: 0.75
Batch: 340; loss: 0.57; acc: 0.84
Batch: 360; loss: 0.51; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.65; acc: 0.78
Batch: 420; loss: 0.57; acc: 0.77
Batch: 440; loss: 0.62; acc: 0.81
Batch: 460; loss: 0.56; acc: 0.8
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.57; acc: 0.84
Batch: 520; loss: 0.54; acc: 0.8
Batch: 540; loss: 0.38; acc: 0.84
Batch: 560; loss: 0.51; acc: 0.88
Batch: 580; loss: 0.67; acc: 0.75
Batch: 600; loss: 0.71; acc: 0.77
Batch: 620; loss: 0.58; acc: 0.78
Batch: 640; loss: 0.56; acc: 0.84
Batch: 660; loss: 0.55; acc: 0.8
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.97; acc: 0.67
Batch: 760; loss: 0.64; acc: 0.81
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.3521535695181228e-05
7.797012585797347e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.22; acc: 0.98
Val Epoch over. val_loss: 0.5058045225917913; val_accuracy: 0.8413614649681529 

The current subspace-distance is: 7.797012585797347e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.81
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.8
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.45; acc: 0.84
Batch: 260; loss: 0.6; acc: 0.88
Batch: 280; loss: 0.76; acc: 0.77
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.92; acc: 0.72
Batch: 340; loss: 0.33; acc: 0.86
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.94
Batch: 420; loss: 0.85; acc: 0.78
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.55; acc: 0.8
Batch: 500; loss: 0.67; acc: 0.73
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.59; acc: 0.83
Batch: 560; loss: 0.66; acc: 0.83
Batch: 580; loss: 0.68; acc: 0.77
Batch: 600; loss: 0.62; acc: 0.78
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.54; acc: 0.83
Batch: 720; loss: 0.62; acc: 0.84
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.148247222066857e-05
8.499374416715e-06
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.2; acc: 0.98
Val Epoch over. val_loss: 0.5062328700427037; val_accuracy: 0.8398686305732485 

The current subspace-distance is: 8.499374416715e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.64; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.67; acc: 0.75
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.54; acc: 0.86
Batch: 220; loss: 0.68; acc: 0.75
Batch: 240; loss: 0.52; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.73; acc: 0.81
Batch: 300; loss: 0.6; acc: 0.8
Batch: 320; loss: 0.86; acc: 0.8
Batch: 340; loss: 0.54; acc: 0.8
Batch: 360; loss: 0.49; acc: 0.84
Batch: 380; loss: 0.71; acc: 0.78
Batch: 400; loss: 0.73; acc: 0.73
Batch: 420; loss: 0.55; acc: 0.88
Batch: 440; loss: 0.59; acc: 0.81
Batch: 460; loss: 0.6; acc: 0.78
Batch: 480; loss: 0.71; acc: 0.77
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.88; acc: 0.77
Batch: 540; loss: 0.46; acc: 0.83
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.65; acc: 0.84
Batch: 600; loss: 0.77; acc: 0.73
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.5; acc: 0.86
Batch: 680; loss: 0.76; acc: 0.86
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.57; acc: 0.75
Batch: 760; loss: 0.84; acc: 0.72
Batch: 780; loss: 0.6; acc: 0.73
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.225092612206936e-05
8.059754691203125e-06
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.5042971812995376; val_accuracy: 0.8407643312101911 

The current subspace-distance is: 8.059754691203125e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.75; acc: 0.78
Batch: 40; loss: 0.69; acc: 0.83
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.66; acc: 0.75
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.73; acc: 0.77
Batch: 220; loss: 0.43; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.6; acc: 0.81
Batch: 300; loss: 0.68; acc: 0.8
Batch: 320; loss: 0.69; acc: 0.8
Batch: 340; loss: 0.66; acc: 0.75
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.51; acc: 0.86
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.62; acc: 0.84
Batch: 460; loss: 0.61; acc: 0.81
Batch: 480; loss: 0.47; acc: 0.81
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.76; acc: 0.72
Batch: 640; loss: 0.5; acc: 0.78
Batch: 660; loss: 0.6; acc: 0.78
Batch: 680; loss: 0.51; acc: 0.81
Batch: 700; loss: 0.84; acc: 0.69
Batch: 720; loss: 0.45; acc: 0.8
Batch: 740; loss: 0.57; acc: 0.81
Batch: 760; loss: 0.49; acc: 0.8
Batch: 780; loss: 0.5; acc: 0.8
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.1134303096914664e-05
7.91851107351249e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.86; acc: 0.75
Batch: 140; loss: 0.2; acc: 0.97
Val Epoch over. val_loss: 0.5045862245331904; val_accuracy: 0.841859076433121 

The current subspace-distance is: 7.91851107351249e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.69; acc: 0.75
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.55; acc: 0.86
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 0.65; acc: 0.84
Batch: 140; loss: 0.55; acc: 0.86
Batch: 160; loss: 0.55; acc: 0.8
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.88
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.73; acc: 0.73
Batch: 320; loss: 0.8; acc: 0.7
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.78; acc: 0.8
Batch: 380; loss: 0.48; acc: 0.89
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.72; acc: 0.81
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.71; acc: 0.73
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.74; acc: 0.81
Batch: 540; loss: 0.58; acc: 0.81
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.59; acc: 0.83
Batch: 600; loss: 0.64; acc: 0.75
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.59; acc: 0.78
Batch: 680; loss: 0.57; acc: 0.83
Batch: 700; loss: 0.51; acc: 0.81
Batch: 720; loss: 0.58; acc: 0.77
Batch: 740; loss: 0.54; acc: 0.8
Batch: 760; loss: 0.58; acc: 0.88
Batch: 780; loss: 0.61; acc: 0.8
Train Epoch over. train_loss: 0.57; train_accuracy: 0.82 

2.2394418920157477e-05
8.449907909380272e-06
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.5072770231658486; val_accuracy: 0.8398686305732485 

The current subspace-distance is: 8.449907909380272e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.94
Batch: 40; loss: 0.57; acc: 0.78
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.59; acc: 0.83
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.81
Batch: 200; loss: 0.5; acc: 0.83
Batch: 220; loss: 0.58; acc: 0.78
Batch: 240; loss: 0.62; acc: 0.81
Batch: 260; loss: 0.67; acc: 0.8
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.65; acc: 0.81
Batch: 320; loss: 0.94; acc: 0.59
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.73; acc: 0.72
Batch: 380; loss: 0.79; acc: 0.73
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.64; acc: 0.78
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.83
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.68; acc: 0.81
Batch: 560; loss: 0.64; acc: 0.8
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.8
Batch: 620; loss: 0.96; acc: 0.69
Batch: 640; loss: 0.54; acc: 0.8
Batch: 660; loss: 0.85; acc: 0.81
Batch: 680; loss: 0.72; acc: 0.88
Batch: 700; loss: 0.55; acc: 0.83
Batch: 720; loss: 0.49; acc: 0.8
Batch: 740; loss: 0.66; acc: 0.8
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.8; acc: 0.8
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.2115824322099797e-05
8.173316928150598e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4994579595365342; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 8.173316928150598e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.66; acc: 0.81
Batch: 40; loss: 0.55; acc: 0.81
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.75
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.62; acc: 0.78
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.58; acc: 0.84
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.91; acc: 0.72
Batch: 420; loss: 0.51; acc: 0.83
Batch: 440; loss: 0.58; acc: 0.83
Batch: 460; loss: 0.47; acc: 0.83
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.9; acc: 0.7
Batch: 520; loss: 0.52; acc: 0.88
Batch: 540; loss: 0.69; acc: 0.78
Batch: 560; loss: 0.73; acc: 0.8
Batch: 580; loss: 0.55; acc: 0.77
Batch: 600; loss: 0.72; acc: 0.81
Batch: 620; loss: 0.76; acc: 0.73
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.83
Batch: 680; loss: 0.57; acc: 0.81
Batch: 700; loss: 0.52; acc: 0.88
Batch: 720; loss: 0.58; acc: 0.8
Batch: 740; loss: 0.62; acc: 0.75
Batch: 760; loss: 0.63; acc: 0.81
Batch: 780; loss: 0.42; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.1797697627334855e-05
8.743279067857657e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.82; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49968081095795724; val_accuracy: 0.8449442675159236 

The current subspace-distance is: 8.743279067857657e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.55; acc: 0.91
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.58; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.55; acc: 0.8
Batch: 180; loss: 0.79; acc: 0.75
Batch: 200; loss: 0.5; acc: 0.89
Batch: 220; loss: 0.45; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.66; acc: 0.86
Batch: 280; loss: 0.7; acc: 0.78
Batch: 300; loss: 0.6; acc: 0.8
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.53; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.81
Batch: 420; loss: 0.54; acc: 0.8
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.53; acc: 0.84
Batch: 560; loss: 1.03; acc: 0.69
Batch: 580; loss: 0.53; acc: 0.81
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.61; acc: 0.81
Batch: 640; loss: 0.59; acc: 0.78
Batch: 660; loss: 0.53; acc: 0.8
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.44; acc: 0.83
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.2789354261476547e-05
7.800633284205105e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.5012230315975322; val_accuracy: 0.8449442675159236 

The current subspace-distance is: 7.800633284205105e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.78
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.64; acc: 0.75
Batch: 220; loss: 0.56; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.84
Batch: 260; loss: 0.79; acc: 0.83
Batch: 280; loss: 0.54; acc: 0.86
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.64; acc: 0.83
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.65; acc: 0.75
Batch: 420; loss: 0.44; acc: 0.83
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.78
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.48; acc: 0.8
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.55; acc: 0.77
Batch: 580; loss: 0.89; acc: 0.7
Batch: 600; loss: 0.64; acc: 0.83
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.55; acc: 0.81
Batch: 700; loss: 0.6; acc: 0.84
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.84
Batch: 760; loss: 0.71; acc: 0.78
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.1186018784646876e-05
8.080093721218873e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.5014747578626985; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 8.080093721218873e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.94
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.65; acc: 0.83
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.54; acc: 0.8
Batch: 140; loss: 0.46; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.69; acc: 0.83
Batch: 200; loss: 0.62; acc: 0.77
Batch: 220; loss: 0.45; acc: 0.78
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.65; acc: 0.72
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.72; acc: 0.72
Batch: 320; loss: 0.84; acc: 0.75
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.78; acc: 0.75
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.52; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.56; acc: 0.84
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.61; acc: 0.75
Batch: 520; loss: 0.8; acc: 0.77
Batch: 540; loss: 0.65; acc: 0.83
Batch: 560; loss: 0.35; acc: 0.94
Batch: 580; loss: 0.86; acc: 0.73
Batch: 600; loss: 0.48; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.83
Batch: 640; loss: 0.41; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.6; acc: 0.86
Batch: 700; loss: 0.54; acc: 0.81
Batch: 720; loss: 0.69; acc: 0.8
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.7; acc: 0.8
Batch: 780; loss: 0.53; acc: 0.83
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.1734236725023948e-05
7.821721737855114e-06
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.81; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49995559074316814; val_accuracy: 0.8457404458598726 

The current subspace-distance is: 7.821721737855114e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.62; acc: 0.81
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.6; acc: 0.86
Batch: 60; loss: 0.53; acc: 0.86
Batch: 80; loss: 0.66; acc: 0.81
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.73; acc: 0.81
Batch: 140; loss: 0.4; acc: 0.84
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.59; acc: 0.81
Batch: 200; loss: 0.94; acc: 0.75
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.34; acc: 0.84
Batch: 260; loss: 0.71; acc: 0.84
Batch: 280; loss: 0.82; acc: 0.72
Batch: 300; loss: 0.65; acc: 0.8
Batch: 320; loss: 0.54; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.81
Batch: 360; loss: 0.65; acc: 0.75
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.6; acc: 0.81
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.5; acc: 0.83
Batch: 480; loss: 0.41; acc: 0.81
Batch: 500; loss: 0.58; acc: 0.8
Batch: 520; loss: 0.64; acc: 0.77
Batch: 540; loss: 0.61; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.78; acc: 0.8
Batch: 600; loss: 0.67; acc: 0.78
Batch: 620; loss: 0.64; acc: 0.73
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.57; acc: 0.78
Batch: 680; loss: 0.6; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.65; acc: 0.83
Batch: 740; loss: 0.55; acc: 0.8
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.49; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.175141344196163e-05
7.484597517759539e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.82; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4989603599355479; val_accuracy: 0.8444466560509554 

The current subspace-distance is: 7.484597517759539e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.63; acc: 0.78
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.65; acc: 0.83
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.6; acc: 0.81
Batch: 160; loss: 0.89; acc: 0.73
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.66; acc: 0.78
Batch: 220; loss: 0.75; acc: 0.8
Batch: 240; loss: 0.6; acc: 0.78
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.52; acc: 0.86
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.93; acc: 0.75
Batch: 380; loss: 0.39; acc: 0.84
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 1.0; acc: 0.77
Batch: 460; loss: 0.56; acc: 0.81
Batch: 480; loss: 0.59; acc: 0.83
Batch: 500; loss: 0.46; acc: 0.94
Batch: 520; loss: 0.6; acc: 0.84
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.47; acc: 0.89
Batch: 580; loss: 0.53; acc: 0.83
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.66; acc: 0.81
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.61; acc: 0.83
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.59; acc: 0.8
Batch: 740; loss: 0.62; acc: 0.83
Batch: 760; loss: 0.47; acc: 0.88
Batch: 780; loss: 0.69; acc: 0.77
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.110367131535895e-05
7.96168933447916e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.98
Val Epoch over. val_loss: 0.5045169248322773; val_accuracy: 0.84265525477707 

The current subspace-distance is: 7.96168933447916e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.75
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.62; acc: 0.77
Batch: 80; loss: 0.68; acc: 0.72
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.63; acc: 0.83
Batch: 160; loss: 0.64; acc: 0.83
Batch: 180; loss: 0.59; acc: 0.78
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.7; acc: 0.77
Batch: 260; loss: 0.74; acc: 0.78
Batch: 280; loss: 0.65; acc: 0.77
Batch: 300; loss: 0.54; acc: 0.88
Batch: 320; loss: 0.66; acc: 0.8
Batch: 340; loss: 0.78; acc: 0.78
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.77; acc: 0.75
Batch: 400; loss: 0.59; acc: 0.81
Batch: 420; loss: 0.62; acc: 0.77
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.56; acc: 0.83
Batch: 480; loss: 0.58; acc: 0.78
Batch: 500; loss: 0.52; acc: 0.86
Batch: 520; loss: 0.47; acc: 0.83
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.71; acc: 0.78
Batch: 580; loss: 0.54; acc: 0.91
Batch: 600; loss: 0.55; acc: 0.81
Batch: 620; loss: 0.53; acc: 0.86
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.69; acc: 0.75
Batch: 700; loss: 0.66; acc: 0.8
Batch: 720; loss: 0.46; acc: 0.86
Batch: 740; loss: 0.67; acc: 0.78
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.69; acc: 0.75
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.0200965082040057e-05
7.986653145053424e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.84; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4993488650982547; val_accuracy: 0.8451433121019108 

The current subspace-distance is: 7.986653145053424e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.61; acc: 0.89
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.81
Batch: 80; loss: 0.61; acc: 0.77
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.62; acc: 0.8
Batch: 160; loss: 0.54; acc: 0.89
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.63; acc: 0.84
Batch: 220; loss: 0.71; acc: 0.75
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 0.56; acc: 0.84
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.49; acc: 0.81
Batch: 320; loss: 0.52; acc: 0.77
Batch: 340; loss: 0.67; acc: 0.8
Batch: 360; loss: 0.63; acc: 0.78
Batch: 380; loss: 0.63; acc: 0.78
Batch: 400; loss: 0.73; acc: 0.77
Batch: 420; loss: 0.64; acc: 0.8
Batch: 440; loss: 0.66; acc: 0.81
Batch: 460; loss: 0.64; acc: 0.81
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.63; acc: 0.81
Batch: 520; loss: 0.86; acc: 0.8
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.59; acc: 0.83
Batch: 660; loss: 0.7; acc: 0.83
Batch: 680; loss: 0.67; acc: 0.72
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.61; acc: 0.8
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.5; acc: 0.81
Batch: 780; loss: 0.93; acc: 0.7
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.198041147494223e-05
8.309556505992077e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49818576094071576; val_accuracy: 0.8442476114649682 

The current subspace-distance is: 8.309556505992077e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.69; acc: 0.73
Batch: 40; loss: 0.47; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.72; acc: 0.75
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.5; acc: 0.8
Batch: 180; loss: 0.62; acc: 0.81
Batch: 200; loss: 0.61; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.84
Batch: 240; loss: 0.75; acc: 0.72
Batch: 260; loss: 0.67; acc: 0.77
Batch: 280; loss: 0.55; acc: 0.83
Batch: 300; loss: 0.64; acc: 0.77
Batch: 320; loss: 0.87; acc: 0.77
Batch: 340; loss: 0.58; acc: 0.8
Batch: 360; loss: 0.58; acc: 0.8
Batch: 380; loss: 0.74; acc: 0.8
Batch: 400; loss: 0.46; acc: 0.86
Batch: 420; loss: 0.57; acc: 0.77
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.58; acc: 0.83
Batch: 480; loss: 0.49; acc: 0.84
Batch: 500; loss: 0.7; acc: 0.77
Batch: 520; loss: 0.67; acc: 0.8
Batch: 540; loss: 0.59; acc: 0.86
Batch: 560; loss: 0.66; acc: 0.77
Batch: 580; loss: 0.42; acc: 0.91
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.77; acc: 0.75
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.54; acc: 0.8
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.65; acc: 0.78
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.1439305783133022e-05
9.024844075611327e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4990482693834669; val_accuracy: 0.8460390127388535 

The current subspace-distance is: 9.024844075611327e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.84
Batch: 20; loss: 0.68; acc: 0.83
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.68; acc: 0.75
Batch: 100; loss: 0.6; acc: 0.83
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.83
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.69; acc: 0.77
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.81
Batch: 240; loss: 0.55; acc: 0.78
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.73; acc: 0.78
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.49; acc: 0.83
Batch: 380; loss: 0.62; acc: 0.77
Batch: 400; loss: 0.6; acc: 0.81
Batch: 420; loss: 0.51; acc: 0.8
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.76; acc: 0.8
Batch: 500; loss: 0.77; acc: 0.78
Batch: 520; loss: 0.51; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.66; acc: 0.88
Batch: 600; loss: 0.69; acc: 0.78
Batch: 620; loss: 0.67; acc: 0.83
Batch: 640; loss: 0.68; acc: 0.81
Batch: 660; loss: 0.39; acc: 0.83
Batch: 680; loss: 0.52; acc: 0.8
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.58; acc: 0.83
Batch: 740; loss: 0.68; acc: 0.8
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.47; acc: 0.92
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.1815019863424823e-05
8.31589841254754e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.84; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49839949769199277; val_accuracy: 0.8457404458598726 

The current subspace-distance is: 8.31589841254754e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.8
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.65; acc: 0.81
Batch: 160; loss: 0.54; acc: 0.88
Batch: 180; loss: 0.39; acc: 0.84
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.63; acc: 0.78
Batch: 240; loss: 0.68; acc: 0.84
Batch: 260; loss: 0.66; acc: 0.78
Batch: 280; loss: 0.61; acc: 0.86
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.59; acc: 0.84
Batch: 340; loss: 0.59; acc: 0.8
Batch: 360; loss: 0.46; acc: 0.86
Batch: 380; loss: 0.62; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.46; acc: 0.81
Batch: 440; loss: 0.67; acc: 0.75
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.65; acc: 0.78
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.6; acc: 0.78
Batch: 580; loss: 0.86; acc: 0.72
Batch: 600; loss: 0.54; acc: 0.86
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.57; acc: 0.77
Batch: 680; loss: 0.79; acc: 0.78
Batch: 700; loss: 1.0; acc: 0.73
Batch: 720; loss: 0.6; acc: 0.81
Batch: 740; loss: 0.6; acc: 0.8
Batch: 760; loss: 0.63; acc: 0.78
Batch: 780; loss: 0.57; acc: 0.8
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.298789877386298e-05
9.272002898796927e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49948407614686685; val_accuracy: 0.8468351910828026 

The current subspace-distance is: 9.272002898796927e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.73
Batch: 40; loss: 0.94; acc: 0.75
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.55; acc: 0.86
Batch: 100; loss: 0.89; acc: 0.72
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.62; acc: 0.78
Batch: 160; loss: 0.67; acc: 0.81
Batch: 180; loss: 0.58; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.83
Batch: 220; loss: 0.49; acc: 0.83
Batch: 240; loss: 0.66; acc: 0.83
Batch: 260; loss: 0.69; acc: 0.78
Batch: 280; loss: 0.4; acc: 0.83
Batch: 300; loss: 0.66; acc: 0.81
Batch: 320; loss: 0.68; acc: 0.83
Batch: 340; loss: 0.78; acc: 0.83
Batch: 360; loss: 0.55; acc: 0.83
Batch: 380; loss: 0.68; acc: 0.8
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.82; acc: 0.77
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.55; acc: 0.83
Batch: 480; loss: 0.57; acc: 0.84
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.87; acc: 0.7
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.81; acc: 0.69
Batch: 600; loss: 0.59; acc: 0.81
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.5; acc: 0.86
Batch: 680; loss: 0.48; acc: 0.86
Batch: 700; loss: 0.7; acc: 0.75
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.79; acc: 0.77
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.2790774892200716e-05
8.618673746241257e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.81
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4983016091167547; val_accuracy: 0.8462380573248408 

The current subspace-distance is: 8.618673746241257e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.62; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.91
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.65; acc: 0.8
Batch: 160; loss: 0.59; acc: 0.88
Batch: 180; loss: 0.62; acc: 0.81
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.72; acc: 0.75
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.66; acc: 0.83
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.68; acc: 0.78
Batch: 460; loss: 0.51; acc: 0.83
Batch: 480; loss: 0.46; acc: 0.8
Batch: 500; loss: 0.67; acc: 0.78
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.53; acc: 0.88
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.72; acc: 0.73
Batch: 620; loss: 0.57; acc: 0.86
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.5; acc: 0.81
Batch: 680; loss: 0.64; acc: 0.81
Batch: 700; loss: 0.49; acc: 0.84
Batch: 720; loss: 0.67; acc: 0.8
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.61; acc: 0.78
Batch: 780; loss: 0.59; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.2484729925054125e-05
8.751650057092775e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4981853215937402; val_accuracy: 0.8459394904458599 

The current subspace-distance is: 8.751650057092775e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.8
Batch: 20; loss: 0.77; acc: 0.78
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.64; acc: 0.8
Batch: 100; loss: 0.52; acc: 0.83
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.59; acc: 0.78
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.71; acc: 0.83
Batch: 260; loss: 0.41; acc: 0.83
Batch: 280; loss: 0.65; acc: 0.83
Batch: 300; loss: 0.69; acc: 0.78
Batch: 320; loss: 0.56; acc: 0.83
Batch: 340; loss: 0.79; acc: 0.77
Batch: 360; loss: 0.58; acc: 0.88
Batch: 380; loss: 0.52; acc: 0.8
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.76; acc: 0.8
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.78; acc: 0.78
Batch: 480; loss: 0.66; acc: 0.77
Batch: 500; loss: 0.71; acc: 0.81
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.57; acc: 0.81
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.66; acc: 0.75
Batch: 600; loss: 0.63; acc: 0.84
Batch: 620; loss: 0.72; acc: 0.78
Batch: 640; loss: 0.9; acc: 0.77
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.48; acc: 0.8
Batch: 740; loss: 0.6; acc: 0.84
Batch: 760; loss: 0.67; acc: 0.75
Batch: 780; loss: 0.58; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.1574263882939704e-05
9.009228961076587e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4987416895711498; val_accuracy: 0.8442476114649682 

The current subspace-distance is: 9.009228961076587e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.59; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.75
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.76; acc: 0.8
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.56; acc: 0.84
Batch: 160; loss: 0.58; acc: 0.83
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.94; acc: 0.7
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.64; acc: 0.77
Batch: 260; loss: 0.54; acc: 0.78
Batch: 280; loss: 0.69; acc: 0.8
Batch: 300; loss: 0.54; acc: 0.84
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 0.91; acc: 0.66
Batch: 360; loss: 0.75; acc: 0.73
Batch: 380; loss: 0.56; acc: 0.8
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.52; acc: 0.78
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.63; acc: 0.84
Batch: 520; loss: 0.5; acc: 0.81
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.54; acc: 0.8
Batch: 580; loss: 0.54; acc: 0.89
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.81
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.94
Batch: 720; loss: 0.5; acc: 0.86
Batch: 740; loss: 0.66; acc: 0.83
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.2175427147885785e-05
7.251200258906465e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49891145413468596; val_accuracy: 0.8463375796178344 

The current subspace-distance is: 7.251200258906465e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.49; acc: 0.83
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.64; acc: 0.78
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.64; acc: 0.83
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.6; acc: 0.8
Batch: 260; loss: 0.52; acc: 0.81
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.61; acc: 0.84
Batch: 360; loss: 0.55; acc: 0.8
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.71; acc: 0.75
Batch: 440; loss: 0.46; acc: 0.83
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.69; acc: 0.78
Batch: 500; loss: 0.57; acc: 0.83
Batch: 520; loss: 0.46; acc: 0.81
Batch: 540; loss: 0.58; acc: 0.84
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.59; acc: 0.75
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.88
Batch: 660; loss: 0.57; acc: 0.88
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.5; acc: 0.86
Batch: 720; loss: 0.48; acc: 0.83
Batch: 740; loss: 0.59; acc: 0.81
Batch: 760; loss: 0.52; acc: 0.78
Batch: 780; loss: 0.5; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.220215719717089e-05
7.39546067052288e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49864400230395567; val_accuracy: 0.8455414012738853 

The current subspace-distance is: 7.39546067052288e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.43; acc: 0.84
Batch: 60; loss: 0.98; acc: 0.73
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.83; acc: 0.73
Batch: 120; loss: 0.58; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.73; acc: 0.78
Batch: 180; loss: 0.66; acc: 0.8
Batch: 200; loss: 0.72; acc: 0.81
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.58; acc: 0.84
Batch: 280; loss: 1.02; acc: 0.67
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.64; acc: 0.77
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.82; acc: 0.83
Batch: 420; loss: 0.61; acc: 0.77
Batch: 440; loss: 0.67; acc: 0.81
Batch: 460; loss: 0.59; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.77; acc: 0.81
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.59; acc: 0.86
Batch: 580; loss: 0.68; acc: 0.8
Batch: 600; loss: 0.56; acc: 0.8
Batch: 620; loss: 0.6; acc: 0.78
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.62; acc: 0.78
Batch: 680; loss: 0.5; acc: 0.81
Batch: 700; loss: 0.45; acc: 0.89
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.53; acc: 0.86
Batch: 760; loss: 0.48; acc: 0.81
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

2.2649475795333274e-05
7.435528004862135e-06
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49923703444611495; val_accuracy: 0.8461385350318471 

The current subspace-distance is: 7.435528004862135e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.78
Batch: 20; loss: 0.55; acc: 0.89
Batch: 40; loss: 0.56; acc: 0.8
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.69; acc: 0.77
Batch: 160; loss: 0.58; acc: 0.81
Batch: 180; loss: 0.79; acc: 0.77
Batch: 200; loss: 0.63; acc: 0.84
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.5; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.92
Batch: 280; loss: 0.6; acc: 0.78
Batch: 300; loss: 0.65; acc: 0.83
Batch: 320; loss: 0.65; acc: 0.84
Batch: 340; loss: 0.54; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.83
Batch: 440; loss: 0.7; acc: 0.8
Batch: 460; loss: 0.55; acc: 0.8
Batch: 480; loss: 0.62; acc: 0.83
Batch: 500; loss: 0.61; acc: 0.78
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.56; acc: 0.86
Batch: 620; loss: 0.71; acc: 0.78
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.75; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.59; acc: 0.77
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.66; acc: 0.81
Batch: 760; loss: 0.7; acc: 0.8
Batch: 780; loss: 0.71; acc: 0.84
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.1985790226608515e-05
8.457988769805524e-06
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.4994509199242683; val_accuracy: 0.8453423566878981 

The current subspace-distance is: 8.457988769805524e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.62; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.62; acc: 0.75
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.7; acc: 0.83
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.73; acc: 0.8
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.6; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.94; acc: 0.72
Batch: 340; loss: 0.46; acc: 0.84
Batch: 360; loss: 0.71; acc: 0.81
Batch: 380; loss: 0.54; acc: 0.88
Batch: 400; loss: 0.52; acc: 0.81
Batch: 420; loss: 0.6; acc: 0.78
Batch: 440; loss: 0.61; acc: 0.86
Batch: 460; loss: 0.63; acc: 0.81
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.68; acc: 0.81
Batch: 540; loss: 0.76; acc: 0.77
Batch: 560; loss: 0.74; acc: 0.81
Batch: 580; loss: 0.55; acc: 0.81
Batch: 600; loss: 0.93; acc: 0.77
Batch: 620; loss: 0.53; acc: 0.78
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.59; acc: 0.75
Batch: 680; loss: 0.62; acc: 0.78
Batch: 700; loss: 0.62; acc: 0.83
Batch: 720; loss: 0.75; acc: 0.78
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.89
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.235226747870911e-05
7.5444718277140055e-06
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.97
Val Epoch over. val_loss: 0.49858789601523407; val_accuracy: 0.845640923566879 

The current subspace-distance is: 7.5444718277140055e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_125_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 31729
elements in E: 6663900
fraction nonzero: 0.004761325950269362
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.28; acc: 0.11
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.03
Batch: 380; loss: 2.28; acc: 0.09
Batch: 400; loss: 2.28; acc: 0.09
Batch: 420; loss: 2.28; acc: 0.14
Batch: 440; loss: 2.27; acc: 0.11
Batch: 460; loss: 2.28; acc: 0.06
Batch: 480; loss: 2.28; acc: 0.17
Batch: 500; loss: 2.27; acc: 0.23
Batch: 520; loss: 2.28; acc: 0.17
Batch: 540; loss: 2.27; acc: 0.25
Batch: 560; loss: 2.26; acc: 0.36
Batch: 580; loss: 2.26; acc: 0.42
Batch: 600; loss: 2.26; acc: 0.33
Batch: 620; loss: 2.26; acc: 0.3
Batch: 640; loss: 2.25; acc: 0.42
Batch: 660; loss: 2.25; acc: 0.33
Batch: 680; loss: 2.25; acc: 0.27
Batch: 700; loss: 2.24; acc: 0.39
Batch: 720; loss: 2.24; acc: 0.33
Batch: 740; loss: 2.21; acc: 0.45
Batch: 760; loss: 2.21; acc: 0.36
Batch: 780; loss: 2.2; acc: 0.38
Train Epoch over. train_loss: 2.28; train_accuracy: 0.19 

5.1798238018818665e-06
1.7172214938909747e-06
Batch: 0; loss: 2.19; acc: 0.45
Batch: 20; loss: 2.19; acc: 0.39
Batch: 40; loss: 2.17; acc: 0.48
Batch: 60; loss: 2.19; acc: 0.45
Batch: 80; loss: 2.21; acc: 0.34
Batch: 100; loss: 2.18; acc: 0.39
Batch: 120; loss: 2.2; acc: 0.42
Batch: 140; loss: 2.19; acc: 0.44
Val Epoch over. val_loss: 2.1941937747274993; val_accuracy: 0.37579617834394907 

The current subspace-distance is: 1.7172214938909747e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.16; acc: 0.55
Batch: 20; loss: 2.17; acc: 0.47
Batch: 40; loss: 2.19; acc: 0.27
Batch: 60; loss: 2.14; acc: 0.41
Batch: 80; loss: 2.14; acc: 0.23
Batch: 100; loss: 2.04; acc: 0.45
Batch: 120; loss: 2.0; acc: 0.42
Batch: 140; loss: 1.94; acc: 0.42
Batch: 160; loss: 1.76; acc: 0.55
Batch: 180; loss: 1.45; acc: 0.61
Batch: 200; loss: 1.25; acc: 0.59
Batch: 220; loss: 1.05; acc: 0.7
Batch: 240; loss: 0.78; acc: 0.78
Batch: 260; loss: 1.03; acc: 0.66
Batch: 280; loss: 0.93; acc: 0.7
Batch: 300; loss: 0.88; acc: 0.78
Batch: 320; loss: 0.92; acc: 0.67
Batch: 340; loss: 0.73; acc: 0.78
Batch: 360; loss: 0.77; acc: 0.77
Batch: 380; loss: 0.76; acc: 0.8
Batch: 400; loss: 0.65; acc: 0.77
Batch: 420; loss: 0.62; acc: 0.81
Batch: 440; loss: 0.7; acc: 0.84
Batch: 460; loss: 0.69; acc: 0.8
Batch: 480; loss: 0.55; acc: 0.81
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.65; acc: 0.81
Batch: 540; loss: 0.58; acc: 0.83
Batch: 560; loss: 0.62; acc: 0.78
Batch: 580; loss: 0.48; acc: 0.83
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.9; acc: 0.7
Batch: 640; loss: 0.49; acc: 0.89
Batch: 660; loss: 0.61; acc: 0.77
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.65; acc: 0.86
Batch: 720; loss: 0.51; acc: 0.83
Batch: 740; loss: 0.73; acc: 0.8
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 1.04; train_accuracy: 0.69 

1.5392830391647294e-05
5.765018158854218e-06
Batch: 0; loss: 0.58; acc: 0.78
Batch: 20; loss: 0.85; acc: 0.77
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.65; acc: 0.86
Batch: 120; loss: 0.91; acc: 0.77
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.543211866715911; val_accuracy: 0.8294187898089171 

The current subspace-distance is: 5.765018158854218e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.85; acc: 0.62
Batch: 20; loss: 0.74; acc: 0.77
Batch: 40; loss: 0.69; acc: 0.75
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.65; acc: 0.84
Batch: 100; loss: 0.75; acc: 0.81
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.44; acc: 0.88
Batch: 180; loss: 0.56; acc: 0.81
Batch: 200; loss: 0.64; acc: 0.8
Batch: 220; loss: 0.74; acc: 0.78
Batch: 240; loss: 0.61; acc: 0.78
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.74; acc: 0.78
Batch: 320; loss: 0.63; acc: 0.75
Batch: 340; loss: 0.61; acc: 0.78
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.68; acc: 0.86
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.52; acc: 0.84
Batch: 460; loss: 0.72; acc: 0.81
Batch: 480; loss: 0.55; acc: 0.81
Batch: 500; loss: 0.52; acc: 0.78
Batch: 520; loss: 0.53; acc: 0.8
Batch: 540; loss: 1.07; acc: 0.75
Batch: 560; loss: 0.59; acc: 0.77
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.64; acc: 0.77
Batch: 620; loss: 0.58; acc: 0.86
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.77; acc: 0.78
Batch: 760; loss: 0.72; acc: 0.8
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

1.9056251403526403e-05
6.4073537942022085e-06
Batch: 0; loss: 0.67; acc: 0.73
Batch: 20; loss: 0.71; acc: 0.72
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.72; acc: 0.72
Batch: 80; loss: 0.45; acc: 0.8
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 1.2; acc: 0.69
Batch: 140; loss: 0.47; acc: 0.8
Val Epoch over. val_loss: 0.6592862573778553; val_accuracy: 0.7859275477707006 

The current subspace-distance is: 6.4073537942022085e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.03; acc: 0.73
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.6; acc: 0.88
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.43; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.67; acc: 0.8
Batch: 180; loss: 0.43; acc: 0.78
Batch: 200; loss: 0.59; acc: 0.86
Batch: 220; loss: 0.63; acc: 0.81
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.8; acc: 0.77
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.56; acc: 0.84
Batch: 360; loss: 0.61; acc: 0.78
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.48; acc: 0.78
Batch: 420; loss: 0.7; acc: 0.77
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.5; acc: 0.86
Batch: 480; loss: 0.64; acc: 0.78
Batch: 500; loss: 0.39; acc: 0.81
Batch: 520; loss: 0.55; acc: 0.88
Batch: 540; loss: 0.72; acc: 0.77
Batch: 560; loss: 0.57; acc: 0.86
Batch: 580; loss: 0.64; acc: 0.78
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.68; acc: 0.77
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.71; acc: 0.8
Batch: 780; loss: 0.65; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.83 

1.8753547919914126e-05
5.954646894679172e-06
Batch: 0; loss: 0.94; acc: 0.66
Batch: 20; loss: 0.79; acc: 0.67
Batch: 40; loss: 0.55; acc: 0.81
Batch: 60; loss: 1.27; acc: 0.64
Batch: 80; loss: 0.66; acc: 0.81
Batch: 100; loss: 0.88; acc: 0.77
Batch: 120; loss: 1.35; acc: 0.62
Batch: 140; loss: 0.54; acc: 0.73
Val Epoch over. val_loss: 0.7780299837801866; val_accuracy: 0.7492038216560509 

The current subspace-distance is: 5.954646894679172e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.33; acc: 0.59
Batch: 20; loss: 0.57; acc: 0.78
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.68; acc: 0.8
Batch: 100; loss: 0.53; acc: 0.78
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.42; acc: 0.83
Batch: 160; loss: 0.42; acc: 0.88
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.78; acc: 0.73
Batch: 220; loss: 0.59; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.84
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.49; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.6; acc: 0.8
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.42; acc: 0.8
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.59; acc: 0.81
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.65; acc: 0.77
Batch: 600; loss: 0.22; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.52; acc: 0.81
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.9727867766050622e-05
6.298319021880161e-06
Batch: 0; loss: 0.62; acc: 0.77
Batch: 20; loss: 0.73; acc: 0.75
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 1.05; acc: 0.67
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.75; acc: 0.81
Batch: 120; loss: 1.21; acc: 0.72
Batch: 140; loss: 0.62; acc: 0.7
Val Epoch over. val_loss: 0.6637741120377924; val_accuracy: 0.7868232484076433 

The current subspace-distance is: 6.298319021880161e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.78
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.63; acc: 0.81
Batch: 160; loss: 0.53; acc: 0.81
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.43; acc: 0.81
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.68; acc: 0.81
Batch: 280; loss: 0.54; acc: 0.83
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.63; acc: 0.77
Batch: 360; loss: 0.61; acc: 0.75
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.53; acc: 0.8
Batch: 420; loss: 0.56; acc: 0.81
Batch: 440; loss: 0.55; acc: 0.83
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.51; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.83
Batch: 560; loss: 0.52; acc: 0.84
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.52; acc: 0.84
Batch: 640; loss: 0.67; acc: 0.78
Batch: 660; loss: 0.63; acc: 0.83
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.69; acc: 0.81
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.6; acc: 0.8
Batch: 760; loss: 0.79; acc: 0.78
Batch: 780; loss: 0.57; acc: 0.83
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.994677586480975e-05
7.126629952836083e-06
Batch: 0; loss: 0.51; acc: 0.75
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.3; acc: 0.95
Batch: 60; loss: 0.88; acc: 0.78
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.89
Batch: 120; loss: 1.08; acc: 0.73
Batch: 140; loss: 0.32; acc: 0.84
Val Epoch over. val_loss: 0.5362310276669302; val_accuracy: 0.8279259554140127 

The current subspace-distance is: 7.126629952836083e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.78
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.83
Batch: 180; loss: 0.41; acc: 0.8
Batch: 200; loss: 0.56; acc: 0.84
Batch: 220; loss: 0.62; acc: 0.88
Batch: 240; loss: 0.51; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.81
Batch: 280; loss: 0.5; acc: 0.86
Batch: 300; loss: 0.56; acc: 0.78
Batch: 320; loss: 0.89; acc: 0.8
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.7; acc: 0.84
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.58; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.78
Batch: 560; loss: 0.23; acc: 0.98
Batch: 580; loss: 0.49; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.61; acc: 0.78
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.49; acc: 0.84
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.98820107470965e-05
6.2410449572780635e-06
Batch: 0; loss: 0.61; acc: 0.83
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 0.91; acc: 0.75
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.5505143260690057; val_accuracy: 0.8290207006369427 

The current subspace-distance is: 6.2410449572780635e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.68; acc: 0.78
Batch: 20; loss: 0.65; acc: 0.84
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.56; acc: 0.77
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.7; acc: 0.83
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.78
Batch: 160; loss: 0.84; acc: 0.75
Batch: 180; loss: 0.62; acc: 0.78
Batch: 200; loss: 0.56; acc: 0.77
Batch: 220; loss: 0.59; acc: 0.73
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.46; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.54; acc: 0.78
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.44; acc: 0.83
Batch: 480; loss: 0.49; acc: 0.81
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.59; acc: 0.75
Batch: 540; loss: 0.57; acc: 0.8
Batch: 560; loss: 0.64; acc: 0.78
Batch: 580; loss: 0.33; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.54; acc: 0.83
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.96; acc: 0.73
Batch: 700; loss: 0.76; acc: 0.81
Batch: 720; loss: 0.52; acc: 0.86
Batch: 740; loss: 0.58; acc: 0.8
Batch: 760; loss: 0.74; acc: 0.83
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.9414539565332234e-05
6.3981374296417926e-06
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.61; acc: 0.84
Batch: 120; loss: 0.92; acc: 0.72
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.4858346830602664; val_accuracy: 0.846437101910828 

The current subspace-distance is: 6.3981374296417926e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.8
Batch: 20; loss: 0.59; acc: 0.78
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.55; acc: 0.84
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.91
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.73; acc: 0.81
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.61; acc: 0.78
Batch: 400; loss: 0.4; acc: 0.83
Batch: 420; loss: 0.33; acc: 0.94
Batch: 440; loss: 0.73; acc: 0.81
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.7; acc: 0.8
Batch: 500; loss: 0.46; acc: 0.83
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.63; acc: 0.83
Batch: 560; loss: 0.49; acc: 0.88
Batch: 580; loss: 0.66; acc: 0.78
Batch: 600; loss: 0.73; acc: 0.73
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.82; acc: 0.72
Batch: 720; loss: 0.87; acc: 0.78
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.65; acc: 0.84
Batch: 780; loss: 0.52; acc: 0.81
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.95010125025874e-05
6.866402145533357e-06
Batch: 0; loss: 0.7; acc: 0.7
Batch: 20; loss: 0.67; acc: 0.75
Batch: 40; loss: 0.37; acc: 0.94
Batch: 60; loss: 0.93; acc: 0.73
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.63; acc: 0.89
Batch: 120; loss: 0.97; acc: 0.69
Batch: 140; loss: 0.22; acc: 0.92
Val Epoch over. val_loss: 0.6463993334086837; val_accuracy: 0.7999601910828026 

The current subspace-distance is: 6.866402145533357e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.63; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.44; acc: 0.81
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.81
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.7; acc: 0.77
Batch: 260; loss: 0.58; acc: 0.84
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.47; acc: 0.77
Batch: 380; loss: 0.51; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.73; acc: 0.81
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.51; acc: 0.86
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.52; acc: 0.83
Batch: 560; loss: 0.58; acc: 0.83
Batch: 580; loss: 0.88; acc: 0.8
Batch: 600; loss: 0.73; acc: 0.75
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.78; acc: 0.75
Batch: 660; loss: 0.71; acc: 0.83
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.55; acc: 0.86
Batch: 740; loss: 0.53; acc: 0.8
Batch: 760; loss: 0.45; acc: 0.81
Batch: 780; loss: 0.82; acc: 0.77
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.9671271729748696e-05
6.481423497461947e-06
Batch: 0; loss: 0.52; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.95
Batch: 60; loss: 0.86; acc: 0.73
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.59; acc: 0.86
Batch: 120; loss: 0.86; acc: 0.75
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.4791149300564626; val_accuracy: 0.850218949044586 

The current subspace-distance is: 6.481423497461947e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.77
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.58; acc: 0.8
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.48; acc: 0.78
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.49; acc: 0.83
Batch: 320; loss: 0.62; acc: 0.83
Batch: 340; loss: 0.53; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.4; acc: 0.83
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.52; acc: 0.84
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.57; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.94; acc: 0.78
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

2.033877171925269e-05
6.927983577043051e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.98
Batch: 60; loss: 0.64; acc: 0.78
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.09; acc: 1.0
Val Epoch over. val_loss: 0.4273370765386873; val_accuracy: 0.8695262738853503 

The current subspace-distance is: 6.927983577043051e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.84; acc: 0.78
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.42; acc: 0.83
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.38; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.48; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.55; acc: 0.83
Batch: 380; loss: 0.64; acc: 0.83
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.78
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.5; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.65; acc: 0.84
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

1.877749673440121e-05
6.951769591978518e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.97
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.5; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.98
Val Epoch over. val_loss: 0.42271534078250267; val_accuracy: 0.8663415605095541 

The current subspace-distance is: 6.951769591978518e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.59; acc: 0.89
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.74; acc: 0.8
Batch: 160; loss: 0.86; acc: 0.75
Batch: 180; loss: 0.6; acc: 0.75
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.5; acc: 0.89
Batch: 260; loss: 1.0; acc: 0.72
Batch: 280; loss: 0.38; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.88
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.5; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.5; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.46; acc: 0.81
Batch: 460; loss: 0.6; acc: 0.75
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.49; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.71; acc: 0.8
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.5; acc: 0.86
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.31; acc: 0.86
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.66; acc: 0.83
Batch: 780; loss: 0.54; acc: 0.8
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

1.9000135580427013e-05
6.504344128188677e-06
Batch: 0; loss: 0.46; acc: 0.83
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.78
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.42997562733425454; val_accuracy: 0.8713176751592356 

The current subspace-distance is: 6.504344128188677e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.62; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.6; acc: 0.8
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.76; acc: 0.81
Batch: 240; loss: 0.6; acc: 0.81
Batch: 260; loss: 0.46; acc: 0.86
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.55; acc: 0.83
Batch: 440; loss: 0.4; acc: 0.84
Batch: 460; loss: 0.56; acc: 0.8
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.51; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.83
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.48; acc: 0.83
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.46; acc: 0.84
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

1.9699396943906322e-05
7.0046671680756845e-06
Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.41676954963025015; val_accuracy: 0.8728105095541401 

The current subspace-distance is: 7.0046671680756845e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.66; acc: 0.81
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.69; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.62; acc: 0.81
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.52; acc: 0.73
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.48; acc: 0.83
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.61; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.63; acc: 0.8
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.84
Batch: 420; loss: 0.46; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.94
Batch: 460; loss: 0.42; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.54; acc: 0.77
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.61; acc: 0.83
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.54; acc: 0.78
Batch: 700; loss: 0.5; acc: 0.84
Batch: 720; loss: 0.54; acc: 0.83
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.53; acc: 0.8
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

1.99868136405712e-05
6.373175892804284e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.98
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.4104506082975181; val_accuracy: 0.8726114649681529 

The current subspace-distance is: 6.373175892804284e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.64; acc: 0.8
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.8; acc: 0.81
Batch: 160; loss: 0.6; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.8
Batch: 260; loss: 0.39; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.63; acc: 0.81
Batch: 320; loss: 0.67; acc: 0.83
Batch: 340; loss: 0.48; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.66; acc: 0.81
Batch: 420; loss: 0.68; acc: 0.75
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.62; acc: 0.86
Batch: 480; loss: 0.48; acc: 0.88
Batch: 500; loss: 0.56; acc: 0.8
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.63; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.73; acc: 0.77
Batch: 740; loss: 0.43; acc: 0.83
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.69; acc: 0.8
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.0628855054383166e-05
7.215604000521125e-06
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.97
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.418917143800456; val_accuracy: 0.870421974522293 

The current subspace-distance is: 7.215604000521125e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.49; acc: 0.86
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.59; acc: 0.83
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.65; acc: 0.81
Batch: 440; loss: 0.49; acc: 0.83
Batch: 460; loss: 0.51; acc: 0.86
Batch: 480; loss: 0.58; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.81
Batch: 580; loss: 0.51; acc: 0.89
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.81
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.44; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.84
Batch: 780; loss: 0.58; acc: 0.8
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

1.9907954992959276e-05
7.157236723287497e-06
Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.97
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.98
Val Epoch over. val_loss: 0.4330280037822237; val_accuracy: 0.8691281847133758 

The current subspace-distance is: 7.157236723287497e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.52; acc: 0.84
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.6; acc: 0.8
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.45; acc: 0.81
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.46; acc: 0.88
Batch: 380; loss: 0.38; acc: 0.84
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.63; acc: 0.83
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.51; acc: 0.88
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.47; acc: 0.94
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.54; acc: 0.75
Batch: 680; loss: 0.6; acc: 0.84
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.59; acc: 0.78
Batch: 760; loss: 0.68; acc: 0.77
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.034741555689834e-05
7.729787284915801e-06
Batch: 0; loss: 0.37; acc: 0.84
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.83
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4445429695829464; val_accuracy: 0.8623606687898089 

The current subspace-distance is: 7.729787284915801e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.65; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.8
Batch: 140; loss: 0.54; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.37; acc: 0.94
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.52; acc: 0.8
Batch: 280; loss: 0.41; acc: 0.83
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.59; acc: 0.88
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.6; acc: 0.84
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.66; acc: 0.86
Batch: 460; loss: 0.64; acc: 0.8
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.6; acc: 0.83
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.58; acc: 0.8
Batch: 640; loss: 0.69; acc: 0.83
Batch: 660; loss: 0.65; acc: 0.8
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.83
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.56; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.0940424292348325e-05
7.606653980474221e-06
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.41171195125503907; val_accuracy: 0.8753980891719745 

The current subspace-distance is: 7.606653980474221e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.61; acc: 0.77
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.62; acc: 0.83
Batch: 100; loss: 0.62; acc: 0.83
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.51; acc: 0.78
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.6; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.57; acc: 0.86
Batch: 380; loss: 0.52; acc: 0.84
Batch: 400; loss: 0.58; acc: 0.78
Batch: 420; loss: 0.51; acc: 0.81
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.44; acc: 0.81
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.8; acc: 0.72
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.62; acc: 0.86
Batch: 760; loss: 0.52; acc: 0.81
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.1416401068563573e-05
6.741766355844447e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.66; acc: 0.78
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.431124227346888; val_accuracy: 0.8668391719745223 

The current subspace-distance is: 6.741766355844447e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.86
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.42; acc: 0.92
Batch: 200; loss: 0.43; acc: 0.83
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.58; acc: 0.8
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.78
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.34; acc: 0.84
Batch: 440; loss: 0.51; acc: 0.81
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.61; acc: 0.77
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.83
Batch: 560; loss: 0.61; acc: 0.81
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.45; acc: 0.8
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.72; acc: 0.78
Batch: 680; loss: 0.77; acc: 0.83
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.55; acc: 0.83
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.0247029169695452e-05
6.696487616864033e-06
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.39344113780434725; val_accuracy: 0.8815684713375797 

The current subspace-distance is: 6.696487616864033e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.81
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.39; acc: 0.84
Batch: 160; loss: 0.37; acc: 0.94
Batch: 180; loss: 0.86; acc: 0.75
Batch: 200; loss: 0.45; acc: 0.83
Batch: 220; loss: 0.51; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.86
Batch: 260; loss: 0.33; acc: 0.86
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.67; acc: 0.78
Batch: 360; loss: 0.79; acc: 0.84
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.89
Batch: 500; loss: 0.63; acc: 0.83
Batch: 520; loss: 0.65; acc: 0.78
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.6; acc: 0.88
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.56; acc: 0.84
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.0072706320206635e-05
6.8281246967671905e-06
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.98
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3930067931106136; val_accuracy: 0.8792794585987261 

The current subspace-distance is: 6.8281246967671905e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.83
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.48; acc: 0.81
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.74; acc: 0.8
Batch: 280; loss: 0.61; acc: 0.77
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.83
Batch: 620; loss: 0.65; acc: 0.81
Batch: 640; loss: 0.42; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.23; acc: 0.97
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

1.9451086700428277e-05
6.152131390990689e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.4198169362772802; val_accuracy: 0.871218152866242 

The current subspace-distance is: 6.152131390990689e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.58; acc: 0.81
Batch: 20; loss: 0.62; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.76; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.41; acc: 0.8
Batch: 300; loss: 0.39; acc: 0.86
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.42; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.83
Batch: 540; loss: 0.76; acc: 0.81
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.45; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.84
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.8
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

2.0465302441152744e-05
8.023291229619645e-06
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3939988258632885; val_accuracy: 0.8801751592356688 

The current subspace-distance is: 8.023291229619645e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.62; acc: 0.77
Batch: 180; loss: 0.37; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.81
Batch: 220; loss: 0.49; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.54; acc: 0.94
Batch: 320; loss: 0.4; acc: 0.92
Batch: 340; loss: 0.57; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.78
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.69; acc: 0.8
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.86
Batch: 460; loss: 0.23; acc: 0.97
Batch: 480; loss: 0.54; acc: 0.84
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.57; acc: 0.84
Batch: 620; loss: 0.48; acc: 0.81
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.066918386844918e-05
7.001265657891054e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3936963145425365; val_accuracy: 0.8817675159235668 

The current subspace-distance is: 7.001265657891054e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.68; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.58; acc: 0.83
Batch: 200; loss: 0.49; acc: 0.86
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.62; acc: 0.83
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.58; acc: 0.84
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.57; acc: 0.83
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.76; acc: 0.8
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.0297182345530018e-05
7.528692549385596e-06
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.4022532068904798; val_accuracy: 0.8761942675159236 

The current subspace-distance is: 7.528692549385596e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.59; acc: 0.84
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.65; acc: 0.75
Batch: 300; loss: 0.53; acc: 0.88
Batch: 320; loss: 0.55; acc: 0.81
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.64; acc: 0.78
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.84
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.8; acc: 0.81
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.57; acc: 0.86
Batch: 600; loss: 0.6; acc: 0.8
Batch: 620; loss: 0.37; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

1.913317282742355e-05
7.105827535269782e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.98
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.40595809076052564; val_accuracy: 0.8759952229299363 

The current subspace-distance is: 7.105827535269782e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.8
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.55; acc: 0.8
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.59; acc: 0.84
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.58; acc: 0.88
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.8; acc: 0.77
Batch: 340; loss: 0.16; acc: 0.98
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.66; acc: 0.78
Batch: 420; loss: 0.53; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.64; acc: 0.86
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.61; acc: 0.8
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.51; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.82; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.084976040350739e-05
7.045544407446869e-06
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.4133311602625118; val_accuracy: 0.8743033439490446 

The current subspace-distance is: 7.045544407446869e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.56; acc: 0.91
Batch: 160; loss: 0.39; acc: 0.92
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.69; acc: 0.83
Batch: 220; loss: 0.52; acc: 0.83
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.5; acc: 0.81
Batch: 300; loss: 0.59; acc: 0.84
Batch: 320; loss: 0.55; acc: 0.88
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.34; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.48; acc: 0.83
Batch: 500; loss: 0.79; acc: 0.81
Batch: 520; loss: 0.58; acc: 0.83
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.5; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.54; acc: 0.8
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

2.0252493413863704e-05
7.030881079117535e-06
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.40248261178564876; val_accuracy: 0.8761942675159236 

The current subspace-distance is: 7.030881079117535e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.67; acc: 0.84
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.47; acc: 0.86
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.56; acc: 0.88
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.51; acc: 0.78
Batch: 420; loss: 0.61; acc: 0.81
Batch: 440; loss: 0.46; acc: 0.81
Batch: 460; loss: 0.28; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.84; acc: 0.78
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.81
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.6; acc: 0.84
Batch: 680; loss: 0.44; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.86
Batch: 720; loss: 0.42; acc: 0.81
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.52; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

1.9637071090983227e-05
6.566415322595276e-06
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4058923676704905; val_accuracy: 0.875 

The current subspace-distance is: 6.566415322595276e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.64; acc: 0.83
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.58; acc: 0.8
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.56; acc: 0.8
Batch: 320; loss: 0.51; acc: 0.78
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.44; acc: 0.81
Batch: 380; loss: 0.72; acc: 0.83
Batch: 400; loss: 0.46; acc: 0.81
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.62; acc: 0.75
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.57; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.54; acc: 0.83
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0075251086382195e-05
6.951314389880281e-06
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3919057140874255; val_accuracy: 0.8809713375796179 

The current subspace-distance is: 6.951314389880281e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.35; acc: 0.84
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.75; acc: 0.83
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.46; acc: 0.8
Batch: 500; loss: 0.71; acc: 0.77
Batch: 520; loss: 0.59; acc: 0.86
Batch: 540; loss: 0.37; acc: 0.83
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.53; acc: 0.86
Batch: 640; loss: 0.23; acc: 0.97
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.56; acc: 0.84
Batch: 720; loss: 0.53; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.97
Batch: 760; loss: 0.65; acc: 0.81
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0891582607873715e-05
6.250652404560242e-06
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.8
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.39112367091854666; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 6.250652404560242e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.49; acc: 0.81
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.83
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.46; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.52; acc: 0.83
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.55; acc: 0.8
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.64; acc: 0.86
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.81
Batch: 520; loss: 0.51; acc: 0.88
Batch: 540; loss: 0.46; acc: 0.91
Batch: 560; loss: 0.79; acc: 0.78
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.62; acc: 0.81
Batch: 640; loss: 0.52; acc: 0.8
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0328770915511996e-05
6.959479833312798e-06
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3914587228161514; val_accuracy: 0.8818670382165605 

The current subspace-distance is: 6.959479833312798e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.91
Batch: 120; loss: 0.54; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.47; acc: 0.86
Batch: 240; loss: 0.61; acc: 0.78
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.51; acc: 0.8
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.81
Batch: 540; loss: 0.53; acc: 0.77
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.52; acc: 0.91
Batch: 600; loss: 0.58; acc: 0.84
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.94
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.81
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0849105567322113e-05
7.442174137395341e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.39815872603920616; val_accuracy: 0.8779856687898089 

The current subspace-distance is: 7.442174137395341e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.41; acc: 0.83
Batch: 100; loss: 0.6; acc: 0.83
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.61; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.53; acc: 0.86
Batch: 300; loss: 0.53; acc: 0.81
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.63; acc: 0.84
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.53; acc: 0.91
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.71; acc: 0.73
Batch: 520; loss: 0.45; acc: 0.81
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.62; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.49; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.66; acc: 0.84
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.73; acc: 0.78
Batch: 780; loss: 0.41; acc: 0.83
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

1.9783819880103692e-05
6.769555511709768e-06
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.39233544687176963; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 6.769555511709768e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.55; acc: 0.81
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.59; acc: 0.8
Batch: 220; loss: 0.54; acc: 0.86
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.58; acc: 0.83
Batch: 300; loss: 0.49; acc: 0.81
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.42; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.86
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.48; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.54; acc: 0.81
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.49; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.46; acc: 0.81
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.54; acc: 0.84
Batch: 720; loss: 0.57; acc: 0.83
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0544262952171266e-05
7.123529485397739e-06
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.98
Val Epoch over. val_loss: 0.3906815316361986; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 7.123529485397739e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.51; acc: 0.75
Batch: 40; loss: 0.58; acc: 0.78
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.54; acc: 0.83
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.56; acc: 0.81
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.64; acc: 0.83
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.53; acc: 0.83
Batch: 420; loss: 0.51; acc: 0.83
Batch: 440; loss: 0.66; acc: 0.75
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.51; acc: 0.81
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.57; acc: 0.83
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.81
Batch: 720; loss: 0.43; acc: 0.81
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.57; acc: 0.81
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0230549125699326e-05
6.541185484820744e-06
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3987817340975354; val_accuracy: 0.8762937898089171 

The current subspace-distance is: 6.541185484820744e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.78
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.63; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.69; acc: 0.81
Batch: 360; loss: 0.49; acc: 0.8
Batch: 380; loss: 0.56; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.49; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.53; acc: 0.89
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.78; acc: 0.84
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.47; acc: 0.81
Batch: 680; loss: 0.63; acc: 0.83
Batch: 700; loss: 0.47; acc: 0.8
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.68; acc: 0.86
Batch: 760; loss: 0.65; acc: 0.83
Batch: 780; loss: 0.46; acc: 0.83
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.041347215708811e-05
6.444974133046344e-06
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.78
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.39029510974124737; val_accuracy: 0.8828622611464968 

The current subspace-distance is: 6.444974133046344e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.55; acc: 0.81
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.75; acc: 0.75
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.54; acc: 0.83
Batch: 360; loss: 0.43; acc: 0.83
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.56; acc: 0.83
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.56; acc: 0.81
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.51; acc: 0.86
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.53; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.1034044038970023e-05
7.36140327717294e-06
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3912336155772209; val_accuracy: 0.8808718152866242 

The current subspace-distance is: 7.36140327717294e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.81; acc: 0.75
Batch: 40; loss: 0.55; acc: 0.83
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.83
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.63; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.88
Batch: 200; loss: 0.48; acc: 0.81
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.6; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.83
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.84
Batch: 520; loss: 0.51; acc: 0.83
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.48; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.49; acc: 0.78
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.42; acc: 0.89
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.77; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0681265596067533e-05
6.840025434939889e-06
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.3944338803553277; val_accuracy: 0.877687101910828 

The current subspace-distance is: 6.840025434939889e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.83
Batch: 280; loss: 0.59; acc: 0.83
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.74; acc: 0.77
Batch: 400; loss: 0.41; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.68; acc: 0.86
Batch: 500; loss: 0.53; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.57; acc: 0.84
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.51; acc: 0.84
Batch: 640; loss: 0.68; acc: 0.8
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.57; acc: 0.8
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0901381503790617e-05
7.456900675606448e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3885668416027051; val_accuracy: 0.8826632165605095 

The current subspace-distance is: 7.456900675606448e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.73; acc: 0.81
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.51; acc: 0.81
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.97
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.65; acc: 0.84
Batch: 260; loss: 0.32; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.81
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.61; acc: 0.81
Batch: 400; loss: 0.5; acc: 0.8
Batch: 420; loss: 0.51; acc: 0.84
Batch: 440; loss: 0.45; acc: 0.83
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.67; acc: 0.8
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.58; acc: 0.8
Batch: 700; loss: 0.55; acc: 0.86
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.55; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0424613467184827e-05
6.779947852919577e-06
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3885958920808355; val_accuracy: 0.8837579617834395 

The current subspace-distance is: 6.779947852919577e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.89; acc: 0.73
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.59; acc: 0.83
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.88
Batch: 220; loss: 0.45; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.92
Batch: 260; loss: 0.35; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.84
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.68; acc: 0.84
Batch: 380; loss: 0.41; acc: 0.88
Batch: 400; loss: 0.62; acc: 0.77
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.6; acc: 0.78
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.81
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.68; acc: 0.84
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

1.9916691599064507e-05
7.2901339080999605e-06
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.3884214346955536; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 7.2901339080999605e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.46; acc: 0.8
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.55; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.95
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.4; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.54; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.88
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.88
Batch: 660; loss: 0.43; acc: 0.83
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.34; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.69
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.1807083612657152e-05
7.334623205679236e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3897661254948871; val_accuracy: 0.8816679936305732 

The current subspace-distance is: 7.334623205679236e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.84
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.47; acc: 0.81
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.53; acc: 0.83
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.57; acc: 0.83
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.63; acc: 0.83
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.83
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.64; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.1117184587637894e-05
7.919501513242722e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3905317461129966; val_accuracy: 0.881468949044586 

The current subspace-distance is: 7.919501513242722e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.39; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.79; acc: 0.77
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.59; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.77; acc: 0.8
Batch: 360; loss: 0.55; acc: 0.81
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.6; acc: 0.8
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.84
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.47; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.147011400666088e-05
7.118715529941255e-06
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3897956707010603; val_accuracy: 0.8831608280254777 

The current subspace-distance is: 7.118715529941255e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.83
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.44; acc: 0.86
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.5; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.61; acc: 0.83
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.5; acc: 0.81
Batch: 780; loss: 0.46; acc: 0.83
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0008325009257533e-05
7.276256383192958e-06
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.98
Val Epoch over. val_loss: 0.3893498019997481; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 7.276256383192958e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.38; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.88
Batch: 180; loss: 0.55; acc: 0.84
Batch: 200; loss: 0.38; acc: 0.84
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.83
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.51; acc: 0.88
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.54; acc: 0.86
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.51; acc: 0.89
Batch: 620; loss: 0.54; acc: 0.78
Batch: 640; loss: 0.31; acc: 0.86
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.72; acc: 0.78
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.0222341845510527e-05
6.5021595219150186e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.389225765730545; val_accuracy: 0.8818670382165605 

The current subspace-distance is: 6.5021595219150186e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.52; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.75; acc: 0.77
Batch: 180; loss: 0.76; acc: 0.78
Batch: 200; loss: 0.61; acc: 0.86
Batch: 220; loss: 0.54; acc: 0.8
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.59; acc: 0.81
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.51; acc: 0.81
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.62; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.08403780561639e-05
8.024298949749209e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3916622356149801; val_accuracy: 0.8809713375796179 

The current subspace-distance is: 8.024298949749209e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.89
Batch: 40; loss: 0.47; acc: 0.81
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.89
Batch: 100; loss: 0.7; acc: 0.83
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.88
Batch: 240; loss: 0.42; acc: 0.84
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.83; acc: 0.81
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.84
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.5; acc: 0.88
Batch: 460; loss: 0.71; acc: 0.81
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.56; acc: 0.81
Batch: 580; loss: 0.36; acc: 0.83
Batch: 600; loss: 0.56; acc: 0.83
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.51; acc: 0.84
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.62; acc: 0.78
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.5; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.136323382728733e-05
6.857255812064977e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3890992817795201; val_accuracy: 0.8828622611464968 

The current subspace-distance is: 6.857255812064977e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_150_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 37208
elements in E: 7774550
fraction nonzero: 0.004785871851103922
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.3; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.28; acc: 0.11
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.05
Batch: 380; loss: 2.29; acc: 0.09
Batch: 400; loss: 2.28; acc: 0.08
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.27; acc: 0.09
Batch: 460; loss: 2.27; acc: 0.05
Batch: 480; loss: 2.27; acc: 0.09
Batch: 500; loss: 2.27; acc: 0.09
Batch: 520; loss: 2.27; acc: 0.11
Batch: 540; loss: 2.26; acc: 0.11
Batch: 560; loss: 2.26; acc: 0.17
Batch: 580; loss: 2.26; acc: 0.25
Batch: 600; loss: 2.25; acc: 0.3
Batch: 620; loss: 2.25; acc: 0.14
Batch: 640; loss: 2.23; acc: 0.22
Batch: 660; loss: 2.24; acc: 0.2
Batch: 680; loss: 2.22; acc: 0.2
Batch: 700; loss: 2.21; acc: 0.33
Batch: 720; loss: 2.22; acc: 0.36
Batch: 740; loss: 2.21; acc: 0.3
Batch: 760; loss: 2.2; acc: 0.28
Batch: 780; loss: 2.16; acc: 0.3
Train Epoch over. train_loss: 2.27; train_accuracy: 0.15 

5.6036947171378415e-06
1.8789999103319133e-06
Batch: 0; loss: 2.16; acc: 0.41
Batch: 20; loss: 2.17; acc: 0.28
Batch: 40; loss: 2.12; acc: 0.44
Batch: 60; loss: 2.14; acc: 0.39
Batch: 80; loss: 2.13; acc: 0.45
Batch: 100; loss: 2.14; acc: 0.47
Batch: 120; loss: 2.16; acc: 0.39
Batch: 140; loss: 2.11; acc: 0.5
Val Epoch over. val_loss: 2.1497785468010386; val_accuracy: 0.38584792993630573 

The current subspace-distance is: 1.8789999103319133e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.17; acc: 0.38
Batch: 20; loss: 2.13; acc: 0.44
Batch: 40; loss: 2.1; acc: 0.5
Batch: 60; loss: 2.01; acc: 0.55
Batch: 80; loss: 2.02; acc: 0.45
Batch: 100; loss: 1.77; acc: 0.53
Batch: 120; loss: 1.65; acc: 0.55
Batch: 140; loss: 1.4; acc: 0.64
Batch: 160; loss: 1.0; acc: 0.69
Batch: 180; loss: 1.05; acc: 0.66
Batch: 200; loss: 1.01; acc: 0.67
Batch: 220; loss: 0.86; acc: 0.7
Batch: 240; loss: 0.74; acc: 0.77
Batch: 260; loss: 0.75; acc: 0.72
Batch: 280; loss: 0.94; acc: 0.61
Batch: 300; loss: 0.76; acc: 0.73
Batch: 320; loss: 0.91; acc: 0.77
Batch: 340; loss: 0.7; acc: 0.84
Batch: 360; loss: 0.8; acc: 0.72
Batch: 380; loss: 0.86; acc: 0.69
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.59; acc: 0.8
Batch: 440; loss: 0.72; acc: 0.77
Batch: 460; loss: 0.71; acc: 0.78
Batch: 480; loss: 0.64; acc: 0.86
Batch: 500; loss: 0.55; acc: 0.88
Batch: 520; loss: 0.64; acc: 0.8
Batch: 540; loss: 0.63; acc: 0.8
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.68; acc: 0.78
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.83; acc: 0.8
Batch: 640; loss: 0.55; acc: 0.88
Batch: 660; loss: 0.74; acc: 0.78
Batch: 680; loss: 0.5; acc: 0.83
Batch: 700; loss: 0.71; acc: 0.8
Batch: 720; loss: 0.75; acc: 0.72
Batch: 740; loss: 0.68; acc: 0.73
Batch: 760; loss: 0.62; acc: 0.77
Batch: 780; loss: 0.53; acc: 0.86
Train Epoch over. train_loss: 0.95; train_accuracy: 0.72 

1.6626807337161154e-05
6.673129064438399e-06
Batch: 0; loss: 0.67; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.73
Batch: 40; loss: 0.3; acc: 0.86
Batch: 60; loss: 0.81; acc: 0.77
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.595327001563303; val_accuracy: 0.8185708598726115 

The current subspace-distance is: 6.673129064438399e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.06; acc: 0.64
Batch: 20; loss: 0.91; acc: 0.77
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.51; acc: 0.91
Batch: 80; loss: 0.56; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.47; acc: 0.83
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.76; acc: 0.78
Batch: 220; loss: 0.68; acc: 0.75
Batch: 240; loss: 0.65; acc: 0.78
Batch: 260; loss: 0.49; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.7; acc: 0.81
Batch: 320; loss: 0.64; acc: 0.75
Batch: 340; loss: 0.6; acc: 0.83
Batch: 360; loss: 0.63; acc: 0.84
Batch: 380; loss: 0.62; acc: 0.75
Batch: 400; loss: 0.67; acc: 0.84
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.5; acc: 0.83
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.61; acc: 0.81
Batch: 500; loss: 0.5; acc: 0.83
Batch: 520; loss: 0.55; acc: 0.88
Batch: 540; loss: 0.8; acc: 0.69
Batch: 560; loss: 0.62; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.6; acc: 0.8
Batch: 640; loss: 0.67; acc: 0.84
Batch: 660; loss: 0.52; acc: 0.8
Batch: 680; loss: 0.59; acc: 0.75
Batch: 700; loss: 0.51; acc: 0.89
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.65; acc: 0.8
Batch: 760; loss: 0.58; acc: 0.81
Batch: 780; loss: 0.63; acc: 0.81
Train Epoch over. train_loss: 0.56; train_accuracy: 0.82 

1.8574934074422345e-05
7.213589469756698e-06
Batch: 0; loss: 0.83; acc: 0.72
Batch: 20; loss: 0.96; acc: 0.64
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.83; acc: 0.81
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 1.3; acc: 0.66
Batch: 140; loss: 0.49; acc: 0.78
Val Epoch over. val_loss: 0.6759048671859085; val_accuracy: 0.7901074840764332 

The current subspace-distance is: 7.213589469756698e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.78
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.65; acc: 0.83
Batch: 60; loss: 0.54; acc: 0.77
Batch: 80; loss: 0.66; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.83
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.53; acc: 0.89
Batch: 160; loss: 0.74; acc: 0.72
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.56; acc: 0.8
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.61; acc: 0.8
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.64; acc: 0.83
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.53; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.84
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.62; acc: 0.83
Batch: 440; loss: 0.75; acc: 0.78
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.72; acc: 0.77
Batch: 560; loss: 0.62; acc: 0.78
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.7; acc: 0.78
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.84
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.88
Batch: 760; loss: 0.73; acc: 0.75
Batch: 780; loss: 0.55; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

2.0043231415911578e-05
6.405132808140479e-06
Batch: 0; loss: 2.19; acc: 0.42
Batch: 20; loss: 2.08; acc: 0.47
Batch: 40; loss: 1.83; acc: 0.58
Batch: 60; loss: 2.49; acc: 0.56
Batch: 80; loss: 1.96; acc: 0.58
Batch: 100; loss: 1.99; acc: 0.52
Batch: 120; loss: 2.5; acc: 0.39
Batch: 140; loss: 2.06; acc: 0.52
Val Epoch over. val_loss: 2.0307849638021676; val_accuracy: 0.5078622611464968 

The current subspace-distance is: 6.405132808140479e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.69; acc: 0.47
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.45; acc: 0.89
Batch: 60; loss: 0.62; acc: 0.83
Batch: 80; loss: 0.74; acc: 0.8
Batch: 100; loss: 0.52; acc: 0.75
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.6; acc: 0.86
Batch: 220; loss: 0.46; acc: 0.83
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.67; acc: 0.8
Batch: 320; loss: 0.59; acc: 0.8
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.86
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.43; acc: 0.81
Batch: 420; loss: 0.53; acc: 0.8
Batch: 440; loss: 0.63; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.55; acc: 0.78
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.58; acc: 0.8
Batch: 540; loss: 0.65; acc: 0.73
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.74; acc: 0.72
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.84
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.5; acc: 0.8
Batch: 720; loss: 0.45; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.5; train_accuracy: 0.84 

2.1289504729793407e-05
7.116731012501987e-06
Batch: 0; loss: 1.25; acc: 0.59
Batch: 20; loss: 1.22; acc: 0.58
Batch: 40; loss: 0.85; acc: 0.7
Batch: 60; loss: 1.92; acc: 0.55
Batch: 80; loss: 1.21; acc: 0.55
Batch: 100; loss: 0.95; acc: 0.66
Batch: 120; loss: 1.76; acc: 0.5
Batch: 140; loss: 1.14; acc: 0.62
Val Epoch over. val_loss: 1.3898130833722984; val_accuracy: 0.5897691082802548 

The current subspace-distance is: 7.116731012501987e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.16; acc: 0.62
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.63; acc: 0.81
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.53; acc: 0.8
Batch: 280; loss: 0.71; acc: 0.8
Batch: 300; loss: 0.65; acc: 0.8
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.7; acc: 0.77
Batch: 360; loss: 0.5; acc: 0.8
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.61; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.52; acc: 0.83
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.86
Batch: 580; loss: 0.65; acc: 0.83
Batch: 600; loss: 0.46; acc: 0.84
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.8
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.55; acc: 0.8
Batch: 760; loss: 0.75; acc: 0.72
Batch: 780; loss: 0.64; acc: 0.78
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

2.0978406610083766e-05
7.169320269895252e-06
Batch: 0; loss: 0.87; acc: 0.75
Batch: 20; loss: 0.73; acc: 0.77
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 1.07; acc: 0.69
Batch: 80; loss: 0.7; acc: 0.8
Batch: 100; loss: 0.59; acc: 0.83
Batch: 120; loss: 1.08; acc: 0.62
Batch: 140; loss: 0.44; acc: 0.83
Val Epoch over. val_loss: 0.790233206217456; val_accuracy: 0.7487062101910829 

The current subspace-distance is: 7.169320269895252e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.97; acc: 0.66
Batch: 20; loss: 0.44; acc: 0.84
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.58; acc: 0.83
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.83
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.65; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.86; acc: 0.75
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.4; acc: 0.84
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.43; acc: 0.8
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.52; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.55; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.84
Batch: 620; loss: 0.45; acc: 0.83
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.58; acc: 0.81
Batch: 700; loss: 0.33; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.81
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.53; acc: 0.81
Batch: 780; loss: 0.42; acc: 0.83
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.021120599238202e-05
7.327970251935767e-06
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.72; acc: 0.72
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.42688606527580575; val_accuracy: 0.867734872611465 

The current subspace-distance is: 7.327970251935767e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.88
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.8; acc: 0.78
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 1.1; acc: 0.67
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.56; acc: 0.81
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.83
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.54; acc: 0.83
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.61; acc: 0.77
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.86
Batch: 460; loss: 0.54; acc: 0.86
Batch: 480; loss: 0.43; acc: 0.84
Batch: 500; loss: 0.48; acc: 0.89
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.57; acc: 0.8
Batch: 560; loss: 0.59; acc: 0.81
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.69; acc: 0.78
Batch: 700; loss: 0.55; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.51; acc: 0.8
Batch: 760; loss: 0.77; acc: 0.8
Batch: 780; loss: 0.48; acc: 0.81
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.0592493456206284e-05
7.365275905613089e-06
Batch: 0; loss: 0.65; acc: 0.78
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 1.06; acc: 0.75
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.6333124174433908; val_accuracy: 0.8024482484076433 

The current subspace-distance is: 7.365275905613089e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.56; acc: 0.78
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.71; acc: 0.78
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.83
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.34; acc: 0.84
Batch: 300; loss: 0.59; acc: 0.83
Batch: 320; loss: 0.81; acc: 0.73
Batch: 340; loss: 0.49; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.55; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.77
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.56; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.83
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.68; acc: 0.84
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.58; acc: 0.8
Batch: 600; loss: 0.67; acc: 0.77
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.92
Batch: 700; loss: 0.73; acc: 0.8
Batch: 720; loss: 0.46; acc: 0.81
Batch: 740; loss: 0.54; acc: 0.8
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.0731033146148548e-05
6.702752216369845e-06
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.23; acc: 0.89
Val Epoch over. val_loss: 0.4532284617993482; val_accuracy: 0.8630573248407644 

The current subspace-distance is: 6.702752216369845e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.7; acc: 0.83
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.35; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.55; acc: 0.81
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.78
Batch: 200; loss: 0.58; acc: 0.8
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.6; acc: 0.81
Batch: 280; loss: 0.37; acc: 0.81
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.52; acc: 0.84
Batch: 400; loss: 0.49; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.51; acc: 0.84
Batch: 460; loss: 0.83; acc: 0.8
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.57; acc: 0.81
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.79; acc: 0.81
Batch: 600; loss: 0.77; acc: 0.75
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.98; acc: 0.69
Batch: 660; loss: 0.42; acc: 0.83
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.81
Batch: 720; loss: 0.48; acc: 0.81
Batch: 740; loss: 0.83; acc: 0.75
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.63; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

2.010985917877406e-05
7.260719939949922e-06
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4409010276483123; val_accuracy: 0.8618630573248408 

The current subspace-distance is: 7.260719939949922e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.52; acc: 0.83
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.65; acc: 0.83
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.5; acc: 0.83
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.83
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.55; acc: 0.83
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.55; acc: 0.83
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.73; acc: 0.81
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

2.1087478671688586e-05
6.919471161381807e-06
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.73
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.39112121768438135; val_accuracy: 0.877687101910828 

The current subspace-distance is: 6.919471161381807e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.73; acc: 0.83
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.6; acc: 0.8
Batch: 300; loss: 0.39; acc: 0.83
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.44; acc: 0.86
Batch: 380; loss: 0.59; acc: 0.83
Batch: 400; loss: 0.79; acc: 0.78
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.62; acc: 0.84
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.53; acc: 0.81
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.83
Batch: 600; loss: 0.31; acc: 0.83
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.54; acc: 0.75
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

1.9861532564391382e-05
6.7249839048599824e-06
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.3871965532659725; val_accuracy: 0.8794785031847133 

The current subspace-distance is: 6.7249839048599824e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.63; acc: 0.81
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.57; acc: 0.84
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.64; acc: 0.78
Batch: 160; loss: 0.54; acc: 0.81
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.4; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.95
Batch: 260; loss: 0.64; acc: 0.81
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.53; acc: 0.78
Batch: 380; loss: 0.7; acc: 0.8
Batch: 400; loss: 0.44; acc: 0.84
Batch: 420; loss: 0.53; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.77
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.45; acc: 0.83
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.44; acc: 0.81
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.94; acc: 0.73
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.51; acc: 0.83
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

2.0464614863158204e-05
6.769321771571413e-06
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.83
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.3982780393521497; val_accuracy: 0.8788813694267515 

The current subspace-distance is: 6.769321771571413e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.83
Batch: 80; loss: 0.68; acc: 0.78
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.71; acc: 0.75
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.65; acc: 0.73
Batch: 300; loss: 0.6; acc: 0.8
Batch: 320; loss: 0.5; acc: 0.81
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.51; acc: 0.77
Batch: 440; loss: 0.49; acc: 0.83
Batch: 460; loss: 0.71; acc: 0.8
Batch: 480; loss: 0.53; acc: 0.88
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.83
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.46; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.43; train_accuracy: 0.86 

2.101872996718157e-05
7.1659574132354464e-06
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4217225499213881; val_accuracy: 0.8691281847133758 

The current subspace-distance is: 7.1659574132354464e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.54; acc: 0.78
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.51; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.84
Batch: 360; loss: 0.64; acc: 0.8
Batch: 380; loss: 0.55; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.83
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.34; acc: 0.84
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.42; acc: 0.91
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.64; acc: 0.77
Batch: 700; loss: 0.55; acc: 0.81
Batch: 720; loss: 0.57; acc: 0.78
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.49; acc: 0.81
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.1033782104495913e-05
6.878013664390892e-06
Batch: 0; loss: 0.54; acc: 0.81
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.76; acc: 0.8
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.92
Val Epoch over. val_loss: 0.4285433292388916; val_accuracy: 0.8628582802547771 

The current subspace-distance is: 6.878013664390892e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.53; acc: 0.84
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.65; acc: 0.81
Batch: 160; loss: 0.62; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.84
Batch: 320; loss: 0.49; acc: 0.81
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.8; acc: 0.8
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.61; acc: 0.86
Batch: 480; loss: 0.54; acc: 0.78
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.83; acc: 0.75
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.88
Batch: 620; loss: 0.37; acc: 0.94
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.55; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.023744491452817e-05
7.201290372904623e-06
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.4019517188618897; val_accuracy: 0.8717157643312102 

The current subspace-distance is: 7.201290372904623e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.97
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.64; acc: 0.8
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.4; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.83
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.48; acc: 0.81
Batch: 480; loss: 0.61; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.58; acc: 0.83
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.43; acc: 0.83
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.55; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.84
Batch: 780; loss: 0.55; acc: 0.81
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.046930603682995e-05
6.809342266933527e-06
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.3887212654207922; val_accuracy: 0.8818670382165605 

The current subspace-distance is: 6.809342266933527e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.55; acc: 0.84
Batch: 200; loss: 0.63; acc: 0.81
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.52; acc: 0.86
Batch: 260; loss: 0.43; acc: 0.83
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.53; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.53; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.64; acc: 0.81
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.65; acc: 0.81
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.071256676572375e-05
6.595501417905325e-06
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.3789654960677882; val_accuracy: 0.8825636942675159 

The current subspace-distance is: 6.595501417905325e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.44; acc: 0.89
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.56; acc: 0.89
Batch: 380; loss: 0.41; acc: 0.84
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.51; acc: 0.86
Batch: 460; loss: 0.47; acc: 0.83
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.63; acc: 0.8
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.56; acc: 0.81
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.92
Batch: 760; loss: 0.51; acc: 0.81
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.0537963791866787e-05
7.017358711891575e-06
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.4481078386781322; val_accuracy: 0.85828025477707 

The current subspace-distance is: 7.017358711891575e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.42; acc: 0.84
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.61; acc: 0.83
Batch: 120; loss: 0.45; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.63; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.45; acc: 0.81
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.24; acc: 0.88
Batch: 520; loss: 0.61; acc: 0.78
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.42; acc: 0.8
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.79; acc: 0.75
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.65; acc: 0.81
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.07331122510368e-05
6.934156772331335e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.39658778170301656; val_accuracy: 0.8815684713375797 

The current subspace-distance is: 6.934156772331335e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.43; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.53; acc: 0.88
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.57; acc: 0.84
Batch: 560; loss: 0.7; acc: 0.83
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.48; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.84
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0593653971445747e-05
6.292030775512103e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3637203405237502; val_accuracy: 0.8881369426751592 

The current subspace-distance is: 6.292030775512103e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.56; acc: 0.83
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.83
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.74; acc: 0.86
Batch: 200; loss: 0.48; acc: 0.81
Batch: 220; loss: 0.53; acc: 0.81
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.47; acc: 0.81
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.54; acc: 0.78
Batch: 460; loss: 0.41; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.95
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.63; acc: 0.84
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.54; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.36; acc: 0.84
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.5; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.95
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.59; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.4; train_accuracy: 0.87 

2.0421406588866375e-05
6.438095169869484e-06
Batch: 0; loss: 0.37; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.3747490192199968; val_accuracy: 0.8854498407643312 

The current subspace-distance is: 6.438095169869484e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.8
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.47; acc: 0.88
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.79; acc: 0.7
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.58; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.73; acc: 0.77
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.57; acc: 0.8
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0795001546503045e-05
7.261417522386182e-06
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.3817368868240126; val_accuracy: 0.8811703821656051 

The current subspace-distance is: 7.261417522386182e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.39; acc: 0.88
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.58; acc: 0.84
Batch: 240; loss: 0.52; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.86
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.84
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.47; acc: 0.84
Batch: 540; loss: 0.64; acc: 0.81
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.59; acc: 0.88
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.59; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.051907722488977e-05
7.264149189722957e-06
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.3682806407380256; val_accuracy: 0.8850517515923567 

The current subspace-distance is: 7.264149189722957e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.46; acc: 0.83
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.62; acc: 0.84
Batch: 320; loss: 0.52; acc: 0.83
Batch: 340; loss: 0.61; acc: 0.8
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.65; acc: 0.84
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.54; acc: 0.86
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.64; acc: 0.83
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.56; acc: 0.81
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.81
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.56; acc: 0.8
Batch: 760; loss: 0.32; acc: 0.95
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0722725821542554e-05
6.621432930842275e-06
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3650363708852203; val_accuracy: 0.8890326433121019 

The current subspace-distance is: 6.621432930842275e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.89
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.84
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.55; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.56; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.42; acc: 0.83
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.83
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.66; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.059148027910851e-05
6.173527708597248e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.62; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.36068960336173417; val_accuracy: 0.8896297770700637 

The current subspace-distance is: 6.173527708597248e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.54; acc: 0.8
Batch: 280; loss: 0.64; acc: 0.83
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.56; acc: 0.83
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.44; acc: 0.81
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.42; acc: 0.83
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.1445810489240102e-05
6.91958030074602e-06
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.36571776539466944; val_accuracy: 0.8856488853503185 

The current subspace-distance is: 6.91958030074602e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.51; acc: 0.81
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.58; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.5; acc: 0.77
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.63; acc: 0.84
Batch: 400; loss: 0.55; acc: 0.8
Batch: 420; loss: 0.49; acc: 0.89
Batch: 440; loss: 0.48; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.13; acc: 0.98
Batch: 520; loss: 0.66; acc: 0.78
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.95
Batch: 680; loss: 0.64; acc: 0.86
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.43; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.039361061179079e-05
6.2918725234339945e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3622772960336345; val_accuracy: 0.8901273885350318 

The current subspace-distance is: 6.2918725234339945e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.39; acc: 0.94
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.86
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.57; acc: 0.84
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.61; acc: 0.84
Batch: 520; loss: 0.49; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.47; acc: 0.84
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.41; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0064646378159523e-05
6.509704235213576e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3772838566523449; val_accuracy: 0.883359872611465 

The current subspace-distance is: 6.509704235213576e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.86
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.89; acc: 0.8
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.57; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.53; acc: 0.83
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.092804243147839e-05
7.226310572150396e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3654706209043788; val_accuracy: 0.8891321656050956 

The current subspace-distance is: 7.226310572150396e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.86
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.84
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.47; acc: 0.81
Batch: 320; loss: 0.42; acc: 0.84
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.81
Batch: 380; loss: 0.66; acc: 0.81
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.83
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.66; acc: 0.8
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.83
Batch: 780; loss: 0.47; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0864030375378206e-05
6.001724614179693e-06
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35829943845606155; val_accuracy: 0.8898288216560509 

The current subspace-distance is: 6.001724614179693e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.81
Batch: 40; loss: 0.44; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.97
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.51; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.58; acc: 0.77
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.66; acc: 0.84
Batch: 420; loss: 0.45; acc: 0.83
Batch: 440; loss: 0.52; acc: 0.84
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.43; acc: 0.84
Batch: 620; loss: 0.61; acc: 0.83
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.030616633419413e-05
6.56734573567519e-06
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3594015132469736; val_accuracy: 0.8889331210191083 

The current subspace-distance is: 6.56734573567519e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.51; acc: 0.86
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.5; acc: 0.86
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.83
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.8
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.88
Batch: 520; loss: 0.49; acc: 0.88
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.7; acc: 0.84
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.65; acc: 0.81
Batch: 640; loss: 0.43; acc: 0.84
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0115508959861472e-05
6.441471668949816e-06
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3570150016409576; val_accuracy: 0.8899283439490446 

The current subspace-distance is: 6.441471668949816e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.45; acc: 0.81
Batch: 240; loss: 0.51; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.54; acc: 0.86
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.38; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.48; acc: 0.83
Batch: 480; loss: 0.44; acc: 0.86
Batch: 500; loss: 0.26; acc: 0.86
Batch: 520; loss: 0.47; acc: 0.89
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.6; acc: 0.81
Batch: 600; loss: 0.6; acc: 0.81
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.84
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.53; acc: 0.81
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0490117094595917e-05
7.107723376975628e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3607735548429428; val_accuracy: 0.8891321656050956 

The current subspace-distance is: 7.107723376975628e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.6; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.8
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.83
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.31; acc: 0.86
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.52; acc: 0.81
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.51; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.52; acc: 0.81
Batch: 520; loss: 0.74; acc: 0.8
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.49; acc: 0.86
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.64; acc: 0.83
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.126592335116584e-05
7.17522380000446e-06
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.3594436740419667; val_accuracy: 0.8898288216560509 

The current subspace-distance is: 7.17522380000446e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.57; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.42; acc: 0.81
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.6; acc: 0.83
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.78
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.52; acc: 0.83
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.49; acc: 0.88
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.4; acc: 0.86
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.37; acc: 0.83
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.62; acc: 0.83
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.01991406356683e-05
6.703740837110672e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.35562701124674195; val_accuracy: 0.8911226114649682 

The current subspace-distance is: 6.703740837110672e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.47; acc: 0.8
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.6; acc: 0.78
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.92
Batch: 140; loss: 0.54; acc: 0.81
Batch: 160; loss: 0.64; acc: 0.81
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.64; acc: 0.84
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.81
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0878438590443693e-05
6.537497029057704e-06
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3588978747843177; val_accuracy: 0.88953025477707 

The current subspace-distance is: 6.537497029057704e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.46; acc: 0.83
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.61; acc: 0.86
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.94
Batch: 320; loss: 0.47; acc: 0.8
Batch: 340; loss: 0.7; acc: 0.75
Batch: 360; loss: 0.56; acc: 0.86
Batch: 380; loss: 0.59; acc: 0.86
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.61; acc: 0.78
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.5; acc: 0.81
Batch: 580; loss: 0.51; acc: 0.88
Batch: 600; loss: 0.16; acc: 0.98
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.94
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.47; acc: 0.84
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.66; acc: 0.84
Batch: 760; loss: 0.63; acc: 0.81
Batch: 780; loss: 0.32; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0349458281998523e-05
6.03170747126569e-06
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.35541150059289994; val_accuracy: 0.8910230891719745 

The current subspace-distance is: 6.03170747126569e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.53; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.83
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.55; acc: 0.83
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.88
Batch: 520; loss: 0.57; acc: 0.86
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.83
Batch: 700; loss: 0.31; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.47; acc: 0.81
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.077233511954546e-05
6.317384304566076e-06
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.35837618536820076; val_accuracy: 0.8894307324840764 

The current subspace-distance is: 6.317384304566076e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.53; acc: 0.8
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.59; acc: 0.8
Batch: 340; loss: 0.42; acc: 0.81
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.47; acc: 0.84
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.95
Batch: 520; loss: 0.4; acc: 0.84
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.8
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.46; acc: 0.81
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.45; acc: 0.83
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.54; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0929996026097797e-05
6.440701781684766e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.35465951154755937; val_accuracy: 0.8911226114649682 

The current subspace-distance is: 6.440701781684766e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.57; acc: 0.84
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.58; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.45; acc: 0.81
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.54; acc: 0.78
Batch: 760; loss: 0.35; acc: 0.84
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.078463148791343e-05
7.164745966292685e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.35414919959511726; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 7.164745966292685e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.68; acc: 0.83
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.53; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.49; acc: 0.81
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.53; acc: 0.83
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.39; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.45; acc: 0.81
Batch: 580; loss: 0.52; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.64; acc: 0.83
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.032264819717966e-05
6.776225745852571e-06
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3556163795055098; val_accuracy: 0.893312101910828 

The current subspace-distance is: 6.776225745852571e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.73; acc: 0.75
Batch: 120; loss: 0.47; acc: 0.8
Batch: 140; loss: 0.6; acc: 0.8
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.53; acc: 0.81
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.83
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.83
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.5; acc: 0.84
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.56; acc: 0.83
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.0226032575010322e-05
5.88541797696962e-06
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.35368440186331984; val_accuracy: 0.8936106687898089 

The current subspace-distance is: 5.88541797696962e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.28; acc: 0.95
Batch: 300; loss: 0.59; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.54; acc: 0.92
Batch: 380; loss: 0.54; acc: 0.84
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.36; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.52; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.1038327759015374e-05
6.448984549933812e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3537039381873076; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 6.448984549933812e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.38; acc: 0.83
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.58; acc: 0.78
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.78
Batch: 300; loss: 0.44; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.47; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.16; acc: 0.98
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.88
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.79; acc: 0.81
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.092255454044789e-05
6.428936558222631e-06
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.83
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35553966367700296; val_accuracy: 0.8915207006369427 

The current subspace-distance is: 6.428936558222631e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.86
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.72; acc: 0.78
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.58; acc: 0.81
Batch: 260; loss: 0.35; acc: 0.84
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.49; acc: 0.88
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.53; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.83
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.44; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.1384885258157738e-05
7.827504305168986e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3542999877671527; val_accuracy: 0.8926154458598726 

The current subspace-distance is: 7.827504305168986e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.95
Batch: 160; loss: 0.5; acc: 0.86
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.5; acc: 0.84
Batch: 320; loss: 0.31; acc: 0.86
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.41; acc: 0.89
Batch: 400; loss: 0.58; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.48; acc: 0.84
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.0531550035229884e-05
6.4893829403445125e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3541822596245511; val_accuracy: 0.8927149681528662 

The current subspace-distance is: 6.4893829403445125e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.59; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.58; acc: 0.78
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.52; acc: 0.83
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.78; acc: 0.78
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.62; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.59; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.83
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.84
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.45; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.95
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.4; acc: 0.92
Batch: 740; loss: 0.54; acc: 0.81
Batch: 760; loss: 0.6; acc: 0.83
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.1259565983200446e-05
6.699648565700045e-06
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.35524648143227694; val_accuracy: 0.8928144904458599 

The current subspace-distance is: 6.699648565700045e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.53; acc: 0.83
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.64; acc: 0.77
Batch: 200; loss: 0.5; acc: 0.91
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.81
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.84
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.34; acc: 0.84
Batch: 660; loss: 0.54; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.58; acc: 0.84
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.52; acc: 0.84
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.1214300431893207e-05
7.022100362519268e-06
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.35400100289636355; val_accuracy: 0.8921178343949044 

The current subspace-distance is: 7.022100362519268e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.49; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.49; acc: 0.81
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.8
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.3; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.76; acc: 0.78
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.65; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.52; acc: 0.88
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.34; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.59; acc: 0.84
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.5; acc: 0.83
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.83
Batch: 660; loss: 0.59; acc: 0.84
Batch: 680; loss: 0.5; acc: 0.83
Batch: 700; loss: 0.32; acc: 0.86
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.84
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.057232632068917e-05
6.51067057333421e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3534578723227902; val_accuracy: 0.8930135350318471 

The current subspace-distance is: 6.51067057333421e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_175_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 42365
elements in E: 8885200
fraction nonzero: 0.0047680412371134025
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.3; acc: 0.05
Batch: 200; loss: 2.31; acc: 0.08
Batch: 220; loss: 2.29; acc: 0.12
Batch: 240; loss: 2.3; acc: 0.12
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.11
Batch: 300; loss: 2.27; acc: 0.17
Batch: 320; loss: 2.28; acc: 0.11
Batch: 340; loss: 2.28; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.03
Batch: 380; loss: 2.28; acc: 0.09
Batch: 400; loss: 2.27; acc: 0.08
Batch: 420; loss: 2.27; acc: 0.12
Batch: 440; loss: 2.26; acc: 0.11
Batch: 460; loss: 2.26; acc: 0.09
Batch: 480; loss: 2.26; acc: 0.16
Batch: 500; loss: 2.24; acc: 0.2
Batch: 520; loss: 2.25; acc: 0.19
Batch: 540; loss: 2.25; acc: 0.19
Batch: 560; loss: 2.22; acc: 0.3
Batch: 580; loss: 2.21; acc: 0.27
Batch: 600; loss: 2.2; acc: 0.27
Batch: 620; loss: 2.17; acc: 0.38
Batch: 640; loss: 2.12; acc: 0.42
Batch: 660; loss: 2.12; acc: 0.28
Batch: 680; loss: 2.04; acc: 0.48
Batch: 700; loss: 1.95; acc: 0.48
Batch: 720; loss: 1.91; acc: 0.5
Batch: 740; loss: 1.62; acc: 0.55
Batch: 760; loss: 1.51; acc: 0.53
Batch: 780; loss: 1.17; acc: 0.72
Train Epoch over. train_loss: 2.18; train_accuracy: 0.2 

7.638701390533242e-06
4.0814456951920874e-06
Batch: 0; loss: 1.03; acc: 0.72
Batch: 20; loss: 1.21; acc: 0.61
Batch: 40; loss: 0.8; acc: 0.8
Batch: 60; loss: 1.12; acc: 0.7
Batch: 80; loss: 0.97; acc: 0.72
Batch: 100; loss: 0.91; acc: 0.77
Batch: 120; loss: 1.28; acc: 0.66
Batch: 140; loss: 0.77; acc: 0.84
Val Epoch over. val_loss: 1.0567126323463052; val_accuracy: 0.6991441082802548 

The current subspace-distance is: 4.0814456951920874e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.11; acc: 0.66
Batch: 20; loss: 0.71; acc: 0.84
Batch: 40; loss: 1.21; acc: 0.64
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.91; acc: 0.73
Batch: 100; loss: 0.7; acc: 0.83
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.88; acc: 0.75
Batch: 160; loss: 0.61; acc: 0.75
Batch: 180; loss: 0.81; acc: 0.75
Batch: 200; loss: 0.78; acc: 0.78
Batch: 220; loss: 0.53; acc: 0.83
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.73; acc: 0.8
Batch: 280; loss: 0.55; acc: 0.8
Batch: 300; loss: 0.71; acc: 0.78
Batch: 320; loss: 0.73; acc: 0.78
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.59; acc: 0.89
Batch: 380; loss: 0.69; acc: 0.78
Batch: 400; loss: 0.49; acc: 0.89
Batch: 420; loss: 0.64; acc: 0.8
Batch: 440; loss: 0.44; acc: 0.91
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.81
Batch: 640; loss: 0.44; acc: 0.91
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.66; acc: 0.78
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.65; acc: 0.86
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.81
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.61; train_accuracy: 0.82 

1.7032112737069838e-05
5.891786713618785e-06
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.44015102952149265; val_accuracy: 0.8669386942675159 

The current subspace-distance is: 5.891786713618785e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.68; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.8
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.83
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.7; acc: 0.84
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.67; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.83
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.6; acc: 0.89
Batch: 300; loss: 0.58; acc: 0.8
Batch: 320; loss: 0.52; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.86
Batch: 400; loss: 0.64; acc: 0.81
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.45; acc: 0.89
Batch: 540; loss: 0.62; acc: 0.84
Batch: 560; loss: 0.68; acc: 0.83
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.91
Batch: 640; loss: 0.62; acc: 0.83
Batch: 660; loss: 0.47; acc: 0.91
Batch: 680; loss: 0.55; acc: 0.89
Batch: 700; loss: 0.48; acc: 0.88
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.54; acc: 0.81
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.45; train_accuracy: 0.87 

1.8391694538877346e-05
6.295910679909866e-06
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.63; acc: 0.78
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.6; acc: 0.86
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.55; acc: 0.81
Batch: 120; loss: 0.98; acc: 0.7
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.5216213661204477; val_accuracy: 0.8409633757961783 

The current subspace-distance is: 6.295910679909866e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.77
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.53; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.57; acc: 0.86
Batch: 180; loss: 0.41; acc: 0.84
Batch: 200; loss: 0.48; acc: 0.84
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.64; acc: 0.86
Batch: 300; loss: 0.72; acc: 0.83
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.86
Batch: 420; loss: 0.46; acc: 0.81
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.61; acc: 0.81
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.53; acc: 0.88
Batch: 640; loss: 0.43; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.54; acc: 0.81
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

1.9071063434239477e-05
5.872537258255761e-06
Batch: 0; loss: 0.86; acc: 0.7
Batch: 20; loss: 1.05; acc: 0.64
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 1.38; acc: 0.7
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.97; acc: 0.7
Batch: 120; loss: 1.45; acc: 0.56
Batch: 140; loss: 0.75; acc: 0.73
Val Epoch over. val_loss: 0.9147149762909883; val_accuracy: 0.7298964968152867 

The current subspace-distance is: 5.872537258255761e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.33; acc: 0.64
Batch: 20; loss: 0.69; acc: 0.78
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.54; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.83
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.5; acc: 0.84
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.86
Batch: 420; loss: 0.51; acc: 0.86
Batch: 440; loss: 0.43; acc: 0.81
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.51; acc: 0.81
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

1.9621142200776376e-05
6.903742360009346e-06
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.78; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.97; acc: 0.72
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.5126056606602517; val_accuracy: 0.8357882165605095 

The current subspace-distance is: 6.903742360009346e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.45; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.41; acc: 0.92
Batch: 260; loss: 0.47; acc: 0.83
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.62; acc: 0.78
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.92
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.91
Batch: 780; loss: 0.64; acc: 0.81
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.0393470549606718e-05
6.892789315315895e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.63; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.33666919181301336; val_accuracy: 0.8980891719745223 

The current subspace-distance is: 6.892789315315895e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.55; acc: 0.84
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.52; acc: 0.86
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.98
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.98
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.21; acc: 0.89
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.95
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.055799268418923e-05
5.761642114521237e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.98; acc: 0.73
Batch: 140; loss: 0.15; acc: 0.92
Val Epoch over. val_loss: 0.34630220143753254; val_accuracy: 0.8963972929936306 

The current subspace-distance is: 5.761642114521237e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.79; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.61; acc: 0.86
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.58; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.48; acc: 0.81
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.84
Batch: 540; loss: 0.56; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.84; acc: 0.78
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

1.957789936568588e-05
5.630940449918853e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.56; acc: 0.8
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.42; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 1.16; acc: 0.7
Batch: 140; loss: 0.22; acc: 0.89
Val Epoch over. val_loss: 0.41391515515887056; val_accuracy: 0.8715167197452229 

The current subspace-distance is: 5.630940449918853e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.92
Batch: 320; loss: 0.71; acc: 0.78
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.56; acc: 0.83
Batch: 480; loss: 0.44; acc: 0.83
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.92
Batch: 600; loss: 0.55; acc: 0.83
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.48; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.61; acc: 0.84
Batch: 720; loss: 0.51; acc: 0.88
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

1.9986448023701087e-05
6.331524673441891e-06
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.7; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.94; acc: 0.73
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.451869700887021; val_accuracy: 0.8651472929936306 

The current subspace-distance is: 6.331524673441891e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.83
Batch: 280; loss: 0.61; acc: 0.81
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.43; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.68; acc: 0.84
Batch: 600; loss: 0.53; acc: 0.81
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.008524643315468e-05
6.0359325289027765e-06
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.6; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.9; acc: 0.75
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.34913141531929087; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 6.0359325289027765e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.29; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.52; acc: 0.81
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0358180336188525e-05
6.172513167257421e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.3048899640940177; val_accuracy: 0.9097332802547771 

The current subspace-distance is: 6.172513167257421e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.56; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.7; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.095647323585581e-05
6.466325430665165e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.08; acc: 1.0
Val Epoch over. val_loss: 0.3057280721937775; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 6.466325430665165e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.6; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.48; acc: 0.81
Batch: 160; loss: 0.76; acc: 0.8
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.65; acc: 0.88
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.95
Batch: 260; loss: 0.63; acc: 0.88
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.38; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.82; acc: 0.84
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.86
Batch: 700; loss: 0.3; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

1.9825043636956252e-05
6.381560979207279e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.81; acc: 0.81
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.3090174157575817; val_accuracy: 0.9096337579617835 

The current subspace-distance is: 6.381560979207279e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.45; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.47; acc: 0.89
Batch: 160; loss: 0.5; acc: 0.86
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.94
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.44; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.86
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.43; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

1.9768174752243795e-05
6.260922873480013e-06
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.86; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.34725955555773086; val_accuracy: 0.8955015923566879 

The current subspace-distance is: 6.260922873480013e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.6; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.83
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.42; acc: 0.84
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.58; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.98
Batch: 440; loss: 0.39; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.32; acc: 0.95
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.5; acc: 0.88
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.97
Batch: 780; loss: 0.37; acc: 0.83
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.071416747639887e-05
6.76545232636272e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.30883128926822334; val_accuracy: 0.9105294585987261 

The current subspace-distance is: 6.76545232636272e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.55; acc: 0.89
Batch: 160; loss: 0.48; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.88
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.61; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.83
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.5; acc: 0.91
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.23; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.66; acc: 0.83
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0867006242042407e-05
6.5570325205044355e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.30704972169296757; val_accuracy: 0.9090366242038217 

The current subspace-distance is: 6.5570325205044355e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.42; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.57; acc: 0.84
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.55; acc: 0.83
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.51; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.51; acc: 0.8
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0223766114213504e-05
6.959860002098139e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.79; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.310764428797611; val_accuracy: 0.9068471337579618 

The current subspace-distance is: 6.959860002098139e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.84
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.47; acc: 0.8
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.47; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.54; acc: 0.84
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

1.9523620721884072e-05
6.440453034883831e-06
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3187834686914067; val_accuracy: 0.9037619426751592 

The current subspace-distance is: 6.440453034883831e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.89
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.84
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

1.9907616660930216e-05
6.919534826010931e-06
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3185412375505563; val_accuracy: 0.9036624203821656 

The current subspace-distance is: 6.919534826010931e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.86
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.53; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.62; acc: 0.86
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.86
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.62; acc: 0.81
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.53; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0593746739905328e-05
5.714286999136675e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.31099159377300817; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 5.714286999136675e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.95
Batch: 480; loss: 0.36; acc: 0.83
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.51; acc: 0.8
Batch: 680; loss: 0.59; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0903595213894732e-05
6.3582288021279965e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.30061165620661845; val_accuracy: 0.9103304140127388 

The current subspace-distance is: 6.3582288021279965e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.47; acc: 0.8
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.81
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.94
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.46; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.84
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.81
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.86
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.09898644243367e-05
6.307846433628583e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.81; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.30309445728921586; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 6.307846433628583e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.57; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.6; acc: 0.86
Batch: 280; loss: 0.62; acc: 0.81
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.12; acc: 0.98
Batch: 460; loss: 0.28; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.56; acc: 0.86
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

1.9702347344718874e-05
6.411434696929064e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.82; acc: 0.78
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3101418584490278; val_accuracy: 0.9104299363057324 

The current subspace-distance is: 6.411434696929064e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.59; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.38; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.86
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.39; acc: 0.92
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0286895960452966e-05
6.299507731455378e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.30091353660081605; val_accuracy: 0.9090366242038217 

The current subspace-distance is: 6.299507731455378e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.83
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.48; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.53; acc: 0.8
Batch: 300; loss: 0.55; acc: 0.84
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.44; acc: 0.81
Batch: 360; loss: 0.26; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.86
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0174233213765547e-05
6.0634133660641965e-06
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.30266385072260904; val_accuracy: 0.9091361464968153 

The current subspace-distance is: 6.0634133660641965e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.52; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.52; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.66; acc: 0.84
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.46; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

1.9359389625606127e-05
5.82979419050389e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.8; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3030691249355389; val_accuracy: 0.9095342356687898 

The current subspace-distance is: 5.82979419050389e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.42; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.86
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.52; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.51; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.141879485861864e-05
6.658794063696405e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.30374382559660895; val_accuracy: 0.9102308917197452 

The current subspace-distance is: 6.658794063696405e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.98
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.81; acc: 0.83
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.55; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0666799173341133e-05
6.555042546096956e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.300612946272276; val_accuracy: 0.9109275477707006 

The current subspace-distance is: 6.555042546096956e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.95
Batch: 20; loss: 0.59; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.84
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.86
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.65; acc: 0.81
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.88
Batch: 700; loss: 0.56; acc: 0.84
Batch: 720; loss: 0.42; acc: 0.83
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.122542355209589e-05
5.8639648159442e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.30242881805274135; val_accuracy: 0.9090366242038217 

The current subspace-distance is: 5.8639648159442e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.86
Batch: 300; loss: 0.39; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.52; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.68; acc: 0.86
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.61; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.44; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.91
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1073754396638833e-05
6.298480457189726e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.81; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.302277015771266; val_accuracy: 0.9116242038216561 

The current subspace-distance is: 6.298480457189726e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.71; acc: 0.73
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.65; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.11; acc: 0.98
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.42; acc: 0.92
Batch: 660; loss: 0.52; acc: 0.83
Batch: 680; loss: 0.53; acc: 0.8
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.157052222173661e-05
5.995887931931065e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.29945246998671515; val_accuracy: 0.9104299363057324 

The current subspace-distance is: 5.995887931931065e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.84
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.86
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.019221028604079e-05
5.738346317230025e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.79; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.29935655942198575; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 5.738346317230025e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.39; acc: 0.83
Batch: 240; loss: 0.19; acc: 0.98
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.33; acc: 0.86
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.25; acc: 0.97
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.63; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.92
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

1.9692288333317265e-05
5.716319265047787e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.29929723400788705; val_accuracy: 0.9105294585987261 

The current subspace-distance is: 5.716319265047787e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.86
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.6; acc: 0.84
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.5; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.82; acc: 0.81
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.4; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.88
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0889227016596124e-05
7.030859705992043e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.79; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2980348649583045; val_accuracy: 0.9121218152866242 

The current subspace-distance is: 7.030859705992043e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.36; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.92
Batch: 220; loss: 0.1; acc: 1.0
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.81
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.5; acc: 0.83
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.51; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.84
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.1017716790083796e-05
5.8488080867391545e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.29846385676579873; val_accuracy: 0.9113256369426752 

The current subspace-distance is: 5.8488080867391545e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.83
Batch: 440; loss: 0.34; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.16; acc: 0.98
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0192443116684444e-05
6.287529686233029e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2981628535469626; val_accuracy: 0.9118232484076433 

The current subspace-distance is: 6.287529686233029e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.51; acc: 0.83
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.45; acc: 0.81
Batch: 160; loss: 0.47; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.57; acc: 0.84
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.43; acc: 0.86
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.59; acc: 0.84
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.63; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.95
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.0466142814257182e-05
6.799836683057947e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.81; acc: 0.8
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.30241300528691073; val_accuracy: 0.9103304140127388 

The current subspace-distance is: 6.799836683057947e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.51; acc: 0.81
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.54; acc: 0.86
Batch: 180; loss: 0.4; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.94
Batch: 340; loss: 0.65; acc: 0.83
Batch: 360; loss: 0.6; acc: 0.84
Batch: 380; loss: 0.61; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.52; acc: 0.88
Batch: 580; loss: 0.69; acc: 0.8
Batch: 600; loss: 0.48; acc: 0.83
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.43; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.44; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.001444408961106e-05
5.941247763985302e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2974779461836739; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 5.941247763985302e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.54; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.48; acc: 0.83
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.88
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.0391909856698476e-05
6.651330295426305e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2978165766615776; val_accuracy: 0.9120222929936306 

The current subspace-distance is: 6.651330295426305e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.66; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.56; acc: 0.88
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.48; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.98
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.75; acc: 0.81
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.038857746811118e-05
6.861219389975304e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.79; acc: 0.8
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2994591644757493; val_accuracy: 0.9097332802547771 

The current subspace-distance is: 6.861219389975304e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.97
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.8
Batch: 300; loss: 0.34; acc: 0.83
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.47; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.46; acc: 0.83
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.41; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.0287701772758737e-05
6.030271379131591e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.29711631282119993; val_accuracy: 0.9106289808917197 

The current subspace-distance is: 6.030271379131591e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.5; acc: 0.88
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.54; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.4; acc: 0.84
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.25; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.39; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.53; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.079689147649333e-05
6.3662391767138615e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.297018070723031; val_accuracy: 0.9123208598726115 

The current subspace-distance is: 6.3662391767138615e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.63; acc: 0.84
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.58; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.86
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.59; acc: 0.86
Batch: 380; loss: 0.41; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.56; acc: 0.83
Batch: 760; loss: 0.27; acc: 0.88
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.108199078065809e-05
6.34782736597117e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2968920628498694; val_accuracy: 0.9117237261146497 

The current subspace-distance is: 6.34782736597117e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.84
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.35; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.4; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.97
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.0424120521056466e-05
6.703602593916003e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.29764519043409143; val_accuracy: 0.9118232484076433 

The current subspace-distance is: 6.703602593916003e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.44; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.91
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.1338217266020365e-05
6.687169843644369e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2970129402864511; val_accuracy: 0.9114251592356688 

The current subspace-distance is: 6.687169843644369e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.73; acc: 0.78
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.5; acc: 0.84
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.53; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.94
Batch: 680; loss: 0.52; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.1039400962763466e-05
6.222947831702186e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2978849723745304; val_accuracy: 0.9120222929936306 

The current subspace-distance is: 6.222947831702186e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.95
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.53; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.88
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.1010107957408763e-05
5.511162271432113e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2974214579221929; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 5.511162271432113e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.53; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.53; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.0480287275859155e-05
6.781009687983897e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.2979445025134998; val_accuracy: 0.9114251592356688 

The current subspace-distance is: 6.781009687983897e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.31; acc: 0.84
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.84
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.58; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.069210859190207e-05
6.817945177317597e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2981337374135567; val_accuracy: 0.9110270700636943 

The current subspace-distance is: 6.817945177317597e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.81
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.86
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.47; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.83
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.83
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.91 

2.1288078642101027e-05
6.682085313514108e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2970389225253254; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 6.682085313514108e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 44502
elements in E: 9329460
fraction nonzero: 0.004770050999736319
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.05
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.06
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.11
Batch: 300; loss: 2.27; acc: 0.19
Batch: 320; loss: 2.27; acc: 0.11
Batch: 340; loss: 2.26; acc: 0.16
Batch: 360; loss: 2.27; acc: 0.11
Batch: 380; loss: 2.26; acc: 0.22
Batch: 400; loss: 2.24; acc: 0.25
Batch: 420; loss: 2.24; acc: 0.25
Batch: 440; loss: 2.23; acc: 0.36
Batch: 460; loss: 2.2; acc: 0.44
Batch: 480; loss: 2.16; acc: 0.44
Batch: 500; loss: 2.08; acc: 0.53
Batch: 520; loss: 2.01; acc: 0.64
Batch: 540; loss: 1.88; acc: 0.61
Batch: 560; loss: 1.63; acc: 0.67
Batch: 580; loss: 1.4; acc: 0.69
Batch: 600; loss: 1.21; acc: 0.66
Batch: 620; loss: 0.91; acc: 0.75
Batch: 640; loss: 0.84; acc: 0.73
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.54; acc: 0.86
Batch: 700; loss: 0.69; acc: 0.83
Batch: 720; loss: 0.49; acc: 0.88
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.87; acc: 0.69
Batch: 780; loss: 0.64; acc: 0.86
Train Epoch over. train_loss: 1.84; train_accuracy: 0.36 

9.768647942109965e-06
4.896277005173033e-06
Batch: 0; loss: 0.87; acc: 0.69
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.49; acc: 0.89
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.76; acc: 0.81
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 0.86; acc: 0.72
Batch: 140; loss: 0.35; acc: 0.91
Val Epoch over. val_loss: 0.7051196796878888; val_accuracy: 0.7777667197452229 

The current subspace-distance is: 4.896277005173033e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.7
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.89; acc: 0.72
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.61; acc: 0.8
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.66; acc: 0.83
Batch: 160; loss: 0.59; acc: 0.78
Batch: 180; loss: 0.58; acc: 0.88
Batch: 200; loss: 0.61; acc: 0.78
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.68; acc: 0.78
Batch: 320; loss: 0.6; acc: 0.78
Batch: 340; loss: 0.52; acc: 0.81
Batch: 360; loss: 0.64; acc: 0.81
Batch: 380; loss: 0.48; acc: 0.84
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.66; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.83
Batch: 540; loss: 0.58; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.57; acc: 0.77
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.61; acc: 0.75
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.56; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.83
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

1.6934731320361607e-05
5.3977450988895725e-06
Batch: 0; loss: 0.74; acc: 0.73
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.41; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.44; acc: 0.81
Batch: 100; loss: 0.53; acc: 0.8
Batch: 120; loss: 0.82; acc: 0.75
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.573716931946718; val_accuracy: 0.8109076433121019 

The current subspace-distance is: 5.3977450988895725e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.77
Batch: 20; loss: 0.69; acc: 0.83
Batch: 40; loss: 0.44; acc: 0.8
Batch: 60; loss: 0.46; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.89
Batch: 120; loss: 0.56; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.44; acc: 0.89
Batch: 180; loss: 0.67; acc: 0.81
Batch: 200; loss: 0.75; acc: 0.78
Batch: 220; loss: 0.68; acc: 0.84
Batch: 240; loss: 0.49; acc: 0.83
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.62; acc: 0.8
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.39; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.49; acc: 0.83
Batch: 540; loss: 0.51; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.84
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.53; acc: 0.83
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.57; acc: 0.81
Batch: 760; loss: 0.63; acc: 0.83
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

1.9199418602511287e-05
6.346283953462262e-06
Batch: 0; loss: 0.62; acc: 0.77
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.81
Batch: 80; loss: 0.76; acc: 0.8
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.7
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.6424275389902151; val_accuracy: 0.7916003184713376 

The current subspace-distance is: 6.346283953462262e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.81
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.84; acc: 0.81
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.47; acc: 0.88
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.55; acc: 0.8
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.58; acc: 0.83
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.46; acc: 0.83
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.66; acc: 0.86
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.65; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.49; acc: 0.81
Batch: 780; loss: 0.46; acc: 0.81
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

1.9959252313128673e-05
6.712839876854559e-06
Batch: 0; loss: 0.62; acc: 0.75
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 1.0; acc: 0.72
Batch: 80; loss: 0.65; acc: 0.81
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 1.31; acc: 0.58
Batch: 140; loss: 0.52; acc: 0.8
Val Epoch over. val_loss: 0.6425414395749949; val_accuracy: 0.7981687898089171 

The current subspace-distance is: 6.712839876854559e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.17; acc: 0.62
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.53; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.81
Batch: 160; loss: 0.52; acc: 0.84
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.54; acc: 0.84
Batch: 220; loss: 0.5; acc: 0.81
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.62; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.84
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.56; acc: 0.81
Batch: 500; loss: 0.27; acc: 0.95
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.75; acc: 0.75
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.62; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

1.9714494555955753e-05
6.447115993069019e-06
Batch: 0; loss: 1.17; acc: 0.61
Batch: 20; loss: 1.76; acc: 0.5
Batch: 40; loss: 0.95; acc: 0.75
Batch: 60; loss: 1.81; acc: 0.52
Batch: 80; loss: 1.65; acc: 0.56
Batch: 100; loss: 1.45; acc: 0.59
Batch: 120; loss: 2.24; acc: 0.52
Batch: 140; loss: 1.26; acc: 0.62
Val Epoch over. val_loss: 1.4648028817146448; val_accuracy: 0.6096735668789809 

The current subspace-distance is: 6.447115993069019e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.59; acc: 0.52
Batch: 20; loss: 0.34; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.55; acc: 0.81
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.45; acc: 0.89
Batch: 280; loss: 0.42; acc: 0.91
Batch: 300; loss: 0.61; acc: 0.83
Batch: 320; loss: 0.51; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.46; acc: 0.89
Batch: 420; loss: 0.61; acc: 0.77
Batch: 440; loss: 0.27; acc: 0.86
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.31; acc: 0.86
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.54; acc: 0.84
Batch: 580; loss: 0.37; acc: 0.86
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.89
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.77; acc: 0.73
Batch: 780; loss: 0.8; acc: 0.8
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

1.9732015061890706e-05
6.19877801000257e-06
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 1.04; acc: 0.7
Batch: 140; loss: 0.26; acc: 0.94
Val Epoch over. val_loss: 0.4942471534013748; val_accuracy: 0.8438495222929936 

The current subspace-distance is: 6.19877801000257e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.49; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.84
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.45; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.64; acc: 0.83
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.59; acc: 0.83
Batch: 540; loss: 0.51; acc: 0.84
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.72; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.53; acc: 0.77
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.49; acc: 0.83
Batch: 740; loss: 0.38; acc: 0.81
Batch: 760; loss: 0.21; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0019642761326395e-05
6.582028618140612e-06
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35330144600693586; val_accuracy: 0.8961982484076433 

The current subspace-distance is: 6.582028618140612e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.76; acc: 0.8
Batch: 40; loss: 0.3; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.86
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.57; acc: 0.88
Batch: 220; loss: 0.49; acc: 0.81
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.84
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.6; acc: 0.84
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.46; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.86
Batch: 540; loss: 0.5; acc: 0.83
Batch: 560; loss: 0.62; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.74; acc: 0.81
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.51; acc: 0.84
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

1.95616485143546e-05
6.953162937861634e-06
Batch: 0; loss: 1.54; acc: 0.58
Batch: 20; loss: 2.93; acc: 0.45
Batch: 40; loss: 0.88; acc: 0.75
Batch: 60; loss: 1.97; acc: 0.47
Batch: 80; loss: 1.88; acc: 0.62
Batch: 100; loss: 1.54; acc: 0.59
Batch: 120; loss: 2.45; acc: 0.56
Batch: 140; loss: 1.49; acc: 0.69
Val Epoch over. val_loss: 1.9321177598017796; val_accuracy: 0.5672770700636943 

The current subspace-distance is: 6.953162937861634e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.05; acc: 0.61
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.59; acc: 0.81
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.55; acc: 0.84
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.91; acc: 0.8
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.8
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.54; acc: 0.84
Batch: 560; loss: 0.46; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.5; acc: 0.84
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.94
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.54; acc: 0.86
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0389874407555908e-05
7.209704108390724e-06
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.4295413274863723; val_accuracy: 0.8718152866242038 

The current subspace-distance is: 7.209704108390724e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.83
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.58; acc: 0.86
Batch: 420; loss: 0.25; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.35; acc: 0.84
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

1.974267615878489e-05
7.142827598727308e-06
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.59; acc: 0.77
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.91
Batch: 120; loss: 1.1; acc: 0.72
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.44553994131126223; val_accuracy: 0.8598726114649682 

The current subspace-distance is: 7.142827598727308e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.75; acc: 0.81
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.94
Batch: 240; loss: 0.41; acc: 0.84
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.4; acc: 0.83
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.84
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.94
Batch: 660; loss: 0.44; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.42; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.0042525648023002e-05
6.408133685908979e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3095473170185545; val_accuracy: 0.9076433121019108 

The current subspace-distance is: 6.408133685908979e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.58; acc: 0.84
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.5; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.57; acc: 0.86
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.42; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

1.9798975699814036e-05
6.965099146327702e-06
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.31375195290062835; val_accuracy: 0.9085390127388535 

The current subspace-distance is: 6.965099146327702e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.94
Batch: 260; loss: 0.51; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.46; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.47; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.53; acc: 0.81
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.8
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0306040823925287e-05
6.503840722871246e-06
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.32541460159477914; val_accuracy: 0.9029657643312102 

The current subspace-distance is: 6.503840722871246e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.86
Batch: 220; loss: 0.61; acc: 0.77
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.44; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.83
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0324034267105162e-05
6.522617695736699e-06
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3626859890427559; val_accuracy: 0.894406847133758 

The current subspace-distance is: 6.522617695736699e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.49; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.95
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.86
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.012601362366695e-05
6.878394742670935e-06
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.81
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3309677349059445; val_accuracy: 0.8995820063694268 

The current subspace-distance is: 6.878394742670935e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.37; acc: 0.81
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.59; acc: 0.88
Batch: 160; loss: 0.54; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.84
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.73; acc: 0.86
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.43; acc: 0.84
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.65; acc: 0.88
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.55; acc: 0.8
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0445153495529667e-05
7.242296760523459e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.83
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3092622620284937; val_accuracy: 0.9050557324840764 

The current subspace-distance is: 7.242296760523459e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.83; acc: 0.77
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.54; acc: 0.84
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.35; acc: 0.83
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.57; acc: 0.88
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.38; acc: 0.86
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

1.9972159861936234e-05
6.2119706853991374e-06
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35267764168560123; val_accuracy: 0.8984872611464968 

The current subspace-distance is: 6.2119706853991374e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.5; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.35; acc: 0.94
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.89
Batch: 680; loss: 0.37; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.84
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.0153374862275086e-05
6.686561391688883e-06
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.8
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.4332044111790171; val_accuracy: 0.8716162420382165 

The current subspace-distance is: 6.686561391688883e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.95
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.45; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.83
Batch: 580; loss: 0.33; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.49; acc: 0.8
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0363018848001957e-05
7.126785476430086e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.30772789145351215; val_accuracy: 0.9084394904458599 

The current subspace-distance is: 7.126785476430086e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.61; acc: 0.78
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.13; acc: 0.98
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

1.9863738998537883e-05
6.428673714253819e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.75
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.3092106996448177; val_accuracy: 0.9078423566878981 

The current subspace-distance is: 6.428673714253819e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.58; acc: 0.83
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.61; acc: 0.81
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.83
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.020534338953439e-05
6.483452580141602e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2896550023441861; val_accuracy: 0.912718949044586 

The current subspace-distance is: 6.483452580141602e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.94
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.5; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

1.9910447008442134e-05
6.845497409813106e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.30123020428570974; val_accuracy: 0.9085390127388535 

The current subspace-distance is: 6.845497409813106e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.5; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.61; acc: 0.8
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.55; acc: 0.89
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.92
Batch: 620; loss: 0.47; acc: 0.8
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.4; acc: 0.83
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.0667257558670826e-05
6.677385499642696e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2963855069154387; val_accuracy: 0.9103304140127388 

The current subspace-distance is: 6.677385499642696e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.53; acc: 0.88
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0229075744282454e-05
7.654589353478514e-06
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2990250665765659; val_accuracy: 0.9131170382165605 

The current subspace-distance is: 7.654589353478514e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.46; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.84
Batch: 200; loss: 0.18; acc: 0.98
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.66; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.5; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.83
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.37; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.064784712274559e-05
7.228771210066043e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.29164127848900046; val_accuracy: 0.914609872611465 

The current subspace-distance is: 7.228771210066043e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.55; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.42; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.24; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0839990611420944e-05
6.489870429504663e-06
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28474858222873345; val_accuracy: 0.9136146496815286 

The current subspace-distance is: 6.489870429504663e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.42; acc: 0.84
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.45; acc: 0.92
Batch: 320; loss: 0.49; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.65; acc: 0.81
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.37; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

1.975596387637779e-05
6.8235303842811845e-06
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.84
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.83
Batch: 120; loss: 0.77; acc: 0.75
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.36187846740339974; val_accuracy: 0.8872412420382165 

The current subspace-distance is: 6.8235303842811845e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.33; acc: 0.83
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.58; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.8
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.53; acc: 0.89
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.52; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0450297597562894e-05
6.4585901782265864e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.77
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.29597136890812287; val_accuracy: 0.9086385350318471 

The current subspace-distance is: 6.4585901782265864e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.52; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.83
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0932035113219172e-05
7.424365776387276e-06
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.31422319201527127; val_accuracy: 0.9078423566878981 

The current subspace-distance is: 7.424365776387276e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.97
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.6; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.6; acc: 0.84
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.36; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.38; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0379848137963563e-05
6.4607047534082085e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2831086038973681; val_accuracy: 0.9152070063694268 

The current subspace-distance is: 6.4607047534082085e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.63; acc: 0.83
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.4; acc: 0.86
Batch: 400; loss: 0.39; acc: 0.83
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.56; acc: 0.84
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.157009657821618e-05
6.9701973188784905e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28355929440563654; val_accuracy: 0.9165007961783439 

The current subspace-distance is: 6.9701973188784905e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.42; acc: 0.81
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.46; acc: 0.81
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.49; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

1.984846494451631e-05
7.263305633387063e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.28046844548480526; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 7.263305633387063e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.38; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.86
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.46; acc: 0.88
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0479363229242153e-05
6.555204436153872e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2833598929036195; val_accuracy: 0.9170979299363057 

The current subspace-distance is: 6.555204436153872e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.45; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.8
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.42; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.66; acc: 0.81
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.049577778961975e-05
7.777618520776741e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2837270449870711; val_accuracy: 0.9132165605095541 

The current subspace-distance is: 7.777618520776741e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.42; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.88
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.47; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.31; acc: 0.86
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.44; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.57; acc: 0.84
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0356230379547924e-05
7.0808923737786245e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2821012975493814; val_accuracy: 0.9139132165605095 

The current subspace-distance is: 7.0808923737786245e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.55; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.032674638030585e-05
7.192234079411719e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.27979574599273643; val_accuracy: 0.9152070063694268 

The current subspace-distance is: 7.192234079411719e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.49; acc: 0.81
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.043018139374908e-05
7.0580458668700885e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2896036180151496; val_accuracy: 0.9113256369426752 

The current subspace-distance is: 7.0580458668700885e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.53; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.47; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.86
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.58; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

1.9977465854026377e-05
6.580446552106878e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2839838492737454; val_accuracy: 0.9177945859872612 

The current subspace-distance is: 6.580446552106878e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.57; acc: 0.78
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.88
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.054590186162386e-05
7.307725809369003e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.28021449747548743; val_accuracy: 0.9159036624203821 

The current subspace-distance is: 7.307725809369003e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.8
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.84
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.88
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.4; acc: 0.92
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.098236836900469e-05
6.252349976421101e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2815758510000387; val_accuracy: 0.9158041401273885 

The current subspace-distance is: 6.252349976421101e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.44; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.88
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.56; acc: 0.81
Batch: 300; loss: 0.49; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.55; acc: 0.81
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.86
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.0151046555838548e-05
7.176412509579677e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27898094357009146; val_accuracy: 0.9164012738853503 

The current subspace-distance is: 7.176412509579677e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.5; acc: 0.94
Batch: 260; loss: 0.4; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.84
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.0162546206847765e-05
7.1860436037241016e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27967456296371046; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 7.1860436037241016e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.056958692264743e-05
7.252939667523606e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2796295454168016; val_accuracy: 0.9163017515923567 

The current subspace-distance is: 7.252939667523606e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.49; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.038972161244601e-05
7.764529982523527e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2789447219793204; val_accuracy: 0.916202229299363 

The current subspace-distance is: 7.764529982523527e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.84
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.5; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.39; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.45; acc: 0.84
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.138830859621521e-05
7.174738584581064e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27857558552626593; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 7.174738584581064e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.56; acc: 0.84
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.56; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.53; acc: 0.86
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.44; acc: 0.86
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

1.9934050214942545e-05
7.019820714049274e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27904821187257767; val_accuracy: 0.9171974522292994 

The current subspace-distance is: 7.019820714049274e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.48; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.0552794012473896e-05
6.494176432170207e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2787510304693963; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 6.494176432170207e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.47; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.23; acc: 0.89
Batch: 440; loss: 0.58; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

1.9799779693130404e-05
6.636742000409868e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27899062320305285; val_accuracy: 0.916202229299363 

The current subspace-distance is: 6.636742000409868e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.84
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.64; acc: 0.84
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.88
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.86
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.0332243366283365e-05
5.948460056970362e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.28133874229944433; val_accuracy: 0.9170979299363057 

The current subspace-distance is: 5.948460056970362e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.52; acc: 0.81
Batch: 460; loss: 0.62; acc: 0.83
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.88
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.49; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.84
Batch: 740; loss: 0.23; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.0025750927743502e-05
7.227534297271632e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27864040628929804; val_accuracy: 0.9173964968152867 

The current subspace-distance is: 7.227534297271632e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_210_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 46137
elements in E: 9773720
fraction nonzero: 0.004720515832252203
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.3; acc: 0.09
Batch: 280; loss: 2.29; acc: 0.16
Batch: 300; loss: 2.28; acc: 0.17
Batch: 320; loss: 2.28; acc: 0.12
Batch: 340; loss: 2.27; acc: 0.19
Batch: 360; loss: 2.28; acc: 0.14
Batch: 380; loss: 2.28; acc: 0.16
Batch: 400; loss: 2.27; acc: 0.23
Batch: 420; loss: 2.28; acc: 0.2
Batch: 440; loss: 2.26; acc: 0.38
Batch: 460; loss: 2.26; acc: 0.3
Batch: 480; loss: 2.25; acc: 0.31
Batch: 500; loss: 2.23; acc: 0.33
Batch: 520; loss: 2.22; acc: 0.45
Batch: 540; loss: 2.22; acc: 0.36
Batch: 560; loss: 2.21; acc: 0.34
Batch: 580; loss: 2.18; acc: 0.33
Batch: 600; loss: 2.19; acc: 0.39
Batch: 620; loss: 2.11; acc: 0.45
Batch: 640; loss: 1.99; acc: 0.58
Batch: 660; loss: 1.93; acc: 0.52
Batch: 680; loss: 1.85; acc: 0.58
Batch: 700; loss: 1.41; acc: 0.66
Batch: 720; loss: 1.45; acc: 0.56
Batch: 740; loss: 0.94; acc: 0.78
Batch: 760; loss: 1.1; acc: 0.64
Batch: 780; loss: 0.8; acc: 0.73
Train Epoch over. train_loss: 2.11; train_accuracy: 0.28 

8.409331712755375e-06
4.615394118445693e-06
Batch: 0; loss: 1.04; acc: 0.62
Batch: 20; loss: 1.21; acc: 0.62
Batch: 40; loss: 0.76; acc: 0.81
Batch: 60; loss: 0.97; acc: 0.72
Batch: 80; loss: 0.81; acc: 0.75
Batch: 100; loss: 0.8; acc: 0.75
Batch: 120; loss: 1.22; acc: 0.67
Batch: 140; loss: 0.57; acc: 0.86
Val Epoch over. val_loss: 0.9544900830384273; val_accuracy: 0.7123805732484076 

The current subspace-distance is: 4.615394118445693e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.97; acc: 0.67
Batch: 20; loss: 0.84; acc: 0.72
Batch: 40; loss: 0.89; acc: 0.72
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.81; acc: 0.72
Batch: 100; loss: 0.99; acc: 0.69
Batch: 120; loss: 0.72; acc: 0.7
Batch: 140; loss: 0.76; acc: 0.77
Batch: 160; loss: 0.65; acc: 0.8
Batch: 180; loss: 0.58; acc: 0.88
Batch: 200; loss: 0.61; acc: 0.77
Batch: 220; loss: 0.49; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.72; acc: 0.78
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.71; acc: 0.78
Batch: 320; loss: 0.71; acc: 0.78
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.69; acc: 0.81
Batch: 380; loss: 0.57; acc: 0.83
Batch: 400; loss: 0.52; acc: 0.88
Batch: 420; loss: 0.68; acc: 0.78
Batch: 440; loss: 0.87; acc: 0.83
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.61; acc: 0.84
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.58; acc: 0.77
Batch: 640; loss: 0.71; acc: 0.8
Batch: 660; loss: 0.57; acc: 0.78
Batch: 680; loss: 0.44; acc: 0.92
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.68; acc: 0.81
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.63; train_accuracy: 0.81 

1.8061513401335105e-05
6.1523192016466055e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.78; acc: 0.77
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.57; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.4805848425740649; val_accuracy: 0.8543988853503185 

The current subspace-distance is: 6.1523192016466055e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.75; acc: 0.81
Batch: 40; loss: 0.46; acc: 0.81
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.51; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.78; acc: 0.8
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.5; acc: 0.83
Batch: 180; loss: 0.57; acc: 0.81
Batch: 200; loss: 0.68; acc: 0.75
Batch: 220; loss: 0.67; acc: 0.8
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.68; acc: 0.78
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.84; acc: 0.77
Batch: 320; loss: 0.76; acc: 0.73
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.49; acc: 0.84
Batch: 400; loss: 0.63; acc: 0.83
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.52; acc: 0.84
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.66; acc: 0.77
Batch: 540; loss: 0.77; acc: 0.8
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.58; acc: 0.8
Batch: 620; loss: 0.38; acc: 0.84
Batch: 640; loss: 0.6; acc: 0.78
Batch: 660; loss: 0.43; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.84
Batch: 700; loss: 0.47; acc: 0.86
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.64; acc: 0.8
Batch: 760; loss: 0.66; acc: 0.72
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

2.021300679189153e-05
5.918065653531812e-06
Batch: 0; loss: 0.44; acc: 0.81
Batch: 20; loss: 0.73; acc: 0.73
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.72; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 1.02; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.499124067034691; val_accuracy: 0.8447452229299363 

The current subspace-distance is: 5.918065653531812e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.63; acc: 0.73
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.63; acc: 0.81
Batch: 160; loss: 0.56; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.73; acc: 0.78
Batch: 300; loss: 0.62; acc: 0.84
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.61; acc: 0.78
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.48; acc: 0.83
Batch: 440; loss: 0.49; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.68; acc: 0.77
Batch: 560; loss: 0.71; acc: 0.78
Batch: 580; loss: 0.52; acc: 0.78
Batch: 600; loss: 0.7; acc: 0.81
Batch: 620; loss: 0.48; acc: 0.89
Batch: 640; loss: 0.53; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.51; acc: 0.75
Batch: 780; loss: 0.85; acc: 0.77
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

2.093416333082132e-05
6.568037406395888e-06
Batch: 0; loss: 1.38; acc: 0.61
Batch: 20; loss: 1.37; acc: 0.62
Batch: 40; loss: 1.06; acc: 0.73
Batch: 60; loss: 1.92; acc: 0.7
Batch: 80; loss: 1.41; acc: 0.69
Batch: 100; loss: 1.52; acc: 0.64
Batch: 120; loss: 2.07; acc: 0.53
Batch: 140; loss: 1.13; acc: 0.61
Val Epoch over. val_loss: 1.310992828220319; val_accuracy: 0.6541600318471338 

The current subspace-distance is: 6.568037406395888e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.14; acc: 0.48
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.6; acc: 0.75
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.67; acc: 0.8
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.52; acc: 0.78
Batch: 220; loss: 0.45; acc: 0.83
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.83
Batch: 440; loss: 0.53; acc: 0.8
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.48; acc: 0.83
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.57; acc: 0.84
Batch: 540; loss: 0.53; acc: 0.77
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.54; acc: 0.83
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

1.982766843866557e-05
6.25097982265288e-06
Batch: 0; loss: 0.47; acc: 0.8
Batch: 20; loss: 0.88; acc: 0.73
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.76; acc: 0.77
Batch: 80; loss: 0.69; acc: 0.86
Batch: 100; loss: 0.55; acc: 0.88
Batch: 120; loss: 1.19; acc: 0.72
Batch: 140; loss: 0.32; acc: 0.89
Val Epoch over. val_loss: 0.594882258516588; val_accuracy: 0.8070262738853503 

The current subspace-distance is: 6.25097982265288e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.56; acc: 0.89
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.78
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.48; acc: 0.81
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.53; acc: 0.81
Batch: 700; loss: 0.65; acc: 0.81
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.69; acc: 0.78
Batch: 780; loss: 0.51; acc: 0.83
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.0865167243755423e-05
6.772037068003556e-06
Batch: 0; loss: 0.66; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.84
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.64; acc: 0.83
Batch: 120; loss: 1.24; acc: 0.64
Batch: 140; loss: 0.31; acc: 0.92
Val Epoch over. val_loss: 0.5938795299097231; val_accuracy: 0.8140923566878981 

The current subspace-distance is: 6.772037068003556e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.75
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.62; acc: 0.8
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.6; acc: 0.84
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.77; acc: 0.77
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.94
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.84
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.42; acc: 0.86
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

2.035460238403175e-05
7.139418357837712e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.34871840837654794; val_accuracy: 0.8953025477707006 

The current subspace-distance is: 7.139418357837712e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.6; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.73; acc: 0.83
Batch: 160; loss: 0.65; acc: 0.75
Batch: 180; loss: 0.58; acc: 0.81
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.41; acc: 0.84
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.86
Batch: 460; loss: 0.42; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.4; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.64; acc: 0.81
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.73; acc: 0.81
Batch: 700; loss: 0.51; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.89
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.68; acc: 0.78
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.1525755073525943e-05
7.789815754222218e-06
Batch: 0; loss: 0.62; acc: 0.84
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.99; acc: 0.7
Batch: 80; loss: 0.49; acc: 0.81
Batch: 100; loss: 0.64; acc: 0.75
Batch: 120; loss: 1.26; acc: 0.77
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.6979664569827402; val_accuracy: 0.796875 

The current subspace-distance is: 7.789815754222218e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.5; acc: 0.89
Batch: 200; loss: 0.49; acc: 0.83
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.54; acc: 0.81
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.77; acc: 0.83
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.52; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.54; acc: 0.84
Batch: 480; loss: 0.68; acc: 0.8
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.92
Batch: 580; loss: 0.51; acc: 0.88
Batch: 600; loss: 0.75; acc: 0.8
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.77; acc: 0.8
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.49; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.2102820366853848e-05
7.154128979891539e-06
Batch: 0; loss: 0.39; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.41044336177740887; val_accuracy: 0.8751990445859873 

The current subspace-distance is: 7.154128979891539e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.45; acc: 0.83
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.86
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.59; acc: 0.81
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.62; acc: 0.86
Batch: 600; loss: 0.65; acc: 0.77
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.56; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.42; acc: 0.88
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

2.1668382032657973e-05
7.768647265038453e-06
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.89; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.37437715680356237; val_accuracy: 0.8876393312101911 

The current subspace-distance is: 7.768647265038453e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.83
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.23; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.91
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.88
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.41; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.43; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.42; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.107478394464124e-05
7.34387958800653e-06
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.83
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.3058545746526141; val_accuracy: 0.9071457006369427 

The current subspace-distance is: 7.34387958800653e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.53; acc: 0.83
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.88
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.83
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.45; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.44; acc: 0.91
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1874553567613475e-05
7.8777329690638e-06
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.30053238777123437; val_accuracy: 0.9078423566878981 

The current subspace-distance is: 7.8777329690638e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.53; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.42; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.47; acc: 0.94
Batch: 260; loss: 0.37; acc: 0.83
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.83
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.89
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.45; acc: 0.81
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.18653331103269e-05
7.171312972786836e-06
Batch: 0; loss: 0.32; acc: 0.84
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.3163490068808103; val_accuracy: 0.902468152866242 

The current subspace-distance is: 7.171312972786836e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.5; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.94
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.84
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.46; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1873132936889306e-05
7.322739747905871e-06
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.83
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.332385668044637; val_accuracy: 0.8963972929936306 

The current subspace-distance is: 7.322739747905871e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.54; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.97
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.84
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.218965528300032e-05
8.231450919993222e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2965170447566327; val_accuracy: 0.9088375796178344 

The current subspace-distance is: 8.231450919993222e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.95
Batch: 160; loss: 0.4; acc: 0.94
Batch: 180; loss: 0.4; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.86
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.95
Batch: 400; loss: 0.8; acc: 0.83
Batch: 420; loss: 0.41; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.52; acc: 0.91
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.5; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1928057321929373e-05
8.095614248304628e-06
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.29924544428659094; val_accuracy: 0.9079418789808917 

The current subspace-distance is: 8.095614248304628e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.39; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.59; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.52; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.8
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.81
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.20258480112534e-05
7.309180546144489e-06
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.32453306090490075; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 7.309180546144489e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.83
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.86
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.43; acc: 0.8
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.54; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.09; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.45; acc: 0.81
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.44; acc: 0.88
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.122192563547287e-05
7.652136446267832e-06
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.33797039570891935; val_accuracy: 0.8945063694267515 

The current subspace-distance is: 7.652136446267832e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.51; acc: 0.84
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.34; acc: 0.84
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.83
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.44; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.4; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.3235907065100037e-05
8.142186743498314e-06
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.29041652127530926; val_accuracy: 0.9105294585987261 

The current subspace-distance is: 8.142186743498314e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.59; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.88
Batch: 320; loss: 0.59; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.48; acc: 0.89
Batch: 420; loss: 0.53; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.38; acc: 0.84
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.36; acc: 0.84
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.61; acc: 0.84
Batch: 600; loss: 0.2; acc: 0.98
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.54; acc: 0.8
Batch: 680; loss: 0.24; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.45; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.2423839254770428e-05
6.791824034735328e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.30437861041278597; val_accuracy: 0.9044585987261147 

The current subspace-distance is: 6.791824034735328e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.4; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.84
Batch: 220; loss: 0.18; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.53; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.83
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.34; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.5; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.208309160778299e-05
7.797288162691984e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2852753333177916; val_accuracy: 0.9138136942675159 

The current subspace-distance is: 7.797288162691984e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.48; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.23; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.51; acc: 0.8
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.52; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.41; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.2706986783305183e-05
7.97585744294338e-06
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.28483013528737294; val_accuracy: 0.9110270700636943 

The current subspace-distance is: 7.97585744294338e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.88
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.58; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.86
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.44; acc: 0.83
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.228623634437099e-05
7.240654213092057e-06
Batch: 0; loss: 0.34; acc: 0.84
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.29; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.81; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.3109243811837807; val_accuracy: 0.903562898089172 

The current subspace-distance is: 7.240654213092057e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.16; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.95
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.46; acc: 0.78
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.45; acc: 0.83
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.54; acc: 0.81
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.2073978470871225e-05
7.199535957624903e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2868998966114536; val_accuracy: 0.9126194267515924 

The current subspace-distance is: 7.199535957624903e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.55; acc: 0.84
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.57; acc: 0.86
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.8
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.97
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.5; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.55; acc: 0.89
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1921629013377242e-05
7.570568413939327e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2864625089724732; val_accuracy: 0.9141122611464968 

The current subspace-distance is: 7.570568413939327e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.83
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.47; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.84
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.98
Batch: 740; loss: 0.63; acc: 0.84
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.39; acc: 0.81
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.2184722183737904e-05
7.567144621134503e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2861355473613663; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 7.567144621134503e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.52; acc: 0.83
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.51; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.84
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.3073729607858695e-05
7.839850695745554e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.28681165143657644; val_accuracy: 0.9106289808917197 

The current subspace-distance is: 7.839850695745554e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.83
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.48; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.46; acc: 0.84
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.218916233687196e-05
7.738009117019828e-06
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.8; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.29033377638478186; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 7.738009117019828e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.88
Batch: 240; loss: 0.09; acc: 1.0
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.8
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.89
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.23; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.2483318389276974e-05
7.731448022241239e-06
Batch: 0; loss: 0.28; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.76; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28823823206553795; val_accuracy: 0.9131170382165605 

The current subspace-distance is: 7.731448022241239e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.57; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.54; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1977628421154805e-05
7.951746738399379e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.29460128515389317; val_accuracy: 0.9095342356687898 

The current subspace-distance is: 7.951746738399379e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.47; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.51; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.94
Batch: 400; loss: 0.57; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.43; acc: 0.86
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.49; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.8
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2375948901753873e-05
8.122829967760481e-06
Batch: 0; loss: 0.29; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28122031570050365; val_accuracy: 0.9145103503184714 

The current subspace-distance is: 8.122829967760481e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.72; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.55; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.44; acc: 0.84
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.43; acc: 0.84
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2072932551964186e-05
7.687502147746272e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2789363158973539; val_accuracy: 0.9161027070063694 

The current subspace-distance is: 7.687502147746272e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.55; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.44; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.54; acc: 0.91
Batch: 560; loss: 0.62; acc: 0.86
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2698781322105788e-05
8.264205462182872e-06
Batch: 0; loss: 0.24; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2823844823962564; val_accuracy: 0.9147093949044586 

The current subspace-distance is: 8.264205462182872e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.98
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.42; acc: 0.81
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.36; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.14; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.6; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.84
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.51; acc: 0.8
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2100470232544467e-05
7.682580871914979e-06
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.28334625141256176; val_accuracy: 0.914609872611465 

The current subspace-distance is: 7.682580871914979e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.52; acc: 0.8
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.49; acc: 0.88
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.86
Batch: 520; loss: 0.42; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2463051209342666e-05
6.957867299206555e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2798430446511621; val_accuracy: 0.9147093949044586 

The current subspace-distance is: 6.957867299206555e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.46; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.36; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.84
Batch: 300; loss: 0.53; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.15; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.24976447498193e-05
7.254471711348742e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2855625736295797; val_accuracy: 0.9129179936305732 

The current subspace-distance is: 7.254471711348742e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.51; acc: 0.81
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.246593066956848e-05
7.6015512604499236e-06
Batch: 0; loss: 0.29; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2833122173739467; val_accuracy: 0.9143113057324841 

The current subspace-distance is: 7.6015512604499236e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.84
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.39; acc: 0.86
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.52; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.230776590295136e-05
7.176539838837925e-06
Batch: 0; loss: 0.25; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2800790169246637; val_accuracy: 0.9149084394904459 

The current subspace-distance is: 7.176539838837925e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.94
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2448244635597803e-05
7.5538760029303376e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.79; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27863003396589286; val_accuracy: 0.9153065286624203 

The current subspace-distance is: 7.5538760029303376e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.5; acc: 0.89
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.88
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.47; acc: 0.8
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.5; acc: 0.88
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2194253688212484e-05
7.167224794102367e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2781225854329243; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 7.167224794102367e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.89
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.32; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1999963792040944e-05
7.332816039706813e-06
Batch: 0; loss: 0.25; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2780866844306706; val_accuracy: 0.916202229299363 

The current subspace-distance is: 7.332816039706813e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.59; acc: 0.86
Batch: 260; loss: 0.33; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2322228687698953e-05
7.025650120340288e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27825625247921154; val_accuracy: 0.9157046178343949 

The current subspace-distance is: 7.025650120340288e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.59; acc: 0.84
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.3; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.43; acc: 0.83
Batch: 440; loss: 0.25; acc: 0.84
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2551648726221174e-05
6.8532058321579825e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27810497899913483; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 6.8532058321579825e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.43; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.5; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.84
Batch: 780; loss: 0.25; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2170619558892213e-05
6.471872438851278e-06
Batch: 0; loss: 0.25; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2781149419439826; val_accuracy: 0.916202229299363 

The current subspace-distance is: 6.471872438851278e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.83
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.194968328694813e-05
7.338477189477999e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2786696215106803; val_accuracy: 0.9145103503184714 

The current subspace-distance is: 7.338477189477999e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.86
Batch: 300; loss: 0.48; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.42; acc: 0.89
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.5; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.23; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.95
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.290764678036794e-05
7.483060016966192e-06
Batch: 0; loss: 0.25; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.278430130569988; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 7.483060016966192e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.84
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.31; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2193120457814075e-05
7.0515934567083605e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2780605201271309; val_accuracy: 0.9164012738853503 

The current subspace-distance is: 7.0515934567083605e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.43; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.53; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.98
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.42; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2129328499431722e-05
8.267531484307256e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2779071341464474; val_accuracy: 0.9163017515923567 

The current subspace-distance is: 8.267531484307256e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.95
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.5; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.56; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.88
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2029780666343868e-05
7.895012458902784e-06
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27886101729266205; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 7.895012458902784e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.54; acc: 0.81
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.98
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1792546249344014e-05
6.787107395211933e-06
Batch: 0; loss: 0.26; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27806594813610336; val_accuracy: 0.9164012738853503 

The current subspace-distance is: 6.787107395211933e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_220_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 48002
elements in E: 10217980
fraction nonzero: 0.004697797412012942
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.22
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.06
Batch: 160; loss: 2.3; acc: 0.17
Batch: 180; loss: 2.29; acc: 0.09
Batch: 200; loss: 2.3; acc: 0.12
Batch: 220; loss: 2.29; acc: 0.23
Batch: 240; loss: 2.3; acc: 0.17
Batch: 260; loss: 2.3; acc: 0.16
Batch: 280; loss: 2.28; acc: 0.22
Batch: 300; loss: 2.28; acc: 0.23
Batch: 320; loss: 2.28; acc: 0.25
Batch: 340; loss: 2.27; acc: 0.3
Batch: 360; loss: 2.28; acc: 0.25
Batch: 380; loss: 2.27; acc: 0.2
Batch: 400; loss: 2.26; acc: 0.28
Batch: 420; loss: 2.26; acc: 0.27
Batch: 440; loss: 2.24; acc: 0.31
Batch: 460; loss: 2.24; acc: 0.31
Batch: 480; loss: 2.24; acc: 0.23
Batch: 500; loss: 2.19; acc: 0.38
Batch: 520; loss: 2.19; acc: 0.3
Batch: 540; loss: 2.17; acc: 0.33
Batch: 560; loss: 2.1; acc: 0.42
Batch: 580; loss: 2.03; acc: 0.48
Batch: 600; loss: 1.96; acc: 0.53
Batch: 620; loss: 1.79; acc: 0.55
Batch: 640; loss: 1.49; acc: 0.64
Batch: 660; loss: 1.29; acc: 0.59
Batch: 680; loss: 1.14; acc: 0.67
Batch: 700; loss: 0.96; acc: 0.69
Batch: 720; loss: 1.06; acc: 0.69
Batch: 740; loss: 0.78; acc: 0.77
Batch: 760; loss: 0.94; acc: 0.72
Batch: 780; loss: 0.61; acc: 0.84
Train Epoch over. train_loss: 1.99; train_accuracy: 0.35 

1.0184201528318226e-05
5.888395662623225e-06
Batch: 0; loss: 0.6; acc: 0.77
Batch: 20; loss: 1.16; acc: 0.66
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.69; acc: 0.83
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.52; acc: 0.83
Batch: 120; loss: 1.12; acc: 0.7
Batch: 140; loss: 0.57; acc: 0.83
Val Epoch over. val_loss: 0.7360667533175961; val_accuracy: 0.7641321656050956 

The current subspace-distance is: 5.888395662623225e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.77
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.7; acc: 0.77
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.82; acc: 0.72
Batch: 100; loss: 0.58; acc: 0.75
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.73; acc: 0.77
Batch: 160; loss: 0.69; acc: 0.77
Batch: 180; loss: 0.47; acc: 0.84
Batch: 200; loss: 0.7; acc: 0.75
Batch: 220; loss: 0.63; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.59; acc: 0.77
Batch: 280; loss: 0.7; acc: 0.75
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.88; acc: 0.77
Batch: 340; loss: 0.7; acc: 0.81
Batch: 360; loss: 0.61; acc: 0.8
Batch: 380; loss: 0.74; acc: 0.81
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.77; acc: 0.67
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.89
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.52; acc: 0.81
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.57; acc: 0.86
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.49; acc: 0.8
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

1.847874045779463e-05
5.907954346184852e-06
Batch: 0; loss: 0.43; acc: 0.91
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.78; acc: 0.83
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.44965464189933363; val_accuracy: 0.8626592356687898 

The current subspace-distance is: 5.907954346184852e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.81
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.42; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.56; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.84
Batch: 240; loss: 0.53; acc: 0.81
Batch: 260; loss: 0.46; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.94; acc: 0.72
Batch: 340; loss: 0.59; acc: 0.81
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.52; acc: 0.83
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.83
Batch: 460; loss: 0.65; acc: 0.77
Batch: 480; loss: 0.43; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.55; acc: 0.84
Batch: 560; loss: 0.47; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.43; acc: 0.89
Batch: 640; loss: 0.59; acc: 0.84
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.55; acc: 0.84
Batch: 760; loss: 0.6; acc: 0.89
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

1.949818579305429e-05
6.376837973220972e-06
Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 1.04; acc: 0.69
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.9; acc: 0.75
Batch: 80; loss: 0.63; acc: 0.8
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 1.29; acc: 0.67
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.6989251827927911; val_accuracy: 0.7818471337579618 

The current subspace-distance is: 6.376837973220972e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.9; acc: 0.78
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.57; acc: 0.81
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.81; acc: 0.75
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.43; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.62; acc: 0.83
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.52; acc: 0.92
Batch: 320; loss: 0.72; acc: 0.77
Batch: 340; loss: 0.53; acc: 0.83
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.68; acc: 0.81
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.49; acc: 0.81
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.43; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.8
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.55; acc: 0.88
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.64; acc: 0.83
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

1.9918681573471986e-05
6.4107866819540504e-06
Batch: 0; loss: 1.66; acc: 0.59
Batch: 20; loss: 1.66; acc: 0.58
Batch: 40; loss: 1.35; acc: 0.66
Batch: 60; loss: 2.12; acc: 0.64
Batch: 80; loss: 1.46; acc: 0.64
Batch: 100; loss: 1.42; acc: 0.64
Batch: 120; loss: 1.98; acc: 0.52
Batch: 140; loss: 1.44; acc: 0.62
Val Epoch over. val_loss: 1.5591146281570385; val_accuracy: 0.61046974522293 

The current subspace-distance is: 6.4107866819540504e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.21; acc: 0.58
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.36; acc: 0.83
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.5; acc: 0.83
Batch: 340; loss: 0.51; acc: 0.78
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.44; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.92
Batch: 520; loss: 0.75; acc: 0.78
Batch: 540; loss: 0.47; acc: 0.81
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.7; acc: 0.78
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.51; acc: 0.83
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.065525040961802e-05
6.414211384253576e-06
Batch: 0; loss: 1.28; acc: 0.7
Batch: 20; loss: 1.58; acc: 0.69
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 1.37; acc: 0.7
Batch: 80; loss: 1.15; acc: 0.77
Batch: 100; loss: 0.76; acc: 0.77
Batch: 120; loss: 1.88; acc: 0.7
Batch: 140; loss: 0.89; acc: 0.75
Val Epoch over. val_loss: 1.0966954605214914; val_accuracy: 0.7132762738853503 

The current subspace-distance is: 6.414211384253576e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.3; acc: 0.69
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.46; acc: 0.81
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.5; acc: 0.83
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.84
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.84
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.59; acc: 0.77
Batch: 700; loss: 0.57; acc: 0.83
Batch: 720; loss: 0.26; acc: 0.86
Batch: 740; loss: 0.56; acc: 0.78
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.84; acc: 0.7
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.1655521777574904e-05
7.167267995100701e-06
Batch: 0; loss: 0.66; acc: 0.72
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.94; acc: 0.73
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 1.17; acc: 0.72
Batch: 140; loss: 0.27; acc: 0.88
Val Epoch over. val_loss: 0.6731878469704063; val_accuracy: 0.7996616242038217 

The current subspace-distance is: 7.167267995100701e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.88; acc: 0.77
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.43; acc: 0.8
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.51; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.88
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.54; acc: 0.8
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.77; acc: 0.81
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.43; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.47; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.83
Batch: 780; loss: 0.4; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

2.0623867385438643e-05
6.7657097133633215e-06
Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.97
Val Epoch over. val_loss: 0.38237764899897725; val_accuracy: 0.8872412420382165 

The current subspace-distance is: 6.7657097133633215e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.84
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.66; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.97
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.62; acc: 0.81
Batch: 180; loss: 0.51; acc: 0.8
Batch: 200; loss: 0.55; acc: 0.83
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 0.49; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.86
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.95
Batch: 380; loss: 0.47; acc: 0.81
Batch: 400; loss: 0.31; acc: 0.86
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.61; acc: 0.83
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.4; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.83
Batch: 680; loss: 0.65; acc: 0.81
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.56; acc: 0.8
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0690235032816418e-05
6.402981398423435e-06
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.33; acc: 0.84
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 1.2; acc: 0.77
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.55848569740915; val_accuracy: 0.8283240445859873 

The current subspace-distance is: 6.402981398423435e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.77; acc: 0.78
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.55; acc: 0.84
Batch: 480; loss: 0.43; acc: 0.83
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.52; acc: 0.89
Batch: 580; loss: 0.44; acc: 0.83
Batch: 600; loss: 0.68; acc: 0.7
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.42; acc: 0.89
Batch: 740; loss: 0.51; acc: 0.83
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0560237317113206e-05
6.60206524116802e-06
Batch: 0; loss: 0.59; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.73
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.69; acc: 0.83
Batch: 80; loss: 0.36; acc: 0.83
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.89; acc: 0.75
Batch: 140; loss: 0.28; acc: 0.89
Val Epoch over. val_loss: 0.5389463815149987; val_accuracy: 0.8381767515923567 

The current subspace-distance is: 6.60206524116802e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.51; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.46; acc: 0.81
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.5; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.58; acc: 0.8
Batch: 480; loss: 0.28; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.6; acc: 0.8
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.51; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.5; acc: 0.81
Batch: 740; loss: 0.52; acc: 0.84
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.66; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.0593335648300126e-05
7.1596728048461955e-06
Batch: 0; loss: 0.77; acc: 0.7
Batch: 20; loss: 1.01; acc: 0.69
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.88; acc: 0.77
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.78; acc: 0.84
Batch: 120; loss: 1.31; acc: 0.64
Batch: 140; loss: 0.3; acc: 0.91
Val Epoch over. val_loss: 0.7271899647393804; val_accuracy: 0.7825437898089171 

The current subspace-distance is: 7.1596728048461955e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.15; acc: 0.66
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.36; acc: 0.94
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.95
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.38; acc: 0.84
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.14; acc: 0.98
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.97
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.1514768377528526e-05
6.838078661530744e-06
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3267298246360129; val_accuracy: 0.901671974522293 

The current subspace-distance is: 6.838078661530744e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.84
Batch: 140; loss: 0.37; acc: 0.89
Batch: 160; loss: 0.67; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.49; acc: 0.88
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.86
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.46; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.64; acc: 0.83
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.97
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.139081152563449e-05
6.9803504629817326e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.318502141886456; val_accuracy: 0.9052547770700637 

The current subspace-distance is: 6.9803504629817326e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.84
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.54; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.51; acc: 0.81
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.51; acc: 0.78
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.88
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.38; acc: 0.81
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.84
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.48; acc: 0.86
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.35; acc: 0.81
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.54; acc: 0.84
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.056709854514338e-05
6.889373253216036e-06
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.76; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.98
Val Epoch over. val_loss: 0.33883776601142945; val_accuracy: 0.9013734076433121 

The current subspace-distance is: 6.889373253216036e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.4; acc: 0.94
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.88
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.63; acc: 0.81
Batch: 240; loss: 0.51; acc: 0.83
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.42; acc: 0.86
Batch: 360; loss: 0.48; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.86
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.94
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.1788884623674676e-05
7.15518626748235e-06
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.33397998810289015; val_accuracy: 0.9008757961783439 

The current subspace-distance is: 7.15518626748235e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.47; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.39; acc: 0.92
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.8
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.83
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.1298512365319766e-05
7.050907697703224e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.32006597148764665; val_accuracy: 0.9044585987261147 

The current subspace-distance is: 7.050907697703224e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.91
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.67; acc: 0.88
Batch: 160; loss: 0.48; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.82; acc: 0.8
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.49; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.59; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.181446507165674e-05
7.642338459845632e-06
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.311697072165597; val_accuracy: 0.9080414012738853 

The current subspace-distance is: 7.642338459845632e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.91
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.98
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.59; acc: 0.84
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.86
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.49; acc: 0.8
Batch: 480; loss: 0.7; acc: 0.83
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.1734087567892857e-05
7.211904630821664e-06
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3191058460836578; val_accuracy: 0.9071457006369427 

The current subspace-distance is: 7.211904630821664e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.48; acc: 0.83
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.55; acc: 0.8
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.83
Batch: 460; loss: 0.7; acc: 0.83
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.5; acc: 0.91
Batch: 540; loss: 0.38; acc: 0.89
Batch: 560; loss: 0.41; acc: 0.83
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.51; acc: 0.81
Batch: 720; loss: 0.58; acc: 0.86
Batch: 740; loss: 0.43; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.1757721697213128e-05
7.278979865077417e-06
Batch: 0; loss: 0.4; acc: 0.81
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.3535844744865302; val_accuracy: 0.8929140127388535 

The current subspace-distance is: 7.278979865077417e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.58; acc: 0.84
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.44; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.95
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.46; acc: 0.89
Batch: 660; loss: 0.39; acc: 0.86
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.165256955777295e-05
7.1342387855111156e-06
Batch: 0; loss: 0.34; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.31600143712986806; val_accuracy: 0.9074442675159236 

The current subspace-distance is: 7.1342387855111156e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.66; acc: 0.78
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.45; acc: 0.81
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.42; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.97
Batch: 620; loss: 0.48; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.6; acc: 0.77
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.08; acc: 1.0
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.2250718757277355e-05
7.163984719227301e-06
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.31000242104670805; val_accuracy: 0.9082404458598726 

The current subspace-distance is: 7.163984719227301e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.43; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.98
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.46; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.37; acc: 0.81
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.95
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.37; acc: 0.91
Batch: 660; loss: 0.49; acc: 0.83
Batch: 680; loss: 0.63; acc: 0.83
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.34; acc: 0.86
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1115039999131113e-05
6.769666470063385e-06
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.29742288152883006; val_accuracy: 0.9122213375796179 

The current subspace-distance is: 6.769666470063385e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.66; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.5; acc: 0.84
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.43; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.48; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.91
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.83
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.3; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1873775040148757e-05
6.8418830778682604e-06
Batch: 0; loss: 0.27; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3016238417357776; val_accuracy: 0.9107285031847133 

The current subspace-distance is: 6.8418830778682604e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.91
Batch: 260; loss: 0.51; acc: 0.88
Batch: 280; loss: 0.36; acc: 0.8
Batch: 300; loss: 0.44; acc: 0.91
Batch: 320; loss: 0.53; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.37; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.204748489020858e-05
7.174311122071231e-06
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.33357758521084574; val_accuracy: 0.8968949044585988 

The current subspace-distance is: 7.174311122071231e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.84
Batch: 200; loss: 0.35; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.6; acc: 0.86
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.86
Batch: 500; loss: 0.44; acc: 0.91
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.59; acc: 0.84
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.5; acc: 0.84
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.2019125026417896e-05
7.39568667995627e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2989934034123542; val_accuracy: 0.9134156050955414 

The current subspace-distance is: 7.39568667995627e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.27; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.86
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.86
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.43; acc: 0.89
Batch: 280; loss: 0.56; acc: 0.86
Batch: 300; loss: 0.47; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.62; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.84
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.52; acc: 0.83
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.56; acc: 0.88
Batch: 500; loss: 0.48; acc: 0.84
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.97
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.24; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.157505696231965e-05
7.549187557742698e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.30072811715731956; val_accuracy: 0.9117237261146497 

The current subspace-distance is: 7.549187557742698e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.86
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.47; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.65; acc: 0.84
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.54; acc: 0.78
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.29; acc: 0.86
Batch: 540; loss: 0.37; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1920164726907387e-05
7.113118499546545e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2982664159528769; val_accuracy: 0.9122213375796179 

The current subspace-distance is: 7.113118499546545e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.69; acc: 0.81
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.56; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.37; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.54; acc: 0.84
Batch: 600; loss: 0.38; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.54; acc: 0.88
Batch: 660; loss: 0.31; acc: 0.95
Batch: 680; loss: 0.42; acc: 0.88
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.38; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1195543013163842e-05
7.2905545493995305e-06
Batch: 0; loss: 0.3; acc: 0.86
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.30916542875444053; val_accuracy: 0.9060509554140127 

The current subspace-distance is: 7.2905545493995305e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.6; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.49; acc: 0.84
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.66; acc: 0.83
Batch: 420; loss: 0.45; acc: 0.84
Batch: 440; loss: 0.48; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.73; acc: 0.78
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1207821191637777e-05
7.4790727921936195e-06
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3041930798275076; val_accuracy: 0.9115246815286624 

The current subspace-distance is: 7.4790727921936195e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.97
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.81
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.5; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1508038116735406e-05
7.3685619099705946e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3084073830040018; val_accuracy: 0.9072452229299363 

The current subspace-distance is: 7.3685619099705946e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.43; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.84
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.92
Batch: 440; loss: 0.49; acc: 0.8
Batch: 460; loss: 0.23; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.61; acc: 0.88
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.53; acc: 0.88
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.49; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.2066053134039976e-05
7.566502517875051e-06
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.3049027541545546; val_accuracy: 0.9070461783439491 

The current subspace-distance is: 7.566502517875051e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.84
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.58; acc: 0.83
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.55; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.83
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2265970983426087e-05
7.492021723010112e-06
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.94
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2916165754958323; val_accuracy: 0.9152070063694268 

The current subspace-distance is: 7.492021723010112e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.43; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.84
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.59; acc: 0.84
Batch: 420; loss: 0.19; acc: 0.97
Batch: 440; loss: 0.64; acc: 0.84
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.64; acc: 0.83
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.83
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.47; acc: 0.89
Batch: 600; loss: 0.4; acc: 0.88
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1958376237307675e-05
6.675742952211294e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.29819907205309837; val_accuracy: 0.9125199044585988 

The current subspace-distance is: 6.675742952211294e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.53; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.51; acc: 0.83
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1964162442600355e-05
6.97016639605863e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.09; acc: 1.0
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.29370852305915707; val_accuracy: 0.9141122611464968 

The current subspace-distance is: 6.97016639605863e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.36; acc: 0.86
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.92
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.37; acc: 0.86
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.61; acc: 0.86
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.84
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.251978912681807e-05
6.807735189795494e-06
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.29360617989092874; val_accuracy: 0.9129179936305732 

The current subspace-distance is: 6.807735189795494e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.22; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.09; acc: 1.0
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.5; acc: 0.84
Batch: 540; loss: 0.27; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.83
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.57; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.179922375944443e-05
6.986188054725062e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.09; acc: 1.0
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2932678740352962; val_accuracy: 0.9134156050955414 

The current subspace-distance is: 6.986188054725062e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.55; acc: 0.86
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.49; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.45; acc: 0.8
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.56; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.210919228673447e-05
7.4658673838712275e-06
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2927059156784586; val_accuracy: 0.9139132165605095 

The current subspace-distance is: 7.4658673838712275e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.51; acc: 0.88
Batch: 240; loss: 0.34; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.57; acc: 0.84
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.46; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.83
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.86
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.84
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1541711248573847e-05
7.136038675525924e-06
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2971427329121881; val_accuracy: 0.9104299363057324 

The current subspace-distance is: 7.136038675525924e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.41; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.45; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.86
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.48; acc: 0.88
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.52; acc: 0.83
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.46; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.88
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.62; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.133379348379094e-05
6.926975402166136e-06
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.29229796298180416; val_accuracy: 0.9148089171974523 

The current subspace-distance is: 6.926975402166136e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.95
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.36; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1570349417743273e-05
7.677623216295615e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.7; acc: 0.8
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2938363084889901; val_accuracy: 0.9128184713375797 

The current subspace-distance is: 7.677623216295615e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.86
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.31; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.45; acc: 0.92
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1292498786351644e-05
7.19687204764341e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.29085097635152996; val_accuracy: 0.9145103503184714 

The current subspace-distance is: 7.19687204764341e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.38; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.132046574843116e-05
7.402937626466155e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.28953687984282805; val_accuracy: 0.9153065286624203 

The current subspace-distance is: 7.402937626466155e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.37; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.83
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.37; acc: 0.84
Batch: 240; loss: 0.54; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.59; acc: 0.86
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.91
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.53; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2400647139875218e-05
8.007045835256577e-06
Batch: 0; loss: 0.26; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.28981648062824444; val_accuracy: 0.9151074840764332 

The current subspace-distance is: 8.007045835256577e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.45; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.53; acc: 0.86
Batch: 260; loss: 0.53; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.52; acc: 0.84
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.98
Batch: 740; loss: 0.4; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2079077098169364e-05
8.057385457505006e-06
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.28972298004160263; val_accuracy: 0.9160031847133758 

The current subspace-distance is: 8.057385457505006e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.38; acc: 0.84
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.51; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.97
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.86
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0856956325587817e-05
6.9027319113956764e-06
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2901007855773731; val_accuracy: 0.9147093949044586 

The current subspace-distance is: 6.9027319113956764e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.43; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.18; acc: 0.98
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.43; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.206624958489556e-05
7.225782155728666e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.28968721929534225; val_accuracy: 0.9158041401273885 

The current subspace-distance is: 7.225782155728666e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.83
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.49; acc: 0.83
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.86
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.56; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.4; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.84
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.88
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.45; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1652534996974282e-05
7.236293185997056e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.09; acc: 1.0
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.29125783343318923; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 7.236293185997056e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.88
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.41; acc: 0.86
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.46; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.45; acc: 0.89
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2006146537023596e-05
7.744772119622212e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2903075257114544; val_accuracy: 0.915406050955414 

The current subspace-distance is: 7.744772119622212e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.57; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.5; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1604862922686152e-05
7.196893420768902e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.29074316647402043; val_accuracy: 0.9129179936305732 

The current subspace-distance is: 7.196893420768902e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.59; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.89
Batch: 140; loss: 0.49; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.59; acc: 0.88
Batch: 200; loss: 0.59; acc: 0.88
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.88
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.42; acc: 0.81
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.84
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.84
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1275674953358248e-05
7.486132290068781e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.09; acc: 1.0
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.28945222720029246; val_accuracy: 0.915406050955414 

The current subspace-distance is: 7.486132290068781e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.68; acc: 0.83
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.43; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.53; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.35; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2070771592552774e-05
8.693043128005229e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2896247683389551; val_accuracy: 0.9148089171974523 

The current subspace-distance is: 8.693043128005229e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_230_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 50616
elements in E: 10662240
fraction nonzero: 0.004747220096339981
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.05
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.06
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.17
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.28; acc: 0.14
Batch: 300; loss: 2.26; acc: 0.23
Batch: 320; loss: 2.26; acc: 0.23
Batch: 340; loss: 2.25; acc: 0.33
Batch: 360; loss: 2.26; acc: 0.23
Batch: 380; loss: 2.24; acc: 0.36
Batch: 400; loss: 2.24; acc: 0.34
Batch: 420; loss: 2.23; acc: 0.39
Batch: 440; loss: 2.22; acc: 0.41
Batch: 460; loss: 2.17; acc: 0.47
Batch: 480; loss: 2.12; acc: 0.52
Batch: 500; loss: 2.04; acc: 0.47
Batch: 520; loss: 1.98; acc: 0.58
Batch: 540; loss: 1.8; acc: 0.53
Batch: 560; loss: 1.45; acc: 0.67
Batch: 580; loss: 1.08; acc: 0.81
Batch: 600; loss: 1.1; acc: 0.67
Batch: 620; loss: 0.83; acc: 0.78
Batch: 640; loss: 0.83; acc: 0.73
Batch: 660; loss: 0.8; acc: 0.77
Batch: 680; loss: 0.64; acc: 0.8
Batch: 700; loss: 0.93; acc: 0.73
Batch: 720; loss: 0.75; acc: 0.8
Batch: 740; loss: 0.67; acc: 0.75
Batch: 760; loss: 1.09; acc: 0.72
Batch: 780; loss: 0.63; acc: 0.8
Train Epoch over. train_loss: 1.83; train_accuracy: 0.39 

1.0498309165996034e-05
5.223254902375629e-06
Batch: 0; loss: 0.7; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.72
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.55; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.26; acc: 0.94
Val Epoch over. val_loss: 0.6024419391990468; val_accuracy: 0.8178742038216561 

The current subspace-distance is: 5.223254902375629e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.75
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.85; acc: 0.67
Batch: 60; loss: 0.64; acc: 0.8
Batch: 80; loss: 0.62; acc: 0.8
Batch: 100; loss: 0.86; acc: 0.66
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.61; acc: 0.78
Batch: 160; loss: 0.61; acc: 0.77
Batch: 180; loss: 0.57; acc: 0.86
Batch: 200; loss: 0.69; acc: 0.78
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.54; acc: 0.83
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.57; acc: 0.78
Batch: 320; loss: 0.72; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.52; acc: 0.81
Batch: 380; loss: 0.56; acc: 0.84
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.55; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.83
Batch: 460; loss: 0.49; acc: 0.78
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.54; acc: 0.78
Batch: 540; loss: 0.6; acc: 0.84
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.62; acc: 0.8
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.84
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.39; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.65; acc: 0.83
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.5; train_accuracy: 0.84 

1.7538695828989148e-05
6.542698429257143e-06
Batch: 0; loss: 0.53; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.3910821995158104; val_accuracy: 0.8791799363057324 

The current subspace-distance is: 6.542698429257143e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.78
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.88
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.71; acc: 0.8
Batch: 340; loss: 0.47; acc: 0.84
Batch: 360; loss: 0.53; acc: 0.84
Batch: 380; loss: 0.55; acc: 0.88
Batch: 400; loss: 0.65; acc: 0.83
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.46; acc: 0.83
Batch: 460; loss: 0.52; acc: 0.86
Batch: 480; loss: 0.57; acc: 0.8
Batch: 500; loss: 0.46; acc: 0.83
Batch: 520; loss: 0.48; acc: 0.83
Batch: 540; loss: 0.83; acc: 0.75
Batch: 560; loss: 0.44; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.86
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.71; acc: 0.78
Batch: 660; loss: 0.37; acc: 0.94
Batch: 680; loss: 0.46; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.69; acc: 0.84
Batch: 780; loss: 0.5; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

1.917138979479205e-05
6.967414719838416e-06
Batch: 0; loss: 0.8; acc: 0.75
Batch: 20; loss: 0.67; acc: 0.77
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.43; acc: 0.84
Batch: 100; loss: 0.72; acc: 0.75
Batch: 120; loss: 1.01; acc: 0.75
Batch: 140; loss: 0.33; acc: 0.89
Val Epoch over. val_loss: 0.6524073166452395; val_accuracy: 0.8050358280254777 

The current subspace-distance is: 6.967414719838416e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.63; acc: 0.81
Batch: 80; loss: 0.39; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.66; acc: 0.8
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.84
Batch: 240; loss: 0.52; acc: 0.86
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.63; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.56; acc: 0.83
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.57; acc: 0.86
Batch: 560; loss: 0.6; acc: 0.8
Batch: 580; loss: 0.62; acc: 0.81
Batch: 600; loss: 0.46; acc: 0.92
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.46; acc: 0.91
Batch: 760; loss: 0.5; acc: 0.86
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.0264806153136306e-05
6.771699190721847e-06
Batch: 0; loss: 1.93; acc: 0.58
Batch: 20; loss: 1.47; acc: 0.53
Batch: 40; loss: 1.65; acc: 0.66
Batch: 60; loss: 2.34; acc: 0.64
Batch: 80; loss: 1.8; acc: 0.72
Batch: 100; loss: 1.73; acc: 0.64
Batch: 120; loss: 2.09; acc: 0.52
Batch: 140; loss: 1.58; acc: 0.66
Val Epoch over. val_loss: 1.7873062005468234; val_accuracy: 0.6279856687898089 

The current subspace-distance is: 6.771699190721847e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.45; acc: 0.62
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.63; acc: 0.84
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.61; acc: 0.86
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.83
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.32; acc: 0.86
Batch: 580; loss: 0.46; acc: 0.81
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.037256126641296e-05
7.173558060458163e-06
Batch: 0; loss: 0.86; acc: 0.75
Batch: 20; loss: 1.02; acc: 0.7
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 1.07; acc: 0.75
Batch: 80; loss: 0.79; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 1.25; acc: 0.7
Batch: 140; loss: 0.52; acc: 0.78
Val Epoch over. val_loss: 0.7766603497183246; val_accuracy: 0.7684116242038217 

The current subspace-distance is: 7.173558060458163e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.81
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.84
Batch: 160; loss: 0.45; acc: 0.84
Batch: 180; loss: 0.31; acc: 0.83
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.59; acc: 0.83
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.89
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.59; acc: 0.77
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.45; acc: 0.84
Batch: 700; loss: 0.74; acc: 0.8
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.5; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.0585845049936324e-05
6.493753062386531e-06
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.79; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.92
Val Epoch over. val_loss: 0.3813193076450354; val_accuracy: 0.8859474522292994 

The current subspace-distance is: 6.493753062386531e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.47; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.67; acc: 0.78
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.42; acc: 0.83
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.46; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.57; acc: 0.83
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.0704314010799862e-05
6.5217859628319275e-06
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.339134974701769; val_accuracy: 0.8988853503184714 

The current subspace-distance is: 6.5217859628319275e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.71; acc: 0.73
Batch: 40; loss: 0.33; acc: 0.84
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.56; acc: 0.81
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.57; acc: 0.8
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.27; acc: 0.84
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.52; acc: 0.8
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.0615871108020656e-05
7.539133548561949e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.78
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.68; acc: 0.8
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3430896274223449; val_accuracy: 0.8908240445859873 

The current subspace-distance is: 7.539133548561949e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.47; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.74; acc: 0.84
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.84
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.66; acc: 0.75
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.65; acc: 0.84
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.48; acc: 0.83
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.62; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.91
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.5; acc: 0.88
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.074341864499729e-05
6.7861410570912994e-06
Batch: 0; loss: 0.81; acc: 0.81
Batch: 20; loss: 0.91; acc: 0.73
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.72; acc: 0.84
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.58; acc: 0.84
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.5691349121985162; val_accuracy: 0.8317078025477707 

The current subspace-distance is: 6.7861410570912994e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.53; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.38; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.48; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.36; acc: 0.84
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.54; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.1005456801503897e-05
7.4175873123749625e-06
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.61; acc: 0.78
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.62; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.38243293491708247; val_accuracy: 0.883359872611465 

The current subspace-distance is: 7.4175873123749625e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.64; acc: 0.84
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.83
Batch: 340; loss: 0.36; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.86
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.33; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.43; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.81
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1323265173123218e-05
7.114787422324298e-06
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.51; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2876544327113279; val_accuracy: 0.9117237261146497 

The current subspace-distance is: 7.114787422324298e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.48; acc: 0.86
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.63; acc: 0.86
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.84
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0490486349444836e-05
6.522778676298913e-06
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.51; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.58; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.3117482129270863; val_accuracy: 0.9026671974522293 

The current subspace-distance is: 6.522778676298913e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.84
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.88
Batch: 80; loss: 0.5; acc: 0.89
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.57; acc: 0.84
Batch: 160; loss: 0.49; acc: 0.81
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.62; acc: 0.78
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.43; acc: 0.84
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.118801603501197e-05
7.058021310513141e-06
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.30595280578846384; val_accuracy: 0.9048566878980892 

The current subspace-distance is: 7.058021310513141e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.94
Batch: 220; loss: 0.59; acc: 0.84
Batch: 240; loss: 0.5; acc: 0.84
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0302950360928662e-05
7.0572209551755805e-06
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.54; acc: 0.8
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.33259065468220195; val_accuracy: 0.8963972929936306 

The current subspace-distance is: 7.0572209551755805e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.83
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.5; acc: 0.84
Batch: 380; loss: 0.39; acc: 0.84
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.26; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.3; acc: 0.84
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1024325178586878e-05
7.132561677281046e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3010581853757998; val_accuracy: 0.9056528662420382 

The current subspace-distance is: 7.132561677281046e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.81
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.59; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.89
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.91; acc: 0.84
Batch: 420; loss: 0.27; acc: 0.88
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.71; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.55; acc: 0.88
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.84
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2281365090748295e-05
6.893036697874777e-06
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.51; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.3031427502916877; val_accuracy: 0.9086385350318471 

The current subspace-distance is: 6.893036697874777e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.88
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.83
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.83
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.55; acc: 0.83
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.13593702937942e-05
6.397210199793335e-06
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28864986202709236; val_accuracy: 0.9121218152866242 

The current subspace-distance is: 6.397210199793335e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.48; acc: 0.89
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.88
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.39; acc: 0.84
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.45; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.54; acc: 0.89
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.45; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.43; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1733474568463862e-05
7.089176506269723e-06
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.33018562895287373; val_accuracy: 0.8987858280254777 

The current subspace-distance is: 7.089176506269723e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.55; acc: 0.8
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.51; acc: 0.83
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.56; acc: 0.78
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.58; acc: 0.78
Batch: 640; loss: 0.48; acc: 0.88
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1415438823169097e-05
7.252432624227367e-06
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.30361366146214447; val_accuracy: 0.9061504777070064 

The current subspace-distance is: 7.252432624227367e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.56; acc: 0.77
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.86
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.5; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.44; acc: 0.83
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.77; acc: 0.78
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1512463717954233e-05
7.189581083366647e-06
Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.29662423699524754; val_accuracy: 0.9085390127388535 

The current subspace-distance is: 7.189581083366647e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.83
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.88
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.43; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.86
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.41; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0837940610363148e-05
7.122917395463446e-06
Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2837163054259719; val_accuracy: 0.9113256369426752 

The current subspace-distance is: 7.122917395463446e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.84
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.55; acc: 0.84
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.84
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1547557480516843e-05
7.4110503192059696e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2750482990103922; val_accuracy: 0.9145103503184714 

The current subspace-distance is: 7.4110503192059696e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.42; acc: 0.86
Batch: 280; loss: 0.42; acc: 0.8
Batch: 300; loss: 0.25; acc: 0.97
Batch: 320; loss: 0.55; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.45; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.38; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1646004825015552e-05
6.439632215915481e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.78
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.3033788287240988; val_accuracy: 0.9026671974522293 

The current subspace-distance is: 6.439632215915481e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.92
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.84
Batch: 560; loss: 0.24; acc: 0.88
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.43; acc: 0.91
Batch: 620; loss: 0.5; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.41; acc: 0.83
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.2448632080340758e-05
8.466462531941943e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2746954882505593; val_accuracy: 0.9158041401273885 

The current subspace-distance is: 8.466462531941943e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.83
Batch: 180; loss: 0.3; acc: 0.86
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.97
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.63; acc: 0.84
Batch: 300; loss: 0.51; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.88
Batch: 340; loss: 0.43; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.56; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.45; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.86
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1432100766105577e-05
7.1658091655990575e-06
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.88
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.28354825136388184; val_accuracy: 0.9125199044585988 

The current subspace-distance is: 7.1658091655990575e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.98
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.83
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.44; acc: 0.81
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.86
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.117842814186588e-05
6.967267381696729e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2779925765505262; val_accuracy: 0.9140127388535032 

The current subspace-distance is: 6.967267381696729e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.83
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.55; acc: 0.86
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.49; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.89
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.51; acc: 0.81
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1006255337852053e-05
7.361154530372005e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.51; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2832779801765065; val_accuracy: 0.9116242038216561 

The current subspace-distance is: 7.361154530372005e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.84
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.86
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.86
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.61; acc: 0.84
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.45; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1688034394173883e-05
8.15198745840462e-06
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2904909226070544; val_accuracy: 0.9104299363057324 

The current subspace-distance is: 8.15198745840462e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.52; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.86
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.6; acc: 0.88
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.84
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.83
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1107634893269278e-05
7.495161298720632e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.52; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.88
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.28424110994407326; val_accuracy: 0.9124203821656051 

The current subspace-distance is: 7.495161298720632e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.88
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.83
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.68; acc: 0.83
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.59; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.98
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.58; acc: 0.81
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.4; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.48; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.147146369679831e-05
6.1115410971979145e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.88
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2850788350507712; val_accuracy: 0.9107285031847133 

The current subspace-distance is: 6.1115410971979145e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.56; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.44; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.45; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.5; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.5; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.39; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.176117959606927e-05
7.046369319141377e-06
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.27361943781565706; val_accuracy: 0.9166003184713376 

The current subspace-distance is: 7.046369319141377e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.84
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.5; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.205093733209651e-05
6.537897661473835e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.274439752244266; val_accuracy: 0.9147093949044586 

The current subspace-distance is: 6.537897661473835e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.44; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.63; acc: 0.81
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.47; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1345502318581566e-05
6.925335128471488e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.27605572698792075; val_accuracy: 0.916202229299363 

The current subspace-distance is: 6.925335128471488e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.83
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.84
Batch: 680; loss: 0.11; acc: 1.0
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0908717488055117e-05
7.032604571577394e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2765444053965769; val_accuracy: 0.9138136942675159 

The current subspace-distance is: 7.032604571577394e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.49; acc: 0.86
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.164515171898529e-05
7.207906037365319e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2731233971418848; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 7.207906037365319e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.39; acc: 0.92
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.86
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.98
Batch: 700; loss: 0.39; acc: 0.92
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1096224372740835e-05
6.394687261490617e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.5; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2746947085971286; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 6.394687261490617e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.43; acc: 0.83
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.84
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.83
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.54; acc: 0.83
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.44; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.151628359570168e-05
7.031780569377588e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.83
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.28023542245482186; val_accuracy: 0.9132165605095541 

The current subspace-distance is: 7.031780569377588e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.86
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.43; acc: 0.83
Batch: 380; loss: 0.52; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.89
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.42; acc: 0.89
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.49; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1421357814688236e-05
7.2283041845366824e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2724289839529687; val_accuracy: 0.9166998407643312 

The current subspace-distance is: 7.2283041845366824e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.39; acc: 0.83
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.48; acc: 0.91
Batch: 660; loss: 0.56; acc: 0.81
Batch: 680; loss: 0.46; acc: 0.86
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.42; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.113531627401244e-05
6.897139883221826e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2729099848467833; val_accuracy: 0.9152070063694268 

The current subspace-distance is: 6.897139883221826e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.83
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.44; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.84
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.86
Batch: 620; loss: 0.4; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1342655600165017e-05
6.982727882132167e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2742157273801269; val_accuracy: 0.9157046178343949 

The current subspace-distance is: 6.982727882132167e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.88
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.43; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.84
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.45; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1381796614150517e-05
7.342201115534408e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.27049724045832446; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 7.342201115534408e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.83
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.54; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.88
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.88
Batch: 720; loss: 0.52; acc: 0.83
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.2156440536491573e-05
7.71958366385661e-06
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2722280774811271; val_accuracy: 0.917296974522293 

The current subspace-distance is: 7.71958366385661e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.6; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.36; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.47; acc: 0.83
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.43; acc: 0.86
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.86
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.86
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.0927773221046664e-05
7.454093065462075e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2711627342898375; val_accuracy: 0.9174960191082803 

The current subspace-distance is: 7.454093065462075e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.44; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.52; acc: 0.88
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1539637600653805e-05
7.66472385294037e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2708592280555683; val_accuracy: 0.9179936305732485 

The current subspace-distance is: 7.66472385294037e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.5; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.88
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.98
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.52; acc: 0.83
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.53; acc: 0.94
Batch: 760; loss: 0.52; acc: 0.88
Batch: 780; loss: 0.4; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1161149561521597e-05
7.1418890001950786e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2715721950884078; val_accuracy: 0.9181926751592356 

The current subspace-distance is: 7.1418890001950786e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.88
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.88
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.47; acc: 0.81
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.39; acc: 0.83
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.86
Batch: 400; loss: 0.37; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1237003238638863e-05
7.3685646384547e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.27119336291483254; val_accuracy: 0.918093152866242 

The current subspace-distance is: 7.3685646384547e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.3; acc: 0.86
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.88
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1355950593715534e-05
7.578904842375778e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2707175895761532; val_accuracy: 0.9178941082802548 

The current subspace-distance is: 7.578904842375778e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.17; acc: 0.98
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.89
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.83
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.203074654971715e-05
7.698780791542958e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2709882042020749; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 7.698780791542958e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.48; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.38; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.86
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.54; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1296045815688558e-05
6.735896477039205e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.27247131070133984; val_accuracy: 0.9173964968152867 

The current subspace-distance is: 6.735896477039205e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.8
Batch: 120; loss: 0.36; acc: 0.84
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.72; acc: 0.83
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.83
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.48; acc: 0.89
Batch: 620; loss: 0.4; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1540628949878737e-05
7.592107522214064e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.47; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.27149294245584754; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 7.592107522214064e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_240_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 53317
elements in E: 11106500
fraction nonzero: 0.004800522216719939
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.16
Batch: 100; loss: 2.29; acc: 0.08
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.05
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.16
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.29; acc: 0.19
Batch: 260; loss: 2.29; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.2
Batch: 300; loss: 2.26; acc: 0.22
Batch: 320; loss: 2.26; acc: 0.2
Batch: 340; loss: 2.25; acc: 0.31
Batch: 360; loss: 2.24; acc: 0.34
Batch: 380; loss: 2.24; acc: 0.25
Batch: 400; loss: 2.22; acc: 0.27
Batch: 420; loss: 2.21; acc: 0.33
Batch: 440; loss: 2.2; acc: 0.25
Batch: 460; loss: 2.15; acc: 0.41
Batch: 480; loss: 2.09; acc: 0.42
Batch: 500; loss: 1.93; acc: 0.5
Batch: 520; loss: 1.75; acc: 0.64
Batch: 540; loss: 1.38; acc: 0.66
Batch: 560; loss: 0.97; acc: 0.81
Batch: 580; loss: 0.9; acc: 0.8
Batch: 600; loss: 0.98; acc: 0.73
Batch: 620; loss: 0.89; acc: 0.7
Batch: 640; loss: 0.73; acc: 0.73
Batch: 660; loss: 0.66; acc: 0.78
Batch: 680; loss: 0.77; acc: 0.75
Batch: 700; loss: 0.81; acc: 0.75
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.51; acc: 0.81
Batch: 760; loss: 0.77; acc: 0.83
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 1.77; train_accuracy: 0.4 

1.0642199413268827e-05
4.995966264687013e-06
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.85; acc: 0.75
Batch: 40; loss: 0.44; acc: 0.91
Batch: 60; loss: 0.86; acc: 0.75
Batch: 80; loss: 0.52; acc: 0.8
Batch: 100; loss: 0.61; acc: 0.77
Batch: 120; loss: 1.13; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.91
Val Epoch over. val_loss: 0.645615928491969; val_accuracy: 0.7936902866242038 

The current subspace-distance is: 4.995966264687013e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.94
Batch: 40; loss: 0.61; acc: 0.75
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.7; acc: 0.7
Batch: 100; loss: 0.41; acc: 0.84
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.5; acc: 0.86
Batch: 180; loss: 0.65; acc: 0.84
Batch: 200; loss: 0.79; acc: 0.77
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.97
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.49; acc: 0.86
Batch: 300; loss: 0.53; acc: 0.84
Batch: 320; loss: 0.67; acc: 0.8
Batch: 340; loss: 0.51; acc: 0.84
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.44; acc: 0.91
Batch: 460; loss: 0.54; acc: 0.77
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.49; acc: 0.84
Batch: 540; loss: 0.6; acc: 0.83
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.63; acc: 0.8
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.45; acc: 0.8
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

1.8212862414657138e-05
6.552437298523728e-06
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.3736952524750855; val_accuracy: 0.8862460191082803 

The current subspace-distance is: 6.552437298523728e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.44; acc: 0.81
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.89
Batch: 220; loss: 0.59; acc: 0.81
Batch: 240; loss: 0.63; acc: 0.78
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.95
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.63; acc: 0.8
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.6; acc: 0.81
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.33; acc: 0.84
Batch: 520; loss: 0.5; acc: 0.81
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.68; acc: 0.78
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.7; acc: 0.84
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.54; acc: 0.83
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.52; acc: 0.8
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

1.877152499218937e-05
6.017935902491445e-06
Batch: 0; loss: 0.61; acc: 0.83
Batch: 20; loss: 0.88; acc: 0.78
Batch: 40; loss: 0.6; acc: 0.86
Batch: 60; loss: 0.92; acc: 0.77
Batch: 80; loss: 0.71; acc: 0.83
Batch: 100; loss: 0.79; acc: 0.8
Batch: 120; loss: 1.03; acc: 0.77
Batch: 140; loss: 0.25; acc: 0.89
Val Epoch over. val_loss: 0.680089094931153; val_accuracy: 0.8238455414012739 

The current subspace-distance is: 6.017935902491445e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.86
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.63; acc: 0.8
Batch: 60; loss: 0.54; acc: 0.8
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.54; acc: 0.8
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.83
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.41; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.86
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.34; acc: 0.91
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.38; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.86
Batch: 540; loss: 0.63; acc: 0.78
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.44; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.020018655457534e-05
6.349076102196705e-06
Batch: 0; loss: 1.86; acc: 0.53
Batch: 20; loss: 1.66; acc: 0.56
Batch: 40; loss: 1.67; acc: 0.67
Batch: 60; loss: 2.82; acc: 0.59
Batch: 80; loss: 1.65; acc: 0.7
Batch: 100; loss: 2.07; acc: 0.67
Batch: 120; loss: 2.29; acc: 0.55
Batch: 140; loss: 2.19; acc: 0.73
Val Epoch over. val_loss: 1.8695819746157167; val_accuracy: 0.5942476114649682 

The current subspace-distance is: 6.349076102196705e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.1; acc: 0.55
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.81
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.45; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.83
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.56; acc: 0.81
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.86
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.86
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.006762042583432e-05
6.289539669523947e-06
Batch: 0; loss: 0.85; acc: 0.67
Batch: 20; loss: 1.44; acc: 0.61
Batch: 40; loss: 0.61; acc: 0.8
Batch: 60; loss: 1.46; acc: 0.66
Batch: 80; loss: 1.22; acc: 0.69
Batch: 100; loss: 0.91; acc: 0.69
Batch: 120; loss: 1.31; acc: 0.59
Batch: 140; loss: 0.83; acc: 0.73
Val Epoch over. val_loss: 1.115061589676863; val_accuracy: 0.6671974522292994 

The current subspace-distance is: 6.289539669523947e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.26; acc: 0.7
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.41; acc: 0.91
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.36; acc: 0.88
Batch: 260; loss: 0.49; acc: 0.83
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.44; acc: 0.89
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.64; acc: 0.86
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.49; acc: 0.89
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.25; acc: 0.88
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.48; acc: 0.81
Batch: 780; loss: 0.64; acc: 0.8
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.0593699446180835e-05
6.360727638821118e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37095628128309915; val_accuracy: 0.8862460191082803 

The current subspace-distance is: 6.360727638821118e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.51; acc: 0.86
Batch: 160; loss: 0.35; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.43; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.66; acc: 0.8
Batch: 400; loss: 0.27; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.59; acc: 0.84
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.83
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.0916395442327484e-05
6.337492777674925e-06
Batch: 0; loss: 0.58; acc: 0.83
Batch: 20; loss: 1.0; acc: 0.67
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 1.07; acc: 0.7
Batch: 140; loss: 0.42; acc: 0.88
Val Epoch over. val_loss: 0.6725690610659351; val_accuracy: 0.7872213375796179 

The current subspace-distance is: 6.337492777674925e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.8
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.45; acc: 0.86
Batch: 160; loss: 0.66; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.38; acc: 0.84
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.62; acc: 0.81
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.55; acc: 0.81
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.78; acc: 0.81
Batch: 700; loss: 0.72; acc: 0.8
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.33; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.054637297987938e-05
6.494431545434054e-06
Batch: 0; loss: 0.98; acc: 0.72
Batch: 20; loss: 1.39; acc: 0.62
Batch: 40; loss: 0.36; acc: 0.89
Batch: 60; loss: 1.17; acc: 0.75
Batch: 80; loss: 1.19; acc: 0.75
Batch: 100; loss: 0.88; acc: 0.78
Batch: 120; loss: 1.38; acc: 0.67
Batch: 140; loss: 0.8; acc: 0.77
Val Epoch over. val_loss: 0.9549135049437262; val_accuracy: 0.7240246815286624 

The current subspace-distance is: 6.494431545434054e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.72
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.44; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.32; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.48; acc: 0.81
Batch: 500; loss: 0.43; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.47; acc: 0.86
Batch: 560; loss: 0.36; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.86
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.153060086129699e-05
6.4150481193792075e-06
Batch: 0; loss: 0.67; acc: 0.8
Batch: 20; loss: 0.63; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.93; acc: 0.75
Batch: 80; loss: 0.49; acc: 0.8
Batch: 100; loss: 0.76; acc: 0.8
Batch: 120; loss: 1.03; acc: 0.67
Batch: 140; loss: 0.3; acc: 0.89
Val Epoch over. val_loss: 0.6464199783505907; val_accuracy: 0.8066281847133758 

The current subspace-distance is: 6.4150481193792075e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.78
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.5; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.91
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.72; acc: 0.78
Batch: 620; loss: 0.31; acc: 0.86
Batch: 640; loss: 0.6; acc: 0.86
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.1290423319442198e-05
6.9394604906847235e-06
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.21; acc: 0.89
Batch: 100; loss: 0.59; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.95
Val Epoch over. val_loss: 0.3433554584433319; val_accuracy: 0.8920183121019108 

The current subspace-distance is: 6.9394604906847235e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.53; acc: 0.86
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.41; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1469008061103523e-05
6.843617939011892e-06
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25811092664671553; val_accuracy: 0.9206807324840764 

The current subspace-distance is: 6.843617939011892e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.44; acc: 0.8
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.26; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.83
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.89
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.4; acc: 0.89
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1763455151813105e-05
7.741446097497828e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.2566059008715259; val_accuracy: 0.9226711783439491 

The current subspace-distance is: 7.741446097497828e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.84
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.41; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.98
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.59; acc: 0.81
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.12464619835373e-05
7.40530504117487e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24964482918571515; val_accuracy: 0.9235668789808917 

The current subspace-distance is: 7.40530504117487e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.57; acc: 0.86
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.31; acc: 0.84
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1119607481523417e-05
6.876630322949495e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25837305176315034; val_accuracy: 0.9211783439490446 

The current subspace-distance is: 6.876630322949495e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.83
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.86
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.41; acc: 0.88
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.45; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1257894331938587e-05
7.690021448070183e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.26581350448215085; val_accuracy: 0.9169984076433121 

The current subspace-distance is: 7.690021448070183e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.53; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.52; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.72; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.91
Batch: 500; loss: 0.26; acc: 0.88
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.170920379285235e-05
6.559846497111721e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.24441263193537474; val_accuracy: 0.9261544585987261 

The current subspace-distance is: 6.559846497111721e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.61; acc: 0.84
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.89
Batch: 340; loss: 0.53; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.48; acc: 0.83
Batch: 440; loss: 0.3; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.84
Batch: 480; loss: 0.51; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.86
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.4; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.6; acc: 0.81
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1860396373085678e-05
8.108106158033479e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.29069216295507305; val_accuracy: 0.9106289808917197 

The current subspace-distance is: 8.108106158033479e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.86
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.37; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.97
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.34; acc: 0.83
Batch: 600; loss: 0.32; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.43; acc: 0.91
Batch: 740; loss: 0.46; acc: 0.88
Batch: 760; loss: 0.46; acc: 0.83
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1455000023706816e-05
7.951462066557724e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.6; acc: 0.78
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3544136651192501; val_accuracy: 0.8941082802547771 

The current subspace-distance is: 7.951462066557724e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.98
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.47; acc: 0.88
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.41; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.97
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.71; acc: 0.83
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.5; acc: 0.78
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1409698092611507e-05
7.1687290983390994e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2558646337336795; val_accuracy: 0.9238654458598726 

The current subspace-distance is: 7.1687290983390994e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.39; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.53; acc: 0.81
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.84
Batch: 420; loss: 0.48; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.46; acc: 0.86
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.44; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.65; acc: 0.81
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.98
Batch: 740; loss: 0.46; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1744144760305062e-05
7.403343715850497e-06
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.25111482902222376; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 7.403343715850497e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.44; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.83
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.46; acc: 0.81
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.1635885786963627e-05
7.5102584560227115e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.24590429903310576; val_accuracy: 0.9266520700636943 

The current subspace-distance is: 7.5102584560227115e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.56; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.97
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

2.1587366063613445e-05
8.07762990007177e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.24339768492207406; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 8.07762990007177e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.52; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.39; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.89
Batch: 780; loss: 0.14; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.186824167438317e-05
7.522993200836936e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2507866958903659; val_accuracy: 0.9242635350318471 

The current subspace-distance is: 7.522993200836936e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.49; acc: 0.88
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.42; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.52; acc: 0.84
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.4; acc: 0.88
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.41; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1507832570932806e-05
7.361579719145084e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.24761101290298876; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 7.361579719145084e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.44; acc: 0.86
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.89
Batch: 440; loss: 0.5; acc: 0.86
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.46; acc: 0.83
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1954343537800014e-05
7.70545011619106e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2516134194080617; val_accuracy: 0.9247611464968153 

The current subspace-distance is: 7.70545011619106e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.4; acc: 0.84
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.52; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.44; acc: 0.84
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.47; acc: 0.88
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1710924556828104e-05
7.85817792348098e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.24169296256391107; val_accuracy: 0.9262539808917197 

The current subspace-distance is: 7.85817792348098e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.53; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.56; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.08; acc: 1.0
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.89
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1433539586723782e-05
6.626876256632386e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.24743659315025732; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 6.626876256632386e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.35; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.53; acc: 0.83
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.86
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.47; acc: 0.86
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.41; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1628216927638277e-05
7.2552452365926e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24650723209521572; val_accuracy: 0.9273487261146497 

The current subspace-distance is: 7.2552452365926e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.44; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1698295313399285e-05
7.590187124151271e-06
Batch: 0; loss: 0.12; acc: 1.0
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.2700561387523724; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 7.590187124151271e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.54; acc: 0.92
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.48; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.61; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.34; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1606250811601058e-05
7.639250725333113e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.24573418789893198; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 7.639250725333113e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.4; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.48; acc: 0.88
Batch: 320; loss: 0.45; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.49; acc: 0.88
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.13; acc: 0.98
Batch: 460; loss: 0.17; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.97
Batch: 620; loss: 0.42; acc: 0.83
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.45; acc: 0.91
Batch: 680; loss: 0.56; acc: 0.84
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.128398591594305e-05
7.395476586680161e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2372434676215527; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 7.395476586680161e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.44; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.88
Batch: 580; loss: 0.31; acc: 0.84
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.7; acc: 0.81
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.88
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1138084775884636e-05
6.56767952023074e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.24122302637548204; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 6.56767952023074e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.51; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.278224565088749e-05
8.63683544594096e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2409235393023415; val_accuracy: 0.9287420382165605 

The current subspace-distance is: 8.63683544594096e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.43; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.88
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.84
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.58; acc: 0.86
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.184836739616003e-05
7.49721220927313e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.24296307606492074; val_accuracy: 0.929140127388535 

The current subspace-distance is: 7.49721220927313e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.51; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.86
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.229019628430251e-05
7.76619344833307e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.23982209372957042; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 7.76619344833307e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.58; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1038860722910613e-05
7.296877356566256e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2380812948771343; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 7.296877356566256e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.33; acc: 0.84
Batch: 160; loss: 0.48; acc: 0.81
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.84
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.88
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1840145564056e-05
7.886262210377026e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24311485369304184; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 7.886262210377026e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.97
Batch: 140; loss: 0.55; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.88
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.6; acc: 0.84
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.43; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.98
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.83
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.183402466471307e-05
8.315702871186659e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.23838839563689415; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 8.315702871186659e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.38; acc: 0.81
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.263156602566596e-05
7.748123607598245e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.23740212512528822; val_accuracy: 0.9293391719745223 

The current subspace-distance is: 7.748123607598245e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.64; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.86
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.43; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.88
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.35; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.39; acc: 0.81
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1736455892096274e-05
7.934111636132002e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2394616050040646; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 7.934111636132002e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.91
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.3; acc: 0.86
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2107635231805034e-05
7.761518645565957e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.23832335916294414; val_accuracy: 0.9293391719745223 

The current subspace-distance is: 7.761518645565957e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.89
Batch: 40; loss: 0.37; acc: 0.86
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.37; acc: 0.94
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.72; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.24; acc: 0.89
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.44; acc: 0.89
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.94
Batch: 760; loss: 0.64; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.241961374238599e-05
8.214576155296527e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2382418717595802; val_accuracy: 0.9287420382165605 

The current subspace-distance is: 8.214576155296527e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.97
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.27; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.86
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.89
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.15360960282851e-05
6.173896508698817e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23854930331088176; val_accuracy: 0.9299363057324841 

The current subspace-distance is: 6.173896508698817e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1715233742725104e-05
7.892798748798668e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2391561782521427; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 7.892798748798668e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.35; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.95
Batch: 660; loss: 0.07; acc: 1.0
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.1; acc: 1.0
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.3; acc: 0.88
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1678550183423795e-05
7.416428616124904e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2381909083171635; val_accuracy: 0.9293391719745223 

The current subspace-distance is: 7.416428616124904e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.48; acc: 0.86
Batch: 320; loss: 0.35; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.248727105325088e-05
7.53358835936524e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.23825055543499388; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 7.53358835936524e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.83
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.84
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.46; acc: 0.81
Batch: 500; loss: 0.24; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2193915356183425e-05
8.096729288809001e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2390709697346019; val_accuracy: 0.9300358280254777 

The current subspace-distance is: 8.096729288809001e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.89
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.65; acc: 0.84
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1464782548719086e-05
7.208437182271155e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2380337671252193; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 7.208437182271155e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.52; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.86
Batch: 380; loss: 0.36; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.6; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1537663997150958e-05
7.794918019499164e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2375048801872381; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 7.794918019499164e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.8
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.55; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2044941943022422e-05
7.347292921622284e-06
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2387920068043053; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 7.347292921622284e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_250_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 54338
elements in E: 11550760
fraction nonzero: 0.0047042791989444855
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.28; acc: 0.16
Batch: 240; loss: 2.29; acc: 0.16
Batch: 260; loss: 2.3; acc: 0.14
Batch: 280; loss: 2.28; acc: 0.2
Batch: 300; loss: 2.27; acc: 0.23
Batch: 320; loss: 2.27; acc: 0.23
Batch: 340; loss: 2.26; acc: 0.25
Batch: 360; loss: 2.26; acc: 0.36
Batch: 380; loss: 2.25; acc: 0.36
Batch: 400; loss: 2.25; acc: 0.31
Batch: 420; loss: 2.24; acc: 0.27
Batch: 440; loss: 2.23; acc: 0.22
Batch: 460; loss: 2.2; acc: 0.34
Batch: 480; loss: 2.19; acc: 0.28
Batch: 500; loss: 2.12; acc: 0.36
Batch: 520; loss: 2.12; acc: 0.28
Batch: 540; loss: 2.1; acc: 0.38
Batch: 560; loss: 1.91; acc: 0.56
Batch: 580; loss: 1.83; acc: 0.55
Batch: 600; loss: 1.63; acc: 0.5
Batch: 620; loss: 1.33; acc: 0.64
Batch: 640; loss: 1.11; acc: 0.7
Batch: 660; loss: 0.94; acc: 0.7
Batch: 680; loss: 0.98; acc: 0.66
Batch: 700; loss: 1.11; acc: 0.66
Batch: 720; loss: 1.47; acc: 0.58
Batch: 740; loss: 0.66; acc: 0.83
Batch: 760; loss: 0.96; acc: 0.73
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 1.93; train_accuracy: 0.34 

9.849393791228067e-06
5.259470526652876e-06
Batch: 0; loss: 0.62; acc: 0.75
Batch: 20; loss: 0.81; acc: 0.67
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.64; acc: 0.83
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.66; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.88
Val Epoch over. val_loss: 0.546393336194336; val_accuracy: 0.833797770700637 

The current subspace-distance is: 5.259470526652876e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.84
Batch: 20; loss: 0.54; acc: 0.84
Batch: 40; loss: 0.78; acc: 0.75
Batch: 60; loss: 0.62; acc: 0.77
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.61; acc: 0.77
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.52; acc: 0.89
Batch: 160; loss: 0.47; acc: 0.86
Batch: 180; loss: 0.6; acc: 0.86
Batch: 200; loss: 0.66; acc: 0.8
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.66; acc: 0.83
Batch: 320; loss: 0.85; acc: 0.73
Batch: 340; loss: 0.48; acc: 0.89
Batch: 360; loss: 0.53; acc: 0.81
Batch: 380; loss: 0.75; acc: 0.73
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.58; acc: 0.78
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.45; acc: 0.84
Batch: 480; loss: 0.52; acc: 0.84
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.65; acc: 0.81
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.62; acc: 0.8
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.48; acc: 0.84
Batch: 700; loss: 0.38; acc: 0.84
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.5; train_accuracy: 0.85 

1.827831511036493e-05
5.929195594944758e-06
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.52; acc: 0.83
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.41494831210298905; val_accuracy: 0.8682324840764332 

The current subspace-distance is: 5.929195594944758e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.81
Batch: 20; loss: 0.54; acc: 0.8
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.39; acc: 0.83
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.61; acc: 0.83
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.45; acc: 0.84
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.51; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.53; acc: 0.78
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.86
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.56; acc: 0.91
Batch: 760; loss: 0.54; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

1.9029890609090216e-05
6.139962351880968e-06
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.74; acc: 0.75
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.24; acc: 0.88
Batch: 100; loss: 0.62; acc: 0.86
Batch: 120; loss: 0.85; acc: 0.77
Batch: 140; loss: 0.22; acc: 0.94
Val Epoch over. val_loss: 0.45316175238531864; val_accuracy: 0.857484076433121 

The current subspace-distance is: 6.139962351880968e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.42; acc: 0.81
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.67; acc: 0.8
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.38; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.51; acc: 0.83
Batch: 440; loss: 0.34; acc: 0.84
Batch: 460; loss: 0.45; acc: 0.91
Batch: 480; loss: 0.47; acc: 0.88
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.34; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.86
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.7; acc: 0.77
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.0526736989268102e-05
7.125425327103585e-06
Batch: 0; loss: 0.74; acc: 0.75
Batch: 20; loss: 0.75; acc: 0.78
Batch: 40; loss: 0.65; acc: 0.8
Batch: 60; loss: 1.36; acc: 0.67
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.94; acc: 0.77
Batch: 120; loss: 1.07; acc: 0.62
Batch: 140; loss: 0.53; acc: 0.77
Val Epoch over. val_loss: 0.8240795001672332; val_accuracy: 0.7433320063694268 

The current subspace-distance is: 7.125425327103585e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.92; acc: 0.72
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.83
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.84
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.56; acc: 0.84
Batch: 180; loss: 0.18; acc: 0.91
Batch: 200; loss: 0.72; acc: 0.75
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.88
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.92; acc: 0.8
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.89
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.029328425123822e-05
6.768028470105492e-06
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.74; acc: 0.78
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.79; acc: 0.8
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.3; acc: 0.88
Val Epoch over. val_loss: 0.5333462474262638; val_accuracy: 0.8362858280254777 

The current subspace-distance is: 6.768028470105492e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.28; acc: 0.86
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.45; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.94
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.68; acc: 0.86
Batch: 320; loss: 0.28; acc: 0.86
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.88
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.92
Batch: 640; loss: 0.82; acc: 0.75
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.58; acc: 0.75
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.0292394765419886e-05
6.290809324127622e-06
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.8
Batch: 60; loss: 1.07; acc: 0.72
Batch: 80; loss: 0.33; acc: 0.84
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.96; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.5556993036987675; val_accuracy: 0.8214570063694268 

The current subspace-distance is: 6.290809324127622e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.72
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.45; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.72; acc: 0.83
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.5; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.107146428897977e-05
7.0556384343944956e-06
Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.95; acc: 0.73
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.7; acc: 0.84
Batch: 120; loss: 0.85; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.91
Val Epoch over. val_loss: 0.5601621294382272; val_accuracy: 0.8322054140127388 

The current subspace-distance is: 7.0556384343944956e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.75; acc: 0.75
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.49; acc: 0.83
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.34; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.56; acc: 0.83
Batch: 220; loss: 0.41; acc: 0.84
Batch: 240; loss: 0.45; acc: 0.83
Batch: 260; loss: 0.4; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.88
Batch: 340; loss: 0.38; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.38; acc: 0.86
Batch: 420; loss: 0.36; acc: 0.92
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.5; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.51; acc: 0.81
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.83
Batch: 760; loss: 0.56; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.0887928258161992e-05
7.329052095883526e-06
Batch: 0; loss: 0.74; acc: 0.78
Batch: 20; loss: 1.61; acc: 0.67
Batch: 40; loss: 0.39; acc: 0.81
Batch: 60; loss: 0.95; acc: 0.83
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 1.39; acc: 0.73
Batch: 140; loss: 0.77; acc: 0.78
Val Epoch over. val_loss: 0.8648784604801494; val_accuracy: 0.7519904458598726 

The current subspace-distance is: 7.329052095883526e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.75
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.6; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.74; acc: 0.81
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.98
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.57; acc: 0.88
Batch: 480; loss: 0.48; acc: 0.83
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.97
Batch: 540; loss: 0.57; acc: 0.84
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.84
Batch: 660; loss: 0.48; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.39; acc: 0.86
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.0812190996366553e-05
6.396163826138945e-06
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.41840432598522515; val_accuracy: 0.8733081210191083 

The current subspace-distance is: 6.396163826138945e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.84
Batch: 460; loss: 0.52; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.86
Batch: 500; loss: 0.24; acc: 0.88
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.44; acc: 0.86
Batch: 600; loss: 0.56; acc: 0.78
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.98
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.48; acc: 0.86
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.091940950776916e-05
6.471701453847345e-06
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.62; acc: 0.78
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.54; acc: 0.89
Batch: 120; loss: 0.9; acc: 0.75
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.40398129901498747; val_accuracy: 0.8743033439490446 

The current subspace-distance is: 6.471701453847345e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.84
Batch: 340; loss: 0.23; acc: 0.97
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.44; acc: 0.92
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.1532005121116526e-05
6.3820079958532006e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26125254617280264; val_accuracy: 0.9220740445859873 

The current subspace-distance is: 6.3820079958532006e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.14; acc: 0.98
Batch: 320; loss: 0.4; acc: 0.91
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.84
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.38; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.88
Batch: 500; loss: 0.15; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.47; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.51; acc: 0.84
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1011119315517135e-05
7.0260512075037695e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26813077765285587; val_accuracy: 0.9212778662420382 

The current subspace-distance is: 7.0260512075037695e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.41; acc: 0.91
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.7; acc: 0.8
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.41; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.55; acc: 0.86
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.62; acc: 0.8
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.55; acc: 0.89
Batch: 780; loss: 0.53; acc: 0.8
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.09628797165351e-05
6.736364412063267e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2890496076482117; val_accuracy: 0.915406050955414 

The current subspace-distance is: 6.736364412063267e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.72; acc: 0.8
Batch: 240; loss: 0.28; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.98
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.58; acc: 0.84
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1358588128350675e-05
6.512063464469975e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.28295599740401955; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 6.512063464469975e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.46; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.84
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.84
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.86
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.41; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.86
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.147978921129834e-05
6.9723041633551475e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2802284399083086; val_accuracy: 0.9168988853503185 

The current subspace-distance is: 6.9723041633551475e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.88
Batch: 100; loss: 0.18; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.7; acc: 0.88
Batch: 160; loss: 0.46; acc: 0.89
Batch: 180; loss: 0.48; acc: 0.92
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.94
Batch: 400; loss: 0.44; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.5; acc: 0.92
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.98
Batch: 720; loss: 0.67; acc: 0.88
Batch: 740; loss: 0.26; acc: 0.88
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1103358449181542e-05
6.69608061798499e-06
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.25989937483315256; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 6.69608061798499e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.86
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.98
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.46; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.4; acc: 0.83
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1950803784420714e-05
6.366064553731121e-06
Batch: 0; loss: 0.27; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.31464124065200993; val_accuracy: 0.9048566878980892 

The current subspace-distance is: 6.366064553731121e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.43; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1280004148138687e-05
6.423957529477775e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.2699254220885456; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 6.423957529477775e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.2; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.55; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.46; acc: 0.88
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.47; acc: 0.86
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.48; acc: 0.84
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.29; acc: 0.89
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.182704338338226e-05
6.954990567464847e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.27872218998374454; val_accuracy: 0.9148089171974523 

The current subspace-distance is: 6.954990567464847e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.66; acc: 0.75
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.55; acc: 0.92
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.112551374011673e-05
6.878805834276136e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.25678086221502844; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 6.878805834276136e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.48; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.88
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.88
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.83
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.84
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.170306834159419e-05
6.890303666295949e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.25006601605920276; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 6.890303666295949e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.84
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.5; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.29; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.86
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.84
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.55; acc: 0.86
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1789428501506336e-05
6.784747711208183e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.2505996777515882; val_accuracy: 0.924562101910828 

The current subspace-distance is: 6.784747711208183e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.89
Batch: 20; loss: 0.46; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.84
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.29; acc: 0.86
Batch: 300; loss: 0.37; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.41; acc: 0.84
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.43; acc: 0.81
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1720488803111948e-05
6.75176579534309e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2692171315763407; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 6.75176579534309e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.88
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.56; acc: 0.86
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2187758077052422e-05
6.8487261160044e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2503188105335661; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 6.8487261160044e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.08; acc: 1.0
Batch: 140; loss: 0.4; acc: 0.91
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.59; acc: 0.88
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.37; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.187585414503701e-05
6.67107769913855e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.26318619948378796; val_accuracy: 0.9209792993630573 

The current subspace-distance is: 6.67107769913855e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.88
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.98
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.88
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.6; acc: 0.84
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2611688109464012e-05
7.251735951285809e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.24927586765520893; val_accuracy: 0.927547770700637 

The current subspace-distance is: 7.251735951285809e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.45; acc: 0.89
Batch: 280; loss: 0.39; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.42; acc: 0.81
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.84
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1805832147947513e-05
6.45830459689023e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.25475405737947504; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 6.45830459689023e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.48; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.83
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.45; acc: 0.78
Batch: 420; loss: 0.48; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.38; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.213222614955157e-05
7.4718514042615425e-06
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2483007551473417; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 7.4718514042615425e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.55; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.92
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.41; acc: 0.84
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1895411919103935e-05
6.433730959543027e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.25151817607367116; val_accuracy: 0.9253582802547771 

The current subspace-distance is: 6.433730959543027e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.6; acc: 0.88
Batch: 160; loss: 0.27; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.11; acc: 1.0
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.53; acc: 0.88
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.42; acc: 0.83
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.59; acc: 0.88
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.83
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.52; acc: 0.89
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.86
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2093609004514292e-05
6.66636333335191e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2579213078044782; val_accuracy: 0.9216759554140127 

The current subspace-distance is: 6.66636333335191e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.84
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.47; acc: 0.84
Batch: 380; loss: 0.35; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.21; acc: 0.97
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.57; acc: 0.88
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2134880055091344e-05
7.235872089950135e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24488205972845387; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 7.235872089950135e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.91
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.08; acc: 1.0
Batch: 400; loss: 0.5; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.39; acc: 0.94
Batch: 560; loss: 0.4; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.47; acc: 0.84
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.1; acc: 1.0
Batch: 680; loss: 0.23; acc: 0.89
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1716867195209488e-05
6.674193173239473e-06
Batch: 0; loss: 0.13; acc: 1.0
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.24524737555225185; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 6.674193173239473e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.88
Batch: 520; loss: 0.54; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.52; acc: 0.86
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.182675052608829e-05
6.9276488829927985e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24413877768311532; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 6.9276488829927985e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.37; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.98
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.66; acc: 0.88
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.35; acc: 0.88
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1597694285446778e-05
6.900677362864371e-06
Batch: 0; loss: 0.13; acc: 1.0
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2444831009503383; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 6.900677362864371e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.57; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.86
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.46; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.39; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.163394856324885e-05
6.850098088762024e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24524840266461584; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 6.850098088762024e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.83
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2240996258915402e-05
7.033721885818522e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2432364859398763; val_accuracy: 0.9273487261146497 

The current subspace-distance is: 7.033721885818522e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.84
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.37; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.84
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.83
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.86
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.32; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.84
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2180653104442172e-05
7.093932254065294e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2453680843067397; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 7.093932254065294e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.88
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.32; acc: 0.86
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.64; acc: 0.86
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.91
Batch: 760; loss: 0.55; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1922234736848623e-05
6.571771791641368e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2431494794358873; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 6.571771791641368e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.97
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.09; acc: 1.0
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.94
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.6; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1579435269813985e-05
6.4986193137883674e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24278668736576275; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 6.4986193137883674e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.84
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.36; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.86
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.84
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.84
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1644820662913844e-05
6.731710527674295e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.24287267302157015; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 6.731710527674295e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.88
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.45; acc: 0.83
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.45; acc: 0.89
Batch: 500; loss: 0.52; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1414458387880586e-05
7.759465916024055e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24122209524273114; val_accuracy: 0.9292396496815286 

The current subspace-distance is: 7.759465916024055e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.27; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.42; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1740483134635724e-05
6.686895630991785e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24158307936066276; val_accuracy: 0.9288415605095541 

The current subspace-distance is: 6.686895630991785e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.31; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.41; acc: 0.86
Batch: 260; loss: 0.31; acc: 0.88
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.86
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.84
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.54; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.58; acc: 0.91
Batch: 760; loss: 0.18; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2067690224503167e-05
6.903386292833602e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24127762517921483; val_accuracy: 0.928343949044586 

The current subspace-distance is: 6.903386292833602e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.47; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.86
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.83
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2416061256080866e-05
7.065420959406765e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2418862734061138; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 7.065420959406765e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.43; acc: 0.83
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.24121795326937e-05
6.873101483506616e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2421701629260543; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 6.873101483506616e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.91
Batch: 240; loss: 0.55; acc: 0.84
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.07; acc: 1.0
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1444328012876213e-05
6.7111932366969995e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24191117751750219; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 6.7111932366969995e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.86
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1983645638101734e-05
6.748389751010109e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2418640490123041; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 6.748389751010109e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.91
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.161076554330066e-05
6.944201231817715e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24238625591158108; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 6.944201231817715e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.39; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.86
Batch: 340; loss: 0.26; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.89
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.43; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.33; acc: 0.84
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.86
Batch: 620; loss: 0.4; acc: 0.84
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.46; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.155955007765442e-05
6.501139068859629e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24097300717120718; val_accuracy: 0.9296377388535032 

The current subspace-distance is: 6.501139068859629e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.97
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.62; acc: 0.83
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.98
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.08; acc: 1.0
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.46; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.41; acc: 0.84
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.154668800358195e-05
6.742479399690637e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.97
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24121652821161946; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 6.742479399690637e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_260_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 56998
elements in E: 11995020
fraction nonzero: 0.00475180533254634
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.16
Batch: 260; loss: 2.29; acc: 0.12
Batch: 280; loss: 2.28; acc: 0.16
Batch: 300; loss: 2.27; acc: 0.19
Batch: 320; loss: 2.28; acc: 0.27
Batch: 340; loss: 2.27; acc: 0.23
Batch: 360; loss: 2.27; acc: 0.17
Batch: 380; loss: 2.26; acc: 0.28
Batch: 400; loss: 2.26; acc: 0.25
Batch: 420; loss: 2.26; acc: 0.16
Batch: 440; loss: 2.25; acc: 0.28
Batch: 460; loss: 2.22; acc: 0.27
Batch: 480; loss: 2.22; acc: 0.23
Batch: 500; loss: 2.16; acc: 0.34
Batch: 520; loss: 2.15; acc: 0.3
Batch: 540; loss: 2.11; acc: 0.39
Batch: 560; loss: 1.96; acc: 0.56
Batch: 580; loss: 1.78; acc: 0.58
Batch: 600; loss: 1.37; acc: 0.59
Batch: 620; loss: 1.13; acc: 0.66
Batch: 640; loss: 0.87; acc: 0.8
Batch: 660; loss: 0.97; acc: 0.73
Batch: 680; loss: 0.96; acc: 0.7
Batch: 700; loss: 1.07; acc: 0.69
Batch: 720; loss: 0.89; acc: 0.7
Batch: 740; loss: 0.59; acc: 0.8
Batch: 760; loss: 1.01; acc: 0.69
Batch: 780; loss: 0.54; acc: 0.84
Train Epoch over. train_loss: 1.91; train_accuracy: 0.34 

9.741604117152747e-06
5.1850665840902366e-06
Batch: 0; loss: 1.47; acc: 0.56
Batch: 20; loss: 1.37; acc: 0.56
Batch: 40; loss: 0.94; acc: 0.7
Batch: 60; loss: 1.38; acc: 0.66
Batch: 80; loss: 1.27; acc: 0.64
Batch: 100; loss: 0.97; acc: 0.7
Batch: 120; loss: 1.78; acc: 0.56
Batch: 140; loss: 0.92; acc: 0.7
Val Epoch over. val_loss: 1.2875604602941282; val_accuracy: 0.6289808917197452 

The current subspace-distance is: 5.1850665840902366e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.19; acc: 0.56
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.87; acc: 0.7
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.59; acc: 0.8
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.62; acc: 0.88
Batch: 160; loss: 0.45; acc: 0.83
Batch: 180; loss: 0.56; acc: 0.84
Batch: 200; loss: 0.81; acc: 0.78
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.45; acc: 0.88
Batch: 280; loss: 0.73; acc: 0.77
Batch: 300; loss: 0.61; acc: 0.78
Batch: 320; loss: 0.68; acc: 0.8
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.61; acc: 0.77
Batch: 380; loss: 0.58; acc: 0.78
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.58; acc: 0.83
Batch: 460; loss: 0.48; acc: 0.81
Batch: 480; loss: 0.38; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.56; acc: 0.8
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.69; acc: 0.73
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.58; acc: 0.83
Batch: 700; loss: 0.54; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.89
Batch: 740; loss: 0.44; acc: 0.86
Batch: 760; loss: 0.41; acc: 0.84
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.51; train_accuracy: 0.84 

1.7870035662781447e-05
6.333910732791992e-06
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.65; acc: 0.78
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.83
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4635036845875394; val_accuracy: 0.8546974522292994 

The current subspace-distance is: 6.333910732791992e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.73
Batch: 20; loss: 0.7; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.65; acc: 0.77
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.77; acc: 0.77
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.52; acc: 0.83
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.88
Batch: 400; loss: 0.55; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.5; acc: 0.84
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.69; acc: 0.81
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.52; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.86
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.49; acc: 0.8
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

1.953635182871949e-05
6.847399163234513e-06
Batch: 0; loss: 0.76; acc: 0.81
Batch: 20; loss: 1.21; acc: 0.66
Batch: 40; loss: 0.53; acc: 0.86
Batch: 60; loss: 0.83; acc: 0.8
Batch: 80; loss: 0.67; acc: 0.81
Batch: 100; loss: 0.8; acc: 0.7
Batch: 120; loss: 1.47; acc: 0.69
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.7556774354284737; val_accuracy: 0.7925955414012739 

The current subspace-distance is: 6.847399163234513e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.78
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.35; acc: 0.91
Batch: 160; loss: 0.59; acc: 0.83
Batch: 180; loss: 0.37; acc: 0.86
Batch: 200; loss: 0.47; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.52; acc: 0.84
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.51; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.98
Batch: 540; loss: 0.71; acc: 0.75
Batch: 560; loss: 0.47; acc: 0.81
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.48; acc: 0.81
Batch: 640; loss: 0.56; acc: 0.8
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.37; train_accuracy: 0.89 

2.0131485143792816e-05
7.408789770124713e-06
Batch: 0; loss: 0.94; acc: 0.72
Batch: 20; loss: 0.94; acc: 0.69
Batch: 40; loss: 0.93; acc: 0.77
Batch: 60; loss: 1.55; acc: 0.66
Batch: 80; loss: 0.47; acc: 0.81
Batch: 100; loss: 0.95; acc: 0.75
Batch: 120; loss: 1.64; acc: 0.52
Batch: 140; loss: 0.85; acc: 0.78
Val Epoch over. val_loss: 0.9556880959659625; val_accuracy: 0.7430334394904459 

The current subspace-distance is: 7.408789770124713e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.52; acc: 0.61
Batch: 20; loss: 0.38; acc: 0.83
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.88
Batch: 200; loss: 0.44; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.48; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.63; acc: 0.86
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.46; acc: 0.88
Batch: 740; loss: 0.17; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.0840981960645877e-05
7.626700607943349e-06
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 1.07; acc: 0.75
Batch: 80; loss: 0.35; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.86
Batch: 120; loss: 0.97; acc: 0.73
Batch: 140; loss: 0.35; acc: 0.86
Val Epoch over. val_loss: 0.5802653522058657; val_accuracy: 0.8230493630573248 

The current subspace-distance is: 7.626700607943349e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.69; acc: 0.83
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.84
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.46; acc: 0.81
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.5; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.84
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.84; acc: 0.73
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.087563552777283e-05
7.300744528038194e-06
Batch: 0; loss: 0.88; acc: 0.73
Batch: 20; loss: 0.85; acc: 0.75
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.93; acc: 0.78
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.81; acc: 0.77
Batch: 120; loss: 1.53; acc: 0.56
Batch: 140; loss: 0.29; acc: 0.86
Val Epoch over. val_loss: 0.7601991320491597; val_accuracy: 0.7696058917197452 

The current subspace-distance is: 7.300744528038194e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.54; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.84
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.97
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.205562122981064e-05
7.5498828664422035e-06
Batch: 0; loss: 0.33; acc: 0.89
Batch: 20; loss: 0.55; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.98
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.3584978743723244; val_accuracy: 0.8914211783439491 

The current subspace-distance is: 7.5498828664422035e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.53; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.47; acc: 0.91
Batch: 220; loss: 0.42; acc: 0.88
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.37; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.83
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.42; acc: 0.91
Batch: 520; loss: 0.49; acc: 0.88
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.39; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.91
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.54; acc: 0.86
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.63; acc: 0.86
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2179254301590845e-05
7.617331903020386e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.41; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2795984470255815; val_accuracy: 0.9155055732484076 

The current subspace-distance is: 7.617331903020386e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.82; acc: 0.81
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.22; acc: 0.97
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.88
Batch: 220; loss: 0.34; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.62; acc: 0.81
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.83
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.55; acc: 0.83
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.63; acc: 0.84
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2283842554315925e-05
7.873676622693893e-06
Batch: 0; loss: 0.68; acc: 0.77
Batch: 20; loss: 0.76; acc: 0.77
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.59; acc: 0.84
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.75
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.46408036621702703; val_accuracy: 0.8586783439490446 

The current subspace-distance is: 7.873676622693893e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.92
Batch: 460; loss: 0.45; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.63; acc: 0.81
Batch: 620; loss: 0.17; acc: 0.92
Batch: 640; loss: 0.5; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.81
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.45; acc: 0.84
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.24283903662581e-05
7.831185939721763e-06
Batch: 0; loss: 0.36; acc: 0.84
Batch: 20; loss: 0.6; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.38390307114192634; val_accuracy: 0.8812699044585988 

The current subspace-distance is: 7.831185939721763e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.86
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.98
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.39; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

2.2315305614029057e-05
7.7549748311867e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2557316622726477; val_accuracy: 0.9190883757961783 

The current subspace-distance is: 7.7549748311867e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2588226784137078e-05
7.485724836442387e-06
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.26620943208408965; val_accuracy: 0.9184912420382165 

The current subspace-distance is: 7.485724836442387e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.33; acc: 0.94
Batch: 260; loss: 0.59; acc: 0.83
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.37; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.54; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.318362567166332e-05
7.998042747203726e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2522884312851034; val_accuracy: 0.9205812101910829 

The current subspace-distance is: 7.998042747203726e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.84
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.4; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.44; acc: 0.88
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.91
Batch: 460; loss: 0.56; acc: 0.84
Batch: 480; loss: 0.46; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.09; acc: 1.0
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1945408661849797e-05
7.799823833920527e-06
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2480593124867245; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 7.799823833920527e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.48; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.38; acc: 0.86
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.84
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.92
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2560661818715744e-05
7.328803349082591e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26266219780133787; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 7.328803349082591e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.51; acc: 0.88
Batch: 160; loss: 0.47; acc: 0.92
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.84
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.57; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.42; acc: 0.92
Batch: 480; loss: 0.46; acc: 0.88
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.88
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2549720597453415e-05
7.152995294745779e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2524314624536189; val_accuracy: 0.9226711783439491 

The current subspace-distance is: 7.152995294745779e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.62; acc: 0.84
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.83
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.39; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.61; acc: 0.88
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2788472051615827e-05
7.396648470603395e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.25686324273894545; val_accuracy: 0.9233678343949044 

The current subspace-distance is: 7.396648470603395e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.88
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.89
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.88
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2016800357960165e-05
8.19441720523173e-06
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.5; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.3025687916833124; val_accuracy: 0.9097332802547771 

The current subspace-distance is: 8.19441720523173e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.48; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.83
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.4; acc: 0.91
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.83
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2351756342686713e-05
7.937595910334494e-06
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2546040662534677; val_accuracy: 0.921875 

The current subspace-distance is: 7.937595910334494e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.42; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.15; acc: 0.97
Batch: 660; loss: 0.39; acc: 0.84
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2300524506135844e-05
8.125805834424682e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2696741480071833; val_accuracy: 0.9190883757961783 

The current subspace-distance is: 8.125805834424682e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.89
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.94
Batch: 340; loss: 0.38; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.28; acc: 0.89
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.88
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.233346094726585e-05
7.79374659032328e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23582065900325017; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 7.79374659032328e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.56; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.86
Batch: 360; loss: 0.2; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.88
Batch: 540; loss: 0.13; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.44; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2692722268402576e-05
7.817017831257544e-06
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2422296670117196; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 7.817017831257544e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.84
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.249740282422863e-05
7.711942998867016e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24913887288065473; val_accuracy: 0.924562101910828 

The current subspace-distance is: 7.711942998867016e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.3055032215779647e-05
7.613123671035282e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23831043112429845; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 7.613123671035282e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.1; acc: 1.0
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2678592358715832e-05
8.39747372083366e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23972113454227995; val_accuracy: 0.9259554140127388 

The current subspace-distance is: 8.39747372083366e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.89
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.89
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.91
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.94
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.257683991047088e-05
6.93129686624161e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24581724414779882; val_accuracy: 0.9258558917197452 

The current subspace-distance is: 6.93129686624161e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.98
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.63; acc: 0.84
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.12; acc: 1.0
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.24671221076278e-05
7.945402103359811e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24187378386023697; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 7.945402103359811e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.54; acc: 0.88
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.97
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2427822841564193e-05
8.284382602141704e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2407847751098074; val_accuracy: 0.9260549363057324 

The current subspace-distance is: 8.284382602141704e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.57; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.4; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.34; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2855179850012064e-05
7.780357918818481e-06
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.2504806089078545; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 7.780357918818481e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.31; acc: 0.86
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.63; acc: 0.84
Batch: 540; loss: 0.34; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.98
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.95
Batch: 780; loss: 0.47; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.3309217795031145e-05
7.699015441176016e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24526252977217838; val_accuracy: 0.9255573248407644 

The current subspace-distance is: 7.699015441176016e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.33; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.86
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.38; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.93 

2.2493199139717035e-05
7.391072813334176e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2375381198848129; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 7.391072813334176e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.81
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.09; acc: 1.0
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.51; acc: 0.86
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.36; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2195721612661146e-05
8.018316293600947e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.238331314200049; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 8.018316293600947e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.89
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.3009733922663145e-05
7.580947112728609e-06
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23966354905230225; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 7.580947112728609e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.5; acc: 0.8
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.97
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.09; acc: 1.0
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.3418802811647765e-05
7.649917279195506e-06
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2378829737567598; val_accuracy: 0.9266520700636943 

The current subspace-distance is: 7.649917279195506e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.41; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.35; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.3103773855837062e-05
8.404628715652507e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24218468557877146; val_accuracy: 0.926453025477707 

The current subspace-distance is: 8.404628715652507e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.53; acc: 0.89
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.41; acc: 0.92
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.84
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.2358759451890364e-05
7.925145837361924e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2400966098259209; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 7.925145837361924e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.88
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.32; acc: 0.94
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.18; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.09; acc: 1.0
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.91
Batch: 420; loss: 0.08; acc: 1.0
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.24; acc: 0.88
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2906197045813315e-05
7.76706019678386e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23879222937260464; val_accuracy: 0.927547770700637 

The current subspace-distance is: 7.76706019678386e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.5; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.33; acc: 0.91
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.6; acc: 0.83
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.88
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.35; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2429978344007395e-05
7.99930694483919e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23775127102994614; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 7.99930694483919e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.3383323423331603e-05
7.4609888542909175e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23785452914845412; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 7.4609888542909175e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.95
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.97
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2350788640324026e-05
7.632394044776447e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23745901949086767; val_accuracy: 0.928343949044586 

The current subspace-distance is: 7.632394044776447e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.29; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.86
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.32; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.3160193450166844e-05
7.77443256083643e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23550709583766902; val_accuracy: 0.9296377388535032 

The current subspace-distance is: 7.77443256083643e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.07; acc: 1.0
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2401411115424708e-05
8.338661245943513e-06
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2359759620610316; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 8.338661245943513e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2783628082834184e-05
8.14976647234289e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23539850969982754; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 8.14976647234289e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.47; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.88
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.36; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.260257679154165e-05
7.891713721619453e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23717699361265085; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 7.891713721619453e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.84
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.4; acc: 0.88
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.41; acc: 0.91
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2550337234861217e-05
7.617383744218387e-06
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23676837249925942; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 7.617383744218387e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.86
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.38; acc: 0.86
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2688504031975754e-05
8.258832167484798e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23651012816246908; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 8.258832167484798e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.25; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.256763218611013e-05
8.196827366191428e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2364584153435033; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 8.196827366191428e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.92
Batch: 280; loss: 0.49; acc: 0.84
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.88
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.35; acc: 0.88
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2886486476636492e-05
7.850706424505915e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2370059596979694; val_accuracy: 0.9290406050955414 

The current subspace-distance is: 7.850706424505915e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.33; acc: 0.86
Batch: 200; loss: 0.38; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.88
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.42; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.308693183294963e-05
8.615012120571919e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23745759064035052; val_accuracy: 0.9296377388535032 

The current subspace-distance is: 8.615012120571919e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.46; acc: 0.89
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.13; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.41; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.3077342120814137e-05
7.411862952722004e-06
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.23587419562468862; val_accuracy: 0.9296377388535032 

The current subspace-distance is: 7.411862952722004e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_270_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 59264
elements in E: 12439280
fraction nonzero: 0.004764262883382318
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.12
Batch: 240; loss: 2.28; acc: 0.22
Batch: 260; loss: 2.28; acc: 0.16
Batch: 280; loss: 2.28; acc: 0.19
Batch: 300; loss: 2.25; acc: 0.3
Batch: 320; loss: 2.24; acc: 0.23
Batch: 340; loss: 2.23; acc: 0.28
Batch: 360; loss: 2.21; acc: 0.28
Batch: 380; loss: 2.2; acc: 0.25
Batch: 400; loss: 2.17; acc: 0.33
Batch: 420; loss: 2.13; acc: 0.3
Batch: 440; loss: 2.05; acc: 0.48
Batch: 460; loss: 1.86; acc: 0.61
Batch: 480; loss: 1.68; acc: 0.58
Batch: 500; loss: 1.16; acc: 0.75
Batch: 520; loss: 1.07; acc: 0.7
Batch: 540; loss: 0.89; acc: 0.77
Batch: 560; loss: 0.56; acc: 0.86
Batch: 580; loss: 0.58; acc: 0.89
Batch: 600; loss: 0.68; acc: 0.81
Batch: 620; loss: 0.83; acc: 0.77
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.7; acc: 0.78
Batch: 700; loss: 0.71; acc: 0.8
Batch: 720; loss: 0.48; acc: 0.88
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 1.18; acc: 0.66
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 1.66; train_accuracy: 0.43 

1.1362780242052395e-05
5.1204624469392e-06
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.88; acc: 0.78
Batch: 140; loss: 0.24; acc: 0.94
Val Epoch over. val_loss: 0.5253391519283793; val_accuracy: 0.8522093949044586 

The current subspace-distance is: 5.1204624469392e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.83
Batch: 20; loss: 0.49; acc: 0.88
Batch: 40; loss: 0.81; acc: 0.78
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.63; acc: 0.83
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.51; acc: 0.83
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.98
Batch: 260; loss: 0.6; acc: 0.83
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.63; acc: 0.84
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.56; acc: 0.84
Batch: 380; loss: 0.59; acc: 0.78
Batch: 400; loss: 0.41; acc: 0.89
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.91
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.83
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.78
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.83
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.46; train_accuracy: 0.86 

1.8527465726947412e-05
6.755157301086001e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.49; acc: 0.83
Batch: 120; loss: 0.76; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.4113722741129292; val_accuracy: 0.8705214968152867 

The current subspace-distance is: 6.755157301086001e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.67; acc: 0.83
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.49; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.84
Batch: 220; loss: 0.64; acc: 0.88
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.59; acc: 0.81
Batch: 340; loss: 0.51; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.84
Batch: 400; loss: 0.66; acc: 0.83
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.42; acc: 0.83
Batch: 540; loss: 0.66; acc: 0.88
Batch: 560; loss: 0.5; acc: 0.83
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.56; acc: 0.83
Batch: 700; loss: 0.48; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.84
Batch: 760; loss: 0.48; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

2.040622530330438e-05
6.784260676795384e-06
Batch: 0; loss: 0.47; acc: 0.84
Batch: 20; loss: 0.7; acc: 0.78
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.54; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.67; acc: 0.83
Batch: 120; loss: 1.06; acc: 0.72
Batch: 140; loss: 0.31; acc: 0.91
Val Epoch over. val_loss: 0.4905655818760015; val_accuracy: 0.8471337579617835 

The current subspace-distance is: 6.784260676795384e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.56; acc: 0.84
Batch: 60; loss: 0.66; acc: 0.77
Batch: 80; loss: 0.47; acc: 0.8
Batch: 100; loss: 0.33; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.84
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.48; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.54; acc: 0.88
Batch: 440; loss: 0.4; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.92
Batch: 540; loss: 0.61; acc: 0.78
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.31; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.43; acc: 0.88
Batch: 760; loss: 0.46; acc: 0.86
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

2.069572474283632e-05
6.945622317289235e-06
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.89; acc: 0.78
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.21; acc: 0.94
Val Epoch over. val_loss: 0.4715087688794941; val_accuracy: 0.8596735668789809 

The current subspace-distance is: 6.945622317289235e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.77; acc: 0.8
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.39; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.42; acc: 0.83
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.88
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

2.098422555718571e-05
6.705642590532079e-06
Batch: 0; loss: 0.55; acc: 0.8
Batch: 20; loss: 0.6; acc: 0.8
Batch: 40; loss: 0.32; acc: 0.88
Batch: 60; loss: 0.79; acc: 0.81
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.84
Batch: 120; loss: 1.01; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.57203974380235; val_accuracy: 0.8220541401273885 

The current subspace-distance is: 6.705642590532079e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.89
Batch: 20; loss: 0.39; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.52; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.81
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.88
Batch: 380; loss: 0.33; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.86
Batch: 700; loss: 0.43; acc: 0.83
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.089853114739526e-05
7.120114787539933e-06
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.66; acc: 0.84
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.395280362551759; val_accuracy: 0.8803742038216561 

The current subspace-distance is: 7.120114787539933e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.32; acc: 0.94
Batch: 140; loss: 0.51; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.88
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.57; acc: 0.84
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.95
Batch: 540; loss: 0.44; acc: 0.88
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.1838499378645793e-05
6.788032806070987e-06
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.44; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.29557073583743376; val_accuracy: 0.9095342356687898 

The current subspace-distance is: 6.788032806070987e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.52; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.59; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.35; acc: 0.88
Batch: 160; loss: 0.51; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.84
Batch: 200; loss: 0.37; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.33; acc: 0.86
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.16; acc: 0.98
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.5; acc: 0.83
Batch: 560; loss: 0.45; acc: 0.89
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.6; acc: 0.81
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.1681602447642945e-05
7.071108484524302e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.84
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.34444909504834254; val_accuracy: 0.893312101910828 

The current subspace-distance is: 7.071108484524302e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.5; acc: 0.88
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.49; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.78; acc: 0.78
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.35; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.52; acc: 0.84
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.62; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.91
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

2.15962172660511e-05
7.029054359009024e-06
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.364772003001658; val_accuracy: 0.8877388535031847 

The current subspace-distance is: 7.029054359009024e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.86
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.84
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.42; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.49; acc: 0.83
Batch: 660; loss: 0.42; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.39; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.242903610749636e-05
7.262103281391319e-06
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.5; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3614187879120089; val_accuracy: 0.8880374203821656 

The current subspace-distance is: 7.262103281391319e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.34; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.36; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.33; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.88
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.51; acc: 0.86
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.2225945940590464e-05
8.298601642309222e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.25759146789646453; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 8.298601642309222e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.62; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.89
Batch: 340; loss: 0.06; acc: 1.0
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.32; acc: 0.89
Batch: 420; loss: 0.17; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.86
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.136806506314315e-05
6.639423645538045e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.26187218248749233; val_accuracy: 0.9221735668789809 

The current subspace-distance is: 6.639423645538045e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.41; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.49; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.34; acc: 0.88
Batch: 200; loss: 0.38; acc: 0.88
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.81
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.76; acc: 0.8
Batch: 660; loss: 0.35; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.193830550822895e-05
7.51459265302401e-06
Batch: 0; loss: 0.23; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26302126659804087; val_accuracy: 0.9209792993630573 

The current subspace-distance is: 7.51459265302401e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.32; acc: 0.86
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.88
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.3; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.92
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.42; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.2785468900110573e-05
8.118205187201966e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2626795764941319; val_accuracy: 0.9203821656050956 

The current subspace-distance is: 8.118205187201966e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.19; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.36; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.89
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.2222895495360717e-05
7.189429197751451e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2565720367963147; val_accuracy: 0.9230692675159236 

The current subspace-distance is: 7.189429197751451e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.47; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.66; acc: 0.81
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.34; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.32; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.57; acc: 0.89
Batch: 420; loss: 0.46; acc: 0.91
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.52; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.91
Batch: 720; loss: 0.57; acc: 0.86
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2030291802366264e-05
6.92890125719714e-06
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.25573626931780463; val_accuracy: 0.9244625796178344 

The current subspace-distance is: 6.92890125719714e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.53; acc: 0.81
Batch: 480; loss: 0.65; acc: 0.86
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.88
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2004249331075698e-05
7.1067547651182394e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2599666422577041; val_accuracy: 0.92296974522293 

The current subspace-distance is: 7.1067547651182394e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.34; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.45; acc: 0.91
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.52; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.48; acc: 0.83
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1885894966544583e-05
7.415453637804603e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.84
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.09; acc: 0.95
Val Epoch over. val_loss: 0.2625008024227847; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 7.415453637804603e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.08; acc: 1.0
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.44; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.52; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.303489418409299e-05
7.967175406520255e-06
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.25911030246858385; val_accuracy: 0.9236664012738853 

The current subspace-distance is: 7.967175406520255e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.47; acc: 0.86
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.98
Batch: 360; loss: 0.31; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.56; acc: 0.81
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.42; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2398584405891597e-05
7.968621503096074e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2489834949374199; val_accuracy: 0.9268511146496815 

The current subspace-distance is: 7.968621503096074e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.97
Batch: 480; loss: 0.31; acc: 0.84
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.84
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1877314793528058e-05
7.057098173390841e-06
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24427536748064932; val_accuracy: 0.928343949044586 

The current subspace-distance is: 7.057098173390841e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.29; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.89
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.86
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.43; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2160878870636225e-05
7.024904334684834e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24650574703315262; val_accuracy: 0.9281449044585988 

The current subspace-distance is: 7.024904334684834e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.26; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.97
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.41; acc: 0.86
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2338334019877948e-05
7.749566975689959e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.251619432287611; val_accuracy: 0.9270501592356688 

The current subspace-distance is: 7.749566975689959e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.5; acc: 0.86
Batch: 300; loss: 0.47; acc: 0.89
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.86
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2253516362980008e-05
7.81944709160598e-06
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.24959378694273104; val_accuracy: 0.9261544585987261 

The current subspace-distance is: 7.81944709160598e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.84
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.53; acc: 0.84
Batch: 300; loss: 0.5; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.86
Batch: 420; loss: 0.09; acc: 1.0
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2240366888581775e-05
7.509378065151395e-06
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24443789512203756; val_accuracy: 0.9287420382165605 

The current subspace-distance is: 7.509378065151395e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.34; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.98
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.89
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.63; acc: 0.84
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.32; acc: 0.88
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.95
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2274327420745976e-05
7.72735984355677e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2464188550877723; val_accuracy: 0.9265525477707006 

The current subspace-distance is: 7.72735984355677e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.24; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.6; acc: 0.86
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.24; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2229891328606755e-05
8.128566150844563e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2528820515248426; val_accuracy: 0.9227707006369427 

The current subspace-distance is: 8.128566150844563e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.89
Batch: 420; loss: 0.45; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.4; acc: 0.81
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.42; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.36; acc: 0.88
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.261652480228804e-05
7.675845154153649e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24463704160776487; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 7.675845154153649e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.84
Batch: 140; loss: 0.46; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.08; acc: 1.0
Batch: 260; loss: 0.27; acc: 0.95
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.28; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.5; acc: 0.86
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.98
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2232245100894943e-05
8.110788257909007e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.25043698155860994; val_accuracy: 0.9250597133757962 

The current subspace-distance is: 8.110788257909007e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.43; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.46; acc: 0.89
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.91
Batch: 520; loss: 0.64; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.23; acc: 0.88
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.47; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.299380321346689e-05
7.112292678357335e-06
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2503373288567279; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 7.112292678357335e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.88
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.51; acc: 0.88
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.86
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.51; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.86
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.5; acc: 0.83
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.288852738274727e-05
7.823903615644667e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.86
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.24430403379118368; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 7.823903615644667e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.98
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.98
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.52; acc: 0.84
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.29; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2892618289915845e-05
7.72948442318011e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.24161421156423107; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 7.72948442318011e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.36; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.95
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.37; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.56; acc: 0.89
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.37; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.64; acc: 0.84
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.3007029085420072e-05
7.66035827837186e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24142190645549708; val_accuracy: 0.9292396496815286 

The current subspace-distance is: 7.66035827837186e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.45; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.49; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.1996711438987404e-05
8.190569133148529e-06
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24229953579224978; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 8.190569133148529e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.46; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.84
Batch: 600; loss: 0.22; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2269079636316746e-05
7.2658617682463955e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24446108049837648; val_accuracy: 0.9295382165605095 

The current subspace-distance is: 7.2658617682463955e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.44; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2724803784512915e-05
7.906087375886273e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24532728955434385; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 7.906087375886273e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.37; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.235427928098943e-05
7.99379722593585e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24390181540778488; val_accuracy: 0.927547770700637 

The current subspace-distance is: 7.99379722593585e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.37; acc: 0.89
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.89
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.43; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.83
Batch: 380; loss: 0.56; acc: 0.84
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.246893200208433e-05
6.861069778096862e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24168493247525707; val_accuracy: 0.928343949044586 

The current subspace-distance is: 6.861069778096862e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.36; acc: 0.89
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.86
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.330457209609449e-05
8.068074748734944e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2410893919788728; val_accuracy: 0.9301353503184714 

The current subspace-distance is: 8.068074748734944e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.45; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.95
Batch: 140; loss: 0.25; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.39; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.26; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.89
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2518215700984e-05
8.572238584747538e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24077468220690254; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 8.572238584747538e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.13; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.292467252118513e-05
7.533898951805895e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2404724878324255; val_accuracy: 0.9303343949044586 

The current subspace-distance is: 7.533898951805895e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.57; acc: 0.89
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.24; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.32; acc: 0.88
Batch: 240; loss: 0.64; acc: 0.84
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.23; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2136520783533342e-05
7.210213425423717e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.23971375378121615; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 7.210213425423717e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.98
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.86
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.27; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.09; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.88
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.41; acc: 0.84
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.269137985422276e-05
7.442592959705507e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24008758049339626; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 7.442592959705507e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.35; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.48; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.31; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.25; acc: 0.89
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.3054124540067278e-05
7.04717103872099e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24017228205112895; val_accuracy: 0.9301353503184714 

The current subspace-distance is: 7.04717103872099e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2377211280399933e-05
7.49881291994825e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24107047916645077; val_accuracy: 0.929140127388535 

The current subspace-distance is: 7.49881291994825e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.46; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.98
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.250660691061057e-05
7.457685114786727e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24059121689171928; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 7.457685114786727e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.35; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2737141989637166e-05
8.098717444227077e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2403462418135564; val_accuracy: 0.9293391719745223 

The current subspace-distance is: 8.098717444227077e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.43; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.45; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.322433101653587e-05
8.208133294829167e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24092474624894228; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 8.208133294829167e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.44; acc: 0.89
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.91
Batch: 420; loss: 0.1; acc: 1.0
Batch: 440; loss: 0.39; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.91
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2593705580220558e-05
7.492544682463631e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.2406197195623521; val_accuracy: 0.9289410828025477 

The current subspace-distance is: 7.492544682463631e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.89
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.91
Batch: 440; loss: 0.36; acc: 0.84
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.17; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.59; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.88
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.41; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.297382161486894e-05
6.877228770463262e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.58; acc: 0.86
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.24042677271897625; val_accuracy: 0.9293391719745223 

The current subspace-distance is: 6.877228770463262e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_280_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 61317
elements in E: 12883540
fraction nonzero: 0.004759328569632259
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.31; acc: 0.03
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.05
Batch: 200; loss: 2.3; acc: 0.08
Batch: 220; loss: 2.28; acc: 0.14
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.09
Batch: 280; loss: 2.27; acc: 0.11
Batch: 300; loss: 2.26; acc: 0.17
Batch: 320; loss: 2.26; acc: 0.11
Batch: 340; loss: 2.25; acc: 0.16
Batch: 360; loss: 2.26; acc: 0.11
Batch: 380; loss: 2.24; acc: 0.12
Batch: 400; loss: 2.22; acc: 0.22
Batch: 420; loss: 2.21; acc: 0.25
Batch: 440; loss: 2.19; acc: 0.28
Batch: 460; loss: 2.12; acc: 0.5
Batch: 480; loss: 2.09; acc: 0.33
Batch: 500; loss: 1.95; acc: 0.48
Batch: 520; loss: 1.81; acc: 0.61
Batch: 540; loss: 1.44; acc: 0.66
Batch: 560; loss: 1.22; acc: 0.59
Batch: 580; loss: 0.88; acc: 0.83
Batch: 600; loss: 0.97; acc: 0.62
Batch: 620; loss: 0.82; acc: 0.78
Batch: 640; loss: 0.69; acc: 0.78
Batch: 660; loss: 0.77; acc: 0.75
Batch: 680; loss: 0.68; acc: 0.8
Batch: 700; loss: 0.82; acc: 0.75
Batch: 720; loss: 0.98; acc: 0.75
Batch: 740; loss: 0.65; acc: 0.83
Batch: 760; loss: 1.05; acc: 0.72
Batch: 780; loss: 0.58; acc: 0.88
Train Epoch over. train_loss: 1.79; train_accuracy: 0.36 

1.103510567190824e-05
5.904516910959501e-06
Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 0.76; acc: 0.72
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.82; acc: 0.8
Batch: 80; loss: 0.57; acc: 0.81
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 0.27; acc: 0.94
Val Epoch over. val_loss: 0.6882169486800577; val_accuracy: 0.7866242038216561 

The current subspace-distance is: 5.904516910959501e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.75
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.66; acc: 0.78
Batch: 60; loss: 0.53; acc: 0.78
Batch: 80; loss: 0.8; acc: 0.7
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.73; acc: 0.77
Batch: 160; loss: 0.6; acc: 0.83
Batch: 180; loss: 0.56; acc: 0.86
Batch: 200; loss: 0.67; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.18; acc: 0.98
Batch: 260; loss: 0.64; acc: 0.78
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.81
Batch: 320; loss: 0.9; acc: 0.75
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.5; acc: 0.86
Batch: 380; loss: 0.54; acc: 0.8
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.52; acc: 0.84
Batch: 440; loss: 0.59; acc: 0.86
Batch: 460; loss: 0.94; acc: 0.67
Batch: 480; loss: 0.35; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.4; acc: 0.86
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.86
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.47; acc: 0.91
Batch: 660; loss: 0.52; acc: 0.83
Batch: 680; loss: 0.55; acc: 0.86
Batch: 700; loss: 0.51; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

1.865214653662406e-05
6.65618563289172e-06
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.98
Val Epoch over. val_loss: 0.38361626517051345; val_accuracy: 0.8847531847133758 

The current subspace-distance is: 6.65618563289172e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.7; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.84
Batch: 220; loss: 0.73; acc: 0.78
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.88
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.55; acc: 0.88
Batch: 320; loss: 0.47; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.47; acc: 0.84
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.92
Batch: 480; loss: 0.47; acc: 0.83
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.4; acc: 0.88
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.46; acc: 0.86
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.57; acc: 0.88
Batch: 640; loss: 0.58; acc: 0.84
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.71; acc: 0.83
Train Epoch over. train_loss: 0.38; train_accuracy: 0.89 

2.066041633952409e-05
6.7253081397211645e-06
Batch: 0; loss: 0.97; acc: 0.72
Batch: 20; loss: 0.68; acc: 0.75
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.77; acc: 0.86
Batch: 80; loss: 0.57; acc: 0.78
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 1.12; acc: 0.7
Batch: 140; loss: 0.3; acc: 0.86
Val Epoch over. val_loss: 0.5960473142042282; val_accuracy: 0.8203622611464968 

The current subspace-distance is: 6.7253081397211645e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.81
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.49; acc: 0.86
Batch: 60; loss: 0.61; acc: 0.78
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.86
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.57; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.46; acc: 0.83
Batch: 440; loss: 0.48; acc: 0.83
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.52; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.49; acc: 0.88
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.38; acc: 0.84
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.35; train_accuracy: 0.9 

2.1070178263471462e-05
7.480829935957445e-06
Batch: 0; loss: 0.92; acc: 0.72
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 1.12; acc: 0.81
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.86
Batch: 120; loss: 1.06; acc: 0.64
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.6212967683555214; val_accuracy: 0.814390923566879 

The current subspace-distance is: 7.480829935957445e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.95; acc: 0.72
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.65; acc: 0.83
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.4; acc: 0.81
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.83
Batch: 380; loss: 0.48; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.43; acc: 0.83
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.47; acc: 0.88
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.88
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.35; acc: 0.89
Batch: 720; loss: 0.5; acc: 0.86
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.1912304873694666e-05
7.111393642844632e-06
Batch: 0; loss: 2.29; acc: 0.55
Batch: 20; loss: 2.27; acc: 0.58
Batch: 40; loss: 1.71; acc: 0.59
Batch: 60; loss: 2.45; acc: 0.55
Batch: 80; loss: 2.61; acc: 0.55
Batch: 100; loss: 1.81; acc: 0.55
Batch: 120; loss: 2.39; acc: 0.47
Batch: 140; loss: 1.64; acc: 0.59
Val Epoch over. val_loss: 2.020972641789989; val_accuracy: 0.5730493630573248 

The current subspace-distance is: 7.111393642844632e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.15; acc: 0.56
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.86
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.45; acc: 0.81
Batch: 180; loss: 0.31; acc: 0.84
Batch: 200; loss: 0.38; acc: 0.84
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.94
Batch: 260; loss: 0.6; acc: 0.75
Batch: 280; loss: 0.36; acc: 0.94
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.37; acc: 0.83
Batch: 340; loss: 0.31; acc: 0.86
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.89
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.88
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.44; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.59; acc: 0.84
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.44; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.78
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

2.226685501227621e-05
6.603086603718111e-06
Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.89
Batch: 60; loss: 0.74; acc: 0.81
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.89; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.91
Val Epoch over. val_loss: 0.4101627697800375; val_accuracy: 0.8736066878980892 

The current subspace-distance is: 6.603086603718111e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.43; acc: 0.84
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.89
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.88
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.20834044739604e-05
7.397735316772014e-06
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.77
Batch: 140; loss: 0.15; acc: 0.95
Val Epoch over. val_loss: 0.41195759400250803; val_accuracy: 0.8691281847133758 

The current subspace-distance is: 7.397735316772014e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.6; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.48; acc: 0.89
Batch: 160; loss: 0.67; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.22; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.89
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.46; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.39; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.6; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.55; acc: 0.8
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.2316182366921566e-05
7.306501174753066e-06
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.8
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.79; acc: 0.78
Batch: 80; loss: 0.57; acc: 0.83
Batch: 100; loss: 0.35; acc: 0.86
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.514949281314376; val_accuracy: 0.8461385350318471 

The current subspace-distance is: 7.306501174753066e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.64; acc: 0.84
Batch: 80; loss: 0.41; acc: 0.84
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.34; acc: 0.89
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.5; acc: 0.88
Batch: 200; loss: 0.15; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.88
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.84
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.84
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.64; acc: 0.84
Batch: 720; loss: 0.54; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.83
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.22718772420194e-05
6.744034635630669e-06
Batch: 0; loss: 0.9; acc: 0.81
Batch: 20; loss: 0.95; acc: 0.69
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 1.02; acc: 0.83
Batch: 80; loss: 0.99; acc: 0.75
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 1.22; acc: 0.67
Batch: 140; loss: 0.35; acc: 0.89
Val Epoch over. val_loss: 0.7407925758202365; val_accuracy: 0.7990644904458599 

The current subspace-distance is: 6.744034635630669e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.81; acc: 0.78
Batch: 20; loss: 0.36; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.86
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.89
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.46; acc: 0.83
Batch: 580; loss: 0.62; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.55; acc: 0.83
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.3; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.2191466996446252e-05
7.020518296485534e-06
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.96; acc: 0.77
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 0.21; acc: 0.91
Val Epoch over. val_loss: 0.4418621254479809; val_accuracy: 0.8663415605095541 

The current subspace-distance is: 7.020518296485534e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.76; acc: 0.81
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.43; acc: 0.83
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.25; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.89
Batch: 580; loss: 0.32; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.86
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.38; acc: 0.84
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.43; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2286951207206585e-05
7.216635367512936e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2515713416372135; val_accuracy: 0.9247611464968153 

The current subspace-distance is: 7.216635367512936e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.95
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.5; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.84
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2279460608842783e-05
7.6157543844601605e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2499653022665127; val_accuracy: 0.9272492038216561 

The current subspace-distance is: 7.6157543844601605e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.98
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.57; acc: 0.89
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.61; acc: 0.81
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.47; acc: 0.84
Batch: 280; loss: 0.26; acc: 0.86
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.98
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.35; acc: 0.81
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.25474050239427e-05
7.212217496999074e-06
Batch: 0; loss: 0.31; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2998749099576929; val_accuracy: 0.911922770700637 

The current subspace-distance is: 7.212217496999074e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.08; acc: 1.0
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.88
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.34; acc: 0.92
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.22686448978493e-05
6.778799615858588e-06
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24019843455000667; val_accuracy: 0.9298367834394905 

The current subspace-distance is: 6.778799615858588e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.47; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.98
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.86
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.11; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.89
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.97
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.346380460949149e-05
7.487888979085255e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2358990432872514; val_accuracy: 0.930234872611465 

The current subspace-distance is: 7.487888979085255e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.88
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.6; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.59; acc: 0.86
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.98
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.98
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.42; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.258778113173321e-05
6.8581925916078035e-06
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.26314253783577185; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 6.8581925916078035e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.58; acc: 0.83
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.86
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.86
Batch: 480; loss: 0.53; acc: 0.86
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.86
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2459502361016348e-05
6.710382422170369e-06
Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.31360016796429446; val_accuracy: 0.9070461783439491 

The current subspace-distance is: 6.710382422170369e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.86
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.84
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.88
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.44; acc: 0.84
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.51; acc: 0.91
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.3229189537232742e-05
7.686919161642436e-06
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.84
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2751344915740429; val_accuracy: 0.919187898089172 

The current subspace-distance is: 7.686919161642436e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.45; acc: 0.84
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.88
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.48; acc: 0.86
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2722828362020664e-05
7.266401553351898e-06
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2484815658135399; val_accuracy: 0.9262539808917197 

The current subspace-distance is: 7.266401553351898e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.89
Batch: 200; loss: 0.5; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.92
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2611638996750116e-05
7.287957032531267e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.57; acc: 0.78
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.2666204464473542; val_accuracy: 0.9197850318471338 

The current subspace-distance is: 7.287957032531267e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.39; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.98
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.91
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.228109588031657e-05
6.8736167122551706e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.22467152203676427; val_accuracy: 0.9339171974522293 

The current subspace-distance is: 6.8736167122551706e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.86
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2544909370481037e-05
7.118052508303663e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.23459014325005234; val_accuracy: 0.932921974522293 

The current subspace-distance is: 7.118052508303663e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.54; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.3348866307060234e-05
7.097230991348624e-06
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2432134880144505; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 7.097230991348624e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.32; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.88
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2738684492651373e-05
6.808303623984102e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.21817830552578352; val_accuracy: 0.93640525477707 

The current subspace-distance is: 6.808303623984102e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.97
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.88
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2928297767066397e-05
7.106409611878917e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.56; acc: 0.8
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2262876643947545; val_accuracy: 0.9345143312101911 

The current subspace-distance is: 7.106409611878917e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.84
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2611468011746183e-05
6.763142664567567e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2134476339527566; val_accuracy: 0.939390923566879 

The current subspace-distance is: 6.763142664567567e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.34; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.35; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.98
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.23; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2901154807186686e-05
7.074612767610233e-06
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.58; acc: 0.78
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21767551612085217; val_accuracy: 0.935609076433121 

The current subspace-distance is: 7.074612767610233e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.31; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.45; acc: 0.88
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.53; acc: 0.88
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.364313149882946e-05
7.738334716123063e-06
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.53; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2233922327423741; val_accuracy: 0.9353105095541401 

The current subspace-distance is: 7.738334716123063e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.4; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.35; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.91
Batch: 300; loss: 0.41; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.88
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.316563404747285e-05
6.936958016012795e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2303933258981082; val_accuracy: 0.9323248407643312 

The current subspace-distance is: 6.936958016012795e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.51; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.32; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.2632271793554537e-05
7.096189619915094e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2231663131647429; val_accuracy: 0.9350119426751592 

The current subspace-distance is: 7.096189619915094e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.92
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.41; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.47; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3482007236452773e-05
7.238807484100107e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2151751569027354; val_accuracy: 0.9349124203821656 

The current subspace-distance is: 7.238807484100107e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.31; acc: 0.95
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.12; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.58; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.33; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.91
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.2340354917105287e-05
7.397407898679376e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.211568575577846; val_accuracy: 0.9367038216560509 

The current subspace-distance is: 7.397407898679376e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.51; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.41; acc: 0.86
Batch: 580; loss: 0.1; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.07; acc: 1.0
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.2556809199159034e-05
7.513441232731566e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2141966979452379; val_accuracy: 0.9376990445859873 

The current subspace-distance is: 7.513441232731566e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.27; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.89
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.292422686878126e-05
7.757686034892686e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.08; acc: 1.0
Batch: 120; loss: 0.54; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21389715966715175; val_accuracy: 0.9366042993630573 

The current subspace-distance is: 7.757686034892686e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.39; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.32; acc: 0.94
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.39; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.3; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.89
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.325448986084666e-05
7.5579418989946134e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20908874049070914; val_accuracy: 0.9389928343949044 

The current subspace-distance is: 7.5579418989946134e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3827476979931816e-05
7.521543921029661e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20730958888485174; val_accuracy: 0.9398885350318471 

The current subspace-distance is: 7.521543921029661e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.28; acc: 0.86
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.38; acc: 0.92
Batch: 380; loss: 0.08; acc: 1.0
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.28; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3888776922831312e-05
7.743390597170219e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20728618678915653; val_accuracy: 0.9388933121019108 

The current subspace-distance is: 7.743390597170219e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3032302124192938e-05
6.982894774409942e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2132391506912792; val_accuracy: 0.9382961783439491 

The current subspace-distance is: 6.982894774409942e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3130349291022867e-05
7.595089300593827e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20715026111359808; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 7.595089300593827e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.14; acc: 0.98
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.323663284187205e-05
7.054027264530305e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20961789359712296; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 7.054027264530305e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.86
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.3092998162610456e-05
7.392610768874874e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2069731571587028; val_accuracy: 0.9379976114649682 

The current subspace-distance is: 7.392610768874874e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.88
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.5; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.86
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.350482282054145e-05
7.597273452120135e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20777239340837975; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 7.597273452120135e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.25; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.91
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.37; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.3908636649139225e-05
7.944788194436114e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2057494595053659; val_accuracy: 0.9389928343949044 

The current subspace-distance is: 7.944788194436114e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.06; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.46; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.07; acc: 1.0
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.3703161787125282e-05
7.90547528595198e-06
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.2056215273773974; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 7.90547528595198e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.88
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.84
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.318148108315654e-05
7.021313649602234e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20514455803070858; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 7.021313649602234e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.34; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.54; acc: 0.91
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.3229913495015353e-05
6.9724683271488175e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20762189195319347; val_accuracy: 0.9396894904458599 

The current subspace-distance is: 6.9724683271488175e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.08; acc: 1.0
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.88
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.3319918909692205e-05
7.223934971989365e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20753584785541151; val_accuracy: 0.9395899681528662 

The current subspace-distance is: 7.223934971989365e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.44; acc: 0.89
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.91
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.2656278815702535e-05
7.28911800251808e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20558077098125485; val_accuracy: 0.9399880573248408 

The current subspace-distance is: 7.28911800251808e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.4; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.88
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.28; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.38; acc: 0.91
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.5; acc: 0.88
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.88
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.3313625206355937e-05
7.781344720569905e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20619297783323534; val_accuracy: 0.939390923566879 

The current subspace-distance is: 7.781344720569905e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.84
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.27197688218439e-05
7.245365850394592e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20644145194369895; val_accuracy: 0.9392914012738853 

The current subspace-distance is: 7.245365850394592e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_290_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 63280
elements in E: 13327800
fraction nonzero: 0.004747970407719204
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.09
Batch: 120; loss: 2.3; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.29; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.11
Batch: 200; loss: 2.3; acc: 0.16
Batch: 220; loss: 2.27; acc: 0.38
Batch: 240; loss: 2.28; acc: 0.28
Batch: 260; loss: 2.28; acc: 0.19
Batch: 280; loss: 2.27; acc: 0.28
Batch: 300; loss: 2.25; acc: 0.2
Batch: 320; loss: 2.24; acc: 0.36
Batch: 340; loss: 2.2; acc: 0.42
Batch: 360; loss: 2.17; acc: 0.5
Batch: 380; loss: 2.14; acc: 0.36
Batch: 400; loss: 2.08; acc: 0.47
Batch: 420; loss: 2.01; acc: 0.36
Batch: 440; loss: 1.88; acc: 0.53
Batch: 460; loss: 1.53; acc: 0.53
Batch: 480; loss: 1.51; acc: 0.5
Batch: 500; loss: 0.98; acc: 0.73
Batch: 520; loss: 0.93; acc: 0.78
Batch: 540; loss: 1.14; acc: 0.7
Batch: 560; loss: 0.76; acc: 0.78
Batch: 580; loss: 0.74; acc: 0.78
Batch: 600; loss: 0.98; acc: 0.73
Batch: 620; loss: 0.75; acc: 0.8
Batch: 640; loss: 0.52; acc: 0.88
Batch: 660; loss: 0.57; acc: 0.77
Batch: 680; loss: 0.99; acc: 0.66
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.63; acc: 0.78
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 1.03; acc: 0.77
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 1.65; train_accuracy: 0.47 

1.1512187484186143e-05
4.708120286522899e-06
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.97; acc: 0.73
Batch: 80; loss: 0.58; acc: 0.8
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 1.06; acc: 0.69
Batch: 140; loss: 0.27; acc: 0.91
Val Epoch over. val_loss: 0.5801212706003979; val_accuracy: 0.8247412420382165 

The current subspace-distance is: 4.708120286522899e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.75
Batch: 20; loss: 0.37; acc: 0.92
Batch: 40; loss: 0.85; acc: 0.73
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.8
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.57; acc: 0.86
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.57; acc: 0.8
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.98
Batch: 260; loss: 0.52; acc: 0.8
Batch: 280; loss: 0.49; acc: 0.83
Batch: 300; loss: 0.65; acc: 0.78
Batch: 320; loss: 0.54; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.43; acc: 0.91
Batch: 380; loss: 0.49; acc: 0.81
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.92
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.69; acc: 0.83
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.88
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.38; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

1.865731246653013e-05
6.300889708654722e-06
Batch: 0; loss: 0.21; acc: 0.97
Batch: 20; loss: 0.56; acc: 0.75
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.35113846432346446; val_accuracy: 0.8892316878980892 

The current subspace-distance is: 6.300889708654722e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.74; acc: 0.8
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.58; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.84
Batch: 220; loss: 0.54; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.83
Batch: 320; loss: 0.61; acc: 0.8
Batch: 340; loss: 0.37; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.88
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.5; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.027964910666924e-05
6.884576123411534e-06
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.58; acc: 0.84
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.3533532389077791; val_accuracy: 0.8891321656050956 

The current subspace-distance is: 6.884576123411534e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.8
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.73; acc: 0.8
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.47; acc: 0.88
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.89
Batch: 420; loss: 0.46; acc: 0.83
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.84
Batch: 500; loss: 0.27; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.48; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.0938285160809755e-05
6.813110303482972e-06
Batch: 0; loss: 0.93; acc: 0.67
Batch: 20; loss: 1.06; acc: 0.62
Batch: 40; loss: 1.21; acc: 0.72
Batch: 60; loss: 1.74; acc: 0.64
Batch: 80; loss: 1.2; acc: 0.69
Batch: 100; loss: 1.34; acc: 0.69
Batch: 120; loss: 1.91; acc: 0.64
Batch: 140; loss: 0.78; acc: 0.84
Val Epoch over. val_loss: 1.2052432856741984; val_accuracy: 0.6900875796178344 

The current subspace-distance is: 6.813110303482972e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.75; acc: 0.62
Batch: 20; loss: 0.43; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.42; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.55; acc: 0.84
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.48; acc: 0.84
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.88
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.1336847566999495e-05
6.860256689833477e-06
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.74; acc: 0.84
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.5; acc: 0.84
Batch: 120; loss: 0.89; acc: 0.8
Batch: 140; loss: 0.3; acc: 0.86
Val Epoch over. val_loss: 0.5609629120037054; val_accuracy: 0.8264331210191083 

The current subspace-distance is: 6.860256689833477e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.56; acc: 0.84
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.56; acc: 0.81
Batch: 760; loss: 0.45; acc: 0.86
Batch: 780; loss: 0.56; acc: 0.81
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

2.141108961950522e-05
7.066281796141993e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.55; acc: 0.86
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.64; acc: 0.83
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.303593539555741; val_accuracy: 0.9088375796178344 

The current subspace-distance is: 7.066281796141993e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.43; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.63; acc: 0.86
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.29; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1538166038226336e-05
6.616173322981922e-06
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.52; acc: 0.81
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.52; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.5041242976477192; val_accuracy: 0.8452428343949044 

The current subspace-distance is: 6.616173322981922e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.48; acc: 0.91
Batch: 40; loss: 0.29; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.43; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.3; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.31; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.48; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.98
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.218115514551755e-05
7.365174951701192e-06
Batch: 0; loss: 0.43; acc: 0.83
Batch: 20; loss: 0.82; acc: 0.73
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.87; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.92; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.6201082418678673; val_accuracy: 0.8178742038216561 

The current subspace-distance is: 7.365174951701192e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.34; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.39; acc: 0.86
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.71; acc: 0.86
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.52; acc: 0.88
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.42; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.92
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2372343664756045e-05
7.102198196662357e-06
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27413179870149135; val_accuracy: 0.9182921974522293 

The current subspace-distance is: 7.102198196662357e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.97
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.28; acc: 0.88
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.88
Batch: 400; loss: 0.3; acc: 0.95
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.65; acc: 0.84
Batch: 600; loss: 0.39; acc: 0.86
Batch: 620; loss: 0.17; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.91
Batch: 680; loss: 0.08; acc: 1.0
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2366473785950802e-05
7.328730589506449e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.81
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.36; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.3088786273150687; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 7.328730589506449e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.34; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.37; acc: 0.84
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.06; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2233354684431106e-05
7.213789558591088e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20802425131628846; val_accuracy: 0.9371019108280255 

The current subspace-distance is: 7.213789558591088e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.08; acc: 1.0
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.48; acc: 0.88
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.09; acc: 1.0
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.294124715263024e-05
7.85941392678069e-06
Batch: 0; loss: 0.17; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.56; acc: 0.86
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.23823860579520273; val_accuracy: 0.9278463375796179 

The current subspace-distance is: 7.85941392678069e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.29; acc: 0.97
Batch: 260; loss: 0.28; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.35; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.5; acc: 0.88
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.41; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.197430694650393e-05
7.188811196101597e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21367380490443508; val_accuracy: 0.9359076433121019 

The current subspace-distance is: 7.188811196101597e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.42; acc: 0.84
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.19; acc: 0.98
Batch: 220; loss: 0.38; acc: 0.84
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.33; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.3; acc: 0.91
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.288156065333169e-05
6.909167495905422e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2340771025699225; val_accuracy: 0.9285429936305732 

The current subspace-distance is: 6.909167495905422e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.94
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.05; acc: 1.0
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.91
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.259823122585658e-05
7.591314442834118e-06
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.97
Batch: 120; loss: 0.51; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.21806638281507668; val_accuracy: 0.9338176751592356 

The current subspace-distance is: 7.591314442834118e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.88
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.33; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.97
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.35; acc: 0.95
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.2480417101178318e-05
7.268211447808426e-06
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.91
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20739443298239427; val_accuracy: 0.9384952229299363 

The current subspace-distance is: 7.268211447808426e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.91
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.334659620828461e-05
7.124544481484918e-06
Batch: 0; loss: 0.14; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.97
Batch: 120; loss: 0.51; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21435197130747283; val_accuracy: 0.9373009554140127 

The current subspace-distance is: 7.124544481484918e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.98
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.49; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.38; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.2923355572856963e-05
7.2584998633828945e-06
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.91
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.26663019491513823; val_accuracy: 0.9179936305732485 

The current subspace-distance is: 7.2584998633828945e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.86
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.44; acc: 0.88
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.86
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.37; acc: 0.92
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.329526614630595e-05
8.11018435342703e-06
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.22126932279058512; val_accuracy: 0.9374004777070064 

The current subspace-distance is: 8.11018435342703e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.32; acc: 0.89
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.41; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.97
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.29; acc: 0.91
Batch: 660; loss: 0.59; acc: 0.81
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.31; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.2669770260108635e-05
7.461683708243072e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.21957567421968577; val_accuracy: 0.9325238853503185 

The current subspace-distance is: 7.461683708243072e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.89
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.24; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.95
Batch: 700; loss: 0.08; acc: 1.0
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.284192669321783e-05
7.448058113368461e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1962718151948729; val_accuracy: 0.9427746815286624 

The current subspace-distance is: 7.448058113368461e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.84
Batch: 240; loss: 0.03; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.39; acc: 0.92
Batch: 440; loss: 0.2; acc: 0.89
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.83
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.98
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.97
Batch: 760; loss: 0.36; acc: 0.89
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.3370719645754434e-05
7.993979124876205e-06
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20126612011675432; val_accuracy: 0.9409832802547771 

The current subspace-distance is: 7.993979124876205e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.94
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.4; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.91
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.325415516679641e-05
7.739206012047362e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.203816816053549; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 7.739206012047362e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.39; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.4; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.06; acc: 1.0
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.276733903272543e-05
7.706087671977002e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.92
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.20040660653453155; val_accuracy: 0.9400875796178344 

The current subspace-distance is: 7.706087671977002e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.07; acc: 1.0
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.41; acc: 0.88
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.32; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.97
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.92
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.24; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.275442056998145e-05
7.262352482939605e-06
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.49; acc: 0.89
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19938245291115753; val_accuracy: 0.9430732484076433 

The current subspace-distance is: 7.262352482939605e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.98
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.56; acc: 0.88
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.2986863768892363e-05
7.5120406108908355e-06
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19717766317556712; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 7.5120406108908355e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.06; acc: 1.0
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.98
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.97
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.33; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.2524356609210372e-05
7.448055384884356e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19637710992602786; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 7.448055384884356e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.89
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.2446307411883026e-05
6.85048053128412e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1943952956883486; val_accuracy: 0.9422770700636943 

The current subspace-distance is: 6.85048053128412e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.2827593056717888e-05
7.211694537545554e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.20659906972365774; val_accuracy: 0.9378980891719745 

The current subspace-distance is: 7.211694537545554e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.46; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.09; acc: 1.0
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.55; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.2819756850367412e-05
7.557875051134033e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19798305033332414; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 7.557875051134033e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.06; acc: 1.0
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.3; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.91
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3144086298998445e-05
7.397463832603535e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.92
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19697594795684525; val_accuracy: 0.9418789808917197 

The current subspace-distance is: 7.397463832603535e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.36; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.35; acc: 0.92
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.45; acc: 0.92
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.86
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.88
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2933538275538012e-05
7.392043698928319e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19428777538097589; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 7.392043698928319e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.39; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.16; acc: 0.91
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2754813471692614e-05
6.9115194492042065e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.45; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1947216501720487; val_accuracy: 0.942078025477707 

The current subspace-distance is: 6.9115194492042065e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.89
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3015096303424798e-05
7.358639777521603e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19340548281124822; val_accuracy: 0.9434713375796179 

The current subspace-distance is: 7.358639777521603e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.28; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.84
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.251211481052451e-05
7.05224965713569e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19402754234422923; val_accuracy: 0.9430732484076433 

The current subspace-distance is: 7.05224965713569e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.39; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.04; acc: 0.98
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.53; acc: 0.84
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2961912691243924e-05
6.966310138523113e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.91
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.1958098242794917; val_accuracy: 0.9427746815286624 

The current subspace-distance is: 6.966310138523113e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.14; acc: 0.98
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3704778868705034e-05
7.474757694581058e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19650071117860876; val_accuracy: 0.9421775477707006 

The current subspace-distance is: 7.474757694581058e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.84
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.69; acc: 0.86
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.36; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.37; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.05; acc: 1.0
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3523898562416434e-05
7.529879894718761e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19527143486152598; val_accuracy: 0.941281847133758 

The current subspace-distance is: 7.529879894718761e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.29; acc: 0.89
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.28; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3487324142479338e-05
7.929949788376689e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.19504562146060025; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 7.929949788376689e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.91
Batch: 80; loss: 0.07; acc: 1.0
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.25; acc: 0.89
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.89
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3158507246989757e-05
7.047319286357379e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1951336911078661; val_accuracy: 0.9424761146496815 

The current subspace-distance is: 7.047319286357379e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.34; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.84
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.91
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2765460016671568e-05
7.57735688239336e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19300088187928793; val_accuracy: 0.9435708598726115 

The current subspace-distance is: 7.57735688239336e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.37; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2707803509547375e-05
6.982695595070254e-06
Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1939084552596234; val_accuracy: 0.943172770700637 

The current subspace-distance is: 6.982695595070254e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.98
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.45; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.89
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2861155230202712e-05
7.870310582802631e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19306744728830588; val_accuracy: 0.943968949044586 

The current subspace-distance is: 7.870310582802631e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.1; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.95
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.88
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.302121174579952e-05
7.883635589678306e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19309046816460457; val_accuracy: 0.943172770700637 

The current subspace-distance is: 7.883635589678306e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.13; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.88
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.98
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.32; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2334870664053597e-05
7.090106009854935e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19484734831223632; val_accuracy: 0.9426751592356688 

The current subspace-distance is: 7.090106009854935e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.89
Batch: 360; loss: 0.18; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.98
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.264378963445779e-05
7.3660467023728415e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1929704770208544; val_accuracy: 0.9433718152866242 

The current subspace-distance is: 7.3660467023728415e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.98
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.19; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3225507902679965e-05
7.258395271492191e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19308707692844282; val_accuracy: 0.9430732484076433 

The current subspace-distance is: 7.258395271492191e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.88
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.4; acc: 0.86
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.88
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.88
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2591435481444933e-05
7.335148893616861e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19317784584512945; val_accuracy: 0.9426751592356688 

The current subspace-distance is: 7.335148893616861e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.38; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.83
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.95
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.307399336132221e-05
7.369168542936677e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.92
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1941520344513427; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 7.369168542936677e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.4; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3479731680708937e-05
7.874628863646649e-06
Batch: 0; loss: 0.13; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.92
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.19361638038709855; val_accuracy: 0.943172770700637 

The current subspace-distance is: 7.874628863646649e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 73836
elements in E: 15549100
fraction nonzero: 0.004748570656822581
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.06
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.29; acc: 0.11
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.3; acc: 0.08
Batch: 160; loss: 2.28; acc: 0.17
Batch: 180; loss: 2.29; acc: 0.06
Batch: 200; loss: 2.29; acc: 0.17
Batch: 220; loss: 2.27; acc: 0.22
Batch: 240; loss: 2.27; acc: 0.22
Batch: 260; loss: 2.27; acc: 0.2
Batch: 280; loss: 2.27; acc: 0.2
Batch: 300; loss: 2.25; acc: 0.23
Batch: 320; loss: 2.23; acc: 0.28
Batch: 340; loss: 2.21; acc: 0.36
Batch: 360; loss: 2.15; acc: 0.42
Batch: 380; loss: 2.13; acc: 0.42
Batch: 400; loss: 2.02; acc: 0.56
Batch: 420; loss: 1.9; acc: 0.42
Batch: 440; loss: 1.48; acc: 0.69
Batch: 460; loss: 1.03; acc: 0.77
Batch: 480; loss: 1.26; acc: 0.52
Batch: 500; loss: 0.7; acc: 0.8
Batch: 520; loss: 0.83; acc: 0.75
Batch: 540; loss: 0.71; acc: 0.84
Batch: 560; loss: 0.72; acc: 0.77
Batch: 580; loss: 0.57; acc: 0.89
Batch: 600; loss: 0.86; acc: 0.7
Batch: 620; loss: 0.78; acc: 0.83
Batch: 640; loss: 0.55; acc: 0.88
Batch: 660; loss: 0.55; acc: 0.84
Batch: 680; loss: 0.68; acc: 0.7
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.57; acc: 0.81
Batch: 740; loss: 0.55; acc: 0.84
Batch: 760; loss: 0.81; acc: 0.72
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 1.55; train_accuracy: 0.48 

1.1975382221862674e-05
5.298125415720278e-06
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.4372977211976507; val_accuracy: 0.8662420382165605 

The current subspace-distance is: 5.298125415720278e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.86
Batch: 20; loss: 0.37; acc: 0.86
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.47; acc: 0.88
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.53; acc: 0.84
Batch: 200; loss: 0.61; acc: 0.78
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.53; acc: 0.88
Batch: 280; loss: 0.39; acc: 0.88
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 0.77; acc: 0.78
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.41; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.54; acc: 0.84
Batch: 560; loss: 0.43; acc: 0.84
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.5; acc: 0.84
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

1.926414370245766e-05
6.645751000178279e-06
Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.45; acc: 0.88
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.63; acc: 0.78
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.36168650903139904; val_accuracy: 0.8838574840764332 

The current subspace-distance is: 6.645751000178279e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.8
Batch: 20; loss: 0.87; acc: 0.73
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.38; acc: 0.91
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.69; acc: 0.81
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.5; acc: 0.88
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.64; acc: 0.78
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.59; acc: 0.86
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.64; acc: 0.83
Batch: 560; loss: 0.39; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.56; acc: 0.77
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.39; acc: 0.91
Batch: 760; loss: 0.42; acc: 0.89
Batch: 780; loss: 0.56; acc: 0.84
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.0334819055278786e-05
6.851770649518585e-06
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.55; acc: 0.81
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.56; acc: 0.84
Batch: 100; loss: 0.8; acc: 0.75
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.38; acc: 0.88
Val Epoch over. val_loss: 0.5153157515036073; val_accuracy: 0.8384753184713376 

The current subspace-distance is: 6.851770649518585e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.83
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.51; acc: 0.84
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.45; acc: 0.91
Batch: 300; loss: 0.51; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0815587049582973e-05
6.5877934503077995e-06
Batch: 0; loss: 2.24; acc: 0.5
Batch: 20; loss: 1.52; acc: 0.58
Batch: 40; loss: 1.43; acc: 0.77
Batch: 60; loss: 2.37; acc: 0.61
Batch: 80; loss: 1.15; acc: 0.7
Batch: 100; loss: 1.99; acc: 0.5
Batch: 120; loss: 2.59; acc: 0.45
Batch: 140; loss: 1.24; acc: 0.66
Val Epoch over. val_loss: 1.608385141108446; val_accuracy: 0.6163415605095541 

The current subspace-distance is: 6.5877934503077995e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.96; acc: 0.53
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.51; acc: 0.8
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.31; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.88
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.88
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.54; acc: 0.84
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.095141462632455e-05
6.9485927269852255e-06
Batch: 0; loss: 0.54; acc: 0.77
Batch: 20; loss: 0.84; acc: 0.75
Batch: 40; loss: 0.28; acc: 0.95
Batch: 60; loss: 0.8; acc: 0.8
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.5; acc: 0.81
Batch: 120; loss: 1.03; acc: 0.67
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.5548975077594162; val_accuracy: 0.8214570063694268 

The current subspace-distance is: 6.9485927269852255e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.91
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.36; acc: 0.88
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.45; acc: 0.91
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.84
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.25; acc: 0.89
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.07; acc: 1.0
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.84
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.47; acc: 0.83
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.1717023628298193e-05
7.220108727779007e-06
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.27; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.9; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.30592684870123105; val_accuracy: 0.9080414012738853 

The current subspace-distance is: 7.220108727779007e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.51; acc: 0.86
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.89
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.3; acc: 0.88
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.88
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2078031179262325e-05
8.246620382124092e-06
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.41; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2742984464783577; val_accuracy: 0.9185907643312102 

The current subspace-distance is: 8.246620382124092e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.33; acc: 0.91
Batch: 160; loss: 0.44; acc: 0.81
Batch: 180; loss: 0.43; acc: 0.84
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.32; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.08; acc: 1.0
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.49; acc: 0.81
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2999069187790155e-05
7.596587693114998e-06
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.22286410349759328; val_accuracy: 0.9334195859872612 

The current subspace-distance is: 7.596587693114998e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.84
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.88
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.47; acc: 0.86
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.22; acc: 0.98
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.89
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.3085260181687772e-05
7.149531029426726e-06
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 0.52; acc: 0.8
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.86; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.4834544892618611; val_accuracy: 0.8583797770700637 

The current subspace-distance is: 7.149531029426726e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.44; acc: 0.92
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.5; acc: 0.88
Batch: 600; loss: 0.4; acc: 0.81
Batch: 620; loss: 0.24; acc: 0.92
Batch: 640; loss: 0.42; acc: 0.89
Batch: 660; loss: 0.39; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.35; acc: 0.86
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

2.297300670761615e-05
7.049564374028705e-06
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.65; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.63; acc: 0.72
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.32406947913633033; val_accuracy: 0.9023686305732485 

The current subspace-distance is: 7.049564374028705e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.31; acc: 0.88
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.37; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.25; acc: 0.89
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.26; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.91
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

2.3761494958307594e-05
7.3371725193283055e-06
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.49; acc: 0.84
Batch: 140; loss: 0.04; acc: 1.0
Val Epoch over. val_loss: 0.19952990283157415; val_accuracy: 0.9413813694267515 

The current subspace-distance is: 7.3371725193283055e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.23; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3051241441862658e-05
7.158586413424928e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.199558812531696; val_accuracy: 0.9397890127388535 

The current subspace-distance is: 7.158586413424928e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.37; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.31; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.3; acc: 0.86
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2464759240392596e-05
7.20627531336504e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19732325353250382; val_accuracy: 0.9405851910828026 

The current subspace-distance is: 7.20627531336504e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.36; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.43; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.32; acc: 0.86
Batch: 540; loss: 0.06; acc: 1.0
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2777878257329576e-05
7.219880444608862e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19633486705600836; val_accuracy: 0.9419785031847133 

The current subspace-distance is: 7.219880444608862e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.46; acc: 0.91
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.338068406970706e-05
7.743607966403943e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.187601380928117; val_accuracy: 0.9444665605095541 

The current subspace-distance is: 7.743607966403943e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.52; acc: 0.91
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.37; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.59; acc: 0.81
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.44; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.89
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3336930098594166e-05
7.32468333808356e-06
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.91
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.20378845640618332; val_accuracy: 0.9403861464968153 

The current subspace-distance is: 7.32468333808356e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.53; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.07; acc: 1.0
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.91
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.89
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.89
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.298137405887246e-05
6.9261704993550666e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1996222984069472; val_accuracy: 0.941281847133758 

The current subspace-distance is: 6.9261704993550666e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.88
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.89
Batch: 560; loss: 0.22; acc: 0.89
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.21; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.54; acc: 0.84
Batch: 760; loss: 0.33; acc: 0.89
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.325965579075273e-05
7.686832759645768e-06
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18826213483787646; val_accuracy: 0.945859872611465 

The current subspace-distance is: 7.686832759645768e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.89
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.89
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.22; acc: 0.89
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.297363243997097e-05
7.231958988995757e-06
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19423686219438627; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 7.231958988995757e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.3; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.36; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.3; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.35005918511888e-05
7.582688795082504e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19599168531739028; val_accuracy: 0.9422770700636943 

The current subspace-distance is: 7.582688795082504e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.25; acc: 0.88
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.12; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3370221242657863e-05
7.366389127128059e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17946620537027433; val_accuracy: 0.9477507961783439 

The current subspace-distance is: 7.366389127128059e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.41; acc: 0.91
Batch: 420; loss: 0.34; acc: 0.91
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.31; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.07; acc: 1.0
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.91
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.98
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.07; acc: 1.0
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.345756183785852e-05
7.338247542065801e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18247965671074617; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 7.338247542065801e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.91
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.98
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3474836780223995e-05
7.1206532084033825e-06
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.19528282165622254; val_accuracy: 0.9423765923566879 

The current subspace-distance is: 7.1206532084033825e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3566784875583835e-05
7.445028586516855e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.18349048326824122; val_accuracy: 0.9454617834394905 

The current subspace-distance is: 7.445028586516855e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.33; acc: 0.86
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.33; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.53; acc: 0.89
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.09; acc: 1.0
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3100890757632442e-05
7.56766621634597e-06
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18558475394157847; val_accuracy: 0.9460589171974523 

The current subspace-distance is: 7.56766621634597e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.39; acc: 0.84
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.18; acc: 0.97
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.11; acc: 1.0
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.330419374629855e-05
7.3416345003352035e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18018134182710557; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 7.3416345003352035e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.09; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.48; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.06; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.322202271898277e-05
7.084845947247231e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.35; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1858395628488747; val_accuracy: 0.9459593949044586 

The current subspace-distance is: 7.084845947247231e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.22; acc: 0.97
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.97
Batch: 680; loss: 0.41; acc: 0.94
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3724176571704447e-05
7.17620378054562e-06
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18583875491171126; val_accuracy: 0.9450636942675159 

The current subspace-distance is: 7.17620378054562e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.37; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.19; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.91
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3505770514020696e-05
7.747562449367251e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1833695765038964; val_accuracy: 0.946656050955414 

The current subspace-distance is: 7.747562449367251e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.89
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3782584321452305e-05
8.57575378176989e-06
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.19994006445927984; val_accuracy: 0.9389928343949044 

The current subspace-distance is: 8.57575378176989e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.2; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.08; acc: 1.0
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3480901290895417e-05
7.208532679214841e-06
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1782211557647605; val_accuracy: 0.9470541401273885 

The current subspace-distance is: 7.208532679214841e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.95
Batch: 400; loss: 0.42; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.36; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3453480025636964e-05
8.15139264886966e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18072044970408366; val_accuracy: 0.9464570063694268 

The current subspace-distance is: 8.15139264886966e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.39; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.362164741498418e-05
6.9999609877413604e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17883329095829065; val_accuracy: 0.9469546178343949 

The current subspace-distance is: 6.9999609877413604e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.91
Batch: 160; loss: 0.29; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.3; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.310215677425731e-05
7.641478987352457e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17805323441317128; val_accuracy: 0.9477507961783439 

The current subspace-distance is: 7.641478987352457e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.37; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.89
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.95
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.98
Batch: 240; loss: 0.05; acc: 1.0
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.08; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3544134819530882e-05
7.454594651790103e-06
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17900728372631558; val_accuracy: 0.9479498407643312 

The current subspace-distance is: 7.454594651790103e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.39; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.92
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.37; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.395545016042888e-05
7.646904123248532e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18327426881926834; val_accuracy: 0.946656050955414 

The current subspace-distance is: 7.646904123248532e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.36; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3812321160221472e-05
7.2871139309427235e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17702870588203903; val_accuracy: 0.9478503184713376 

The current subspace-distance is: 7.2871139309427235e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.98
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.45; acc: 0.84
Batch: 180; loss: 0.19; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.91
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.98
Batch: 380; loss: 0.52; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.84
Batch: 460; loss: 0.39; acc: 0.89
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.16; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.368332934565842e-05
7.821318831702229e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17962903187722917; val_accuracy: 0.9467555732484076 

The current subspace-distance is: 7.821318831702229e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.31; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.06; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.318528640898876e-05
7.130991434678435e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17788663122114862; val_accuracy: 0.9477507961783439 

The current subspace-distance is: 7.130991434678435e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.11; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.07; acc: 1.0
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.08; acc: 1.0
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3652837626286782e-05
8.579774657846428e-06
Batch: 0; loss: 0.13; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1770805041216741; val_accuracy: 0.9475517515923567 

The current subspace-distance is: 8.579774657846428e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.98
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.21; acc: 0.92
Batch: 240; loss: 0.3; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.48; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.98
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3397522454615682e-05
7.416043445118703e-06
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17677472591115412; val_accuracy: 0.9482484076433121 

The current subspace-distance is: 7.416043445118703e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.05; acc: 1.0
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.59; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.88
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.29; acc: 0.86
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.25; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.43; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.4225055312854238e-05
7.940288924146444e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17668536537961596; val_accuracy: 0.9475517515923567 

The current subspace-distance is: 7.940288924146444e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3827107725082897e-05
7.260032816702733e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17692564534628466; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 7.260032816702733e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.98
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.29; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.33964547078358e-05
8.088963113550562e-06
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1765614353167783; val_accuracy: 0.9478503184713376 

The current subspace-distance is: 8.088963113550562e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.3734070055070333e-05
7.473887762898812e-06
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17910151719857173; val_accuracy: 0.947452229299363 

The current subspace-distance is: 7.473887762898812e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.92
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.94
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.317864345968701e-05
7.211195679701632e-06
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1767441486334725; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 7.211195679701632e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.09; acc: 1.0
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.323510307178367e-05
6.857458174636122e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1768771146133447; val_accuracy: 0.9475517515923567 

The current subspace-distance is: 6.857458174636122e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.86
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.89
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.92
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.97
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.94
Batch: 740; loss: 0.1; acc: 0.98
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.310859053977765e-05
7.108911631803494e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1767912261235486; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 7.108911631803494e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.37; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.08; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.347142253711354e-05
6.965762622712646e-06
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17714521606826478; val_accuracy: 0.9465565286624203 

The current subspace-distance is: 6.965762622712646e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.98
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

2.4180151740438305e-05
7.632008419022895e-06
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1771474626555944; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 7.632008419022895e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_350_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 84538
elements in E: 17770400
fraction nonzero: 0.0047572367532526
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.17
Batch: 100; loss: 2.29; acc: 0.06
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.3; acc: 0.03
Batch: 160; loss: 2.28; acc: 0.14
Batch: 180; loss: 2.29; acc: 0.08
Batch: 200; loss: 2.28; acc: 0.14
Batch: 220; loss: 2.26; acc: 0.19
Batch: 240; loss: 2.26; acc: 0.3
Batch: 260; loss: 2.27; acc: 0.3
Batch: 280; loss: 2.25; acc: 0.33
Batch: 300; loss: 2.22; acc: 0.36
Batch: 320; loss: 2.18; acc: 0.36
Batch: 340; loss: 2.1; acc: 0.56
Batch: 360; loss: 1.95; acc: 0.53
Batch: 380; loss: 1.81; acc: 0.47
Batch: 400; loss: 1.43; acc: 0.64
Batch: 420; loss: 1.22; acc: 0.66
Batch: 440; loss: 1.22; acc: 0.69
Batch: 460; loss: 0.69; acc: 0.86
Batch: 480; loss: 0.92; acc: 0.72
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.62; acc: 0.8
Batch: 540; loss: 0.59; acc: 0.78
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.51; acc: 0.8
Batch: 620; loss: 0.57; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.94
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.75; acc: 0.8
Batch: 720; loss: 0.46; acc: 0.89
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.65; acc: 0.81
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 1.43; train_accuracy: 0.53 

1.3744856914854608e-05
7.787296453898307e-06
Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.87; acc: 0.8
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.08; acc: 1.0
Val Epoch over. val_loss: 0.4972311136828866; val_accuracy: 0.841062898089172 

The current subspace-distance is: 7.787296453898307e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.41; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.34; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.47; acc: 0.86
Batch: 200; loss: 0.32; acc: 0.88
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.63; acc: 0.88
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.53; acc: 0.75
Batch: 320; loss: 0.5; acc: 0.86
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.43; acc: 0.88
Batch: 560; loss: 0.32; acc: 0.88
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.39; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.36; acc: 0.83
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

1.9666696971398778e-05
8.691459697729442e-06
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.29455119556492304; val_accuracy: 0.9084394904458599 

The current subspace-distance is: 8.691459697729442e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.84
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.86
Batch: 320; loss: 0.52; acc: 0.77
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.83
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.61; acc: 0.88
Batch: 560; loss: 0.31; acc: 0.86
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.52; acc: 0.84
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.86
Batch: 760; loss: 0.58; acc: 0.88
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

2.076528653560672e-05
9.369030522066168e-06
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.77
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.55; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.88
Batch: 120; loss: 0.91; acc: 0.75
Batch: 140; loss: 0.31; acc: 0.86
Val Epoch over. val_loss: 0.47869595610032417; val_accuracy: 0.8511146496815286 

The current subspace-distance is: 9.369030522066168e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.58; acc: 0.78
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.91
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.25; acc: 0.86
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.35; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.44; acc: 0.84
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

2.2048599930712953e-05
1.0815809218911454e-05
Batch: 0; loss: 0.8; acc: 0.72
Batch: 20; loss: 0.82; acc: 0.77
Batch: 40; loss: 0.74; acc: 0.8
Batch: 60; loss: 1.26; acc: 0.73
Batch: 80; loss: 1.01; acc: 0.77
Batch: 100; loss: 0.79; acc: 0.8
Batch: 120; loss: 1.15; acc: 0.62
Batch: 140; loss: 0.46; acc: 0.88
Val Epoch over. val_loss: 0.8353804526435342; val_accuracy: 0.7727906050955414 

The current subspace-distance is: 1.0815809218911454e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.54; acc: 0.66
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.29; acc: 0.84
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.34; acc: 0.86
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.06; acc: 1.0
Batch: 300; loss: 0.28; acc: 0.88
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.39; acc: 0.89
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.2273941794992425e-05
9.892369234876242e-06
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.35; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.38; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.3750280963292547; val_accuracy: 0.8798765923566879 

The current subspace-distance is: 9.892369234876242e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.88
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.89
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.88
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.54; acc: 0.83
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.2870724933454767e-05
1.0050242963188794e-05
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.4; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.78; acc: 0.81
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.39167050556961897; val_accuracy: 0.8784832802547771 

The current subspace-distance is: 1.0050242963188794e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.89
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.3023307221592404e-05
1.0377728358434979e-05
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2634937871176346; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 1.0377728358434979e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.32; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.88
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.86
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.282158129673917e-05
9.813522410695441e-06
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.78; acc: 0.78
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.93; acc: 0.75
Batch: 80; loss: 0.88; acc: 0.81
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.95; acc: 0.8
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.7026464868882659; val_accuracy: 0.8010549363057324 

The current subspace-distance is: 9.813522410695441e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.86
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.88
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.41; acc: 0.86
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3155678718467243e-05
1.0071567885461263e-05
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.61; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.48; acc: 0.83
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.37291236366530894; val_accuracy: 0.8900278662420382 

The current subspace-distance is: 1.0071567885461263e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.91
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.28; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.89
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.91
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.65; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.3884244001237676e-05
1.1043527592846658e-05
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2557165661150483; val_accuracy: 0.9211783439490446 

The current subspace-distance is: 1.1043527592846658e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.27; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.358821984671522e-05
1.0570761332928669e-05
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.91
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17982907861376266; val_accuracy: 0.9468550955414012 

The current subspace-distance is: 1.0570761332928669e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.06; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.4121374735841528e-05
1.1173646271345206e-05
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17549564143654647; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 1.1173646271345206e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.86
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.39952678384725e-05
1.0559495422057807e-05
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19061383064005785; val_accuracy: 0.9437699044585988 

The current subspace-distance is: 1.0559495422057807e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.36; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.417227551632095e-05
1.1205667760805227e-05
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1813070434293929; val_accuracy: 0.946656050955414 

The current subspace-distance is: 1.1205667760805227e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.05; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.29; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.4116008717101067e-05
1.1005084161297418e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1695077265523801; val_accuracy: 0.9506369426751592 

The current subspace-distance is: 1.1005084161297418e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.92
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.33; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.26; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.14; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.4066972400760278e-05
1.0638746061886195e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18127537001470093; val_accuracy: 0.9476512738853503 

The current subspace-distance is: 1.0638746061886195e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.05; acc: 1.0
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.3567114112665877e-05
1.0169065717491321e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.19008473437398102; val_accuracy: 0.9436703821656051 

The current subspace-distance is: 1.0169065717491321e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.4456221581203863e-05
1.0955084690067451e-05
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18417404100868354; val_accuracy: 0.9464570063694268 

The current subspace-distance is: 1.0955084690067451e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.36; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.89
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.33; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.23; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.4033237423282117e-05
1.0679349543352146e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17071100677938977; val_accuracy: 0.9508359872611465 

The current subspace-distance is: 1.0679349543352146e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.14; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.36; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.05; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.88
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.86
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.27; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.3855551262386143e-05
1.082396374840755e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1666898805244713; val_accuracy: 0.9506369426751592 

The current subspace-distance is: 1.082396374840755e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.04; acc: 1.0
Batch: 80; loss: 0.21; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.94
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.98
Batch: 340; loss: 0.36; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4104607291519642e-05
1.1149901183671318e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.171547510536613; val_accuracy: 0.9501393312101911 

The current subspace-distance is: 1.1149901183671318e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.02; acc: 1.0
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.03; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3413746021105908e-05
9.763960406417027e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16880331681981967; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 9.763960406417027e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.98
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.2; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.1; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.404215047135949e-05
1.048936064762529e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17360172942755328; val_accuracy: 0.9469546178343949 

The current subspace-distance is: 1.048936064762529e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.07; acc: 1.0
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.02; acc: 1.0
Batch: 480; loss: 0.15; acc: 0.98
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.12; acc: 0.92
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.91
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.18; acc: 0.95
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.429970663797576e-05
1.0963720342260785e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1651302595284714; val_accuracy: 0.9522292993630573 

The current subspace-distance is: 1.0963720342260785e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.1; acc: 0.98
Batch: 280; loss: 0.19; acc: 0.92
Batch: 300; loss: 0.33; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.91
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.412364301562775e-05
1.0840403774636798e-05
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16791824775801342; val_accuracy: 0.9508359872611465 

The current subspace-distance is: 1.0840403774636798e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.92
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.98
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.25; acc: 0.91
Batch: 200; loss: 0.14; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.12; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3885977498139255e-05
1.0779147487482987e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16465555613113056; val_accuracy: 0.95203025477707 

The current subspace-distance is: 1.0779147487482987e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.26; acc: 0.88
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.34; acc: 0.92
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.26; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.89
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4660890630912036e-05
1.1026884749298915e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1723658932954263; val_accuracy: 0.947452229299363 

The current subspace-distance is: 1.1026884749298915e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.03; acc: 1.0
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.45; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4760522137512453e-05
1.1453740626166109e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1633220174747288; val_accuracy: 0.9503383757961783 

The current subspace-distance is: 1.1453740626166109e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.385743209742941e-05
1.0802545148180798e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16645782303278614; val_accuracy: 0.9507364649681529 

The current subspace-distance is: 1.0802545148180798e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.29; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.06; acc: 1.0
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.13; acc: 0.98
Batch: 440; loss: 0.29; acc: 0.89
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.49; acc: 0.91
Batch: 540; loss: 0.12; acc: 0.98
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.98
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4086992198135704e-05
1.0814615052368026e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.33; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16590382322479205; val_accuracy: 0.9513335987261147 

The current subspace-distance is: 1.0814615052368026e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.88
Batch: 100; loss: 0.03; acc: 1.0
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.94
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.91
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.38; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4260740246973e-05
1.057418376149144e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1616785665321502; val_accuracy: 0.9517316878980892 

The current subspace-distance is: 1.057418376149144e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.95
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.15; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.08; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.500468326616101e-05
1.1413074389565736e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16186237214192464; val_accuracy: 0.9517316878980892 

The current subspace-distance is: 1.1413074389565736e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.23; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.88
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.06; acc: 1.0
Batch: 700; loss: 0.24; acc: 0.97
Batch: 720; loss: 0.03; acc: 1.0
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.94
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4285080144181848e-05
1.1518512110342272e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1612257194367184; val_accuracy: 0.9517316878980892 

The current subspace-distance is: 1.1518512110342272e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.05; acc: 1.0
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.08; acc: 1.0
Batch: 580; loss: 0.4; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.03; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4211387426475994e-05
1.0943784218397923e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16189429080884926; val_accuracy: 0.9517316878980892 

The current subspace-distance is: 1.0943784218397923e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.28; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.88
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.07; acc: 1.0
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4644044970045798e-05
1.1198198990314268e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16222183949723365; val_accuracy: 0.9514331210191083 

The current subspace-distance is: 1.1198198990314268e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.95
Batch: 260; loss: 0.09; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.35; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.07; acc: 1.0
Batch: 760; loss: 0.05; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.397814932919573e-05
1.0716005817812402e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1636780456752534; val_accuracy: 0.948546974522293 

The current subspace-distance is: 1.0716005817812402e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4404887881246395e-05
1.0651160664565396e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16343967792145006; val_accuracy: 0.9500398089171974 

The current subspace-distance is: 1.0651160664565396e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.92
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.55; acc: 0.88
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.03; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.06; acc: 1.0
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.92
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4265882530016825e-05
1.0599023880786262e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16211032112882395; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 1.0599023880786262e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.92
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.98
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.4724438844714314e-05
1.0953050150419585e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1626152965435936; val_accuracy: 0.9505374203821656 

The current subspace-distance is: 1.0953050150419585e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.89
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.03; acc: 1.0
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3967311790329404e-05
1.054723634297261e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16286379841577475; val_accuracy: 0.9526273885350318 

The current subspace-distance is: 1.054723634297261e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4430461053270847e-05
1.070174857886741e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16090471278520146; val_accuracy: 0.9526273885350318 

The current subspace-distance is: 1.070174857886741e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.03; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.2; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.45; acc: 0.94
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.36; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4305973056470975e-05
1.1430698577896692e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1609733140297756; val_accuracy: 0.9526273885350318 

The current subspace-distance is: 1.1430698577896692e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.12; acc: 0.98
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.91
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.29; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4141401809174567e-05
1.081422669813037e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16125076686500744; val_accuracy: 0.9523288216560509 

The current subspace-distance is: 1.081422669813037e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.98
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.443486482661683e-05
1.0954558092635125e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1617861865384943; val_accuracy: 0.9518312101910829 

The current subspace-distance is: 1.0954558092635125e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.1; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.02; acc: 1.0
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.04; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.506316923245322e-05
1.0434494470246136e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1622820697772275; val_accuracy: 0.9517316878980892 

The current subspace-distance is: 1.0434494470246136e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.91
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.1; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.98
Batch: 720; loss: 0.21; acc: 0.89
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4079257855191827e-05
1.0734069292084314e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1613885220021579; val_accuracy: 0.9529259554140127 

The current subspace-distance is: 1.0734069292084314e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.97
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.07; acc: 1.0
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4622193450341e-05
1.1064003047067672e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1614751907623118; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 1.1064003047067672e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.48; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.88
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.06; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4212557036662474e-05
1.0993093383149244e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.1612275350530436; val_accuracy: 0.95203025477707 

The current subspace-distance is: 1.0993093383149244e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.91
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.06; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.89
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.430066524539143e-05
1.0448123248352204e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16135060293659284; val_accuracy: 0.9525278662420382 

The current subspace-distance is: 1.0448123248352204e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.98
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.95
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.4694900275790133e-05
1.1155756510561332e-05
Batch: 0; loss: 0.02; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.0; acc: 1.0
Val Epoch over. val_loss: 0.16100885609912266; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 1.1155756510561332e-05 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 94784
elements in E: 19991700
fraction nonzero: 0.0047411675845475875
Epoch 1 start
The current lr is: 1.0
/home/llang/thesis-intrinsic-dimension/logging_helper.py:44: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax1 = plt.subplots()
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.08
Batch: 60; loss: 2.29; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.2
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.11
Batch: 160; loss: 2.27; acc: 0.2
Batch: 180; loss: 2.28; acc: 0.23
Batch: 200; loss: 2.27; acc: 0.23
Batch: 220; loss: 2.25; acc: 0.41
Batch: 240; loss: 2.23; acc: 0.42
Batch: 260; loss: 2.23; acc: 0.33
Batch: 280; loss: 2.18; acc: 0.48
Batch: 300; loss: 2.14; acc: 0.38
Batch: 320; loss: 1.94; acc: 0.58
Batch: 340; loss: 1.68; acc: 0.59
Batch: 360; loss: 1.13; acc: 0.7
Batch: 380; loss: 1.08; acc: 0.67
Batch: 400; loss: 0.67; acc: 0.8
Batch: 420; loss: 0.88; acc: 0.7
Batch: 440; loss: 0.5; acc: 0.89
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.97; acc: 0.62
Batch: 500; loss: 0.6; acc: 0.84
Batch: 520; loss: 0.57; acc: 0.83
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.77; acc: 0.75
Batch: 620; loss: 0.7; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.86
Batch: 660; loss: 0.38; acc: 0.89
Batch: 680; loss: 0.66; acc: 0.8
Batch: 700; loss: 0.5; acc: 0.78
Batch: 720; loss: 0.55; acc: 0.86
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.68; acc: 0.81
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.407852687407285e-05
8.02943941380363e-06
Batch: 0; loss: 0.46; acc: 0.91
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.4055200489653144; val_accuracy: 0.8751990445859873 

The current subspace-distance is: 8.02943941380363e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.84
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.67; acc: 0.83
Batch: 340; loss: 0.33; acc: 0.95
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.39; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.88
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.61; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.83
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

1.9083572624367662e-05
8.906892617233098e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.29080921990476594; val_accuracy: 0.9095342356687898 

The current subspace-distance is: 8.906892617233098e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.88
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.66; acc: 0.77
Batch: 240; loss: 0.26; acc: 0.91
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.53; acc: 0.88
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.3; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.92
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.36; acc: 0.84
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.0464973204070702e-05
9.0593548520701e-06
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.89; acc: 0.77
Batch: 40; loss: 0.41; acc: 0.91
Batch: 60; loss: 0.8; acc: 0.83
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.65; acc: 0.84
Batch: 120; loss: 1.06; acc: 0.77
Batch: 140; loss: 0.27; acc: 0.92
Val Epoch over. val_loss: 0.5895259323393464; val_accuracy: 0.8441480891719745 

The current subspace-distance is: 9.0593548520701e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.8
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.32; acc: 0.91
Batch: 60; loss: 0.42; acc: 0.84
Batch: 80; loss: 0.43; acc: 0.91
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.92
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.5; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.88
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.84
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.38; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.48; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.31; acc: 0.94
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.35; acc: 0.91
Batch: 760; loss: 0.29; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.84
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.120966018992476e-05
9.488637260801625e-06
Batch: 0; loss: 0.92; acc: 0.62
Batch: 20; loss: 0.97; acc: 0.73
Batch: 40; loss: 1.13; acc: 0.73
Batch: 60; loss: 1.77; acc: 0.72
Batch: 80; loss: 0.88; acc: 0.78
Batch: 100; loss: 1.29; acc: 0.73
Batch: 120; loss: 1.49; acc: 0.64
Batch: 140; loss: 0.62; acc: 0.83
Val Epoch over. val_loss: 1.0741768137664551; val_accuracy: 0.7308917197452229 

The current subspace-distance is: 9.488637260801625e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.31; acc: 0.59
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.33; acc: 0.84
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.2; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.39; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.43; acc: 0.86
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.1381036276579835e-05
9.082072210730985e-06
Batch: 0; loss: 0.67; acc: 0.8
Batch: 20; loss: 1.43; acc: 0.64
Batch: 40; loss: 0.49; acc: 0.84
Batch: 60; loss: 1.0; acc: 0.69
Batch: 80; loss: 1.14; acc: 0.75
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 1.44; acc: 0.7
Batch: 140; loss: 0.83; acc: 0.81
Val Epoch over. val_loss: 0.9573295119271916; val_accuracy: 0.7361664012738853 

The current subspace-distance is: 9.082072210730985e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.1; acc: 0.67
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.39; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.24; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.37; acc: 0.88
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.34; acc: 0.84
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.51; acc: 0.86
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

2.1633130018017255e-05
9.73805072135292e-06
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.83; acc: 0.83
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.2762721389721913; val_accuracy: 0.9196855095541401 

The current subspace-distance is: 9.73805072135292e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.35; acc: 0.84
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.2061138224671595e-05
9.324963684775867e-06
Batch: 0; loss: 0.08; acc: 1.0
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.52; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.2381011846528691; val_accuracy: 0.927547770700637 

The current subspace-distance is: 9.324963684775867e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.3; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.25; acc: 0.91
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.91
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.46; acc: 0.84
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.2323467419482768e-05
9.665021025284659e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.6; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.23975627378198752; val_accuracy: 0.9260549363057324 

The current subspace-distance is: 9.665021025284659e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.97
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.5; acc: 0.91
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.21; acc: 0.89
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.84
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

2.243610651930794e-05
9.421827598998789e-06
Batch: 0; loss: 0.43; acc: 0.86
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.61; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3917086973881266; val_accuracy: 0.8805732484076433 

The current subspace-distance is: 9.421827598998789e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.84
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.97
Batch: 280; loss: 0.23; acc: 0.97
Batch: 300; loss: 0.08; acc: 1.0
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.28; acc: 0.88
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.89
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.48; acc: 0.89
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.2976841137278825e-05
9.700424016045872e-06
Batch: 0; loss: 0.17; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25869263817740096; val_accuracy: 0.9186902866242038 

The current subspace-distance is: 9.700424016045872e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.16; acc: 0.98
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.04; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

2.2928235921426676e-05
9.702460374683142e-06
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.18379844252945512; val_accuracy: 0.9457603503184714 

The current subspace-distance is: 9.702460374683142e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.91
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.2; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.276592203998007e-05
9.707173376227729e-06
Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1778737767629183; val_accuracy: 0.9454617834394905 

The current subspace-distance is: 9.707173376227729e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.98
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.18; acc: 0.92
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.09; acc: 1.0
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.39; acc: 0.88
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.314874654985033e-05
1.01112918855506e-05
Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.17075902425274728; val_accuracy: 0.9487460191082803 

The current subspace-distance is: 1.01112918855506e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.34; acc: 0.95
Batch: 80; loss: 0.5; acc: 0.91
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.92
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.07; acc: 0.95
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.2; acc: 0.89
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.3370812414214015e-05
1.0222160199191421e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.22343404607693101; val_accuracy: 0.9308320063694268 

The current subspace-distance is: 1.0222160199191421e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.07; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.23; acc: 0.89
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.33; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.3370042981696315e-05
9.855903954303358e-06
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.16946848121228492; val_accuracy: 0.9495421974522293 

The current subspace-distance is: 9.855903954303358e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.35; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.38; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.97
Batch: 540; loss: 0.3; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.27; acc: 0.89
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.34; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.3536656954092905e-05
1.0437993296363857e-05
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17537116845417175; val_accuracy: 0.9487460191082803 

The current subspace-distance is: 1.0437993296363857e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.4; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.92
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.48; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.1; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.3728114683763124e-05
1.0057603503810242e-05
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.20803212820534495; val_accuracy: 0.9375 

The current subspace-distance is: 1.0057603503810242e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.09; acc: 0.98
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.28; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.25; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.94
Batch: 540; loss: 0.21; acc: 0.97
Batch: 560; loss: 0.12; acc: 0.94
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.3476846763514914e-05
1.0577998182270676e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.05; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.17330373750086042; val_accuracy: 0.9490445859872612 

The current subspace-distance is: 1.0577998182270676e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

2.371367190789897e-05
1.021526531985728e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1674061182435531; val_accuracy: 0.9503383757961783 

The current subspace-distance is: 1.021526531985728e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.29; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.31; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3559006876894273e-05
1.0162789294554386e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16961894179605375; val_accuracy: 0.9488455414012739 

The current subspace-distance is: 1.0162789294554386e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.07; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.36; acc: 0.88
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3216334739117883e-05
9.728641089168377e-06
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16008546435908907; val_accuracy: 0.9536226114649682 

The current subspace-distance is: 9.728641089168377e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.08; acc: 1.0
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.92
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.09; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.98
Batch: 760; loss: 0.36; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3896864149719477e-05
1.0340935659769457e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16604917154760118; val_accuracy: 0.9514331210191083 

The current subspace-distance is: 1.0340935659769457e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.07; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.05; acc: 1.0
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.08; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.1; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3649212380405515e-05
9.941863936546724e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.02; acc: 0.98
Val Epoch over. val_loss: 0.16719756576760558; val_accuracy: 0.9499402866242038 

The current subspace-distance is: 9.941863936546724e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.25; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.28; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.95
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.16; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3815231543267146e-05
1.088098724721931e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16118097094118974; val_accuracy: 0.9536226114649682 

The current subspace-distance is: 1.088098724721931e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.88
Batch: 180; loss: 0.04; acc: 1.0
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.97
Batch: 300; loss: 0.42; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3776945454301313e-05
1.0625387403706554e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1589196303942401; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.0625387403706554e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.06; acc: 1.0
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.92
Batch: 400; loss: 0.1; acc: 0.98
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3470702217309736e-05
9.99154508463107e-06
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15805469685868853; val_accuracy: 0.9538216560509554 

The current subspace-distance is: 9.99154508463107e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.98
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3537048036814667e-05
9.612397661840077e-06
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1614781475750504; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 9.612397661840077e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.39; acc: 0.89
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.04; acc: 0.98
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.98
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.91
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.326097819604911e-05
1.0711815775721334e-05
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16006474232502804; val_accuracy: 0.9528264331210191 

The current subspace-distance is: 1.0711815775721334e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.89
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.91
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3963249986991286e-05
1.0784677215269767e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.36; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1691516750272672; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 1.0784677215269767e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.36; acc: 0.89
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.54; acc: 0.91
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.35; acc: 0.91
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3823844458092935e-05
1.0105294677487109e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1605265788781415; val_accuracy: 0.9540207006369427 

The current subspace-distance is: 1.0105294677487109e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.09; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3670711016166024e-05
1.0661317901394796e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15824368354051735; val_accuracy: 0.9541202229299363 

The current subspace-distance is: 1.0661317901394796e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.05; acc: 0.97
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.11; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.05; acc: 1.0
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.38; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3949731257744133e-05
1.0757637028291356e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15912337546610528; val_accuracy: 0.9530254777070064 

The current subspace-distance is: 1.0757637028291356e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.04; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.94
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.08; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.94
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.326705725863576e-05
9.712270184536465e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15941685217486065; val_accuracy: 0.9536226114649682 

The current subspace-distance is: 9.712270184536465e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.98
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.89
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3735527065582573e-05
9.76438241195865e-06
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15820955852888952; val_accuracy: 0.9541202229299363 

The current subspace-distance is: 9.76438241195865e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.97
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.98
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.98
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.92
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.383846185693983e-05
9.832045179791749e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15992962243925235; val_accuracy: 0.9538216560509554 

The current subspace-distance is: 9.832045179791749e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.396827403572388e-05
1.0630777978803962e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1585930800836557; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 1.0630777978803962e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.25; acc: 0.97
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.15; acc: 0.98
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.98
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.361803490202874e-05
1.0593696970317978e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1581763368645671; val_accuracy: 0.9551154458598726 

The current subspace-distance is: 1.0593696970317978e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.03; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.48; acc: 0.89
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.06; acc: 1.0
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.34; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3511787730967626e-05
9.719038644107059e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15908350693477188; val_accuracy: 0.9529259554140127 

The current subspace-distance is: 9.719038644107059e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.05; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.356403274461627e-05
1.001876898953924e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15853577240067682; val_accuracy: 0.9534235668789809 

The current subspace-distance is: 1.001876898953924e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.26; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.07; acc: 1.0
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.92
Batch: 540; loss: 0.06; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3384987798635848e-05
9.772484190762043e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15824800677550066; val_accuracy: 0.9532245222929936 

The current subspace-distance is: 9.772484190762043e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.03; acc: 1.0
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.92
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.32; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.06; acc: 0.97
Batch: 700; loss: 0.05; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.3690892703598365e-05
1.0499566997168586e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15740374554019826; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.0499566997168586e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.92
Batch: 160; loss: 0.02; acc: 1.0
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.42; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.27; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.16; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.08; acc: 1.0
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.21; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.4110273443511687e-05
1.092450474970974e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15705492546793762; val_accuracy: 0.9552149681528662 

The current subspace-distance is: 1.092450474970974e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.23; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.2; acc: 0.91
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.4071627194643952e-05
1.0632409612298943e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15682484883411674; val_accuracy: 0.9551154458598726 

The current subspace-distance is: 1.0632409612298943e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.06; acc: 0.95
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.45; acc: 0.94
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.4145849238266237e-05
1.05305080069229e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15757309427117086; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 1.05305080069229e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.05; acc: 1.0
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.02; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.88
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.3810895072529092e-05
1.0738090168160852e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.84
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1580819650345547; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.0738090168160852e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.98
Batch: 80; loss: 0.05; acc: 1.0
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.39; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.92
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.12; acc: 0.95
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.349901114939712e-05
9.927035534929018e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15785874172475686; val_accuracy: 0.95421974522293 

The current subspace-distance is: 9.927035534929018e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.05; acc: 1.0
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.03; acc: 1.0
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.91
Batch: 760; loss: 0.25; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.357593984925188e-05
1.0291647413396277e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15719111218668852; val_accuracy: 0.9545183121019108 

The current subspace-distance is: 1.0291647413396277e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.09; acc: 1.0
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.11; acc: 0.94
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.350303293496836e-05
1.0191081855737139e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15724353743776395; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.0191081855737139e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.27; acc: 0.94
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.08; acc: 1.0
Batch: 300; loss: 0.33; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.08; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.97
Batch: 640; loss: 0.05; acc: 0.98
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.95 

2.401170968369115e-05
1.0529175597184803e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15756786598046874; val_accuracy: 0.9543192675159236 

The current subspace-distance is: 1.0529175597184803e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.98
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.39; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.04; acc: 0.98
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.29; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.11; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.3517091904068366e-05
9.643406883697025e-06
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1572086089735578; val_accuracy: 0.955015923566879 

The current subspace-distance is: 9.643406883697025e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_450_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 105069
elements in E: 22213000
fraction nonzero: 0.004730067978210958
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.08
Batch: 20; loss: 2.32; acc: 0.05
Batch: 40; loss: 2.29; acc: 0.09
Batch: 60; loss: 2.29; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.25
Batch: 100; loss: 2.28; acc: 0.23
Batch: 120; loss: 2.28; acc: 0.14
Batch: 140; loss: 2.27; acc: 0.14
Batch: 160; loss: 2.25; acc: 0.3
Batch: 180; loss: 2.26; acc: 0.2
Batch: 200; loss: 2.22; acc: 0.31
Batch: 220; loss: 2.18; acc: 0.45
Batch: 240; loss: 2.11; acc: 0.33
Batch: 260; loss: 2.02; acc: 0.36
Batch: 280; loss: 1.7; acc: 0.53
Batch: 300; loss: 1.34; acc: 0.58
Batch: 320; loss: 0.8; acc: 0.73
Batch: 340; loss: 0.85; acc: 0.81
Batch: 360; loss: 0.62; acc: 0.8
Batch: 380; loss: 0.73; acc: 0.78
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.57; acc: 0.81
Batch: 440; loss: 0.45; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.61; acc: 0.8
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.58; acc: 0.77
Batch: 540; loss: 0.38; acc: 0.92
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.89
Batch: 600; loss: 0.46; acc: 0.81
Batch: 620; loss: 0.64; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.59; acc: 0.77
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.45; acc: 0.89
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.62; acc: 0.8
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 1.14; train_accuracy: 0.63 

1.4011336133989971e-05
7.238943908305373e-06
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.36887757736406507; val_accuracy: 0.8914211783439491 

The current subspace-distance is: 7.238943908305373e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.37; acc: 0.84
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.44; acc: 0.86
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.92
Batch: 300; loss: 0.41; acc: 0.84
Batch: 320; loss: 0.69; acc: 0.88
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.95
Batch: 480; loss: 0.3; acc: 0.88
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.38; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

1.9018445527763106e-05
8.219296432798728e-06
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.2710741374428105; val_accuracy: 0.9142117834394905 

The current subspace-distance is: 8.219296432798728e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.42; acc: 0.86
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.66; acc: 0.83
Batch: 320; loss: 0.48; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.88
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.48; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.89
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.33; acc: 0.94
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

2.047079397016205e-05
8.519489711034112e-06
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.88
Batch: 120; loss: 1.12; acc: 0.73
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4474025969007972; val_accuracy: 0.8623606687898089 

The current subspace-distance is: 8.519489711034112e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.1; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.51; acc: 0.86
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.89
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.97
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

2.158957977371756e-05
9.262017556466162e-06
Batch: 0; loss: 1.22; acc: 0.67
Batch: 20; loss: 0.91; acc: 0.81
Batch: 40; loss: 1.38; acc: 0.8
Batch: 60; loss: 1.68; acc: 0.75
Batch: 80; loss: 0.96; acc: 0.84
Batch: 100; loss: 1.14; acc: 0.78
Batch: 120; loss: 2.19; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.84
Val Epoch over. val_loss: 1.1767822905520724; val_accuracy: 0.769406847133758 

The current subspace-distance is: 9.262017556466162e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.26; acc: 0.77
Batch: 20; loss: 0.31; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.14; acc: 0.98
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.37; acc: 0.83
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.46; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

2.1814201318193227e-05
8.72487453307258e-06
Batch: 0; loss: 0.48; acc: 0.8
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.64; acc: 0.78
Batch: 80; loss: 0.63; acc: 0.86
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 1.0; acc: 0.77
Batch: 140; loss: 0.25; acc: 0.91
Val Epoch over. val_loss: 0.5029755017844735; val_accuracy: 0.8474323248407644 

The current subspace-distance is: 8.72487453307258e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.88
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.19; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.33; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.98
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

2.210481216025073e-05
8.510351108270697e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.92
Batch: 100; loss: 0.28; acc: 0.95
Batch: 120; loss: 0.87; acc: 0.8
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2827597508432379; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 8.510351108270697e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.11; acc: 0.97
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.97
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.2255648218560964e-05
9.135365871770773e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.3128562883301905; val_accuracy: 0.9068471337579618 

The current subspace-distance is: 9.135365871770773e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.19; acc: 0.89
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.92
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.11; acc: 0.94
Batch: 620; loss: 0.06; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.92
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.33; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.271264384035021e-05
9.323538506578188e-06
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2197926004126573; val_accuracy: 0.9320262738853503 

The current subspace-distance is: 9.323538506578188e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.97
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.91
Batch: 160; loss: 0.32; acc: 0.95
Batch: 180; loss: 0.43; acc: 0.91
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.49; acc: 0.92
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.46; acc: 0.89
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.23; acc: 0.89
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

2.3154283553594723e-05
9.258445061277598e-06
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.33666782721782185; val_accuracy: 0.9012738853503185 

The current subspace-distance is: 9.258445061277598e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.33; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.92
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.89
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.42; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.43; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

2.3589347620145418e-05
1.0175742318097036e-05
Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.73; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.94
Batch: 100; loss: 0.68; acc: 0.83
Batch: 120; loss: 1.39; acc: 0.69
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.4864235658222323; val_accuracy: 0.8594745222929936 

The current subspace-distance is: 1.0175742318097036e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.81
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.16; acc: 0.95
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.26; acc: 0.89
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.320074418094009e-05
9.232312550011557e-06
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15925364967459327; val_accuracy: 0.9545183121019108 

The current subspace-distance is: 9.232312550011557e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.21; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.02; acc: 1.0
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.04; acc: 1.0
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.95
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.317156940989662e-05
9.425792086403817e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.23; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.15517971909065156; val_accuracy: 0.9540207006369427 

The current subspace-distance is: 9.425792086403817e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.13; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.98
Batch: 260; loss: 0.36; acc: 0.86
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.41; acc: 0.89
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.34; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.25; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.313830736966338e-05
9.045054866874125e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15869455953027792; val_accuracy: 0.9529259554140127 

The current subspace-distance is: 9.045054866874125e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.88
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.95
Batch: 460; loss: 0.49; acc: 0.86
Batch: 480; loss: 0.21; acc: 0.98
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3747454179101624e-05
9.392409992869943e-06
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1753467721449342; val_accuracy: 0.9461584394904459 

The current subspace-distance is: 9.392409992869943e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.18; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.05; acc: 1.0
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.04; acc: 0.98
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3615046302438714e-05
9.368925930175465e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.16835635354754272; val_accuracy: 0.951234076433121 

The current subspace-distance is: 9.368925930175465e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.25; acc: 0.95
Batch: 180; loss: 0.33; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.33; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.97
Batch: 680; loss: 0.03; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.3; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3599868654855527e-05
9.336753464594949e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19655371063454136; val_accuracy: 0.9407842356687898 

The current subspace-distance is: 9.336753464594949e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.5; acc: 0.88
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.1; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.05; acc: 0.97
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.32; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.94
Batch: 540; loss: 0.02; acc: 1.0
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.15; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

2.3438562493538484e-05
8.825627446640283e-06
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18085050302895772; val_accuracy: 0.9463574840764332 

The current subspace-distance is: 8.825627446640283e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.02; acc: 1.0
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.03; acc: 0.98
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.06; acc: 1.0
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.12; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.353623858653009e-05
9.532266631140374e-06
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.23065861352499883; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 9.532266631140374e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.04; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.08; acc: 0.98
Batch: 400; loss: 0.17; acc: 0.94
Batch: 420; loss: 0.04; acc: 1.0
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.98
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.07; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.88
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.357514858886134e-05
9.248403330275323e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15270681952120393; val_accuracy: 0.9557125796178344 

The current subspace-distance is: 9.248403330275323e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.03; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.33; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.04; acc: 1.0
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.97
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

2.3741580662317574e-05
9.628828593122307e-06
Batch: 0; loss: 0.05; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1502306184666172; val_accuracy: 0.9545183121019108 

The current subspace-distance is: 9.628828593122307e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.06; acc: 1.0
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.98
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.13; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.92
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.365775617363397e-05
9.614606824470684e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14501460302312663; val_accuracy: 0.9565087579617835 

The current subspace-distance is: 9.614606824470684e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.92
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.94
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.374324139964301e-05
9.62023750616936e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14749874637290172; val_accuracy: 0.9551154458598726 

The current subspace-distance is: 9.62023750616936e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.89
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.1; acc: 0.95
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.07; acc: 0.95
Batch: 180; loss: 0.15; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.18; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.88
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.91
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.04; acc: 1.0
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.05; acc: 1.0
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.16; acc: 0.94
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.3851227524573915e-05
9.704396688903216e-06
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17086436141543326; val_accuracy: 0.9490445859872612 

The current subspace-distance is: 9.704396688903216e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.04; acc: 1.0
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.1; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.04; acc: 0.98
Batch: 780; loss: 0.44; acc: 0.94
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.3886366761871614e-05
9.979913556890097e-06
Batch: 0; loss: 0.04; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.148718530656236; val_accuracy: 0.9557125796178344 

The current subspace-distance is: 9.979913556890097e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.94
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.16; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.381477133894805e-05
9.66544757829979e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.147635909663454; val_accuracy: 0.9562101910828026 

The current subspace-distance is: 9.66544757829979e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.04; acc: 0.98
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.03; acc: 1.0
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.06; acc: 1.0
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.98
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.398807009740267e-05
9.556171789881773e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14559106917897607; val_accuracy: 0.9566082802547771 

The current subspace-distance is: 9.556171789881773e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.03; acc: 1.0
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.03; acc: 1.0
Batch: 240; loss: 0.12; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.98
Batch: 320; loss: 0.41; acc: 0.89
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.4; acc: 0.94
Batch: 440; loss: 0.3; acc: 0.95
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.15; acc: 0.98
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.377821692789439e-05
9.711489838082343e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15088939348793334; val_accuracy: 0.955015923566879 

The current subspace-distance is: 9.711489838082343e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.02; acc: 1.0
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.09; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.04; acc: 0.98
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.03; acc: 0.98
Batch: 560; loss: 0.25; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.04; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.4185514121199958e-05
9.622916877560783e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14490067735788928; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 9.622916877560783e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.97
Batch: 20; loss: 0.35; acc: 0.95
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.92
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.05; acc: 1.0
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.89
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.04; acc: 1.0
Batch: 760; loss: 0.03; acc: 1.0
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.3771928681526333e-05
9.588543434801977e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15041486183359365; val_accuracy: 0.9548168789808917 

The current subspace-distance is: 9.588543434801977e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.07; acc: 1.0
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.05; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.37; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.3628765120520256e-05
9.225846952176653e-06
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14336039738100806; val_accuracy: 0.9583001592356688 

The current subspace-distance is: 9.225846952176653e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.02; acc: 1.0
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.03; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.07; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.401071833446622e-05
9.75818602455547e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14435815058980778; val_accuracy: 0.9563097133757962 

The current subspace-distance is: 9.75818602455547e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.95
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.18; acc: 0.98
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.04; acc: 0.98
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.08; acc: 0.98
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.02; acc: 1.0
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.396232775936369e-05
9.68296080827713e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.35; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14307816210351174; val_accuracy: 0.957703025477707 

The current subspace-distance is: 9.68296080827713e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.14; acc: 0.98
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.03; acc: 0.98
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.94
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.05; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.05; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.41057659877697e-05
9.837748621066567e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14349075394925798; val_accuracy: 0.956906847133758 

The current subspace-distance is: 9.837748621066567e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.11; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.07; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.98
Batch: 580; loss: 0.47; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.98
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.89
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.97
Batch: 780; loss: 0.03; acc: 0.98
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.3635120669496246e-05
9.487859642831609e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14332813878727566; val_accuracy: 0.9574044585987261 

The current subspace-distance is: 9.487859642831609e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.97
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.1; acc: 0.94
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.08; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.18; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.03; acc: 0.98
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.07; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.2; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.97
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.4215851226472296e-05
9.354654139315244e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14270131577067313; val_accuracy: 0.9585987261146497 

The current subspace-distance is: 9.354654139315244e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.06; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.89
Batch: 220; loss: 0.06; acc: 0.98
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.27; acc: 0.97
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.92
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.23; acc: 0.89
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.4132468752213754e-05
1.0233309694740456e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14283820357956703; val_accuracy: 0.9584992038216561 

The current subspace-distance is: 1.0233309694740456e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.4103548639686778e-05
9.924760888679884e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14322065597601757; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 9.924760888679884e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.92
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.03; acc: 0.98
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.02; acc: 1.0
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.05; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.14; train_accuracy: 0.96 

2.4067991034826264e-05
9.394291737407912e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14224288401425264; val_accuracy: 0.9584992038216561 

The current subspace-distance is: 9.394291737407912e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.05; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.13; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.22; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.4217446480179206e-05
9.340517863165587e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1460905463262728; val_accuracy: 0.9573049363057324 

The current subspace-distance is: 9.340517863165587e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.05; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.22; acc: 0.88
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.3968796085682698e-05
9.898201824398711e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14330212373262757; val_accuracy: 0.9579020700636943 

The current subspace-distance is: 9.898201824398711e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.11; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.15; acc: 0.94
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.09; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.97
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.97
Batch: 720; loss: 0.05; acc: 0.97
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.3886070266598836e-05
9.368643986817915e-06
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14197827877986963; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.368643986817915e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.21; acc: 0.92
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.09; acc: 0.95
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.44; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.97
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.09; acc: 0.97
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.32; acc: 0.86
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.411885179753881e-05
9.572613635100424e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14187722733825636; val_accuracy: 0.9581011146496815 

The current subspace-distance is: 9.572613635100424e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.21; acc: 0.98
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.03; acc: 1.0
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.95
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.12; acc: 0.95
Batch: 680; loss: 0.03; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.91
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.4005426894291304e-05
1.0334113540011458e-05
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1422077437067867; val_accuracy: 0.9583996815286624 

The current subspace-distance is: 1.0334113540011458e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.13; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.04; acc: 1.0
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.98
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.403904545644764e-05
9.590377885615453e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14187328064232874; val_accuracy: 0.9590963375796179 

The current subspace-distance is: 9.590377885615453e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.36; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.04; acc: 0.98
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.3; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.98
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.03; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.19; acc: 0.97
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.04; acc: 1.0
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.03; acc: 0.98
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.412579306110274e-05
9.69140455708839e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14242629851600166; val_accuracy: 0.9576035031847133 

The current subspace-distance is: 9.69140455708839e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.04; acc: 0.98
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.14; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.06; acc: 0.98
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.03; acc: 1.0
Batch: 600; loss: 0.04; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.1; acc: 0.94
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.409946137049701e-05
9.738831067807041e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1426532889959539; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.738831067807041e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.05; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.03; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.07; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.19; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.05; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.09; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.95
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.04; acc: 0.98
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.4361561372643337e-05
9.659558600105811e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14256280314201003; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.659558600105811e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.38; acc: 0.92
Batch: 80; loss: 0.04; acc: 1.0
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.05; acc: 0.97
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.04; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.12; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.09; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.04; acc: 0.98
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.413518086541444e-05
9.086534191737883e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14233211558430817; val_accuracy: 0.9580015923566879 

The current subspace-distance is: 9.086534191737883e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.06; acc: 0.97
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.05; acc: 1.0
Batch: 300; loss: 0.18; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.05; acc: 1.0
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.03; acc: 1.0
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.95
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.95
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.424503145448398e-05
1.0020055015047546e-05
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14261169781445698; val_accuracy: 0.9584992038216561 

The current subspace-distance is: 1.0020055015047546e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.34; acc: 0.91
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.06; acc: 1.0
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.06; acc: 1.0
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.07; acc: 0.97
Batch: 500; loss: 0.07; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.02; acc: 1.0
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.13; train_accuracy: 0.96 

2.394178409304004e-05
9.55501036514761e-06
Batch: 0; loss: 0.03; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14204926442378646; val_accuracy: 0.9586982484076433 

The current subspace-distance is: 9.55501036514761e-06 

plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
plots/subspace_training/lenet/2020-01-22 20:45:30/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
