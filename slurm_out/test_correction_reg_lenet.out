model : reg_lenet
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 2
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : True
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 20:47:39
nonzero elements in E: 10595
elements in E: 2197600
fraction nonzero: 0.004821168547506371
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.37; acc: 0.17
Batch: 20; loss: 2.37; acc: 0.05
Batch: 40; loss: 2.25; acc: 0.17
Batch: 60; loss: 2.29; acc: 0.09
Batch: 80; loss: 2.27; acc: 0.22
Batch: 100; loss: 2.27; acc: 0.14
Batch: 120; loss: 2.2; acc: 0.17
Batch: 140; loss: 2.22; acc: 0.17
Batch: 160; loss: 2.2; acc: 0.23
Batch: 180; loss: 2.22; acc: 0.28
Batch: 200; loss: 2.23; acc: 0.19
Batch: 220; loss: 2.25; acc: 0.25
Batch: 240; loss: 2.22; acc: 0.23
Batch: 260; loss: 2.26; acc: 0.16
Batch: 280; loss: 2.21; acc: 0.25
Batch: 300; loss: 2.21; acc: 0.25
Batch: 320; loss: 2.18; acc: 0.34
Batch: 340; loss: 2.2; acc: 0.28
Batch: 360; loss: 2.15; acc: 0.27
Batch: 380; loss: 2.22; acc: 0.17
Batch: 400; loss: 2.22; acc: 0.16
Batch: 420; loss: 2.13; acc: 0.36
Batch: 440; loss: 2.19; acc: 0.23
Batch: 460; loss: 2.14; acc: 0.36
Batch: 480; loss: 2.15; acc: 0.33
Batch: 500; loss: 2.17; acc: 0.28
Batch: 520; loss: 2.13; acc: 0.33
Batch: 540; loss: 2.22; acc: 0.2
Batch: 560; loss: 2.12; acc: 0.44
Batch: 580; loss: 2.16; acc: 0.31
Batch: 600; loss: 2.11; acc: 0.38
Batch: 620; loss: 2.12; acc: 0.44
Batch: 640; loss: 2.1; acc: 0.34
Batch: 660; loss: 2.11; acc: 0.3
Batch: 680; loss: 2.16; acc: 0.33
Batch: 700; loss: 2.11; acc: 0.3
Batch: 720; loss: 2.12; acc: 0.31
Batch: 740; loss: 2.13; acc: 0.25
Batch: 760; loss: 2.0; acc: 0.38
Batch: 780; loss: 2.14; acc: 0.28
Train Epoch over. train_loss: 2.19; train_accuracy: 0.26 

8.116075150610413e-06
2.344079803151544e-06
Batch: 0; loss: 2.1; acc: 0.28
Batch: 20; loss: 2.07; acc: 0.3
Batch: 40; loss: 2.0; acc: 0.45
Batch: 60; loss: 1.99; acc: 0.39
Batch: 80; loss: 2.07; acc: 0.28
Batch: 100; loss: 2.08; acc: 0.38
Batch: 120; loss: 2.1; acc: 0.25
Batch: 140; loss: 2.05; acc: 0.33
Val Epoch over. val_loss: 2.0797318463112897; val_accuracy: 0.31468949044585987 

The current subspace-distance is: 2.344079803151544e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.14; acc: 0.25
Batch: 20; loss: 2.09; acc: 0.2
Batch: 40; loss: 2.04; acc: 0.36
Batch: 60; loss: 2.15; acc: 0.3
Batch: 80; loss: 2.05; acc: 0.36
Batch: 100; loss: 1.96; acc: 0.36
Batch: 120; loss: 2.09; acc: 0.23
Batch: 140; loss: 1.95; acc: 0.36
Batch: 160; loss: 1.99; acc: 0.34
Batch: 180; loss: 2.06; acc: 0.28
Batch: 200; loss: 1.96; acc: 0.31
Batch: 220; loss: 1.97; acc: 0.28
Batch: 240; loss: 1.98; acc: 0.31
Batch: 260; loss: 1.97; acc: 0.3
Batch: 280; loss: 1.98; acc: 0.36
Batch: 300; loss: 1.91; acc: 0.31
Batch: 320; loss: 1.87; acc: 0.31
Batch: 340; loss: 1.8; acc: 0.41
Batch: 360; loss: 1.95; acc: 0.31
Batch: 380; loss: 1.8; acc: 0.31
Batch: 400; loss: 1.85; acc: 0.31
Batch: 420; loss: 1.95; acc: 0.3
Batch: 440; loss: 1.72; acc: 0.39
Batch: 460; loss: 1.74; acc: 0.42
Batch: 480; loss: 1.76; acc: 0.38
Batch: 500; loss: 1.79; acc: 0.39
Batch: 520; loss: 1.68; acc: 0.39
Batch: 540; loss: 1.95; acc: 0.27
Batch: 560; loss: 1.77; acc: 0.36
Batch: 580; loss: 1.88; acc: 0.25
Batch: 600; loss: 1.48; acc: 0.53
Batch: 620; loss: 1.62; acc: 0.47
Batch: 640; loss: 1.68; acc: 0.31
Batch: 660; loss: 1.59; acc: 0.44
Batch: 680; loss: 1.55; acc: 0.42
Batch: 700; loss: 1.36; acc: 0.56
Batch: 720; loss: 1.53; acc: 0.47
Batch: 740; loss: 1.47; acc: 0.44
Batch: 760; loss: 1.38; acc: 0.56
Batch: 780; loss: 1.62; acc: 0.44
Train Epoch over. train_loss: 1.81; train_accuracy: 0.38 

1.636624256207142e-05
4.730748514703009e-06
Batch: 0; loss: 1.45; acc: 0.48
Batch: 20; loss: 1.45; acc: 0.52
Batch: 40; loss: 1.23; acc: 0.61
Batch: 60; loss: 1.28; acc: 0.55
Batch: 80; loss: 1.37; acc: 0.59
Batch: 100; loss: 1.39; acc: 0.58
Batch: 120; loss: 1.46; acc: 0.53
Batch: 140; loss: 1.37; acc: 0.52
Val Epoch over. val_loss: 1.5101889546509761; val_accuracy: 0.4945262738853503 

The current subspace-distance is: 4.730748514703009e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.43; acc: 0.53
Batch: 20; loss: 1.52; acc: 0.5
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.6; acc: 0.47
Batch: 80; loss: 1.45; acc: 0.53
Batch: 100; loss: 1.47; acc: 0.5
Batch: 120; loss: 1.49; acc: 0.5
Batch: 140; loss: 1.37; acc: 0.48
Batch: 160; loss: 1.47; acc: 0.55
Batch: 180; loss: 1.55; acc: 0.42
Batch: 200; loss: 1.32; acc: 0.64
Batch: 220; loss: 1.43; acc: 0.45
Batch: 240; loss: 1.46; acc: 0.5
Batch: 260; loss: 1.41; acc: 0.53
Batch: 280; loss: 1.36; acc: 0.58
Batch: 300; loss: 1.42; acc: 0.53
Batch: 320; loss: 1.59; acc: 0.47
Batch: 340; loss: 1.4; acc: 0.56
Batch: 360; loss: 1.56; acc: 0.45
Batch: 380; loss: 1.64; acc: 0.44
Batch: 400; loss: 1.5; acc: 0.47
Batch: 420; loss: 1.47; acc: 0.53
Batch: 440; loss: 1.37; acc: 0.52
Batch: 460; loss: 1.46; acc: 0.55
Batch: 480; loss: 1.47; acc: 0.48
Batch: 500; loss: 1.61; acc: 0.45
Batch: 520; loss: 1.26; acc: 0.56
Batch: 540; loss: 1.45; acc: 0.5
Batch: 560; loss: 1.35; acc: 0.52
Batch: 580; loss: 1.52; acc: 0.47
Batch: 600; loss: 1.31; acc: 0.56
Batch: 620; loss: 1.26; acc: 0.55
Batch: 640; loss: 1.43; acc: 0.48
Batch: 660; loss: 1.43; acc: 0.48
Batch: 680; loss: 1.44; acc: 0.5
Batch: 700; loss: 1.46; acc: 0.47
Batch: 720; loss: 1.62; acc: 0.47
Batch: 740; loss: 1.27; acc: 0.55
Batch: 760; loss: 1.35; acc: 0.56
Batch: 780; loss: 1.3; acc: 0.61
Train Epoch over. train_loss: 1.43; train_accuracy: 0.52 

1.9960747522418387e-05
4.608175458997721e-06
Batch: 0; loss: 1.29; acc: 0.55
Batch: 20; loss: 1.19; acc: 0.66
Batch: 40; loss: 1.15; acc: 0.64
Batch: 60; loss: 1.24; acc: 0.59
Batch: 80; loss: 1.23; acc: 0.59
Batch: 100; loss: 1.34; acc: 0.53
Batch: 120; loss: 1.41; acc: 0.52
Batch: 140; loss: 1.13; acc: 0.59
Val Epoch over. val_loss: 1.3888383864597151; val_accuracy: 0.5211982484076433 

The current subspace-distance is: 4.608175458997721e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.6; acc: 0.45
Batch: 20; loss: 1.46; acc: 0.56
Batch: 40; loss: 1.37; acc: 0.45
Batch: 60; loss: 1.28; acc: 0.61
Batch: 80; loss: 1.52; acc: 0.47
Batch: 100; loss: 1.17; acc: 0.66
Batch: 120; loss: 1.31; acc: 0.52
Batch: 140; loss: 1.4; acc: 0.5
Batch: 160; loss: 1.16; acc: 0.62
Batch: 180; loss: 1.48; acc: 0.52
Batch: 200; loss: 1.42; acc: 0.5
Batch: 220; loss: 1.29; acc: 0.58
Batch: 240; loss: 1.37; acc: 0.52
Batch: 260; loss: 1.26; acc: 0.52
Batch: 280; loss: 1.47; acc: 0.55
Batch: 300; loss: 1.86; acc: 0.38
Batch: 320; loss: 1.08; acc: 0.67
Batch: 340; loss: 1.36; acc: 0.48
Batch: 360; loss: 1.45; acc: 0.52
Batch: 380; loss: 1.35; acc: 0.52
Batch: 400; loss: 1.33; acc: 0.52
Batch: 420; loss: 1.61; acc: 0.45
Batch: 440; loss: 1.43; acc: 0.55
Batch: 460; loss: 1.49; acc: 0.47
Batch: 480; loss: 1.3; acc: 0.61
Batch: 500; loss: 1.53; acc: 0.44
Batch: 520; loss: 1.37; acc: 0.53
Batch: 540; loss: 1.59; acc: 0.47
Batch: 560; loss: 1.48; acc: 0.48
Batch: 580; loss: 1.49; acc: 0.52
Batch: 600; loss: 1.45; acc: 0.52
Batch: 620; loss: 1.31; acc: 0.56
Batch: 640; loss: 0.95; acc: 0.67
Batch: 660; loss: 1.43; acc: 0.5
Batch: 680; loss: 1.44; acc: 0.48
Batch: 700; loss: 1.22; acc: 0.61
Batch: 720; loss: 1.34; acc: 0.56
Batch: 740; loss: 1.26; acc: 0.55
Batch: 760; loss: 1.55; acc: 0.53
Batch: 780; loss: 1.36; acc: 0.52
Train Epoch over. train_loss: 1.37; train_accuracy: 0.54 

1.9632781913969666e-05
6.072444648452802e-06
Batch: 0; loss: 1.26; acc: 0.53
Batch: 20; loss: 1.15; acc: 0.69
Batch: 40; loss: 1.03; acc: 0.66
Batch: 60; loss: 1.18; acc: 0.61
Batch: 80; loss: 1.19; acc: 0.56
Batch: 100; loss: 1.3; acc: 0.61
Batch: 120; loss: 1.4; acc: 0.61
Batch: 140; loss: 1.11; acc: 0.69
Val Epoch over. val_loss: 1.3470344346040373; val_accuracy: 0.5445859872611465 

The current subspace-distance is: 6.072444648452802e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.4; acc: 0.55
Batch: 20; loss: 1.48; acc: 0.47
Batch: 40; loss: 1.39; acc: 0.48
Batch: 60; loss: 1.23; acc: 0.61
Batch: 80; loss: 1.33; acc: 0.56
Batch: 100; loss: 1.29; acc: 0.61
Batch: 120; loss: 1.39; acc: 0.44
Batch: 140; loss: 1.36; acc: 0.55
Batch: 160; loss: 1.21; acc: 0.55
Batch: 180; loss: 1.3; acc: 0.55
Batch: 200; loss: 1.43; acc: 0.5
Batch: 220; loss: 1.49; acc: 0.47
Batch: 240; loss: 1.48; acc: 0.52
Batch: 260; loss: 1.16; acc: 0.58
Batch: 280; loss: 1.61; acc: 0.39
Batch: 300; loss: 1.35; acc: 0.53
Batch: 320; loss: 1.47; acc: 0.55
Batch: 340; loss: 1.51; acc: 0.52
Batch: 360; loss: 1.32; acc: 0.56
Batch: 380; loss: 1.35; acc: 0.53
Batch: 400; loss: 1.38; acc: 0.53
Batch: 420; loss: 1.51; acc: 0.48
Batch: 440; loss: 1.15; acc: 0.66
Batch: 460; loss: 1.33; acc: 0.55
Batch: 480; loss: 1.46; acc: 0.52
Batch: 500; loss: 1.26; acc: 0.59
Batch: 520; loss: 1.34; acc: 0.53
Batch: 540; loss: 1.13; acc: 0.61
Batch: 560; loss: 1.32; acc: 0.61
Batch: 580; loss: 1.2; acc: 0.59
Batch: 600; loss: 1.37; acc: 0.59
Batch: 620; loss: 1.44; acc: 0.55
Batch: 640; loss: 1.32; acc: 0.53
Batch: 660; loss: 1.46; acc: 0.5
Batch: 680; loss: 1.3; acc: 0.5
Batch: 700; loss: 1.46; acc: 0.48
Batch: 720; loss: 1.32; acc: 0.5
Batch: 740; loss: 1.29; acc: 0.56
Batch: 760; loss: 1.25; acc: 0.61
Batch: 780; loss: 1.42; acc: 0.47
Train Epoch over. train_loss: 1.36; train_accuracy: 0.55 

1.9742350559681654e-05
5.674407475453336e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.2; acc: 0.59
Batch: 40; loss: 1.08; acc: 0.66
Batch: 60; loss: 1.25; acc: 0.59
Batch: 80; loss: 1.33; acc: 0.52
Batch: 100; loss: 1.3; acc: 0.53
Batch: 120; loss: 1.47; acc: 0.61
Batch: 140; loss: 1.01; acc: 0.64
Val Epoch over. val_loss: 1.3714128037926498; val_accuracy: 0.5418988853503185 

The current subspace-distance is: 5.674407475453336e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.6; acc: 0.45
Batch: 20; loss: 1.31; acc: 0.61
Batch: 40; loss: 1.43; acc: 0.52
Batch: 60; loss: 1.1; acc: 0.64
Batch: 80; loss: 1.33; acc: 0.52
Batch: 100; loss: 1.21; acc: 0.61
Batch: 120; loss: 1.23; acc: 0.58
Batch: 140; loss: 1.5; acc: 0.52
Batch: 160; loss: 1.32; acc: 0.55
Batch: 180; loss: 1.34; acc: 0.55
Batch: 200; loss: 1.45; acc: 0.5
Batch: 220; loss: 1.15; acc: 0.59
Batch: 240; loss: 1.07; acc: 0.69
Batch: 260; loss: 1.23; acc: 0.66
Batch: 280; loss: 1.37; acc: 0.55
Batch: 300; loss: 1.25; acc: 0.62
Batch: 320; loss: 1.16; acc: 0.62
Batch: 340; loss: 1.2; acc: 0.59
Batch: 360; loss: 1.23; acc: 0.59
Batch: 380; loss: 1.24; acc: 0.56
Batch: 400; loss: 1.3; acc: 0.53
Batch: 420; loss: 1.45; acc: 0.52
Batch: 440; loss: 1.12; acc: 0.67
Batch: 460; loss: 1.02; acc: 0.7
Batch: 480; loss: 1.37; acc: 0.56
Batch: 500; loss: 1.15; acc: 0.7
Batch: 520; loss: 1.12; acc: 0.7
Batch: 540; loss: 1.4; acc: 0.55
Batch: 560; loss: 1.4; acc: 0.53
Batch: 580; loss: 1.39; acc: 0.59
Batch: 600; loss: 1.34; acc: 0.56
Batch: 620; loss: 1.31; acc: 0.58
Batch: 640; loss: 1.5; acc: 0.5
Batch: 660; loss: 1.26; acc: 0.62
Batch: 680; loss: 1.39; acc: 0.47
Batch: 700; loss: 1.23; acc: 0.59
Batch: 720; loss: 1.5; acc: 0.38
Batch: 740; loss: 1.46; acc: 0.55
Batch: 760; loss: 1.37; acc: 0.61
Batch: 780; loss: 1.3; acc: 0.52
Train Epoch over. train_loss: 1.34; train_accuracy: 0.56 

2.0144436348346062e-05
5.62856894248398e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.31; acc: 0.56
Batch: 40; loss: 1.06; acc: 0.69
Batch: 60; loss: 1.24; acc: 0.56
Batch: 80; loss: 1.35; acc: 0.61
Batch: 100; loss: 1.25; acc: 0.56
Batch: 120; loss: 1.44; acc: 0.61
Batch: 140; loss: 1.06; acc: 0.66
Val Epoch over. val_loss: 1.3741698606758361; val_accuracy: 0.5397093949044586 

The current subspace-distance is: 5.62856894248398e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.12; acc: 0.61
Batch: 20; loss: 1.3; acc: 0.53
Batch: 40; loss: 1.39; acc: 0.53
Batch: 60; loss: 1.41; acc: 0.56
Batch: 80; loss: 1.33; acc: 0.56
Batch: 100; loss: 1.57; acc: 0.47
Batch: 120; loss: 1.27; acc: 0.56
Batch: 140; loss: 1.24; acc: 0.56
Batch: 160; loss: 1.32; acc: 0.56
Batch: 180; loss: 1.48; acc: 0.5
Batch: 200; loss: 1.23; acc: 0.55
Batch: 220; loss: 1.09; acc: 0.62
Batch: 240; loss: 1.36; acc: 0.55
Batch: 260; loss: 1.38; acc: 0.53
Batch: 280; loss: 1.41; acc: 0.56
Batch: 300; loss: 1.49; acc: 0.52
Batch: 320; loss: 1.47; acc: 0.58
Batch: 340; loss: 1.44; acc: 0.48
Batch: 360; loss: 1.09; acc: 0.72
Batch: 380; loss: 1.46; acc: 0.48
Batch: 400; loss: 1.22; acc: 0.62
Batch: 420; loss: 1.26; acc: 0.67
Batch: 440; loss: 1.37; acc: 0.52
Batch: 460; loss: 1.22; acc: 0.62
Batch: 480; loss: 1.55; acc: 0.55
Batch: 500; loss: 1.23; acc: 0.61
Batch: 520; loss: 1.53; acc: 0.58
Batch: 540; loss: 1.31; acc: 0.59
Batch: 560; loss: 1.34; acc: 0.58
Batch: 580; loss: 1.15; acc: 0.64
Batch: 600; loss: 1.41; acc: 0.55
Batch: 620; loss: 1.21; acc: 0.58
Batch: 640; loss: 1.59; acc: 0.48
Batch: 660; loss: 1.22; acc: 0.59
Batch: 680; loss: 1.24; acc: 0.62
Batch: 700; loss: 1.38; acc: 0.55
Batch: 720; loss: 1.33; acc: 0.55
Batch: 740; loss: 1.22; acc: 0.59
Batch: 760; loss: 1.51; acc: 0.47
Batch: 780; loss: 1.32; acc: 0.61
Train Epoch over. train_loss: 1.33; train_accuracy: 0.56 

2.1333953554858454e-05
5.766468348156195e-06
Batch: 0; loss: 1.14; acc: 0.58
Batch: 20; loss: 1.3; acc: 0.56
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 1.16; acc: 0.61
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.26; acc: 0.61
Batch: 120; loss: 1.44; acc: 0.61
Batch: 140; loss: 0.98; acc: 0.69
Val Epoch over. val_loss: 1.322997969806574; val_accuracy: 0.5605095541401274 

The current subspace-distance is: 5.766468348156195e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.44; acc: 0.47
Batch: 20; loss: 1.33; acc: 0.59
Batch: 40; loss: 1.16; acc: 0.64
Batch: 60; loss: 1.23; acc: 0.66
Batch: 80; loss: 1.38; acc: 0.53
Batch: 100; loss: 1.31; acc: 0.58
Batch: 120; loss: 1.24; acc: 0.64
Batch: 140; loss: 1.35; acc: 0.56
Batch: 160; loss: 1.22; acc: 0.66
Batch: 180; loss: 1.56; acc: 0.41
Batch: 200; loss: 1.31; acc: 0.56
Batch: 220; loss: 1.44; acc: 0.59
Batch: 240; loss: 1.46; acc: 0.52
Batch: 260; loss: 1.44; acc: 0.55
Batch: 280; loss: 1.23; acc: 0.59
Batch: 300; loss: 1.28; acc: 0.62
Batch: 320; loss: 1.6; acc: 0.47
Batch: 340; loss: 1.31; acc: 0.53
Batch: 360; loss: 1.23; acc: 0.69
Batch: 380; loss: 1.28; acc: 0.48
Batch: 400; loss: 1.6; acc: 0.52
Batch: 420; loss: 1.35; acc: 0.5
Batch: 440; loss: 1.56; acc: 0.52
Batch: 460; loss: 1.45; acc: 0.58
Batch: 480; loss: 1.35; acc: 0.53
Batch: 500; loss: 1.45; acc: 0.53
Batch: 520; loss: 1.32; acc: 0.55
Batch: 540; loss: 1.09; acc: 0.66
Batch: 560; loss: 1.22; acc: 0.58
Batch: 580; loss: 1.31; acc: 0.55
Batch: 600; loss: 1.06; acc: 0.67
Batch: 620; loss: 1.1; acc: 0.62
Batch: 640; loss: 1.43; acc: 0.55
Batch: 660; loss: 1.51; acc: 0.5
Batch: 680; loss: 1.38; acc: 0.56
Batch: 700; loss: 1.14; acc: 0.62
Batch: 720; loss: 1.28; acc: 0.58
Batch: 740; loss: 1.7; acc: 0.5
Batch: 760; loss: 1.33; acc: 0.53
Batch: 780; loss: 1.33; acc: 0.61
Train Epoch over. train_loss: 1.33; train_accuracy: 0.56 

2.029202732956037e-05
6.28254929324612e-06
Batch: 0; loss: 1.24; acc: 0.62
Batch: 20; loss: 1.33; acc: 0.52
Batch: 40; loss: 1.03; acc: 0.7
Batch: 60; loss: 1.09; acc: 0.66
Batch: 80; loss: 1.18; acc: 0.66
Batch: 100; loss: 1.36; acc: 0.55
Batch: 120; loss: 1.54; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.75
Val Epoch over. val_loss: 1.3069818145150591; val_accuracy: 0.5758359872611465 

The current subspace-distance is: 6.28254929324612e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.2; acc: 0.58
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 1.29; acc: 0.59
Batch: 60; loss: 1.32; acc: 0.5
Batch: 80; loss: 1.33; acc: 0.52
Batch: 100; loss: 1.2; acc: 0.55
Batch: 120; loss: 1.15; acc: 0.66
Batch: 140; loss: 1.12; acc: 0.66
Batch: 160; loss: 1.35; acc: 0.56
Batch: 180; loss: 1.27; acc: 0.5
Batch: 200; loss: 1.41; acc: 0.48
Batch: 220; loss: 1.51; acc: 0.58
Batch: 240; loss: 1.11; acc: 0.64
Batch: 260; loss: 1.34; acc: 0.56
Batch: 280; loss: 1.35; acc: 0.59
Batch: 300; loss: 1.46; acc: 0.47
Batch: 320; loss: 1.43; acc: 0.48
Batch: 340; loss: 1.32; acc: 0.59
Batch: 360; loss: 1.32; acc: 0.55
Batch: 380; loss: 1.16; acc: 0.59
Batch: 400; loss: 1.52; acc: 0.55
Batch: 420; loss: 1.52; acc: 0.47
Batch: 440; loss: 1.45; acc: 0.53
Batch: 460; loss: 1.43; acc: 0.52
Batch: 480; loss: 1.3; acc: 0.55
Batch: 500; loss: 1.29; acc: 0.53
Batch: 520; loss: 1.37; acc: 0.59
Batch: 540; loss: 1.25; acc: 0.62
Batch: 560; loss: 1.43; acc: 0.56
Batch: 580; loss: 1.28; acc: 0.53
Batch: 600; loss: 1.25; acc: 0.56
Batch: 620; loss: 1.62; acc: 0.45
Batch: 640; loss: 1.23; acc: 0.62
Batch: 660; loss: 1.48; acc: 0.5
Batch: 680; loss: 1.33; acc: 0.56
Batch: 700; loss: 1.32; acc: 0.56
Batch: 720; loss: 1.39; acc: 0.56
Batch: 740; loss: 1.5; acc: 0.47
Batch: 760; loss: 1.39; acc: 0.53
Batch: 780; loss: 1.29; acc: 0.59
Train Epoch over. train_loss: 1.33; train_accuracy: 0.56 

1.9969904315075837e-05
6.107147783041e-06
Batch: 0; loss: 1.5; acc: 0.53
Batch: 20; loss: 1.65; acc: 0.42
Batch: 40; loss: 1.17; acc: 0.67
Batch: 60; loss: 1.26; acc: 0.62
Batch: 80; loss: 1.28; acc: 0.55
Batch: 100; loss: 1.67; acc: 0.45
Batch: 120; loss: 1.83; acc: 0.5
Batch: 140; loss: 1.31; acc: 0.64
Val Epoch over. val_loss: 1.5380001721108796; val_accuracy: 0.5041799363057324 

The current subspace-distance is: 6.107147783041e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.65; acc: 0.53
Batch: 20; loss: 1.28; acc: 0.52
Batch: 40; loss: 1.53; acc: 0.45
Batch: 60; loss: 1.23; acc: 0.61
Batch: 80; loss: 1.41; acc: 0.48
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.13; acc: 0.61
Batch: 140; loss: 1.22; acc: 0.58
Batch: 160; loss: 1.41; acc: 0.52
Batch: 180; loss: 1.33; acc: 0.47
Batch: 200; loss: 1.26; acc: 0.66
Batch: 220; loss: 1.18; acc: 0.58
Batch: 240; loss: 1.21; acc: 0.56
Batch: 260; loss: 1.22; acc: 0.58
Batch: 280; loss: 1.28; acc: 0.61
Batch: 300; loss: 1.44; acc: 0.55
Batch: 320; loss: 1.23; acc: 0.61
Batch: 340; loss: 1.17; acc: 0.64
Batch: 360; loss: 0.99; acc: 0.73
Batch: 380; loss: 1.22; acc: 0.59
Batch: 400; loss: 1.34; acc: 0.59
Batch: 420; loss: 1.23; acc: 0.59
Batch: 440; loss: 1.4; acc: 0.53
Batch: 460; loss: 1.22; acc: 0.58
Batch: 480; loss: 1.33; acc: 0.58
Batch: 500; loss: 1.2; acc: 0.66
Batch: 520; loss: 1.22; acc: 0.59
Batch: 540; loss: 1.41; acc: 0.48
Batch: 560; loss: 1.43; acc: 0.45
Batch: 580; loss: 1.35; acc: 0.5
Batch: 600; loss: 1.15; acc: 0.64
Batch: 620; loss: 1.37; acc: 0.53
Batch: 640; loss: 1.11; acc: 0.69
Batch: 660; loss: 1.34; acc: 0.55
Batch: 680; loss: 1.37; acc: 0.59
Batch: 700; loss: 1.23; acc: 0.61
Batch: 720; loss: 1.39; acc: 0.53
Batch: 740; loss: 1.32; acc: 0.59
Batch: 760; loss: 1.5; acc: 0.53
Batch: 780; loss: 1.24; acc: 0.61
Train Epoch over. train_loss: 1.32; train_accuracy: 0.56 

1.8083412214764394e-05
4.967222594132181e-06
Batch: 0; loss: 1.17; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.5
Batch: 40; loss: 1.05; acc: 0.67
Batch: 60; loss: 1.2; acc: 0.56
Batch: 80; loss: 1.28; acc: 0.59
Batch: 100; loss: 1.28; acc: 0.56
Batch: 120; loss: 1.41; acc: 0.64
Batch: 140; loss: 0.97; acc: 0.69
Val Epoch over. val_loss: 1.3155820654456023; val_accuracy: 0.5632961783439491 

The current subspace-distance is: 4.967222594132181e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.25; acc: 0.59
Batch: 20; loss: 1.51; acc: 0.48
Batch: 40; loss: 1.35; acc: 0.48
Batch: 60; loss: 1.13; acc: 0.69
Batch: 80; loss: 1.24; acc: 0.66
Batch: 100; loss: 1.12; acc: 0.67
Batch: 120; loss: 1.33; acc: 0.56
Batch: 140; loss: 1.31; acc: 0.59
Batch: 160; loss: 1.15; acc: 0.64
Batch: 180; loss: 1.46; acc: 0.52
Batch: 200; loss: 1.56; acc: 0.55
Batch: 220; loss: 1.23; acc: 0.53
Batch: 240; loss: 1.25; acc: 0.52
Batch: 260; loss: 1.34; acc: 0.61
Batch: 280; loss: 1.36; acc: 0.55
Batch: 300; loss: 1.27; acc: 0.62
Batch: 320; loss: 1.35; acc: 0.55
Batch: 340; loss: 1.19; acc: 0.61
Batch: 360; loss: 1.33; acc: 0.58
Batch: 380; loss: 1.66; acc: 0.42
Batch: 400; loss: 1.15; acc: 0.64
Batch: 420; loss: 1.31; acc: 0.56
Batch: 440; loss: 1.42; acc: 0.52
Batch: 460; loss: 1.21; acc: 0.64
Batch: 480; loss: 1.16; acc: 0.61
Batch: 500; loss: 1.39; acc: 0.55
Batch: 520; loss: 1.27; acc: 0.59
Batch: 540; loss: 1.43; acc: 0.5
Batch: 560; loss: 1.29; acc: 0.53
Batch: 580; loss: 1.44; acc: 0.52
Batch: 600; loss: 1.5; acc: 0.48
Batch: 620; loss: 1.07; acc: 0.64
Batch: 640; loss: 0.93; acc: 0.69
Batch: 660; loss: 1.45; acc: 0.52
Batch: 680; loss: 1.35; acc: 0.58
Batch: 700; loss: 1.23; acc: 0.61
Batch: 720; loss: 1.4; acc: 0.53
Batch: 740; loss: 1.24; acc: 0.56
Batch: 760; loss: 1.13; acc: 0.59
Batch: 780; loss: 1.37; acc: 0.64
Train Epoch over. train_loss: 1.31; train_accuracy: 0.57 

2.2064463337301277e-05
7.30593865228002e-06
Batch: 0; loss: 1.19; acc: 0.59
Batch: 20; loss: 1.31; acc: 0.5
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 1.13; acc: 0.58
Batch: 80; loss: 1.17; acc: 0.59
Batch: 100; loss: 1.31; acc: 0.53
Batch: 120; loss: 1.4; acc: 0.64
Batch: 140; loss: 0.95; acc: 0.69
Val Epoch over. val_loss: 1.2931597153092647; val_accuracy: 0.5725517515923567 

The current subspace-distance is: 7.30593865228002e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.55; acc: 0.53
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.34; acc: 0.48
Batch: 60; loss: 1.14; acc: 0.58
Batch: 80; loss: 1.37; acc: 0.55
Batch: 100; loss: 1.23; acc: 0.56
Batch: 120; loss: 1.35; acc: 0.53
Batch: 140; loss: 1.22; acc: 0.56
Batch: 160; loss: 1.33; acc: 0.62
Batch: 180; loss: 1.17; acc: 0.59
Batch: 200; loss: 1.06; acc: 0.7
Batch: 220; loss: 1.25; acc: 0.58
Batch: 240; loss: 1.26; acc: 0.59
Batch: 260; loss: 1.33; acc: 0.56
Batch: 280; loss: 1.36; acc: 0.52
Batch: 300; loss: 1.35; acc: 0.61
Batch: 320; loss: 1.42; acc: 0.55
Batch: 340; loss: 1.54; acc: 0.48
Batch: 360; loss: 1.27; acc: 0.55
Batch: 380; loss: 1.35; acc: 0.58
Batch: 400; loss: 1.51; acc: 0.48
Batch: 420; loss: 1.28; acc: 0.59
Batch: 440; loss: 1.21; acc: 0.61
Batch: 460; loss: 1.61; acc: 0.47
Batch: 480; loss: 1.36; acc: 0.58
Batch: 500; loss: 1.31; acc: 0.5
Batch: 520; loss: 1.56; acc: 0.5
Batch: 540; loss: 1.2; acc: 0.61
Batch: 560; loss: 1.22; acc: 0.58
Batch: 580; loss: 1.11; acc: 0.56
Batch: 600; loss: 1.2; acc: 0.64
Batch: 620; loss: 1.28; acc: 0.62
Batch: 640; loss: 1.31; acc: 0.55
Batch: 660; loss: 1.39; acc: 0.53
Batch: 680; loss: 1.16; acc: 0.61
Batch: 700; loss: 1.18; acc: 0.64
Batch: 720; loss: 1.3; acc: 0.55
Batch: 740; loss: 1.48; acc: 0.48
Batch: 760; loss: 1.08; acc: 0.69
Batch: 780; loss: 1.27; acc: 0.55
Train Epoch over. train_loss: 1.31; train_accuracy: 0.57 

2.0527271772152744e-05
4.789269951288588e-06
Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.31; acc: 0.53
Batch: 40; loss: 1.07; acc: 0.64
Batch: 60; loss: 1.21; acc: 0.53
Batch: 80; loss: 1.22; acc: 0.53
Batch: 100; loss: 1.39; acc: 0.55
Batch: 120; loss: 1.51; acc: 0.56
Batch: 140; loss: 0.97; acc: 0.7
Val Epoch over. val_loss: 1.3223914226908593; val_accuracy: 0.5554339171974523 

The current subspace-distance is: 4.789269951288588e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.43; acc: 0.53
Batch: 20; loss: 1.24; acc: 0.55
Batch: 40; loss: 1.37; acc: 0.55
Batch: 60; loss: 1.29; acc: 0.61
Batch: 80; loss: 1.34; acc: 0.59
Batch: 100; loss: 1.21; acc: 0.64
Batch: 120; loss: 1.11; acc: 0.62
Batch: 140; loss: 1.19; acc: 0.64
Batch: 160; loss: 1.31; acc: 0.62
Batch: 180; loss: 1.24; acc: 0.61
Batch: 200; loss: 1.2; acc: 0.55
Batch: 220; loss: 1.2; acc: 0.58
Batch: 240; loss: 1.37; acc: 0.52
Batch: 260; loss: 1.27; acc: 0.55
Batch: 280; loss: 1.44; acc: 0.55
Batch: 300; loss: 1.19; acc: 0.58
Batch: 320; loss: 1.29; acc: 0.64
Batch: 340; loss: 1.43; acc: 0.59
Batch: 360; loss: 1.18; acc: 0.58
Batch: 380; loss: 1.14; acc: 0.59
Batch: 400; loss: 1.44; acc: 0.53
Batch: 420; loss: 1.21; acc: 0.58
Batch: 440; loss: 1.16; acc: 0.61
Batch: 460; loss: 1.2; acc: 0.62
Batch: 480; loss: 1.64; acc: 0.47
Batch: 500; loss: 1.33; acc: 0.55
Batch: 520; loss: 1.34; acc: 0.59
Batch: 540; loss: 1.33; acc: 0.48
Batch: 560; loss: 1.27; acc: 0.53
Batch: 580; loss: 1.09; acc: 0.69
Batch: 600; loss: 1.07; acc: 0.61
Batch: 620; loss: 1.41; acc: 0.56
Batch: 640; loss: 1.15; acc: 0.66
Batch: 660; loss: 1.4; acc: 0.58
Batch: 680; loss: 1.37; acc: 0.58
Batch: 700; loss: 1.23; acc: 0.58
Batch: 720; loss: 1.16; acc: 0.58
Batch: 740; loss: 1.27; acc: 0.62
Batch: 760; loss: 1.15; acc: 0.58
Batch: 780; loss: 1.33; acc: 0.56
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.845072074502241e-05
5.14196199219441e-06
Batch: 0; loss: 1.2; acc: 0.62
Batch: 20; loss: 1.31; acc: 0.52
Batch: 40; loss: 0.98; acc: 0.72
Batch: 60; loss: 1.11; acc: 0.64
Batch: 80; loss: 1.12; acc: 0.61
Batch: 100; loss: 1.35; acc: 0.52
Batch: 120; loss: 1.44; acc: 0.62
Batch: 140; loss: 0.97; acc: 0.69
Val Epoch over. val_loss: 1.2889778576079447; val_accuracy: 0.5791202229299363 

The current subspace-distance is: 5.14196199219441e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.19; acc: 0.61
Batch: 20; loss: 1.21; acc: 0.53
Batch: 40; loss: 1.41; acc: 0.55
Batch: 60; loss: 1.27; acc: 0.64
Batch: 80; loss: 1.45; acc: 0.52
Batch: 100; loss: 0.99; acc: 0.69
Batch: 120; loss: 1.34; acc: 0.56
Batch: 140; loss: 1.26; acc: 0.59
Batch: 160; loss: 1.42; acc: 0.56
Batch: 180; loss: 1.33; acc: 0.56
Batch: 200; loss: 1.05; acc: 0.62
Batch: 220; loss: 1.34; acc: 0.55
Batch: 240; loss: 1.42; acc: 0.52
Batch: 260; loss: 1.16; acc: 0.67
Batch: 280; loss: 1.22; acc: 0.62
Batch: 300; loss: 1.34; acc: 0.55
Batch: 320; loss: 1.35; acc: 0.59
Batch: 340; loss: 1.4; acc: 0.56
Batch: 360; loss: 1.31; acc: 0.52
Batch: 380; loss: 1.43; acc: 0.59
Batch: 400; loss: 1.44; acc: 0.53
Batch: 420; loss: 1.25; acc: 0.59
Batch: 440; loss: 1.19; acc: 0.64
Batch: 460; loss: 1.67; acc: 0.41
Batch: 480; loss: 1.22; acc: 0.64
Batch: 500; loss: 1.37; acc: 0.61
Batch: 520; loss: 1.45; acc: 0.5
Batch: 540; loss: 1.12; acc: 0.64
Batch: 560; loss: 1.34; acc: 0.56
Batch: 580; loss: 1.23; acc: 0.62
Batch: 600; loss: 1.27; acc: 0.53
Batch: 620; loss: 1.47; acc: 0.5
Batch: 640; loss: 1.14; acc: 0.62
Batch: 660; loss: 1.19; acc: 0.55
Batch: 680; loss: 1.32; acc: 0.58
Batch: 700; loss: 1.13; acc: 0.69
Batch: 720; loss: 1.32; acc: 0.55
Batch: 740; loss: 1.5; acc: 0.5
Batch: 760; loss: 1.15; acc: 0.66
Batch: 780; loss: 1.31; acc: 0.59
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

2.039486753346864e-05
5.4793817980680615e-06
Batch: 0; loss: 1.19; acc: 0.59
Batch: 20; loss: 1.28; acc: 0.55
Batch: 40; loss: 1.08; acc: 0.67
Batch: 60; loss: 1.21; acc: 0.56
Batch: 80; loss: 1.24; acc: 0.55
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.45; acc: 0.61
Batch: 140; loss: 0.94; acc: 0.69
Val Epoch over. val_loss: 1.3190879058686031; val_accuracy: 0.559812898089172 

The current subspace-distance is: 5.4793817980680615e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.47; acc: 0.55
Batch: 20; loss: 1.0; acc: 0.67
Batch: 40; loss: 1.15; acc: 0.58
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 1.23; acc: 0.66
Batch: 100; loss: 1.39; acc: 0.52
Batch: 120; loss: 1.18; acc: 0.59
Batch: 140; loss: 1.14; acc: 0.66
Batch: 160; loss: 1.36; acc: 0.55
Batch: 180; loss: 1.66; acc: 0.44
Batch: 200; loss: 1.23; acc: 0.53
Batch: 220; loss: 1.46; acc: 0.5
Batch: 240; loss: 1.4; acc: 0.5
Batch: 260; loss: 1.21; acc: 0.55
Batch: 280; loss: 1.16; acc: 0.67
Batch: 300; loss: 1.26; acc: 0.55
Batch: 320; loss: 1.48; acc: 0.53
Batch: 340; loss: 1.22; acc: 0.61
Batch: 360; loss: 1.23; acc: 0.59
Batch: 380; loss: 1.62; acc: 0.5
Batch: 400; loss: 1.04; acc: 0.7
Batch: 420; loss: 1.26; acc: 0.62
Batch: 440; loss: 1.35; acc: 0.58
Batch: 460; loss: 1.25; acc: 0.58
Batch: 480; loss: 1.31; acc: 0.64
Batch: 500; loss: 1.47; acc: 0.47
Batch: 520; loss: 1.39; acc: 0.56
Batch: 540; loss: 1.21; acc: 0.59
Batch: 560; loss: 1.16; acc: 0.66
Batch: 580; loss: 1.11; acc: 0.61
Batch: 600; loss: 1.11; acc: 0.62
Batch: 620; loss: 1.14; acc: 0.59
Batch: 640; loss: 1.22; acc: 0.61
Batch: 660; loss: 1.51; acc: 0.52
Batch: 680; loss: 1.35; acc: 0.61
Batch: 700; loss: 1.44; acc: 0.56
Batch: 720; loss: 1.21; acc: 0.66
Batch: 740; loss: 1.23; acc: 0.53
Batch: 760; loss: 1.49; acc: 0.44
Batch: 780; loss: 1.24; acc: 0.56
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

2.4240705897682346e-05
5.194724508328363e-06
Batch: 0; loss: 1.22; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.5
Batch: 40; loss: 1.0; acc: 0.7
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.59
Batch: 100; loss: 1.34; acc: 0.52
Batch: 120; loss: 1.41; acc: 0.61
Batch: 140; loss: 0.97; acc: 0.67
Val Epoch over. val_loss: 1.2938682816590472; val_accuracy: 0.5729498407643312 

The current subspace-distance is: 5.194724508328363e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.52; acc: 0.48
Batch: 20; loss: 1.32; acc: 0.59
Batch: 40; loss: 1.46; acc: 0.45
Batch: 60; loss: 1.53; acc: 0.56
Batch: 80; loss: 1.29; acc: 0.58
Batch: 100; loss: 1.09; acc: 0.62
Batch: 120; loss: 1.42; acc: 0.42
Batch: 140; loss: 1.12; acc: 0.66
Batch: 160; loss: 1.08; acc: 0.67
Batch: 180; loss: 1.29; acc: 0.59
Batch: 200; loss: 1.22; acc: 0.62
Batch: 220; loss: 1.38; acc: 0.48
Batch: 240; loss: 1.09; acc: 0.61
Batch: 260; loss: 1.36; acc: 0.55
Batch: 280; loss: 1.38; acc: 0.55
Batch: 300; loss: 1.27; acc: 0.52
Batch: 320; loss: 1.23; acc: 0.66
Batch: 340; loss: 1.12; acc: 0.62
Batch: 360; loss: 1.42; acc: 0.5
Batch: 380; loss: 1.09; acc: 0.58
Batch: 400; loss: 1.4; acc: 0.47
Batch: 420; loss: 1.16; acc: 0.64
Batch: 440; loss: 1.46; acc: 0.53
Batch: 460; loss: 1.22; acc: 0.56
Batch: 480; loss: 1.23; acc: 0.61
Batch: 500; loss: 1.41; acc: 0.52
Batch: 520; loss: 1.3; acc: 0.58
Batch: 540; loss: 1.42; acc: 0.55
Batch: 560; loss: 1.36; acc: 0.5
Batch: 580; loss: 1.39; acc: 0.55
Batch: 600; loss: 1.23; acc: 0.59
Batch: 620; loss: 1.13; acc: 0.75
Batch: 640; loss: 1.35; acc: 0.53
Batch: 660; loss: 0.93; acc: 0.66
Batch: 680; loss: 1.22; acc: 0.55
Batch: 700; loss: 1.11; acc: 0.56
Batch: 720; loss: 1.36; acc: 0.61
Batch: 740; loss: 1.42; acc: 0.53
Batch: 760; loss: 1.17; acc: 0.64
Batch: 780; loss: 1.45; acc: 0.48
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

2.0382551156217232e-05
5.3671769819629844e-06
Batch: 0; loss: 1.2; acc: 0.58
Batch: 20; loss: 1.3; acc: 0.52
Batch: 40; loss: 1.01; acc: 0.69
Batch: 60; loss: 1.14; acc: 0.59
Batch: 80; loss: 1.15; acc: 0.56
Batch: 100; loss: 1.36; acc: 0.56
Batch: 120; loss: 1.44; acc: 0.58
Batch: 140; loss: 0.95; acc: 0.75
Val Epoch over. val_loss: 1.2907481379569716; val_accuracy: 0.5756369426751592 

The current subspace-distance is: 5.3671769819629844e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.32; acc: 0.59
Batch: 20; loss: 1.29; acc: 0.42
Batch: 40; loss: 1.38; acc: 0.59
Batch: 60; loss: 1.25; acc: 0.66
Batch: 80; loss: 1.18; acc: 0.7
Batch: 100; loss: 1.1; acc: 0.62
Batch: 120; loss: 1.25; acc: 0.58
Batch: 140; loss: 1.22; acc: 0.64
Batch: 160; loss: 1.3; acc: 0.67
Batch: 180; loss: 1.29; acc: 0.58
Batch: 200; loss: 1.33; acc: 0.56
Batch: 220; loss: 1.3; acc: 0.52
Batch: 240; loss: 1.12; acc: 0.64
Batch: 260; loss: 1.42; acc: 0.58
Batch: 280; loss: 1.43; acc: 0.48
Batch: 300; loss: 1.28; acc: 0.61
Batch: 320; loss: 1.37; acc: 0.52
Batch: 340; loss: 1.25; acc: 0.61
Batch: 360; loss: 1.27; acc: 0.59
Batch: 380; loss: 1.37; acc: 0.58
Batch: 400; loss: 1.39; acc: 0.47
Batch: 420; loss: 1.18; acc: 0.61
Batch: 440; loss: 1.39; acc: 0.5
Batch: 460; loss: 0.95; acc: 0.62
Batch: 480; loss: 1.28; acc: 0.58
Batch: 500; loss: 1.24; acc: 0.55
Batch: 520; loss: 1.4; acc: 0.58
Batch: 540; loss: 1.34; acc: 0.56
Batch: 560; loss: 1.63; acc: 0.53
Batch: 580; loss: 1.15; acc: 0.7
Batch: 600; loss: 1.44; acc: 0.52
Batch: 620; loss: 1.33; acc: 0.5
Batch: 640; loss: 1.26; acc: 0.53
Batch: 660; loss: 1.16; acc: 0.7
Batch: 680; loss: 1.34; acc: 0.56
Batch: 700; loss: 1.33; acc: 0.55
Batch: 720; loss: 1.33; acc: 0.56
Batch: 740; loss: 1.33; acc: 0.66
Batch: 760; loss: 1.48; acc: 0.5
Batch: 780; loss: 1.1; acc: 0.62
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.86522702279035e-05
6.518728696391918e-06
Batch: 0; loss: 1.18; acc: 0.59
Batch: 20; loss: 1.29; acc: 0.48
Batch: 40; loss: 1.04; acc: 0.66
Batch: 60; loss: 1.17; acc: 0.58
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.31; acc: 0.56
Batch: 120; loss: 1.38; acc: 0.61
Batch: 140; loss: 0.94; acc: 0.72
Val Epoch over. val_loss: 1.3109552355328942; val_accuracy: 0.5625 

The current subspace-distance is: 6.518728696391918e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.35; acc: 0.5
Batch: 20; loss: 1.36; acc: 0.59
Batch: 40; loss: 1.54; acc: 0.55
Batch: 60; loss: 1.41; acc: 0.45
Batch: 80; loss: 1.41; acc: 0.58
Batch: 100; loss: 1.1; acc: 0.66
Batch: 120; loss: 1.36; acc: 0.58
Batch: 140; loss: 1.46; acc: 0.48
Batch: 160; loss: 1.24; acc: 0.55
Batch: 180; loss: 1.45; acc: 0.53
Batch: 200; loss: 1.09; acc: 0.64
Batch: 220; loss: 1.44; acc: 0.5
Batch: 240; loss: 1.58; acc: 0.5
Batch: 260; loss: 1.18; acc: 0.64
Batch: 280; loss: 1.35; acc: 0.53
Batch: 300; loss: 1.06; acc: 0.66
Batch: 320; loss: 1.31; acc: 0.59
Batch: 340; loss: 1.49; acc: 0.48
Batch: 360; loss: 1.49; acc: 0.48
Batch: 380; loss: 1.31; acc: 0.58
Batch: 400; loss: 1.41; acc: 0.52
Batch: 420; loss: 1.41; acc: 0.52
Batch: 440; loss: 1.42; acc: 0.55
Batch: 460; loss: 1.34; acc: 0.56
Batch: 480; loss: 1.22; acc: 0.56
Batch: 500; loss: 1.29; acc: 0.61
Batch: 520; loss: 1.28; acc: 0.55
Batch: 540; loss: 1.36; acc: 0.55
Batch: 560; loss: 1.42; acc: 0.56
Batch: 580; loss: 1.26; acc: 0.52
Batch: 600; loss: 1.46; acc: 0.55
Batch: 620; loss: 1.53; acc: 0.53
Batch: 640; loss: 1.01; acc: 0.69
Batch: 660; loss: 1.45; acc: 0.52
Batch: 680; loss: 1.63; acc: 0.44
Batch: 700; loss: 1.29; acc: 0.58
Batch: 720; loss: 1.41; acc: 0.52
Batch: 740; loss: 1.19; acc: 0.56
Batch: 760; loss: 1.22; acc: 0.56
Batch: 780; loss: 1.54; acc: 0.52
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.977077772608027e-05
5.735892955271993e-06
Batch: 0; loss: 1.21; acc: 0.58
Batch: 20; loss: 1.26; acc: 0.55
Batch: 40; loss: 1.01; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.59
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.33; acc: 0.55
Batch: 120; loss: 1.41; acc: 0.59
Batch: 140; loss: 0.95; acc: 0.69
Val Epoch over. val_loss: 1.2895846568095457; val_accuracy: 0.5785230891719745 

The current subspace-distance is: 5.735892955271993e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.23; acc: 0.61
Batch: 20; loss: 1.5; acc: 0.5
Batch: 40; loss: 1.36; acc: 0.53
Batch: 60; loss: 1.28; acc: 0.56
Batch: 80; loss: 1.28; acc: 0.55
Batch: 100; loss: 1.32; acc: 0.58
Batch: 120; loss: 1.29; acc: 0.56
Batch: 140; loss: 1.36; acc: 0.59
Batch: 160; loss: 1.43; acc: 0.58
Batch: 180; loss: 1.21; acc: 0.58
Batch: 200; loss: 1.3; acc: 0.55
Batch: 220; loss: 1.18; acc: 0.59
Batch: 240; loss: 1.23; acc: 0.61
Batch: 260; loss: 1.27; acc: 0.56
Batch: 280; loss: 1.39; acc: 0.55
Batch: 300; loss: 1.36; acc: 0.58
Batch: 320; loss: 1.41; acc: 0.55
Batch: 340; loss: 1.32; acc: 0.52
Batch: 360; loss: 1.16; acc: 0.61
Batch: 380; loss: 1.38; acc: 0.52
Batch: 400; loss: 1.23; acc: 0.61
Batch: 420; loss: 1.33; acc: 0.56
Batch: 440; loss: 1.37; acc: 0.48
Batch: 460; loss: 1.07; acc: 0.69
Batch: 480; loss: 1.21; acc: 0.67
Batch: 500; loss: 1.4; acc: 0.55
Batch: 520; loss: 1.28; acc: 0.56
Batch: 540; loss: 1.9; acc: 0.45
Batch: 560; loss: 1.29; acc: 0.53
Batch: 580; loss: 1.25; acc: 0.59
Batch: 600; loss: 1.31; acc: 0.62
Batch: 620; loss: 1.11; acc: 0.64
Batch: 640; loss: 1.27; acc: 0.59
Batch: 660; loss: 1.08; acc: 0.66
Batch: 680; loss: 1.28; acc: 0.55
Batch: 700; loss: 1.28; acc: 0.55
Batch: 720; loss: 1.3; acc: 0.53
Batch: 740; loss: 1.36; acc: 0.62
Batch: 760; loss: 1.46; acc: 0.48
Batch: 780; loss: 1.45; acc: 0.47
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

1.728965617076028e-05
5.798694473924115e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.31; acc: 0.5
Batch: 40; loss: 1.03; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.56
Batch: 80; loss: 1.19; acc: 0.58
Batch: 100; loss: 1.31; acc: 0.58
Batch: 120; loss: 1.34; acc: 0.62
Batch: 140; loss: 0.95; acc: 0.69
Val Epoch over. val_loss: 1.309717778567296; val_accuracy: 0.5666799363057324 

The current subspace-distance is: 5.798694473924115e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.27; acc: 0.58
Batch: 20; loss: 1.27; acc: 0.58
Batch: 40; loss: 1.3; acc: 0.61
Batch: 60; loss: 1.37; acc: 0.53
Batch: 80; loss: 1.34; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.28; acc: 0.61
Batch: 140; loss: 1.45; acc: 0.62
Batch: 160; loss: 1.04; acc: 0.59
Batch: 180; loss: 1.48; acc: 0.53
Batch: 200; loss: 1.37; acc: 0.53
Batch: 220; loss: 1.4; acc: 0.53
Batch: 240; loss: 1.61; acc: 0.53
Batch: 260; loss: 1.33; acc: 0.59
Batch: 280; loss: 1.39; acc: 0.56
Batch: 300; loss: 1.08; acc: 0.67
Batch: 320; loss: 1.43; acc: 0.47
Batch: 340; loss: 1.4; acc: 0.55
Batch: 360; loss: 1.38; acc: 0.5
Batch: 380; loss: 1.35; acc: 0.48
Batch: 400; loss: 1.44; acc: 0.5
Batch: 420; loss: 1.35; acc: 0.52
Batch: 440; loss: 1.36; acc: 0.55
Batch: 460; loss: 1.65; acc: 0.44
Batch: 480; loss: 1.07; acc: 0.59
Batch: 500; loss: 1.39; acc: 0.52
Batch: 520; loss: 1.41; acc: 0.55
Batch: 540; loss: 1.53; acc: 0.48
Batch: 560; loss: 1.45; acc: 0.44
Batch: 580; loss: 1.4; acc: 0.56
Batch: 600; loss: 1.43; acc: 0.56
Batch: 620; loss: 1.07; acc: 0.69
Batch: 640; loss: 1.08; acc: 0.64
Batch: 660; loss: 1.13; acc: 0.56
Batch: 680; loss: 1.38; acc: 0.59
Batch: 700; loss: 1.01; acc: 0.66
Batch: 720; loss: 1.1; acc: 0.59
Batch: 740; loss: 1.37; acc: 0.58
Batch: 760; loss: 1.5; acc: 0.55
Batch: 780; loss: 0.96; acc: 0.69
Train Epoch over. train_loss: 1.3; train_accuracy: 0.57 

2.0654790205298923e-05
5.834439434693195e-06
Batch: 0; loss: 1.19; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.53
Batch: 40; loss: 1.02; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.35; acc: 0.58
Batch: 120; loss: 1.37; acc: 0.61
Batch: 140; loss: 0.93; acc: 0.77
Val Epoch over. val_loss: 1.2912685852141896; val_accuracy: 0.5752388535031847 

The current subspace-distance is: 5.834439434693195e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.36; acc: 0.53
Batch: 20; loss: 1.26; acc: 0.55
Batch: 40; loss: 1.33; acc: 0.52
Batch: 60; loss: 1.47; acc: 0.47
Batch: 80; loss: 1.16; acc: 0.61
Batch: 100; loss: 1.51; acc: 0.48
Batch: 120; loss: 1.21; acc: 0.59
Batch: 140; loss: 1.32; acc: 0.61
Batch: 160; loss: 1.2; acc: 0.53
Batch: 180; loss: 1.22; acc: 0.56
Batch: 200; loss: 1.71; acc: 0.45
Batch: 220; loss: 1.42; acc: 0.48
Batch: 240; loss: 1.26; acc: 0.55
Batch: 260; loss: 1.21; acc: 0.56
Batch: 280; loss: 1.52; acc: 0.5
Batch: 300; loss: 1.16; acc: 0.62
Batch: 320; loss: 1.42; acc: 0.47
Batch: 340; loss: 1.34; acc: 0.55
Batch: 360; loss: 1.08; acc: 0.66
Batch: 380; loss: 1.16; acc: 0.59
Batch: 400; loss: 1.16; acc: 0.62
Batch: 420; loss: 1.53; acc: 0.55
Batch: 440; loss: 1.26; acc: 0.62
Batch: 460; loss: 1.14; acc: 0.61
Batch: 480; loss: 1.31; acc: 0.52
Batch: 500; loss: 1.21; acc: 0.62
Batch: 520; loss: 1.08; acc: 0.67
Batch: 540; loss: 1.23; acc: 0.67
Batch: 560; loss: 1.4; acc: 0.53
Batch: 580; loss: 1.43; acc: 0.55
Batch: 600; loss: 1.28; acc: 0.48
Batch: 620; loss: 1.31; acc: 0.45
Batch: 640; loss: 1.47; acc: 0.53
Batch: 660; loss: 1.29; acc: 0.58
Batch: 680; loss: 1.51; acc: 0.5
Batch: 700; loss: 1.08; acc: 0.62
Batch: 720; loss: 1.17; acc: 0.61
Batch: 740; loss: 1.31; acc: 0.58
Batch: 760; loss: 1.27; acc: 0.58
Batch: 780; loss: 1.32; acc: 0.56
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9416915165493265e-05
6.222491265361896e-06
Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.3; acc: 0.5
Batch: 40; loss: 1.0; acc: 0.67
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.15; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.55
Batch: 120; loss: 1.42; acc: 0.58
Batch: 140; loss: 0.95; acc: 0.72
Val Epoch over. val_loss: 1.2907648227017396; val_accuracy: 0.5730493630573248 

The current subspace-distance is: 6.222491265361896e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.12; acc: 0.67
Batch: 20; loss: 1.23; acc: 0.56
Batch: 40; loss: 1.44; acc: 0.58
Batch: 60; loss: 1.46; acc: 0.44
Batch: 80; loss: 1.22; acc: 0.55
Batch: 100; loss: 1.27; acc: 0.61
Batch: 120; loss: 1.4; acc: 0.55
Batch: 140; loss: 1.28; acc: 0.62
Batch: 160; loss: 1.22; acc: 0.61
Batch: 180; loss: 1.14; acc: 0.59
Batch: 200; loss: 1.13; acc: 0.62
Batch: 220; loss: 1.28; acc: 0.52
Batch: 240; loss: 1.5; acc: 0.5
Batch: 260; loss: 1.39; acc: 0.47
Batch: 280; loss: 1.48; acc: 0.5
Batch: 300; loss: 1.39; acc: 0.53
Batch: 320; loss: 1.08; acc: 0.69
Batch: 340; loss: 1.2; acc: 0.64
Batch: 360; loss: 1.32; acc: 0.61
Batch: 380; loss: 1.36; acc: 0.55
Batch: 400; loss: 1.2; acc: 0.59
Batch: 420; loss: 1.23; acc: 0.55
Batch: 440; loss: 1.31; acc: 0.61
Batch: 460; loss: 1.15; acc: 0.62
Batch: 480; loss: 1.16; acc: 0.67
Batch: 500; loss: 1.18; acc: 0.69
Batch: 520; loss: 1.33; acc: 0.62
Batch: 540; loss: 1.26; acc: 0.59
Batch: 560; loss: 1.3; acc: 0.56
Batch: 580; loss: 1.31; acc: 0.59
Batch: 600; loss: 1.17; acc: 0.55
Batch: 620; loss: 1.3; acc: 0.56
Batch: 640; loss: 1.14; acc: 0.66
Batch: 660; loss: 1.29; acc: 0.61
Batch: 680; loss: 1.28; acc: 0.55
Batch: 700; loss: 1.23; acc: 0.66
Batch: 720; loss: 1.31; acc: 0.58
Batch: 740; loss: 1.32; acc: 0.56
Batch: 760; loss: 1.33; acc: 0.66
Batch: 780; loss: 1.71; acc: 0.42
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.125509490724653e-05
5.763522040069802e-06
Batch: 0; loss: 1.22; acc: 0.56
Batch: 20; loss: 1.3; acc: 0.5
Batch: 40; loss: 1.01; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.13; acc: 0.61
Batch: 100; loss: 1.38; acc: 0.53
Batch: 120; loss: 1.41; acc: 0.59
Batch: 140; loss: 0.94; acc: 0.73
Val Epoch over. val_loss: 1.2886752732999764; val_accuracy: 0.5753383757961783 

The current subspace-distance is: 5.763522040069802e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 1.31; acc: 0.55
Batch: 40; loss: 1.62; acc: 0.45
Batch: 60; loss: 1.39; acc: 0.52
Batch: 80; loss: 1.44; acc: 0.5
Batch: 100; loss: 1.11; acc: 0.58
Batch: 120; loss: 1.1; acc: 0.69
Batch: 140; loss: 1.54; acc: 0.48
Batch: 160; loss: 1.25; acc: 0.58
Batch: 180; loss: 1.5; acc: 0.52
Batch: 200; loss: 1.27; acc: 0.62
Batch: 220; loss: 1.26; acc: 0.56
Batch: 240; loss: 1.12; acc: 0.67
Batch: 260; loss: 1.24; acc: 0.59
Batch: 280; loss: 1.53; acc: 0.52
Batch: 300; loss: 1.06; acc: 0.7
Batch: 320; loss: 1.35; acc: 0.61
Batch: 340; loss: 1.47; acc: 0.52
Batch: 360; loss: 1.08; acc: 0.67
Batch: 380; loss: 1.22; acc: 0.58
Batch: 400; loss: 1.34; acc: 0.58
Batch: 420; loss: 1.25; acc: 0.58
Batch: 440; loss: 1.2; acc: 0.61
Batch: 460; loss: 1.63; acc: 0.52
Batch: 480; loss: 1.39; acc: 0.5
Batch: 500; loss: 1.26; acc: 0.59
Batch: 520; loss: 1.38; acc: 0.58
Batch: 540; loss: 1.24; acc: 0.55
Batch: 560; loss: 1.29; acc: 0.58
Batch: 580; loss: 1.54; acc: 0.48
Batch: 600; loss: 1.4; acc: 0.56
Batch: 620; loss: 1.18; acc: 0.61
Batch: 640; loss: 1.2; acc: 0.58
Batch: 660; loss: 1.48; acc: 0.48
Batch: 680; loss: 1.33; acc: 0.53
Batch: 700; loss: 1.3; acc: 0.61
Batch: 720; loss: 1.26; acc: 0.52
Batch: 740; loss: 1.2; acc: 0.53
Batch: 760; loss: 1.14; acc: 0.58
Batch: 780; loss: 1.38; acc: 0.53
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0181927538942546e-05
6.464914804382715e-06
Batch: 0; loss: 1.18; acc: 0.59
Batch: 20; loss: 1.28; acc: 0.5
Batch: 40; loss: 1.01; acc: 0.69
Batch: 60; loss: 1.13; acc: 0.61
Batch: 80; loss: 1.15; acc: 0.55
Batch: 100; loss: 1.34; acc: 0.58
Batch: 120; loss: 1.39; acc: 0.59
Batch: 140; loss: 0.93; acc: 0.75
Val Epoch over. val_loss: 1.2874576829041644; val_accuracy: 0.5747412420382165 

The current subspace-distance is: 6.464914804382715e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.53; acc: 0.53
Batch: 20; loss: 1.39; acc: 0.55
Batch: 40; loss: 1.44; acc: 0.53
Batch: 60; loss: 1.35; acc: 0.5
Batch: 80; loss: 1.7; acc: 0.45
Batch: 100; loss: 1.03; acc: 0.66
Batch: 120; loss: 1.38; acc: 0.53
Batch: 140; loss: 1.34; acc: 0.53
Batch: 160; loss: 1.38; acc: 0.59
Batch: 180; loss: 1.32; acc: 0.53
Batch: 200; loss: 1.2; acc: 0.61
Batch: 220; loss: 0.98; acc: 0.75
Batch: 240; loss: 1.35; acc: 0.58
Batch: 260; loss: 1.45; acc: 0.61
Batch: 280; loss: 1.43; acc: 0.47
Batch: 300; loss: 1.12; acc: 0.64
Batch: 320; loss: 1.14; acc: 0.62
Batch: 340; loss: 1.27; acc: 0.61
Batch: 360; loss: 1.19; acc: 0.59
Batch: 380; loss: 1.3; acc: 0.62
Batch: 400; loss: 1.32; acc: 0.53
Batch: 420; loss: 1.41; acc: 0.53
Batch: 440; loss: 1.47; acc: 0.58
Batch: 460; loss: 1.18; acc: 0.59
Batch: 480; loss: 1.3; acc: 0.53
Batch: 500; loss: 1.31; acc: 0.56
Batch: 520; loss: 1.29; acc: 0.58
Batch: 540; loss: 1.42; acc: 0.59
Batch: 560; loss: 1.27; acc: 0.62
Batch: 580; loss: 1.25; acc: 0.59
Batch: 600; loss: 1.48; acc: 0.53
Batch: 620; loss: 1.22; acc: 0.55
Batch: 640; loss: 1.1; acc: 0.66
Batch: 660; loss: 1.32; acc: 0.55
Batch: 680; loss: 1.1; acc: 0.59
Batch: 700; loss: 1.31; acc: 0.55
Batch: 720; loss: 1.33; acc: 0.61
Batch: 740; loss: 1.46; acc: 0.52
Batch: 760; loss: 1.23; acc: 0.61
Batch: 780; loss: 1.28; acc: 0.55
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9177070498699322e-05
6.803998076065909e-06
Batch: 0; loss: 1.23; acc: 0.56
Batch: 20; loss: 1.3; acc: 0.53
Batch: 40; loss: 1.01; acc: 0.69
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 1.12; acc: 0.59
Batch: 100; loss: 1.39; acc: 0.53
Batch: 120; loss: 1.43; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.73
Val Epoch over. val_loss: 1.29246570236364; val_accuracy: 0.5765326433121019 

The current subspace-distance is: 6.803998076065909e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.19; acc: 0.56
Batch: 20; loss: 1.21; acc: 0.61
Batch: 40; loss: 1.26; acc: 0.56
Batch: 60; loss: 1.29; acc: 0.55
Batch: 80; loss: 1.08; acc: 0.69
Batch: 100; loss: 1.55; acc: 0.52
Batch: 120; loss: 1.35; acc: 0.55
Batch: 140; loss: 1.17; acc: 0.62
Batch: 160; loss: 1.4; acc: 0.45
Batch: 180; loss: 1.26; acc: 0.58
Batch: 200; loss: 1.2; acc: 0.58
Batch: 220; loss: 1.31; acc: 0.56
Batch: 240; loss: 1.25; acc: 0.59
Batch: 260; loss: 1.3; acc: 0.52
Batch: 280; loss: 1.23; acc: 0.66
Batch: 300; loss: 1.27; acc: 0.55
Batch: 320; loss: 1.2; acc: 0.64
Batch: 340; loss: 1.35; acc: 0.58
Batch: 360; loss: 1.48; acc: 0.52
Batch: 380; loss: 1.39; acc: 0.56
Batch: 400; loss: 1.47; acc: 0.44
Batch: 420; loss: 1.39; acc: 0.53
Batch: 440; loss: 1.25; acc: 0.61
Batch: 460; loss: 1.06; acc: 0.69
Batch: 480; loss: 1.2; acc: 0.66
Batch: 500; loss: 1.42; acc: 0.5
Batch: 520; loss: 1.48; acc: 0.47
Batch: 540; loss: 1.35; acc: 0.58
Batch: 560; loss: 1.26; acc: 0.61
Batch: 580; loss: 0.93; acc: 0.7
Batch: 600; loss: 1.18; acc: 0.61
Batch: 620; loss: 1.44; acc: 0.45
Batch: 640; loss: 1.36; acc: 0.53
Batch: 660; loss: 1.19; acc: 0.7
Batch: 680; loss: 1.11; acc: 0.69
Batch: 700; loss: 1.08; acc: 0.64
Batch: 720; loss: 1.09; acc: 0.59
Batch: 740; loss: 1.39; acc: 0.52
Batch: 760; loss: 1.21; acc: 0.58
Batch: 780; loss: 1.25; acc: 0.53
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.1713218302465975e-05
6.636044872720959e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.5
Batch: 40; loss: 1.0; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.61
Batch: 80; loss: 1.13; acc: 0.56
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.41; acc: 0.58
Batch: 140; loss: 0.95; acc: 0.72
Val Epoch over. val_loss: 1.290435573477654; val_accuracy: 0.5732484076433121 

The current subspace-distance is: 6.636044872720959e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.19; acc: 0.64
Batch: 20; loss: 1.54; acc: 0.53
Batch: 40; loss: 1.3; acc: 0.5
Batch: 60; loss: 1.26; acc: 0.58
Batch: 80; loss: 1.47; acc: 0.53
Batch: 100; loss: 1.07; acc: 0.66
Batch: 120; loss: 1.3; acc: 0.55
Batch: 140; loss: 1.63; acc: 0.48
Batch: 160; loss: 1.16; acc: 0.61
Batch: 180; loss: 1.0; acc: 0.73
Batch: 200; loss: 1.3; acc: 0.56
Batch: 220; loss: 1.3; acc: 0.61
Batch: 240; loss: 1.37; acc: 0.53
Batch: 260; loss: 1.28; acc: 0.59
Batch: 280; loss: 1.54; acc: 0.47
Batch: 300; loss: 1.46; acc: 0.58
Batch: 320; loss: 1.72; acc: 0.42
Batch: 340; loss: 1.09; acc: 0.69
Batch: 360; loss: 1.24; acc: 0.58
Batch: 380; loss: 1.23; acc: 0.67
Batch: 400; loss: 1.25; acc: 0.55
Batch: 420; loss: 1.28; acc: 0.52
Batch: 440; loss: 1.53; acc: 0.48
Batch: 460; loss: 1.29; acc: 0.58
Batch: 480; loss: 1.23; acc: 0.59
Batch: 500; loss: 1.4; acc: 0.55
Batch: 520; loss: 1.03; acc: 0.72
Batch: 540; loss: 1.27; acc: 0.62
Batch: 560; loss: 1.02; acc: 0.62
Batch: 580; loss: 1.04; acc: 0.61
Batch: 600; loss: 1.39; acc: 0.53
Batch: 620; loss: 1.34; acc: 0.55
Batch: 640; loss: 1.16; acc: 0.58
Batch: 660; loss: 1.53; acc: 0.47
Batch: 680; loss: 1.58; acc: 0.64
Batch: 700; loss: 1.28; acc: 0.53
Batch: 720; loss: 1.47; acc: 0.48
Batch: 740; loss: 1.11; acc: 0.59
Batch: 760; loss: 1.23; acc: 0.58
Batch: 780; loss: 1.24; acc: 0.59
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0271463654353283e-05
6.693519480904797e-06
Batch: 0; loss: 1.2; acc: 0.61
Batch: 20; loss: 1.3; acc: 0.52
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.13; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.56
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 0.95; acc: 0.73
Val Epoch over. val_loss: 1.2902128935619523; val_accuracy: 0.5749402866242038 

The current subspace-distance is: 6.693519480904797e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.32; acc: 0.53
Batch: 20; loss: 1.27; acc: 0.61
Batch: 40; loss: 1.29; acc: 0.55
Batch: 60; loss: 1.25; acc: 0.66
Batch: 80; loss: 1.43; acc: 0.55
Batch: 100; loss: 1.43; acc: 0.59
Batch: 120; loss: 1.25; acc: 0.62
Batch: 140; loss: 1.3; acc: 0.52
Batch: 160; loss: 1.4; acc: 0.55
Batch: 180; loss: 1.35; acc: 0.55
Batch: 200; loss: 1.11; acc: 0.58
Batch: 220; loss: 1.3; acc: 0.61
Batch: 240; loss: 1.21; acc: 0.58
Batch: 260; loss: 1.19; acc: 0.67
Batch: 280; loss: 1.27; acc: 0.56
Batch: 300; loss: 1.2; acc: 0.59
Batch: 320; loss: 1.17; acc: 0.61
Batch: 340; loss: 1.36; acc: 0.55
Batch: 360; loss: 1.29; acc: 0.59
Batch: 380; loss: 1.32; acc: 0.56
Batch: 400; loss: 1.15; acc: 0.62
Batch: 420; loss: 1.49; acc: 0.45
Batch: 440; loss: 1.2; acc: 0.56
Batch: 460; loss: 1.0; acc: 0.73
Batch: 480; loss: 1.18; acc: 0.64
Batch: 500; loss: 1.12; acc: 0.64
Batch: 520; loss: 1.42; acc: 0.48
Batch: 540; loss: 1.49; acc: 0.52
Batch: 560; loss: 1.18; acc: 0.64
Batch: 580; loss: 1.1; acc: 0.61
Batch: 600; loss: 1.49; acc: 0.47
Batch: 620; loss: 1.23; acc: 0.61
Batch: 640; loss: 1.22; acc: 0.59
Batch: 660; loss: 1.28; acc: 0.53
Batch: 680; loss: 1.37; acc: 0.58
Batch: 700; loss: 1.15; acc: 0.64
Batch: 720; loss: 1.26; acc: 0.61
Batch: 740; loss: 1.25; acc: 0.64
Batch: 760; loss: 1.17; acc: 0.69
Batch: 780; loss: 1.14; acc: 0.56
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.7721096810419112e-05
6.563211627508281e-06
Batch: 0; loss: 1.22; acc: 0.59
Batch: 20; loss: 1.33; acc: 0.56
Batch: 40; loss: 1.0; acc: 0.72
Batch: 60; loss: 1.1; acc: 0.61
Batch: 80; loss: 1.11; acc: 0.56
Batch: 100; loss: 1.38; acc: 0.55
Batch: 120; loss: 1.43; acc: 0.58
Batch: 140; loss: 0.96; acc: 0.72
Val Epoch over. val_loss: 1.2966323734089067; val_accuracy: 0.5738455414012739 

The current subspace-distance is: 6.563211627508281e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.35; acc: 0.53
Batch: 20; loss: 1.44; acc: 0.53
Batch: 40; loss: 1.23; acc: 0.64
Batch: 60; loss: 1.4; acc: 0.48
Batch: 80; loss: 1.46; acc: 0.47
Batch: 100; loss: 1.46; acc: 0.53
Batch: 120; loss: 1.43; acc: 0.62
Batch: 140; loss: 1.05; acc: 0.66
Batch: 160; loss: 1.46; acc: 0.55
Batch: 180; loss: 1.13; acc: 0.62
Batch: 200; loss: 1.26; acc: 0.59
Batch: 220; loss: 1.3; acc: 0.66
Batch: 240; loss: 1.49; acc: 0.55
Batch: 260; loss: 1.1; acc: 0.59
Batch: 280; loss: 1.36; acc: 0.59
Batch: 300; loss: 1.51; acc: 0.52
Batch: 320; loss: 1.14; acc: 0.62
Batch: 340; loss: 1.14; acc: 0.62
Batch: 360; loss: 1.13; acc: 0.61
Batch: 380; loss: 1.42; acc: 0.52
Batch: 400; loss: 1.46; acc: 0.55
Batch: 420; loss: 1.43; acc: 0.55
Batch: 440; loss: 1.34; acc: 0.44
Batch: 460; loss: 1.28; acc: 0.58
Batch: 480; loss: 1.58; acc: 0.56
Batch: 500; loss: 1.27; acc: 0.55
Batch: 520; loss: 1.43; acc: 0.59
Batch: 540; loss: 1.32; acc: 0.61
Batch: 560; loss: 1.33; acc: 0.59
Batch: 580; loss: 1.15; acc: 0.69
Batch: 600; loss: 1.46; acc: 0.5
Batch: 620; loss: 1.44; acc: 0.5
Batch: 640; loss: 1.28; acc: 0.61
Batch: 660; loss: 1.22; acc: 0.67
Batch: 680; loss: 1.38; acc: 0.52
Batch: 700; loss: 1.2; acc: 0.56
Batch: 720; loss: 1.34; acc: 0.56
Batch: 740; loss: 1.14; acc: 0.7
Batch: 760; loss: 1.46; acc: 0.52
Batch: 780; loss: 1.33; acc: 0.5
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.2445941795012914e-05
7.1079120971262455e-06
Batch: 0; loss: 1.2; acc: 0.58
Batch: 20; loss: 1.28; acc: 0.5
Batch: 40; loss: 1.01; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.35; acc: 0.53
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.94; acc: 0.73
Val Epoch over. val_loss: 1.2860598249040591; val_accuracy: 0.576234076433121 

The current subspace-distance is: 7.1079120971262455e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.46; acc: 0.53
Batch: 20; loss: 1.55; acc: 0.47
Batch: 40; loss: 1.35; acc: 0.59
Batch: 60; loss: 1.43; acc: 0.47
Batch: 80; loss: 1.47; acc: 0.55
Batch: 100; loss: 1.21; acc: 0.61
Batch: 120; loss: 1.3; acc: 0.58
Batch: 140; loss: 1.27; acc: 0.59
Batch: 160; loss: 1.2; acc: 0.66
Batch: 180; loss: 1.08; acc: 0.58
Batch: 200; loss: 1.44; acc: 0.5
Batch: 220; loss: 1.39; acc: 0.55
Batch: 240; loss: 1.14; acc: 0.56
Batch: 260; loss: 1.28; acc: 0.62
Batch: 280; loss: 1.43; acc: 0.45
Batch: 300; loss: 1.31; acc: 0.56
Batch: 320; loss: 1.47; acc: 0.53
Batch: 340; loss: 1.36; acc: 0.53
Batch: 360; loss: 1.0; acc: 0.77
Batch: 380; loss: 1.39; acc: 0.52
Batch: 400; loss: 1.32; acc: 0.58
Batch: 420; loss: 1.36; acc: 0.56
Batch: 440; loss: 1.39; acc: 0.62
Batch: 460; loss: 1.14; acc: 0.62
Batch: 480; loss: 1.24; acc: 0.61
Batch: 500; loss: 1.26; acc: 0.53
Batch: 520; loss: 1.39; acc: 0.52
Batch: 540; loss: 1.3; acc: 0.69
Batch: 560; loss: 1.42; acc: 0.53
Batch: 580; loss: 1.23; acc: 0.59
Batch: 600; loss: 1.27; acc: 0.61
Batch: 620; loss: 1.37; acc: 0.45
Batch: 640; loss: 1.34; acc: 0.55
Batch: 660; loss: 1.19; acc: 0.62
Batch: 680; loss: 1.3; acc: 0.59
Batch: 700; loss: 1.25; acc: 0.56
Batch: 720; loss: 1.09; acc: 0.69
Batch: 740; loss: 1.64; acc: 0.53
Batch: 760; loss: 1.43; acc: 0.56
Batch: 780; loss: 1.07; acc: 0.58
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9639306628960185e-05
6.089216185500845e-06
Batch: 0; loss: 1.19; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.69
Batch: 60; loss: 1.13; acc: 0.58
Batch: 80; loss: 1.16; acc: 0.56
Batch: 100; loss: 1.35; acc: 0.55
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 0.91; acc: 0.75
Val Epoch over. val_loss: 1.2858119447519825; val_accuracy: 0.5738455414012739 

The current subspace-distance is: 6.089216185500845e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.24; acc: 0.61
Batch: 20; loss: 1.73; acc: 0.52
Batch: 40; loss: 1.1; acc: 0.67
Batch: 60; loss: 1.19; acc: 0.64
Batch: 80; loss: 1.31; acc: 0.58
Batch: 100; loss: 0.95; acc: 0.67
Batch: 120; loss: 1.59; acc: 0.48
Batch: 140; loss: 1.29; acc: 0.59
Batch: 160; loss: 1.3; acc: 0.48
Batch: 180; loss: 1.3; acc: 0.55
Batch: 200; loss: 1.4; acc: 0.53
Batch: 220; loss: 1.47; acc: 0.62
Batch: 240; loss: 1.67; acc: 0.47
Batch: 260; loss: 1.48; acc: 0.59
Batch: 280; loss: 1.18; acc: 0.62
Batch: 300; loss: 1.3; acc: 0.56
Batch: 320; loss: 1.29; acc: 0.53
Batch: 340; loss: 1.34; acc: 0.53
Batch: 360; loss: 1.38; acc: 0.52
Batch: 380; loss: 1.43; acc: 0.53
Batch: 400; loss: 1.2; acc: 0.66
Batch: 420; loss: 1.36; acc: 0.53
Batch: 440; loss: 1.3; acc: 0.5
Batch: 460; loss: 1.43; acc: 0.5
Batch: 480; loss: 1.14; acc: 0.61
Batch: 500; loss: 1.14; acc: 0.61
Batch: 520; loss: 1.25; acc: 0.64
Batch: 540; loss: 1.34; acc: 0.62
Batch: 560; loss: 1.32; acc: 0.58
Batch: 580; loss: 1.49; acc: 0.52
Batch: 600; loss: 1.29; acc: 0.53
Batch: 620; loss: 1.31; acc: 0.59
Batch: 640; loss: 1.12; acc: 0.59
Batch: 660; loss: 1.2; acc: 0.56
Batch: 680; loss: 1.2; acc: 0.59
Batch: 700; loss: 1.2; acc: 0.62
Batch: 720; loss: 1.08; acc: 0.67
Batch: 740; loss: 1.39; acc: 0.62
Batch: 760; loss: 1.2; acc: 0.62
Batch: 780; loss: 1.46; acc: 0.62
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9679388060467318e-05
5.4279976211546455e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.53
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.13; acc: 0.59
Batch: 80; loss: 1.15; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.56
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.77
Val Epoch over. val_loss: 1.2871311508166563; val_accuracy: 0.575437898089172 

The current subspace-distance is: 5.4279976211546455e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.34; acc: 0.58
Batch: 20; loss: 1.13; acc: 0.59
Batch: 40; loss: 1.42; acc: 0.53
Batch: 60; loss: 1.2; acc: 0.64
Batch: 80; loss: 0.92; acc: 0.77
Batch: 100; loss: 1.12; acc: 0.64
Batch: 120; loss: 1.35; acc: 0.59
Batch: 140; loss: 1.09; acc: 0.64
Batch: 160; loss: 1.05; acc: 0.67
Batch: 180; loss: 1.38; acc: 0.55
Batch: 200; loss: 1.1; acc: 0.62
Batch: 220; loss: 1.2; acc: 0.61
Batch: 240; loss: 1.15; acc: 0.62
Batch: 260; loss: 1.19; acc: 0.64
Batch: 280; loss: 1.3; acc: 0.72
Batch: 300; loss: 1.19; acc: 0.59
Batch: 320; loss: 1.45; acc: 0.5
Batch: 340; loss: 1.39; acc: 0.58
Batch: 360; loss: 1.3; acc: 0.55
Batch: 380; loss: 1.19; acc: 0.62
Batch: 400; loss: 1.12; acc: 0.67
Batch: 420; loss: 1.28; acc: 0.56
Batch: 440; loss: 1.39; acc: 0.53
Batch: 460; loss: 1.6; acc: 0.5
Batch: 480; loss: 1.41; acc: 0.53
Batch: 500; loss: 1.26; acc: 0.58
Batch: 520; loss: 1.23; acc: 0.62
Batch: 540; loss: 1.07; acc: 0.64
Batch: 560; loss: 1.27; acc: 0.59
Batch: 580; loss: 1.55; acc: 0.56
Batch: 600; loss: 1.23; acc: 0.58
Batch: 620; loss: 1.27; acc: 0.55
Batch: 640; loss: 1.34; acc: 0.58
Batch: 660; loss: 1.36; acc: 0.52
Batch: 680; loss: 1.39; acc: 0.52
Batch: 700; loss: 1.38; acc: 0.55
Batch: 720; loss: 1.56; acc: 0.52
Batch: 740; loss: 1.37; acc: 0.52
Batch: 760; loss: 1.26; acc: 0.61
Batch: 780; loss: 1.43; acc: 0.45
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9128498024656437e-05
6.288455097092083e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.58
Batch: 80; loss: 1.13; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.56
Batch: 120; loss: 1.37; acc: 0.59
Batch: 140; loss: 0.93; acc: 0.75
Val Epoch over. val_loss: 1.2838838275071163; val_accuracy: 0.5789211783439491 

The current subspace-distance is: 6.288455097092083e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.23; acc: 0.59
Batch: 20; loss: 1.3; acc: 0.64
Batch: 40; loss: 1.29; acc: 0.59
Batch: 60; loss: 1.24; acc: 0.61
Batch: 80; loss: 1.41; acc: 0.59
Batch: 100; loss: 1.41; acc: 0.5
Batch: 120; loss: 1.2; acc: 0.62
Batch: 140; loss: 1.29; acc: 0.56
Batch: 160; loss: 1.5; acc: 0.56
Batch: 180; loss: 1.48; acc: 0.55
Batch: 200; loss: 1.62; acc: 0.55
Batch: 220; loss: 1.24; acc: 0.64
Batch: 240; loss: 1.33; acc: 0.56
Batch: 260; loss: 1.46; acc: 0.55
Batch: 280; loss: 1.29; acc: 0.53
Batch: 300; loss: 1.24; acc: 0.62
Batch: 320; loss: 1.01; acc: 0.66
Batch: 340; loss: 1.06; acc: 0.62
Batch: 360; loss: 1.38; acc: 0.55
Batch: 380; loss: 1.26; acc: 0.58
Batch: 400; loss: 1.31; acc: 0.55
Batch: 420; loss: 1.32; acc: 0.53
Batch: 440; loss: 1.33; acc: 0.53
Batch: 460; loss: 1.17; acc: 0.56
Batch: 480; loss: 1.27; acc: 0.56
Batch: 500; loss: 1.09; acc: 0.62
Batch: 520; loss: 1.49; acc: 0.48
Batch: 540; loss: 1.35; acc: 0.55
Batch: 560; loss: 1.46; acc: 0.47
Batch: 580; loss: 1.52; acc: 0.52
Batch: 600; loss: 1.31; acc: 0.5
Batch: 620; loss: 1.29; acc: 0.52
Batch: 640; loss: 1.12; acc: 0.69
Batch: 660; loss: 1.12; acc: 0.64
Batch: 680; loss: 1.35; acc: 0.55
Batch: 700; loss: 0.94; acc: 0.77
Batch: 720; loss: 0.99; acc: 0.67
Batch: 740; loss: 1.11; acc: 0.62
Batch: 760; loss: 1.32; acc: 0.56
Batch: 780; loss: 1.52; acc: 0.56
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.068748653982766e-05
5.691105343430536e-06
Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.29; acc: 0.53
Batch: 40; loss: 1.01; acc: 0.67
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.12; acc: 0.61
Batch: 100; loss: 1.38; acc: 0.52
Batch: 120; loss: 1.4; acc: 0.59
Batch: 140; loss: 0.94; acc: 0.73
Val Epoch over. val_loss: 1.288230030020331; val_accuracy: 0.5772292993630573 

The current subspace-distance is: 5.691105343430536e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.14; acc: 0.67
Batch: 20; loss: 1.25; acc: 0.67
Batch: 40; loss: 1.19; acc: 0.59
Batch: 60; loss: 1.3; acc: 0.55
Batch: 80; loss: 1.28; acc: 0.56
Batch: 100; loss: 1.41; acc: 0.59
Batch: 120; loss: 1.2; acc: 0.62
Batch: 140; loss: 1.38; acc: 0.52
Batch: 160; loss: 1.35; acc: 0.55
Batch: 180; loss: 1.27; acc: 0.55
Batch: 200; loss: 1.08; acc: 0.7
Batch: 220; loss: 1.5; acc: 0.47
Batch: 240; loss: 1.37; acc: 0.48
Batch: 260; loss: 1.48; acc: 0.61
Batch: 280; loss: 1.23; acc: 0.64
Batch: 300; loss: 1.18; acc: 0.59
Batch: 320; loss: 1.35; acc: 0.62
Batch: 340; loss: 1.3; acc: 0.55
Batch: 360; loss: 1.25; acc: 0.58
Batch: 380; loss: 1.24; acc: 0.59
Batch: 400; loss: 1.35; acc: 0.55
Batch: 420; loss: 1.31; acc: 0.56
Batch: 440; loss: 1.41; acc: 0.53
Batch: 460; loss: 1.3; acc: 0.61
Batch: 480; loss: 1.23; acc: 0.59
Batch: 500; loss: 1.16; acc: 0.64
Batch: 520; loss: 1.44; acc: 0.55
Batch: 540; loss: 1.07; acc: 0.64
Batch: 560; loss: 1.29; acc: 0.59
Batch: 580; loss: 1.26; acc: 0.53
Batch: 600; loss: 1.05; acc: 0.66
Batch: 620; loss: 1.26; acc: 0.59
Batch: 640; loss: 1.38; acc: 0.53
Batch: 660; loss: 1.59; acc: 0.5
Batch: 680; loss: 1.15; acc: 0.69
Batch: 700; loss: 1.21; acc: 0.64
Batch: 720; loss: 1.54; acc: 0.5
Batch: 740; loss: 1.2; acc: 0.61
Batch: 760; loss: 1.37; acc: 0.53
Batch: 780; loss: 1.45; acc: 0.5
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.1944535546936095e-05
5.83698647460551e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.15; acc: 0.59
Batch: 100; loss: 1.35; acc: 0.55
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.73
Val Epoch over. val_loss: 1.2839493812269467; val_accuracy: 0.5782245222929936 

The current subspace-distance is: 5.83698647460551e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.35; acc: 0.56
Batch: 20; loss: 1.22; acc: 0.59
Batch: 40; loss: 1.29; acc: 0.61
Batch: 60; loss: 1.47; acc: 0.59
Batch: 80; loss: 1.42; acc: 0.52
Batch: 100; loss: 1.39; acc: 0.53
Batch: 120; loss: 1.32; acc: 0.55
Batch: 140; loss: 1.4; acc: 0.5
Batch: 160; loss: 1.14; acc: 0.59
Batch: 180; loss: 1.18; acc: 0.58
Batch: 200; loss: 1.49; acc: 0.52
Batch: 220; loss: 1.21; acc: 0.64
Batch: 240; loss: 1.3; acc: 0.64
Batch: 260; loss: 1.31; acc: 0.52
Batch: 280; loss: 1.15; acc: 0.66
Batch: 300; loss: 1.45; acc: 0.52
Batch: 320; loss: 1.13; acc: 0.56
Batch: 340; loss: 1.18; acc: 0.64
Batch: 360; loss: 1.21; acc: 0.61
Batch: 380; loss: 0.82; acc: 0.73
Batch: 400; loss: 1.12; acc: 0.58
Batch: 420; loss: 1.63; acc: 0.44
Batch: 440; loss: 1.3; acc: 0.55
Batch: 460; loss: 1.32; acc: 0.52
Batch: 480; loss: 1.26; acc: 0.55
Batch: 500; loss: 1.09; acc: 0.64
Batch: 520; loss: 1.49; acc: 0.5
Batch: 540; loss: 1.37; acc: 0.5
Batch: 560; loss: 1.12; acc: 0.62
Batch: 580; loss: 1.23; acc: 0.61
Batch: 600; loss: 1.51; acc: 0.58
Batch: 620; loss: 1.4; acc: 0.61
Batch: 640; loss: 1.4; acc: 0.58
Batch: 660; loss: 1.18; acc: 0.58
Batch: 680; loss: 1.33; acc: 0.52
Batch: 700; loss: 1.13; acc: 0.55
Batch: 720; loss: 1.22; acc: 0.62
Batch: 740; loss: 1.46; acc: 0.5
Batch: 760; loss: 1.28; acc: 0.59
Batch: 780; loss: 1.12; acc: 0.58
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.2001739125698805e-05
7.505314897571225e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.77
Val Epoch over. val_loss: 1.2840111768169769; val_accuracy: 0.57921974522293 

The current subspace-distance is: 7.505314897571225e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.32; acc: 0.59
Batch: 20; loss: 1.29; acc: 0.59
Batch: 40; loss: 1.31; acc: 0.58
Batch: 60; loss: 1.2; acc: 0.64
Batch: 80; loss: 1.59; acc: 0.48
Batch: 100; loss: 1.13; acc: 0.64
Batch: 120; loss: 1.24; acc: 0.56
Batch: 140; loss: 1.38; acc: 0.5
Batch: 160; loss: 1.38; acc: 0.58
Batch: 180; loss: 1.1; acc: 0.62
Batch: 200; loss: 1.13; acc: 0.56
Batch: 220; loss: 0.98; acc: 0.73
Batch: 240; loss: 1.44; acc: 0.47
Batch: 260; loss: 1.4; acc: 0.56
Batch: 280; loss: 1.36; acc: 0.55
Batch: 300; loss: 1.34; acc: 0.59
Batch: 320; loss: 1.37; acc: 0.55
Batch: 340; loss: 1.2; acc: 0.53
Batch: 360; loss: 1.35; acc: 0.59
Batch: 380; loss: 1.34; acc: 0.56
Batch: 400; loss: 1.46; acc: 0.58
Batch: 420; loss: 1.22; acc: 0.59
Batch: 440; loss: 1.08; acc: 0.67
Batch: 460; loss: 1.11; acc: 0.62
Batch: 480; loss: 1.31; acc: 0.53
Batch: 500; loss: 1.21; acc: 0.61
Batch: 520; loss: 1.05; acc: 0.64
Batch: 540; loss: 1.31; acc: 0.56
Batch: 560; loss: 1.33; acc: 0.45
Batch: 580; loss: 1.44; acc: 0.58
Batch: 600; loss: 1.24; acc: 0.58
Batch: 620; loss: 1.37; acc: 0.5
Batch: 640; loss: 1.21; acc: 0.66
Batch: 660; loss: 1.29; acc: 0.56
Batch: 680; loss: 1.38; acc: 0.55
Batch: 700; loss: 1.3; acc: 0.62
Batch: 720; loss: 1.24; acc: 0.62
Batch: 740; loss: 1.41; acc: 0.47
Batch: 760; loss: 1.3; acc: 0.64
Batch: 780; loss: 1.24; acc: 0.61
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0647385099437088e-05
7.20621346772532e-06
Batch: 0; loss: 1.22; acc: 0.59
Batch: 20; loss: 1.28; acc: 0.53
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.56
Batch: 80; loss: 1.14; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.39; acc: 0.58
Batch: 140; loss: 0.93; acc: 0.75
Val Epoch over. val_loss: 1.2858670426022476; val_accuracy: 0.5767316878980892 

The current subspace-distance is: 7.20621346772532e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.29; acc: 0.58
Batch: 20; loss: 1.26; acc: 0.58
Batch: 40; loss: 1.19; acc: 0.61
Batch: 60; loss: 1.2; acc: 0.62
Batch: 80; loss: 1.32; acc: 0.56
Batch: 100; loss: 1.21; acc: 0.67
Batch: 120; loss: 1.21; acc: 0.53
Batch: 140; loss: 1.22; acc: 0.64
Batch: 160; loss: 1.11; acc: 0.61
Batch: 180; loss: 1.18; acc: 0.67
Batch: 200; loss: 1.27; acc: 0.53
Batch: 220; loss: 1.22; acc: 0.61
Batch: 240; loss: 1.41; acc: 0.53
Batch: 260; loss: 1.47; acc: 0.44
Batch: 280; loss: 1.17; acc: 0.62
Batch: 300; loss: 1.33; acc: 0.56
Batch: 320; loss: 1.33; acc: 0.55
Batch: 340; loss: 1.2; acc: 0.61
Batch: 360; loss: 1.32; acc: 0.61
Batch: 380; loss: 1.09; acc: 0.59
Batch: 400; loss: 1.29; acc: 0.59
Batch: 420; loss: 1.41; acc: 0.61
Batch: 440; loss: 1.16; acc: 0.61
Batch: 460; loss: 1.19; acc: 0.66
Batch: 480; loss: 1.5; acc: 0.52
Batch: 500; loss: 1.5; acc: 0.5
Batch: 520; loss: 1.49; acc: 0.48
Batch: 540; loss: 1.31; acc: 0.53
Batch: 560; loss: 1.34; acc: 0.52
Batch: 580; loss: 1.44; acc: 0.56
Batch: 600; loss: 0.91; acc: 0.73
Batch: 620; loss: 1.35; acc: 0.59
Batch: 640; loss: 1.42; acc: 0.55
Batch: 660; loss: 1.36; acc: 0.58
Batch: 680; loss: 1.05; acc: 0.66
Batch: 700; loss: 1.43; acc: 0.58
Batch: 720; loss: 1.38; acc: 0.56
Batch: 740; loss: 1.29; acc: 0.58
Batch: 760; loss: 1.42; acc: 0.52
Batch: 780; loss: 1.19; acc: 0.59
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.173532993765548e-05
6.018280600983417e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.36; acc: 0.53
Batch: 120; loss: 1.38; acc: 0.59
Batch: 140; loss: 0.92; acc: 0.78
Val Epoch over. val_loss: 1.2840425596115694; val_accuracy: 0.5760350318471338 

The current subspace-distance is: 6.018280600983417e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.14; acc: 0.58
Batch: 20; loss: 1.2; acc: 0.58
Batch: 40; loss: 1.27; acc: 0.52
Batch: 60; loss: 1.28; acc: 0.62
Batch: 80; loss: 1.36; acc: 0.52
Batch: 100; loss: 1.29; acc: 0.61
Batch: 120; loss: 1.18; acc: 0.66
Batch: 140; loss: 1.43; acc: 0.52
Batch: 160; loss: 1.23; acc: 0.59
Batch: 180; loss: 1.37; acc: 0.58
Batch: 200; loss: 1.61; acc: 0.48
Batch: 220; loss: 1.41; acc: 0.62
Batch: 240; loss: 1.41; acc: 0.53
Batch: 260; loss: 1.38; acc: 0.53
Batch: 280; loss: 1.05; acc: 0.7
Batch: 300; loss: 1.27; acc: 0.58
Batch: 320; loss: 1.32; acc: 0.58
Batch: 340; loss: 1.21; acc: 0.61
Batch: 360; loss: 1.44; acc: 0.45
Batch: 380; loss: 1.44; acc: 0.53
Batch: 400; loss: 1.31; acc: 0.55
Batch: 420; loss: 1.66; acc: 0.44
Batch: 440; loss: 1.33; acc: 0.66
Batch: 460; loss: 1.04; acc: 0.7
Batch: 480; loss: 1.52; acc: 0.58
Batch: 500; loss: 1.25; acc: 0.62
Batch: 520; loss: 1.53; acc: 0.52
Batch: 540; loss: 1.07; acc: 0.72
Batch: 560; loss: 1.2; acc: 0.58
Batch: 580; loss: 1.32; acc: 0.59
Batch: 600; loss: 1.13; acc: 0.61
Batch: 620; loss: 1.39; acc: 0.58
Batch: 640; loss: 1.16; acc: 0.7
Batch: 660; loss: 1.49; acc: 0.52
Batch: 680; loss: 1.3; acc: 0.58
Batch: 700; loss: 1.44; acc: 0.52
Batch: 720; loss: 1.41; acc: 0.53
Batch: 740; loss: 1.38; acc: 0.55
Batch: 760; loss: 1.32; acc: 0.56
Batch: 780; loss: 1.1; acc: 0.59
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.929676000145264e-05
6.265726369747426e-06
Batch: 0; loss: 1.21; acc: 0.58
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.67
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.13; acc: 0.61
Batch: 100; loss: 1.36; acc: 0.55
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.93; acc: 0.75
Val Epoch over. val_loss: 1.2839013197619444; val_accuracy: 0.5806130573248408 

The current subspace-distance is: 6.265726369747426e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.32; acc: 0.53
Batch: 20; loss: 1.23; acc: 0.61
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.36; acc: 0.58
Batch: 80; loss: 1.07; acc: 0.7
Batch: 100; loss: 1.17; acc: 0.66
Batch: 120; loss: 1.32; acc: 0.55
Batch: 140; loss: 1.3; acc: 0.59
Batch: 160; loss: 1.09; acc: 0.62
Batch: 180; loss: 1.36; acc: 0.48
Batch: 200; loss: 1.16; acc: 0.64
Batch: 220; loss: 1.06; acc: 0.64
Batch: 240; loss: 1.46; acc: 0.55
Batch: 260; loss: 1.45; acc: 0.58
Batch: 280; loss: 1.16; acc: 0.67
Batch: 300; loss: 1.13; acc: 0.61
Batch: 320; loss: 1.33; acc: 0.61
Batch: 340; loss: 1.41; acc: 0.59
Batch: 360; loss: 1.18; acc: 0.67
Batch: 380; loss: 1.27; acc: 0.55
Batch: 400; loss: 1.54; acc: 0.48
Batch: 420; loss: 1.52; acc: 0.55
Batch: 440; loss: 1.55; acc: 0.56
Batch: 460; loss: 1.34; acc: 0.56
Batch: 480; loss: 1.18; acc: 0.64
Batch: 500; loss: 1.46; acc: 0.55
Batch: 520; loss: 1.29; acc: 0.64
Batch: 540; loss: 1.34; acc: 0.48
Batch: 560; loss: 1.24; acc: 0.56
Batch: 580; loss: 1.02; acc: 0.66
Batch: 600; loss: 1.31; acc: 0.53
Batch: 620; loss: 1.28; acc: 0.58
Batch: 640; loss: 1.18; acc: 0.62
Batch: 660; loss: 1.31; acc: 0.53
Batch: 680; loss: 1.14; acc: 0.58
Batch: 700; loss: 1.27; acc: 0.58
Batch: 720; loss: 1.02; acc: 0.66
Batch: 740; loss: 1.58; acc: 0.47
Batch: 760; loss: 1.38; acc: 0.58
Batch: 780; loss: 1.38; acc: 0.53
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.8867935068556108e-05
5.7145621212839615e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.93; acc: 0.73
Val Epoch over. val_loss: 1.2838665968293597; val_accuracy: 0.57921974522293 

The current subspace-distance is: 5.7145621212839615e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.35; acc: 0.58
Batch: 20; loss: 1.22; acc: 0.56
Batch: 40; loss: 1.26; acc: 0.59
Batch: 60; loss: 1.37; acc: 0.53
Batch: 80; loss: 1.05; acc: 0.7
Batch: 100; loss: 1.14; acc: 0.69
Batch: 120; loss: 1.52; acc: 0.53
Batch: 140; loss: 1.33; acc: 0.58
Batch: 160; loss: 1.19; acc: 0.58
Batch: 180; loss: 1.43; acc: 0.5
Batch: 200; loss: 1.36; acc: 0.55
Batch: 220; loss: 1.17; acc: 0.61
Batch: 240; loss: 1.49; acc: 0.47
Batch: 260; loss: 1.23; acc: 0.58
Batch: 280; loss: 1.3; acc: 0.55
Batch: 300; loss: 1.33; acc: 0.47
Batch: 320; loss: 1.25; acc: 0.56
Batch: 340; loss: 1.39; acc: 0.48
Batch: 360; loss: 1.23; acc: 0.61
Batch: 380; loss: 1.17; acc: 0.59
Batch: 400; loss: 1.18; acc: 0.66
Batch: 420; loss: 1.55; acc: 0.52
Batch: 440; loss: 1.34; acc: 0.56
Batch: 460; loss: 1.42; acc: 0.5
Batch: 480; loss: 1.5; acc: 0.45
Batch: 500; loss: 1.42; acc: 0.5
Batch: 520; loss: 1.23; acc: 0.59
Batch: 540; loss: 1.31; acc: 0.58
Batch: 560; loss: 1.29; acc: 0.59
Batch: 580; loss: 1.29; acc: 0.5
Batch: 600; loss: 1.31; acc: 0.58
Batch: 620; loss: 1.35; acc: 0.55
Batch: 640; loss: 1.39; acc: 0.58
Batch: 660; loss: 1.34; acc: 0.55
Batch: 680; loss: 1.41; acc: 0.58
Batch: 700; loss: 1.16; acc: 0.64
Batch: 720; loss: 1.34; acc: 0.58
Batch: 740; loss: 1.18; acc: 0.59
Batch: 760; loss: 1.04; acc: 0.7
Batch: 780; loss: 1.23; acc: 0.59
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9670362235046923e-05
5.6030421546893194e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.75
Val Epoch over. val_loss: 1.2837889680437222; val_accuracy: 0.5790207006369427 

The current subspace-distance is: 5.6030421546893194e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.28; acc: 0.53
Batch: 20; loss: 1.48; acc: 0.53
Batch: 40; loss: 1.3; acc: 0.61
Batch: 60; loss: 1.16; acc: 0.64
Batch: 80; loss: 1.02; acc: 0.62
Batch: 100; loss: 1.05; acc: 0.64
Batch: 120; loss: 1.66; acc: 0.5
Batch: 140; loss: 1.26; acc: 0.58
Batch: 160; loss: 1.23; acc: 0.58
Batch: 180; loss: 1.08; acc: 0.67
Batch: 200; loss: 1.31; acc: 0.66
Batch: 220; loss: 1.17; acc: 0.64
Batch: 240; loss: 1.56; acc: 0.47
Batch: 260; loss: 1.22; acc: 0.67
Batch: 280; loss: 1.18; acc: 0.66
Batch: 300; loss: 1.49; acc: 0.56
Batch: 320; loss: 1.16; acc: 0.59
Batch: 340; loss: 1.26; acc: 0.64
Batch: 360; loss: 1.34; acc: 0.59
Batch: 380; loss: 1.39; acc: 0.55
Batch: 400; loss: 1.25; acc: 0.55
Batch: 420; loss: 1.24; acc: 0.55
Batch: 440; loss: 1.35; acc: 0.55
Batch: 460; loss: 1.61; acc: 0.5
Batch: 480; loss: 1.31; acc: 0.48
Batch: 500; loss: 1.67; acc: 0.5
Batch: 520; loss: 1.48; acc: 0.53
Batch: 540; loss: 1.26; acc: 0.56
Batch: 560; loss: 1.52; acc: 0.53
Batch: 580; loss: 1.62; acc: 0.47
Batch: 600; loss: 1.15; acc: 0.66
Batch: 620; loss: 1.4; acc: 0.56
Batch: 640; loss: 1.26; acc: 0.59
Batch: 660; loss: 1.5; acc: 0.59
Batch: 680; loss: 1.21; acc: 0.55
Batch: 700; loss: 1.27; acc: 0.59
Batch: 720; loss: 1.21; acc: 0.62
Batch: 740; loss: 1.21; acc: 0.59
Batch: 760; loss: 1.38; acc: 0.62
Batch: 780; loss: 1.03; acc: 0.69
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.07012035389198e-05
5.509871698450297e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.11; acc: 0.59
Batch: 80; loss: 1.14; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.56
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.75
Val Epoch over. val_loss: 1.2829007889814437; val_accuracy: 0.5789211783439491 

The current subspace-distance is: 5.509871698450297e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.26; acc: 0.61
Batch: 20; loss: 1.19; acc: 0.58
Batch: 40; loss: 1.14; acc: 0.59
Batch: 60; loss: 1.47; acc: 0.48
Batch: 80; loss: 1.14; acc: 0.62
Batch: 100; loss: 1.08; acc: 0.69
Batch: 120; loss: 1.34; acc: 0.58
Batch: 140; loss: 1.19; acc: 0.64
Batch: 160; loss: 1.24; acc: 0.58
Batch: 180; loss: 1.47; acc: 0.5
Batch: 200; loss: 1.27; acc: 0.62
Batch: 220; loss: 1.41; acc: 0.56
Batch: 240; loss: 1.53; acc: 0.42
Batch: 260; loss: 1.18; acc: 0.62
Batch: 280; loss: 1.24; acc: 0.53
Batch: 300; loss: 1.27; acc: 0.56
Batch: 320; loss: 1.25; acc: 0.58
Batch: 340; loss: 1.45; acc: 0.53
Batch: 360; loss: 1.25; acc: 0.62
Batch: 380; loss: 1.12; acc: 0.62
Batch: 400; loss: 1.29; acc: 0.61
Batch: 420; loss: 1.22; acc: 0.59
Batch: 440; loss: 1.36; acc: 0.56
Batch: 460; loss: 1.21; acc: 0.61
Batch: 480; loss: 1.41; acc: 0.55
Batch: 500; loss: 1.21; acc: 0.61
Batch: 520; loss: 1.3; acc: 0.58
Batch: 540; loss: 1.36; acc: 0.48
Batch: 560; loss: 1.37; acc: 0.55
Batch: 580; loss: 1.53; acc: 0.48
Batch: 600; loss: 1.35; acc: 0.55
Batch: 620; loss: 1.19; acc: 0.64
Batch: 640; loss: 1.35; acc: 0.56
Batch: 660; loss: 1.04; acc: 0.7
Batch: 680; loss: 1.26; acc: 0.5
Batch: 700; loss: 1.36; acc: 0.58
Batch: 720; loss: 1.25; acc: 0.56
Batch: 740; loss: 1.08; acc: 0.69
Batch: 760; loss: 1.28; acc: 0.59
Batch: 780; loss: 1.2; acc: 0.59
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0259538359823637e-05
5.461772161652334e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.5
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.55
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.78
Val Epoch over. val_loss: 1.282878216284855; val_accuracy: 0.5785230891719745 

The current subspace-distance is: 5.461772161652334e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.07; acc: 0.66
Batch: 20; loss: 1.05; acc: 0.62
Batch: 40; loss: 1.13; acc: 0.59
Batch: 60; loss: 1.42; acc: 0.55
Batch: 80; loss: 1.36; acc: 0.55
Batch: 100; loss: 1.11; acc: 0.58
Batch: 120; loss: 1.34; acc: 0.53
Batch: 140; loss: 1.34; acc: 0.55
Batch: 160; loss: 1.26; acc: 0.58
Batch: 180; loss: 1.24; acc: 0.59
Batch: 200; loss: 1.28; acc: 0.59
Batch: 220; loss: 1.01; acc: 0.66
Batch: 240; loss: 1.28; acc: 0.59
Batch: 260; loss: 1.45; acc: 0.53
Batch: 280; loss: 1.09; acc: 0.64
Batch: 300; loss: 1.25; acc: 0.59
Batch: 320; loss: 1.14; acc: 0.7
Batch: 340; loss: 1.18; acc: 0.53
Batch: 360; loss: 1.21; acc: 0.58
Batch: 380; loss: 1.14; acc: 0.62
Batch: 400; loss: 1.22; acc: 0.62
Batch: 420; loss: 1.62; acc: 0.53
Batch: 440; loss: 1.15; acc: 0.66
Batch: 460; loss: 1.35; acc: 0.55
Batch: 480; loss: 1.39; acc: 0.55
Batch: 500; loss: 1.48; acc: 0.53
Batch: 520; loss: 1.33; acc: 0.55
Batch: 540; loss: 1.26; acc: 0.58
Batch: 560; loss: 1.42; acc: 0.52
Batch: 580; loss: 1.1; acc: 0.61
Batch: 600; loss: 1.69; acc: 0.41
Batch: 620; loss: 1.33; acc: 0.67
Batch: 640; loss: 1.13; acc: 0.67
Batch: 660; loss: 1.53; acc: 0.48
Batch: 680; loss: 1.32; acc: 0.62
Batch: 700; loss: 1.41; acc: 0.55
Batch: 720; loss: 1.18; acc: 0.58
Batch: 740; loss: 1.1; acc: 0.62
Batch: 760; loss: 1.41; acc: 0.59
Batch: 780; loss: 1.36; acc: 0.64
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0663481336669065e-05
4.635493951354874e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.5
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.75
Val Epoch over. val_loss: 1.2830995040334714; val_accuracy: 0.5774283439490446 

The current subspace-distance is: 4.635493951354874e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.32; acc: 0.55
Batch: 20; loss: 1.55; acc: 0.48
Batch: 40; loss: 1.29; acc: 0.62
Batch: 60; loss: 1.45; acc: 0.5
Batch: 80; loss: 1.24; acc: 0.69
Batch: 100; loss: 1.34; acc: 0.48
Batch: 120; loss: 1.13; acc: 0.64
Batch: 140; loss: 1.5; acc: 0.55
Batch: 160; loss: 1.56; acc: 0.47
Batch: 180; loss: 1.36; acc: 0.52
Batch: 200; loss: 1.48; acc: 0.52
Batch: 220; loss: 1.36; acc: 0.53
Batch: 240; loss: 1.31; acc: 0.55
Batch: 260; loss: 1.29; acc: 0.58
Batch: 280; loss: 1.08; acc: 0.7
Batch: 300; loss: 1.4; acc: 0.62
Batch: 320; loss: 1.5; acc: 0.48
Batch: 340; loss: 1.42; acc: 0.5
Batch: 360; loss: 1.41; acc: 0.53
Batch: 380; loss: 1.28; acc: 0.66
Batch: 400; loss: 1.27; acc: 0.55
Batch: 420; loss: 1.37; acc: 0.5
Batch: 440; loss: 1.19; acc: 0.61
Batch: 460; loss: 1.4; acc: 0.61
Batch: 480; loss: 1.28; acc: 0.58
Batch: 500; loss: 1.18; acc: 0.56
Batch: 520; loss: 1.35; acc: 0.55
Batch: 540; loss: 1.35; acc: 0.53
Batch: 560; loss: 1.3; acc: 0.56
Batch: 580; loss: 1.27; acc: 0.59
Batch: 600; loss: 1.33; acc: 0.52
Batch: 620; loss: 1.08; acc: 0.62
Batch: 640; loss: 1.25; acc: 0.55
Batch: 660; loss: 1.37; acc: 0.53
Batch: 680; loss: 1.35; acc: 0.55
Batch: 700; loss: 1.08; acc: 0.67
Batch: 720; loss: 1.17; acc: 0.59
Batch: 740; loss: 1.41; acc: 0.62
Batch: 760; loss: 1.49; acc: 0.47
Batch: 780; loss: 1.5; acc: 0.48
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0395878891577013e-05
6.295307684922591e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.5
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.56
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.78
Val Epoch over. val_loss: 1.2825183894983523; val_accuracy: 0.5771297770700637 

The current subspace-distance is: 6.295307684922591e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.31; acc: 0.58
Batch: 20; loss: 1.25; acc: 0.64
Batch: 40; loss: 1.13; acc: 0.56
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 1.26; acc: 0.69
Batch: 100; loss: 1.25; acc: 0.62
Batch: 120; loss: 1.32; acc: 0.59
Batch: 140; loss: 1.42; acc: 0.47
Batch: 160; loss: 1.22; acc: 0.59
Batch: 180; loss: 1.27; acc: 0.58
Batch: 200; loss: 1.32; acc: 0.61
Batch: 220; loss: 1.65; acc: 0.41
Batch: 240; loss: 1.44; acc: 0.58
Batch: 260; loss: 1.19; acc: 0.64
Batch: 280; loss: 1.44; acc: 0.52
Batch: 300; loss: 1.22; acc: 0.52
Batch: 320; loss: 1.29; acc: 0.53
Batch: 340; loss: 1.17; acc: 0.59
Batch: 360; loss: 1.33; acc: 0.47
Batch: 380; loss: 1.54; acc: 0.48
Batch: 400; loss: 1.53; acc: 0.55
Batch: 420; loss: 1.01; acc: 0.69
Batch: 440; loss: 1.3; acc: 0.53
Batch: 460; loss: 1.43; acc: 0.53
Batch: 480; loss: 1.38; acc: 0.52
Batch: 500; loss: 1.28; acc: 0.53
Batch: 520; loss: 1.01; acc: 0.7
Batch: 540; loss: 1.36; acc: 0.55
Batch: 560; loss: 1.51; acc: 0.47
Batch: 580; loss: 1.14; acc: 0.69
Batch: 600; loss: 0.96; acc: 0.69
Batch: 620; loss: 1.08; acc: 0.66
Batch: 640; loss: 1.06; acc: 0.67
Batch: 660; loss: 1.44; acc: 0.58
Batch: 680; loss: 1.24; acc: 0.52
Batch: 700; loss: 1.33; acc: 0.56
Batch: 720; loss: 1.29; acc: 0.56
Batch: 740; loss: 1.18; acc: 0.59
Batch: 760; loss: 1.35; acc: 0.56
Batch: 780; loss: 1.03; acc: 0.64
Train Epoch over. train_loss: 1.29; train_accuracy: 0.58 

1.9575263650040142e-05
5.720472927350784e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.52
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.58
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.78
Val Epoch over. val_loss: 1.2828524792270295; val_accuracy: 0.5795183121019108 

The current subspace-distance is: 5.720472927350784e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.2; acc: 0.62
Batch: 20; loss: 1.38; acc: 0.56
Batch: 40; loss: 1.46; acc: 0.55
Batch: 60; loss: 1.31; acc: 0.62
Batch: 80; loss: 1.26; acc: 0.55
Batch: 100; loss: 1.56; acc: 0.55
Batch: 120; loss: 1.21; acc: 0.62
Batch: 140; loss: 1.01; acc: 0.67
Batch: 160; loss: 1.17; acc: 0.62
Batch: 180; loss: 1.36; acc: 0.61
Batch: 200; loss: 1.18; acc: 0.62
Batch: 220; loss: 1.26; acc: 0.59
Batch: 240; loss: 1.22; acc: 0.61
Batch: 260; loss: 1.36; acc: 0.55
Batch: 280; loss: 1.3; acc: 0.56
Batch: 300; loss: 1.25; acc: 0.61
Batch: 320; loss: 1.2; acc: 0.58
Batch: 340; loss: 1.3; acc: 0.56
Batch: 360; loss: 1.1; acc: 0.69
Batch: 380; loss: 1.4; acc: 0.53
Batch: 400; loss: 1.43; acc: 0.52
Batch: 420; loss: 1.17; acc: 0.56
Batch: 440; loss: 1.42; acc: 0.53
Batch: 460; loss: 1.14; acc: 0.59
Batch: 480; loss: 1.13; acc: 0.62
Batch: 500; loss: 1.43; acc: 0.48
Batch: 520; loss: 1.39; acc: 0.56
Batch: 540; loss: 1.28; acc: 0.59
Batch: 560; loss: 1.08; acc: 0.67
Batch: 580; loss: 1.26; acc: 0.56
Batch: 600; loss: 1.17; acc: 0.59
Batch: 620; loss: 0.99; acc: 0.67
Batch: 640; loss: 1.44; acc: 0.47
Batch: 660; loss: 1.26; acc: 0.62
Batch: 680; loss: 1.5; acc: 0.48
Batch: 700; loss: 1.45; acc: 0.56
Batch: 720; loss: 1.16; acc: 0.62
Batch: 740; loss: 1.06; acc: 0.67
Batch: 760; loss: 1.06; acc: 0.7
Batch: 780; loss: 1.42; acc: 0.56
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.0071105609531514e-05
7.338930117839482e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.52
Batch: 40; loss: 1.03; acc: 0.66
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.77
Val Epoch over. val_loss: 1.2829924939544337; val_accuracy: 0.5783240445859873 

The current subspace-distance is: 7.338930117839482e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.35; acc: 0.58
Batch: 20; loss: 1.17; acc: 0.64
Batch: 40; loss: 1.29; acc: 0.59
Batch: 60; loss: 1.25; acc: 0.64
Batch: 80; loss: 1.09; acc: 0.62
Batch: 100; loss: 1.39; acc: 0.61
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 1.24; acc: 0.58
Batch: 160; loss: 1.36; acc: 0.55
Batch: 180; loss: 1.15; acc: 0.61
Batch: 200; loss: 1.31; acc: 0.59
Batch: 220; loss: 1.1; acc: 0.66
Batch: 240; loss: 1.44; acc: 0.47
Batch: 260; loss: 1.13; acc: 0.61
Batch: 280; loss: 1.33; acc: 0.59
Batch: 300; loss: 1.23; acc: 0.62
Batch: 320; loss: 1.4; acc: 0.64
Batch: 340; loss: 1.24; acc: 0.62
Batch: 360; loss: 1.53; acc: 0.55
Batch: 380; loss: 1.33; acc: 0.55
Batch: 400; loss: 1.13; acc: 0.61
Batch: 420; loss: 1.41; acc: 0.53
Batch: 440; loss: 1.42; acc: 0.53
Batch: 460; loss: 1.22; acc: 0.61
Batch: 480; loss: 1.33; acc: 0.59
Batch: 500; loss: 1.54; acc: 0.52
Batch: 520; loss: 1.48; acc: 0.44
Batch: 540; loss: 1.45; acc: 0.47
Batch: 560; loss: 1.41; acc: 0.55
Batch: 580; loss: 1.26; acc: 0.62
Batch: 600; loss: 1.32; acc: 0.5
Batch: 620; loss: 1.19; acc: 0.58
Batch: 640; loss: 1.38; acc: 0.64
Batch: 660; loss: 1.23; acc: 0.64
Batch: 680; loss: 1.19; acc: 0.61
Batch: 700; loss: 1.39; acc: 0.53
Batch: 720; loss: 1.57; acc: 0.45
Batch: 740; loss: 1.32; acc: 0.58
Batch: 760; loss: 1.29; acc: 0.58
Batch: 780; loss: 1.41; acc: 0.52
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

2.053775460808538e-05
5.719835826312192e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.52
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.11; acc: 0.58
Batch: 80; loss: 1.13; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.93; acc: 0.75
Val Epoch over. val_loss: 1.2833856518860836; val_accuracy: 0.57703025477707 

The current subspace-distance is: 5.719835826312192e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.34; acc: 0.61
Batch: 20; loss: 1.27; acc: 0.56
Batch: 40; loss: 1.25; acc: 0.56
Batch: 60; loss: 1.4; acc: 0.53
Batch: 80; loss: 1.08; acc: 0.64
Batch: 100; loss: 1.15; acc: 0.59
Batch: 120; loss: 1.25; acc: 0.56
Batch: 140; loss: 1.16; acc: 0.56
Batch: 160; loss: 1.27; acc: 0.52
Batch: 180; loss: 1.38; acc: 0.53
Batch: 200; loss: 1.38; acc: 0.59
Batch: 220; loss: 1.17; acc: 0.59
Batch: 240; loss: 1.32; acc: 0.58
Batch: 260; loss: 1.24; acc: 0.59
Batch: 280; loss: 1.15; acc: 0.58
Batch: 300; loss: 1.3; acc: 0.55
Batch: 320; loss: 1.24; acc: 0.55
Batch: 340; loss: 1.39; acc: 0.55
Batch: 360; loss: 1.15; acc: 0.66
Batch: 380; loss: 1.27; acc: 0.59
Batch: 400; loss: 1.51; acc: 0.52
Batch: 420; loss: 1.06; acc: 0.67
Batch: 440; loss: 1.4; acc: 0.56
Batch: 460; loss: 1.05; acc: 0.72
Batch: 480; loss: 1.27; acc: 0.53
Batch: 500; loss: 1.48; acc: 0.5
Batch: 520; loss: 1.16; acc: 0.64
Batch: 540; loss: 1.02; acc: 0.75
Batch: 560; loss: 1.16; acc: 0.64
Batch: 580; loss: 1.19; acc: 0.66
Batch: 600; loss: 1.4; acc: 0.48
Batch: 620; loss: 1.49; acc: 0.53
Batch: 640; loss: 1.15; acc: 0.64
Batch: 660; loss: 1.25; acc: 0.61
Batch: 680; loss: 1.39; acc: 0.52
Batch: 700; loss: 1.37; acc: 0.58
Batch: 720; loss: 1.35; acc: 0.52
Batch: 740; loss: 1.43; acc: 0.47
Batch: 760; loss: 1.22; acc: 0.59
Batch: 780; loss: 1.54; acc: 0.5
Train Epoch over. train_loss: 1.29; train_accuracy: 0.58 

2.0150378986727446e-05
5.607475031865761e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.52
Batch: 40; loss: 1.02; acc: 0.66
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.59
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.77
Val Epoch over. val_loss: 1.282674207808865; val_accuracy: 0.5777269108280255 

The current subspace-distance is: 5.607475031865761e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.25; acc: 0.55
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 1.16; acc: 0.67
Batch: 60; loss: 1.23; acc: 0.62
Batch: 80; loss: 1.41; acc: 0.59
Batch: 100; loss: 1.1; acc: 0.62
Batch: 120; loss: 1.29; acc: 0.62
Batch: 140; loss: 1.0; acc: 0.69
Batch: 160; loss: 1.29; acc: 0.64
Batch: 180; loss: 1.37; acc: 0.58
Batch: 200; loss: 1.08; acc: 0.7
Batch: 220; loss: 1.42; acc: 0.52
Batch: 240; loss: 1.28; acc: 0.55
Batch: 260; loss: 1.25; acc: 0.58
Batch: 280; loss: 1.08; acc: 0.66
Batch: 300; loss: 1.22; acc: 0.56
Batch: 320; loss: 1.18; acc: 0.62
Batch: 340; loss: 1.08; acc: 0.7
Batch: 360; loss: 1.33; acc: 0.59
Batch: 380; loss: 1.3; acc: 0.56
Batch: 400; loss: 1.11; acc: 0.62
Batch: 420; loss: 1.08; acc: 0.64
Batch: 440; loss: 1.28; acc: 0.64
Batch: 460; loss: 1.25; acc: 0.58
Batch: 480; loss: 1.43; acc: 0.56
Batch: 500; loss: 1.54; acc: 0.47
Batch: 520; loss: 1.03; acc: 0.62
Batch: 540; loss: 1.27; acc: 0.59
Batch: 560; loss: 1.32; acc: 0.59
Batch: 580; loss: 1.27; acc: 0.58
Batch: 600; loss: 1.38; acc: 0.59
Batch: 620; loss: 1.17; acc: 0.67
Batch: 640; loss: 1.14; acc: 0.66
Batch: 660; loss: 1.18; acc: 0.58
Batch: 680; loss: 1.33; acc: 0.53
Batch: 700; loss: 1.2; acc: 0.69
Batch: 720; loss: 1.58; acc: 0.48
Batch: 740; loss: 1.3; acc: 0.53
Batch: 760; loss: 1.11; acc: 0.59
Batch: 780; loss: 1.24; acc: 0.61
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.9357546989340335e-05
5.417854026745772e-06
Batch: 0; loss: 1.21; acc: 0.59
Batch: 20; loss: 1.27; acc: 0.52
Batch: 40; loss: 1.03; acc: 0.66
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.14; acc: 0.59
Batch: 100; loss: 1.38; acc: 0.53
Batch: 120; loss: 1.38; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.77
Val Epoch over. val_loss: 1.283037706545204; val_accuracy: 0.5783240445859873 

The current subspace-distance is: 5.417854026745772e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.2; acc: 0.56
Batch: 20; loss: 1.38; acc: 0.52
Batch: 40; loss: 1.03; acc: 0.66
Batch: 60; loss: 1.45; acc: 0.52
Batch: 80; loss: 1.18; acc: 0.66
Batch: 100; loss: 1.24; acc: 0.5
Batch: 120; loss: 1.07; acc: 0.7
Batch: 140; loss: 1.18; acc: 0.66
Batch: 160; loss: 1.15; acc: 0.66
Batch: 180; loss: 1.35; acc: 0.56
Batch: 200; loss: 1.24; acc: 0.64
Batch: 220; loss: 1.25; acc: 0.55
Batch: 240; loss: 1.55; acc: 0.48
Batch: 260; loss: 1.2; acc: 0.58
Batch: 280; loss: 1.4; acc: 0.48
Batch: 300; loss: 1.17; acc: 0.62
Batch: 320; loss: 1.06; acc: 0.61
Batch: 340; loss: 1.28; acc: 0.59
Batch: 360; loss: 1.5; acc: 0.5
Batch: 380; loss: 1.23; acc: 0.64
Batch: 400; loss: 1.33; acc: 0.55
Batch: 420; loss: 1.04; acc: 0.69
Batch: 440; loss: 1.0; acc: 0.67
Batch: 460; loss: 1.24; acc: 0.61
Batch: 480; loss: 1.26; acc: 0.62
Batch: 500; loss: 1.25; acc: 0.56
Batch: 520; loss: 1.08; acc: 0.69
Batch: 540; loss: 1.31; acc: 0.62
Batch: 560; loss: 1.11; acc: 0.69
Batch: 580; loss: 1.54; acc: 0.52
Batch: 600; loss: 1.31; acc: 0.59
Batch: 620; loss: 1.49; acc: 0.48
Batch: 640; loss: 1.68; acc: 0.45
Batch: 660; loss: 1.14; acc: 0.64
Batch: 680; loss: 1.23; acc: 0.66
Batch: 700; loss: 1.34; acc: 0.56
Batch: 720; loss: 1.26; acc: 0.58
Batch: 740; loss: 1.48; acc: 0.55
Batch: 760; loss: 1.41; acc: 0.55
Batch: 780; loss: 1.19; acc: 0.67
Train Epoch over. train_loss: 1.3; train_accuracy: 0.58 

1.7547721654409543e-05
4.727288342110114e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.5
Batch: 40; loss: 1.03; acc: 0.67
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.15; acc: 0.58
Batch: 100; loss: 1.36; acc: 0.55
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.77
Val Epoch over. val_loss: 1.2828922370436844; val_accuracy: 0.5777269108280255 

The current subspace-distance is: 4.727288342110114e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.39; acc: 0.59
Batch: 20; loss: 1.25; acc: 0.55
Batch: 40; loss: 1.09; acc: 0.67
Batch: 60; loss: 1.37; acc: 0.56
Batch: 80; loss: 1.54; acc: 0.48
Batch: 100; loss: 1.37; acc: 0.55
Batch: 120; loss: 1.3; acc: 0.61
Batch: 140; loss: 1.39; acc: 0.55
Batch: 160; loss: 1.25; acc: 0.64
Batch: 180; loss: 1.32; acc: 0.58
Batch: 200; loss: 1.19; acc: 0.61
Batch: 220; loss: 1.21; acc: 0.61
Batch: 240; loss: 1.1; acc: 0.64
Batch: 260; loss: 1.37; acc: 0.52
Batch: 280; loss: 1.15; acc: 0.62
Batch: 300; loss: 1.38; acc: 0.61
Batch: 320; loss: 1.19; acc: 0.62
Batch: 340; loss: 1.11; acc: 0.61
Batch: 360; loss: 1.36; acc: 0.48
Batch: 380; loss: 1.3; acc: 0.58
Batch: 400; loss: 1.26; acc: 0.62
Batch: 420; loss: 1.23; acc: 0.69
Batch: 440; loss: 1.24; acc: 0.66
Batch: 460; loss: 1.26; acc: 0.55
Batch: 480; loss: 1.33; acc: 0.61
Batch: 500; loss: 1.44; acc: 0.52
Batch: 520; loss: 1.11; acc: 0.7
Batch: 540; loss: 1.3; acc: 0.61
Batch: 560; loss: 1.38; acc: 0.55
Batch: 580; loss: 1.25; acc: 0.53
Batch: 600; loss: 1.21; acc: 0.61
Batch: 620; loss: 1.37; acc: 0.55
Batch: 640; loss: 1.26; acc: 0.61
Batch: 660; loss: 1.06; acc: 0.67
Batch: 680; loss: 1.43; acc: 0.53
Batch: 700; loss: 1.44; acc: 0.52
Batch: 720; loss: 1.18; acc: 0.55
Batch: 740; loss: 1.41; acc: 0.56
Batch: 760; loss: 1.35; acc: 0.55
Batch: 780; loss: 1.38; acc: 0.56
Train Epoch over. train_loss: 1.29; train_accuracy: 0.58 

1.952204002009239e-05
5.842528480570763e-06
Batch: 0; loss: 1.2; acc: 0.59
Batch: 20; loss: 1.26; acc: 0.52
Batch: 40; loss: 1.03; acc: 0.66
Batch: 60; loss: 1.12; acc: 0.58
Batch: 80; loss: 1.13; acc: 0.58
Batch: 100; loss: 1.37; acc: 0.53
Batch: 120; loss: 1.37; acc: 0.58
Batch: 140; loss: 0.92; acc: 0.78
Val Epoch over. val_loss: 1.282431620321456; val_accuracy: 0.5782245222929936 

The current subspace-distance is: 5.842528480570763e-06 

plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 20995
elements in E: 4395200
fraction nonzero: 0.004776801965780852
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.37; acc: 0.17
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.24; acc: 0.16
Batch: 60; loss: 2.27; acc: 0.08
Batch: 80; loss: 2.25; acc: 0.12
Batch: 100; loss: 2.27; acc: 0.11
Batch: 120; loss: 2.22; acc: 0.22
Batch: 140; loss: 2.18; acc: 0.3
Batch: 160; loss: 2.18; acc: 0.28
Batch: 180; loss: 2.17; acc: 0.34
Batch: 200; loss: 2.2; acc: 0.17
Batch: 220; loss: 2.22; acc: 0.17
Batch: 240; loss: 2.16; acc: 0.33
Batch: 260; loss: 2.21; acc: 0.19
Batch: 280; loss: 2.14; acc: 0.28
Batch: 300; loss: 2.15; acc: 0.38
Batch: 320; loss: 2.07; acc: 0.34
Batch: 340; loss: 2.1; acc: 0.38
Batch: 360; loss: 2.07; acc: 0.39
Batch: 380; loss: 2.13; acc: 0.25
Batch: 400; loss: 2.07; acc: 0.36
Batch: 420; loss: 1.98; acc: 0.39
Batch: 440; loss: 2.0; acc: 0.39
Batch: 460; loss: 1.93; acc: 0.42
Batch: 480; loss: 1.9; acc: 0.41
Batch: 500; loss: 1.94; acc: 0.36
Batch: 520; loss: 1.79; acc: 0.47
Batch: 540; loss: 2.01; acc: 0.31
Batch: 560; loss: 1.83; acc: 0.42
Batch: 580; loss: 1.82; acc: 0.39
Batch: 600; loss: 1.78; acc: 0.47
Batch: 620; loss: 1.73; acc: 0.44
Batch: 640; loss: 1.64; acc: 0.44
Batch: 660; loss: 1.68; acc: 0.44
Batch: 680; loss: 1.74; acc: 0.41
Batch: 700; loss: 1.71; acc: 0.41
Batch: 720; loss: 1.77; acc: 0.39
Batch: 740; loss: 1.49; acc: 0.53
Batch: 760; loss: 1.27; acc: 0.61
Batch: 780; loss: 1.59; acc: 0.42
Train Epoch over. train_loss: 1.99; train_accuracy: 0.33 

1.2422467079886701e-05
4.460830950847594e-06
Batch: 0; loss: 1.36; acc: 0.58
Batch: 20; loss: 1.4; acc: 0.55
Batch: 40; loss: 1.3; acc: 0.62
Batch: 60; loss: 1.3; acc: 0.62
Batch: 80; loss: 1.39; acc: 0.58
Batch: 100; loss: 1.32; acc: 0.61
Batch: 120; loss: 1.48; acc: 0.56
Batch: 140; loss: 1.46; acc: 0.59
Val Epoch over. val_loss: 1.439948347723408; val_accuracy: 0.5492635350318471 

The current subspace-distance is: 4.460830950847594e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.61; acc: 0.47
Batch: 20; loss: 1.5; acc: 0.45
Batch: 40; loss: 1.43; acc: 0.53
Batch: 60; loss: 1.41; acc: 0.55
Batch: 80; loss: 1.34; acc: 0.61
Batch: 100; loss: 1.08; acc: 0.67
Batch: 120; loss: 1.2; acc: 0.61
Batch: 140; loss: 1.18; acc: 0.58
Batch: 160; loss: 1.02; acc: 0.66
Batch: 180; loss: 1.47; acc: 0.56
Batch: 200; loss: 0.9; acc: 0.73
Batch: 220; loss: 1.19; acc: 0.59
Batch: 240; loss: 1.09; acc: 0.61
Batch: 260; loss: 1.63; acc: 0.52
Batch: 280; loss: 1.19; acc: 0.64
Batch: 300; loss: 1.12; acc: 0.66
Batch: 320; loss: 1.33; acc: 0.53
Batch: 340; loss: 0.97; acc: 0.67
Batch: 360; loss: 1.1; acc: 0.62
Batch: 380; loss: 0.91; acc: 0.7
Batch: 400; loss: 1.14; acc: 0.55
Batch: 420; loss: 1.0; acc: 0.66
Batch: 440; loss: 0.84; acc: 0.73
Batch: 460; loss: 0.81; acc: 0.72
Batch: 480; loss: 1.14; acc: 0.58
Batch: 500; loss: 1.17; acc: 0.59
Batch: 520; loss: 1.06; acc: 0.67
Batch: 540; loss: 1.07; acc: 0.61
Batch: 560; loss: 0.94; acc: 0.75
Batch: 580; loss: 1.06; acc: 0.64
Batch: 600; loss: 0.92; acc: 0.7
Batch: 620; loss: 1.17; acc: 0.62
Batch: 640; loss: 1.19; acc: 0.52
Batch: 660; loss: 0.98; acc: 0.75
Batch: 680; loss: 1.14; acc: 0.61
Batch: 700; loss: 0.8; acc: 0.75
Batch: 720; loss: 1.09; acc: 0.64
Batch: 740; loss: 0.96; acc: 0.7
Batch: 760; loss: 0.94; acc: 0.69
Batch: 780; loss: 1.22; acc: 0.58
Train Epoch over. train_loss: 1.15; train_accuracy: 0.62 

2.1126323190401308e-05
6.550088528456399e-06
Batch: 0; loss: 1.19; acc: 0.69
Batch: 20; loss: 1.39; acc: 0.55
Batch: 40; loss: 0.88; acc: 0.73
Batch: 60; loss: 1.23; acc: 0.64
Batch: 80; loss: 0.99; acc: 0.61
Batch: 100; loss: 1.09; acc: 0.67
Batch: 120; loss: 1.3; acc: 0.53
Batch: 140; loss: 0.88; acc: 0.73
Val Epoch over. val_loss: 1.1938260869615396; val_accuracy: 0.6022093949044586 

The current subspace-distance is: 6.550088528456399e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.29; acc: 0.53
Batch: 20; loss: 0.91; acc: 0.69
Batch: 40; loss: 0.88; acc: 0.7
Batch: 60; loss: 1.2; acc: 0.56
Batch: 80; loss: 1.28; acc: 0.53
Batch: 100; loss: 0.97; acc: 0.66
Batch: 120; loss: 0.99; acc: 0.64
Batch: 140; loss: 0.58; acc: 0.86
Batch: 160; loss: 1.09; acc: 0.64
Batch: 180; loss: 1.19; acc: 0.62
Batch: 200; loss: 1.04; acc: 0.69
Batch: 220; loss: 1.19; acc: 0.59
Batch: 240; loss: 0.95; acc: 0.67
Batch: 260; loss: 1.05; acc: 0.67
Batch: 280; loss: 1.38; acc: 0.55
Batch: 300; loss: 0.79; acc: 0.73
Batch: 320; loss: 1.17; acc: 0.62
Batch: 340; loss: 1.02; acc: 0.7
Batch: 360; loss: 1.1; acc: 0.69
Batch: 380; loss: 1.34; acc: 0.61
Batch: 400; loss: 1.04; acc: 0.69
Batch: 420; loss: 1.56; acc: 0.55
Batch: 440; loss: 0.73; acc: 0.78
Batch: 460; loss: 0.93; acc: 0.69
Batch: 480; loss: 0.78; acc: 0.73
Batch: 500; loss: 1.27; acc: 0.56
Batch: 520; loss: 1.04; acc: 0.75
Batch: 540; loss: 1.32; acc: 0.58
Batch: 560; loss: 0.89; acc: 0.75
Batch: 580; loss: 0.97; acc: 0.66
Batch: 600; loss: 1.02; acc: 0.7
Batch: 620; loss: 1.07; acc: 0.53
Batch: 640; loss: 1.15; acc: 0.59
Batch: 660; loss: 0.91; acc: 0.75
Batch: 680; loss: 0.97; acc: 0.67
Batch: 700; loss: 1.1; acc: 0.67
Batch: 720; loss: 0.93; acc: 0.66
Batch: 740; loss: 0.83; acc: 0.77
Batch: 760; loss: 0.84; acc: 0.7
Batch: 780; loss: 0.91; acc: 0.7
Train Epoch over. train_loss: 1.05; train_accuracy: 0.66 

2.0522546037682332e-05
6.276794465520652e-06
Batch: 0; loss: 1.83; acc: 0.52
Batch: 20; loss: 1.89; acc: 0.53
Batch: 40; loss: 1.51; acc: 0.61
Batch: 60; loss: 1.79; acc: 0.53
Batch: 80; loss: 1.79; acc: 0.53
Batch: 100; loss: 1.58; acc: 0.59
Batch: 120; loss: 1.35; acc: 0.55
Batch: 140; loss: 1.15; acc: 0.7
Val Epoch over. val_loss: 1.6687781127395145; val_accuracy: 0.5308519108280255 

The current subspace-distance is: 6.276794465520652e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.11; acc: 0.34
Batch: 20; loss: 1.13; acc: 0.59
Batch: 40; loss: 0.86; acc: 0.78
Batch: 60; loss: 1.57; acc: 0.62
Batch: 80; loss: 1.16; acc: 0.56
Batch: 100; loss: 0.88; acc: 0.7
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.84; acc: 0.7
Batch: 160; loss: 0.72; acc: 0.73
Batch: 180; loss: 1.08; acc: 0.58
Batch: 200; loss: 0.92; acc: 0.66
Batch: 220; loss: 0.97; acc: 0.64
Batch: 240; loss: 0.72; acc: 0.8
Batch: 260; loss: 0.81; acc: 0.78
Batch: 280; loss: 1.03; acc: 0.66
Batch: 300; loss: 1.41; acc: 0.58
Batch: 320; loss: 0.81; acc: 0.72
Batch: 340; loss: 1.01; acc: 0.7
Batch: 360; loss: 1.03; acc: 0.69
Batch: 380; loss: 0.93; acc: 0.67
Batch: 400; loss: 1.0; acc: 0.66
Batch: 420; loss: 1.27; acc: 0.58
Batch: 440; loss: 1.01; acc: 0.55
Batch: 460; loss: 1.29; acc: 0.59
Batch: 480; loss: 1.12; acc: 0.67
Batch: 500; loss: 0.99; acc: 0.69
Batch: 520; loss: 0.8; acc: 0.73
Batch: 540; loss: 1.01; acc: 0.73
Batch: 560; loss: 1.22; acc: 0.64
Batch: 580; loss: 1.16; acc: 0.61
Batch: 600; loss: 1.02; acc: 0.78
Batch: 620; loss: 0.75; acc: 0.8
Batch: 640; loss: 0.64; acc: 0.83
Batch: 660; loss: 1.28; acc: 0.58
Batch: 680; loss: 0.99; acc: 0.75
Batch: 700; loss: 0.93; acc: 0.7
Batch: 720; loss: 0.88; acc: 0.75
Batch: 740; loss: 0.78; acc: 0.69
Batch: 760; loss: 1.01; acc: 0.64
Batch: 780; loss: 0.82; acc: 0.75
Train Epoch over. train_loss: 1.0; train_accuracy: 0.67 

2.1146237486391328e-05
5.49202604815946e-06
Batch: 0; loss: 0.88; acc: 0.61
Batch: 20; loss: 1.36; acc: 0.58
Batch: 40; loss: 0.82; acc: 0.75
Batch: 60; loss: 1.15; acc: 0.67
Batch: 80; loss: 1.04; acc: 0.75
Batch: 100; loss: 0.96; acc: 0.66
Batch: 120; loss: 1.24; acc: 0.61
Batch: 140; loss: 0.93; acc: 0.67
Val Epoch over. val_loss: 1.1058604106022294; val_accuracy: 0.6330613057324841 

The current subspace-distance is: 5.49202604815946e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.29; acc: 0.53
Batch: 20; loss: 1.26; acc: 0.59
Batch: 40; loss: 1.06; acc: 0.61
Batch: 60; loss: 0.87; acc: 0.67
Batch: 80; loss: 0.71; acc: 0.75
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 1.25; acc: 0.62
Batch: 160; loss: 0.86; acc: 0.7
Batch: 180; loss: 0.75; acc: 0.77
Batch: 200; loss: 1.12; acc: 0.69
Batch: 220; loss: 1.09; acc: 0.53
Batch: 240; loss: 1.03; acc: 0.67
Batch: 260; loss: 0.85; acc: 0.75
Batch: 280; loss: 0.85; acc: 0.73
Batch: 300; loss: 0.93; acc: 0.67
Batch: 320; loss: 0.88; acc: 0.69
Batch: 340; loss: 0.92; acc: 0.72
Batch: 360; loss: 0.78; acc: 0.73
Batch: 380; loss: 1.08; acc: 0.67
Batch: 400; loss: 0.87; acc: 0.72
Batch: 420; loss: 0.88; acc: 0.69
Batch: 440; loss: 0.77; acc: 0.72
Batch: 460; loss: 0.81; acc: 0.69
Batch: 480; loss: 1.17; acc: 0.61
Batch: 500; loss: 0.85; acc: 0.69
Batch: 520; loss: 0.82; acc: 0.69
Batch: 540; loss: 0.69; acc: 0.73
Batch: 560; loss: 0.8; acc: 0.72
Batch: 580; loss: 0.93; acc: 0.77
Batch: 600; loss: 0.75; acc: 0.78
Batch: 620; loss: 0.9; acc: 0.72
Batch: 640; loss: 0.83; acc: 0.69
Batch: 660; loss: 0.77; acc: 0.72
Batch: 680; loss: 0.76; acc: 0.69
Batch: 700; loss: 0.9; acc: 0.72
Batch: 720; loss: 0.79; acc: 0.73
Batch: 740; loss: 0.87; acc: 0.72
Batch: 760; loss: 0.83; acc: 0.7
Batch: 780; loss: 1.17; acc: 0.64
Train Epoch over. train_loss: 0.91; train_accuracy: 0.7 

2.2029789761290886e-05
5.959896498097805e-06
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 1.12; acc: 0.67
Batch: 40; loss: 0.54; acc: 0.84
Batch: 60; loss: 0.86; acc: 0.72
Batch: 80; loss: 0.81; acc: 0.8
Batch: 100; loss: 0.7; acc: 0.7
Batch: 120; loss: 1.12; acc: 0.64
Batch: 140; loss: 0.67; acc: 0.81
Val Epoch over. val_loss: 0.8334011913864476; val_accuracy: 0.7296974522292994 

The current subspace-distance is: 5.959896498097805e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.0; acc: 0.73
Batch: 20; loss: 0.9; acc: 0.67
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 0.84; acc: 0.72
Batch: 80; loss: 0.93; acc: 0.64
Batch: 100; loss: 0.69; acc: 0.73
Batch: 120; loss: 0.95; acc: 0.72
Batch: 140; loss: 0.96; acc: 0.66
Batch: 160; loss: 0.65; acc: 0.8
Batch: 180; loss: 1.11; acc: 0.64
Batch: 200; loss: 1.08; acc: 0.7
Batch: 220; loss: 0.65; acc: 0.77
Batch: 240; loss: 0.69; acc: 0.8
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 1.13; acc: 0.62
Batch: 300; loss: 0.77; acc: 0.7
Batch: 320; loss: 1.13; acc: 0.7
Batch: 340; loss: 0.7; acc: 0.77
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.96; acc: 0.67
Batch: 400; loss: 0.74; acc: 0.72
Batch: 420; loss: 0.93; acc: 0.75
Batch: 440; loss: 0.83; acc: 0.72
Batch: 460; loss: 0.77; acc: 0.75
Batch: 480; loss: 1.17; acc: 0.62
Batch: 500; loss: 1.09; acc: 0.62
Batch: 520; loss: 0.66; acc: 0.84
Batch: 540; loss: 0.78; acc: 0.77
Batch: 560; loss: 0.74; acc: 0.72
Batch: 580; loss: 0.72; acc: 0.8
Batch: 600; loss: 0.85; acc: 0.75
Batch: 620; loss: 1.02; acc: 0.69
Batch: 640; loss: 0.85; acc: 0.73
Batch: 660; loss: 0.75; acc: 0.78
Batch: 680; loss: 1.06; acc: 0.64
Batch: 700; loss: 0.84; acc: 0.77
Batch: 720; loss: 0.71; acc: 0.83
Batch: 740; loss: 0.87; acc: 0.64
Batch: 760; loss: 0.97; acc: 0.72
Batch: 780; loss: 0.73; acc: 0.86
Train Epoch over. train_loss: 0.89; train_accuracy: 0.71 

2.4290089640999213e-05
7.196176284196554e-06
Batch: 0; loss: 1.41; acc: 0.53
Batch: 20; loss: 1.94; acc: 0.45
Batch: 40; loss: 1.07; acc: 0.61
Batch: 60; loss: 1.35; acc: 0.55
Batch: 80; loss: 1.87; acc: 0.47
Batch: 100; loss: 1.33; acc: 0.58
Batch: 120; loss: 1.79; acc: 0.47
Batch: 140; loss: 1.34; acc: 0.59
Val Epoch over. val_loss: 1.506439603058396; val_accuracy: 0.5135350318471338 

The current subspace-distance is: 7.196176284196554e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.38; acc: 0.53
Batch: 20; loss: 0.81; acc: 0.7
Batch: 40; loss: 0.8; acc: 0.75
Batch: 60; loss: 1.07; acc: 0.67
Batch: 80; loss: 1.02; acc: 0.62
Batch: 100; loss: 0.97; acc: 0.69
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.81; acc: 0.73
Batch: 160; loss: 1.0; acc: 0.66
Batch: 180; loss: 0.7; acc: 0.78
Batch: 200; loss: 1.06; acc: 0.69
Batch: 220; loss: 0.8; acc: 0.72
Batch: 240; loss: 0.85; acc: 0.77
Batch: 260; loss: 0.96; acc: 0.67
Batch: 280; loss: 1.06; acc: 0.64
Batch: 300; loss: 0.65; acc: 0.78
Batch: 320; loss: 0.81; acc: 0.8
Batch: 340; loss: 1.14; acc: 0.62
Batch: 360; loss: 0.62; acc: 0.78
Batch: 380; loss: 0.69; acc: 0.77
Batch: 400; loss: 0.74; acc: 0.78
Batch: 420; loss: 0.93; acc: 0.73
Batch: 440; loss: 0.9; acc: 0.78
Batch: 460; loss: 0.96; acc: 0.67
Batch: 480; loss: 0.95; acc: 0.73
Batch: 500; loss: 0.86; acc: 0.73
Batch: 520; loss: 0.92; acc: 0.73
Batch: 540; loss: 0.76; acc: 0.7
Batch: 560; loss: 0.9; acc: 0.67
Batch: 580; loss: 0.76; acc: 0.78
Batch: 600; loss: 1.15; acc: 0.62
Batch: 620; loss: 1.03; acc: 0.66
Batch: 640; loss: 1.05; acc: 0.7
Batch: 660; loss: 0.62; acc: 0.83
Batch: 680; loss: 0.9; acc: 0.77
Batch: 700; loss: 0.94; acc: 0.67
Batch: 720; loss: 0.87; acc: 0.69
Batch: 740; loss: 0.82; acc: 0.69
Batch: 760; loss: 1.13; acc: 0.66
Batch: 780; loss: 0.86; acc: 0.69
Train Epoch over. train_loss: 0.89; train_accuracy: 0.71 

2.161951852031052e-05
6.223922810022486e-06
Batch: 0; loss: 0.82; acc: 0.8
Batch: 20; loss: 1.35; acc: 0.58
Batch: 40; loss: 0.72; acc: 0.75
Batch: 60; loss: 0.96; acc: 0.69
Batch: 80; loss: 0.99; acc: 0.67
Batch: 100; loss: 0.99; acc: 0.67
Batch: 120; loss: 1.16; acc: 0.64
Batch: 140; loss: 0.97; acc: 0.75
Val Epoch over. val_loss: 1.0658013285345334; val_accuracy: 0.6501791401273885 

The current subspace-distance is: 6.223922810022486e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.1; acc: 0.64
Batch: 20; loss: 0.83; acc: 0.77
Batch: 40; loss: 0.95; acc: 0.78
Batch: 60; loss: 0.66; acc: 0.7
Batch: 80; loss: 0.86; acc: 0.64
Batch: 100; loss: 0.98; acc: 0.66
Batch: 120; loss: 0.97; acc: 0.69
Batch: 140; loss: 0.82; acc: 0.67
Batch: 160; loss: 0.98; acc: 0.67
Batch: 180; loss: 0.84; acc: 0.7
Batch: 200; loss: 0.89; acc: 0.67
Batch: 220; loss: 0.84; acc: 0.7
Batch: 240; loss: 0.79; acc: 0.78
Batch: 260; loss: 1.15; acc: 0.58
Batch: 280; loss: 0.75; acc: 0.72
Batch: 300; loss: 0.61; acc: 0.8
Batch: 320; loss: 1.02; acc: 0.7
Batch: 340; loss: 0.78; acc: 0.7
Batch: 360; loss: 0.77; acc: 0.77
Batch: 380; loss: 1.27; acc: 0.55
Batch: 400; loss: 0.79; acc: 0.73
Batch: 420; loss: 1.0; acc: 0.64
Batch: 440; loss: 0.86; acc: 0.66
Batch: 460; loss: 0.94; acc: 0.75
Batch: 480; loss: 1.1; acc: 0.62
Batch: 500; loss: 1.13; acc: 0.66
Batch: 520; loss: 1.09; acc: 0.61
Batch: 540; loss: 1.07; acc: 0.67
Batch: 560; loss: 0.95; acc: 0.64
Batch: 580; loss: 0.64; acc: 0.81
Batch: 600; loss: 0.9; acc: 0.7
Batch: 620; loss: 0.71; acc: 0.7
Batch: 640; loss: 0.7; acc: 0.8
Batch: 660; loss: 0.91; acc: 0.7
Batch: 680; loss: 0.74; acc: 0.75
Batch: 700; loss: 0.86; acc: 0.72
Batch: 720; loss: 0.76; acc: 0.73
Batch: 740; loss: 0.88; acc: 0.75
Batch: 760; loss: 0.73; acc: 0.78
Batch: 780; loss: 1.0; acc: 0.7
Train Epoch over. train_loss: 0.88; train_accuracy: 0.71 

2.40225581364939e-05
6.201188625709619e-06
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 1.22; acc: 0.55
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.79; acc: 0.75
Batch: 80; loss: 0.9; acc: 0.77
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 1.21; acc: 0.56
Batch: 140; loss: 0.89; acc: 0.73
Val Epoch over. val_loss: 0.8727626823315955; val_accuracy: 0.7143710191082803 

The current subspace-distance is: 6.201188625709619e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.97; acc: 0.7
Batch: 60; loss: 0.73; acc: 0.75
Batch: 80; loss: 0.88; acc: 0.72
Batch: 100; loss: 0.63; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.72
Batch: 140; loss: 0.72; acc: 0.75
Batch: 160; loss: 1.0; acc: 0.67
Batch: 180; loss: 0.92; acc: 0.62
Batch: 200; loss: 0.79; acc: 0.78
Batch: 220; loss: 0.76; acc: 0.73
Batch: 240; loss: 0.9; acc: 0.72
Batch: 260; loss: 0.73; acc: 0.77
Batch: 280; loss: 0.77; acc: 0.77
Batch: 300; loss: 0.69; acc: 0.77
Batch: 320; loss: 0.78; acc: 0.78
Batch: 340; loss: 1.31; acc: 0.56
Batch: 360; loss: 0.9; acc: 0.7
Batch: 380; loss: 0.73; acc: 0.78
Batch: 400; loss: 0.99; acc: 0.67
Batch: 420; loss: 0.93; acc: 0.73
Batch: 440; loss: 0.97; acc: 0.66
Batch: 460; loss: 0.88; acc: 0.7
Batch: 480; loss: 0.83; acc: 0.78
Batch: 500; loss: 0.83; acc: 0.78
Batch: 520; loss: 0.91; acc: 0.64
Batch: 540; loss: 0.77; acc: 0.75
Batch: 560; loss: 0.85; acc: 0.75
Batch: 580; loss: 0.8; acc: 0.77
Batch: 600; loss: 0.92; acc: 0.69
Batch: 620; loss: 1.34; acc: 0.55
Batch: 640; loss: 0.85; acc: 0.7
Batch: 660; loss: 0.83; acc: 0.81
Batch: 680; loss: 0.82; acc: 0.73
Batch: 700; loss: 1.16; acc: 0.67
Batch: 720; loss: 0.92; acc: 0.77
Batch: 740; loss: 0.91; acc: 0.73
Batch: 760; loss: 1.08; acc: 0.61
Batch: 780; loss: 0.89; acc: 0.69
Train Epoch over. train_loss: 0.87; train_accuracy: 0.72 

2.449687417538371e-05
6.569547167600831e-06
Batch: 0; loss: 0.64; acc: 0.75
Batch: 20; loss: 1.44; acc: 0.5
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.96; acc: 0.7
Batch: 80; loss: 1.07; acc: 0.62
Batch: 100; loss: 0.93; acc: 0.66
Batch: 120; loss: 1.21; acc: 0.58
Batch: 140; loss: 0.93; acc: 0.7
Val Epoch over. val_loss: 1.0254545280128529; val_accuracy: 0.6471934713375797 

The current subspace-distance is: 6.569547167600831e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.11; acc: 0.58
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 1.04; acc: 0.67
Batch: 60; loss: 0.95; acc: 0.67
Batch: 80; loss: 0.61; acc: 0.81
Batch: 100; loss: 0.65; acc: 0.81
Batch: 120; loss: 0.87; acc: 0.73
Batch: 140; loss: 0.89; acc: 0.67
Batch: 160; loss: 0.95; acc: 0.62
Batch: 180; loss: 0.84; acc: 0.67
Batch: 200; loss: 0.77; acc: 0.73
Batch: 220; loss: 1.02; acc: 0.67
Batch: 240; loss: 0.77; acc: 0.77
Batch: 260; loss: 0.86; acc: 0.8
Batch: 280; loss: 0.59; acc: 0.78
Batch: 300; loss: 0.81; acc: 0.72
Batch: 320; loss: 0.71; acc: 0.77
Batch: 340; loss: 0.49; acc: 0.84
Batch: 360; loss: 0.74; acc: 0.8
Batch: 380; loss: 1.17; acc: 0.66
Batch: 400; loss: 0.54; acc: 0.86
Batch: 420; loss: 0.66; acc: 0.77
Batch: 440; loss: 0.82; acc: 0.72
Batch: 460; loss: 0.82; acc: 0.73
Batch: 480; loss: 0.82; acc: 0.69
Batch: 500; loss: 0.96; acc: 0.75
Batch: 520; loss: 1.19; acc: 0.59
Batch: 540; loss: 1.23; acc: 0.62
Batch: 560; loss: 0.71; acc: 0.8
Batch: 580; loss: 0.9; acc: 0.72
Batch: 600; loss: 0.59; acc: 0.8
Batch: 620; loss: 0.93; acc: 0.73
Batch: 640; loss: 0.74; acc: 0.77
Batch: 660; loss: 0.95; acc: 0.7
Batch: 680; loss: 0.81; acc: 0.72
Batch: 700; loss: 0.7; acc: 0.75
Batch: 720; loss: 0.84; acc: 0.8
Batch: 740; loss: 0.79; acc: 0.75
Batch: 760; loss: 0.81; acc: 0.8
Batch: 780; loss: 0.64; acc: 0.83
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

2.5607239876990207e-05
7.715967512922361e-06
Batch: 0; loss: 0.83; acc: 0.75
Batch: 20; loss: 1.17; acc: 0.64
Batch: 40; loss: 0.68; acc: 0.81
Batch: 60; loss: 0.85; acc: 0.75
Batch: 80; loss: 1.11; acc: 0.56
Batch: 100; loss: 0.85; acc: 0.69
Batch: 120; loss: 1.12; acc: 0.64
Batch: 140; loss: 0.84; acc: 0.75
Val Epoch over. val_loss: 0.9293235555575912; val_accuracy: 0.6855095541401274 

The current subspace-distance is: 7.715967512922361e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.07; acc: 0.66
Batch: 20; loss: 1.0; acc: 0.64
Batch: 40; loss: 0.78; acc: 0.75
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.66; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.73
Batch: 120; loss: 0.74; acc: 0.72
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.91; acc: 0.72
Batch: 180; loss: 0.74; acc: 0.77
Batch: 200; loss: 0.99; acc: 0.67
Batch: 220; loss: 0.63; acc: 0.8
Batch: 240; loss: 0.86; acc: 0.69
Batch: 260; loss: 0.59; acc: 0.8
Batch: 280; loss: 0.78; acc: 0.77
Batch: 300; loss: 0.82; acc: 0.77
Batch: 320; loss: 0.95; acc: 0.72
Batch: 340; loss: 0.65; acc: 0.72
Batch: 360; loss: 0.86; acc: 0.7
Batch: 380; loss: 0.88; acc: 0.69
Batch: 400; loss: 0.7; acc: 0.78
Batch: 420; loss: 0.75; acc: 0.73
Batch: 440; loss: 0.64; acc: 0.81
Batch: 460; loss: 0.6; acc: 0.8
Batch: 480; loss: 0.75; acc: 0.77
Batch: 500; loss: 0.93; acc: 0.67
Batch: 520; loss: 0.58; acc: 0.84
Batch: 540; loss: 0.68; acc: 0.8
Batch: 560; loss: 0.7; acc: 0.78
Batch: 580; loss: 0.78; acc: 0.73
Batch: 600; loss: 0.67; acc: 0.78
Batch: 620; loss: 0.77; acc: 0.73
Batch: 640; loss: 0.52; acc: 0.88
Batch: 660; loss: 0.85; acc: 0.73
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.78; acc: 0.77
Batch: 720; loss: 0.65; acc: 0.75
Batch: 740; loss: 0.68; acc: 0.83
Batch: 760; loss: 0.66; acc: 0.84
Batch: 780; loss: 0.81; acc: 0.69
Train Epoch over. train_loss: 0.77; train_accuracy: 0.75 

2.4688442863407545e-05
7.159510005294578e-06
Batch: 0; loss: 0.62; acc: 0.78
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.67; acc: 0.77
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 0.96; acc: 0.69
Batch: 140; loss: 0.74; acc: 0.78
Val Epoch over. val_loss: 0.7627787246445942; val_accuracy: 0.7428343949044586 

The current subspace-distance is: 7.159510005294578e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 0.75; acc: 0.75
Batch: 40; loss: 0.78; acc: 0.75
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.8; acc: 0.72
Batch: 100; loss: 0.73; acc: 0.84
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.91; acc: 0.7
Batch: 160; loss: 0.86; acc: 0.78
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.54; acc: 0.84
Batch: 220; loss: 0.7; acc: 0.72
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.8; acc: 0.72
Batch: 280; loss: 0.95; acc: 0.66
Batch: 300; loss: 0.88; acc: 0.67
Batch: 320; loss: 0.83; acc: 0.75
Batch: 340; loss: 0.77; acc: 0.72
Batch: 360; loss: 0.84; acc: 0.7
Batch: 380; loss: 1.1; acc: 0.67
Batch: 400; loss: 0.8; acc: 0.75
Batch: 420; loss: 0.75; acc: 0.78
Batch: 440; loss: 0.51; acc: 0.84
Batch: 460; loss: 0.97; acc: 0.64
Batch: 480; loss: 0.6; acc: 0.8
Batch: 500; loss: 0.93; acc: 0.7
Batch: 520; loss: 0.84; acc: 0.75
Batch: 540; loss: 0.68; acc: 0.77
Batch: 560; loss: 0.84; acc: 0.78
Batch: 580; loss: 0.76; acc: 0.75
Batch: 600; loss: 0.68; acc: 0.8
Batch: 620; loss: 0.91; acc: 0.69
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.88; acc: 0.73
Batch: 680; loss: 0.59; acc: 0.8
Batch: 700; loss: 0.64; acc: 0.77
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.82; acc: 0.73
Batch: 760; loss: 0.71; acc: 0.73
Batch: 780; loss: 0.91; acc: 0.72
Train Epoch over. train_loss: 0.76; train_accuracy: 0.75 

2.4992690669023432e-05
7.309546617761953e-06
Batch: 0; loss: 0.55; acc: 0.84
Batch: 20; loss: 1.0; acc: 0.62
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.8; acc: 0.69
Batch: 80; loss: 0.79; acc: 0.75
Batch: 100; loss: 0.76; acc: 0.72
Batch: 120; loss: 1.07; acc: 0.66
Batch: 140; loss: 0.77; acc: 0.7
Val Epoch over. val_loss: 0.7850883026031932; val_accuracy: 0.7363654458598726 

The current subspace-distance is: 7.309546617761953e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.87; acc: 0.64
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.7; acc: 0.8
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 1.04; acc: 0.69
Batch: 160; loss: 0.7; acc: 0.78
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.98; acc: 0.75
Batch: 220; loss: 0.71; acc: 0.77
Batch: 240; loss: 0.78; acc: 0.78
Batch: 260; loss: 0.76; acc: 0.84
Batch: 280; loss: 0.91; acc: 0.67
Batch: 300; loss: 0.59; acc: 0.8
Batch: 320; loss: 0.94; acc: 0.69
Batch: 340; loss: 0.63; acc: 0.81
Batch: 360; loss: 0.64; acc: 0.78
Batch: 380; loss: 0.73; acc: 0.77
Batch: 400; loss: 1.07; acc: 0.66
Batch: 420; loss: 0.69; acc: 0.73
Batch: 440; loss: 0.76; acc: 0.72
Batch: 460; loss: 0.62; acc: 0.8
Batch: 480; loss: 0.86; acc: 0.72
Batch: 500; loss: 1.09; acc: 0.64
Batch: 520; loss: 0.88; acc: 0.66
Batch: 540; loss: 0.79; acc: 0.8
Batch: 560; loss: 0.76; acc: 0.67
Batch: 580; loss: 0.76; acc: 0.8
Batch: 600; loss: 0.55; acc: 0.8
Batch: 620; loss: 0.86; acc: 0.77
Batch: 640; loss: 0.72; acc: 0.77
Batch: 660; loss: 0.79; acc: 0.8
Batch: 680; loss: 0.98; acc: 0.67
Batch: 700; loss: 0.83; acc: 0.72
Batch: 720; loss: 0.79; acc: 0.73
Batch: 740; loss: 0.54; acc: 0.83
Batch: 760; loss: 0.6; acc: 0.8
Batch: 780; loss: 0.67; acc: 0.78
Train Epoch over. train_loss: 0.75; train_accuracy: 0.76 

2.3726714061922394e-05
7.391029612335842e-06
Batch: 0; loss: 0.53; acc: 0.8
Batch: 20; loss: 0.93; acc: 0.64
Batch: 40; loss: 0.55; acc: 0.84
Batch: 60; loss: 0.62; acc: 0.8
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.77; acc: 0.69
Batch: 120; loss: 0.94; acc: 0.67
Batch: 140; loss: 0.73; acc: 0.75
Val Epoch over. val_loss: 0.7331815477769086; val_accuracy: 0.7609474522292994 

The current subspace-distance is: 7.391029612335842e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.66; acc: 0.81
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.69; acc: 0.7
Batch: 60; loss: 0.72; acc: 0.72
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.68; acc: 0.77
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.97; acc: 0.73
Batch: 160; loss: 0.88; acc: 0.77
Batch: 180; loss: 0.78; acc: 0.73
Batch: 200; loss: 0.62; acc: 0.77
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 1.25; acc: 0.67
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 0.75; acc: 0.72
Batch: 300; loss: 0.77; acc: 0.77
Batch: 320; loss: 0.98; acc: 0.62
Batch: 340; loss: 0.72; acc: 0.75
Batch: 360; loss: 0.7; acc: 0.77
Batch: 380; loss: 0.95; acc: 0.72
Batch: 400; loss: 0.75; acc: 0.73
Batch: 420; loss: 0.83; acc: 0.72
Batch: 440; loss: 0.64; acc: 0.73
Batch: 460; loss: 0.72; acc: 0.77
Batch: 480; loss: 0.7; acc: 0.81
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.91; acc: 0.75
Batch: 540; loss: 0.78; acc: 0.73
Batch: 560; loss: 0.7; acc: 0.72
Batch: 580; loss: 0.79; acc: 0.75
Batch: 600; loss: 0.76; acc: 0.75
Batch: 620; loss: 0.77; acc: 0.81
Batch: 640; loss: 0.65; acc: 0.77
Batch: 660; loss: 0.63; acc: 0.81
Batch: 680; loss: 0.65; acc: 0.73
Batch: 700; loss: 0.78; acc: 0.83
Batch: 720; loss: 0.59; acc: 0.78
Batch: 740; loss: 0.67; acc: 0.84
Batch: 760; loss: 0.64; acc: 0.77
Batch: 780; loss: 0.82; acc: 0.78
Train Epoch over. train_loss: 0.74; train_accuracy: 0.76 

2.5672157789813355e-05
7.185930371633731e-06
Batch: 0; loss: 0.54; acc: 0.88
Batch: 20; loss: 0.85; acc: 0.66
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 0.72; acc: 0.75
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.75; acc: 0.77
Batch: 120; loss: 1.03; acc: 0.73
Batch: 140; loss: 0.67; acc: 0.78
Val Epoch over. val_loss: 0.7375040716806035; val_accuracy: 0.7580613057324841 

The current subspace-distance is: 7.185930371633731e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.69; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.84
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.76; acc: 0.8
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.8; acc: 0.77
Batch: 160; loss: 0.91; acc: 0.7
Batch: 180; loss: 0.83; acc: 0.67
Batch: 200; loss: 0.46; acc: 0.84
Batch: 220; loss: 1.0; acc: 0.73
Batch: 240; loss: 0.84; acc: 0.72
Batch: 260; loss: 0.58; acc: 0.81
Batch: 280; loss: 0.79; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.77
Batch: 320; loss: 0.94; acc: 0.69
Batch: 340; loss: 0.92; acc: 0.66
Batch: 360; loss: 0.81; acc: 0.77
Batch: 380; loss: 0.85; acc: 0.66
Batch: 400; loss: 0.5; acc: 0.84
Batch: 420; loss: 0.52; acc: 0.86
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.62; acc: 0.77
Batch: 480; loss: 0.71; acc: 0.77
Batch: 500; loss: 0.78; acc: 0.77
Batch: 520; loss: 0.66; acc: 0.8
Batch: 540; loss: 0.77; acc: 0.78
Batch: 560; loss: 0.76; acc: 0.8
Batch: 580; loss: 0.78; acc: 0.72
Batch: 600; loss: 0.59; acc: 0.88
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.73; acc: 0.73
Batch: 660; loss: 0.92; acc: 0.72
Batch: 680; loss: 0.73; acc: 0.72
Batch: 700; loss: 0.87; acc: 0.69
Batch: 720; loss: 0.84; acc: 0.73
Batch: 740; loss: 0.71; acc: 0.83
Batch: 760; loss: 0.96; acc: 0.72
Batch: 780; loss: 0.95; acc: 0.67
Train Epoch over. train_loss: 0.74; train_accuracy: 0.76 

2.4916764232330024e-05
6.950165698071942e-06
Batch: 0; loss: 0.61; acc: 0.8
Batch: 20; loss: 0.91; acc: 0.67
Batch: 40; loss: 0.54; acc: 0.86
Batch: 60; loss: 0.63; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.75; acc: 0.72
Batch: 120; loss: 1.01; acc: 0.69
Batch: 140; loss: 0.65; acc: 0.75
Val Epoch over. val_loss: 0.7069190683638215; val_accuracy: 0.7655254777070064 

The current subspace-distance is: 6.950165698071942e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.78; acc: 0.69
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.79; acc: 0.77
Batch: 60; loss: 0.96; acc: 0.66
Batch: 80; loss: 0.91; acc: 0.7
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.75; acc: 0.8
Batch: 160; loss: 0.65; acc: 0.81
Batch: 180; loss: 0.63; acc: 0.78
Batch: 200; loss: 0.7; acc: 0.78
Batch: 220; loss: 0.76; acc: 0.78
Batch: 240; loss: 0.75; acc: 0.75
Batch: 260; loss: 0.88; acc: 0.75
Batch: 280; loss: 0.75; acc: 0.75
Batch: 300; loss: 0.74; acc: 0.77
Batch: 320; loss: 0.98; acc: 0.64
Batch: 340; loss: 0.65; acc: 0.75
Batch: 360; loss: 0.8; acc: 0.75
Batch: 380; loss: 0.78; acc: 0.73
Batch: 400; loss: 0.94; acc: 0.67
Batch: 420; loss: 0.67; acc: 0.77
Batch: 440; loss: 0.86; acc: 0.72
Batch: 460; loss: 0.77; acc: 0.75
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.78; acc: 0.81
Batch: 520; loss: 0.83; acc: 0.78
Batch: 540; loss: 0.68; acc: 0.81
Batch: 560; loss: 0.81; acc: 0.7
Batch: 580; loss: 0.7; acc: 0.77
Batch: 600; loss: 0.81; acc: 0.75
Batch: 620; loss: 0.77; acc: 0.78
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.44; acc: 0.84
Batch: 680; loss: 0.91; acc: 0.75
Batch: 700; loss: 0.72; acc: 0.78
Batch: 720; loss: 1.05; acc: 0.64
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.64; acc: 0.78
Batch: 780; loss: 0.72; acc: 0.73
Train Epoch over. train_loss: 0.73; train_accuracy: 0.77 

2.3675640477449633e-05
7.627085778949549e-06
Batch: 0; loss: 0.68; acc: 0.8
Batch: 20; loss: 0.87; acc: 0.59
Batch: 40; loss: 0.6; acc: 0.83
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.74; acc: 0.75
Batch: 120; loss: 1.12; acc: 0.62
Batch: 140; loss: 0.55; acc: 0.86
Val Epoch over. val_loss: 0.6882711328138971; val_accuracy: 0.7792595541401274 

The current subspace-distance is: 7.627085778949549e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.74; acc: 0.73
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.55; acc: 0.81
Batch: 60; loss: 0.8; acc: 0.73
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 0.61; acc: 0.81
Batch: 120; loss: 0.86; acc: 0.7
Batch: 140; loss: 0.69; acc: 0.73
Batch: 160; loss: 0.81; acc: 0.78
Batch: 180; loss: 0.8; acc: 0.77
Batch: 200; loss: 0.83; acc: 0.7
Batch: 220; loss: 0.79; acc: 0.8
Batch: 240; loss: 0.66; acc: 0.78
Batch: 260; loss: 0.78; acc: 0.73
Batch: 280; loss: 0.9; acc: 0.77
Batch: 300; loss: 0.63; acc: 0.77
Batch: 320; loss: 0.87; acc: 0.73
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.76; acc: 0.77
Batch: 380; loss: 0.85; acc: 0.77
Batch: 400; loss: 0.84; acc: 0.7
Batch: 420; loss: 0.72; acc: 0.83
Batch: 440; loss: 0.79; acc: 0.73
Batch: 460; loss: 0.59; acc: 0.75
Batch: 480; loss: 0.62; acc: 0.81
Batch: 500; loss: 0.76; acc: 0.73
Batch: 520; loss: 0.89; acc: 0.67
Batch: 540; loss: 0.96; acc: 0.67
Batch: 560; loss: 1.05; acc: 0.66
Batch: 580; loss: 0.87; acc: 0.8
Batch: 600; loss: 0.54; acc: 0.81
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 0.72; acc: 0.8
Batch: 660; loss: 0.73; acc: 0.77
Batch: 680; loss: 0.73; acc: 0.78
Batch: 700; loss: 0.83; acc: 0.8
Batch: 720; loss: 0.78; acc: 0.8
Batch: 740; loss: 0.48; acc: 0.89
Batch: 760; loss: 0.77; acc: 0.72
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.72; train_accuracy: 0.77 

2.3838001652620733e-05
7.661788004043046e-06
Batch: 0; loss: 0.6; acc: 0.84
Batch: 20; loss: 0.92; acc: 0.62
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.68; acc: 0.78
Batch: 120; loss: 1.05; acc: 0.69
Batch: 140; loss: 0.55; acc: 0.75
Val Epoch over. val_loss: 0.6983155042502531; val_accuracy: 0.7722929936305732 

The current subspace-distance is: 7.661788004043046e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.88; acc: 0.67
Batch: 20; loss: 0.64; acc: 0.75
Batch: 40; loss: 0.92; acc: 0.69
Batch: 60; loss: 0.76; acc: 0.73
Batch: 80; loss: 0.82; acc: 0.73
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.72; acc: 0.72
Batch: 160; loss: 0.81; acc: 0.67
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.72; acc: 0.77
Batch: 240; loss: 0.7; acc: 0.78
Batch: 260; loss: 0.62; acc: 0.81
Batch: 280; loss: 0.66; acc: 0.83
Batch: 300; loss: 0.8; acc: 0.75
Batch: 320; loss: 0.65; acc: 0.77
Batch: 340; loss: 0.71; acc: 0.78
Batch: 360; loss: 0.76; acc: 0.7
Batch: 380; loss: 0.79; acc: 0.8
Batch: 400; loss: 0.8; acc: 0.75
Batch: 420; loss: 0.49; acc: 0.81
Batch: 440; loss: 0.85; acc: 0.77
Batch: 460; loss: 0.86; acc: 0.81
Batch: 480; loss: 1.03; acc: 0.69
Batch: 500; loss: 0.69; acc: 0.77
Batch: 520; loss: 0.9; acc: 0.69
Batch: 540; loss: 0.67; acc: 0.77
Batch: 560; loss: 0.83; acc: 0.7
Batch: 580; loss: 0.85; acc: 0.75
Batch: 600; loss: 0.63; acc: 0.75
Batch: 620; loss: 0.72; acc: 0.8
Batch: 640; loss: 0.71; acc: 0.8
Batch: 660; loss: 0.93; acc: 0.75
Batch: 680; loss: 0.81; acc: 0.7
Batch: 700; loss: 0.73; acc: 0.77
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.76; acc: 0.7
Batch: 760; loss: 0.57; acc: 0.81
Batch: 780; loss: 1.01; acc: 0.77
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

2.4518447389709763e-05
7.125296178855933e-06
Batch: 0; loss: 0.64; acc: 0.84
Batch: 20; loss: 0.85; acc: 0.69
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.59; acc: 0.8
Batch: 100; loss: 0.7; acc: 0.77
Batch: 120; loss: 1.01; acc: 0.7
Batch: 140; loss: 0.56; acc: 0.75
Val Epoch over. val_loss: 0.6945090996232003; val_accuracy: 0.7758757961783439 

The current subspace-distance is: 7.125296178855933e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.83; acc: 0.73
Batch: 20; loss: 0.76; acc: 0.77
Batch: 40; loss: 0.65; acc: 0.86
Batch: 60; loss: 0.65; acc: 0.88
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.77; acc: 0.75
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.86; acc: 0.69
Batch: 160; loss: 0.82; acc: 0.69
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.79; acc: 0.72
Batch: 220; loss: 0.68; acc: 0.75
Batch: 240; loss: 0.51; acc: 0.86
Batch: 260; loss: 0.71; acc: 0.72
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.72; acc: 0.77
Batch: 320; loss: 0.66; acc: 0.72
Batch: 340; loss: 0.74; acc: 0.78
Batch: 360; loss: 0.66; acc: 0.78
Batch: 380; loss: 0.78; acc: 0.69
Batch: 400; loss: 0.95; acc: 0.72
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 0.65; acc: 0.77
Batch: 460; loss: 0.65; acc: 0.8
Batch: 480; loss: 0.76; acc: 0.75
Batch: 500; loss: 0.71; acc: 0.8
Batch: 520; loss: 0.83; acc: 0.78
Batch: 540; loss: 1.0; acc: 0.69
Batch: 560; loss: 0.77; acc: 0.75
Batch: 580; loss: 0.55; acc: 0.81
Batch: 600; loss: 0.88; acc: 0.73
Batch: 620; loss: 0.66; acc: 0.81
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.81
Batch: 700; loss: 0.61; acc: 0.78
Batch: 720; loss: 0.47; acc: 0.83
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.79; acc: 0.77
Batch: 780; loss: 0.88; acc: 0.61
Train Epoch over. train_loss: 0.71; train_accuracy: 0.77 

2.4760307496762834e-05
8.197522220143583e-06
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.94; acc: 0.58
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 0.65; acc: 0.8
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 1.26; acc: 0.62
Batch: 140; loss: 0.69; acc: 0.7
Val Epoch over. val_loss: 0.7763675272844399; val_accuracy: 0.7486066878980892 

The current subspace-distance is: 8.197522220143583e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.75; acc: 0.8
Batch: 20; loss: 0.75; acc: 0.78
Batch: 40; loss: 0.7; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.77
Batch: 80; loss: 0.84; acc: 0.73
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.77; acc: 0.75
Batch: 140; loss: 0.79; acc: 0.78
Batch: 160; loss: 0.73; acc: 0.8
Batch: 180; loss: 0.85; acc: 0.73
Batch: 200; loss: 0.85; acc: 0.73
Batch: 220; loss: 0.64; acc: 0.81
Batch: 240; loss: 0.68; acc: 0.73
Batch: 260; loss: 0.63; acc: 0.78
Batch: 280; loss: 0.75; acc: 0.77
Batch: 300; loss: 0.67; acc: 0.8
Batch: 320; loss: 0.64; acc: 0.81
Batch: 340; loss: 0.87; acc: 0.67
Batch: 360; loss: 0.78; acc: 0.7
Batch: 380; loss: 0.62; acc: 0.83
Batch: 400; loss: 0.69; acc: 0.78
Batch: 420; loss: 0.83; acc: 0.7
Batch: 440; loss: 0.72; acc: 0.78
Batch: 460; loss: 0.76; acc: 0.77
Batch: 480; loss: 0.43; acc: 0.88
Batch: 500; loss: 0.86; acc: 0.72
Batch: 520; loss: 0.57; acc: 0.78
Batch: 540; loss: 0.91; acc: 0.7
Batch: 560; loss: 0.82; acc: 0.72
Batch: 580; loss: 0.83; acc: 0.78
Batch: 600; loss: 0.77; acc: 0.73
Batch: 620; loss: 0.41; acc: 0.88
Batch: 640; loss: 0.58; acc: 0.8
Batch: 660; loss: 0.83; acc: 0.7
Batch: 680; loss: 0.72; acc: 0.75
Batch: 700; loss: 0.65; acc: 0.73
Batch: 720; loss: 0.54; acc: 0.78
Batch: 740; loss: 0.89; acc: 0.69
Batch: 760; loss: 0.9; acc: 0.73
Batch: 780; loss: 0.72; acc: 0.77
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

2.78188399533974e-05
7.866736268624663e-06
Batch: 0; loss: 0.62; acc: 0.81
Batch: 20; loss: 0.81; acc: 0.66
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.62; acc: 0.84
Batch: 80; loss: 0.51; acc: 0.81
Batch: 100; loss: 0.64; acc: 0.77
Batch: 120; loss: 1.15; acc: 0.64
Batch: 140; loss: 0.55; acc: 0.81
Val Epoch over. val_loss: 0.674679094818747; val_accuracy: 0.7860270700636943 

The current subspace-distance is: 7.866736268624663e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.5; acc: 0.81
Batch: 40; loss: 0.71; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.75
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.76; acc: 0.78
Batch: 160; loss: 0.6; acc: 0.83
Batch: 180; loss: 0.6; acc: 0.83
Batch: 200; loss: 1.0; acc: 0.69
Batch: 220; loss: 0.62; acc: 0.84
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.74; acc: 0.77
Batch: 280; loss: 0.83; acc: 0.73
Batch: 300; loss: 0.56; acc: 0.81
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 1.05; acc: 0.66
Batch: 360; loss: 0.71; acc: 0.81
Batch: 380; loss: 0.59; acc: 0.84
Batch: 400; loss: 0.67; acc: 0.78
Batch: 420; loss: 0.68; acc: 0.77
Batch: 440; loss: 0.65; acc: 0.78
Batch: 460; loss: 0.61; acc: 0.83
Batch: 480; loss: 0.78; acc: 0.77
Batch: 500; loss: 0.55; acc: 0.86
Batch: 520; loss: 0.46; acc: 0.81
Batch: 540; loss: 0.76; acc: 0.78
Batch: 560; loss: 0.69; acc: 0.77
Batch: 580; loss: 0.79; acc: 0.75
Batch: 600; loss: 0.53; acc: 0.83
Batch: 620; loss: 0.69; acc: 0.75
Batch: 640; loss: 0.73; acc: 0.75
Batch: 660; loss: 0.45; acc: 0.88
Batch: 680; loss: 0.56; acc: 0.84
Batch: 700; loss: 0.54; acc: 0.81
Batch: 720; loss: 0.82; acc: 0.8
Batch: 740; loss: 0.51; acc: 0.86
Batch: 760; loss: 0.54; acc: 0.8
Batch: 780; loss: 0.79; acc: 0.8
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.428635343676433e-05
7.544154868810438e-06
Batch: 0; loss: 0.67; acc: 0.8
Batch: 20; loss: 0.82; acc: 0.69
Batch: 40; loss: 0.54; acc: 0.8
Batch: 60; loss: 0.63; acc: 0.86
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 1.21; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.83
Val Epoch over. val_loss: 0.6488827797257977; val_accuracy: 0.79578025477707 

The current subspace-distance is: 7.544154868810438e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.79; acc: 0.78
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.73
Batch: 80; loss: 0.87; acc: 0.73
Batch: 100; loss: 0.75; acc: 0.75
Batch: 120; loss: 1.01; acc: 0.62
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.66; acc: 0.83
Batch: 180; loss: 0.78; acc: 0.77
Batch: 200; loss: 0.85; acc: 0.72
Batch: 220; loss: 0.76; acc: 0.73
Batch: 240; loss: 0.94; acc: 0.69
Batch: 260; loss: 0.7; acc: 0.77
Batch: 280; loss: 0.95; acc: 0.72
Batch: 300; loss: 1.02; acc: 0.73
Batch: 320; loss: 0.74; acc: 0.8
Batch: 340; loss: 0.48; acc: 0.81
Batch: 360; loss: 0.77; acc: 0.72
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.43; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.78; acc: 0.83
Batch: 460; loss: 0.61; acc: 0.81
Batch: 480; loss: 0.67; acc: 0.86
Batch: 500; loss: 0.67; acc: 0.77
Batch: 520; loss: 0.71; acc: 0.81
Batch: 540; loss: 0.68; acc: 0.73
Batch: 560; loss: 0.68; acc: 0.8
Batch: 580; loss: 0.75; acc: 0.77
Batch: 600; loss: 0.71; acc: 0.8
Batch: 620; loss: 0.82; acc: 0.78
Batch: 640; loss: 0.63; acc: 0.78
Batch: 660; loss: 0.71; acc: 0.83
Batch: 680; loss: 0.74; acc: 0.8
Batch: 700; loss: 0.73; acc: 0.72
Batch: 720; loss: 0.68; acc: 0.83
Batch: 740; loss: 0.72; acc: 0.72
Batch: 760; loss: 0.63; acc: 0.86
Batch: 780; loss: 0.96; acc: 0.67
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.4539680453017354e-05
8.391983101319056e-06
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 0.83; acc: 0.67
Batch: 40; loss: 0.55; acc: 0.8
Batch: 60; loss: 0.62; acc: 0.88
Batch: 80; loss: 0.54; acc: 0.81
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 1.23; acc: 0.67
Batch: 140; loss: 0.47; acc: 0.81
Val Epoch over. val_loss: 0.6439941859549019; val_accuracy: 0.7945859872611465 

The current subspace-distance is: 8.391983101319056e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.99; acc: 0.7
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.83; acc: 0.69
Batch: 100; loss: 0.67; acc: 0.78
Batch: 120; loss: 0.54; acc: 0.78
Batch: 140; loss: 0.84; acc: 0.73
Batch: 160; loss: 0.56; acc: 0.81
Batch: 180; loss: 0.7; acc: 0.78
Batch: 200; loss: 0.85; acc: 0.75
Batch: 220; loss: 0.66; acc: 0.8
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.72; acc: 0.81
Batch: 280; loss: 0.78; acc: 0.67
Batch: 300; loss: 0.59; acc: 0.88
Batch: 320; loss: 0.73; acc: 0.77
Batch: 340; loss: 0.64; acc: 0.8
Batch: 360; loss: 0.61; acc: 0.81
Batch: 380; loss: 0.54; acc: 0.81
Batch: 400; loss: 0.85; acc: 0.7
Batch: 420; loss: 0.49; acc: 0.81
Batch: 440; loss: 0.57; acc: 0.86
Batch: 460; loss: 0.97; acc: 0.73
Batch: 480; loss: 0.66; acc: 0.81
Batch: 500; loss: 0.64; acc: 0.8
Batch: 520; loss: 0.79; acc: 0.75
Batch: 540; loss: 0.55; acc: 0.83
Batch: 560; loss: 0.61; acc: 0.86
Batch: 580; loss: 0.55; acc: 0.8
Batch: 600; loss: 1.02; acc: 0.73
Batch: 620; loss: 0.6; acc: 0.8
Batch: 640; loss: 0.84; acc: 0.77
Batch: 660; loss: 0.66; acc: 0.75
Batch: 680; loss: 0.6; acc: 0.86
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.7; acc: 0.78
Batch: 740; loss: 0.78; acc: 0.75
Batch: 760; loss: 0.56; acc: 0.75
Batch: 780; loss: 0.98; acc: 0.67
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.5700910555315204e-05
7.516513051086804e-06
Batch: 0; loss: 0.68; acc: 0.8
Batch: 20; loss: 0.79; acc: 0.72
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.65; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 1.3; acc: 0.7
Batch: 140; loss: 0.46; acc: 0.83
Val Epoch over. val_loss: 0.6500938077261493; val_accuracy: 0.7966759554140127 

The current subspace-distance is: 7.516513051086804e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.96; acc: 0.67
Batch: 20; loss: 0.88; acc: 0.7
Batch: 40; loss: 0.64; acc: 0.77
Batch: 60; loss: 0.53; acc: 0.8
Batch: 80; loss: 0.98; acc: 0.67
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.89; acc: 0.72
Batch: 160; loss: 0.73; acc: 0.75
Batch: 180; loss: 0.45; acc: 0.86
Batch: 200; loss: 0.66; acc: 0.81
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.67; acc: 0.78
Batch: 260; loss: 0.93; acc: 0.64
Batch: 280; loss: 0.72; acc: 0.75
Batch: 300; loss: 0.58; acc: 0.83
Batch: 320; loss: 0.63; acc: 0.83
Batch: 340; loss: 0.45; acc: 0.84
Batch: 360; loss: 0.47; acc: 0.8
Batch: 380; loss: 0.78; acc: 0.77
Batch: 400; loss: 0.56; acc: 0.78
Batch: 420; loss: 0.7; acc: 0.72
Batch: 440; loss: 0.84; acc: 0.77
Batch: 460; loss: 0.68; acc: 0.77
Batch: 480; loss: 0.56; acc: 0.83
Batch: 500; loss: 0.77; acc: 0.75
Batch: 520; loss: 0.45; acc: 0.91
Batch: 540; loss: 0.77; acc: 0.78
Batch: 560; loss: 0.83; acc: 0.75
Batch: 580; loss: 0.76; acc: 0.78
Batch: 600; loss: 0.85; acc: 0.72
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.63; acc: 0.8
Batch: 660; loss: 0.79; acc: 0.7
Batch: 680; loss: 0.65; acc: 0.8
Batch: 700; loss: 0.99; acc: 0.78
Batch: 720; loss: 0.67; acc: 0.75
Batch: 740; loss: 0.68; acc: 0.81
Batch: 760; loss: 1.01; acc: 0.78
Batch: 780; loss: 0.82; acc: 0.72
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.5869212549878284e-05
7.1487020250060596e-06
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 0.8; acc: 0.69
Batch: 40; loss: 0.52; acc: 0.81
Batch: 60; loss: 0.65; acc: 0.83
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 1.26; acc: 0.66
Batch: 140; loss: 0.48; acc: 0.83
Val Epoch over. val_loss: 0.6463562616497088; val_accuracy: 0.7981687898089171 

The current subspace-distance is: 7.1487020250060596e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.66; acc: 0.8
Batch: 40; loss: 0.64; acc: 0.8
Batch: 60; loss: 1.05; acc: 0.67
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.74; acc: 0.77
Batch: 120; loss: 0.64; acc: 0.77
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 0.88; acc: 0.7
Batch: 180; loss: 0.76; acc: 0.73
Batch: 200; loss: 0.57; acc: 0.86
Batch: 220; loss: 0.72; acc: 0.73
Batch: 240; loss: 0.63; acc: 0.83
Batch: 260; loss: 0.83; acc: 0.73
Batch: 280; loss: 0.58; acc: 0.77
Batch: 300; loss: 0.61; acc: 0.81
Batch: 320; loss: 0.77; acc: 0.75
Batch: 340; loss: 0.58; acc: 0.78
Batch: 360; loss: 0.83; acc: 0.75
Batch: 380; loss: 0.67; acc: 0.83
Batch: 400; loss: 0.7; acc: 0.73
Batch: 420; loss: 0.54; acc: 0.77
Batch: 440; loss: 0.57; acc: 0.83
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.54; acc: 0.8
Batch: 500; loss: 0.8; acc: 0.73
Batch: 520; loss: 0.94; acc: 0.66
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.49; acc: 0.91
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.69; acc: 0.77
Batch: 640; loss: 0.72; acc: 0.77
Batch: 660; loss: 0.73; acc: 0.83
Batch: 680; loss: 1.04; acc: 0.64
Batch: 700; loss: 0.57; acc: 0.8
Batch: 720; loss: 0.56; acc: 0.83
Batch: 740; loss: 0.81; acc: 0.77
Batch: 760; loss: 0.83; acc: 0.72
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.432252404105384e-05
7.64644119044533e-06
Batch: 0; loss: 0.67; acc: 0.8
Batch: 20; loss: 0.79; acc: 0.72
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.63; acc: 0.84
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.61; acc: 0.77
Batch: 120; loss: 1.2; acc: 0.69
Batch: 140; loss: 0.46; acc: 0.81
Val Epoch over. val_loss: 0.6397087389876128; val_accuracy: 0.7991640127388535 

The current subspace-distance is: 7.64644119044533e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.92; acc: 0.75
Batch: 40; loss: 0.74; acc: 0.8
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.81; acc: 0.73
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.73; acc: 0.81
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.51; acc: 0.91
Batch: 200; loss: 0.5; acc: 0.81
Batch: 220; loss: 0.93; acc: 0.78
Batch: 240; loss: 0.94; acc: 0.77
Batch: 260; loss: 0.52; acc: 0.81
Batch: 280; loss: 0.58; acc: 0.78
Batch: 300; loss: 0.75; acc: 0.8
Batch: 320; loss: 0.74; acc: 0.77
Batch: 340; loss: 0.48; acc: 0.84
Batch: 360; loss: 0.55; acc: 0.84
Batch: 380; loss: 0.6; acc: 0.78
Batch: 400; loss: 0.64; acc: 0.83
Batch: 420; loss: 0.69; acc: 0.77
Batch: 440; loss: 0.56; acc: 0.84
Batch: 460; loss: 0.62; acc: 0.75
Batch: 480; loss: 0.48; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.8
Batch: 520; loss: 0.48; acc: 0.86
Batch: 540; loss: 0.74; acc: 0.78
Batch: 560; loss: 0.59; acc: 0.78
Batch: 580; loss: 0.51; acc: 0.83
Batch: 600; loss: 0.62; acc: 0.83
Batch: 620; loss: 0.77; acc: 0.77
Batch: 640; loss: 0.59; acc: 0.78
Batch: 660; loss: 0.56; acc: 0.78
Batch: 680; loss: 0.59; acc: 0.84
Batch: 700; loss: 0.65; acc: 0.8
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.69; acc: 0.86
Batch: 780; loss: 0.45; acc: 0.91
Train Epoch over. train_loss: 0.68; train_accuracy: 0.79 

2.6202958906651475e-05
6.5689246184774674e-06
Batch: 0; loss: 0.68; acc: 0.81
Batch: 20; loss: 0.79; acc: 0.69
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.66; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.61; acc: 0.78
Batch: 120; loss: 1.21; acc: 0.67
Batch: 140; loss: 0.49; acc: 0.81
Val Epoch over. val_loss: 0.6508367103376206; val_accuracy: 0.7931926751592356 

The current subspace-distance is: 6.5689246184774674e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.86; acc: 0.72
Batch: 20; loss: 0.79; acc: 0.77
Batch: 40; loss: 0.87; acc: 0.77
Batch: 60; loss: 0.95; acc: 0.78
Batch: 80; loss: 0.68; acc: 0.8
Batch: 100; loss: 0.72; acc: 0.78
Batch: 120; loss: 0.51; acc: 0.8
Batch: 140; loss: 0.78; acc: 0.77
Batch: 160; loss: 0.6; acc: 0.73
Batch: 180; loss: 0.66; acc: 0.81
Batch: 200; loss: 0.57; acc: 0.78
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 0.57; acc: 0.81
Batch: 260; loss: 0.66; acc: 0.73
Batch: 280; loss: 0.73; acc: 0.8
Batch: 300; loss: 0.96; acc: 0.77
Batch: 320; loss: 0.59; acc: 0.84
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.69; acc: 0.72
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.76; acc: 0.77
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.69; acc: 0.75
Batch: 480; loss: 0.59; acc: 0.88
Batch: 500; loss: 0.91; acc: 0.72
Batch: 520; loss: 0.61; acc: 0.83
Batch: 540; loss: 0.71; acc: 0.8
Batch: 560; loss: 0.51; acc: 0.8
Batch: 580; loss: 0.48; acc: 0.81
Batch: 600; loss: 0.82; acc: 0.7
Batch: 620; loss: 0.56; acc: 0.84
Batch: 640; loss: 0.63; acc: 0.8
Batch: 660; loss: 0.71; acc: 0.77
Batch: 680; loss: 0.72; acc: 0.75
Batch: 700; loss: 0.68; acc: 0.77
Batch: 720; loss: 0.77; acc: 0.7
Batch: 740; loss: 0.71; acc: 0.73
Batch: 760; loss: 0.69; acc: 0.81
Batch: 780; loss: 0.44; acc: 0.91
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.4472170480294153e-05
7.751169505354483e-06
Batch: 0; loss: 0.68; acc: 0.8
Batch: 20; loss: 0.83; acc: 0.69
Batch: 40; loss: 0.52; acc: 0.81
Batch: 60; loss: 0.66; acc: 0.83
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 1.3; acc: 0.66
Batch: 140; loss: 0.49; acc: 0.81
Val Epoch over. val_loss: 0.6516075944824583; val_accuracy: 0.7934912420382165 

The current subspace-distance is: 7.751169505354483e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.89; acc: 0.75
Batch: 20; loss: 0.72; acc: 0.77
Batch: 40; loss: 0.54; acc: 0.78
Batch: 60; loss: 0.68; acc: 0.75
Batch: 80; loss: 0.61; acc: 0.78
Batch: 100; loss: 1.01; acc: 0.73
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.66; acc: 0.73
Batch: 160; loss: 0.89; acc: 0.77
Batch: 180; loss: 0.66; acc: 0.81
Batch: 200; loss: 0.66; acc: 0.78
Batch: 220; loss: 0.77; acc: 0.77
Batch: 240; loss: 0.71; acc: 0.77
Batch: 260; loss: 0.74; acc: 0.73
Batch: 280; loss: 0.75; acc: 0.81
Batch: 300; loss: 0.99; acc: 0.66
Batch: 320; loss: 0.66; acc: 0.8
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.8; acc: 0.73
Batch: 400; loss: 0.87; acc: 0.73
Batch: 420; loss: 0.65; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.79; acc: 0.77
Batch: 500; loss: 0.56; acc: 0.78
Batch: 520; loss: 0.77; acc: 0.77
Batch: 540; loss: 0.69; acc: 0.75
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.55; acc: 0.84
Batch: 600; loss: 0.56; acc: 0.84
Batch: 620; loss: 0.6; acc: 0.81
Batch: 640; loss: 0.52; acc: 0.8
Batch: 660; loss: 0.64; acc: 0.78
Batch: 680; loss: 0.62; acc: 0.77
Batch: 700; loss: 0.69; acc: 0.75
Batch: 720; loss: 1.22; acc: 0.66
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.8; acc: 0.78
Batch: 780; loss: 0.62; acc: 0.86
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.31188751058653e-05
7.159716460591881e-06
Batch: 0; loss: 0.7; acc: 0.8
Batch: 20; loss: 0.79; acc: 0.69
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.6; acc: 0.77
Batch: 120; loss: 1.19; acc: 0.69
Batch: 140; loss: 0.45; acc: 0.83
Val Epoch over. val_loss: 0.6351532450147496; val_accuracy: 0.7982683121019108 

The current subspace-distance is: 7.159716460591881e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.81; acc: 0.67
Batch: 20; loss: 0.85; acc: 0.75
Batch: 40; loss: 0.54; acc: 0.81
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.87; acc: 0.77
Batch: 100; loss: 0.72; acc: 0.78
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.72; acc: 0.75
Batch: 160; loss: 0.42; acc: 0.88
Batch: 180; loss: 0.65; acc: 0.8
Batch: 200; loss: 0.68; acc: 0.86
Batch: 220; loss: 0.88; acc: 0.73
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.83
Batch: 280; loss: 0.57; acc: 0.83
Batch: 300; loss: 0.66; acc: 0.75
Batch: 320; loss: 0.63; acc: 0.8
Batch: 340; loss: 0.78; acc: 0.75
Batch: 360; loss: 0.5; acc: 0.83
Batch: 380; loss: 0.62; acc: 0.75
Batch: 400; loss: 0.78; acc: 0.75
Batch: 420; loss: 0.73; acc: 0.83
Batch: 440; loss: 0.65; acc: 0.83
Batch: 460; loss: 0.59; acc: 0.81
Batch: 480; loss: 0.72; acc: 0.81
Batch: 500; loss: 0.66; acc: 0.75
Batch: 520; loss: 0.78; acc: 0.73
Batch: 540; loss: 0.57; acc: 0.83
Batch: 560; loss: 0.62; acc: 0.8
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.69; acc: 0.81
Batch: 620; loss: 0.6; acc: 0.8
Batch: 640; loss: 0.67; acc: 0.75
Batch: 660; loss: 0.86; acc: 0.73
Batch: 680; loss: 0.66; acc: 0.81
Batch: 700; loss: 0.8; acc: 0.8
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.91; acc: 0.7
Batch: 760; loss: 0.98; acc: 0.67
Batch: 780; loss: 0.64; acc: 0.78
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.370422225794755e-05
7.223847205750644e-06
Batch: 0; loss: 0.71; acc: 0.77
Batch: 20; loss: 0.83; acc: 0.67
Batch: 40; loss: 0.49; acc: 0.81
Batch: 60; loss: 0.67; acc: 0.78
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.67; acc: 0.78
Batch: 120; loss: 1.28; acc: 0.66
Batch: 140; loss: 0.48; acc: 0.84
Val Epoch over. val_loss: 0.64496183357421; val_accuracy: 0.7959792993630573 

The current subspace-distance is: 7.223847205750644e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 0.92; acc: 0.62
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.62; acc: 0.77
Batch: 80; loss: 0.84; acc: 0.73
Batch: 100; loss: 0.56; acc: 0.75
Batch: 120; loss: 0.9; acc: 0.7
Batch: 140; loss: 0.52; acc: 0.8
Batch: 160; loss: 0.65; acc: 0.83
Batch: 180; loss: 0.77; acc: 0.75
Batch: 200; loss: 0.79; acc: 0.8
Batch: 220; loss: 1.03; acc: 0.67
Batch: 240; loss: 0.76; acc: 0.78
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 1.02; acc: 0.66
Batch: 320; loss: 0.68; acc: 0.78
Batch: 340; loss: 0.59; acc: 0.84
Batch: 360; loss: 0.8; acc: 0.78
Batch: 380; loss: 0.73; acc: 0.75
Batch: 400; loss: 0.73; acc: 0.8
Batch: 420; loss: 0.71; acc: 0.78
Batch: 440; loss: 0.96; acc: 0.72
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.56; acc: 0.8
Batch: 500; loss: 0.57; acc: 0.84
Batch: 520; loss: 0.59; acc: 0.83
Batch: 540; loss: 0.86; acc: 0.69
Batch: 560; loss: 0.67; acc: 0.78
Batch: 580; loss: 0.75; acc: 0.73
Batch: 600; loss: 0.67; acc: 0.8
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.87; acc: 0.73
Batch: 660; loss: 0.85; acc: 0.78
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.76; acc: 0.72
Batch: 720; loss: 0.51; acc: 0.8
Batch: 740; loss: 0.66; acc: 0.88
Batch: 760; loss: 0.78; acc: 0.72
Batch: 780; loss: 0.72; acc: 0.77
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.4703893359401263e-05
7.795407327648718e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.77; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.53; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.78
Batch: 120; loss: 1.26; acc: 0.67
Batch: 140; loss: 0.45; acc: 0.86
Val Epoch over. val_loss: 0.6373145242405546; val_accuracy: 0.7996616242038217 

The current subspace-distance is: 7.795407327648718e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.55; acc: 0.83
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.47; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.56; acc: 0.84
Batch: 120; loss: 0.77; acc: 0.81
Batch: 140; loss: 0.6; acc: 0.75
Batch: 160; loss: 0.71; acc: 0.78
Batch: 180; loss: 0.72; acc: 0.84
Batch: 200; loss: 0.79; acc: 0.73
Batch: 220; loss: 0.6; acc: 0.75
Batch: 240; loss: 0.66; acc: 0.78
Batch: 260; loss: 0.89; acc: 0.77
Batch: 280; loss: 0.64; acc: 0.83
Batch: 300; loss: 0.74; acc: 0.75
Batch: 320; loss: 0.85; acc: 0.72
Batch: 340; loss: 0.52; acc: 0.81
Batch: 360; loss: 0.69; acc: 0.73
Batch: 380; loss: 0.65; acc: 0.8
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.58; acc: 0.77
Batch: 440; loss: 0.57; acc: 0.78
Batch: 460; loss: 0.95; acc: 0.7
Batch: 480; loss: 0.72; acc: 0.8
Batch: 500; loss: 0.73; acc: 0.77
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.47; acc: 0.89
Batch: 560; loss: 0.73; acc: 0.77
Batch: 580; loss: 0.67; acc: 0.81
Batch: 600; loss: 0.73; acc: 0.78
Batch: 620; loss: 0.7; acc: 0.77
Batch: 640; loss: 0.63; acc: 0.78
Batch: 660; loss: 0.87; acc: 0.73
Batch: 680; loss: 0.72; acc: 0.8
Batch: 700; loss: 0.62; acc: 0.81
Batch: 720; loss: 0.89; acc: 0.75
Batch: 740; loss: 0.64; acc: 0.8
Batch: 760; loss: 0.73; acc: 0.77
Batch: 780; loss: 0.8; acc: 0.73
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.3964075808180496e-05
7.394991371256765e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.73
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.83
Batch: 100; loss: 0.6; acc: 0.75
Batch: 120; loss: 1.15; acc: 0.72
Batch: 140; loss: 0.44; acc: 0.86
Val Epoch over. val_loss: 0.6376650120801987; val_accuracy: 0.7959792993630573 

The current subspace-distance is: 7.394991371256765e-06 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.52; acc: 0.91
Batch: 20; loss: 0.7; acc: 0.84
Batch: 40; loss: 0.57; acc: 0.83
Batch: 60; loss: 0.73; acc: 0.73
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.74; acc: 0.75
Batch: 120; loss: 0.72; acc: 0.83
Batch: 140; loss: 0.85; acc: 0.78
Batch: 160; loss: 0.77; acc: 0.78
Batch: 180; loss: 0.78; acc: 0.78
Batch: 200; loss: 0.8; acc: 0.77
Batch: 220; loss: 0.58; acc: 0.81
Batch: 240; loss: 0.74; acc: 0.77
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 0.64; acc: 0.72
Batch: 300; loss: 0.64; acc: 0.73
Batch: 320; loss: 0.38; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.61; acc: 0.81
Batch: 380; loss: 0.67; acc: 0.78
Batch: 400; loss: 0.83; acc: 0.77
Batch: 420; loss: 0.75; acc: 0.75
Batch: 440; loss: 0.75; acc: 0.73
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.79; acc: 0.8
Batch: 500; loss: 0.56; acc: 0.84
Batch: 520; loss: 0.69; acc: 0.75
Batch: 540; loss: 0.72; acc: 0.8
Batch: 560; loss: 0.81; acc: 0.72
Batch: 580; loss: 0.66; acc: 0.77
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.72; acc: 0.8
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.56; acc: 0.81
Batch: 680; loss: 1.07; acc: 0.66
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.72; acc: 0.77
Batch: 760; loss: 0.62; acc: 0.81
Batch: 780; loss: 0.7; acc: 0.72
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.3819144189474173e-05
8.91948275238974e-06
Batch: 0; loss: 0.72; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.69
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.69; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.77
Batch: 120; loss: 1.24; acc: 0.72
Batch: 140; loss: 0.46; acc: 0.84
Val Epoch over. val_loss: 0.6366800504505254; val_accuracy: 0.7986664012738853 

The current subspace-distance is: 8.91948275238974e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.79; acc: 0.73
Batch: 40; loss: 0.48; acc: 0.88
Batch: 60; loss: 0.81; acc: 0.69
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.58; acc: 0.83
Batch: 160; loss: 0.63; acc: 0.84
Batch: 180; loss: 0.8; acc: 0.75
Batch: 200; loss: 0.5; acc: 0.8
Batch: 220; loss: 0.65; acc: 0.81
Batch: 240; loss: 0.53; acc: 0.84
Batch: 260; loss: 0.56; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.92
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.91; acc: 0.7
Batch: 340; loss: 0.55; acc: 0.8
Batch: 360; loss: 0.5; acc: 0.88
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.67; acc: 0.8
Batch: 420; loss: 0.69; acc: 0.84
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.68; acc: 0.77
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.64; acc: 0.78
Batch: 540; loss: 0.5; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.97; acc: 0.73
Batch: 600; loss: 0.66; acc: 0.83
Batch: 620; loss: 0.8; acc: 0.8
Batch: 640; loss: 0.6; acc: 0.81
Batch: 660; loss: 0.96; acc: 0.73
Batch: 680; loss: 0.5; acc: 0.84
Batch: 700; loss: 0.69; acc: 0.81
Batch: 720; loss: 0.78; acc: 0.7
Batch: 740; loss: 0.71; acc: 0.78
Batch: 760; loss: 0.66; acc: 0.78
Batch: 780; loss: 1.05; acc: 0.72
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.492064049874898e-05
7.313490641536191e-06
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.66
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.63; acc: 0.77
Batch: 120; loss: 1.22; acc: 0.7
Batch: 140; loss: 0.42; acc: 0.91
Val Epoch over. val_loss: 0.6364763897315712; val_accuracy: 0.7972730891719745 

The current subspace-distance is: 7.313490641536191e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.83; acc: 0.72
Batch: 20; loss: 0.77; acc: 0.77
Batch: 40; loss: 0.44; acc: 0.81
Batch: 60; loss: 0.65; acc: 0.78
Batch: 80; loss: 0.85; acc: 0.7
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 0.75; acc: 0.78
Batch: 140; loss: 0.74; acc: 0.8
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.7; acc: 0.78
Batch: 200; loss: 0.66; acc: 0.77
Batch: 220; loss: 0.54; acc: 0.78
Batch: 240; loss: 0.63; acc: 0.8
Batch: 260; loss: 0.89; acc: 0.67
Batch: 280; loss: 0.72; acc: 0.75
Batch: 300; loss: 0.67; acc: 0.78
Batch: 320; loss: 0.84; acc: 0.77
Batch: 340; loss: 0.6; acc: 0.83
Batch: 360; loss: 0.7; acc: 0.83
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.59; acc: 0.84
Batch: 420; loss: 0.85; acc: 0.7
Batch: 440; loss: 0.93; acc: 0.66
Batch: 460; loss: 0.69; acc: 0.78
Batch: 480; loss: 0.53; acc: 0.86
Batch: 500; loss: 0.72; acc: 0.78
Batch: 520; loss: 0.65; acc: 0.75
Batch: 540; loss: 0.65; acc: 0.78
Batch: 560; loss: 0.79; acc: 0.77
Batch: 580; loss: 0.73; acc: 0.75
Batch: 600; loss: 1.0; acc: 0.72
Batch: 620; loss: 0.87; acc: 0.75
Batch: 640; loss: 0.6; acc: 0.8
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.67; acc: 0.81
Batch: 700; loss: 1.04; acc: 0.73
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.69; acc: 0.75
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.3380616767099127e-05
7.718234883213881e-06
Batch: 0; loss: 0.75; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.53; acc: 0.86
Batch: 100; loss: 0.64; acc: 0.78
Batch: 120; loss: 1.29; acc: 0.7
Batch: 140; loss: 0.45; acc: 0.86
Val Epoch over. val_loss: 0.636032556272616; val_accuracy: 0.8013535031847133 

The current subspace-distance is: 7.718234883213881e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.7; acc: 0.84
Batch: 20; loss: 0.56; acc: 0.84
Batch: 40; loss: 0.73; acc: 0.78
Batch: 60; loss: 0.62; acc: 0.77
Batch: 80; loss: 0.86; acc: 0.72
Batch: 100; loss: 0.56; acc: 0.83
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.54; acc: 0.78
Batch: 160; loss: 1.01; acc: 0.62
Batch: 180; loss: 0.48; acc: 0.88
Batch: 200; loss: 0.63; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.86
Batch: 240; loss: 0.85; acc: 0.77
Batch: 260; loss: 0.62; acc: 0.83
Batch: 280; loss: 0.76; acc: 0.81
Batch: 300; loss: 0.73; acc: 0.78
Batch: 320; loss: 0.45; acc: 0.91
Batch: 340; loss: 0.52; acc: 0.8
Batch: 360; loss: 0.83; acc: 0.75
Batch: 380; loss: 0.6; acc: 0.78
Batch: 400; loss: 0.79; acc: 0.78
Batch: 420; loss: 0.73; acc: 0.78
Batch: 440; loss: 0.56; acc: 0.81
Batch: 460; loss: 0.57; acc: 0.81
Batch: 480; loss: 0.63; acc: 0.8
Batch: 500; loss: 0.52; acc: 0.89
Batch: 520; loss: 0.65; acc: 0.73
Batch: 540; loss: 0.53; acc: 0.8
Batch: 560; loss: 0.74; acc: 0.8
Batch: 580; loss: 0.74; acc: 0.78
Batch: 600; loss: 0.73; acc: 0.81
Batch: 620; loss: 0.86; acc: 0.66
Batch: 640; loss: 0.66; acc: 0.8
Batch: 660; loss: 0.56; acc: 0.8
Batch: 680; loss: 0.65; acc: 0.78
Batch: 700; loss: 0.56; acc: 0.78
Batch: 720; loss: 0.6; acc: 0.84
Batch: 740; loss: 0.57; acc: 0.78
Batch: 760; loss: 0.76; acc: 0.75
Batch: 780; loss: 0.88; acc: 0.75
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.4063965611276217e-05
8.273261300928425e-06
Batch: 0; loss: 0.74; acc: 0.78
Batch: 20; loss: 0.81; acc: 0.69
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.67; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.86
Batch: 100; loss: 0.62; acc: 0.77
Batch: 120; loss: 1.21; acc: 0.7
Batch: 140; loss: 0.47; acc: 0.86
Val Epoch over. val_loss: 0.6384958769105802; val_accuracy: 0.7976711783439491 

The current subspace-distance is: 8.273261300928425e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.55; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.82; acc: 0.69
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.6; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.73
Batch: 140; loss: 0.5; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.91; acc: 0.72
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.81; acc: 0.8
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.66; acc: 0.8
Batch: 300; loss: 0.66; acc: 0.8
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.81
Batch: 360; loss: 0.62; acc: 0.8
Batch: 380; loss: 0.58; acc: 0.86
Batch: 400; loss: 0.86; acc: 0.73
Batch: 420; loss: 0.66; acc: 0.78
Batch: 440; loss: 0.83; acc: 0.7
Batch: 460; loss: 0.63; acc: 0.77
Batch: 480; loss: 0.82; acc: 0.75
Batch: 500; loss: 0.8; acc: 0.77
Batch: 520; loss: 0.91; acc: 0.66
Batch: 540; loss: 0.67; acc: 0.77
Batch: 560; loss: 0.59; acc: 0.78
Batch: 580; loss: 0.65; acc: 0.84
Batch: 600; loss: 0.52; acc: 0.8
Batch: 620; loss: 0.72; acc: 0.81
Batch: 640; loss: 0.68; acc: 0.81
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.55; acc: 0.88
Batch: 700; loss: 0.61; acc: 0.8
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.8; acc: 0.77
Batch: 760; loss: 0.76; acc: 0.8
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.5173854737658985e-05
7.348503004322993e-06
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.79; acc: 0.69
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 1.23; acc: 0.72
Batch: 140; loss: 0.45; acc: 0.84
Val Epoch over. val_loss: 0.6344525265465876; val_accuracy: 0.7972730891719745 

The current subspace-distance is: 7.348503004322993e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.64; acc: 0.77
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.73
Batch: 80; loss: 0.75; acc: 0.8
Batch: 100; loss: 0.78; acc: 0.75
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.74; acc: 0.75
Batch: 160; loss: 0.73; acc: 0.75
Batch: 180; loss: 0.66; acc: 0.77
Batch: 200; loss: 0.68; acc: 0.73
Batch: 220; loss: 0.53; acc: 0.8
Batch: 240; loss: 0.64; acc: 0.8
Batch: 260; loss: 0.81; acc: 0.7
Batch: 280; loss: 0.55; acc: 0.86
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 0.71; acc: 0.77
Batch: 340; loss: 0.88; acc: 0.77
Batch: 360; loss: 0.89; acc: 0.7
Batch: 380; loss: 0.69; acc: 0.8
Batch: 400; loss: 0.72; acc: 0.78
Batch: 420; loss: 0.73; acc: 0.78
Batch: 440; loss: 0.69; acc: 0.81
Batch: 460; loss: 0.68; acc: 0.8
Batch: 480; loss: 1.0; acc: 0.69
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.61; acc: 0.78
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.81; acc: 0.75
Batch: 580; loss: 0.92; acc: 0.72
Batch: 600; loss: 0.52; acc: 0.86
Batch: 620; loss: 1.0; acc: 0.75
Batch: 640; loss: 0.67; acc: 0.72
Batch: 660; loss: 0.55; acc: 0.86
Batch: 680; loss: 0.54; acc: 0.78
Batch: 700; loss: 0.47; acc: 0.88
Batch: 720; loss: 0.8; acc: 0.78
Batch: 740; loss: 0.78; acc: 0.72
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.5136992917396128e-05
8.424654879490845e-06
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.79; acc: 0.69
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.62; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.72
Batch: 140; loss: 0.45; acc: 0.86
Val Epoch over. val_loss: 0.6334200974102993; val_accuracy: 0.8019506369426752 

The current subspace-distance is: 8.424654879490845e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.64; acc: 0.75
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.63; acc: 0.8
Batch: 60; loss: 0.61; acc: 0.81
Batch: 80; loss: 0.46; acc: 0.91
Batch: 100; loss: 0.75; acc: 0.7
Batch: 120; loss: 0.51; acc: 0.86
Batch: 140; loss: 0.76; acc: 0.75
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.6; acc: 0.83
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.74; acc: 0.75
Batch: 240; loss: 0.66; acc: 0.73
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 0.74; acc: 0.78
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.53; acc: 0.84
Batch: 340; loss: 0.99; acc: 0.69
Batch: 360; loss: 0.66; acc: 0.84
Batch: 380; loss: 0.79; acc: 0.78
Batch: 400; loss: 1.17; acc: 0.64
Batch: 420; loss: 1.02; acc: 0.73
Batch: 440; loss: 1.11; acc: 0.7
Batch: 460; loss: 0.62; acc: 0.75
Batch: 480; loss: 0.62; acc: 0.8
Batch: 500; loss: 0.68; acc: 0.77
Batch: 520; loss: 0.66; acc: 0.77
Batch: 540; loss: 0.84; acc: 0.77
Batch: 560; loss: 0.58; acc: 0.78
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.61; acc: 0.8
Batch: 620; loss: 0.54; acc: 0.86
Batch: 640; loss: 0.7; acc: 0.78
Batch: 660; loss: 0.62; acc: 0.8
Batch: 680; loss: 0.65; acc: 0.8
Batch: 700; loss: 0.6; acc: 0.78
Batch: 720; loss: 0.59; acc: 0.81
Batch: 740; loss: 0.88; acc: 0.7
Batch: 760; loss: 0.55; acc: 0.88
Batch: 780; loss: 0.73; acc: 0.77
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.742726428550668e-05
7.394844033115078e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.69; acc: 0.78
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 1.23; acc: 0.7
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.6328576930389282; val_accuracy: 0.7993630573248408 

The current subspace-distance is: 7.394844033115078e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.69; acc: 0.8
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.62; acc: 0.8
Batch: 140; loss: 0.54; acc: 0.86
Batch: 160; loss: 0.64; acc: 0.78
Batch: 180; loss: 0.85; acc: 0.69
Batch: 200; loss: 0.79; acc: 0.75
Batch: 220; loss: 0.75; acc: 0.78
Batch: 240; loss: 0.9; acc: 0.75
Batch: 260; loss: 0.75; acc: 0.75
Batch: 280; loss: 0.91; acc: 0.77
Batch: 300; loss: 0.46; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.71; acc: 0.75
Batch: 360; loss: 0.74; acc: 0.8
Batch: 380; loss: 0.63; acc: 0.83
Batch: 400; loss: 0.58; acc: 0.8
Batch: 420; loss: 0.84; acc: 0.7
Batch: 440; loss: 0.76; acc: 0.67
Batch: 460; loss: 0.69; acc: 0.73
Batch: 480; loss: 0.71; acc: 0.78
Batch: 500; loss: 0.87; acc: 0.72
Batch: 520; loss: 0.75; acc: 0.78
Batch: 540; loss: 0.67; acc: 0.75
Batch: 560; loss: 0.65; acc: 0.81
Batch: 580; loss: 0.89; acc: 0.72
Batch: 600; loss: 0.55; acc: 0.83
Batch: 620; loss: 0.59; acc: 0.8
Batch: 640; loss: 0.6; acc: 0.83
Batch: 660; loss: 0.69; acc: 0.8
Batch: 680; loss: 0.64; acc: 0.77
Batch: 700; loss: 0.62; acc: 0.81
Batch: 720; loss: 0.59; acc: 0.81
Batch: 740; loss: 0.52; acc: 0.78
Batch: 760; loss: 0.71; acc: 0.78
Batch: 780; loss: 0.65; acc: 0.75
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.536909596528858e-05
6.8523208938131575e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.77; acc: 0.69
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.72; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.62; acc: 0.77
Batch: 120; loss: 1.28; acc: 0.69
Batch: 140; loss: 0.44; acc: 0.84
Val Epoch over. val_loss: 0.635195893656676; val_accuracy: 0.7996616242038217 

The current subspace-distance is: 6.8523208938131575e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.55; acc: 0.78
Batch: 20; loss: 0.69; acc: 0.8
Batch: 40; loss: 0.55; acc: 0.86
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.63; acc: 0.84
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.91; acc: 0.75
Batch: 140; loss: 0.8; acc: 0.77
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.6; acc: 0.78
Batch: 200; loss: 0.68; acc: 0.77
Batch: 220; loss: 0.6; acc: 0.88
Batch: 240; loss: 0.63; acc: 0.81
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.88
Batch: 300; loss: 0.83; acc: 0.81
Batch: 320; loss: 0.64; acc: 0.81
Batch: 340; loss: 0.76; acc: 0.73
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.73; acc: 0.78
Batch: 400; loss: 0.63; acc: 0.8
Batch: 420; loss: 0.81; acc: 0.75
Batch: 440; loss: 0.8; acc: 0.75
Batch: 460; loss: 0.84; acc: 0.7
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.99; acc: 0.72
Batch: 520; loss: 0.67; acc: 0.81
Batch: 540; loss: 0.8; acc: 0.77
Batch: 560; loss: 0.63; acc: 0.84
Batch: 580; loss: 0.69; acc: 0.83
Batch: 600; loss: 0.48; acc: 0.78
Batch: 620; loss: 0.84; acc: 0.67
Batch: 640; loss: 0.62; acc: 0.81
Batch: 660; loss: 0.96; acc: 0.69
Batch: 680; loss: 0.89; acc: 0.77
Batch: 700; loss: 0.63; acc: 0.84
Batch: 720; loss: 0.73; acc: 0.78
Batch: 740; loss: 0.7; acc: 0.84
Batch: 760; loss: 0.59; acc: 0.8
Batch: 780; loss: 0.55; acc: 0.81
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

2.5726787498570047e-05
9.294943083659746e-06
Batch: 0; loss: 0.7; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.69
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.72
Batch: 140; loss: 0.45; acc: 0.84
Val Epoch over. val_loss: 0.6314216146043911; val_accuracy: 0.8010549363057324 

The current subspace-distance is: 9.294943083659746e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.73; acc: 0.83
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.39; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.91
Batch: 180; loss: 0.56; acc: 0.83
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 0.77; acc: 0.78
Batch: 240; loss: 0.96; acc: 0.59
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.62; acc: 0.8
Batch: 300; loss: 0.77; acc: 0.81
Batch: 320; loss: 0.54; acc: 0.81
Batch: 340; loss: 0.7; acc: 0.84
Batch: 360; loss: 0.71; acc: 0.81
Batch: 380; loss: 0.7; acc: 0.78
Batch: 400; loss: 0.65; acc: 0.83
Batch: 420; loss: 0.78; acc: 0.8
Batch: 440; loss: 0.65; acc: 0.84
Batch: 460; loss: 0.62; acc: 0.8
Batch: 480; loss: 0.56; acc: 0.78
Batch: 500; loss: 0.75; acc: 0.72
Batch: 520; loss: 0.72; acc: 0.8
Batch: 540; loss: 0.73; acc: 0.81
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.75; acc: 0.75
Batch: 600; loss: 0.8; acc: 0.78
Batch: 620; loss: 0.68; acc: 0.77
Batch: 640; loss: 0.8; acc: 0.8
Batch: 660; loss: 0.7; acc: 0.77
Batch: 680; loss: 0.47; acc: 0.86
Batch: 700; loss: 0.89; acc: 0.73
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.46; acc: 0.83
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.471956395311281e-05
8.805593097349629e-06
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.69
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.72
Batch: 140; loss: 0.45; acc: 0.84
Val Epoch over. val_loss: 0.6318378687664202; val_accuracy: 0.7991640127388535 

The current subspace-distance is: 8.805593097349629e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.39; acc: 0.84
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.65; acc: 0.81
Batch: 120; loss: 0.57; acc: 0.73
Batch: 140; loss: 0.6; acc: 0.8
Batch: 160; loss: 0.67; acc: 0.88
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.65; acc: 0.77
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.69; acc: 0.75
Batch: 260; loss: 0.74; acc: 0.77
Batch: 280; loss: 0.46; acc: 0.83
Batch: 300; loss: 0.84; acc: 0.81
Batch: 320; loss: 0.56; acc: 0.83
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.59; acc: 0.77
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.75; acc: 0.84
Batch: 420; loss: 0.83; acc: 0.73
Batch: 440; loss: 0.48; acc: 0.86
Batch: 460; loss: 0.7; acc: 0.8
Batch: 480; loss: 0.73; acc: 0.78
Batch: 500; loss: 0.6; acc: 0.81
Batch: 520; loss: 0.64; acc: 0.75
Batch: 540; loss: 0.7; acc: 0.81
Batch: 560; loss: 0.98; acc: 0.72
Batch: 580; loss: 0.64; acc: 0.84
Batch: 600; loss: 0.82; acc: 0.75
Batch: 620; loss: 0.74; acc: 0.83
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.94; acc: 0.69
Batch: 680; loss: 0.76; acc: 0.77
Batch: 700; loss: 0.57; acc: 0.84
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.69; acc: 0.81
Batch: 760; loss: 0.71; acc: 0.8
Batch: 780; loss: 0.72; acc: 0.78
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.374587165832054e-05
8.00371344666928e-06
Batch: 0; loss: 0.73; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.5; acc: 0.88
Batch: 100; loss: 0.61; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.73
Batch: 140; loss: 0.44; acc: 0.86
Val Epoch over. val_loss: 0.6299951955391343; val_accuracy: 0.8030453821656051 

The current subspace-distance is: 8.00371344666928e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.68; acc: 0.81
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.62; acc: 0.78
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.81; acc: 0.77
Batch: 160; loss: 0.84; acc: 0.75
Batch: 180; loss: 0.76; acc: 0.72
Batch: 200; loss: 0.8; acc: 0.7
Batch: 220; loss: 0.58; acc: 0.77
Batch: 240; loss: 0.75; acc: 0.77
Batch: 260; loss: 0.66; acc: 0.77
Batch: 280; loss: 0.38; acc: 0.94
Batch: 300; loss: 0.77; acc: 0.77
Batch: 320; loss: 0.81; acc: 0.7
Batch: 340; loss: 0.67; acc: 0.84
Batch: 360; loss: 0.77; acc: 0.8
Batch: 380; loss: 0.93; acc: 0.69
Batch: 400; loss: 0.7; acc: 0.83
Batch: 420; loss: 0.7; acc: 0.75
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 1.04; acc: 0.75
Batch: 480; loss: 0.78; acc: 0.72
Batch: 500; loss: 0.52; acc: 0.86
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.59; acc: 0.86
Batch: 560; loss: 0.66; acc: 0.81
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.61; acc: 0.83
Batch: 620; loss: 0.56; acc: 0.83
Batch: 640; loss: 0.73; acc: 0.77
Batch: 660; loss: 0.6; acc: 0.83
Batch: 680; loss: 0.61; acc: 0.83
Batch: 700; loss: 0.57; acc: 0.8
Batch: 720; loss: 0.56; acc: 0.78
Batch: 740; loss: 0.79; acc: 0.72
Batch: 760; loss: 0.84; acc: 0.75
Batch: 780; loss: 0.54; acc: 0.88
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.374239920754917e-05
7.754765647405293e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 1.24; acc: 0.73
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.6290856620688348; val_accuracy: 0.8027468152866242 

The current subspace-distance is: 7.754765647405293e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.88
Batch: 40; loss: 0.94; acc: 0.73
Batch: 60; loss: 0.87; acc: 0.77
Batch: 80; loss: 0.64; acc: 0.83
Batch: 100; loss: 0.53; acc: 0.8
Batch: 120; loss: 0.51; acc: 0.83
Batch: 140; loss: 0.65; acc: 0.77
Batch: 160; loss: 0.68; acc: 0.81
Batch: 180; loss: 0.72; acc: 0.77
Batch: 200; loss: 0.72; acc: 0.8
Batch: 220; loss: 0.98; acc: 0.69
Batch: 240; loss: 0.55; acc: 0.81
Batch: 260; loss: 0.74; acc: 0.78
Batch: 280; loss: 0.71; acc: 0.8
Batch: 300; loss: 0.47; acc: 0.83
Batch: 320; loss: 0.76; acc: 0.73
Batch: 340; loss: 0.47; acc: 0.86
Batch: 360; loss: 0.72; acc: 0.77
Batch: 380; loss: 0.91; acc: 0.75
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.75; acc: 0.77
Batch: 460; loss: 0.97; acc: 0.72
Batch: 480; loss: 0.92; acc: 0.73
Batch: 500; loss: 0.67; acc: 0.8
Batch: 520; loss: 0.46; acc: 0.88
Batch: 540; loss: 0.49; acc: 0.88
Batch: 560; loss: 0.94; acc: 0.7
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.74; acc: 0.75
Batch: 640; loss: 0.48; acc: 0.8
Batch: 660; loss: 0.79; acc: 0.81
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.75; acc: 0.73
Batch: 720; loss: 0.85; acc: 0.78
Batch: 740; loss: 0.62; acc: 0.78
Batch: 760; loss: 0.76; acc: 0.81
Batch: 780; loss: 0.67; acc: 0.8
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.4554270567023195e-05
8.117495781334583e-06
Batch: 0; loss: 0.71; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 1.25; acc: 0.73
Batch: 140; loss: 0.44; acc: 0.84
Val Epoch over. val_loss: 0.6295306263076272; val_accuracy: 0.803343949044586 

The current subspace-distance is: 8.117495781334583e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.63; acc: 0.75
Batch: 20; loss: 0.97; acc: 0.7
Batch: 40; loss: 0.89; acc: 0.67
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.68; acc: 0.7
Batch: 100; loss: 0.93; acc: 0.75
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.64; acc: 0.78
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.7; acc: 0.77
Batch: 200; loss: 0.69; acc: 0.78
Batch: 220; loss: 0.62; acc: 0.81
Batch: 240; loss: 0.7; acc: 0.75
Batch: 260; loss: 0.77; acc: 0.77
Batch: 280; loss: 0.55; acc: 0.84
Batch: 300; loss: 0.67; acc: 0.78
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.47; acc: 0.81
Batch: 360; loss: 0.57; acc: 0.83
Batch: 380; loss: 0.74; acc: 0.81
Batch: 400; loss: 0.91; acc: 0.77
Batch: 420; loss: 0.45; acc: 0.84
Batch: 440; loss: 0.59; acc: 0.83
Batch: 460; loss: 0.52; acc: 0.81
Batch: 480; loss: 0.59; acc: 0.8
Batch: 500; loss: 1.08; acc: 0.67
Batch: 520; loss: 0.75; acc: 0.78
Batch: 540; loss: 0.5; acc: 0.91
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.62; acc: 0.81
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.74; acc: 0.8
Batch: 680; loss: 0.63; acc: 0.77
Batch: 700; loss: 0.76; acc: 0.75
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.32; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.94
Batch: 780; loss: 0.68; acc: 0.8
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.3877917556092143e-05
8.16579267848283e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.79; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.8
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 1.3; acc: 0.7
Batch: 140; loss: 0.45; acc: 0.84
Val Epoch over. val_loss: 0.6318935366572848; val_accuracy: 0.8023487261146497 

The current subspace-distance is: 8.16579267848283e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.9; acc: 0.73
Batch: 20; loss: 0.54; acc: 0.77
Batch: 40; loss: 0.78; acc: 0.67
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.86; acc: 0.72
Batch: 120; loss: 1.11; acc: 0.69
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 0.76; acc: 0.77
Batch: 180; loss: 0.62; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.6; acc: 0.8
Batch: 240; loss: 0.87; acc: 0.77
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.92; acc: 0.8
Batch: 320; loss: 0.69; acc: 0.78
Batch: 340; loss: 0.56; acc: 0.83
Batch: 360; loss: 0.73; acc: 0.75
Batch: 380; loss: 0.71; acc: 0.77
Batch: 400; loss: 0.82; acc: 0.67
Batch: 420; loss: 0.8; acc: 0.77
Batch: 440; loss: 0.81; acc: 0.8
Batch: 460; loss: 0.55; acc: 0.8
Batch: 480; loss: 0.78; acc: 0.77
Batch: 500; loss: 0.56; acc: 0.83
Batch: 520; loss: 0.42; acc: 0.88
Batch: 540; loss: 0.78; acc: 0.72
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.54; acc: 0.8
Batch: 620; loss: 0.65; acc: 0.78
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.58; acc: 0.84
Batch: 680; loss: 0.56; acc: 0.83
Batch: 700; loss: 0.78; acc: 0.75
Batch: 720; loss: 0.73; acc: 0.78
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.54; acc: 0.83
Batch: 780; loss: 0.65; acc: 0.81
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.449262683512643e-05
6.8046051637793425e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.49; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.8
Batch: 120; loss: 1.29; acc: 0.7
Batch: 140; loss: 0.45; acc: 0.84
Val Epoch over. val_loss: 0.6309685023726931; val_accuracy: 0.8023487261146497 

The current subspace-distance is: 6.8046051637793425e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.61; acc: 0.86
Batch: 20; loss: 1.03; acc: 0.72
Batch: 40; loss: 0.42; acc: 0.92
Batch: 60; loss: 0.49; acc: 0.78
Batch: 80; loss: 0.6; acc: 0.83
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.65; acc: 0.75
Batch: 140; loss: 0.64; acc: 0.78
Batch: 160; loss: 0.69; acc: 0.78
Batch: 180; loss: 0.98; acc: 0.67
Batch: 200; loss: 0.79; acc: 0.75
Batch: 220; loss: 0.66; acc: 0.81
Batch: 240; loss: 0.59; acc: 0.77
Batch: 260; loss: 0.68; acc: 0.73
Batch: 280; loss: 0.63; acc: 0.81
Batch: 300; loss: 0.77; acc: 0.78
Batch: 320; loss: 0.66; acc: 0.81
Batch: 340; loss: 0.62; acc: 0.81
Batch: 360; loss: 0.51; acc: 0.84
Batch: 380; loss: 0.61; acc: 0.8
Batch: 400; loss: 0.53; acc: 0.84
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.59; acc: 0.75
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.84
Batch: 520; loss: 0.7; acc: 0.78
Batch: 540; loss: 0.54; acc: 0.83
Batch: 560; loss: 0.64; acc: 0.81
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.61; acc: 0.8
Batch: 620; loss: 0.57; acc: 0.84
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.72; acc: 0.78
Batch: 680; loss: 0.68; acc: 0.7
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.39; acc: 0.91
Batch: 740; loss: 0.56; acc: 0.83
Batch: 760; loss: 0.61; acc: 0.8
Batch: 780; loss: 0.71; acc: 0.72
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.5669824026408605e-05
7.499450475734193e-06
Batch: 0; loss: 0.74; acc: 0.77
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.51; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.8
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.61; acc: 0.78
Batch: 120; loss: 1.29; acc: 0.72
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.6301161257704352; val_accuracy: 0.8022492038216561 

The current subspace-distance is: 7.499450475734193e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.52; acc: 0.89
Batch: 60; loss: 0.81; acc: 0.77
Batch: 80; loss: 0.96; acc: 0.66
Batch: 100; loss: 0.59; acc: 0.81
Batch: 120; loss: 0.59; acc: 0.77
Batch: 140; loss: 0.35; acc: 0.84
Batch: 160; loss: 0.79; acc: 0.75
Batch: 180; loss: 0.81; acc: 0.83
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.69; acc: 0.78
Batch: 240; loss: 0.55; acc: 0.81
Batch: 260; loss: 0.64; acc: 0.78
Batch: 280; loss: 0.58; acc: 0.84
Batch: 300; loss: 0.71; acc: 0.77
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.66; acc: 0.84
Batch: 360; loss: 0.75; acc: 0.75
Batch: 380; loss: 0.92; acc: 0.69
Batch: 400; loss: 0.6; acc: 0.8
Batch: 420; loss: 0.66; acc: 0.81
Batch: 440; loss: 0.59; acc: 0.84
Batch: 460; loss: 0.73; acc: 0.83
Batch: 480; loss: 0.71; acc: 0.81
Batch: 500; loss: 0.79; acc: 0.69
Batch: 520; loss: 0.63; acc: 0.78
Batch: 540; loss: 0.66; acc: 0.75
Batch: 560; loss: 0.64; acc: 0.84
Batch: 580; loss: 0.59; acc: 0.77
Batch: 600; loss: 0.62; acc: 0.8
Batch: 620; loss: 0.59; acc: 0.89
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.57; acc: 0.77
Batch: 700; loss: 0.67; acc: 0.83
Batch: 720; loss: 0.61; acc: 0.8
Batch: 740; loss: 0.59; acc: 0.78
Batch: 760; loss: 0.66; acc: 0.77
Batch: 780; loss: 0.89; acc: 0.72
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.556756226113066e-05
8.337400686286855e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.78; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.6; acc: 0.78
Batch: 120; loss: 1.25; acc: 0.73
Batch: 140; loss: 0.45; acc: 0.86
Val Epoch over. val_loss: 0.630696470190765; val_accuracy: 0.8019506369426752 

The current subspace-distance is: 8.337400686286855e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.64; acc: 0.81
Batch: 20; loss: 0.65; acc: 0.86
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 0.72; acc: 0.75
Batch: 80; loss: 0.67; acc: 0.73
Batch: 100; loss: 0.79; acc: 0.72
Batch: 120; loss: 0.38; acc: 0.91
Batch: 140; loss: 0.61; acc: 0.84
Batch: 160; loss: 0.64; acc: 0.8
Batch: 180; loss: 0.62; acc: 0.73
Batch: 200; loss: 0.65; acc: 0.75
Batch: 220; loss: 0.8; acc: 0.78
Batch: 240; loss: 0.74; acc: 0.78
Batch: 260; loss: 0.53; acc: 0.81
Batch: 280; loss: 0.81; acc: 0.75
Batch: 300; loss: 0.6; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.88
Batch: 340; loss: 0.53; acc: 0.81
Batch: 360; loss: 0.62; acc: 0.83
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.7; acc: 0.77
Batch: 420; loss: 0.47; acc: 0.86
Batch: 440; loss: 0.52; acc: 0.84
Batch: 460; loss: 0.78; acc: 0.8
Batch: 480; loss: 0.93; acc: 0.77
Batch: 500; loss: 0.72; acc: 0.8
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.64; acc: 0.78
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.49; acc: 0.81
Batch: 600; loss: 0.63; acc: 0.86
Batch: 620; loss: 0.73; acc: 0.8
Batch: 640; loss: 0.87; acc: 0.69
Batch: 660; loss: 0.53; acc: 0.91
Batch: 680; loss: 0.83; acc: 0.69
Batch: 700; loss: 0.52; acc: 0.84
Batch: 720; loss: 0.69; acc: 0.78
Batch: 740; loss: 0.62; acc: 0.81
Batch: 760; loss: 0.93; acc: 0.73
Batch: 780; loss: 0.69; acc: 0.81
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.3285154384211637e-05
8.403862921113614e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.81
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 1.27; acc: 0.72
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.6283860238874035; val_accuracy: 0.8032444267515924 

The current subspace-distance is: 8.403862921113614e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.66; acc: 0.8
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.62; acc: 0.8
Batch: 60; loss: 0.68; acc: 0.8
Batch: 80; loss: 0.69; acc: 0.83
Batch: 100; loss: 0.75; acc: 0.81
Batch: 120; loss: 0.57; acc: 0.8
Batch: 140; loss: 0.57; acc: 0.8
Batch: 160; loss: 0.64; acc: 0.83
Batch: 180; loss: 0.73; acc: 0.78
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.63; acc: 0.77
Batch: 240; loss: 0.7; acc: 0.75
Batch: 260; loss: 0.63; acc: 0.81
Batch: 280; loss: 0.69; acc: 0.73
Batch: 300; loss: 0.74; acc: 0.73
Batch: 320; loss: 0.5; acc: 0.77
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.83; acc: 0.73
Batch: 380; loss: 0.55; acc: 0.81
Batch: 400; loss: 0.83; acc: 0.78
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.75; acc: 0.73
Batch: 480; loss: 1.21; acc: 0.67
Batch: 500; loss: 0.7; acc: 0.83
Batch: 520; loss: 0.61; acc: 0.8
Batch: 540; loss: 0.61; acc: 0.83
Batch: 560; loss: 1.04; acc: 0.67
Batch: 580; loss: 0.74; acc: 0.75
Batch: 600; loss: 0.53; acc: 0.81
Batch: 620; loss: 0.76; acc: 0.8
Batch: 640; loss: 0.44; acc: 0.86
Batch: 660; loss: 0.64; acc: 0.83
Batch: 680; loss: 0.94; acc: 0.78
Batch: 700; loss: 0.89; acc: 0.7
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.71; acc: 0.81
Batch: 760; loss: 0.63; acc: 0.8
Batch: 780; loss: 0.68; acc: 0.78
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

2.679402314242907e-05
7.83663199399598e-06
Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.7
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.49; acc: 0.88
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 1.26; acc: 0.72
Batch: 140; loss: 0.43; acc: 0.86
Val Epoch over. val_loss: 0.6284651699339509; val_accuracy: 0.8037420382165605 

The current subspace-distance is: 7.83663199399598e-06 

plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 42292
elements in E: 8790400
fraction nonzero: 0.004811157626501638
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.37; acc: 0.17
Batch: 20; loss: 2.24; acc: 0.12
Batch: 40; loss: 2.23; acc: 0.19
Batch: 60; loss: 2.19; acc: 0.31
Batch: 80; loss: 2.15; acc: 0.33
Batch: 100; loss: 2.19; acc: 0.23
Batch: 120; loss: 2.11; acc: 0.31
Batch: 140; loss: 2.05; acc: 0.38
Batch: 160; loss: 1.92; acc: 0.38
Batch: 180; loss: 1.8; acc: 0.52
Batch: 200; loss: 1.93; acc: 0.33
Batch: 220; loss: 1.92; acc: 0.34
Batch: 240; loss: 1.77; acc: 0.38
Batch: 260; loss: 1.79; acc: 0.39
Batch: 280; loss: 1.55; acc: 0.48
Batch: 300; loss: 1.56; acc: 0.56
Batch: 320; loss: 1.43; acc: 0.61
Batch: 340; loss: 1.47; acc: 0.55
Batch: 360; loss: 1.4; acc: 0.45
Batch: 380; loss: 1.61; acc: 0.45
Batch: 400; loss: 1.45; acc: 0.52
Batch: 420; loss: 1.2; acc: 0.64
Batch: 440; loss: 1.3; acc: 0.62
Batch: 460; loss: 1.27; acc: 0.55
Batch: 480; loss: 1.19; acc: 0.61
Batch: 500; loss: 1.04; acc: 0.73
Batch: 520; loss: 1.1; acc: 0.59
Batch: 540; loss: 1.2; acc: 0.61
Batch: 560; loss: 1.28; acc: 0.58
Batch: 580; loss: 1.18; acc: 0.53
Batch: 600; loss: 0.99; acc: 0.72
Batch: 620; loss: 1.13; acc: 0.69
Batch: 640; loss: 0.89; acc: 0.72
Batch: 660; loss: 1.35; acc: 0.52
Batch: 680; loss: 1.33; acc: 0.56
Batch: 700; loss: 1.25; acc: 0.59
Batch: 720; loss: 1.38; acc: 0.58
Batch: 740; loss: 0.88; acc: 0.72
Batch: 760; loss: 0.74; acc: 0.69
Batch: 780; loss: 1.13; acc: 0.7
Train Epoch over. train_loss: 1.51; train_accuracy: 0.51 

1.7168822523672134e-05
5.869605502084596e-06
Batch: 0; loss: 1.17; acc: 0.64
Batch: 20; loss: 1.29; acc: 0.59
Batch: 40; loss: 0.79; acc: 0.72
Batch: 60; loss: 0.96; acc: 0.67
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 1.02; acc: 0.77
Batch: 120; loss: 1.26; acc: 0.55
Batch: 140; loss: 0.92; acc: 0.7
Val Epoch over. val_loss: 1.0239783149615975; val_accuracy: 0.6710788216560509 

The current subspace-distance is: 5.869605502084596e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.24; acc: 0.59
Batch: 20; loss: 0.99; acc: 0.69
Batch: 40; loss: 1.44; acc: 0.48
Batch: 60; loss: 0.93; acc: 0.77
Batch: 80; loss: 1.02; acc: 0.67
Batch: 100; loss: 0.6; acc: 0.8
Batch: 120; loss: 0.99; acc: 0.61
Batch: 140; loss: 0.96; acc: 0.67
Batch: 160; loss: 0.74; acc: 0.72
Batch: 180; loss: 1.18; acc: 0.67
Batch: 200; loss: 1.11; acc: 0.66
Batch: 220; loss: 0.85; acc: 0.73
Batch: 240; loss: 0.92; acc: 0.64
Batch: 260; loss: 1.21; acc: 0.62
Batch: 280; loss: 1.16; acc: 0.64
Batch: 300; loss: 0.7; acc: 0.8
Batch: 320; loss: 0.79; acc: 0.8
Batch: 340; loss: 0.7; acc: 0.75
Batch: 360; loss: 0.66; acc: 0.81
Batch: 380; loss: 0.79; acc: 0.69
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.69; acc: 0.78
Batch: 440; loss: 0.52; acc: 0.8
Batch: 460; loss: 0.72; acc: 0.78
Batch: 480; loss: 0.73; acc: 0.78
Batch: 500; loss: 0.95; acc: 0.69
Batch: 520; loss: 0.61; acc: 0.8
Batch: 540; loss: 0.89; acc: 0.73
Batch: 560; loss: 0.56; acc: 0.83
Batch: 580; loss: 0.99; acc: 0.69
Batch: 600; loss: 0.6; acc: 0.78
Batch: 620; loss: 0.63; acc: 0.81
Batch: 640; loss: 1.05; acc: 0.66
Batch: 660; loss: 1.08; acc: 0.66
Batch: 680; loss: 0.71; acc: 0.78
Batch: 700; loss: 0.59; acc: 0.81
Batch: 720; loss: 0.72; acc: 0.78
Batch: 740; loss: 0.59; acc: 0.77
Batch: 760; loss: 0.51; acc: 0.81
Batch: 780; loss: 1.17; acc: 0.69
Train Epoch over. train_loss: 0.81; train_accuracy: 0.74 

2.378221324761398e-05
7.504148925363552e-06
Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.8; acc: 0.7
Batch: 40; loss: 0.58; acc: 0.83
Batch: 60; loss: 0.59; acc: 0.8
Batch: 80; loss: 0.56; acc: 0.8
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.41; acc: 0.86
Val Epoch over. val_loss: 0.6335300123615629; val_accuracy: 0.8009554140127388 

The current subspace-distance is: 7.504148925363552e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.51; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.61; acc: 0.83
Batch: 60; loss: 0.64; acc: 0.77
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.84
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.63; acc: 0.8
Batch: 180; loss: 0.74; acc: 0.73
Batch: 200; loss: 0.7; acc: 0.77
Batch: 220; loss: 0.55; acc: 0.78
Batch: 240; loss: 0.68; acc: 0.81
Batch: 260; loss: 0.69; acc: 0.84
Batch: 280; loss: 0.87; acc: 0.75
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.63; acc: 0.81
Batch: 340; loss: 0.86; acc: 0.81
Batch: 360; loss: 0.69; acc: 0.8
Batch: 380; loss: 0.98; acc: 0.69
Batch: 400; loss: 0.91; acc: 0.73
Batch: 420; loss: 0.74; acc: 0.8
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.63; acc: 0.78
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.81; acc: 0.72
Batch: 520; loss: 0.61; acc: 0.83
Batch: 540; loss: 0.47; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.81
Batch: 580; loss: 0.94; acc: 0.7
Batch: 600; loss: 0.67; acc: 0.86
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.61; acc: 0.84
Batch: 680; loss: 0.81; acc: 0.8
Batch: 700; loss: 0.53; acc: 0.8
Batch: 720; loss: 0.74; acc: 0.75
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.61; acc: 0.77
Batch: 780; loss: 0.62; acc: 0.81
Train Epoch over. train_loss: 0.65; train_accuracy: 0.79 

2.599234903755132e-05
7.71273971622577e-06
Batch: 0; loss: 0.79; acc: 0.75
Batch: 20; loss: 0.99; acc: 0.72
Batch: 40; loss: 0.63; acc: 0.84
Batch: 60; loss: 0.74; acc: 0.73
Batch: 80; loss: 0.82; acc: 0.78
Batch: 100; loss: 0.64; acc: 0.73
Batch: 120; loss: 0.87; acc: 0.75
Batch: 140; loss: 0.45; acc: 0.81
Val Epoch over. val_loss: 0.7297788380057948; val_accuracy: 0.7760748407643312 

The current subspace-distance is: 7.71273971622577e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.93; acc: 0.69
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.82; acc: 0.75
Batch: 80; loss: 0.87; acc: 0.72
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.55; acc: 0.86
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.52; acc: 0.88
Batch: 240; loss: 0.64; acc: 0.78
Batch: 260; loss: 0.48; acc: 0.8
Batch: 280; loss: 0.53; acc: 0.83
Batch: 300; loss: 1.05; acc: 0.73
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.54; acc: 0.78
Batch: 360; loss: 0.86; acc: 0.73
Batch: 380; loss: 0.71; acc: 0.72
Batch: 400; loss: 0.69; acc: 0.78
Batch: 420; loss: 0.67; acc: 0.81
Batch: 440; loss: 0.76; acc: 0.78
Batch: 460; loss: 0.84; acc: 0.7
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.63; acc: 0.81
Batch: 520; loss: 0.32; acc: 0.88
Batch: 540; loss: 0.75; acc: 0.73
Batch: 560; loss: 0.71; acc: 0.77
Batch: 580; loss: 1.01; acc: 0.73
Batch: 600; loss: 0.89; acc: 0.78
Batch: 620; loss: 0.35; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.72; acc: 0.84
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 1.17; acc: 0.61
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.68; acc: 0.81
Batch: 780; loss: 0.62; acc: 0.73
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

2.7768728614319116e-05
8.286146112368442e-06
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.83; acc: 0.72
Batch: 40; loss: 0.53; acc: 0.81
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.83
Batch: 120; loss: 0.96; acc: 0.78
Batch: 140; loss: 0.31; acc: 0.89
Val Epoch over. val_loss: 0.5963083200963439; val_accuracy: 0.8032444267515924 

The current subspace-distance is: 8.286146112368442e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 1.03; acc: 0.72
Batch: 40; loss: 0.71; acc: 0.77
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.47; acc: 0.81
Batch: 140; loss: 0.66; acc: 0.77
Batch: 160; loss: 0.55; acc: 0.83
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.71; acc: 0.84
Batch: 220; loss: 0.75; acc: 0.81
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.53; acc: 0.83
Batch: 280; loss: 0.75; acc: 0.77
Batch: 300; loss: 0.62; acc: 0.8
Batch: 320; loss: 0.52; acc: 0.81
Batch: 340; loss: 0.41; acc: 0.83
Batch: 360; loss: 0.54; acc: 0.83
Batch: 380; loss: 0.66; acc: 0.78
Batch: 400; loss: 0.91; acc: 0.72
Batch: 420; loss: 0.49; acc: 0.8
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.57; acc: 0.83
Batch: 480; loss: 0.67; acc: 0.83
Batch: 500; loss: 0.77; acc: 0.78
Batch: 520; loss: 0.62; acc: 0.81
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.46; acc: 0.91
Batch: 620; loss: 0.67; acc: 0.8
Batch: 640; loss: 0.53; acc: 0.86
Batch: 660; loss: 0.57; acc: 0.84
Batch: 680; loss: 0.49; acc: 0.83
Batch: 700; loss: 0.68; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.83
Batch: 740; loss: 0.65; acc: 0.8
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.77; acc: 0.75
Train Epoch over. train_loss: 0.57; train_accuracy: 0.83 

2.7770140150096267e-05
8.164293831214309e-06
Batch: 0; loss: 0.68; acc: 0.8
Batch: 20; loss: 0.97; acc: 0.66
Batch: 40; loss: 0.61; acc: 0.84
Batch: 60; loss: 0.69; acc: 0.73
Batch: 80; loss: 0.59; acc: 0.84
Batch: 100; loss: 0.56; acc: 0.78
Batch: 120; loss: 1.02; acc: 0.77
Batch: 140; loss: 0.26; acc: 0.92
Val Epoch over. val_loss: 0.6586026259858138; val_accuracy: 0.7952826433121019 

The current subspace-distance is: 8.164293831214309e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.14; acc: 0.7
Batch: 20; loss: 0.44; acc: 0.83
Batch: 40; loss: 0.38; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.84
Batch: 100; loss: 0.52; acc: 0.83
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.48; acc: 0.83
Batch: 160; loss: 0.62; acc: 0.83
Batch: 180; loss: 0.52; acc: 0.77
Batch: 200; loss: 0.59; acc: 0.78
Batch: 220; loss: 0.36; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.66; acc: 0.78
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.57; acc: 0.81
Batch: 340; loss: 0.49; acc: 0.89
Batch: 360; loss: 0.6; acc: 0.86
Batch: 380; loss: 0.5; acc: 0.81
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.5; acc: 0.84
Batch: 440; loss: 0.57; acc: 0.86
Batch: 460; loss: 0.47; acc: 0.88
Batch: 480; loss: 0.91; acc: 0.8
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.88
Batch: 560; loss: 0.61; acc: 0.8
Batch: 580; loss: 0.65; acc: 0.81
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.68; acc: 0.83
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.61; acc: 0.78
Batch: 700; loss: 0.71; acc: 0.86
Batch: 720; loss: 0.41; acc: 0.86
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.68; acc: 0.78
Train Epoch over. train_loss: 0.56; train_accuracy: 0.83 

2.7640227926895022e-05
8.57628674566513e-06
Batch: 0; loss: 0.62; acc: 0.8
Batch: 20; loss: 1.05; acc: 0.64
Batch: 40; loss: 0.62; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.75
Batch: 80; loss: 0.62; acc: 0.78
Batch: 100; loss: 0.71; acc: 0.78
Batch: 120; loss: 1.22; acc: 0.73
Batch: 140; loss: 0.36; acc: 0.88
Val Epoch over. val_loss: 0.6284126555843718; val_accuracy: 0.8059315286624203 

The current subspace-distance is: 8.57628674566513e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.64; acc: 0.77
Batch: 40; loss: 0.72; acc: 0.8
Batch: 60; loss: 0.55; acc: 0.83
Batch: 80; loss: 0.77; acc: 0.73
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.44; acc: 0.84
Batch: 160; loss: 0.69; acc: 0.86
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.44; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.44; acc: 0.81
Batch: 260; loss: 0.56; acc: 0.84
Batch: 280; loss: 0.57; acc: 0.83
Batch: 300; loss: 0.51; acc: 0.83
Batch: 320; loss: 0.53; acc: 0.81
Batch: 340; loss: 0.8; acc: 0.75
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.54; acc: 0.83
Batch: 420; loss: 0.64; acc: 0.78
Batch: 440; loss: 0.75; acc: 0.81
Batch: 460; loss: 0.78; acc: 0.81
Batch: 480; loss: 0.73; acc: 0.77
Batch: 500; loss: 0.82; acc: 0.81
Batch: 520; loss: 0.49; acc: 0.83
Batch: 540; loss: 0.38; acc: 0.91
Batch: 560; loss: 0.45; acc: 0.86
Batch: 580; loss: 0.48; acc: 0.86
Batch: 600; loss: 0.5; acc: 0.83
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.7; acc: 0.75
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.46; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.58; acc: 0.88
Batch: 740; loss: 0.47; acc: 0.83
Batch: 760; loss: 0.65; acc: 0.81
Batch: 780; loss: 0.4; acc: 0.84
Train Epoch over. train_loss: 0.55; train_accuracy: 0.83 

2.938247416750528e-05
8.723859536985401e-06
Batch: 0; loss: 0.75; acc: 0.81
Batch: 20; loss: 1.0; acc: 0.66
Batch: 40; loss: 0.65; acc: 0.84
Batch: 60; loss: 0.71; acc: 0.77
Batch: 80; loss: 0.64; acc: 0.8
Batch: 100; loss: 0.6; acc: 0.83
Batch: 120; loss: 1.22; acc: 0.67
Batch: 140; loss: 0.38; acc: 0.89
Val Epoch over. val_loss: 0.7656521749724249; val_accuracy: 0.752687101910828 

The current subspace-distance is: 8.723859536985401e-06 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.89; acc: 0.61
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.59; acc: 0.78
Batch: 100; loss: 0.73; acc: 0.78
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.55; acc: 0.8
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.66; acc: 0.83
Batch: 200; loss: 0.47; acc: 0.81
Batch: 220; loss: 0.46; acc: 0.83
Batch: 240; loss: 0.36; acc: 0.86
Batch: 260; loss: 0.64; acc: 0.84
Batch: 280; loss: 0.61; acc: 0.83
Batch: 300; loss: 0.73; acc: 0.8
Batch: 320; loss: 0.85; acc: 0.7
Batch: 340; loss: 0.6; acc: 0.84
Batch: 360; loss: 0.51; acc: 0.86
Batch: 380; loss: 0.49; acc: 0.83
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.44; acc: 0.84
Batch: 440; loss: 0.67; acc: 0.81
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.54; acc: 0.8
Batch: 500; loss: 0.62; acc: 0.83
Batch: 520; loss: 0.59; acc: 0.77
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.71; acc: 0.73
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.4; acc: 0.91
Batch: 620; loss: 0.31; acc: 0.92
Batch: 640; loss: 0.41; acc: 0.84
Batch: 660; loss: 0.36; acc: 0.88
Batch: 680; loss: 0.78; acc: 0.83
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.67; acc: 0.81
Batch: 760; loss: 0.42; acc: 0.86
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

3.013538480445277e-05
9.81113134912448e-06
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.75; acc: 0.75
Batch: 40; loss: 0.54; acc: 0.8
Batch: 60; loss: 0.67; acc: 0.81
Batch: 80; loss: 0.65; acc: 0.78
Batch: 100; loss: 0.63; acc: 0.75
Batch: 120; loss: 1.15; acc: 0.67
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.5811494353470529; val_accuracy: 0.8172770700636943 

The current subspace-distance is: 9.81113134912448e-06 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.62; acc: 0.81
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.6; acc: 0.77
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.86
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.58; acc: 0.84
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.48; acc: 0.88
Batch: 240; loss: 0.52; acc: 0.91
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.43; acc: 0.84
Batch: 300; loss: 0.59; acc: 0.77
Batch: 320; loss: 0.57; acc: 0.8
Batch: 340; loss: 0.73; acc: 0.84
Batch: 360; loss: 0.46; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.88
Batch: 400; loss: 0.79; acc: 0.77
Batch: 420; loss: 0.67; acc: 0.86
Batch: 440; loss: 1.11; acc: 0.73
Batch: 460; loss: 0.47; acc: 0.89
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.58; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.8
Batch: 580; loss: 0.7; acc: 0.8
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.51; acc: 0.84
Batch: 640; loss: 0.58; acc: 0.81
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.55; acc: 0.86
Batch: 700; loss: 0.55; acc: 0.83
Batch: 720; loss: 0.52; acc: 0.81
Batch: 740; loss: 0.68; acc: 0.89
Batch: 760; loss: 0.71; acc: 0.77
Batch: 780; loss: 0.38; acc: 0.88
Train Epoch over. train_loss: 0.53; train_accuracy: 0.84 

2.842640969902277e-05
8.87270834937226e-06
Batch: 0; loss: 0.51; acc: 0.88
Batch: 20; loss: 0.64; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.47; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.93; acc: 0.77
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.49314399177481416; val_accuracy: 0.8474323248407644 

The current subspace-distance is: 8.87270834937226e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.49; acc: 0.8
Batch: 20; loss: 0.48; acc: 0.84
Batch: 40; loss: 0.52; acc: 0.86
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.78; acc: 0.72
Batch: 140; loss: 0.5; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.57; acc: 0.86
Batch: 200; loss: 0.56; acc: 0.84
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.61; acc: 0.83
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.59; acc: 0.83
Batch: 320; loss: 0.52; acc: 0.88
Batch: 340; loss: 0.47; acc: 0.89
Batch: 360; loss: 0.31; acc: 0.89
Batch: 380; loss: 0.41; acc: 0.86
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.63; acc: 0.8
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.84; acc: 0.77
Batch: 480; loss: 0.78; acc: 0.78
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.58; acc: 0.86
Batch: 540; loss: 0.69; acc: 0.78
Batch: 560; loss: 0.73; acc: 0.75
Batch: 580; loss: 0.58; acc: 0.81
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 0.3; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.84
Batch: 700; loss: 0.39; acc: 0.81
Batch: 720; loss: 0.56; acc: 0.81
Batch: 740; loss: 0.64; acc: 0.81
Batch: 760; loss: 0.44; acc: 0.83
Batch: 780; loss: 0.31; acc: 0.88
Train Epoch over. train_loss: 0.53; train_accuracy: 0.84 

2.9653796445927583e-05
8.988648005470168e-06
Batch: 0; loss: 0.41; acc: 0.91
Batch: 20; loss: 0.61; acc: 0.81
Batch: 40; loss: 0.49; acc: 0.92
Batch: 60; loss: 0.48; acc: 0.8
Batch: 80; loss: 0.59; acc: 0.83
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.81; acc: 0.77
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4925515326155219; val_accuracy: 0.8466361464968153 

The current subspace-distance is: 8.988648005470168e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.91
Batch: 20; loss: 0.63; acc: 0.77
Batch: 40; loss: 0.54; acc: 0.83
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.52; acc: 0.83
Batch: 180; loss: 0.47; acc: 0.91
Batch: 200; loss: 0.92; acc: 0.75
Batch: 220; loss: 0.35; acc: 0.86
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.84
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.66; acc: 0.84
Batch: 380; loss: 0.5; acc: 0.83
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.34; acc: 0.89
Batch: 500; loss: 0.41; acc: 0.8
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.97
Batch: 660; loss: 0.53; acc: 0.84
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.47; acc: 0.8
Batch: 720; loss: 0.45; acc: 0.88
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.92
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

2.9856613764422946e-05
9.783905625226907e-06
Batch: 0; loss: 0.48; acc: 0.91
Batch: 20; loss: 0.69; acc: 0.77
Batch: 40; loss: 0.47; acc: 0.91
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.63; acc: 0.81
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.92; acc: 0.75
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.4978217242439841; val_accuracy: 0.8434514331210191 

The current subspace-distance is: 9.783905625226907e-06 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.61; acc: 0.75
Batch: 20; loss: 0.48; acc: 0.89
Batch: 40; loss: 0.51; acc: 0.81
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.45; acc: 0.83
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.46; acc: 0.84
Batch: 140; loss: 0.6; acc: 0.8
Batch: 160; loss: 0.71; acc: 0.81
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.97
Batch: 220; loss: 0.27; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.48; acc: 0.84
Batch: 280; loss: 0.64; acc: 0.83
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.49; acc: 0.81
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.46; acc: 0.84
Batch: 420; loss: 0.48; acc: 0.84
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.58; acc: 0.8
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.61; acc: 0.86
Batch: 520; loss: 0.5; acc: 0.81
Batch: 540; loss: 0.48; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.57; acc: 0.84
Batch: 600; loss: 0.71; acc: 0.8
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.38; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.44; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.4; acc: 0.91
Batch: 760; loss: 0.31; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

3.0182553018676117e-05
9.255828445020597e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.41; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.41361176459842425; val_accuracy: 0.8749004777070064 

The current subspace-distance is: 9.255828445020597e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.71; acc: 0.8
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.56; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.41; acc: 0.83
Batch: 180; loss: 0.52; acc: 0.89
Batch: 200; loss: 0.63; acc: 0.81
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.6; acc: 0.8
Batch: 260; loss: 0.59; acc: 0.78
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.57; acc: 0.8
Batch: 340; loss: 0.41; acc: 0.81
Batch: 360; loss: 0.34; acc: 0.89
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.77; acc: 0.72
Batch: 420; loss: 0.4; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.89
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.58; acc: 0.91
Batch: 560; loss: 0.38; acc: 0.91
Batch: 580; loss: 0.34; acc: 0.91
Batch: 600; loss: 0.25; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.34; acc: 0.91
Batch: 660; loss: 0.44; acc: 0.83
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.47; acc: 0.83
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

3.088894663960673e-05
8.441161298833322e-06
Batch: 0; loss: 0.43; acc: 0.91
Batch: 20; loss: 0.65; acc: 0.8
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.55; acc: 0.84
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.442690573727629; val_accuracy: 0.8647492038216561 

The current subspace-distance is: 8.441161298833322e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.49; acc: 0.83
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.45; acc: 0.91
Batch: 140; loss: 0.54; acc: 0.88
Batch: 160; loss: 0.52; acc: 0.8
Batch: 180; loss: 0.56; acc: 0.86
Batch: 200; loss: 0.52; acc: 0.83
Batch: 220; loss: 0.53; acc: 0.88
Batch: 240; loss: 0.67; acc: 0.78
Batch: 260; loss: 0.57; acc: 0.83
Batch: 280; loss: 0.6; acc: 0.78
Batch: 300; loss: 0.46; acc: 0.83
Batch: 320; loss: 0.67; acc: 0.84
Batch: 340; loss: 0.57; acc: 0.8
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.57; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.83
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.83
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.92
Batch: 560; loss: 0.32; acc: 0.94
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.29; acc: 0.92
Batch: 620; loss: 0.51; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.49; acc: 0.91
Batch: 680; loss: 0.51; acc: 0.88
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.42; acc: 0.81
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.91
Batch: 780; loss: 0.5; acc: 0.83
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

3.0610990506829694e-05
9.191119715978857e-06
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.39; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.15; acc: 0.92
Val Epoch over. val_loss: 0.43109669730921457; val_accuracy: 0.8676353503184714 

The current subspace-distance is: 9.191119715978857e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.53; acc: 0.89
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.83
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.81; acc: 0.84
Batch: 240; loss: 0.43; acc: 0.84
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.51; acc: 0.83
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.44; acc: 0.78
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.61; acc: 0.81
Batch: 380; loss: 0.5; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.57; acc: 0.8
Batch: 520; loss: 0.5; acc: 0.83
Batch: 540; loss: 0.46; acc: 0.88
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.52; acc: 0.91
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.89
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.58; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.86
Batch: 700; loss: 0.6; acc: 0.81
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.73; acc: 0.77
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.9978649763506837e-05
8.795932444627397e-06
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 0.39; acc: 0.89
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.83; acc: 0.77
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.4301848511217506; val_accuracy: 0.869327229299363 

The current subspace-distance is: 8.795932444627397e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.82; acc: 0.78
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.5; acc: 0.84
Batch: 60; loss: 0.8; acc: 0.78
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.49; acc: 0.81
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.39; acc: 0.86
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.62; acc: 0.77
Batch: 380; loss: 0.38; acc: 0.86
Batch: 400; loss: 0.59; acc: 0.81
Batch: 420; loss: 0.43; acc: 0.91
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.4; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.62; acc: 0.8
Batch: 520; loss: 0.47; acc: 0.84
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.49; acc: 0.81
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.45; acc: 0.84
Batch: 620; loss: 0.62; acc: 0.8
Batch: 640; loss: 0.3; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.84
Batch: 680; loss: 0.49; acc: 0.89
Batch: 700; loss: 0.64; acc: 0.84
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.968754415633157e-05
8.963877917267382e-06
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.43; acc: 0.83
Batch: 80; loss: 0.58; acc: 0.83
Batch: 100; loss: 0.57; acc: 0.84
Batch: 120; loss: 0.79; acc: 0.78
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.44205801245892884; val_accuracy: 0.8645501592356688 

The current subspace-distance is: 8.963877917267382e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.58; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.83
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.31; acc: 0.88
Batch: 260; loss: 0.41; acc: 0.84
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.36; acc: 0.86
Batch: 320; loss: 0.74; acc: 0.8
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.52; acc: 0.83
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.47; acc: 0.83
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.51; acc: 0.78
Batch: 540; loss: 0.52; acc: 0.81
Batch: 560; loss: 0.71; acc: 0.83
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.42; acc: 0.86
Batch: 620; loss: 0.34; acc: 0.89
Batch: 640; loss: 0.41; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.88
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.55; acc: 0.78
Batch: 720; loss: 0.56; acc: 0.84
Batch: 740; loss: 0.32; acc: 0.94
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.9951810574857518e-05
9.997620509238914e-06
Batch: 0; loss: 0.35; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.4386412110298302; val_accuracy: 0.8619625796178344 

The current subspace-distance is: 9.997620509238914e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.81
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.78
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.55; acc: 0.86
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.84
Batch: 160; loss: 0.42; acc: 0.86
Batch: 180; loss: 0.44; acc: 0.91
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.74; acc: 0.8
Batch: 240; loss: 0.55; acc: 0.83
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.45; acc: 0.81
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.52; acc: 0.81
Batch: 360; loss: 0.59; acc: 0.83
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.71; acc: 0.78
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.56; acc: 0.88
Batch: 500; loss: 0.53; acc: 0.88
Batch: 520; loss: 0.58; acc: 0.83
Batch: 540; loss: 0.45; acc: 0.91
Batch: 560; loss: 0.57; acc: 0.8
Batch: 580; loss: 0.47; acc: 0.84
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.56; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.58; acc: 0.88
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.26; acc: 0.88
Batch: 780; loss: 0.8; acc: 0.72
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

3.0213197533157654e-05
9.640149073675275e-06
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.4; acc: 0.91
Batch: 60; loss: 0.36; acc: 0.89
Batch: 80; loss: 0.42; acc: 0.88
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3814699058035377; val_accuracy: 0.8853503184713376 

The current subspace-distance is: 9.640149073675275e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.52; acc: 0.88
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.61; acc: 0.88
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.41; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.95
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.63; acc: 0.8
Batch: 280; loss: 0.25; acc: 0.89
Batch: 300; loss: 0.54; acc: 0.8
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.44; acc: 0.88
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.33; acc: 0.92
Batch: 500; loss: 0.51; acc: 0.84
Batch: 520; loss: 0.52; acc: 0.83
Batch: 540; loss: 0.63; acc: 0.83
Batch: 560; loss: 0.47; acc: 0.91
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.4; acc: 0.89
Batch: 620; loss: 0.64; acc: 0.8
Batch: 640; loss: 0.41; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.62; acc: 0.78
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

3.057429421460256e-05
9.363917342852801e-06
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.79; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.97
Val Epoch over. val_loss: 0.47046797452079264; val_accuracy: 0.8546974522292994 

The current subspace-distance is: 9.363917342852801e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.58; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.52; acc: 0.84
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.65; acc: 0.8
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.57; acc: 0.81
Batch: 220; loss: 0.41; acc: 0.88
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.59; acc: 0.84
Batch: 280; loss: 0.37; acc: 0.89
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.62; acc: 0.81
Batch: 340; loss: 0.64; acc: 0.78
Batch: 360; loss: 0.23; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.86
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.65; acc: 0.81
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.61; acc: 0.81
Batch: 480; loss: 0.42; acc: 0.86
Batch: 500; loss: 0.5; acc: 0.81
Batch: 520; loss: 0.42; acc: 0.89
Batch: 540; loss: 0.71; acc: 0.8
Batch: 560; loss: 0.48; acc: 0.89
Batch: 580; loss: 0.5; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.48; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.64; acc: 0.78
Batch: 760; loss: 0.59; acc: 0.81
Batch: 780; loss: 0.34; acc: 0.89
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.9799526600982063e-05
9.083806617127266e-06
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.61; acc: 0.73
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.86
Batch: 80; loss: 0.51; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.84; acc: 0.78
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.4285549536157566; val_accuracy: 0.8688296178343949 

The current subspace-distance is: 9.083806617127266e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.83
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.5; acc: 0.83
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.42; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.46; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.83
Batch: 220; loss: 0.52; acc: 0.86
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.52; acc: 0.86
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.4; acc: 0.88
Batch: 340; loss: 0.72; acc: 0.8
Batch: 360; loss: 0.78; acc: 0.8
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.48; acc: 0.89
Batch: 480; loss: 0.58; acc: 0.84
Batch: 500; loss: 0.62; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.84
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.73; acc: 0.84
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.34; acc: 0.88
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.49; acc: 0.88
Batch: 760; loss: 0.29; acc: 0.92
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.41; train_accuracy: 0.88 

3.0428660465986468e-05
9.282210157834925e-06
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.55; acc: 0.8
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.36949522793293; val_accuracy: 0.8911226114649682 

The current subspace-distance is: 9.282210157834925e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.55; acc: 0.88
Batch: 20; loss: 0.29; acc: 0.95
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.34; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.8
Batch: 140; loss: 0.57; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.43; acc: 0.92
Batch: 200; loss: 0.5; acc: 0.84
Batch: 220; loss: 0.44; acc: 0.84
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.42; acc: 0.89
Batch: 280; loss: 0.41; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.88
Batch: 320; loss: 0.46; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.34; acc: 0.86
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.38; acc: 0.88
Batch: 500; loss: 0.43; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.64; acc: 0.84
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.5; acc: 0.83
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.61; acc: 0.83
Batch: 720; loss: 0.42; acc: 0.84
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.58; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.9826196623616852e-05
8.674641321704257e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.7; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.37000485538107575; val_accuracy: 0.8892316878980892 

The current subspace-distance is: 8.674641321704257e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.43; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.58; acc: 0.84
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.83
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.52; acc: 0.84
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.56; acc: 0.84
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.39; acc: 0.88
Batch: 480; loss: 0.52; acc: 0.81
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.74; acc: 0.84
Batch: 620; loss: 0.43; acc: 0.91
Batch: 640; loss: 0.52; acc: 0.88
Batch: 660; loss: 0.51; acc: 0.84
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.48; acc: 0.83
Batch: 720; loss: 0.42; acc: 0.86
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.58; acc: 0.83
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.036435373360291e-05
9.887249689199962e-06
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.78; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3736818371589776; val_accuracy: 0.8862460191082803 

The current subspace-distance is: 9.887249689199962e-06 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.62; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.83
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.78; acc: 0.78
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.66; acc: 0.81
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.95
Batch: 240; loss: 0.42; acc: 0.83
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.37; acc: 0.86
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.95
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.86
Batch: 440; loss: 0.46; acc: 0.84
Batch: 460; loss: 0.41; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.91
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 0.57; acc: 0.83
Batch: 600; loss: 0.91; acc: 0.8
Batch: 620; loss: 0.35; acc: 0.84
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.4; acc: 0.89
Batch: 700; loss: 0.49; acc: 0.84
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.5; acc: 0.81
Batch: 760; loss: 0.66; acc: 0.84
Batch: 780; loss: 0.59; acc: 0.84
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.0547369533451274e-05
9.392248102813028e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.84
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.72; acc: 0.78
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.37080861770423357; val_accuracy: 0.8873407643312102 

The current subspace-distance is: 9.392248102813028e-06 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.67; acc: 0.77
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.84
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.38; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.83
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.54; acc: 0.86
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.41; acc: 0.89
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.57; acc: 0.8
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.65; acc: 0.78
Batch: 540; loss: 0.38; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.43; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.45; acc: 0.84
Batch: 680; loss: 0.72; acc: 0.75
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.7; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.105791620328091e-05
1.014796544041019e-05
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.35813206049856866; val_accuracy: 0.8938097133757962 

The current subspace-distance is: 1.014796544041019e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.8; acc: 0.75
Batch: 40; loss: 0.57; acc: 0.88
Batch: 60; loss: 0.37; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.57; acc: 0.81
Batch: 340; loss: 0.38; acc: 0.83
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.31; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.46; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.54; acc: 0.86
Batch: 680; loss: 0.5; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.58; acc: 0.83
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.078769805142656e-05
9.836249773798045e-06
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.86
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3615647514534604; val_accuracy: 0.88953025477707 

The current subspace-distance is: 9.836249773798045e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.33; acc: 0.95
Batch: 100; loss: 0.53; acc: 0.86
Batch: 120; loss: 0.24; acc: 0.95
Batch: 140; loss: 0.46; acc: 0.89
Batch: 160; loss: 0.52; acc: 0.81
Batch: 180; loss: 0.29; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.41; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.83
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.51; acc: 0.77
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.3; acc: 0.94
Batch: 480; loss: 0.45; acc: 0.92
Batch: 500; loss: 0.68; acc: 0.8
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.84
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.64; acc: 0.8
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.53; acc: 0.8
Batch: 700; loss: 0.62; acc: 0.8
Batch: 720; loss: 0.56; acc: 0.83
Batch: 740; loss: 0.41; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.95
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.0725852411706e-05
9.54180086409906e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.77; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.3856039669862978; val_accuracy: 0.8823646496815286 

The current subspace-distance is: 9.54180086409906e-06 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.89
Batch: 120; loss: 0.65; acc: 0.89
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.57; acc: 0.86
Batch: 180; loss: 0.46; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.92
Batch: 240; loss: 0.78; acc: 0.78
Batch: 260; loss: 0.47; acc: 0.89
Batch: 280; loss: 0.59; acc: 0.89
Batch: 300; loss: 0.56; acc: 0.8
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.3; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.88
Batch: 380; loss: 0.5; acc: 0.84
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.59; acc: 0.78
Batch: 480; loss: 0.89; acc: 0.78
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.38; acc: 0.89
Batch: 660; loss: 0.41; acc: 0.86
Batch: 680; loss: 0.36; acc: 0.91
Batch: 700; loss: 0.41; acc: 0.89
Batch: 720; loss: 0.83; acc: 0.78
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.39; acc: 0.88
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.055207707802765e-05
9.497351129539311e-06
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.47; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3659945164516473; val_accuracy: 0.8900278662420382 

The current subspace-distance is: 9.497351129539311e-06 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.81
Batch: 20; loss: 0.53; acc: 0.8
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.42; acc: 0.91
Batch: 220; loss: 0.36; acc: 0.88
Batch: 240; loss: 0.31; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.42; acc: 0.86
Batch: 320; loss: 0.49; acc: 0.86
Batch: 340; loss: 0.56; acc: 0.81
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.35; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.38; acc: 0.86
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.6; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.48; acc: 0.84
Batch: 660; loss: 0.42; acc: 0.8
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.49; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.63; acc: 0.81
Batch: 760; loss: 0.5; acc: 0.83
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

2.992291047121398e-05
9.64809805736877e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.52; acc: 0.78
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.51; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.86
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.40623229234271746; val_accuracy: 0.8757961783439491 

The current subspace-distance is: 9.64809805736877e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.54; acc: 0.86
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.63; acc: 0.84
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.55; acc: 0.86
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.38; acc: 0.84
Batch: 260; loss: 0.27; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.57; acc: 0.84
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.75; acc: 0.84
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.6; acc: 0.86
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.29; acc: 0.92
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.47; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.39; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.84
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.45; acc: 0.83
Batch: 780; loss: 0.48; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.065052806050517e-05
1.0524108802201226e-05
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.47; acc: 0.81
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.36337076008889324; val_accuracy: 0.8900278662420382 

The current subspace-distance is: 1.0524108802201226e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.53; acc: 0.88
Batch: 200; loss: 0.46; acc: 0.83
Batch: 220; loss: 0.39; acc: 0.92
Batch: 240; loss: 0.5; acc: 0.86
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.46; acc: 0.84
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.98
Batch: 360; loss: 0.39; acc: 0.81
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.64; acc: 0.81
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.41; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.48; acc: 0.83
Batch: 600; loss: 0.41; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.51; acc: 0.86
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.42; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.49; acc: 0.86
Batch: 760; loss: 0.56; acc: 0.86
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.2881926017580554e-05
1.032097679853905e-05
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.35503882440222295; val_accuracy: 0.8935111464968153 

The current subspace-distance is: 1.032097679853905e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.43; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.43; acc: 0.84
Batch: 160; loss: 0.57; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.55; acc: 0.81
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.45; acc: 0.83
Batch: 260; loss: 0.43; acc: 0.84
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.91
Batch: 360; loss: 0.4; acc: 0.86
Batch: 380; loss: 0.46; acc: 0.88
Batch: 400; loss: 0.45; acc: 0.86
Batch: 420; loss: 0.49; acc: 0.89
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.88
Batch: 500; loss: 0.47; acc: 0.83
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.36; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.33; acc: 0.89
Batch: 620; loss: 0.51; acc: 0.77
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.91
Batch: 680; loss: 0.71; acc: 0.77
Batch: 700; loss: 0.3; acc: 0.88
Batch: 720; loss: 0.39; acc: 0.84
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.179736086167395e-05
9.465157745580655e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.83
Batch: 120; loss: 0.7; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.36012785222120347; val_accuracy: 0.8902269108280255 

The current subspace-distance is: 9.465157745580655e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.48; acc: 0.83
Batch: 220; loss: 0.54; acc: 0.88
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.59; acc: 0.83
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.5; acc: 0.89
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.89
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.92
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.56; acc: 0.84
Batch: 600; loss: 0.43; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.23; acc: 0.95
Batch: 660; loss: 0.55; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.49; acc: 0.86
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.158548497594893e-05
9.788650459086057e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3581780198083562; val_accuracy: 0.8927149681528662 

The current subspace-distance is: 9.788650459086057e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.29; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.54; acc: 0.84
Batch: 160; loss: 0.37; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.91
Batch: 240; loss: 0.31; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.36; acc: 0.92
Batch: 320; loss: 0.52; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.48; acc: 0.84
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.33; acc: 0.94
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.3; acc: 0.86
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.84
Batch: 580; loss: 0.43; acc: 0.84
Batch: 600; loss: 0.57; acc: 0.86
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.65; acc: 0.83
Batch: 720; loss: 0.38; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.92
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.050350642297417e-05
9.747213880473282e-06
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.36000311056709594; val_accuracy: 0.8926154458598726 

The current subspace-distance is: 9.747213880473282e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.36; acc: 0.86
Batch: 60; loss: 0.5; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.31; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.42; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.59; acc: 0.86
Batch: 260; loss: 0.41; acc: 0.89
Batch: 280; loss: 0.48; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.36; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.25; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.94
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.33; acc: 0.88
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.44; acc: 0.88
Batch: 620; loss: 0.54; acc: 0.83
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.84
Batch: 760; loss: 0.38; acc: 0.89
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.0400758987525478e-05
9.571302143740468e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3520261665723126; val_accuracy: 0.8943073248407644 

The current subspace-distance is: 9.571302143740468e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.34; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.43; acc: 0.83
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.53; acc: 0.89
Batch: 240; loss: 0.41; acc: 0.84
Batch: 260; loss: 0.36; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.47; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.52; acc: 0.86
Batch: 540; loss: 0.39; acc: 0.86
Batch: 560; loss: 0.4; acc: 0.84
Batch: 580; loss: 0.8; acc: 0.83
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.47; acc: 0.84
Batch: 640; loss: 0.62; acc: 0.83
Batch: 660; loss: 0.41; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.54; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.082199691561982e-05
9.579010111337993e-06
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3545390538349273; val_accuracy: 0.8932125796178344 

The current subspace-distance is: 9.579010111337993e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.86
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.83
Batch: 140; loss: 0.77; acc: 0.83
Batch: 160; loss: 0.57; acc: 0.81
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.86
Batch: 280; loss: 0.48; acc: 0.84
Batch: 300; loss: 0.41; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.63; acc: 0.81
Batch: 380; loss: 0.55; acc: 0.86
Batch: 400; loss: 0.31; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.38; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.47; acc: 0.88
Batch: 580; loss: 0.49; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.5; acc: 0.86
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.92
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.27; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.170856507495046e-05
9.383623364556115e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3556735350922414; val_accuracy: 0.894406847133758 

The current subspace-distance is: 9.383623364556115e-06 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.4; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.41; acc: 0.83
Batch: 140; loss: 0.56; acc: 0.86
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.91
Batch: 240; loss: 0.53; acc: 0.81
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.3; acc: 0.86
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.36; acc: 0.91
Batch: 340; loss: 0.5; acc: 0.86
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.65; acc: 0.81
Batch: 400; loss: 0.51; acc: 0.84
Batch: 420; loss: 0.59; acc: 0.84
Batch: 440; loss: 0.66; acc: 0.83
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.72; acc: 0.8
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.52; acc: 0.86
Batch: 560; loss: 0.42; acc: 0.84
Batch: 580; loss: 0.35; acc: 0.86
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.57; acc: 0.84
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.94
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.0618906748713925e-05
9.016932381200604e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.35472722104780235; val_accuracy: 0.8932125796178344 

The current subspace-distance is: 9.016932381200604e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.64; acc: 0.81
Batch: 140; loss: 0.31; acc: 0.88
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.43; acc: 0.88
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.28; acc: 0.89
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.58; acc: 0.86
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.52; acc: 0.83
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.43; acc: 0.84
Batch: 500; loss: 0.47; acc: 0.89
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.86
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.86
Batch: 640; loss: 0.57; acc: 0.88
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.33; acc: 0.89
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.47; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.060327799175866e-05
9.23152401810512e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3539661884687509; val_accuracy: 0.8920183121019108 

The current subspace-distance is: 9.23152401810512e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.35; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.49; acc: 0.84
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.48; acc: 0.88
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.86
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.56; acc: 0.81
Batch: 320; loss: 0.43; acc: 0.83
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.43; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.83
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.54; acc: 0.8
Batch: 440; loss: 0.5; acc: 0.88
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.6; acc: 0.86
Batch: 500; loss: 0.37; acc: 0.86
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.34; acc: 0.86
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.36; acc: 0.91
Batch: 620; loss: 0.56; acc: 0.8
Batch: 640; loss: 0.42; acc: 0.84
Batch: 660; loss: 0.58; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.94
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.45; acc: 0.88
Batch: 760; loss: 0.38; acc: 0.84
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.0437617169809528e-05
9.926036909746472e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35262869326931656; val_accuracy: 0.8936106687898089 

The current subspace-distance is: 9.926036909746472e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.49; acc: 0.86
Batch: 200; loss: 0.33; acc: 0.94
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.56; acc: 0.84
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.38; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.54; acc: 0.81
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.48; acc: 0.86
Batch: 420; loss: 0.41; acc: 0.92
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.49; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.84
Batch: 540; loss: 0.53; acc: 0.89
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.39; acc: 0.89
Batch: 640; loss: 0.72; acc: 0.83
Batch: 660; loss: 0.5; acc: 0.91
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.5; acc: 0.81
Batch: 720; loss: 0.45; acc: 0.84
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.54; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.114682840532623e-05
9.818767466640566e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35241919072570316; val_accuracy: 0.8954020700636943 

The current subspace-distance is: 9.818767466640566e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.86
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.5; acc: 0.86
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.27; acc: 0.89
Batch: 360; loss: 0.47; acc: 0.86
Batch: 380; loss: 0.39; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.31; acc: 0.91
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.55; acc: 0.86
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.67; acc: 0.83
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.55; acc: 0.89
Batch: 600; loss: 0.58; acc: 0.78
Batch: 620; loss: 0.47; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.41; acc: 0.83
Batch: 680; loss: 0.48; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.59; acc: 0.83
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.0232193239498883e-05
9.664794561103918e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.3516632866612665; val_accuracy: 0.8958996815286624 

The current subspace-distance is: 9.664794561103918e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.35; acc: 0.91
Batch: 140; loss: 0.41; acc: 0.83
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.64; acc: 0.83
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.26; acc: 0.95
Batch: 300; loss: 0.49; acc: 0.83
Batch: 320; loss: 0.28; acc: 0.95
Batch: 340; loss: 0.3; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.51; acc: 0.89
Batch: 400; loss: 0.5; acc: 0.86
Batch: 420; loss: 0.37; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.91
Batch: 480; loss: 0.48; acc: 0.81
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.49; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.7; acc: 0.81
Batch: 660; loss: 0.35; acc: 0.84
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.104035567957908e-05
9.924494406732265e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35189095082556365; val_accuracy: 0.8941082802547771 

The current subspace-distance is: 9.924494406732265e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.56; acc: 0.81
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.46; acc: 0.8
Batch: 60; loss: 0.47; acc: 0.8
Batch: 80; loss: 0.27; acc: 0.89
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.35; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.36; acc: 0.91
Batch: 260; loss: 0.4; acc: 0.84
Batch: 280; loss: 0.41; acc: 0.84
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.41; acc: 0.86
Batch: 340; loss: 0.45; acc: 0.91
Batch: 360; loss: 0.47; acc: 0.81
Batch: 380; loss: 0.73; acc: 0.83
Batch: 400; loss: 0.43; acc: 0.84
Batch: 420; loss: 0.5; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.47; acc: 0.91
Batch: 480; loss: 0.51; acc: 0.86
Batch: 500; loss: 0.26; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.75; acc: 0.81
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.39; acc: 0.83
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.31; acc: 0.92
Batch: 760; loss: 0.49; acc: 0.83
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.184927118127234e-05
9.544958629703615e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35115817255654913; val_accuracy: 0.8943073248407644 

The current subspace-distance is: 9.544958629703615e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.88
Batch: 20; loss: 0.74; acc: 0.83
Batch: 40; loss: 0.65; acc: 0.84
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.86
Batch: 100; loss: 0.66; acc: 0.78
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.86
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.89
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.38; acc: 0.88
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.36; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.38; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.46; acc: 0.88
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.92
Batch: 480; loss: 0.32; acc: 0.92
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.23; acc: 0.91
Batch: 640; loss: 0.35; acc: 0.86
Batch: 660; loss: 0.48; acc: 0.84
Batch: 680; loss: 0.6; acc: 0.81
Batch: 700; loss: 0.62; acc: 0.83
Batch: 720; loss: 0.36; acc: 0.83
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.106475924141705e-05
1.0185864994127769e-05
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35362100492047654; val_accuracy: 0.8943073248407644 

The current subspace-distance is: 1.0185864994127769e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.43; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.67; acc: 0.84
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.53; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.27; acc: 0.92
Batch: 240; loss: 0.4; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.67; acc: 0.83
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.88
Batch: 380; loss: 0.36; acc: 0.86
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.49; acc: 0.84
Batch: 440; loss: 0.32; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.32; acc: 0.91
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.81
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.42; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.94
Batch: 740; loss: 0.3; acc: 0.92
Batch: 760; loss: 0.5; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.107551674474962e-05
9.276700438931584e-06
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.91
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3532235986867528; val_accuracy: 0.894406847133758 

The current subspace-distance is: 9.276700438931584e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.65; acc: 0.86
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.22; acc: 0.95
Batch: 120; loss: 0.47; acc: 0.88
Batch: 140; loss: 0.39; acc: 0.86
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.67; acc: 0.81
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.74; acc: 0.8
Batch: 280; loss: 0.35; acc: 0.92
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.44; acc: 0.86
Batch: 340; loss: 0.35; acc: 0.91
Batch: 360; loss: 0.32; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.91
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.63; acc: 0.83
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.63; acc: 0.83
Batch: 620; loss: 0.36; acc: 0.84
Batch: 640; loss: 0.29; acc: 0.88
Batch: 660; loss: 0.49; acc: 0.84
Batch: 680; loss: 0.52; acc: 0.84
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.069090598728508e-05
1.0113594726135489e-05
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.47; acc: 0.84
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.12; acc: 0.95
Val Epoch over. val_loss: 0.3532028880658423; val_accuracy: 0.8947054140127388 

The current subspace-distance is: 1.0113594726135489e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.58; acc: 0.81
Batch: 80; loss: 0.63; acc: 0.81
Batch: 100; loss: 0.43; acc: 0.81
Batch: 120; loss: 0.35; acc: 0.86
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.58; acc: 0.81
Batch: 180; loss: 0.65; acc: 0.83
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.59; acc: 0.81
Batch: 240; loss: 0.39; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.89
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.4; acc: 0.89
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.36; acc: 0.84
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.36; acc: 0.86
Batch: 580; loss: 0.26; acc: 0.89
Batch: 600; loss: 0.39; acc: 0.89
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.47; acc: 0.81
Batch: 740; loss: 0.42; acc: 0.84
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.0696526664542034e-05
1.056605287885759e-05
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.350993627195905; val_accuracy: 0.8937101910828026 

The current subspace-distance is: 1.056605287885759e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.22; acc: 0.91
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.5; acc: 0.83
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.44; acc: 0.91
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.5; acc: 0.83
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.46; acc: 0.84
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.3; acc: 0.89
Batch: 540; loss: 0.51; acc: 0.86
Batch: 560; loss: 0.35; acc: 0.84
Batch: 580; loss: 0.34; acc: 0.86
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.78
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.4; acc: 0.92
Batch: 740; loss: 0.31; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.92
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.1278294045478106e-05
9.376143680128735e-06
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.45; acc: 0.84
Batch: 40; loss: 0.33; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3545676151373584; val_accuracy: 0.8943073248407644 

The current subspace-distance is: 9.376143680128735e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.49; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.95
Batch: 60; loss: 0.51; acc: 0.84
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.36; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.24; acc: 0.95
Batch: 260; loss: 0.34; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.95
Batch: 360; loss: 0.51; acc: 0.8
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.4; acc: 0.86
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.58; acc: 0.91
Batch: 560; loss: 0.62; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.83
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.29; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.37; acc: 0.92
Batch: 680; loss: 0.54; acc: 0.88
Batch: 700; loss: 0.5; acc: 0.88
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.43; acc: 0.83
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.36; acc: 0.84
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.29685935867019e-05
1.0005571311921813e-05
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.45; acc: 0.81
Batch: 40; loss: 0.32; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35112901601442104; val_accuracy: 0.8941082802547771 

The current subspace-distance is: 1.0005571311921813e-05 

plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 62433
elements in E: 13185600
fraction nonzero: 0.004734938114306516
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.37; acc: 0.17
Batch: 20; loss: 2.21; acc: 0.27
Batch: 40; loss: 2.2; acc: 0.23
Batch: 60; loss: 2.16; acc: 0.39
Batch: 80; loss: 2.07; acc: 0.34
Batch: 100; loss: 2.1; acc: 0.25
Batch: 120; loss: 1.95; acc: 0.38
Batch: 140; loss: 1.79; acc: 0.45
Batch: 160; loss: 1.68; acc: 0.47
Batch: 180; loss: 1.49; acc: 0.61
Batch: 200; loss: 1.59; acc: 0.55
Batch: 220; loss: 1.62; acc: 0.45
Batch: 240; loss: 1.48; acc: 0.5
Batch: 260; loss: 1.43; acc: 0.61
Batch: 280; loss: 1.28; acc: 0.56
Batch: 300; loss: 1.25; acc: 0.59
Batch: 320; loss: 1.28; acc: 0.58
Batch: 340; loss: 1.18; acc: 0.67
Batch: 360; loss: 1.09; acc: 0.64
Batch: 380; loss: 1.42; acc: 0.45
Batch: 400; loss: 1.25; acc: 0.56
Batch: 420; loss: 0.89; acc: 0.69
Batch: 440; loss: 0.89; acc: 0.75
Batch: 460; loss: 1.07; acc: 0.66
Batch: 480; loss: 0.9; acc: 0.69
Batch: 500; loss: 0.88; acc: 0.73
Batch: 520; loss: 0.92; acc: 0.69
Batch: 540; loss: 1.03; acc: 0.7
Batch: 560; loss: 1.02; acc: 0.69
Batch: 580; loss: 0.99; acc: 0.62
Batch: 600; loss: 0.73; acc: 0.83
Batch: 620; loss: 0.86; acc: 0.75
Batch: 640; loss: 0.77; acc: 0.73
Batch: 660; loss: 1.0; acc: 0.64
Batch: 680; loss: 0.75; acc: 0.72
Batch: 700; loss: 0.95; acc: 0.75
Batch: 720; loss: 0.89; acc: 0.8
Batch: 740; loss: 0.59; acc: 0.83
Batch: 760; loss: 0.62; acc: 0.78
Batch: 780; loss: 0.86; acc: 0.73
Train Epoch over. train_loss: 1.29; train_accuracy: 0.59 

1.8301532691111788e-05
6.440124707296491e-06
Batch: 0; loss: 0.9; acc: 0.72
Batch: 20; loss: 1.27; acc: 0.59
Batch: 40; loss: 0.73; acc: 0.73
Batch: 60; loss: 0.97; acc: 0.67
Batch: 80; loss: 0.98; acc: 0.73
Batch: 100; loss: 1.04; acc: 0.66
Batch: 120; loss: 1.33; acc: 0.62
Batch: 140; loss: 0.77; acc: 0.66
Val Epoch over. val_loss: 0.9991144017808756; val_accuracy: 0.6571457006369427 

The current subspace-distance is: 6.440124707296491e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.06; acc: 0.61
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 1.1; acc: 0.61
Batch: 60; loss: 0.77; acc: 0.77
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.92; acc: 0.64
Batch: 140; loss: 0.57; acc: 0.8
Batch: 160; loss: 0.57; acc: 0.8
Batch: 180; loss: 1.06; acc: 0.7
Batch: 200; loss: 0.49; acc: 0.84
Batch: 220; loss: 1.02; acc: 0.64
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.97; acc: 0.7
Batch: 280; loss: 0.74; acc: 0.8
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.63; acc: 0.81
Batch: 340; loss: 0.55; acc: 0.81
Batch: 360; loss: 0.66; acc: 0.75
Batch: 380; loss: 0.53; acc: 0.84
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.75; acc: 0.78
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.61; acc: 0.78
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.78; acc: 0.77
Batch: 520; loss: 0.53; acc: 0.83
Batch: 540; loss: 0.85; acc: 0.75
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.81; acc: 0.73
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.44; acc: 0.88
Batch: 640; loss: 0.89; acc: 0.7
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.59; acc: 0.78
Batch: 700; loss: 0.22; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.92
Batch: 740; loss: 0.57; acc: 0.83
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.87; acc: 0.72
Train Epoch over. train_loss: 0.62; train_accuracy: 0.8 

2.4511347874067724e-05
7.784468834870495e-06
Batch: 0; loss: 0.52; acc: 0.86
Batch: 20; loss: 0.49; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.81
Batch: 80; loss: 0.48; acc: 0.86
Batch: 100; loss: 0.72; acc: 0.81
Batch: 120; loss: 0.92; acc: 0.69
Batch: 140; loss: 0.23; acc: 0.91
Val Epoch over. val_loss: 0.54956740605983; val_accuracy: 0.8296178343949044 

The current subspace-distance is: 7.784468834870495e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.46; acc: 0.88
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.45; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.28; acc: 0.95
Batch: 160; loss: 0.52; acc: 0.86
Batch: 180; loss: 0.56; acc: 0.84
Batch: 200; loss: 0.38; acc: 0.91
Batch: 220; loss: 0.62; acc: 0.84
Batch: 240; loss: 0.48; acc: 0.83
Batch: 260; loss: 0.65; acc: 0.83
Batch: 280; loss: 0.79; acc: 0.75
Batch: 300; loss: 0.43; acc: 0.84
Batch: 320; loss: 0.54; acc: 0.83
Batch: 340; loss: 0.61; acc: 0.81
Batch: 360; loss: 0.56; acc: 0.83
Batch: 380; loss: 0.7; acc: 0.8
Batch: 400; loss: 0.61; acc: 0.81
Batch: 420; loss: 0.44; acc: 0.89
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.64; acc: 0.78
Batch: 480; loss: 0.33; acc: 0.88
Batch: 500; loss: 0.57; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.51; acc: 0.8
Batch: 560; loss: 0.52; acc: 0.8
Batch: 580; loss: 0.88; acc: 0.67
Batch: 600; loss: 0.74; acc: 0.78
Batch: 620; loss: 0.32; acc: 0.92
Batch: 640; loss: 0.5; acc: 0.83
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.54; acc: 0.84
Batch: 700; loss: 0.49; acc: 0.89
Batch: 720; loss: 0.54; acc: 0.86
Batch: 740; loss: 0.48; acc: 0.84
Batch: 760; loss: 0.47; acc: 0.84
Batch: 780; loss: 0.48; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

2.7456664611236192e-05
8.256674846052192e-06
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.62; acc: 0.77
Batch: 40; loss: 0.51; acc: 0.88
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.63; acc: 0.8
Batch: 120; loss: 0.94; acc: 0.7
Batch: 140; loss: 0.36; acc: 0.91
Val Epoch over. val_loss: 0.6224045821815539; val_accuracy: 0.8048367834394905 

The current subspace-distance is: 8.256674846052192e-06 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.42; acc: 0.84
Batch: 40; loss: 0.32; acc: 0.89
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.85; acc: 0.78
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.83
Batch: 140; loss: 0.35; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.52; acc: 0.89
Batch: 200; loss: 0.43; acc: 0.81
Batch: 220; loss: 0.68; acc: 0.81
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.48; acc: 0.86
Batch: 300; loss: 0.64; acc: 0.78
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.61; acc: 0.77
Batch: 360; loss: 0.66; acc: 0.8
Batch: 380; loss: 0.84; acc: 0.7
Batch: 400; loss: 0.64; acc: 0.81
Batch: 420; loss: 0.58; acc: 0.84
Batch: 440; loss: 0.54; acc: 0.86
Batch: 460; loss: 0.61; acc: 0.8
Batch: 480; loss: 0.4; acc: 0.86
Batch: 500; loss: 0.58; acc: 0.81
Batch: 520; loss: 0.42; acc: 0.92
Batch: 540; loss: 0.52; acc: 0.86
Batch: 560; loss: 0.72; acc: 0.8
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.75; acc: 0.83
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.54; acc: 0.83
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.28; acc: 0.89
Batch: 720; loss: 0.67; acc: 0.78
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.64; acc: 0.78
Batch: 780; loss: 0.38; acc: 0.84
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

2.797665547404904e-05
9.250281436834484e-06
Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 0.57; acc: 0.84
Batch: 60; loss: 0.71; acc: 0.78
Batch: 80; loss: 0.64; acc: 0.8
Batch: 100; loss: 0.85; acc: 0.78
Batch: 120; loss: 1.23; acc: 0.67
Batch: 140; loss: 0.52; acc: 0.8
Val Epoch over. val_loss: 0.793715148404905; val_accuracy: 0.7553742038216561 

The current subspace-distance is: 9.250281436834484e-06 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.7; acc: 0.88
Batch: 20; loss: 0.73; acc: 0.83
Batch: 40; loss: 0.43; acc: 0.86
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.54; acc: 0.86
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.77; acc: 0.81
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.49; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.83
Batch: 280; loss: 0.38; acc: 0.88
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.88
Batch: 340; loss: 0.71; acc: 0.77
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.89
Batch: 400; loss: 0.4; acc: 0.88
Batch: 420; loss: 0.62; acc: 0.84
Batch: 440; loss: 0.49; acc: 0.88
Batch: 460; loss: 0.38; acc: 0.89
Batch: 480; loss: 0.49; acc: 0.89
Batch: 500; loss: 0.45; acc: 0.83
Batch: 520; loss: 0.5; acc: 0.81
Batch: 540; loss: 0.48; acc: 0.81
Batch: 560; loss: 0.51; acc: 0.86
Batch: 580; loss: 0.52; acc: 0.8
Batch: 600; loss: 0.42; acc: 0.84
Batch: 620; loss: 0.28; acc: 0.91
Batch: 640; loss: 0.46; acc: 0.91
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.92
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.31; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.67; acc: 0.78
Train Epoch over. train_loss: 0.44; train_accuracy: 0.86 

2.8877402655780315e-05
8.935889127315022e-06
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.52; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.25; acc: 0.89
Val Epoch over. val_loss: 0.36583628068873836; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 8.935889127315022e-06 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.74; acc: 0.78
Batch: 20; loss: 0.49; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.86
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.65; acc: 0.84
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.91
Batch: 320; loss: 0.45; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.6; acc: 0.86
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.27; acc: 0.95
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.43; acc: 0.86
Batch: 480; loss: 0.58; acc: 0.83
Batch: 500; loss: 0.38; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.36; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.5; acc: 0.8
Batch: 640; loss: 0.58; acc: 0.86
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.67; acc: 0.78
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.55; acc: 0.84
Batch: 740; loss: 0.49; acc: 0.83
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.55; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

2.9838998671039008e-05
9.183101610688027e-06
Batch: 0; loss: 0.44; acc: 0.89
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 0.55; acc: 0.88
Batch: 60; loss: 0.74; acc: 0.8
Batch: 80; loss: 0.61; acc: 0.83
Batch: 100; loss: 0.7; acc: 0.81
Batch: 120; loss: 1.09; acc: 0.73
Batch: 140; loss: 0.39; acc: 0.89
Val Epoch over. val_loss: 0.5950489822466662; val_accuracy: 0.8158837579617835 

The current subspace-distance is: 9.183101610688027e-06 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.61; acc: 0.8
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.71; acc: 0.77
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.53; acc: 0.83
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.47; acc: 0.89
Batch: 220; loss: 0.46; acc: 0.86
Batch: 240; loss: 0.64; acc: 0.78
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.29; acc: 0.94
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.45; acc: 0.84
Batch: 340; loss: 0.5; acc: 0.81
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.47; acc: 0.8
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.47; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.36; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.49; acc: 0.84
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.66; acc: 0.78
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.35; acc: 0.92
Batch: 700; loss: 0.47; acc: 0.83
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.55; acc: 0.81
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.075670974794775e-05
1.0183576705458108e-05
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.39; acc: 0.91
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.4394513681815688; val_accuracy: 0.8660429936305732 

The current subspace-distance is: 1.0183576705458108e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.64; acc: 0.81
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.45; acc: 0.83
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.5; acc: 0.75
Batch: 280; loss: 0.23; acc: 0.91
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.4; acc: 0.86
Batch: 340; loss: 0.61; acc: 0.84
Batch: 360; loss: 0.31; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.81
Batch: 460; loss: 0.56; acc: 0.81
Batch: 480; loss: 0.68; acc: 0.88
Batch: 500; loss: 0.56; acc: 0.84
Batch: 520; loss: 0.35; acc: 0.94
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.27; acc: 0.94
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.23; acc: 0.89
Batch: 680; loss: 0.58; acc: 0.86
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.35; acc: 0.86
Batch: 780; loss: 0.78; acc: 0.73
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

3.078890949836932e-05
1.006671845971141e-05
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.4; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.78
Batch: 140; loss: 0.22; acc: 0.89
Val Epoch over. val_loss: 0.35538245704333493; val_accuracy: 0.888734076433121 

The current subspace-distance is: 1.006671845971141e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.45; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.39; acc: 0.88
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.38; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.56; acc: 0.83
Batch: 260; loss: 0.18; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.75; acc: 0.78
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.62; acc: 0.81
Batch: 460; loss: 0.23; acc: 0.95
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.39; acc: 0.88
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.67; acc: 0.83
Batch: 600; loss: 0.39; acc: 0.83
Batch: 620; loss: 0.39; acc: 0.84
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.49; acc: 0.88
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.65; acc: 0.84
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.39; train_accuracy: 0.88 

3.084251511609182e-05
9.429094461665954e-06
Batch: 0; loss: 0.51; acc: 0.78
Batch: 20; loss: 0.53; acc: 0.8
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.58; acc: 0.8
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.54; acc: 0.8
Batch: 120; loss: 0.51; acc: 0.81
Batch: 140; loss: 0.17; acc: 0.92
Val Epoch over. val_loss: 0.47673961036144546; val_accuracy: 0.8449442675159236 

The current subspace-distance is: 9.429094461665954e-06 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.83
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.61; acc: 0.8
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.88
Batch: 160; loss: 0.45; acc: 0.84
Batch: 180; loss: 0.51; acc: 0.83
Batch: 200; loss: 0.26; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.32; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.89
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.37; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.89
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.28; acc: 0.95
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.75; acc: 0.83
Batch: 500; loss: 0.48; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.81
Batch: 560; loss: 0.46; acc: 0.84
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.54; acc: 0.8
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.41; acc: 0.88
Batch: 740; loss: 0.58; acc: 0.83
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

3.066108547500335e-05
8.85823192220414e-06
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.44; acc: 0.81
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.89
Batch: 100; loss: 0.48; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4159098087222713; val_accuracy: 0.8687300955414012 

The current subspace-distance is: 8.85823192220414e-06 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.65; acc: 0.8
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.52; acc: 0.86
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.91
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.35; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.2; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.6; acc: 0.86
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.84
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.36; acc: 0.88
Train Epoch over. train_loss: 0.33; train_accuracy: 0.9 

3.130723052890971e-05
1.0233919965685345e-05
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.31; acc: 0.95
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.92
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.33068961654878726; val_accuracy: 0.902468152866242 

The current subspace-distance is: 1.0233919965685345e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.27; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.42; acc: 0.89
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.34; acc: 0.88
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.59; acc: 0.81
Batch: 300; loss: 0.35; acc: 0.86
Batch: 320; loss: 0.37; acc: 0.91
Batch: 340; loss: 0.38; acc: 0.84
Batch: 360; loss: 0.25; acc: 0.88
Batch: 380; loss: 0.45; acc: 0.86
Batch: 400; loss: 0.32; acc: 0.84
Batch: 420; loss: 0.48; acc: 0.88
Batch: 440; loss: 0.22; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.94
Batch: 500; loss: 0.41; acc: 0.89
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.51; acc: 0.88
Batch: 620; loss: 0.36; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.84
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.49; acc: 0.88
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.39; acc: 0.88
Batch: 760; loss: 0.19; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

3.031492633454036e-05
8.474654350720812e-06
Batch: 0; loss: 0.25; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.57; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.29940747099507387; val_accuracy: 0.9050557324840764 

The current subspace-distance is: 8.474654350720812e-06 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.5; acc: 0.89
Batch: 140; loss: 0.35; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.38; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.28; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.91
Batch: 320; loss: 0.55; acc: 0.83
Batch: 340; loss: 0.33; acc: 0.84
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.37; acc: 0.88
Batch: 420; loss: 0.31; acc: 0.88
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.44; acc: 0.83
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.48; acc: 0.83
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.17; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.41; acc: 0.88
Batch: 680; loss: 0.33; acc: 0.88
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.44; acc: 0.91
Batch: 780; loss: 0.35; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

3.149289477732964e-05
9.226750989910215e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.4; acc: 0.84
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.3040202182189674; val_accuracy: 0.9055533439490446 

The current subspace-distance is: 9.226750989910215e-06 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.92
Batch: 140; loss: 0.42; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.89
Batch: 200; loss: 0.3; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.55; acc: 0.81
Batch: 260; loss: 0.29; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.48; acc: 0.84
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.91
Batch: 380; loss: 0.47; acc: 0.89
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.86
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.2; acc: 0.91
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.52; acc: 0.88
Batch: 720; loss: 0.19; acc: 0.95
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

3.158448089379817e-05
9.730219971970655e-06
Batch: 0; loss: 0.29; acc: 0.95
Batch: 20; loss: 0.45; acc: 0.91
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.77; acc: 0.77
Batch: 140; loss: 0.11; acc: 0.94
Val Epoch over. val_loss: 0.34953772665778543; val_accuracy: 0.8898288216560509 

The current subspace-distance is: 9.730219971970655e-06 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.31; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.36; acc: 0.84
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.69; acc: 0.86
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.5; acc: 0.78
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.22; acc: 0.91
Batch: 420; loss: 0.49; acc: 0.81
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.46; acc: 0.91
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.32; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.51; acc: 0.84
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

3.0615679861512035e-05
9.435257197765168e-06
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.64; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.31; acc: 0.94
Batch: 100; loss: 0.47; acc: 0.81
Batch: 120; loss: 1.06; acc: 0.75
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.42774993043606446; val_accuracy: 0.8682324840764332 

The current subspace-distance is: 9.435257197765168e-06 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.88
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.34; acc: 0.91
Batch: 320; loss: 0.47; acc: 0.88
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.24; acc: 0.89
Batch: 400; loss: 0.32; acc: 0.86
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.34; acc: 0.84
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.32; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.92
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.31; acc: 0.89
Batch: 700; loss: 0.41; acc: 0.91
Batch: 720; loss: 0.43; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.95
Batch: 780; loss: 0.56; acc: 0.86
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

3.0858391255605966e-05
9.198412044497672e-06
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.84
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.84
Batch: 120; loss: 0.87; acc: 0.77
Batch: 140; loss: 0.12; acc: 0.94
Val Epoch over. val_loss: 0.33613427163689; val_accuracy: 0.8950039808917197 

The current subspace-distance is: 9.198412044497672e-06 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.35; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.4; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.43; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.29; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.34; acc: 0.86
Batch: 300; loss: 0.3; acc: 0.92
Batch: 320; loss: 0.62; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.88
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.49; acc: 0.86
Batch: 400; loss: 0.73; acc: 0.84
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.37; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.24; acc: 0.89
Batch: 520; loss: 0.66; acc: 0.81
Batch: 540; loss: 0.35; acc: 0.83
Batch: 560; loss: 0.58; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.59; acc: 0.8
Batch: 680; loss: 0.44; acc: 0.91
Batch: 700; loss: 0.58; acc: 0.84
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

3.07196460198611e-05
9.14596785150934e-06
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.35474156123247874; val_accuracy: 0.8908240445859873 

The current subspace-distance is: 9.14596785150934e-06 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.56; acc: 0.83
Batch: 60; loss: 0.42; acc: 0.89
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.88
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.43; acc: 0.88
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.48; acc: 0.89
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.67; acc: 0.86
Batch: 480; loss: 0.44; acc: 0.84
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.43; acc: 0.83
Batch: 580; loss: 0.18; acc: 0.97
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.54; acc: 0.86
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.63; acc: 0.8
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

3.117814048891887e-05
9.699834663479123e-06
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.42; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.8
Batch: 140; loss: 0.07; acc: 0.95
Val Epoch over. val_loss: 0.3137647363410634; val_accuracy: 0.9040605095541401 

The current subspace-distance is: 9.699834663479123e-06 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.32; acc: 0.88
Batch: 20; loss: 0.47; acc: 0.88
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.92
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.37; acc: 0.88
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.32; acc: 0.94
Batch: 480; loss: 0.38; acc: 0.84
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.98
Batch: 740; loss: 0.56; acc: 0.86
Batch: 760; loss: 0.45; acc: 0.84
Batch: 780; loss: 0.43; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

3.107814700342715e-05
9.04652461031219e-06
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.3003294397691253; val_accuracy: 0.908937101910828 

The current subspace-distance is: 9.04652461031219e-06 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.45; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.16; acc: 0.97
Batch: 260; loss: 0.35; acc: 0.89
Batch: 280; loss: 0.29; acc: 0.95
Batch: 300; loss: 0.61; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.89
Batch: 340; loss: 0.45; acc: 0.88
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.38; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.6; acc: 0.88
Batch: 560; loss: 0.39; acc: 0.86
Batch: 580; loss: 0.4; acc: 0.88
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.88
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

3.128699245280586e-05
9.981596122088376e-06
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.41; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.74; acc: 0.78
Batch: 140; loss: 0.07; acc: 0.95
Val Epoch over. val_loss: 0.2872128365620686; val_accuracy: 0.912718949044586 

The current subspace-distance is: 9.981596122088376e-06 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.38; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.33; acc: 0.84
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.94
Batch: 140; loss: 0.23; acc: 0.91
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.36; acc: 0.86
Batch: 200; loss: 0.54; acc: 0.89
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.95
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.45; acc: 0.91
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.4; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.95
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.11; acc: 0.98
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.89
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.28; acc: 0.89
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.1061565096024424e-05
9.179887456411961e-06
Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.62; acc: 0.78
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.2726998931378316; val_accuracy: 0.9144108280254777 

The current subspace-distance is: 9.179887456411961e-06 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.89
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.36; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.21; acc: 0.89
Batch: 160; loss: 0.31; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.42; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.34; acc: 0.84
Batch: 300; loss: 0.47; acc: 0.89
Batch: 320; loss: 0.48; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.89
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.54; acc: 0.89
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.89
Batch: 500; loss: 0.4; acc: 0.91
Batch: 520; loss: 0.29; acc: 0.92
Batch: 540; loss: 0.33; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.41; acc: 0.83
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.95
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.36; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.148653559037484e-05
9.027824489749037e-06
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.88
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.2883684046234295; val_accuracy: 0.9122213375796179 

The current subspace-distance is: 9.027824489749037e-06 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.34; acc: 0.88
Batch: 20; loss: 0.26; acc: 0.89
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.1; acc: 1.0
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.47; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.94
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.38; acc: 0.94
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.4; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.49; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.47; acc: 0.81
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.158488107146695e-05
1.0353995094192214e-05
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27263456307778694; val_accuracy: 0.9166998407643312 

The current subspace-distance is: 1.0353995094192214e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.69; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.86
Batch: 80; loss: 0.52; acc: 0.8
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.34; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.31; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.89
Batch: 260; loss: 0.58; acc: 0.81
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.38; acc: 0.84
Batch: 440; loss: 0.54; acc: 0.81
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.46; acc: 0.86
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.49; acc: 0.91
Batch: 580; loss: 0.39; acc: 0.92
Batch: 600; loss: 0.42; acc: 0.88
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.37; acc: 0.86
Batch: 760; loss: 0.59; acc: 0.83
Batch: 780; loss: 0.34; acc: 0.88
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.2283482141792774e-05
1.067859284376027e-05
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.97
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.84; acc: 0.77
Batch: 140; loss: 0.08; acc: 0.97
Val Epoch over. val_loss: 0.2914708549050009; val_accuracy: 0.9123208598726115 

The current subspace-distance is: 1.067859284376027e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.57; acc: 0.86
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.38; acc: 0.88
Batch: 160; loss: 0.35; acc: 0.92
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.45; acc: 0.88
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.38; acc: 0.88
Batch: 360; loss: 0.29; acc: 0.88
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.84
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.62; acc: 0.83
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.64; acc: 0.88
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.124248905805871e-05
9.131324077316094e-06
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.64; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2629742648001689; val_accuracy: 0.9192874203821656 

The current subspace-distance is: 9.131324077316094e-06 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.78; acc: 0.83
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.37; acc: 0.86
Batch: 160; loss: 0.28; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.27; acc: 0.86
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.84
Batch: 320; loss: 0.35; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.86
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.42; acc: 0.91
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.1863928597886115e-05
9.70929249888286e-06
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2658821270818923; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 9.70929249888286e-06 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.84
Batch: 20; loss: 0.34; acc: 0.86
Batch: 40; loss: 0.46; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.15; acc: 0.94
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.13; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.44; acc: 0.86
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.42; acc: 0.91
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.37; acc: 0.83
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.58; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.217094126739539e-05
1.0094720892084297e-05
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.41; acc: 0.86
Batch: 120; loss: 0.89; acc: 0.77
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.3110243959981165; val_accuracy: 0.9027667197452229 

The current subspace-distance is: 1.0094720892084297e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.5; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.49; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.36; acc: 0.88
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.53; acc: 0.83
Batch: 260; loss: 0.34; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.98
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.5; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.91
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.45; acc: 0.88
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.51; acc: 0.84
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.31; acc: 0.95
Batch: 780; loss: 0.35; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.1545248930342495e-05
1.0132547686225735e-05
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.26469296307130985; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 1.0132547686225735e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.29; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.37; acc: 0.88
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.14; acc: 0.97
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.38; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.55; acc: 0.88
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.91
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.44; acc: 0.84
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.39; acc: 0.89
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.97
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.38; acc: 0.86
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.193106022081338e-05
9.642677468946204e-06
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.3; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.41; acc: 0.83
Batch: 120; loss: 0.86; acc: 0.78
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.2842017989724305; val_accuracy: 0.9132165605095541 

The current subspace-distance is: 9.642677468946204e-06 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.34; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.49; acc: 0.86
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.32; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.94
Batch: 560; loss: 0.26; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.84
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.33; acc: 0.92
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.201845538569614e-05
9.794404832064174e-06
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.86
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.26343780476006734; val_accuracy: 0.9200835987261147 

The current subspace-distance is: 9.794404832064174e-06 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.38; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.45; acc: 0.88
Batch: 200; loss: 0.43; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.17; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.7; acc: 0.78
Batch: 480; loss: 0.38; acc: 0.92
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.22; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.37; acc: 0.89
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.38; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.4; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.123253918602131e-05
1.0457443750055972e-05
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.63; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2635252880537586; val_accuracy: 0.9183917197452229 

The current subspace-distance is: 1.0457443750055972e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.23; acc: 0.97
Batch: 240; loss: 0.46; acc: 0.83
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.43; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.91
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.88
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.92
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.27; acc: 0.94
Batch: 680; loss: 0.62; acc: 0.86
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.188722621416673e-05
9.55538507696474e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.06; acc: 1.0
Val Epoch over. val_loss: 0.2610810198791467; val_accuracy: 0.9208797770700637 

The current subspace-distance is: 9.55538507696474e-06 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.92
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.3; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.91
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.42; acc: 0.86
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.23; acc: 0.91
Batch: 700; loss: 0.39; acc: 0.94
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.86
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.52; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.1469095119973645e-05
9.554337339068297e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2592537062373131; val_accuracy: 0.919984076433121 

The current subspace-distance is: 9.554337339068297e-06 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.84
Batch: 20; loss: 0.39; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.46; acc: 0.84
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.89
Batch: 240; loss: 0.29; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.2; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.91
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.59; acc: 0.89
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.13; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.91
Batch: 700; loss: 0.29; acc: 0.88
Batch: 720; loss: 0.33; acc: 0.88
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.15872639475856e-05
9.4911383712315e-06
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.75; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.26436412415117216; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 9.4911383712315e-06 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.41; acc: 0.89
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.47; acc: 0.86
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.31; acc: 0.95
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.3; acc: 0.95
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.48; acc: 0.81
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.25; acc: 0.88
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.37; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.181079955538735e-05
9.169341865344904e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.263864119341419; val_accuracy: 0.9195859872611465 

The current subspace-distance is: 9.169341865344904e-06 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.41; acc: 0.91
Batch: 240; loss: 0.19; acc: 0.97
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.34; acc: 0.88
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.39; acc: 0.89
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.58; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.89
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.43; acc: 0.91
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.42; acc: 0.88
Batch: 640; loss: 0.49; acc: 0.88
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.4; acc: 0.83
Batch: 720; loss: 0.28; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.129261313006282e-05
8.736994459468406e-06
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25968086781205646; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 8.736994459468406e-06 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.25; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.89
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.88
Batch: 160; loss: 0.34; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.89
Batch: 200; loss: 0.21; acc: 0.89
Batch: 220; loss: 0.17; acc: 0.97
Batch: 240; loss: 0.31; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.31; acc: 0.88
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.11; acc: 0.98
Batch: 700; loss: 0.29; acc: 0.95
Batch: 720; loss: 0.29; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.21103107125964e-05
1.0234944056719542e-05
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.2632893684088804; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 1.0234944056719542e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.38; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.11; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.89
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.84
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.84
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.2; acc: 0.89
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.18; acc: 0.91
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.136319719487801e-05
9.90838907455327e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.36; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.2591535677291026; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 9.90838907455327e-06 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.94
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.53; acc: 0.84
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.13; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.47; acc: 0.91
Batch: 440; loss: 0.43; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.18; acc: 0.94
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.86
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.92
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.1815932743484154e-05
9.41449252422899e-06
Batch: 0; loss: 0.31; acc: 0.89
Batch: 20; loss: 0.34; acc: 0.91
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.83
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2628322457716723; val_accuracy: 0.9202826433121019 

The current subspace-distance is: 9.41449252422899e-06 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.98
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.46; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.95
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.89
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.86
Batch: 520; loss: 0.18; acc: 0.97
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.36; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.25; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.192216536263004e-05
9.370810403197538e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2613444248107588; val_accuracy: 0.9197850318471338 

The current subspace-distance is: 9.370810403197538e-06 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.91
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.46; acc: 0.89
Batch: 200; loss: 0.23; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.89
Batch: 360; loss: 0.29; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.92
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.88
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.42; acc: 0.88
Batch: 660; loss: 0.41; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.34; acc: 0.88
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.191320502082817e-05
9.214141755364835e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2572889787376307; val_accuracy: 0.9214769108280255 

The current subspace-distance is: 9.214141755364835e-06 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.46; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.39; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.95
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.89
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.38; acc: 0.89
Batch: 300; loss: 0.27; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.19; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.26; acc: 0.95
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.49; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.43; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.4; acc: 0.91
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.22; acc: 0.91
Batch: 780; loss: 0.34; acc: 0.86
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

3.213160380255431e-05
9.811670679482631e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.83
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2588071675057624; val_accuracy: 0.9198845541401274 

The current subspace-distance is: 9.811670679482631e-06 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.34; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.56; acc: 0.88
Batch: 180; loss: 0.31; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.37; acc: 0.88
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.41; acc: 0.91
Batch: 400; loss: 0.3; acc: 0.92
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.89
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.48; acc: 0.91
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.34; acc: 0.88
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.17; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.194563032593578e-05
9.608209438738413e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.68; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2595432776554375; val_accuracy: 0.92078025477707 

The current subspace-distance is: 9.608209438738413e-06 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.28; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.33; acc: 0.89
Batch: 240; loss: 0.4; acc: 0.88
Batch: 260; loss: 0.31; acc: 0.89
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.92
Batch: 360; loss: 0.43; acc: 0.91
Batch: 380; loss: 0.42; acc: 0.83
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.89
Batch: 440; loss: 0.4; acc: 0.92
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.56; acc: 0.84
Batch: 580; loss: 0.24; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.39; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.89
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.38; acc: 0.88
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

3.1821473385207355e-05
9.68938365986105e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.37; acc: 0.86
Batch: 120; loss: 0.7; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2569259351036351; val_accuracy: 0.921875 

The current subspace-distance is: 9.68938365986105e-06 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.84
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.84
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.2; acc: 0.94
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.41; acc: 0.89
Batch: 300; loss: 0.28; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.92
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.11; acc: 0.98
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.3; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.38; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.92
Batch: 700; loss: 0.47; acc: 0.89
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.06; acc: 1.0
Batch: 760; loss: 0.09; acc: 1.0
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

3.213447780581191e-05
9.369370673084632e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2580540528532806; val_accuracy: 0.9211783439490446 

The current subspace-distance is: 9.369370673084632e-06 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.2; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.45; acc: 0.91
Batch: 380; loss: 0.36; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.84
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.41; acc: 0.92
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.167618706356734e-05
9.09992650122149e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25793917173412956; val_accuracy: 0.9222730891719745 

The current subspace-distance is: 9.09992650122149e-06 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.33; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.91
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.3; acc: 0.88
Batch: 200; loss: 0.25; acc: 0.94
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.49; acc: 0.89
Batch: 280; loss: 0.26; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.29; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.07; acc: 1.0
Batch: 420; loss: 0.21; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.97
Batch: 500; loss: 0.29; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.88
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

3.112456761300564e-05
8.558628906030208e-06
Batch: 0; loss: 0.28; acc: 0.89
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25839900937239835; val_accuracy: 0.9205812101910829 

The current subspace-distance is: 8.558628906030208e-06 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.5; acc: 0.89
Batch: 180; loss: 0.32; acc: 0.92
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.4; acc: 0.84
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.92
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.37; acc: 0.94
Batch: 360; loss: 0.37; acc: 0.84
Batch: 380; loss: 0.34; acc: 0.91
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.95
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.84
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.19; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.31; acc: 0.88
Batch: 720; loss: 0.25; acc: 0.91
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.283261685282923e-05
9.917052921082359e-06
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.7; acc: 0.78
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25814446674031055; val_accuracy: 0.9206807324840764 

The current subspace-distance is: 9.917052921082359e-06 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.39; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.33; acc: 0.92
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.35; acc: 0.89
Batch: 240; loss: 0.38; acc: 0.86
Batch: 260; loss: 0.3; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.89
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.92
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.3; acc: 0.88
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.39; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.98
Batch: 600; loss: 0.39; acc: 0.95
Batch: 620; loss: 0.21; acc: 0.92
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.91
Batch: 680; loss: 0.43; acc: 0.81
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.53; acc: 0.84
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

3.2147756428457797e-05
9.881230653263628e-06
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.25720913352290536; val_accuracy: 0.9215764331210191 

The current subspace-distance is: 9.881230653263628e-06 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.84
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.33; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.06; acc: 1.0
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.41; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.14; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.88
Batch: 480; loss: 0.52; acc: 0.8
Batch: 500; loss: 0.28; acc: 0.94
Batch: 520; loss: 0.34; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.12; acc: 0.97
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.95
Batch: 680; loss: 0.52; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.16; acc: 0.91
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.91
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

3.2277388527290896e-05
9.514281373412814e-06
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.3; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.84
Batch: 120; loss: 0.69; acc: 0.77
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2575213859320446; val_accuracy: 0.92078025477707 

The current subspace-distance is: 9.514281373412814e-06 

plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 83366
elements in E: 17580800
fraction nonzero: 0.004741877502730251
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.37; acc: 0.17
Batch: 20; loss: 2.2; acc: 0.33
Batch: 40; loss: 2.19; acc: 0.25
Batch: 60; loss: 2.14; acc: 0.33
Batch: 80; loss: 2.03; acc: 0.41
Batch: 100; loss: 2.1; acc: 0.28
Batch: 120; loss: 1.91; acc: 0.36
Batch: 140; loss: 1.68; acc: 0.5
Batch: 160; loss: 1.57; acc: 0.5
Batch: 180; loss: 1.4; acc: 0.58
Batch: 200; loss: 1.42; acc: 0.5
Batch: 220; loss: 1.42; acc: 0.55
Batch: 240; loss: 1.28; acc: 0.52
Batch: 260; loss: 1.14; acc: 0.64
Batch: 280; loss: 0.93; acc: 0.73
Batch: 300; loss: 0.87; acc: 0.77
Batch: 320; loss: 0.87; acc: 0.73
Batch: 340; loss: 0.88; acc: 0.75
Batch: 360; loss: 0.71; acc: 0.75
Batch: 380; loss: 0.99; acc: 0.59
Batch: 400; loss: 0.86; acc: 0.7
Batch: 420; loss: 0.63; acc: 0.8
Batch: 440; loss: 0.68; acc: 0.78
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.84
Batch: 500; loss: 0.54; acc: 0.86
Batch: 520; loss: 0.56; acc: 0.8
Batch: 540; loss: 0.71; acc: 0.7
Batch: 560; loss: 0.78; acc: 0.78
Batch: 580; loss: 0.64; acc: 0.78
Batch: 600; loss: 0.57; acc: 0.86
Batch: 620; loss: 0.61; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.83
Batch: 660; loss: 0.66; acc: 0.78
Batch: 680; loss: 0.56; acc: 0.78
Batch: 700; loss: 0.74; acc: 0.81
Batch: 720; loss: 0.85; acc: 0.75
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.46; acc: 0.88
Batch: 780; loss: 0.85; acc: 0.75
Train Epoch over. train_loss: 1.09; train_accuracy: 0.65 

2.0319828763604164e-05
8.371941476070788e-06
Batch: 0; loss: 1.89; acc: 0.44
Batch: 20; loss: 2.5; acc: 0.47
Batch: 40; loss: 2.07; acc: 0.47
Batch: 60; loss: 2.19; acc: 0.5
Batch: 80; loss: 1.97; acc: 0.53
Batch: 100; loss: 1.89; acc: 0.5
Batch: 120; loss: 2.6; acc: 0.5
Batch: 140; loss: 2.3; acc: 0.56
Val Epoch over. val_loss: 2.167250629443272; val_accuracy: 0.47671178343949044 

The current subspace-distance is: 8.371941476070788e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.88; acc: 0.48
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.62; acc: 0.81
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.65; acc: 0.78
Batch: 140; loss: 0.57; acc: 0.8
Batch: 160; loss: 0.61; acc: 0.75
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.65; acc: 0.75
Batch: 240; loss: 0.35; acc: 0.86
Batch: 260; loss: 0.67; acc: 0.75
Batch: 280; loss: 0.68; acc: 0.83
Batch: 300; loss: 0.27; acc: 0.95
Batch: 320; loss: 0.59; acc: 0.86
Batch: 340; loss: 0.46; acc: 0.8
Batch: 360; loss: 0.45; acc: 0.8
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.86
Batch: 440; loss: 0.33; acc: 0.83
Batch: 460; loss: 0.33; acc: 0.89
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.34; acc: 0.92
Batch: 560; loss: 0.42; acc: 0.88
Batch: 580; loss: 0.53; acc: 0.86
Batch: 600; loss: 0.38; acc: 0.91
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.54; acc: 0.81
Batch: 680; loss: 0.34; acc: 0.84
Batch: 700; loss: 0.31; acc: 0.94
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.41; acc: 0.88
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.76; acc: 0.77
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

2.5509874831186607e-05
9.825846063904464e-06
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.51; acc: 0.81
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.69; acc: 0.81
Batch: 140; loss: 0.16; acc: 0.94
Val Epoch over. val_loss: 0.3797109722142007; val_accuracy: 0.8805732484076433 

The current subspace-distance is: 9.825846063904464e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.09; acc: 1.0
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.94
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.84
Batch: 280; loss: 0.43; acc: 0.86
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.35; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.88
Batch: 360; loss: 0.47; acc: 0.91
Batch: 380; loss: 0.61; acc: 0.83
Batch: 400; loss: 0.67; acc: 0.8
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.37; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.52; acc: 0.78
Batch: 600; loss: 0.64; acc: 0.81
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.29; acc: 0.92
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.48; acc: 0.81
Batch: 740; loss: 0.45; acc: 0.86
Batch: 760; loss: 0.3; acc: 0.92
Batch: 780; loss: 0.29; acc: 0.91
Train Epoch over. train_loss: 0.37; train_accuracy: 0.88 

2.7268441044725478e-05
1.1193207683390938e-05
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.05; acc: 1.0
Val Epoch over. val_loss: 0.3049512515497056; val_accuracy: 0.9010748407643312 

The current subspace-distance is: 1.1193207683390938e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.39; acc: 0.84
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.41; acc: 0.91
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.72; acc: 0.78
Batch: 100; loss: 0.36; acc: 0.86
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.31; acc: 0.86
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.27; acc: 0.86
Batch: 280; loss: 0.5; acc: 0.89
Batch: 300; loss: 0.47; acc: 0.91
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.27; acc: 0.86
Batch: 360; loss: 0.45; acc: 0.83
Batch: 380; loss: 0.47; acc: 0.81
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.35; acc: 0.89
Batch: 460; loss: 0.71; acc: 0.75
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.4; acc: 0.88
Batch: 520; loss: 0.12; acc: 0.97
Batch: 540; loss: 0.44; acc: 0.92
Batch: 560; loss: 0.47; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.89
Batch: 600; loss: 0.57; acc: 0.88
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.98
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.97
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

2.825947194651235e-05
1.0358069630456157e-05
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.81
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.3674017092224899; val_accuracy: 0.8827627388535032 

The current subspace-distance is: 1.0358069630456157e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.86
Batch: 20; loss: 0.39; acc: 0.88
Batch: 40; loss: 0.46; acc: 0.86
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.94
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.38; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.39; acc: 0.86
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.3; acc: 0.86
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.4; acc: 0.89
Batch: 300; loss: 0.35; acc: 0.83
Batch: 320; loss: 0.29; acc: 0.88
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.97
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.3; acc: 0.88
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.36; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.88
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.35; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.41; acc: 0.88
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.15; acc: 0.98
Batch: 660; loss: 0.24; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.51; acc: 0.86
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

2.9306775104487315e-05
1.1466219802969135e-05
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.39; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.81
Batch: 100; loss: 0.39; acc: 0.88
Batch: 120; loss: 1.0; acc: 0.72
Batch: 140; loss: 0.07; acc: 1.0
Val Epoch over. val_loss: 0.37183575199288166; val_accuracy: 0.8796775477707006 

The current subspace-distance is: 1.1466219802969135e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.83
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.86
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.94
Batch: 200; loss: 0.54; acc: 0.86
Batch: 220; loss: 0.22; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.4; acc: 0.84
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.43; acc: 0.88
Batch: 380; loss: 0.29; acc: 0.91
Batch: 400; loss: 0.33; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.58; acc: 0.86
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.33; acc: 0.92
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.38; acc: 0.88
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.46; acc: 0.83
Batch: 700; loss: 0.38; acc: 0.92
Batch: 720; loss: 0.36; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.88
Train Epoch over. train_loss: 0.31; train_accuracy: 0.91 

2.9348120733629912e-05
1.0754854883998632e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.27522533472366395; val_accuracy: 0.916202229299363 

The current subspace-distance is: 1.0754854883998632e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.35; acc: 0.86
Batch: 60; loss: 0.37; acc: 0.86
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.57; acc: 0.88
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.41; acc: 0.86
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.91
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.33; acc: 0.91
Batch: 360; loss: 0.29; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.53; acc: 0.84
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.91
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.41; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.32; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.31; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

3.0041099307709374e-05
1.1591122529353015e-05
Batch: 0; loss: 0.5; acc: 0.83
Batch: 20; loss: 0.77; acc: 0.83
Batch: 40; loss: 0.41; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.81
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.66; acc: 0.84
Batch: 120; loss: 1.12; acc: 0.75
Batch: 140; loss: 0.29; acc: 0.89
Val Epoch over. val_loss: 0.637459494695542; val_accuracy: 0.8126990445859873 

The current subspace-distance is: 1.1591122529353015e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.83
Batch: 20; loss: 0.14; acc: 0.98
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.34; acc: 0.89
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.91
Batch: 260; loss: 0.43; acc: 0.86
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.36; acc: 0.92
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.86
Batch: 400; loss: 0.27; acc: 0.86
Batch: 420; loss: 0.18; acc: 0.92
Batch: 440; loss: 0.28; acc: 0.91
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.46; acc: 0.91
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.86
Batch: 560; loss: 0.21; acc: 0.91
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.19; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.47; acc: 0.84
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.0485727620543912e-05
1.1301751328574028e-05
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.91
Batch: 100; loss: 0.4; acc: 0.95
Batch: 120; loss: 0.71; acc: 0.77
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24350654215190062; val_accuracy: 0.9249601910828026 

The current subspace-distance is: 1.1301751328574028e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.39; acc: 0.84
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.31; acc: 0.94
Batch: 140; loss: 0.22; acc: 0.97
Batch: 160; loss: 0.34; acc: 0.92
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.19; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.57; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.53; acc: 0.91
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.39; acc: 0.84
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.52; acc: 0.81
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.94
Batch: 620; loss: 0.46; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.23; acc: 0.89
Batch: 740; loss: 0.58; acc: 0.84
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.18; acc: 0.91
Train Epoch over. train_loss: 0.29; train_accuracy: 0.91 

3.054038461414166e-05
1.1832985364890192e-05
Batch: 0; loss: 0.36; acc: 0.94
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.30988060519289057; val_accuracy: 0.9047571656050956 

The current subspace-distance is: 1.1832985364890192e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.43; acc: 0.89
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.33; acc: 0.86
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.39; acc: 0.83
Batch: 100; loss: 0.13; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.48; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.37; acc: 0.92
Batch: 260; loss: 0.19; acc: 0.91
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.2; acc: 0.95
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.35; acc: 0.92
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.59; acc: 0.83
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.44; acc: 0.89
Batch: 600; loss: 0.11; acc: 0.98
Batch: 620; loss: 0.46; acc: 0.86
Batch: 640; loss: 0.32; acc: 0.92
Batch: 660; loss: 0.27; acc: 0.92
Batch: 680; loss: 0.3; acc: 0.94
Batch: 700; loss: 0.33; acc: 0.94
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

3.0670005799038336e-05
1.186860663437983e-05
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.32; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.15; acc: 0.94
Val Epoch over. val_loss: 0.3001256197880787; val_accuracy: 0.9057523885350318 

The current subspace-distance is: 1.186860663437983e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.86
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.59; acc: 0.81
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.24; acc: 0.92
Batch: 720; loss: 0.23; acc: 0.94
Batch: 740; loss: 0.31; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.26; acc: 0.92
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.154785736114718e-05
1.1700840332196094e-05
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.21722834524075696; val_accuracy: 0.9327229299363057 

The current subspace-distance is: 1.1700840332196094e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.32; acc: 0.91
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.11; acc: 0.98
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.4; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.32; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.31; acc: 0.88
Batch: 520; loss: 0.29; acc: 0.91
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.21; acc: 0.89
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.1470397516386583e-05
1.2002229595964309e-05
Batch: 0; loss: 0.29; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.8
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24232317025589337; val_accuracy: 0.9252587579617835 

The current subspace-distance is: 1.2002229595964309e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.91
Batch: 140; loss: 0.22; acc: 0.89
Batch: 160; loss: 0.15; acc: 0.98
Batch: 180; loss: 0.24; acc: 0.95
Batch: 200; loss: 0.24; acc: 0.95
Batch: 220; loss: 0.24; acc: 0.94
Batch: 240; loss: 0.4; acc: 0.84
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.17; acc: 0.97
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.89
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.91
Batch: 760; loss: 0.24; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.1617837521480396e-05
1.2236689144629054e-05
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.92
Batch: 120; loss: 0.55; acc: 0.84
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2064019027551648; val_accuracy: 0.9371019108280255 

The current subspace-distance is: 1.2236689144629054e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.23; acc: 0.95
Batch: 20; loss: 0.37; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.94
Batch: 140; loss: 0.32; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.94
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.39; acc: 0.89
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.4; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.89
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.31; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.89
Batch: 500; loss: 0.2; acc: 0.95
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.98
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.98
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.188054688507691e-05
1.24124117064639e-05
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.89
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.8
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.23707083672000345; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 1.24124117064639e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.3; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.47; acc: 0.83
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.22; acc: 0.97
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.95
Batch: 540; loss: 0.34; acc: 0.89
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.18; acc: 0.92
Batch: 600; loss: 0.12; acc: 0.94
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.29; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.97
Batch: 700; loss: 0.31; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.22; acc: 0.95
Batch: 760; loss: 0.45; acc: 0.89
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.205566099495627e-05
1.183867880172329e-05
Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.81
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.49; acc: 0.91
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.55; acc: 0.84
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.34131861326231316; val_accuracy: 0.8957006369426752 

The current subspace-distance is: 1.183867880172329e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.56; acc: 0.88
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.16; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.23; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.98
Batch: 500; loss: 0.2; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.24; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.37; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.23; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.91
Batch: 760; loss: 0.12; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.172903598169796e-05
1.2731545211863704e-05
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.71; acc: 0.81
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.22078475617109591; val_accuracy: 0.9316281847133758 

The current subspace-distance is: 1.2731545211863704e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.46; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.94
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.48; acc: 0.88
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.98
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.200231003575027e-05
1.3009150279685855e-05
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.31; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.47; acc: 0.86
Batch: 120; loss: 0.56; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.23222800904208687; val_accuracy: 0.9286425159235668 

The current subspace-distance is: 1.3009150279685855e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.17; acc: 0.98
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.44; acc: 0.89
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.2; acc: 0.91
Batch: 240; loss: 0.24; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.44; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.91
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.95
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.37; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.37; acc: 0.86
Batch: 720; loss: 0.3; acc: 0.91
Batch: 740; loss: 0.28; acc: 0.95
Batch: 760; loss: 0.11; acc: 0.98
Batch: 780; loss: 0.34; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.19052160193678e-05
1.2023768249491695e-05
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.20942530292234604; val_accuracy: 0.9346138535031847 

The current subspace-distance is: 1.2023768249491695e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.41; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.97
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.91
Batch: 440; loss: 0.28; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.44; acc: 0.88
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.23; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.24; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.88
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.169583578710444e-05
1.1902184269274585e-05
Batch: 0; loss: 0.26; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.89
Batch: 120; loss: 0.67; acc: 0.81
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.27101042503669004; val_accuracy: 0.9176950636942676 

The current subspace-distance is: 1.1902184269274585e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.51; acc: 0.86
Batch: 20; loss: 0.06; acc: 0.98
Batch: 40; loss: 0.22; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.92
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.17; acc: 0.97
Batch: 140; loss: 0.26; acc: 0.89
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.33; acc: 0.84
Batch: 200; loss: 0.25; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.88
Batch: 240; loss: 0.12; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.26; acc: 0.92
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.46; acc: 0.88
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.32; acc: 0.97
Batch: 400; loss: 0.11; acc: 1.0
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.27; acc: 0.88
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.11; acc: 0.98
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.08; acc: 0.98
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

3.239605575799942e-05
1.2697513739112765e-05
Batch: 0; loss: 0.33; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.35; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.65; acc: 0.83
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.24571370703589385; val_accuracy: 0.9246616242038217 

The current subspace-distance is: 1.2697513739112765e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.13; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.41; acc: 0.86
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.94
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.3; acc: 0.89
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.241417289245874e-05
1.3392759683483746e-05
Batch: 0; loss: 0.19; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19220514398566477; val_accuracy: 0.9413813694267515 

The current subspace-distance is: 1.3392759683483746e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.08; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.36; acc: 0.88
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.17; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.89
Batch: 180; loss: 0.21; acc: 0.94
Batch: 200; loss: 0.24; acc: 0.92
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.95
Batch: 260; loss: 0.19; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.94
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.21; acc: 0.91
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.21; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.39; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.29; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.37; acc: 0.84
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.34; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.219622158212587e-05
1.2234897440066561e-05
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19656027174869162; val_accuracy: 0.9382961783439491 

The current subspace-distance is: 1.2234897440066561e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.34; acc: 0.88
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.24; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.25; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.07; acc: 1.0
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.09; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.25; acc: 0.97
Batch: 700; loss: 0.24; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.38; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.271814784966409e-05
1.2040717592753936e-05
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.89
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19806589115007667; val_accuracy: 0.9380971337579618 

The current subspace-distance is: 1.2040717592753936e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.46; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.45; acc: 0.91
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.12; acc: 0.98
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.1; acc: 0.98
Batch: 380; loss: 0.27; acc: 0.94
Batch: 400; loss: 0.04; acc: 1.0
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.98
Batch: 500; loss: 0.26; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.36; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.47; acc: 0.88
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.27; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.29; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.30756556650158e-05
1.3760045476374216e-05
Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19677947414149144; val_accuracy: 0.939390923566879 

The current subspace-distance is: 1.3760045476374216e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.28; acc: 0.91
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.21; acc: 0.97
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.89
Batch: 440; loss: 0.2; acc: 0.95
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.32; acc: 0.88
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.92
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.11; acc: 0.94
Batch: 720; loss: 0.45; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.91
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.2571249903412536e-05
1.2283001524338033e-05
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.46; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19496598737729584; val_accuracy: 0.9402866242038217 

The current subspace-distance is: 1.2283001524338033e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.51; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.09; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.88
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.89
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.11; acc: 0.97
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.91
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.24; acc: 0.89
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.92
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.243976243538782e-05
1.2409146620484535e-05
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1945997966560209; val_accuracy: 0.9400875796178344 

The current subspace-distance is: 1.2409146620484535e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.1; acc: 0.98
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.92
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.98
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.92
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.26; acc: 0.94
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.35; acc: 0.86
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.13; acc: 0.97
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.28; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.303796620457433e-05
1.3237922757980414e-05
Batch: 0; loss: 0.18; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.45; acc: 0.92
Batch: 120; loss: 0.67; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19712776844953275; val_accuracy: 0.9406847133757962 

The current subspace-distance is: 1.3237922757980414e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.59; acc: 0.89
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.3; acc: 0.91
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.16; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.91
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.32; acc: 0.89
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.28; acc: 0.95
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.34; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.293798727099784e-05
1.2188585060357582e-05
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.83
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.1982012082864145; val_accuracy: 0.9406847133757962 

The current subspace-distance is: 1.2188585060357582e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.26; acc: 0.91
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.12; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.17; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.95
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.31; acc: 0.86
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.91
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.27; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.94
Batch: 560; loss: 0.12; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.51; acc: 0.88
Batch: 760; loss: 0.31; acc: 0.91
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.258547076256946e-05
1.2348835298325866e-05
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19807592705841276; val_accuracy: 0.9400875796178344 

The current subspace-distance is: 1.2348835298325866e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.03; acc: 1.0
Batch: 300; loss: 0.25; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.28; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.3; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.91
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.11; acc: 0.95
Batch: 540; loss: 0.23; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.24; acc: 0.92
Batch: 740; loss: 0.34; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

3.2559732062509283e-05
1.2829086699639447e-05
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.95
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19767867292093624; val_accuracy: 0.9395899681528662 

The current subspace-distance is: 1.2829086699639447e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.09; acc: 0.97
Batch: 180; loss: 0.35; acc: 0.91
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.06; acc: 1.0
Batch: 260; loss: 0.17; acc: 0.97
Batch: 280; loss: 0.06; acc: 1.0
Batch: 300; loss: 0.24; acc: 0.95
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.16; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.89
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.67; acc: 0.83
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.95
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.32; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.21; acc: 0.95
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.3; acc: 0.95
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.2433650630991906e-05
1.30034795802203e-05
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19344096509799077; val_accuracy: 0.9422770700636943 

The current subspace-distance is: 1.30034795802203e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.1; acc: 0.98
Batch: 120; loss: 0.21; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.88
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.89
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.15; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.38; acc: 0.89
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.48; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.89
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.89
Batch: 580; loss: 0.27; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.44; acc: 0.88
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.295569695183076e-05
1.3198738088249229e-05
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19054715162154975; val_accuracy: 0.9434713375796179 

The current subspace-distance is: 1.3198738088249229e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.25; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.89
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.21; acc: 0.89
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.39; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.24; acc: 0.92
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.15; acc: 0.95
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.88
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.277187715866603e-05
1.3045695595792495e-05
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19169194794669273; val_accuracy: 0.9410828025477707 

The current subspace-distance is: 1.3045695595792495e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.95
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.33; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.88
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.08; acc: 0.98
Batch: 600; loss: 0.44; acc: 0.91
Batch: 620; loss: 0.12; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.06; acc: 1.0
Batch: 680; loss: 0.13; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.89
Batch: 720; loss: 0.1; acc: 0.98
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.311744876555167e-05
1.1934709618799388e-05
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19136171621881473; val_accuracy: 0.9422770700636943 

The current subspace-distance is: 1.1934709618799388e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.22; acc: 0.91
Batch: 20; loss: 0.07; acc: 1.0
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.06; acc: 1.0
Batch: 140; loss: 0.09; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.94
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.05; acc: 1.0
Batch: 240; loss: 0.32; acc: 0.94
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.28; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.31; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.21; acc: 0.94
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.35; acc: 0.88
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.07; acc: 1.0
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.3; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.267067950218916e-05
1.300969688600162e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.43; acc: 0.92
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1909510973057929; val_accuracy: 0.9427746815286624 

The current subspace-distance is: 1.300969688600162e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.13; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.08; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.23; acc: 0.88
Batch: 480; loss: 0.38; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.35; acc: 0.91
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.26; acc: 0.94
Batch: 640; loss: 0.46; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.92
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.338747410452925e-05
1.3087731531413738e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1883015297115988; val_accuracy: 0.9432722929936306 

The current subspace-distance is: 1.3087731531413738e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.33; acc: 0.91
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.23; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.89
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.14; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.280301461927593e-05
1.3130769730196334e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19047090178652173; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 1.3130769730196334e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.92
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.1; acc: 0.98
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.91
Batch: 400; loss: 0.37; acc: 0.91
Batch: 420; loss: 0.38; acc: 0.88
Batch: 440; loss: 0.38; acc: 0.89
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.28; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.31; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.94
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.317723167128861e-05
1.2917349522467703e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19021934052561498; val_accuracy: 0.9430732484076433 

The current subspace-distance is: 1.2917349522467703e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.34; acc: 0.89
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.56; acc: 0.81
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.25; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.32; acc: 0.91
Batch: 460; loss: 0.14; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.22; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.22; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.06; acc: 1.0
Batch: 620; loss: 0.21; acc: 0.94
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.06; acc: 0.98
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.16; acc: 0.98
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.310929605504498e-05
1.4133924196357839e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19195696372230342; val_accuracy: 0.9428742038216561 

The current subspace-distance is: 1.4133924196357839e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.19; acc: 0.91
Batch: 140; loss: 0.25; acc: 0.89
Batch: 160; loss: 0.07; acc: 0.98
Batch: 180; loss: 0.23; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.16; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.89
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.91
Batch: 500; loss: 0.28; acc: 0.92
Batch: 520; loss: 0.24; acc: 0.95
Batch: 540; loss: 0.34; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.38; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.97
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.301057586213574e-05
1.2798630450561177e-05
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.19022466453492262; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 1.2798630450561177e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.94
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.4; acc: 0.94
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.95
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.19; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.22; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.33; acc: 0.92
Batch: 660; loss: 0.4; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.33; acc: 0.89
Batch: 720; loss: 0.17; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.98
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.262038080720231e-05
1.2408813745423686e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18931375780872478; val_accuracy: 0.9434713375796179 

The current subspace-distance is: 1.2408813745423686e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.89
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.33; acc: 0.89
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.36; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.29; acc: 0.94
Batch: 480; loss: 0.37; acc: 0.88
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.92
Batch: 560; loss: 0.34; acc: 0.89
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.348054815432988e-05
1.3348540960578248e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18880083148551594; val_accuracy: 0.9435708598726115 

The current subspace-distance is: 1.3348540960578248e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.95
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.91
Batch: 180; loss: 0.19; acc: 0.92
Batch: 200; loss: 0.32; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.95
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.23; acc: 0.92
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.34; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.92
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.2694362744223326e-05
1.2398337275953963e-05
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18783233253059872; val_accuracy: 0.9436703821656051 

The current subspace-distance is: 1.2398337275953963e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.98
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.12; acc: 0.95
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.13; acc: 0.97
Batch: 300; loss: 0.02; acc: 1.0
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.29; acc: 0.95
Batch: 380; loss: 0.65; acc: 0.81
Batch: 400; loss: 0.12; acc: 0.98
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.45; acc: 0.91
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.12; acc: 0.98
Batch: 660; loss: 0.17; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.28; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.242521415813826e-05
1.248461012437474e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18802138415586417; val_accuracy: 0.9433718152866242 

The current subspace-distance is: 1.248461012437474e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.94
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.23; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.09; acc: 0.98
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.92
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.08; acc: 1.0
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.98
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.4; acc: 0.89
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.02; acc: 1.0
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.255012052250095e-05
1.3108045095577836e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.63; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18782002504938727; val_accuracy: 0.9434713375796179 

The current subspace-distance is: 1.3108045095577836e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.08; acc: 0.98
Batch: 340; loss: 0.3; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.86
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.38; acc: 0.88
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.97
Batch: 560; loss: 0.07; acc: 0.98
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.94
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.281079261796549e-05
1.2473022252379451e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.62; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18815688765162875; val_accuracy: 0.9433718152866242 

The current subspace-distance is: 1.2473022252379451e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.27; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.4; acc: 0.86
Batch: 200; loss: 0.12; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.95
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.18; acc: 0.94
Batch: 340; loss: 0.13; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.89
Batch: 480; loss: 0.1; acc: 0.97
Batch: 500; loss: 0.23; acc: 0.97
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.16; acc: 0.92
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.27; acc: 0.84
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.277946962043643e-05
1.2554258319141809e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1893791154881192; val_accuracy: 0.9441679936305732 

The current subspace-distance is: 1.2554258319141809e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.86
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.39; acc: 0.86
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.32; acc: 0.84
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.11; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.88
Batch: 580; loss: 0.1; acc: 0.95
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.2591942726867273e-05
1.2204236554680392e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.6; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1880293641073309; val_accuracy: 0.9440684713375797 

The current subspace-distance is: 1.2204236554680392e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.22; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.22; acc: 0.95
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.1; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.89
Batch: 480; loss: 0.14; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.14; acc: 0.97
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.97
Batch: 680; loss: 0.35; acc: 0.88
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.2964257115963846e-05
1.3060743185633328e-05
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.4; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18805006473876867; val_accuracy: 0.9444665605095541 

The current subspace-distance is: 1.3060743185633328e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.95
Batch: 120; loss: 0.09; acc: 0.97
Batch: 140; loss: 0.25; acc: 0.94
Batch: 160; loss: 0.06; acc: 1.0
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.07; acc: 0.98
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.91
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.06; acc: 1.0
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.3; acc: 0.89
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.23; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.91
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.238907447666861e-05
1.3215761100582313e-05
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.41; acc: 0.92
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1885089009857861; val_accuracy: 0.9437699044585988 

The current subspace-distance is: 1.3215761100582313e-05 

plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
nonzero elements in E: 104941
elements in E: 21976000
fraction nonzero: 0.004775254823443757
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.37; acc: 0.17
Batch: 20; loss: 2.18; acc: 0.36
Batch: 40; loss: 2.16; acc: 0.25
Batch: 60; loss: 2.05; acc: 0.36
Batch: 80; loss: 1.88; acc: 0.44
Batch: 100; loss: 1.97; acc: 0.25
Batch: 120; loss: 1.77; acc: 0.34
Batch: 140; loss: 1.56; acc: 0.41
Batch: 160; loss: 1.45; acc: 0.52
Batch: 180; loss: 1.24; acc: 0.62
Batch: 200; loss: 1.36; acc: 0.56
Batch: 220; loss: 1.34; acc: 0.52
Batch: 240; loss: 1.32; acc: 0.56
Batch: 260; loss: 1.24; acc: 0.61
Batch: 280; loss: 1.04; acc: 0.69
Batch: 300; loss: 0.87; acc: 0.81
Batch: 320; loss: 0.85; acc: 0.75
Batch: 340; loss: 0.88; acc: 0.75
Batch: 360; loss: 0.8; acc: 0.77
Batch: 380; loss: 0.89; acc: 0.69
Batch: 400; loss: 0.88; acc: 0.73
Batch: 420; loss: 0.56; acc: 0.8
Batch: 440; loss: 0.67; acc: 0.8
Batch: 460; loss: 0.74; acc: 0.83
Batch: 480; loss: 0.53; acc: 0.8
Batch: 500; loss: 0.55; acc: 0.83
Batch: 520; loss: 0.75; acc: 0.72
Batch: 540; loss: 0.52; acc: 0.88
Batch: 560; loss: 0.75; acc: 0.8
Batch: 580; loss: 1.18; acc: 0.64
Batch: 600; loss: 0.46; acc: 0.86
Batch: 620; loss: 0.82; acc: 0.77
Batch: 640; loss: 0.53; acc: 0.84
Batch: 660; loss: 0.98; acc: 0.77
Batch: 680; loss: 0.53; acc: 0.86
Batch: 700; loss: 0.93; acc: 0.77
Batch: 720; loss: 0.84; acc: 0.78
Batch: 740; loss: 0.45; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.57; acc: 0.81
Train Epoch over. train_loss: 1.07; train_accuracy: 0.65 

2.037670128629543e-05
8.203732249967288e-06
Batch: 0; loss: 0.56; acc: 0.78
Batch: 20; loss: 0.71; acc: 0.83
Batch: 40; loss: 0.41; acc: 0.88
Batch: 60; loss: 0.7; acc: 0.75
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.84; acc: 0.73
Batch: 120; loss: 1.03; acc: 0.66
Batch: 140; loss: 0.37; acc: 0.86
Val Epoch over. val_loss: 0.633417149448091; val_accuracy: 0.7947850318471338 

The current subspace-distance is: 8.203732249967288e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.87; acc: 0.73
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.53; acc: 0.86
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.48; acc: 0.91
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.51; acc: 0.83
Batch: 180; loss: 0.72; acc: 0.83
Batch: 200; loss: 0.36; acc: 0.83
Batch: 220; loss: 0.6; acc: 0.8
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.83; acc: 0.73
Batch: 280; loss: 0.73; acc: 0.8
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.51; acc: 0.83
Batch: 340; loss: 0.31; acc: 0.89
Batch: 360; loss: 0.41; acc: 0.84
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.33; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.84
Batch: 460; loss: 0.36; acc: 0.94
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.72; acc: 0.83
Batch: 600; loss: 0.32; acc: 0.95
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.54; acc: 0.84
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.37; acc: 0.84
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.4; acc: 0.89
Batch: 740; loss: 0.32; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.57; acc: 0.77
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

2.5767772967810743e-05
9.85432507150108e-06
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.33; acc: 0.84
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.95
Batch: 100; loss: 0.51; acc: 0.86
Batch: 120; loss: 0.69; acc: 0.78
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.32747175050958705; val_accuracy: 0.8947054140127388 

The current subspace-distance is: 9.85432507150108e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.48; acc: 0.84
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.14; acc: 0.98
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.32; acc: 0.86
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.38; acc: 0.89
Batch: 260; loss: 0.44; acc: 0.83
Batch: 280; loss: 0.35; acc: 0.89
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.86
Batch: 340; loss: 0.7; acc: 0.89
Batch: 360; loss: 0.46; acc: 0.84
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.48; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.43; acc: 0.89
Batch: 500; loss: 0.49; acc: 0.83
Batch: 520; loss: 0.32; acc: 0.84
Batch: 540; loss: 0.43; acc: 0.86
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.6; acc: 0.84
Batch: 600; loss: 0.37; acc: 0.89
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.23; acc: 0.91
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.37; acc: 0.91
Batch: 720; loss: 0.47; acc: 0.86
Batch: 740; loss: 0.56; acc: 0.89
Batch: 760; loss: 0.41; acc: 0.89
Batch: 780; loss: 0.3; acc: 0.89
Train Epoch over. train_loss: 0.34; train_accuracy: 0.9 

2.7642305212793872e-05
1.0498325536900666e-05
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.51; acc: 0.88
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.3173514554977037; val_accuracy: 0.8986863057324841 

The current subspace-distance is: 1.0498325536900666e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.4; acc: 0.89
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.08; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.92
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.19; acc: 0.92
Batch: 280; loss: 0.47; acc: 0.89
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.94
Batch: 360; loss: 0.48; acc: 0.83
Batch: 380; loss: 0.26; acc: 0.91
Batch: 400; loss: 0.38; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.84
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.48; acc: 0.83
Batch: 500; loss: 0.37; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.95
Batch: 540; loss: 0.53; acc: 0.83
Batch: 560; loss: 0.27; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.81
Batch: 600; loss: 0.73; acc: 0.84
Batch: 620; loss: 0.22; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.53; acc: 0.88
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.22; acc: 0.97
Batch: 720; loss: 0.29; acc: 0.88
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

2.8697388188447803e-05
1.1230680684093386e-05
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.81
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.88; acc: 0.8
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.38654529535846344; val_accuracy: 0.8781847133757962 

The current subspace-distance is: 1.1230680684093386e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.49; acc: 0.86
Batch: 40; loss: 0.39; acc: 0.88
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.49; acc: 0.89
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.44; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.23; acc: 0.97
Batch: 400; loss: 0.45; acc: 0.89
Batch: 420; loss: 0.27; acc: 0.88
Batch: 440; loss: 0.27; acc: 0.91
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.92
Batch: 520; loss: 0.33; acc: 0.91
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.91
Batch: 600; loss: 0.3; acc: 0.89
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.14; acc: 0.98
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.32; acc: 0.86
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

2.9540027753682807e-05
1.192569197883131e-05
Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.38; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.5; acc: 0.84
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.86
Batch: 120; loss: 0.67; acc: 0.78
Batch: 140; loss: 0.2; acc: 0.94
Val Epoch over. val_loss: 0.4372088035960106; val_accuracy: 0.8653463375796179 

The current subspace-distance is: 1.192569197883131e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.77
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.89
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.56; acc: 0.84
Batch: 220; loss: 0.18; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.98
Batch: 260; loss: 0.13; acc: 0.98
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.44; acc: 0.89
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.22; acc: 0.89
Batch: 460; loss: 0.21; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.28; acc: 0.91
Batch: 540; loss: 0.11; acc: 0.98
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.38; acc: 0.86
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.41; acc: 0.91
Batch: 700; loss: 0.3; acc: 0.91
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.29; acc: 0.95
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

3.0198136300896294e-05
1.1899835953954607e-05
Batch: 0; loss: 0.36; acc: 0.88
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.86
Batch: 100; loss: 0.62; acc: 0.81
Batch: 120; loss: 0.79; acc: 0.8
Batch: 140; loss: 0.15; acc: 0.92
Val Epoch over. val_loss: 0.41144519071480273; val_accuracy: 0.8763933121019108 

The current subspace-distance is: 1.1899835953954607e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.31; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.49; acc: 0.89
Batch: 80; loss: 0.08; acc: 0.95
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.23; acc: 0.88
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.31; acc: 0.91
Batch: 340; loss: 0.42; acc: 0.84
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.29; acc: 0.92
Batch: 420; loss: 0.2; acc: 0.97
Batch: 440; loss: 0.29; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.5; acc: 0.89
Batch: 520; loss: 0.53; acc: 0.88
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.91
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.22; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.89
Batch: 720; loss: 0.3; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

3.060729068238288e-05
1.2096701539121568e-05
Batch: 0; loss: 0.83; acc: 0.81
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.51; acc: 0.8
Batch: 60; loss: 0.4; acc: 0.86
Batch: 80; loss: 0.62; acc: 0.83
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 0.92; acc: 0.77
Batch: 140; loss: 0.41; acc: 0.86
Val Epoch over. val_loss: 0.6944122882026016; val_accuracy: 0.8155851910828026 

The current subspace-distance is: 1.2096701539121568e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.84; acc: 0.81
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.34; acc: 0.91
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.47; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.91
Batch: 400; loss: 0.19; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.95
Batch: 440; loss: 0.22; acc: 0.91
Batch: 460; loss: 0.28; acc: 0.92
Batch: 480; loss: 0.49; acc: 0.89
Batch: 500; loss: 0.48; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.95
Batch: 540; loss: 0.3; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.86
Batch: 680; loss: 0.45; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.07; acc: 1.0
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

3.09800889226608e-05
1.1944872312596999e-05
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.83
Batch: 100; loss: 0.44; acc: 0.81
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.402774575314704; val_accuracy: 0.8762937898089171 

The current subspace-distance is: 1.1944872312596999e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.32; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.35; acc: 0.88
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.11; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.37; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.92
Batch: 440; loss: 0.56; acc: 0.88
Batch: 460; loss: 0.23; acc: 0.89
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.19; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.91
Batch: 640; loss: 0.31; acc: 0.89
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.06; acc: 1.0
Batch: 740; loss: 0.41; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.88
Batch: 780; loss: 0.15; acc: 0.97
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

3.148860196233727e-05
1.2886136573797558e-05
Batch: 0; loss: 0.22; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.66; acc: 0.86
Batch: 140; loss: 0.03; acc: 1.0
Val Epoch over. val_loss: 0.2746506274268506; val_accuracy: 0.9153065286624203 

The current subspace-distance is: 1.2886136573797558e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.25; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.1; acc: 1.0
Batch: 160; loss: 0.23; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.19; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.45; acc: 0.88
Batch: 340; loss: 0.18; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.89
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.18; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.43; acc: 0.91
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.56; acc: 0.83
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.26; acc: 0.91
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.11; acc: 0.95
Train Epoch over. train_loss: 0.23; train_accuracy: 0.93 

3.168542025377974e-05
1.2746060747304e-05
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.2351777237027314; val_accuracy: 0.925656847133758 

The current subspace-distance is: 1.2746060747304e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.32; acc: 0.91
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.38; acc: 0.92
Batch: 280; loss: 0.32; acc: 0.89
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.23; acc: 0.95
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.95
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.23; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.48; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.1368923373520374e-05
1.2626150237338152e-05
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.88
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18387068976547308; val_accuracy: 0.9453622611464968 

The current subspace-distance is: 1.2626150237338152e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.2; acc: 0.92
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.24; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.89
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.98
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.22; acc: 0.91
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.36; acc: 0.92
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.2; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

3.202940206392668e-05
1.2647353287320584e-05
Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.46; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1802222220950825; val_accuracy: 0.9463574840764332 

The current subspace-distance is: 1.2647353287320584e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.29; acc: 0.89
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.97
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.12; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.31; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.94
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.08; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.97
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

3.161982385790907e-05
1.1945689038839191e-05
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.167849576136299; val_accuracy: 0.9494426751592356 

The current subspace-distance is: 1.1945689038839191e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.12; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.4; acc: 0.89
Batch: 340; loss: 0.11; acc: 0.94
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.2; acc: 0.95
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.92
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.92
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.97
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

3.204641325282864e-05
1.3496567589754704e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18151233195783986; val_accuracy: 0.944765127388535 

The current subspace-distance is: 1.3496567589754704e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.33; acc: 0.94
Batch: 20; loss: 0.02; acc: 1.0
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.04; acc: 1.0
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.29; acc: 0.92
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.36; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.28; acc: 0.89
Batch: 300; loss: 0.06; acc: 1.0
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.07; acc: 0.97
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.29; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.23; acc: 0.97
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

3.216416007489897e-05
1.279208663618192e-05
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.29; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.47; acc: 0.8
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.24295179327582098; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 1.279208663618192e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.38; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.98
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.09; acc: 0.97
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.08; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.29; acc: 0.92
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.28; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

3.210050635971129e-05
1.2831370440835599e-05
Batch: 0; loss: 0.13; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.84
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.21466415992398172; val_accuracy: 0.9325238853503185 

The current subspace-distance is: 1.2831370440835599e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.04; acc: 1.0
Batch: 60; loss: 0.13; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.14; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.91
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.2; acc: 0.97
Batch: 480; loss: 0.14; acc: 0.98
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.89
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.86
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.31; acc: 0.91
Batch: 700; loss: 0.34; acc: 0.88
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.92
Train Epoch over. train_loss: 0.18; train_accuracy: 0.95 

3.221923907403834e-05
1.2613512808457017e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17034252588251594; val_accuracy: 0.9501393312101911 

The current subspace-distance is: 1.2613512808457017e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.22; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.92
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.11; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.22; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.26; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.95
Batch: 540; loss: 0.11; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.88
Batch: 620; loss: 0.35; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.88
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.46; acc: 0.86
Train Epoch over. train_loss: 0.18; train_accuracy: 0.94 

3.296192880952731e-05
1.2842958312830888e-05
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1793541452924537; val_accuracy: 0.9453622611464968 

The current subspace-distance is: 1.2842958312830888e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.37; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.11; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.05; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.18; acc: 0.91
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.1; acc: 0.95
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.11; acc: 0.98
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.17; acc: 0.92
Batch: 500; loss: 0.36; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.44; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.97
Batch: 580; loss: 0.15; acc: 0.92
Batch: 600; loss: 0.33; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.03; acc: 1.0
Batch: 680; loss: 0.1; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

3.258133074268699e-05
1.3400443094724324e-05
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.91
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.195484515587995; val_accuracy: 0.9398885350318471 

The current subspace-distance is: 1.3400443094724324e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.97
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.91
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.19; acc: 0.97
Batch: 320; loss: 0.09; acc: 1.0
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.32; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.06; acc: 0.97
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.06; acc: 1.0
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

3.26562840200495e-05
1.3531105651054531e-05
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.84
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.34; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.04; acc: 0.98
Val Epoch over. val_loss: 0.24575325666339534; val_accuracy: 0.9281449044585988 

The current subspace-distance is: 1.3531105651054531e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.09; acc: 0.95
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.97
Batch: 340; loss: 0.37; acc: 0.88
Batch: 360; loss: 0.25; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.14; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.92
Batch: 580; loss: 0.41; acc: 0.91
Batch: 600; loss: 0.08; acc: 0.98
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.06; acc: 0.98
Batch: 680; loss: 0.04; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.2563370041316375e-05
1.339243863185402e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15566752293402222; val_accuracy: 0.9535230891719745 

The current subspace-distance is: 1.339243863185402e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.06; acc: 1.0
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.21; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.92
Batch: 260; loss: 0.07; acc: 0.97
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.14; acc: 0.94
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.26; acc: 0.91
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.1; acc: 0.98
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.316446236567572e-05
1.4116040802036878e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15575113235290644; val_accuracy: 0.9525278662420382 

The current subspace-distance is: 1.4116040802036878e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.05; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.18; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.92
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.88
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.17; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.3037660614354536e-05
1.326281653746264e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.3; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16159073201714047; val_accuracy: 0.9511345541401274 

The current subspace-distance is: 1.326281653746264e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.15; acc: 0.94
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.35; acc: 0.88
Batch: 80; loss: 0.44; acc: 0.86
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.07; acc: 0.97
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.88
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.97
Batch: 480; loss: 0.18; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.28; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.94
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.98
Batch: 680; loss: 0.19; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.263842154410668e-05
1.3577668141806498e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16006584600753085; val_accuracy: 0.9514331210191083 

The current subspace-distance is: 1.3577668141806498e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.06; acc: 1.0
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.94
Batch: 140; loss: 0.06; acc: 0.98
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.97
Batch: 300; loss: 0.22; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.89
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.14; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.98
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.03; acc: 1.0
Batch: 480; loss: 0.13; acc: 0.94
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.97
Batch: 720; loss: 0.41; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.97
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.275263588875532e-05
1.360799160465831e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15940683596073443; val_accuracy: 0.9515326433121019 

The current subspace-distance is: 1.360799160465831e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.91
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.28; acc: 0.94
Batch: 140; loss: 0.28; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.98
Batch: 200; loss: 0.06; acc: 0.98
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.19; acc: 0.98
Batch: 260; loss: 0.2; acc: 0.95
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.91
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.03; acc: 1.0
Batch: 460; loss: 0.09; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.05; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.97
Batch: 660; loss: 0.28; acc: 0.86
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.3101194276241586e-05
1.416246232111007e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15422409825074446; val_accuracy: 0.9540207006369427 

The current subspace-distance is: 1.416246232111007e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.24; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.12; acc: 0.97
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.19; acc: 0.97
Batch: 280; loss: 0.14; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.09; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.97
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.98
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.13; acc: 0.94
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.312053740955889e-05
1.3383754776441492e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1585240162149736; val_accuracy: 0.9525278662420382 

The current subspace-distance is: 1.3383754776441492e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.1; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.31; acc: 0.92
Batch: 140; loss: 0.06; acc: 1.0
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.06; acc: 0.98
Batch: 200; loss: 0.26; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.98
Batch: 280; loss: 0.27; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.89
Batch: 320; loss: 0.24; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.06; acc: 1.0
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.51; acc: 0.89
Batch: 740; loss: 0.05; acc: 0.98
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

3.271477180533111e-05
1.3655254406330641e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.91
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16600824204409959; val_accuracy: 0.9511345541401274 

The current subspace-distance is: 1.3655254406330641e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.04; acc: 0.98
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.94
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.91
Batch: 360; loss: 0.05; acc: 1.0
Batch: 380; loss: 0.09; acc: 0.98
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.17; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.94
Batch: 700; loss: 0.27; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.36; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.17; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.3375818020431325e-05
1.3990927982376888e-05
Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.35; acc: 0.89
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16720800125485014; val_accuracy: 0.9502388535031847 

The current subspace-distance is: 1.3990927982376888e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.23; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.04; acc: 0.98
Batch: 160; loss: 0.12; acc: 0.94
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.24; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.26; acc: 0.95
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.08; acc: 0.98
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.05; acc: 1.0
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.22; acc: 0.94
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.12; acc: 0.97
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.26; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.91
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.301596734672785e-05
1.3110508007230237e-05
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1539770512112007; val_accuracy: 0.9543192675159236 

The current subspace-distance is: 1.3110508007230237e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.05; acc: 1.0
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.07; acc: 0.97
Batch: 180; loss: 0.2; acc: 0.92
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.97
Batch: 240; loss: 0.09; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.15; acc: 0.94
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.04; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.91
Batch: 380; loss: 0.06; acc: 0.97
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.47; acc: 0.91
Batch: 480; loss: 0.14; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.08; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.25; acc: 0.91
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.06; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.252108217566274e-05
1.4014380212756805e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14950006372135155; val_accuracy: 0.9553144904458599 

The current subspace-distance is: 1.4014380212756805e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.11; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.94
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.24; acc: 0.97
Batch: 160; loss: 0.37; acc: 0.94
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.91
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.04; acc: 1.0
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.13; acc: 0.94
Batch: 540; loss: 0.25; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.14; acc: 0.91
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.37; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.95
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.2454005122417584e-05
1.3077669791528024e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.25; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15014462756692984; val_accuracy: 0.9555135350318471 

The current subspace-distance is: 1.3077669791528024e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.91
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.12; acc: 0.97
Batch: 240; loss: 0.04; acc: 0.98
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.07; acc: 0.97
Batch: 320; loss: 0.11; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.97
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.97
Batch: 660; loss: 0.16; acc: 0.94
Batch: 680; loss: 0.07; acc: 0.97
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.22; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.2906904380070046e-05
1.4109128642303403e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15127187824932634; val_accuracy: 0.95421974522293 

The current subspace-distance is: 1.4109128642303403e-05 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.89
Batch: 20; loss: 0.18; acc: 0.97
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.27; acc: 0.86
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.28; acc: 0.95
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.14; acc: 0.98
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.07; acc: 0.98
Batch: 500; loss: 0.17; acc: 0.92
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.07; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.98
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.92
Batch: 760; loss: 0.17; acc: 0.97
Batch: 780; loss: 0.03; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.311608452349901e-05
1.3476464118866716e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.22; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15417896457918132; val_accuracy: 0.9534235668789809 

The current subspace-distance is: 1.3476464118866716e-05 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.97
Batch: 140; loss: 0.11; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.02; acc: 1.0
Batch: 240; loss: 0.37; acc: 0.94
Batch: 260; loss: 0.04; acc: 1.0
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.14; acc: 0.97
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.88
Batch: 420; loss: 0.08; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.04; acc: 1.0
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.07; acc: 0.95
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.02; acc: 1.0
Batch: 740; loss: 0.14; acc: 0.92
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.28; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.268082218710333e-05
1.3233949175628368e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14938161360799887; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 1.3233949175628368e-05 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.06; acc: 0.97
Batch: 40; loss: 0.08; acc: 0.97
Batch: 60; loss: 0.1; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.04; acc: 0.98
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.02; acc: 1.0
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.31; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.95
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.07; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.2899988582357764e-05
1.3674843103217427e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14890429975500533; val_accuracy: 0.9552149681528662 

The current subspace-distance is: 1.3674843103217427e-05 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.19; acc: 0.92
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.06; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.21; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.26; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.19; acc: 0.92
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.98
Batch: 460; loss: 0.09; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.97
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.16; acc: 0.94
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.2; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.02; acc: 1.0
Batch: 700; loss: 0.05; acc: 1.0
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.98
Batch: 780; loss: 0.06; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.274162736488506e-05
1.2999174032302108e-05
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15433548352900583; val_accuracy: 0.9544187898089171 

The current subspace-distance is: 1.2999174032302108e-05 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.07; acc: 1.0
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.92
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.05; acc: 0.98
Batch: 240; loss: 0.22; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.06; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.97
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.05; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.91
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.15; acc: 0.97
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.97
Batch: 600; loss: 0.38; acc: 0.92
Batch: 620; loss: 0.03; acc: 0.98
Batch: 640; loss: 0.29; acc: 0.94
Batch: 660; loss: 0.1; acc: 0.94
Batch: 680; loss: 0.16; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.15; acc: 0.98
Batch: 760; loss: 0.09; acc: 0.95
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.338930036989041e-05
1.3310200301930308e-05
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15208911454411828; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 1.3310200301930308e-05 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.11; acc: 0.94
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.15; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.21; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.86
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.06; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.2; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.95
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.06; acc: 0.98
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.98
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.1; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.340336843393743e-05
1.3546246009354945e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1496568319334346; val_accuracy: 0.9545183121019108 

The current subspace-distance is: 1.3546246009354945e-05 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.95
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.09; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.04; acc: 0.98
Batch: 120; loss: 0.18; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.1; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.28; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.21; acc: 0.92
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.07; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.97
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.09; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.13; acc: 0.94
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.94
Batch: 760; loss: 0.08; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.316104266559705e-05
1.3052635040367022e-05
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15061274334598498; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.3052635040367022e-05 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.04; acc: 0.97
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.33; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.94
Batch: 160; loss: 0.11; acc: 0.97
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.92
Batch: 320; loss: 0.14; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.16; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.97
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.97
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.39; acc: 0.92
Batch: 660; loss: 0.35; acc: 0.92
Batch: 680; loss: 0.07; acc: 0.98
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.07; acc: 0.97
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.297364673926495e-05
1.3356899216887541e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14897953109092013; val_accuracy: 0.9548168789808917 

The current subspace-distance is: 1.3356899216887541e-05 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.95
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.1; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.95
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.95
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.27; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.95
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.09; acc: 0.98
Batch: 620; loss: 0.36; acc: 0.92
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.24; acc: 0.95
Batch: 700; loss: 0.09; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.95
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.94
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.27922280121129e-05
1.301421070820652e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14914255883473498; val_accuracy: 0.9548168789808917 

The current subspace-distance is: 1.301421070820652e-05 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.95
Batch: 40; loss: 0.04; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.21; acc: 0.95
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.21; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.95
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.04; acc: 0.98
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.26; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.98
Batch: 520; loss: 0.03; acc: 1.0
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.12; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.97
Batch: 660; loss: 0.22; acc: 0.95
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.04; acc: 1.0
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.04; acc: 1.0
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.292145993327722e-05
1.29688523884397e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14873504501049686; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 1.29688523884397e-05 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.06; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.95
Batch: 200; loss: 0.09; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.94
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.12; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.12; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.95
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.92
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.1; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.340364492032677e-05
1.3161786228010897e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14886530941933585; val_accuracy: 0.9560111464968153 

The current subspace-distance is: 1.3161786228010897e-05 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.14; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.19; acc: 0.95
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.15; acc: 0.95
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.03; acc: 1.0
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.25; acc: 0.95
Batch: 480; loss: 0.24; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.05; acc: 0.97
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.3074400562327355e-05
1.3708436199522112e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1486380247363619; val_accuracy: 0.9554140127388535 

The current subspace-distance is: 1.3708436199522112e-05 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.07; acc: 0.97
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.92
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.12; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.06; acc: 1.0
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.23; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.09; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.07; acc: 0.98
Batch: 600; loss: 0.19; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.98
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.18; acc: 0.91
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.34133037540596e-05
1.3443284842651337e-05
Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1497390008988274; val_accuracy: 0.9555135350318471 

The current subspace-distance is: 1.3443284842651337e-05 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.05; acc: 1.0
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.06; acc: 0.98
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.19; acc: 0.95
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.11; acc: 0.94
Batch: 300; loss: 0.39; acc: 0.92
Batch: 320; loss: 0.04; acc: 1.0
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.95
Batch: 380; loss: 0.06; acc: 1.0
Batch: 400; loss: 0.07; acc: 0.98
Batch: 420; loss: 0.21; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.02; acc: 1.0
Batch: 500; loss: 0.16; acc: 0.98
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.07; acc: 0.97
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.03; acc: 1.0
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.07; acc: 0.95
Batch: 780; loss: 0.15; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.332081905682571e-05
1.3952365407021716e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15113626830991667; val_accuracy: 0.9539211783439491 

The current subspace-distance is: 1.3952365407021716e-05 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.08; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.91
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.09; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.98
Batch: 360; loss: 0.36; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.91
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.26; acc: 0.95
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.95
Batch: 560; loss: 0.15; acc: 0.97
Batch: 580; loss: 0.04; acc: 0.98
Batch: 600; loss: 0.11; acc: 0.95
Batch: 620; loss: 0.41; acc: 0.92
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.1; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.25; acc: 0.97
Batch: 740; loss: 0.08; acc: 0.97
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.1; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.376708991709165e-05
1.3419919923762791e-05
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14887426238340937; val_accuracy: 0.9551154458598726 

The current subspace-distance is: 1.3419919923762791e-05 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.1; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.11; acc: 0.98
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.27; acc: 0.92
Batch: 260; loss: 0.12; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.05; acc: 0.98
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.95
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.05; acc: 1.0
Batch: 640; loss: 0.1; acc: 0.95
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.04; acc: 1.0
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.06; acc: 0.97
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.18; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.306351209175773e-05
1.3873253010387998e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.14895576672853938; val_accuracy: 0.9547173566878981 

The current subspace-distance is: 1.3873253010387998e-05 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.95
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.05; acc: 0.98
Batch: 260; loss: 0.05; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.04; acc: 0.98
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.1; acc: 0.98
Batch: 440; loss: 0.06; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.25; acc: 0.88
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.33; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.05; acc: 0.98
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.05; acc: 0.97
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.97
Batch: 740; loss: 0.28; acc: 0.92
Batch: 760; loss: 0.2; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

3.330110848764889e-05
1.359994348604232e-05
Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.12; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.148737246823159; val_accuracy: 0.9546178343949044 

The current subspace-distance is: 1.359994348604232e-05 

plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
plots/subspace_training/reg_lenet/2020-01-22 20:47:39/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_2_epochs_50_batchsize_64
