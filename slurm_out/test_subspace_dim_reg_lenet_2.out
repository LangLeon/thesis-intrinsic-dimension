model : reg_lenet_2
optimizer : SGD
lr : 1.0
schedule : True
schedule_gamma : 0.4
schedule_freq : 10
seed : 1
n_epochs : 50
batch_size : 64
non_wrapped : False
chunked : False
dense : False
parameter_correction : False
print_freq : 20
print_prec : 2
device : cuda
subspace_training : True
ddim_vs_acc : True
timestamp : 2020-01-22 14:39:50
nonzero elements in E: 7033
elements in E: 988700
fraction nonzero: 0.007113381207646405
Epoch 1 start
The current lr is: 1.0
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
/tmp/pip-req-build-4baxydiv/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.32; acc: 0.05
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.08
Batch: 180; loss: 2.32; acc: 0.08
Batch: 200; loss: 2.31; acc: 0.11
Batch: 220; loss: 2.31; acc: 0.11
Batch: 240; loss: 2.29; acc: 0.09
Batch: 260; loss: 2.3; acc: 0.12
Batch: 280; loss: 2.31; acc: 0.06
Batch: 300; loss: 2.31; acc: 0.12
Batch: 320; loss: 2.29; acc: 0.03
Batch: 340; loss: 2.32; acc: 0.09
Batch: 360; loss: 2.3; acc: 0.11
Batch: 380; loss: 2.3; acc: 0.09
Batch: 400; loss: 2.29; acc: 0.22
Batch: 420; loss: 2.32; acc: 0.09
Batch: 440; loss: 2.31; acc: 0.12
Batch: 460; loss: 2.3; acc: 0.11
Batch: 480; loss: 2.28; acc: 0.17
Batch: 500; loss: 2.31; acc: 0.11
Batch: 520; loss: 2.31; acc: 0.09
Batch: 540; loss: 2.31; acc: 0.06
Batch: 560; loss: 2.29; acc: 0.14
Batch: 580; loss: 2.3; acc: 0.17
Batch: 600; loss: 2.3; acc: 0.19
Batch: 620; loss: 2.31; acc: 0.16
Batch: 640; loss: 2.3; acc: 0.19
Batch: 660; loss: 2.28; acc: 0.28
Batch: 680; loss: 2.31; acc: 0.23
Batch: 700; loss: 2.3; acc: 0.2
Batch: 720; loss: 2.29; acc: 0.27
Batch: 740; loss: 2.31; acc: 0.17
Batch: 760; loss: 2.3; acc: 0.17
Batch: 780; loss: 2.28; acc: 0.27
Train Epoch over. train_loss: 2.3; train_accuracy: 0.12 

Batch: 0; loss: 2.31; acc: 0.19
Batch: 20; loss: 2.31; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.22
Batch: 60; loss: 2.3; acc: 0.14
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.31; acc: 0.19
Batch: 120; loss: 2.31; acc: 0.12
Batch: 140; loss: 2.29; acc: 0.19
Val Epoch over. val_loss: 2.2986581006627174; val_accuracy: 0.17167595541401273 

The current subspace-distance is: 6.077185389585793e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.23
Batch: 20; loss: 2.3; acc: 0.2
Batch: 40; loss: 2.3; acc: 0.2
Batch: 60; loss: 2.28; acc: 0.23
Batch: 80; loss: 2.29; acc: 0.22
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.3; acc: 0.16
Batch: 140; loss: 2.31; acc: 0.16
Batch: 160; loss: 2.29; acc: 0.16
Batch: 180; loss: 2.29; acc: 0.28
Batch: 200; loss: 2.31; acc: 0.14
Batch: 220; loss: 2.29; acc: 0.2
Batch: 240; loss: 2.3; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.27
Batch: 280; loss: 2.3; acc: 0.19
Batch: 300; loss: 2.3; acc: 0.2
Batch: 320; loss: 2.3; acc: 0.17
Batch: 340; loss: 2.29; acc: 0.17
Batch: 360; loss: 2.28; acc: 0.28
Batch: 380; loss: 2.32; acc: 0.09
Batch: 400; loss: 2.28; acc: 0.2
Batch: 420; loss: 2.31; acc: 0.2
Batch: 440; loss: 2.29; acc: 0.2
Batch: 460; loss: 2.29; acc: 0.16
Batch: 480; loss: 2.29; acc: 0.16
Batch: 500; loss: 2.29; acc: 0.08
Batch: 520; loss: 2.3; acc: 0.12
Batch: 540; loss: 2.3; acc: 0.11
Batch: 560; loss: 2.31; acc: 0.05
Batch: 580; loss: 2.29; acc: 0.17
Batch: 600; loss: 2.3; acc: 0.16
Batch: 620; loss: 2.3; acc: 0.12
Batch: 640; loss: 2.29; acc: 0.11
Batch: 660; loss: 2.29; acc: 0.12
Batch: 680; loss: 2.29; acc: 0.14
Batch: 700; loss: 2.28; acc: 0.11
Batch: 720; loss: 2.29; acc: 0.16
Batch: 740; loss: 2.3; acc: 0.11
Batch: 760; loss: 2.28; acc: 0.2
Batch: 780; loss: 2.31; acc: 0.11
Train Epoch over. train_loss: 2.3; train_accuracy: 0.16 

Batch: 0; loss: 2.29; acc: 0.17
Batch: 20; loss: 2.31; acc: 0.06
Batch: 40; loss: 2.28; acc: 0.16
Batch: 60; loss: 2.28; acc: 0.16
Batch: 80; loss: 2.28; acc: 0.14
Batch: 100; loss: 2.3; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.29; acc: 0.11
Val Epoch over. val_loss: 2.2929879252318366; val_accuracy: 0.12539808917197454 

The current subspace-distance is: 8.902211448003072e-06 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.31; acc: 0.09
Batch: 20; loss: 2.31; acc: 0.14
Batch: 40; loss: 2.29; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.09
Batch: 80; loss: 2.29; acc: 0.19
Batch: 100; loss: 2.29; acc: 0.06
Batch: 120; loss: 2.3; acc: 0.08
Batch: 140; loss: 2.28; acc: 0.17
Batch: 160; loss: 2.3; acc: 0.05
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.3; acc: 0.11
Batch: 220; loss: 2.29; acc: 0.09
Batch: 240; loss: 2.28; acc: 0.14
Batch: 260; loss: 2.28; acc: 0.11
Batch: 280; loss: 2.29; acc: 0.12
Batch: 300; loss: 2.32; acc: 0.09
Batch: 320; loss: 2.28; acc: 0.19
Batch: 340; loss: 2.29; acc: 0.09
Batch: 360; loss: 2.29; acc: 0.12
Batch: 380; loss: 2.3; acc: 0.08
Batch: 400; loss: 2.3; acc: 0.2
Batch: 420; loss: 2.29; acc: 0.12
Batch: 440; loss: 2.3; acc: 0.11
Batch: 460; loss: 2.29; acc: 0.11
Batch: 480; loss: 2.28; acc: 0.12
Batch: 500; loss: 2.27; acc: 0.22
Batch: 520; loss: 2.3; acc: 0.12
Batch: 540; loss: 2.29; acc: 0.16
Batch: 560; loss: 2.27; acc: 0.22
Batch: 580; loss: 2.29; acc: 0.16
Batch: 600; loss: 2.3; acc: 0.11
Batch: 620; loss: 2.29; acc: 0.17
Batch: 640; loss: 2.27; acc: 0.17
Batch: 660; loss: 2.29; acc: 0.19
Batch: 680; loss: 2.3; acc: 0.16
Batch: 700; loss: 2.29; acc: 0.16
Batch: 720; loss: 2.28; acc: 0.22
Batch: 740; loss: 2.28; acc: 0.17
Batch: 760; loss: 2.27; acc: 0.22
Batch: 780; loss: 2.3; acc: 0.09
Train Epoch over. train_loss: 2.29; train_accuracy: 0.15 

Batch: 0; loss: 2.28; acc: 0.19
Batch: 20; loss: 2.31; acc: 0.05
Batch: 40; loss: 2.27; acc: 0.23
Batch: 60; loss: 2.28; acc: 0.16
Batch: 80; loss: 2.27; acc: 0.17
Batch: 100; loss: 2.29; acc: 0.12
Batch: 120; loss: 2.29; acc: 0.16
Batch: 140; loss: 2.28; acc: 0.11
Val Epoch over. val_loss: 2.2872705246992173; val_accuracy: 0.15216958598726116 

The current subspace-distance is: 1.1083779099863023e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 2.28; acc: 0.12
Batch: 20; loss: 2.27; acc: 0.16
Batch: 40; loss: 2.3; acc: 0.06
Batch: 60; loss: 2.3; acc: 0.16
Batch: 80; loss: 2.29; acc: 0.14
Batch: 100; loss: 2.27; acc: 0.27
Batch: 120; loss: 2.27; acc: 0.17
Batch: 140; loss: 2.28; acc: 0.14
Batch: 160; loss: 2.31; acc: 0.12
Batch: 180; loss: 2.27; acc: 0.23
Batch: 200; loss: 2.28; acc: 0.2
Batch: 220; loss: 2.25; acc: 0.27
Batch: 240; loss: 2.28; acc: 0.17
Batch: 260; loss: 2.26; acc: 0.19
Batch: 280; loss: 2.3; acc: 0.12
Batch: 300; loss: 2.29; acc: 0.14
Batch: 320; loss: 2.27; acc: 0.22
Batch: 340; loss: 2.31; acc: 0.09
Batch: 360; loss: 2.27; acc: 0.19
Batch: 380; loss: 2.27; acc: 0.25
Batch: 400; loss: 2.26; acc: 0.2
Batch: 420; loss: 2.28; acc: 0.22
Batch: 440; loss: 2.26; acc: 0.11
Batch: 460; loss: 2.25; acc: 0.19
Batch: 480; loss: 2.27; acc: 0.11
Batch: 500; loss: 2.26; acc: 0.22
Batch: 520; loss: 2.28; acc: 0.12
Batch: 540; loss: 2.27; acc: 0.17
Batch: 560; loss: 2.29; acc: 0.09
Batch: 580; loss: 2.28; acc: 0.08
Batch: 600; loss: 2.26; acc: 0.16
Batch: 620; loss: 2.26; acc: 0.17
Batch: 640; loss: 2.23; acc: 0.23
Batch: 660; loss: 2.27; acc: 0.12
Batch: 680; loss: 2.19; acc: 0.31
Batch: 700; loss: 2.28; acc: 0.14
Batch: 720; loss: 2.28; acc: 0.09
Batch: 740; loss: 2.28; acc: 0.11
Batch: 760; loss: 2.27; acc: 0.17
Batch: 780; loss: 2.29; acc: 0.08
Train Epoch over. train_loss: 2.28; train_accuracy: 0.15 

Batch: 0; loss: 2.25; acc: 0.19
Batch: 20; loss: 2.3; acc: 0.06
Batch: 40; loss: 2.24; acc: 0.17
Batch: 60; loss: 2.25; acc: 0.14
Batch: 80; loss: 2.23; acc: 0.19
Batch: 100; loss: 2.28; acc: 0.09
Batch: 120; loss: 2.26; acc: 0.14
Batch: 140; loss: 2.26; acc: 0.22
Val Epoch over. val_loss: 2.264604330062866; val_accuracy: 0.14281449044585987 

The current subspace-distance is: 1.2832551874453202e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 2.25; acc: 0.17
Batch: 20; loss: 2.25; acc: 0.16
Batch: 40; loss: 2.25; acc: 0.17
Batch: 60; loss: 2.22; acc: 0.2
Batch: 80; loss: 2.24; acc: 0.22
Batch: 100; loss: 2.27; acc: 0.08
Batch: 120; loss: 2.23; acc: 0.17
Batch: 140; loss: 2.25; acc: 0.12
Batch: 160; loss: 2.23; acc: 0.17
Batch: 180; loss: 2.28; acc: 0.12
Batch: 200; loss: 2.23; acc: 0.19
Batch: 220; loss: 2.23; acc: 0.14
Batch: 240; loss: 2.25; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.12
Batch: 280; loss: 2.21; acc: 0.19
Batch: 300; loss: 2.21; acc: 0.22
Batch: 320; loss: 2.24; acc: 0.16
Batch: 340; loss: 2.2; acc: 0.2
Batch: 360; loss: 2.23; acc: 0.19
Batch: 380; loss: 2.25; acc: 0.12
Batch: 400; loss: 2.27; acc: 0.09
Batch: 420; loss: 2.24; acc: 0.12
Batch: 440; loss: 2.24; acc: 0.16
Batch: 460; loss: 2.22; acc: 0.19
Batch: 480; loss: 2.26; acc: 0.08
Batch: 500; loss: 2.15; acc: 0.25
Batch: 520; loss: 2.25; acc: 0.16
Batch: 540; loss: 2.23; acc: 0.16
Batch: 560; loss: 2.22; acc: 0.22
Batch: 580; loss: 2.19; acc: 0.17
Batch: 600; loss: 2.12; acc: 0.25
Batch: 620; loss: 2.27; acc: 0.14
Batch: 640; loss: 2.19; acc: 0.2
Batch: 660; loss: 2.15; acc: 0.27
Batch: 680; loss: 2.21; acc: 0.25
Batch: 700; loss: 2.17; acc: 0.3
Batch: 720; loss: 2.14; acc: 0.22
Batch: 740; loss: 2.26; acc: 0.16
Batch: 760; loss: 2.11; acc: 0.38
Batch: 780; loss: 2.11; acc: 0.25
Train Epoch over. train_loss: 2.22; train_accuracy: 0.18 

Batch: 0; loss: 2.09; acc: 0.31
Batch: 20; loss: 2.14; acc: 0.33
Batch: 40; loss: 2.05; acc: 0.36
Batch: 60; loss: 2.08; acc: 0.36
Batch: 80; loss: 2.06; acc: 0.28
Batch: 100; loss: 2.15; acc: 0.25
Batch: 120; loss: 2.12; acc: 0.25
Batch: 140; loss: 2.12; acc: 0.23
Val Epoch over. val_loss: 2.1176648124767716; val_accuracy: 0.2726910828025478 

The current subspace-distance is: 1.6115283870021813e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 2.09; acc: 0.36
Batch: 20; loss: 2.14; acc: 0.31
Batch: 40; loss: 2.01; acc: 0.31
Batch: 60; loss: 2.18; acc: 0.22
Batch: 80; loss: 2.05; acc: 0.34
Batch: 100; loss: 2.13; acc: 0.22
Batch: 120; loss: 2.07; acc: 0.28
Batch: 140; loss: 2.07; acc: 0.2
Batch: 160; loss: 2.05; acc: 0.23
Batch: 180; loss: 2.05; acc: 0.25
Batch: 200; loss: 2.04; acc: 0.23
Batch: 220; loss: 2.06; acc: 0.19
Batch: 240; loss: 2.02; acc: 0.27
Batch: 260; loss: 1.96; acc: 0.33
Batch: 280; loss: 1.84; acc: 0.41
Batch: 300; loss: 1.83; acc: 0.39
Batch: 320; loss: 1.83; acc: 0.34
Batch: 340; loss: 1.81; acc: 0.36
Batch: 360; loss: 1.95; acc: 0.31
Batch: 380; loss: 1.95; acc: 0.28
Batch: 400; loss: 1.76; acc: 0.42
Batch: 420; loss: 1.89; acc: 0.38
Batch: 440; loss: 1.89; acc: 0.28
Batch: 460; loss: 1.76; acc: 0.41
Batch: 480; loss: 1.93; acc: 0.3
Batch: 500; loss: 1.84; acc: 0.39
Batch: 520; loss: 1.8; acc: 0.38
Batch: 540; loss: 1.74; acc: 0.42
Batch: 560; loss: 1.75; acc: 0.39
Batch: 580; loss: 1.69; acc: 0.42
Batch: 600; loss: 1.85; acc: 0.36
Batch: 620; loss: 1.82; acc: 0.33
Batch: 640; loss: 1.68; acc: 0.38
Batch: 660; loss: 1.84; acc: 0.5
Batch: 680; loss: 1.58; acc: 0.47
Batch: 700; loss: 1.82; acc: 0.33
Batch: 720; loss: 1.88; acc: 0.34
Batch: 740; loss: 1.92; acc: 0.36
Batch: 760; loss: 1.79; acc: 0.39
Batch: 780; loss: 1.64; acc: 0.45
Train Epoch over. train_loss: 1.91; train_accuracy: 0.34 

Batch: 0; loss: 1.78; acc: 0.47
Batch: 20; loss: 1.88; acc: 0.38
Batch: 40; loss: 1.62; acc: 0.47
Batch: 60; loss: 1.7; acc: 0.52
Batch: 80; loss: 1.65; acc: 0.48
Batch: 100; loss: 1.76; acc: 0.38
Batch: 120; loss: 1.7; acc: 0.44
Batch: 140; loss: 1.76; acc: 0.39
Val Epoch over. val_loss: 1.7412193899701356; val_accuracy: 0.40863853503184716 

The current subspace-distance is: 2.204379234171938e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.85; acc: 0.33
Batch: 20; loss: 1.76; acc: 0.38
Batch: 40; loss: 1.74; acc: 0.47
Batch: 60; loss: 1.68; acc: 0.36
Batch: 80; loss: 1.76; acc: 0.45
Batch: 100; loss: 1.94; acc: 0.31
Batch: 120; loss: 1.87; acc: 0.33
Batch: 140; loss: 1.77; acc: 0.38
Batch: 160; loss: 1.74; acc: 0.41
Batch: 180; loss: 1.71; acc: 0.48
Batch: 200; loss: 1.67; acc: 0.45
Batch: 220; loss: 1.88; acc: 0.33
Batch: 240; loss: 1.59; acc: 0.48
Batch: 260; loss: 1.54; acc: 0.47
Batch: 280; loss: 1.72; acc: 0.47
Batch: 300; loss: 1.43; acc: 0.56
Batch: 320; loss: 1.83; acc: 0.3
Batch: 340; loss: 1.62; acc: 0.47
Batch: 360; loss: 1.51; acc: 0.45
Batch: 380; loss: 1.85; acc: 0.31
Batch: 400; loss: 1.85; acc: 0.42
Batch: 420; loss: 1.7; acc: 0.39
Batch: 440; loss: 1.63; acc: 0.47
Batch: 460; loss: 1.82; acc: 0.44
Batch: 480; loss: 1.41; acc: 0.61
Batch: 500; loss: 1.5; acc: 0.48
Batch: 520; loss: 1.52; acc: 0.53
Batch: 540; loss: 1.49; acc: 0.5
Batch: 560; loss: 1.36; acc: 0.53
Batch: 580; loss: 1.72; acc: 0.38
Batch: 600; loss: 1.57; acc: 0.47
Batch: 620; loss: 1.59; acc: 0.39
Batch: 640; loss: 1.58; acc: 0.5
Batch: 660; loss: 1.77; acc: 0.38
Batch: 680; loss: 1.49; acc: 0.47
Batch: 700; loss: 1.61; acc: 0.45
Batch: 720; loss: 1.44; acc: 0.53
Batch: 740; loss: 1.57; acc: 0.59
Batch: 760; loss: 1.53; acc: 0.45
Batch: 780; loss: 1.74; acc: 0.38
Train Epoch over. train_loss: 1.64; train_accuracy: 0.45 

Batch: 0; loss: 1.61; acc: 0.47
Batch: 20; loss: 1.79; acc: 0.44
Batch: 40; loss: 1.51; acc: 0.48
Batch: 60; loss: 1.56; acc: 0.48
Batch: 80; loss: 1.56; acc: 0.48
Batch: 100; loss: 1.61; acc: 0.45
Batch: 120; loss: 1.66; acc: 0.45
Batch: 140; loss: 1.44; acc: 0.55
Val Epoch over. val_loss: 1.6131679738403126; val_accuracy: 0.44775079617834396 

The current subspace-distance is: 2.9256079869810492e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.71; acc: 0.36
Batch: 20; loss: 1.63; acc: 0.5
Batch: 40; loss: 1.46; acc: 0.52
Batch: 60; loss: 1.46; acc: 0.53
Batch: 80; loss: 1.34; acc: 0.59
Batch: 100; loss: 1.66; acc: 0.52
Batch: 120; loss: 1.56; acc: 0.42
Batch: 140; loss: 1.59; acc: 0.41
Batch: 160; loss: 1.54; acc: 0.44
Batch: 180; loss: 1.76; acc: 0.39
Batch: 200; loss: 1.47; acc: 0.5
Batch: 220; loss: 1.56; acc: 0.47
Batch: 240; loss: 1.47; acc: 0.52
Batch: 260; loss: 1.45; acc: 0.58
Batch: 280; loss: 1.68; acc: 0.5
Batch: 300; loss: 1.78; acc: 0.41
Batch: 320; loss: 1.63; acc: 0.48
Batch: 340; loss: 1.6; acc: 0.44
Batch: 360; loss: 1.51; acc: 0.42
Batch: 380; loss: 1.32; acc: 0.55
Batch: 400; loss: 1.63; acc: 0.45
Batch: 420; loss: 1.56; acc: 0.45
Batch: 440; loss: 1.76; acc: 0.41
Batch: 460; loss: 1.3; acc: 0.62
Batch: 480; loss: 1.65; acc: 0.56
Batch: 500; loss: 1.53; acc: 0.5
Batch: 520; loss: 1.7; acc: 0.5
Batch: 540; loss: 1.55; acc: 0.47
Batch: 560; loss: 1.51; acc: 0.53
Batch: 580; loss: 1.4; acc: 0.56
Batch: 600; loss: 1.53; acc: 0.52
Batch: 620; loss: 1.44; acc: 0.45
Batch: 640; loss: 1.84; acc: 0.39
Batch: 660; loss: 1.53; acc: 0.45
Batch: 680; loss: 1.39; acc: 0.55
Batch: 700; loss: 1.54; acc: 0.52
Batch: 720; loss: 1.39; acc: 0.58
Batch: 740; loss: 1.81; acc: 0.38
Batch: 760; loss: 1.61; acc: 0.41
Batch: 780; loss: 1.62; acc: 0.44
Train Epoch over. train_loss: 1.57; train_accuracy: 0.48 

Batch: 0; loss: 1.78; acc: 0.34
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.42; acc: 0.5
Batch: 60; loss: 1.65; acc: 0.53
Batch: 80; loss: 1.63; acc: 0.48
Batch: 100; loss: 1.49; acc: 0.5
Batch: 120; loss: 1.58; acc: 0.42
Batch: 140; loss: 1.38; acc: 0.56
Val Epoch over. val_loss: 1.5987896615532553; val_accuracy: 0.4700437898089172 

The current subspace-distance is: 3.4492582926759496e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.89; acc: 0.41
Batch: 20; loss: 1.64; acc: 0.41
Batch: 40; loss: 1.57; acc: 0.52
Batch: 60; loss: 1.47; acc: 0.48
Batch: 80; loss: 1.59; acc: 0.44
Batch: 100; loss: 1.59; acc: 0.5
Batch: 120; loss: 1.63; acc: 0.36
Batch: 140; loss: 1.77; acc: 0.42
Batch: 160; loss: 1.34; acc: 0.5
Batch: 180; loss: 1.51; acc: 0.52
Batch: 200; loss: 1.47; acc: 0.47
Batch: 220; loss: 1.52; acc: 0.53
Batch: 240; loss: 1.69; acc: 0.44
Batch: 260; loss: 1.42; acc: 0.48
Batch: 280; loss: 1.48; acc: 0.55
Batch: 300; loss: 1.75; acc: 0.47
Batch: 320; loss: 1.53; acc: 0.59
Batch: 340; loss: 1.55; acc: 0.47
Batch: 360; loss: 1.65; acc: 0.39
Batch: 380; loss: 1.89; acc: 0.44
Batch: 400; loss: 1.19; acc: 0.67
Batch: 420; loss: 1.38; acc: 0.59
Batch: 440; loss: 1.7; acc: 0.33
Batch: 460; loss: 1.52; acc: 0.44
Batch: 480; loss: 1.82; acc: 0.39
Batch: 500; loss: 1.66; acc: 0.48
Batch: 520; loss: 1.53; acc: 0.45
Batch: 540; loss: 1.49; acc: 0.48
Batch: 560; loss: 1.55; acc: 0.41
Batch: 580; loss: 1.62; acc: 0.44
Batch: 600; loss: 1.46; acc: 0.52
Batch: 620; loss: 1.69; acc: 0.47
Batch: 640; loss: 1.74; acc: 0.47
Batch: 660; loss: 1.61; acc: 0.42
Batch: 680; loss: 1.41; acc: 0.55
Batch: 700; loss: 1.46; acc: 0.52
Batch: 720; loss: 1.61; acc: 0.44
Batch: 740; loss: 1.24; acc: 0.56
Batch: 760; loss: 1.5; acc: 0.44
Batch: 780; loss: 1.63; acc: 0.47
Train Epoch over. train_loss: 1.56; train_accuracy: 0.48 

Batch: 0; loss: 1.84; acc: 0.36
Batch: 20; loss: 1.71; acc: 0.42
Batch: 40; loss: 1.53; acc: 0.41
Batch: 60; loss: 1.66; acc: 0.45
Batch: 80; loss: 1.65; acc: 0.45
Batch: 100; loss: 1.56; acc: 0.39
Batch: 120; loss: 1.73; acc: 0.39
Batch: 140; loss: 1.42; acc: 0.5
Val Epoch over. val_loss: 1.6206866965931692; val_accuracy: 0.4580015923566879 

The current subspace-distance is: 3.8256570405792445e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.97; acc: 0.31
Batch: 20; loss: 1.47; acc: 0.53
Batch: 40; loss: 1.58; acc: 0.5
Batch: 60; loss: 1.51; acc: 0.53
Batch: 80; loss: 1.47; acc: 0.56
Batch: 100; loss: 1.59; acc: 0.45
Batch: 120; loss: 1.79; acc: 0.38
Batch: 140; loss: 1.68; acc: 0.45
Batch: 160; loss: 1.86; acc: 0.48
Batch: 180; loss: 1.44; acc: 0.48
Batch: 200; loss: 1.45; acc: 0.52
Batch: 220; loss: 1.82; acc: 0.47
Batch: 240; loss: 1.66; acc: 0.48
Batch: 260; loss: 2.0; acc: 0.36
Batch: 280; loss: 1.72; acc: 0.45
Batch: 300; loss: 1.45; acc: 0.47
Batch: 320; loss: 1.32; acc: 0.56
Batch: 340; loss: 1.85; acc: 0.36
Batch: 360; loss: 1.49; acc: 0.53
Batch: 380; loss: 1.53; acc: 0.52
Batch: 400; loss: 1.64; acc: 0.45
Batch: 420; loss: 1.92; acc: 0.31
Batch: 440; loss: 1.71; acc: 0.41
Batch: 460; loss: 1.62; acc: 0.45
Batch: 480; loss: 1.56; acc: 0.39
Batch: 500; loss: 1.74; acc: 0.36
Batch: 520; loss: 1.67; acc: 0.45
Batch: 540; loss: 1.51; acc: 0.56
Batch: 560; loss: 1.42; acc: 0.5
Batch: 580; loss: 1.39; acc: 0.53
Batch: 600; loss: 1.31; acc: 0.55
Batch: 620; loss: 1.45; acc: 0.56
Batch: 640; loss: 1.49; acc: 0.44
Batch: 660; loss: 1.63; acc: 0.44
Batch: 680; loss: 1.52; acc: 0.42
Batch: 700; loss: 1.67; acc: 0.5
Batch: 720; loss: 1.46; acc: 0.56
Batch: 740; loss: 1.6; acc: 0.47
Batch: 760; loss: 1.65; acc: 0.48
Batch: 780; loss: 1.52; acc: 0.53
Train Epoch over. train_loss: 1.56; train_accuracy: 0.48 

Batch: 0; loss: 1.78; acc: 0.36
Batch: 20; loss: 1.64; acc: 0.42
Batch: 40; loss: 1.35; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.53
Batch: 80; loss: 1.48; acc: 0.52
Batch: 100; loss: 1.43; acc: 0.5
Batch: 120; loss: 1.6; acc: 0.45
Batch: 140; loss: 1.4; acc: 0.52
Val Epoch over. val_loss: 1.5368822251155878; val_accuracy: 0.4849721337579618 

The current subspace-distance is: 4.2474046495044604e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.53; acc: 0.55
Batch: 20; loss: 1.46; acc: 0.5
Batch: 40; loss: 1.74; acc: 0.42
Batch: 60; loss: 1.63; acc: 0.56
Batch: 80; loss: 1.57; acc: 0.52
Batch: 100; loss: 1.47; acc: 0.48
Batch: 120; loss: 1.66; acc: 0.39
Batch: 140; loss: 1.24; acc: 0.55
Batch: 160; loss: 1.53; acc: 0.55
Batch: 180; loss: 1.65; acc: 0.47
Batch: 200; loss: 1.58; acc: 0.47
Batch: 220; loss: 1.49; acc: 0.48
Batch: 240; loss: 1.62; acc: 0.42
Batch: 260; loss: 1.51; acc: 0.5
Batch: 280; loss: 1.56; acc: 0.44
Batch: 300; loss: 1.38; acc: 0.52
Batch: 320; loss: 1.5; acc: 0.44
Batch: 340; loss: 1.46; acc: 0.5
Batch: 360; loss: 1.57; acc: 0.5
Batch: 380; loss: 1.71; acc: 0.45
Batch: 400; loss: 1.57; acc: 0.44
Batch: 420; loss: 1.45; acc: 0.52
Batch: 440; loss: 1.67; acc: 0.47
Batch: 460; loss: 1.46; acc: 0.5
Batch: 480; loss: 1.29; acc: 0.66
Batch: 500; loss: 1.46; acc: 0.55
Batch: 520; loss: 1.68; acc: 0.44
Batch: 540; loss: 1.53; acc: 0.52
Batch: 560; loss: 1.28; acc: 0.59
Batch: 580; loss: 1.46; acc: 0.55
Batch: 600; loss: 1.62; acc: 0.45
Batch: 620; loss: 1.54; acc: 0.39
Batch: 640; loss: 1.33; acc: 0.59
Batch: 660; loss: 1.57; acc: 0.44
Batch: 680; loss: 1.65; acc: 0.45
Batch: 700; loss: 1.54; acc: 0.42
Batch: 720; loss: 1.79; acc: 0.41
Batch: 740; loss: 1.33; acc: 0.56
Batch: 760; loss: 1.71; acc: 0.41
Batch: 780; loss: 1.7; acc: 0.42
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.68; acc: 0.39
Batch: 20; loss: 1.61; acc: 0.47
Batch: 40; loss: 1.36; acc: 0.56
Batch: 60; loss: 1.46; acc: 0.55
Batch: 80; loss: 1.42; acc: 0.58
Batch: 100; loss: 1.44; acc: 0.5
Batch: 120; loss: 1.6; acc: 0.42
Batch: 140; loss: 1.32; acc: 0.56
Val Epoch over. val_loss: 1.4848799265114365; val_accuracy: 0.5063694267515924 

The current subspace-distance is: 4.5292210415937006e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.67; acc: 0.44
Batch: 20; loss: 1.58; acc: 0.48
Batch: 40; loss: 1.65; acc: 0.45
Batch: 60; loss: 1.53; acc: 0.44
Batch: 80; loss: 1.47; acc: 0.62
Batch: 100; loss: 1.56; acc: 0.47
Batch: 120; loss: 1.72; acc: 0.42
Batch: 140; loss: 1.38; acc: 0.58
Batch: 160; loss: 1.73; acc: 0.45
Batch: 180; loss: 1.6; acc: 0.55
Batch: 200; loss: 1.34; acc: 0.55
Batch: 220; loss: 1.47; acc: 0.55
Batch: 240; loss: 1.49; acc: 0.48
Batch: 260; loss: 1.62; acc: 0.47
Batch: 280; loss: 1.43; acc: 0.53
Batch: 300; loss: 1.49; acc: 0.48
Batch: 320; loss: 1.57; acc: 0.5
Batch: 340; loss: 1.18; acc: 0.62
Batch: 360; loss: 1.69; acc: 0.41
Batch: 380; loss: 1.68; acc: 0.38
Batch: 400; loss: 1.39; acc: 0.55
Batch: 420; loss: 1.66; acc: 0.42
Batch: 440; loss: 1.5; acc: 0.53
Batch: 460; loss: 1.62; acc: 0.44
Batch: 480; loss: 1.49; acc: 0.44
Batch: 500; loss: 1.49; acc: 0.53
Batch: 520; loss: 1.34; acc: 0.52
Batch: 540; loss: 1.64; acc: 0.48
Batch: 560; loss: 1.33; acc: 0.58
Batch: 580; loss: 1.75; acc: 0.45
Batch: 600; loss: 1.41; acc: 0.53
Batch: 620; loss: 1.57; acc: 0.45
Batch: 640; loss: 1.4; acc: 0.59
Batch: 660; loss: 1.49; acc: 0.53
Batch: 680; loss: 1.48; acc: 0.45
Batch: 700; loss: 1.62; acc: 0.47
Batch: 720; loss: 1.56; acc: 0.41
Batch: 740; loss: 1.76; acc: 0.39
Batch: 760; loss: 1.67; acc: 0.34
Batch: 780; loss: 1.5; acc: 0.52
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.74; acc: 0.39
Batch: 20; loss: 1.69; acc: 0.39
Batch: 40; loss: 1.39; acc: 0.55
Batch: 60; loss: 1.45; acc: 0.53
Batch: 80; loss: 1.46; acc: 0.55
Batch: 100; loss: 1.48; acc: 0.55
Batch: 120; loss: 1.7; acc: 0.39
Batch: 140; loss: 1.35; acc: 0.55
Val Epoch over. val_loss: 1.5015086953047734; val_accuracy: 0.4979100318471338 

The current subspace-distance is: 4.8923902795650065e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.63; acc: 0.42
Batch: 20; loss: 1.34; acc: 0.61
Batch: 40; loss: 1.6; acc: 0.47
Batch: 60; loss: 1.54; acc: 0.42
Batch: 80; loss: 1.46; acc: 0.56
Batch: 100; loss: 1.59; acc: 0.45
Batch: 120; loss: 1.65; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.62
Batch: 160; loss: 1.63; acc: 0.47
Batch: 180; loss: 1.59; acc: 0.38
Batch: 200; loss: 1.46; acc: 0.55
Batch: 220; loss: 1.64; acc: 0.39
Batch: 240; loss: 1.45; acc: 0.58
Batch: 260; loss: 1.58; acc: 0.44
Batch: 280; loss: 1.47; acc: 0.44
Batch: 300; loss: 1.6; acc: 0.48
Batch: 320; loss: 1.66; acc: 0.45
Batch: 340; loss: 1.59; acc: 0.45
Batch: 360; loss: 1.38; acc: 0.48
Batch: 380; loss: 1.49; acc: 0.48
Batch: 400; loss: 1.67; acc: 0.44
Batch: 420; loss: 1.48; acc: 0.55
Batch: 440; loss: 1.57; acc: 0.52
Batch: 460; loss: 1.4; acc: 0.55
Batch: 480; loss: 1.54; acc: 0.52
Batch: 500; loss: 1.56; acc: 0.5
Batch: 520; loss: 1.49; acc: 0.55
Batch: 540; loss: 1.5; acc: 0.53
Batch: 560; loss: 1.72; acc: 0.44
Batch: 580; loss: 1.5; acc: 0.38
Batch: 600; loss: 1.5; acc: 0.47
Batch: 620; loss: 1.56; acc: 0.45
Batch: 640; loss: 1.54; acc: 0.52
Batch: 660; loss: 1.65; acc: 0.42
Batch: 680; loss: 1.23; acc: 0.64
Batch: 700; loss: 1.67; acc: 0.44
Batch: 720; loss: 1.71; acc: 0.48
Batch: 740; loss: 1.52; acc: 0.47
Batch: 760; loss: 1.61; acc: 0.5
Batch: 780; loss: 1.64; acc: 0.41
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.75; acc: 0.34
Batch: 20; loss: 1.57; acc: 0.42
Batch: 40; loss: 1.35; acc: 0.55
Batch: 60; loss: 1.43; acc: 0.55
Batch: 80; loss: 1.43; acc: 0.58
Batch: 100; loss: 1.42; acc: 0.5
Batch: 120; loss: 1.54; acc: 0.48
Batch: 140; loss: 1.3; acc: 0.55
Val Epoch over. val_loss: 1.490128558912095; val_accuracy: 0.50109474522293 

The current subspace-distance is: 5.139168570167385e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.51; acc: 0.52
Batch: 20; loss: 1.52; acc: 0.47
Batch: 40; loss: 1.63; acc: 0.48
Batch: 60; loss: 1.56; acc: 0.5
Batch: 80; loss: 1.7; acc: 0.42
Batch: 100; loss: 1.39; acc: 0.58
Batch: 120; loss: 1.29; acc: 0.56
Batch: 140; loss: 1.57; acc: 0.48
Batch: 160; loss: 1.63; acc: 0.42
Batch: 180; loss: 1.58; acc: 0.55
Batch: 200; loss: 1.59; acc: 0.5
Batch: 220; loss: 1.31; acc: 0.5
Batch: 240; loss: 1.65; acc: 0.5
Batch: 260; loss: 1.67; acc: 0.42
Batch: 280; loss: 1.69; acc: 0.44
Batch: 300; loss: 1.45; acc: 0.53
Batch: 320; loss: 1.5; acc: 0.53
Batch: 340; loss: 1.35; acc: 0.58
Batch: 360; loss: 1.67; acc: 0.45
Batch: 380; loss: 1.59; acc: 0.47
Batch: 400; loss: 1.63; acc: 0.45
Batch: 420; loss: 1.47; acc: 0.48
Batch: 440; loss: 1.72; acc: 0.34
Batch: 460; loss: 1.63; acc: 0.45
Batch: 480; loss: 1.35; acc: 0.59
Batch: 500; loss: 1.66; acc: 0.44
Batch: 520; loss: 1.73; acc: 0.47
Batch: 540; loss: 1.63; acc: 0.52
Batch: 560; loss: 1.63; acc: 0.47
Batch: 580; loss: 1.47; acc: 0.47
Batch: 600; loss: 1.42; acc: 0.55
Batch: 620; loss: 1.4; acc: 0.55
Batch: 640; loss: 1.33; acc: 0.58
Batch: 660; loss: 1.46; acc: 0.48
Batch: 680; loss: 1.42; acc: 0.56
Batch: 700; loss: 1.66; acc: 0.48
Batch: 720; loss: 1.34; acc: 0.55
Batch: 740; loss: 1.46; acc: 0.52
Batch: 760; loss: 1.89; acc: 0.38
Batch: 780; loss: 1.39; acc: 0.56
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.75; acc: 0.38
Batch: 20; loss: 1.62; acc: 0.41
Batch: 40; loss: 1.34; acc: 0.59
Batch: 60; loss: 1.42; acc: 0.52
Batch: 80; loss: 1.39; acc: 0.61
Batch: 100; loss: 1.41; acc: 0.58
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.29; acc: 0.5
Val Epoch over. val_loss: 1.4786070813039305; val_accuracy: 0.5095541401273885 

The current subspace-distance is: 5.41824301762972e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.46; acc: 0.53
Batch: 20; loss: 1.51; acc: 0.52
Batch: 40; loss: 1.68; acc: 0.38
Batch: 60; loss: 1.69; acc: 0.48
Batch: 80; loss: 1.52; acc: 0.55
Batch: 100; loss: 1.47; acc: 0.5
Batch: 120; loss: 1.66; acc: 0.44
Batch: 140; loss: 1.59; acc: 0.48
Batch: 160; loss: 1.71; acc: 0.45
Batch: 180; loss: 1.59; acc: 0.45
Batch: 200; loss: 1.49; acc: 0.52
Batch: 220; loss: 1.57; acc: 0.48
Batch: 240; loss: 1.41; acc: 0.61
Batch: 260; loss: 1.51; acc: 0.48
Batch: 280; loss: 1.55; acc: 0.5
Batch: 300; loss: 1.38; acc: 0.48
Batch: 320; loss: 1.56; acc: 0.48
Batch: 340; loss: 1.56; acc: 0.45
Batch: 360; loss: 1.69; acc: 0.39
Batch: 380; loss: 1.39; acc: 0.55
Batch: 400; loss: 1.47; acc: 0.56
Batch: 420; loss: 1.68; acc: 0.45
Batch: 440; loss: 1.59; acc: 0.44
Batch: 460; loss: 1.66; acc: 0.44
Batch: 480; loss: 1.3; acc: 0.55
Batch: 500; loss: 1.75; acc: 0.38
Batch: 520; loss: 1.7; acc: 0.42
Batch: 540; loss: 1.88; acc: 0.34
Batch: 560; loss: 1.51; acc: 0.55
Batch: 580; loss: 1.57; acc: 0.55
Batch: 600; loss: 1.62; acc: 0.45
Batch: 620; loss: 1.48; acc: 0.48
Batch: 640; loss: 1.64; acc: 0.44
Batch: 660; loss: 1.49; acc: 0.48
Batch: 680; loss: 1.56; acc: 0.48
Batch: 700; loss: 1.39; acc: 0.52
Batch: 720; loss: 1.58; acc: 0.45
Batch: 740; loss: 1.63; acc: 0.45
Batch: 760; loss: 1.54; acc: 0.48
Batch: 780; loss: 1.53; acc: 0.45
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.74; acc: 0.34
Batch: 20; loss: 1.62; acc: 0.45
Batch: 40; loss: 1.33; acc: 0.56
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.59
Batch: 100; loss: 1.41; acc: 0.53
Batch: 120; loss: 1.61; acc: 0.47
Batch: 140; loss: 1.29; acc: 0.53
Val Epoch over. val_loss: 1.485527609563937; val_accuracy: 0.5043789808917197 

The current subspace-distance is: 5.751000571763143e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 1.61; acc: 0.45
Batch: 20; loss: 1.43; acc: 0.56
Batch: 40; loss: 1.61; acc: 0.5
Batch: 60; loss: 1.66; acc: 0.44
Batch: 80; loss: 1.58; acc: 0.44
Batch: 100; loss: 1.67; acc: 0.42
Batch: 120; loss: 1.68; acc: 0.36
Batch: 140; loss: 1.4; acc: 0.53
Batch: 160; loss: 1.31; acc: 0.55
Batch: 180; loss: 1.59; acc: 0.52
Batch: 200; loss: 1.42; acc: 0.62
Batch: 220; loss: 1.5; acc: 0.42
Batch: 240; loss: 1.48; acc: 0.48
Batch: 260; loss: 1.64; acc: 0.48
Batch: 280; loss: 1.55; acc: 0.47
Batch: 300; loss: 1.55; acc: 0.52
Batch: 320; loss: 1.55; acc: 0.56
Batch: 340; loss: 1.75; acc: 0.38
Batch: 360; loss: 1.76; acc: 0.41
Batch: 380; loss: 1.41; acc: 0.52
Batch: 400; loss: 1.7; acc: 0.48
Batch: 420; loss: 1.28; acc: 0.61
Batch: 440; loss: 1.45; acc: 0.55
Batch: 460; loss: 1.34; acc: 0.59
Batch: 480; loss: 1.56; acc: 0.45
Batch: 500; loss: 1.79; acc: 0.39
Batch: 520; loss: 1.81; acc: 0.41
Batch: 540; loss: 1.51; acc: 0.52
Batch: 560; loss: 1.58; acc: 0.47
Batch: 580; loss: 1.41; acc: 0.5
Batch: 600; loss: 1.49; acc: 0.48
Batch: 620; loss: 1.88; acc: 0.38
Batch: 640; loss: 1.74; acc: 0.45
Batch: 660; loss: 1.62; acc: 0.52
Batch: 680; loss: 1.49; acc: 0.48
Batch: 700; loss: 1.54; acc: 0.48
Batch: 720; loss: 1.52; acc: 0.52
Batch: 740; loss: 1.48; acc: 0.5
Batch: 760; loss: 1.59; acc: 0.48
Batch: 780; loss: 1.58; acc: 0.47
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.77; acc: 0.39
Batch: 20; loss: 1.65; acc: 0.41
Batch: 40; loss: 1.35; acc: 0.59
Batch: 60; loss: 1.4; acc: 0.53
Batch: 80; loss: 1.39; acc: 0.62
Batch: 100; loss: 1.47; acc: 0.48
Batch: 120; loss: 1.63; acc: 0.42
Batch: 140; loss: 1.3; acc: 0.52
Val Epoch over. val_loss: 1.490528107448748; val_accuracy: 0.49890525477707004 

The current subspace-distance is: 6.001977453706786e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 1.31; acc: 0.64
Batch: 20; loss: 1.48; acc: 0.48
Batch: 40; loss: 1.63; acc: 0.47
Batch: 60; loss: 1.76; acc: 0.39
Batch: 80; loss: 1.58; acc: 0.5
Batch: 100; loss: 1.46; acc: 0.55
Batch: 120; loss: 1.6; acc: 0.39
Batch: 140; loss: 1.53; acc: 0.45
Batch: 160; loss: 1.3; acc: 0.61
Batch: 180; loss: 1.41; acc: 0.53
Batch: 200; loss: 1.47; acc: 0.48
Batch: 220; loss: 1.52; acc: 0.5
Batch: 240; loss: 1.65; acc: 0.44
Batch: 260; loss: 1.76; acc: 0.38
Batch: 280; loss: 1.65; acc: 0.47
Batch: 300; loss: 1.49; acc: 0.53
Batch: 320; loss: 1.7; acc: 0.48
Batch: 340; loss: 1.57; acc: 0.47
Batch: 360; loss: 1.52; acc: 0.48
Batch: 380; loss: 1.55; acc: 0.44
Batch: 400; loss: 1.39; acc: 0.52
Batch: 420; loss: 1.75; acc: 0.48
Batch: 440; loss: 1.4; acc: 0.62
Batch: 460; loss: 1.8; acc: 0.39
Batch: 480; loss: 1.61; acc: 0.47
Batch: 500; loss: 1.47; acc: 0.5
Batch: 520; loss: 1.39; acc: 0.61
Batch: 540; loss: 1.6; acc: 0.41
Batch: 560; loss: 1.57; acc: 0.44
Batch: 580; loss: 1.45; acc: 0.53
Batch: 600; loss: 1.46; acc: 0.45
Batch: 620; loss: 1.82; acc: 0.45
Batch: 640; loss: 1.18; acc: 0.62
Batch: 660; loss: 1.51; acc: 0.53
Batch: 680; loss: 1.52; acc: 0.48
Batch: 700; loss: 1.46; acc: 0.45
Batch: 720; loss: 1.52; acc: 0.42
Batch: 740; loss: 1.61; acc: 0.45
Batch: 760; loss: 1.61; acc: 0.5
Batch: 780; loss: 1.52; acc: 0.53
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.72; acc: 0.38
Batch: 20; loss: 1.64; acc: 0.44
Batch: 40; loss: 1.34; acc: 0.56
Batch: 60; loss: 1.43; acc: 0.53
Batch: 80; loss: 1.37; acc: 0.62
Batch: 100; loss: 1.41; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.28; acc: 0.53
Val Epoch over. val_loss: 1.4695478146243248; val_accuracy: 0.5105493630573248 

The current subspace-distance is: 6.119383033365011e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 1.59; acc: 0.5
Batch: 20; loss: 1.58; acc: 0.5
Batch: 40; loss: 1.45; acc: 0.5
Batch: 60; loss: 1.38; acc: 0.58
Batch: 80; loss: 1.37; acc: 0.58
Batch: 100; loss: 1.55; acc: 0.48
Batch: 120; loss: 1.57; acc: 0.48
Batch: 140; loss: 1.46; acc: 0.5
Batch: 160; loss: 1.4; acc: 0.52
Batch: 180; loss: 1.66; acc: 0.47
Batch: 200; loss: 1.63; acc: 0.48
Batch: 220; loss: 1.71; acc: 0.42
Batch: 240; loss: 1.55; acc: 0.55
Batch: 260; loss: 1.53; acc: 0.48
Batch: 280; loss: 1.73; acc: 0.38
Batch: 300; loss: 1.53; acc: 0.44
Batch: 320; loss: 1.72; acc: 0.42
Batch: 340; loss: 1.6; acc: 0.55
Batch: 360; loss: 1.55; acc: 0.53
Batch: 380; loss: 1.42; acc: 0.5
Batch: 400; loss: 1.64; acc: 0.48
Batch: 420; loss: 1.71; acc: 0.41
Batch: 440; loss: 1.58; acc: 0.42
Batch: 460; loss: 1.42; acc: 0.5
Batch: 480; loss: 1.61; acc: 0.52
Batch: 500; loss: 1.51; acc: 0.53
Batch: 520; loss: 1.34; acc: 0.52
Batch: 540; loss: 1.42; acc: 0.56
Batch: 560; loss: 1.26; acc: 0.53
Batch: 580; loss: 1.62; acc: 0.52
Batch: 600; loss: 1.3; acc: 0.56
Batch: 620; loss: 1.68; acc: 0.53
Batch: 640; loss: 1.56; acc: 0.47
Batch: 660; loss: 1.76; acc: 0.5
Batch: 680; loss: 1.58; acc: 0.5
Batch: 700; loss: 1.34; acc: 0.55
Batch: 720; loss: 1.41; acc: 0.53
Batch: 740; loss: 1.38; acc: 0.53
Batch: 760; loss: 1.37; acc: 0.58
Batch: 780; loss: 1.6; acc: 0.5
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.78; acc: 0.38
Batch: 20; loss: 1.63; acc: 0.39
Batch: 40; loss: 1.35; acc: 0.58
Batch: 60; loss: 1.46; acc: 0.52
Batch: 80; loss: 1.42; acc: 0.59
Batch: 100; loss: 1.44; acc: 0.52
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.29; acc: 0.52
Val Epoch over. val_loss: 1.4810732572701326; val_accuracy: 0.5085589171974523 

The current subspace-distance is: 6.583178037544712e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.39; acc: 0.56
Batch: 20; loss: 1.69; acc: 0.42
Batch: 40; loss: 1.43; acc: 0.56
Batch: 60; loss: 1.37; acc: 0.59
Batch: 80; loss: 1.36; acc: 0.55
Batch: 100; loss: 1.77; acc: 0.48
Batch: 120; loss: 1.41; acc: 0.64
Batch: 140; loss: 1.39; acc: 0.52
Batch: 160; loss: 1.43; acc: 0.56
Batch: 180; loss: 1.42; acc: 0.55
Batch: 200; loss: 1.59; acc: 0.53
Batch: 220; loss: 1.56; acc: 0.5
Batch: 240; loss: 1.61; acc: 0.44
Batch: 260; loss: 1.76; acc: 0.39
Batch: 280; loss: 1.47; acc: 0.47
Batch: 300; loss: 1.71; acc: 0.44
Batch: 320; loss: 1.52; acc: 0.47
Batch: 340; loss: 1.51; acc: 0.48
Batch: 360; loss: 1.51; acc: 0.47
Batch: 380; loss: 1.5; acc: 0.5
Batch: 400; loss: 1.66; acc: 0.44
Batch: 420; loss: 1.33; acc: 0.52
Batch: 440; loss: 1.48; acc: 0.5
Batch: 460; loss: 1.54; acc: 0.52
Batch: 480; loss: 1.69; acc: 0.42
Batch: 500; loss: 1.63; acc: 0.38
Batch: 520; loss: 1.62; acc: 0.52
Batch: 540; loss: 1.55; acc: 0.5
Batch: 560; loss: 1.63; acc: 0.44
Batch: 580; loss: 1.42; acc: 0.53
Batch: 600; loss: 1.52; acc: 0.52
Batch: 620; loss: 1.64; acc: 0.47
Batch: 640; loss: 1.47; acc: 0.52
Batch: 660; loss: 1.61; acc: 0.47
Batch: 680; loss: 1.67; acc: 0.47
Batch: 700; loss: 1.56; acc: 0.5
Batch: 720; loss: 1.64; acc: 0.47
Batch: 740; loss: 1.43; acc: 0.53
Batch: 760; loss: 1.57; acc: 0.47
Batch: 780; loss: 1.76; acc: 0.45
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 1.66; acc: 0.42
Batch: 40; loss: 1.33; acc: 0.59
Batch: 60; loss: 1.39; acc: 0.52
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.45; acc: 0.5
Batch: 120; loss: 1.66; acc: 0.39
Batch: 140; loss: 1.3; acc: 0.48
Val Epoch over. val_loss: 1.4767437489928714; val_accuracy: 0.5067675159235668 

The current subspace-distance is: 6.859513086965308e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.58; acc: 0.52
Batch: 20; loss: 1.6; acc: 0.5
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.46; acc: 0.56
Batch: 80; loss: 1.86; acc: 0.45
Batch: 100; loss: 1.65; acc: 0.47
Batch: 120; loss: 1.39; acc: 0.56
Batch: 140; loss: 1.66; acc: 0.45
Batch: 160; loss: 1.66; acc: 0.47
Batch: 180; loss: 1.57; acc: 0.47
Batch: 200; loss: 1.59; acc: 0.5
Batch: 220; loss: 1.47; acc: 0.56
Batch: 240; loss: 1.64; acc: 0.52
Batch: 260; loss: 1.8; acc: 0.31
Batch: 280; loss: 1.55; acc: 0.42
Batch: 300; loss: 1.57; acc: 0.42
Batch: 320; loss: 1.59; acc: 0.48
Batch: 340; loss: 1.64; acc: 0.47
Batch: 360; loss: 1.59; acc: 0.5
Batch: 380; loss: 1.44; acc: 0.5
Batch: 400; loss: 1.59; acc: 0.52
Batch: 420; loss: 1.6; acc: 0.47
Batch: 440; loss: 1.74; acc: 0.47
Batch: 460; loss: 1.54; acc: 0.52
Batch: 480; loss: 1.56; acc: 0.48
Batch: 500; loss: 1.54; acc: 0.53
Batch: 520; loss: 1.45; acc: 0.52
Batch: 540; loss: 1.21; acc: 0.59
Batch: 560; loss: 1.56; acc: 0.47
Batch: 580; loss: 1.59; acc: 0.42
Batch: 600; loss: 1.51; acc: 0.5
Batch: 620; loss: 1.47; acc: 0.48
Batch: 640; loss: 1.46; acc: 0.53
Batch: 660; loss: 1.41; acc: 0.55
Batch: 680; loss: 1.55; acc: 0.5
Batch: 700; loss: 1.62; acc: 0.5
Batch: 720; loss: 1.38; acc: 0.59
Batch: 740; loss: 1.81; acc: 0.36
Batch: 760; loss: 1.4; acc: 0.53
Batch: 780; loss: 1.76; acc: 0.44
Train Epoch over. train_loss: 1.54; train_accuracy: 0.49 

Batch: 0; loss: 1.73; acc: 0.38
Batch: 20; loss: 1.61; acc: 0.48
Batch: 40; loss: 1.33; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.44; acc: 0.5
Batch: 120; loss: 1.61; acc: 0.42
Batch: 140; loss: 1.28; acc: 0.55
Val Epoch over. val_loss: 1.4696191807461392; val_accuracy: 0.511843152866242 

The current subspace-distance is: 7.138928776839748e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.48; acc: 0.58
Batch: 20; loss: 1.48; acc: 0.53
Batch: 40; loss: 1.66; acc: 0.41
Batch: 60; loss: 1.44; acc: 0.53
Batch: 80; loss: 1.46; acc: 0.58
Batch: 100; loss: 1.47; acc: 0.52
Batch: 120; loss: 1.52; acc: 0.56
Batch: 140; loss: 1.47; acc: 0.5
Batch: 160; loss: 1.66; acc: 0.48
Batch: 180; loss: 1.76; acc: 0.44
Batch: 200; loss: 1.54; acc: 0.44
Batch: 220; loss: 1.36; acc: 0.53
Batch: 240; loss: 1.53; acc: 0.42
Batch: 260; loss: 1.43; acc: 0.55
Batch: 280; loss: 1.63; acc: 0.42
Batch: 300; loss: 1.75; acc: 0.41
Batch: 320; loss: 1.36; acc: 0.55
Batch: 340; loss: 1.37; acc: 0.59
Batch: 360; loss: 1.29; acc: 0.59
Batch: 380; loss: 1.51; acc: 0.5
Batch: 400; loss: 1.3; acc: 0.58
Batch: 420; loss: 1.55; acc: 0.44
Batch: 440; loss: 1.43; acc: 0.58
Batch: 460; loss: 1.29; acc: 0.55
Batch: 480; loss: 1.52; acc: 0.53
Batch: 500; loss: 1.86; acc: 0.41
Batch: 520; loss: 1.38; acc: 0.53
Batch: 540; loss: 1.29; acc: 0.56
Batch: 560; loss: 1.21; acc: 0.59
Batch: 580; loss: 1.32; acc: 0.55
Batch: 600; loss: 1.51; acc: 0.53
Batch: 620; loss: 1.4; acc: 0.5
Batch: 640; loss: 1.82; acc: 0.39
Batch: 660; loss: 1.48; acc: 0.45
Batch: 680; loss: 1.6; acc: 0.48
Batch: 700; loss: 1.57; acc: 0.52
Batch: 720; loss: 1.69; acc: 0.39
Batch: 740; loss: 1.68; acc: 0.44
Batch: 760; loss: 1.44; acc: 0.48
Batch: 780; loss: 1.21; acc: 0.62
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.75; acc: 0.41
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.33; acc: 0.59
Batch: 60; loss: 1.4; acc: 0.52
Batch: 80; loss: 1.37; acc: 0.62
Batch: 100; loss: 1.44; acc: 0.53
Batch: 120; loss: 1.59; acc: 0.42
Batch: 140; loss: 1.27; acc: 0.48
Val Epoch over. val_loss: 1.468401743348237; val_accuracy: 0.5094546178343949 

The current subspace-distance is: 7.214213837869465e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.62; acc: 0.47
Batch: 20; loss: 1.48; acc: 0.44
Batch: 40; loss: 1.41; acc: 0.55
Batch: 60; loss: 1.4; acc: 0.45
Batch: 80; loss: 1.69; acc: 0.42
Batch: 100; loss: 1.65; acc: 0.5
Batch: 120; loss: 1.64; acc: 0.48
Batch: 140; loss: 1.6; acc: 0.44
Batch: 160; loss: 1.5; acc: 0.52
Batch: 180; loss: 1.48; acc: 0.47
Batch: 200; loss: 1.49; acc: 0.55
Batch: 220; loss: 1.78; acc: 0.38
Batch: 240; loss: 1.37; acc: 0.53
Batch: 260; loss: 1.46; acc: 0.52
Batch: 280; loss: 1.3; acc: 0.56
Batch: 300; loss: 1.33; acc: 0.59
Batch: 320; loss: 1.6; acc: 0.44
Batch: 340; loss: 1.62; acc: 0.45
Batch: 360; loss: 1.45; acc: 0.48
Batch: 380; loss: 1.45; acc: 0.52
Batch: 400; loss: 1.69; acc: 0.44
Batch: 420; loss: 1.75; acc: 0.42
Batch: 440; loss: 1.4; acc: 0.58
Batch: 460; loss: 1.58; acc: 0.45
Batch: 480; loss: 1.67; acc: 0.44
Batch: 500; loss: 1.52; acc: 0.52
Batch: 520; loss: 1.5; acc: 0.47
Batch: 540; loss: 1.57; acc: 0.52
Batch: 560; loss: 1.37; acc: 0.53
Batch: 580; loss: 1.46; acc: 0.47
Batch: 600; loss: 1.52; acc: 0.48
Batch: 620; loss: 1.45; acc: 0.52
Batch: 640; loss: 1.43; acc: 0.56
Batch: 660; loss: 1.66; acc: 0.52
Batch: 680; loss: 1.49; acc: 0.58
Batch: 700; loss: 1.29; acc: 0.69
Batch: 720; loss: 1.45; acc: 0.44
Batch: 740; loss: 1.67; acc: 0.47
Batch: 760; loss: 1.51; acc: 0.55
Batch: 780; loss: 1.41; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

Batch: 0; loss: 1.77; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.33; acc: 0.56
Batch: 60; loss: 1.42; acc: 0.5
Batch: 80; loss: 1.39; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.63; acc: 0.41
Batch: 140; loss: 1.28; acc: 0.52
Val Epoch over. val_loss: 1.4679195045665572; val_accuracy: 0.5125398089171974 

The current subspace-distance is: 7.307922351174057e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.5; acc: 0.53
Batch: 20; loss: 1.59; acc: 0.47
Batch: 40; loss: 1.48; acc: 0.52
Batch: 60; loss: 1.62; acc: 0.53
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.3; acc: 0.61
Batch: 120; loss: 1.54; acc: 0.59
Batch: 140; loss: 1.59; acc: 0.45
Batch: 160; loss: 1.49; acc: 0.52
Batch: 180; loss: 1.31; acc: 0.53
Batch: 200; loss: 1.58; acc: 0.44
Batch: 220; loss: 1.44; acc: 0.58
Batch: 240; loss: 1.62; acc: 0.44
Batch: 260; loss: 1.53; acc: 0.44
Batch: 280; loss: 1.67; acc: 0.44
Batch: 300; loss: 1.34; acc: 0.56
Batch: 320; loss: 1.46; acc: 0.52
Batch: 340; loss: 1.37; acc: 0.53
Batch: 360; loss: 1.58; acc: 0.44
Batch: 380; loss: 1.26; acc: 0.59
Batch: 400; loss: 1.7; acc: 0.44
Batch: 420; loss: 1.59; acc: 0.47
Batch: 440; loss: 1.28; acc: 0.61
Batch: 460; loss: 1.61; acc: 0.44
Batch: 480; loss: 1.59; acc: 0.52
Batch: 500; loss: 1.49; acc: 0.5
Batch: 520; loss: 1.55; acc: 0.47
Batch: 540; loss: 1.65; acc: 0.47
Batch: 560; loss: 1.66; acc: 0.44
Batch: 580; loss: 1.49; acc: 0.55
Batch: 600; loss: 1.48; acc: 0.56
Batch: 620; loss: 1.48; acc: 0.53
Batch: 640; loss: 1.66; acc: 0.41
Batch: 660; loss: 1.48; acc: 0.45
Batch: 680; loss: 1.59; acc: 0.47
Batch: 700; loss: 1.55; acc: 0.56
Batch: 720; loss: 1.62; acc: 0.45
Batch: 740; loss: 1.43; acc: 0.53
Batch: 760; loss: 1.53; acc: 0.53
Batch: 780; loss: 1.72; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

Batch: 0; loss: 1.77; acc: 0.34
Batch: 20; loss: 1.64; acc: 0.44
Batch: 40; loss: 1.34; acc: 0.56
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.38; acc: 0.59
Batch: 100; loss: 1.44; acc: 0.48
Batch: 120; loss: 1.65; acc: 0.41
Batch: 140; loss: 1.29; acc: 0.52
Val Epoch over. val_loss: 1.4712716682701354; val_accuracy: 0.5052746815286624 

The current subspace-distance is: 7.61042902013287e-05 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.54; acc: 0.41
Batch: 20; loss: 1.49; acc: 0.52
Batch: 40; loss: 1.51; acc: 0.52
Batch: 60; loss: 1.42; acc: 0.48
Batch: 80; loss: 1.28; acc: 0.62
Batch: 100; loss: 1.49; acc: 0.53
Batch: 120; loss: 1.36; acc: 0.64
Batch: 140; loss: 1.68; acc: 0.47
Batch: 160; loss: 1.42; acc: 0.58
Batch: 180; loss: 1.66; acc: 0.45
Batch: 200; loss: 1.44; acc: 0.53
Batch: 220; loss: 1.51; acc: 0.5
Batch: 240; loss: 1.46; acc: 0.5
Batch: 260; loss: 1.37; acc: 0.48
Batch: 280; loss: 1.52; acc: 0.55
Batch: 300; loss: 1.51; acc: 0.5
Batch: 320; loss: 1.62; acc: 0.48
Batch: 340; loss: 1.73; acc: 0.41
Batch: 360; loss: 1.51; acc: 0.52
Batch: 380; loss: 1.69; acc: 0.47
Batch: 400; loss: 1.51; acc: 0.52
Batch: 420; loss: 1.23; acc: 0.56
Batch: 440; loss: 1.59; acc: 0.45
Batch: 460; loss: 1.74; acc: 0.42
Batch: 480; loss: 1.49; acc: 0.48
Batch: 500; loss: 1.45; acc: 0.5
Batch: 520; loss: 1.41; acc: 0.55
Batch: 540; loss: 1.51; acc: 0.48
Batch: 560; loss: 1.39; acc: 0.5
Batch: 580; loss: 1.56; acc: 0.44
Batch: 600; loss: 1.59; acc: 0.5
Batch: 620; loss: 1.26; acc: 0.55
Batch: 640; loss: 1.43; acc: 0.48
Batch: 660; loss: 1.56; acc: 0.45
Batch: 680; loss: 1.39; acc: 0.59
Batch: 700; loss: 1.33; acc: 0.55
Batch: 720; loss: 1.53; acc: 0.5
Batch: 740; loss: 1.71; acc: 0.34
Batch: 760; loss: 1.39; acc: 0.5
Batch: 780; loss: 1.58; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

Batch: 0; loss: 1.76; acc: 0.36
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.33; acc: 0.56
Batch: 60; loss: 1.43; acc: 0.5
Batch: 80; loss: 1.38; acc: 0.62
Batch: 100; loss: 1.42; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.48
Val Epoch over. val_loss: 1.4647899440899017; val_accuracy: 0.5130374203821656 

The current subspace-distance is: 7.983587420312688e-05 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.29; acc: 0.58
Batch: 20; loss: 1.36; acc: 0.56
Batch: 40; loss: 1.5; acc: 0.48
Batch: 60; loss: 1.53; acc: 0.48
Batch: 80; loss: 1.48; acc: 0.48
Batch: 100; loss: 1.56; acc: 0.48
Batch: 120; loss: 1.57; acc: 0.42
Batch: 140; loss: 1.44; acc: 0.55
Batch: 160; loss: 1.53; acc: 0.47
Batch: 180; loss: 1.68; acc: 0.44
Batch: 200; loss: 1.53; acc: 0.52
Batch: 220; loss: 1.62; acc: 0.41
Batch: 240; loss: 1.16; acc: 0.69
Batch: 260; loss: 1.38; acc: 0.56
Batch: 280; loss: 1.57; acc: 0.44
Batch: 300; loss: 1.39; acc: 0.55
Batch: 320; loss: 1.48; acc: 0.55
Batch: 340; loss: 1.45; acc: 0.5
Batch: 360; loss: 1.72; acc: 0.38
Batch: 380; loss: 1.39; acc: 0.53
Batch: 400; loss: 1.59; acc: 0.42
Batch: 420; loss: 1.69; acc: 0.44
Batch: 440; loss: 1.76; acc: 0.44
Batch: 460; loss: 1.53; acc: 0.55
Batch: 480; loss: 1.43; acc: 0.53
Batch: 500; loss: 1.58; acc: 0.41
Batch: 520; loss: 1.57; acc: 0.42
Batch: 540; loss: 1.72; acc: 0.5
Batch: 560; loss: 1.55; acc: 0.55
Batch: 580; loss: 1.56; acc: 0.55
Batch: 600; loss: 1.66; acc: 0.48
Batch: 620; loss: 1.48; acc: 0.52
Batch: 640; loss: 1.58; acc: 0.47
Batch: 660; loss: 1.65; acc: 0.36
Batch: 680; loss: 1.41; acc: 0.59
Batch: 700; loss: 1.55; acc: 0.45
Batch: 720; loss: 1.63; acc: 0.48
Batch: 740; loss: 1.38; acc: 0.53
Batch: 760; loss: 1.41; acc: 0.47
Batch: 780; loss: 1.36; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.42; acc: 0.5
Batch: 80; loss: 1.38; acc: 0.61
Batch: 100; loss: 1.41; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.28; acc: 0.53
Val Epoch over. val_loss: 1.4652681259592628; val_accuracy: 0.5158240445859873 

The current subspace-distance is: 8.183467434719205e-05 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.48; acc: 0.56
Batch: 20; loss: 1.37; acc: 0.56
Batch: 40; loss: 1.37; acc: 0.61
Batch: 60; loss: 1.61; acc: 0.44
Batch: 80; loss: 1.36; acc: 0.53
Batch: 100; loss: 1.41; acc: 0.56
Batch: 120; loss: 1.42; acc: 0.5
Batch: 140; loss: 1.56; acc: 0.45
Batch: 160; loss: 1.5; acc: 0.42
Batch: 180; loss: 1.44; acc: 0.44
Batch: 200; loss: 1.35; acc: 0.55
Batch: 220; loss: 1.79; acc: 0.42
Batch: 240; loss: 1.28; acc: 0.58
Batch: 260; loss: 1.41; acc: 0.5
Batch: 280; loss: 1.57; acc: 0.48
Batch: 300; loss: 1.73; acc: 0.44
Batch: 320; loss: 1.58; acc: 0.47
Batch: 340; loss: 1.59; acc: 0.42
Batch: 360; loss: 1.49; acc: 0.55
Batch: 380; loss: 1.66; acc: 0.44
Batch: 400; loss: 1.32; acc: 0.58
Batch: 420; loss: 1.59; acc: 0.52
Batch: 440; loss: 1.68; acc: 0.44
Batch: 460; loss: 1.46; acc: 0.53
Batch: 480; loss: 1.44; acc: 0.47
Batch: 500; loss: 1.49; acc: 0.5
Batch: 520; loss: 1.78; acc: 0.39
Batch: 540; loss: 1.67; acc: 0.47
Batch: 560; loss: 1.3; acc: 0.58
Batch: 580; loss: 1.77; acc: 0.45
Batch: 600; loss: 1.61; acc: 0.45
Batch: 620; loss: 1.55; acc: 0.52
Batch: 640; loss: 1.6; acc: 0.45
Batch: 660; loss: 1.78; acc: 0.44
Batch: 680; loss: 1.49; acc: 0.38
Batch: 700; loss: 1.87; acc: 0.38
Batch: 720; loss: 1.55; acc: 0.48
Batch: 740; loss: 1.77; acc: 0.38
Batch: 760; loss: 1.81; acc: 0.28
Batch: 780; loss: 1.43; acc: 0.58
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.77; acc: 0.36
Batch: 20; loss: 1.64; acc: 0.45
Batch: 40; loss: 1.35; acc: 0.55
Batch: 60; loss: 1.44; acc: 0.55
Batch: 80; loss: 1.4; acc: 0.59
Batch: 100; loss: 1.45; acc: 0.55
Batch: 120; loss: 1.66; acc: 0.44
Batch: 140; loss: 1.3; acc: 0.52
Val Epoch over. val_loss: 1.477461004712779; val_accuracy: 0.5134355095541401 

The current subspace-distance is: 8.39207204990089e-05 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.73; acc: 0.45
Batch: 20; loss: 1.5; acc: 0.47
Batch: 40; loss: 1.52; acc: 0.47
Batch: 60; loss: 1.65; acc: 0.45
Batch: 80; loss: 1.32; acc: 0.64
Batch: 100; loss: 1.78; acc: 0.33
Batch: 120; loss: 1.71; acc: 0.47
Batch: 140; loss: 1.52; acc: 0.52
Batch: 160; loss: 1.3; acc: 0.58
Batch: 180; loss: 1.45; acc: 0.48
Batch: 200; loss: 1.4; acc: 0.5
Batch: 220; loss: 1.45; acc: 0.53
Batch: 240; loss: 1.48; acc: 0.53
Batch: 260; loss: 1.42; acc: 0.55
Batch: 280; loss: 1.55; acc: 0.52
Batch: 300; loss: 1.45; acc: 0.56
Batch: 320; loss: 1.53; acc: 0.5
Batch: 340; loss: 1.71; acc: 0.41
Batch: 360; loss: 1.68; acc: 0.52
Batch: 380; loss: 1.82; acc: 0.34
Batch: 400; loss: 1.33; acc: 0.53
Batch: 420; loss: 1.62; acc: 0.45
Batch: 440; loss: 1.41; acc: 0.58
Batch: 460; loss: 1.54; acc: 0.53
Batch: 480; loss: 1.28; acc: 0.58
Batch: 500; loss: 1.53; acc: 0.47
Batch: 520; loss: 1.34; acc: 0.55
Batch: 540; loss: 1.53; acc: 0.53
Batch: 560; loss: 1.57; acc: 0.48
Batch: 580; loss: 1.65; acc: 0.48
Batch: 600; loss: 1.26; acc: 0.61
Batch: 620; loss: 1.31; acc: 0.61
Batch: 640; loss: 1.67; acc: 0.55
Batch: 660; loss: 1.59; acc: 0.52
Batch: 680; loss: 1.58; acc: 0.45
Batch: 700; loss: 1.45; acc: 0.5
Batch: 720; loss: 1.77; acc: 0.44
Batch: 740; loss: 1.52; acc: 0.56
Batch: 760; loss: 1.51; acc: 0.5
Batch: 780; loss: 1.51; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.75; acc: 0.39
Batch: 20; loss: 1.64; acc: 0.44
Batch: 40; loss: 1.33; acc: 0.58
Batch: 60; loss: 1.4; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.45; acc: 0.5
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.28; acc: 0.53
Val Epoch over. val_loss: 1.467241621321174; val_accuracy: 0.5135350318471338 

The current subspace-distance is: 8.764996164245531e-05 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.45; acc: 0.44
Batch: 20; loss: 1.5; acc: 0.5
Batch: 40; loss: 1.5; acc: 0.53
Batch: 60; loss: 1.52; acc: 0.48
Batch: 80; loss: 1.51; acc: 0.52
Batch: 100; loss: 1.55; acc: 0.48
Batch: 120; loss: 1.7; acc: 0.47
Batch: 140; loss: 1.2; acc: 0.62
Batch: 160; loss: 1.44; acc: 0.5
Batch: 180; loss: 1.84; acc: 0.44
Batch: 200; loss: 1.36; acc: 0.61
Batch: 220; loss: 1.35; acc: 0.55
Batch: 240; loss: 1.43; acc: 0.52
Batch: 260; loss: 1.42; acc: 0.58
Batch: 280; loss: 1.43; acc: 0.55
Batch: 300; loss: 1.46; acc: 0.59
Batch: 320; loss: 1.62; acc: 0.41
Batch: 340; loss: 1.72; acc: 0.47
Batch: 360; loss: 1.88; acc: 0.41
Batch: 380; loss: 1.57; acc: 0.38
Batch: 400; loss: 1.57; acc: 0.48
Batch: 420; loss: 1.71; acc: 0.5
Batch: 440; loss: 1.43; acc: 0.56
Batch: 460; loss: 1.62; acc: 0.45
Batch: 480; loss: 1.36; acc: 0.53
Batch: 500; loss: 1.44; acc: 0.5
Batch: 520; loss: 1.41; acc: 0.5
Batch: 540; loss: 1.75; acc: 0.44
Batch: 560; loss: 1.64; acc: 0.45
Batch: 580; loss: 1.23; acc: 0.64
Batch: 600; loss: 1.51; acc: 0.47
Batch: 620; loss: 1.68; acc: 0.44
Batch: 640; loss: 1.63; acc: 0.52
Batch: 660; loss: 1.45; acc: 0.52
Batch: 680; loss: 1.53; acc: 0.47
Batch: 700; loss: 1.73; acc: 0.53
Batch: 720; loss: 1.52; acc: 0.53
Batch: 740; loss: 1.59; acc: 0.53
Batch: 760; loss: 1.55; acc: 0.5
Batch: 780; loss: 1.64; acc: 0.48
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 1.62; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.42; acc: 0.5
Batch: 80; loss: 1.38; acc: 0.61
Batch: 100; loss: 1.42; acc: 0.5
Batch: 120; loss: 1.61; acc: 0.39
Batch: 140; loss: 1.28; acc: 0.52
Val Epoch over. val_loss: 1.4650272988969353; val_accuracy: 0.5100517515923567 

The current subspace-distance is: 9.056436101673171e-05 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.58; acc: 0.55
Batch: 20; loss: 1.39; acc: 0.62
Batch: 40; loss: 1.49; acc: 0.47
Batch: 60; loss: 1.53; acc: 0.48
Batch: 80; loss: 1.38; acc: 0.48
Batch: 100; loss: 1.48; acc: 0.48
Batch: 120; loss: 1.43; acc: 0.52
Batch: 140; loss: 1.64; acc: 0.48
Batch: 160; loss: 1.49; acc: 0.53
Batch: 180; loss: 1.56; acc: 0.42
Batch: 200; loss: 1.5; acc: 0.56
Batch: 220; loss: 1.56; acc: 0.5
Batch: 240; loss: 1.72; acc: 0.47
Batch: 260; loss: 1.41; acc: 0.52
Batch: 280; loss: 1.73; acc: 0.45
Batch: 300; loss: 1.6; acc: 0.48
Batch: 320; loss: 1.73; acc: 0.42
Batch: 340; loss: 1.39; acc: 0.5
Batch: 360; loss: 1.35; acc: 0.56
Batch: 380; loss: 1.46; acc: 0.56
Batch: 400; loss: 1.54; acc: 0.5
Batch: 420; loss: 1.8; acc: 0.39
Batch: 440; loss: 1.57; acc: 0.5
Batch: 460; loss: 1.45; acc: 0.5
Batch: 480; loss: 1.74; acc: 0.39
Batch: 500; loss: 1.45; acc: 0.5
Batch: 520; loss: 1.59; acc: 0.48
Batch: 540; loss: 1.66; acc: 0.41
Batch: 560; loss: 1.34; acc: 0.55
Batch: 580; loss: 1.35; acc: 0.59
Batch: 600; loss: 1.49; acc: 0.48
Batch: 620; loss: 1.71; acc: 0.39
Batch: 640; loss: 1.54; acc: 0.56
Batch: 660; loss: 1.41; acc: 0.55
Batch: 680; loss: 1.37; acc: 0.61
Batch: 700; loss: 1.51; acc: 0.56
Batch: 720; loss: 1.75; acc: 0.39
Batch: 740; loss: 1.49; acc: 0.39
Batch: 760; loss: 1.52; acc: 0.44
Batch: 780; loss: 1.41; acc: 0.53
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

Batch: 0; loss: 1.75; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.44; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.36
Batch: 140; loss: 1.27; acc: 0.53
Val Epoch over. val_loss: 1.4639036898400373; val_accuracy: 0.512937898089172 

The current subspace-distance is: 8.971465285867453e-05 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.73; acc: 0.44
Batch: 20; loss: 1.44; acc: 0.53
Batch: 40; loss: 1.82; acc: 0.36
Batch: 60; loss: 1.59; acc: 0.47
Batch: 80; loss: 1.56; acc: 0.44
Batch: 100; loss: 1.48; acc: 0.53
Batch: 120; loss: 1.61; acc: 0.42
Batch: 140; loss: 1.5; acc: 0.48
Batch: 160; loss: 1.52; acc: 0.52
Batch: 180; loss: 1.72; acc: 0.47
Batch: 200; loss: 1.62; acc: 0.39
Batch: 220; loss: 1.53; acc: 0.56
Batch: 240; loss: 1.78; acc: 0.39
Batch: 260; loss: 1.35; acc: 0.52
Batch: 280; loss: 1.43; acc: 0.55
Batch: 300; loss: 1.37; acc: 0.61
Batch: 320; loss: 1.75; acc: 0.41
Batch: 340; loss: 1.54; acc: 0.52
Batch: 360; loss: 1.56; acc: 0.5
Batch: 380; loss: 1.57; acc: 0.5
Batch: 400; loss: 1.6; acc: 0.44
Batch: 420; loss: 1.5; acc: 0.56
Batch: 440; loss: 1.62; acc: 0.42
Batch: 460; loss: 1.43; acc: 0.61
Batch: 480; loss: 1.85; acc: 0.38
Batch: 500; loss: 1.57; acc: 0.45
Batch: 520; loss: 1.4; acc: 0.64
Batch: 540; loss: 1.52; acc: 0.44
Batch: 560; loss: 1.42; acc: 0.55
Batch: 580; loss: 1.5; acc: 0.44
Batch: 600; loss: 1.48; acc: 0.47
Batch: 620; loss: 1.52; acc: 0.52
Batch: 640; loss: 1.62; acc: 0.47
Batch: 660; loss: 1.73; acc: 0.42
Batch: 680; loss: 1.51; acc: 0.53
Batch: 700; loss: 1.69; acc: 0.41
Batch: 720; loss: 1.67; acc: 0.42
Batch: 740; loss: 1.52; acc: 0.52
Batch: 760; loss: 1.47; acc: 0.48
Batch: 780; loss: 1.53; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.49 

Batch: 0; loss: 1.75; acc: 0.41
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.42; acc: 0.48
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.52
Val Epoch over. val_loss: 1.462494379395892; val_accuracy: 0.5109474522292994 

The current subspace-distance is: 9.285710984840989e-05 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.32; acc: 0.64
Batch: 20; loss: 1.34; acc: 0.62
Batch: 40; loss: 1.57; acc: 0.5
Batch: 60; loss: 1.5; acc: 0.52
Batch: 80; loss: 1.7; acc: 0.45
Batch: 100; loss: 1.44; acc: 0.48
Batch: 120; loss: 1.33; acc: 0.58
Batch: 140; loss: 1.36; acc: 0.59
Batch: 160; loss: 1.72; acc: 0.45
Batch: 180; loss: 1.38; acc: 0.48
Batch: 200; loss: 1.51; acc: 0.44
Batch: 220; loss: 1.48; acc: 0.52
Batch: 240; loss: 1.5; acc: 0.52
Batch: 260; loss: 1.36; acc: 0.58
Batch: 280; loss: 1.62; acc: 0.45
Batch: 300; loss: 1.6; acc: 0.45
Batch: 320; loss: 1.6; acc: 0.45
Batch: 340; loss: 1.32; acc: 0.53
Batch: 360; loss: 1.84; acc: 0.44
Batch: 380; loss: 1.68; acc: 0.47
Batch: 400; loss: 1.7; acc: 0.42
Batch: 420; loss: 1.51; acc: 0.45
Batch: 440; loss: 1.5; acc: 0.53
Batch: 460; loss: 1.78; acc: 0.41
Batch: 480; loss: 1.68; acc: 0.48
Batch: 500; loss: 1.56; acc: 0.47
Batch: 520; loss: 1.53; acc: 0.5
Batch: 540; loss: 1.55; acc: 0.48
Batch: 560; loss: 1.67; acc: 0.44
Batch: 580; loss: 1.67; acc: 0.5
Batch: 600; loss: 1.31; acc: 0.62
Batch: 620; loss: 1.32; acc: 0.58
Batch: 640; loss: 1.55; acc: 0.55
Batch: 660; loss: 1.49; acc: 0.45
Batch: 680; loss: 1.74; acc: 0.44
Batch: 700; loss: 1.63; acc: 0.44
Batch: 720; loss: 1.45; acc: 0.5
Batch: 740; loss: 1.5; acc: 0.52
Batch: 760; loss: 1.61; acc: 0.58
Batch: 780; loss: 1.38; acc: 0.64
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.75; acc: 0.38
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.62
Batch: 100; loss: 1.42; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.52
Val Epoch over. val_loss: 1.4629121844176274; val_accuracy: 0.5125398089171974 

The current subspace-distance is: 9.363888966618106e-05 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.76; acc: 0.42
Batch: 20; loss: 1.61; acc: 0.45
Batch: 40; loss: 1.54; acc: 0.5
Batch: 60; loss: 1.67; acc: 0.45
Batch: 80; loss: 1.41; acc: 0.53
Batch: 100; loss: 1.42; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.45
Batch: 140; loss: 1.48; acc: 0.59
Batch: 160; loss: 1.52; acc: 0.52
Batch: 180; loss: 1.57; acc: 0.45
Batch: 200; loss: 1.65; acc: 0.47
Batch: 220; loss: 1.73; acc: 0.42
Batch: 240; loss: 1.6; acc: 0.53
Batch: 260; loss: 1.58; acc: 0.53
Batch: 280; loss: 1.69; acc: 0.45
Batch: 300; loss: 1.61; acc: 0.5
Batch: 320; loss: 1.37; acc: 0.59
Batch: 340; loss: 1.53; acc: 0.5
Batch: 360; loss: 1.64; acc: 0.47
Batch: 380; loss: 1.73; acc: 0.52
Batch: 400; loss: 1.56; acc: 0.44
Batch: 420; loss: 1.38; acc: 0.53
Batch: 440; loss: 1.54; acc: 0.47
Batch: 460; loss: 1.37; acc: 0.58
Batch: 480; loss: 1.44; acc: 0.56
Batch: 500; loss: 1.8; acc: 0.44
Batch: 520; loss: 1.85; acc: 0.41
Batch: 540; loss: 1.52; acc: 0.52
Batch: 560; loss: 1.69; acc: 0.42
Batch: 580; loss: 1.39; acc: 0.58
Batch: 600; loss: 1.81; acc: 0.44
Batch: 620; loss: 1.41; acc: 0.45
Batch: 640; loss: 1.54; acc: 0.41
Batch: 660; loss: 1.66; acc: 0.5
Batch: 680; loss: 1.62; acc: 0.39
Batch: 700; loss: 1.73; acc: 0.42
Batch: 720; loss: 1.59; acc: 0.48
Batch: 740; loss: 1.49; acc: 0.47
Batch: 760; loss: 1.43; acc: 0.48
Batch: 780; loss: 1.73; acc: 0.47
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.42; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.26; acc: 0.56
Val Epoch over. val_loss: 1.4613371821725445; val_accuracy: 0.5134355095541401 

The current subspace-distance is: 9.59474200499244e-05 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.45; acc: 0.5
Batch: 20; loss: 1.82; acc: 0.38
Batch: 40; loss: 1.77; acc: 0.44
Batch: 60; loss: 1.56; acc: 0.45
Batch: 80; loss: 1.52; acc: 0.56
Batch: 100; loss: 1.83; acc: 0.42
Batch: 120; loss: 1.39; acc: 0.53
Batch: 140; loss: 1.61; acc: 0.41
Batch: 160; loss: 1.47; acc: 0.52
Batch: 180; loss: 1.38; acc: 0.52
Batch: 200; loss: 1.65; acc: 0.36
Batch: 220; loss: 1.5; acc: 0.5
Batch: 240; loss: 1.31; acc: 0.53
Batch: 260; loss: 1.42; acc: 0.52
Batch: 280; loss: 1.43; acc: 0.45
Batch: 300; loss: 1.33; acc: 0.58
Batch: 320; loss: 1.52; acc: 0.56
Batch: 340; loss: 1.49; acc: 0.45
Batch: 360; loss: 1.63; acc: 0.45
Batch: 380; loss: 1.61; acc: 0.48
Batch: 400; loss: 1.77; acc: 0.39
Batch: 420; loss: 1.55; acc: 0.41
Batch: 440; loss: 1.51; acc: 0.52
Batch: 460; loss: 1.49; acc: 0.48
Batch: 480; loss: 1.56; acc: 0.44
Batch: 500; loss: 1.34; acc: 0.56
Batch: 520; loss: 1.59; acc: 0.44
Batch: 540; loss: 1.54; acc: 0.48
Batch: 560; loss: 1.32; acc: 0.56
Batch: 580; loss: 1.47; acc: 0.53
Batch: 600; loss: 1.66; acc: 0.45
Batch: 620; loss: 1.55; acc: 0.55
Batch: 640; loss: 1.5; acc: 0.48
Batch: 660; loss: 1.63; acc: 0.44
Batch: 680; loss: 1.57; acc: 0.47
Batch: 700; loss: 1.44; acc: 0.56
Batch: 720; loss: 1.56; acc: 0.52
Batch: 740; loss: 1.33; acc: 0.55
Batch: 760; loss: 1.25; acc: 0.66
Batch: 780; loss: 1.38; acc: 0.53
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.75; acc: 0.41
Batch: 20; loss: 1.63; acc: 0.44
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.27; acc: 0.52
Val Epoch over. val_loss: 1.4629973856506833; val_accuracy: 0.5116441082802548 

The current subspace-distance is: 0.00010189404565608129 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.62; acc: 0.47
Batch: 20; loss: 1.61; acc: 0.45
Batch: 40; loss: 1.29; acc: 0.56
Batch: 60; loss: 1.63; acc: 0.38
Batch: 80; loss: 1.47; acc: 0.42
Batch: 100; loss: 1.38; acc: 0.56
Batch: 120; loss: 1.22; acc: 0.64
Batch: 140; loss: 1.42; acc: 0.48
Batch: 160; loss: 1.35; acc: 0.62
Batch: 180; loss: 1.47; acc: 0.59
Batch: 200; loss: 1.29; acc: 0.58
Batch: 220; loss: 1.6; acc: 0.5
Batch: 240; loss: 1.59; acc: 0.42
Batch: 260; loss: 1.61; acc: 0.5
Batch: 280; loss: 1.57; acc: 0.61
Batch: 300; loss: 1.6; acc: 0.48
Batch: 320; loss: 1.53; acc: 0.52
Batch: 340; loss: 1.45; acc: 0.55
Batch: 360; loss: 1.52; acc: 0.42
Batch: 380; loss: 1.51; acc: 0.56
Batch: 400; loss: 1.35; acc: 0.62
Batch: 420; loss: 1.36; acc: 0.56
Batch: 440; loss: 1.99; acc: 0.39
Batch: 460; loss: 1.57; acc: 0.47
Batch: 480; loss: 1.64; acc: 0.45
Batch: 500; loss: 1.44; acc: 0.53
Batch: 520; loss: 1.51; acc: 0.52
Batch: 540; loss: 1.78; acc: 0.45
Batch: 560; loss: 1.44; acc: 0.48
Batch: 580; loss: 1.6; acc: 0.5
Batch: 600; loss: 1.4; acc: 0.5
Batch: 620; loss: 1.65; acc: 0.45
Batch: 640; loss: 1.51; acc: 0.48
Batch: 660; loss: 1.75; acc: 0.38
Batch: 680; loss: 1.84; acc: 0.39
Batch: 700; loss: 1.62; acc: 0.48
Batch: 720; loss: 1.54; acc: 0.47
Batch: 740; loss: 1.35; acc: 0.62
Batch: 760; loss: 1.28; acc: 0.61
Batch: 780; loss: 1.73; acc: 0.42
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.36
Batch: 20; loss: 1.62; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.63; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.53
Val Epoch over. val_loss: 1.463127289608026; val_accuracy: 0.5119426751592356 

The current subspace-distance is: 0.00010488071711733937 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.42; acc: 0.56
Batch: 20; loss: 1.43; acc: 0.56
Batch: 40; loss: 1.37; acc: 0.59
Batch: 60; loss: 1.65; acc: 0.42
Batch: 80; loss: 1.71; acc: 0.38
Batch: 100; loss: 1.41; acc: 0.55
Batch: 120; loss: 1.42; acc: 0.58
Batch: 140; loss: 1.65; acc: 0.48
Batch: 160; loss: 1.55; acc: 0.59
Batch: 180; loss: 1.73; acc: 0.41
Batch: 200; loss: 1.79; acc: 0.44
Batch: 220; loss: 1.69; acc: 0.42
Batch: 240; loss: 1.34; acc: 0.56
Batch: 260; loss: 1.39; acc: 0.58
Batch: 280; loss: 1.71; acc: 0.41
Batch: 300; loss: 1.62; acc: 0.45
Batch: 320; loss: 1.62; acc: 0.53
Batch: 340; loss: 1.48; acc: 0.48
Batch: 360; loss: 1.48; acc: 0.56
Batch: 380; loss: 1.51; acc: 0.52
Batch: 400; loss: 1.44; acc: 0.53
Batch: 420; loss: 1.87; acc: 0.39
Batch: 440; loss: 1.56; acc: 0.45
Batch: 460; loss: 1.58; acc: 0.45
Batch: 480; loss: 1.52; acc: 0.53
Batch: 500; loss: 1.39; acc: 0.55
Batch: 520; loss: 1.47; acc: 0.59
Batch: 540; loss: 1.6; acc: 0.42
Batch: 560; loss: 1.51; acc: 0.55
Batch: 580; loss: 1.46; acc: 0.48
Batch: 600; loss: 1.47; acc: 0.48
Batch: 620; loss: 1.59; acc: 0.5
Batch: 640; loss: 1.56; acc: 0.5
Batch: 660; loss: 1.58; acc: 0.44
Batch: 680; loss: 1.65; acc: 0.48
Batch: 700; loss: 1.33; acc: 0.53
Batch: 720; loss: 1.62; acc: 0.42
Batch: 740; loss: 1.46; acc: 0.52
Batch: 760; loss: 1.48; acc: 0.52
Batch: 780; loss: 1.52; acc: 0.47
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.41
Batch: 20; loss: 1.64; acc: 0.44
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.52
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.63; acc: 0.39
Batch: 140; loss: 1.27; acc: 0.52
Val Epoch over. val_loss: 1.4634628926113153; val_accuracy: 0.511046974522293 

The current subspace-distance is: 0.0001045440076268278 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.46; acc: 0.52
Batch: 20; loss: 1.45; acc: 0.52
Batch: 40; loss: 1.52; acc: 0.47
Batch: 60; loss: 1.63; acc: 0.45
Batch: 80; loss: 1.52; acc: 0.56
Batch: 100; loss: 1.66; acc: 0.42
Batch: 120; loss: 1.49; acc: 0.53
Batch: 140; loss: 1.59; acc: 0.48
Batch: 160; loss: 1.55; acc: 0.39
Batch: 180; loss: 1.39; acc: 0.58
Batch: 200; loss: 1.54; acc: 0.5
Batch: 220; loss: 1.32; acc: 0.61
Batch: 240; loss: 1.51; acc: 0.59
Batch: 260; loss: 1.4; acc: 0.59
Batch: 280; loss: 1.41; acc: 0.5
Batch: 300; loss: 1.5; acc: 0.56
Batch: 320; loss: 1.33; acc: 0.62
Batch: 340; loss: 1.42; acc: 0.56
Batch: 360; loss: 1.61; acc: 0.45
Batch: 380; loss: 1.56; acc: 0.47
Batch: 400; loss: 1.69; acc: 0.45
Batch: 420; loss: 1.32; acc: 0.56
Batch: 440; loss: 1.6; acc: 0.5
Batch: 460; loss: 1.58; acc: 0.45
Batch: 480; loss: 1.51; acc: 0.56
Batch: 500; loss: 1.19; acc: 0.61
Batch: 520; loss: 1.57; acc: 0.45
Batch: 540; loss: 1.65; acc: 0.42
Batch: 560; loss: 1.51; acc: 0.53
Batch: 580; loss: 1.77; acc: 0.42
Batch: 600; loss: 1.72; acc: 0.45
Batch: 620; loss: 1.47; acc: 0.56
Batch: 640; loss: 1.56; acc: 0.58
Batch: 660; loss: 1.46; acc: 0.52
Batch: 680; loss: 1.46; acc: 0.55
Batch: 700; loss: 1.5; acc: 0.45
Batch: 720; loss: 1.53; acc: 0.53
Batch: 740; loss: 1.47; acc: 0.52
Batch: 760; loss: 1.3; acc: 0.56
Batch: 780; loss: 1.51; acc: 0.52
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.44; acc: 0.53
Batch: 120; loss: 1.63; acc: 0.42
Batch: 140; loss: 1.27; acc: 0.53
Val Epoch over. val_loss: 1.463316503603747; val_accuracy: 0.5143312101910829 

The current subspace-distance is: 0.00010761196608655155 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.55; acc: 0.44
Batch: 20; loss: 1.68; acc: 0.39
Batch: 40; loss: 1.48; acc: 0.59
Batch: 60; loss: 1.37; acc: 0.53
Batch: 80; loss: 1.55; acc: 0.45
Batch: 100; loss: 1.58; acc: 0.47
Batch: 120; loss: 1.17; acc: 0.66
Batch: 140; loss: 1.6; acc: 0.39
Batch: 160; loss: 1.58; acc: 0.47
Batch: 180; loss: 1.6; acc: 0.47
Batch: 200; loss: 1.32; acc: 0.56
Batch: 220; loss: 1.57; acc: 0.53
Batch: 240; loss: 1.43; acc: 0.58
Batch: 260; loss: 1.34; acc: 0.52
Batch: 280; loss: 1.45; acc: 0.47
Batch: 300; loss: 1.39; acc: 0.58
Batch: 320; loss: 1.38; acc: 0.61
Batch: 340; loss: 1.5; acc: 0.55
Batch: 360; loss: 1.54; acc: 0.47
Batch: 380; loss: 1.67; acc: 0.48
Batch: 400; loss: 1.42; acc: 0.48
Batch: 420; loss: 1.62; acc: 0.44
Batch: 440; loss: 1.38; acc: 0.56
Batch: 460; loss: 1.51; acc: 0.48
Batch: 480; loss: 1.35; acc: 0.55
Batch: 500; loss: 1.4; acc: 0.55
Batch: 520; loss: 1.71; acc: 0.52
Batch: 540; loss: 1.52; acc: 0.42
Batch: 560; loss: 1.8; acc: 0.41
Batch: 580; loss: 1.43; acc: 0.45
Batch: 600; loss: 1.56; acc: 0.48
Batch: 620; loss: 1.56; acc: 0.48
Batch: 640; loss: 1.6; acc: 0.5
Batch: 660; loss: 1.99; acc: 0.39
Batch: 680; loss: 1.5; acc: 0.53
Batch: 700; loss: 1.58; acc: 0.44
Batch: 720; loss: 1.4; acc: 0.53
Batch: 740; loss: 1.46; acc: 0.56
Batch: 760; loss: 1.61; acc: 0.45
Batch: 780; loss: 1.57; acc: 0.55
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.77; acc: 0.38
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.4; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.52
Val Epoch over. val_loss: 1.4660424487605976; val_accuracy: 0.5125398089171974 

The current subspace-distance is: 0.00011022703984053805 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.67; acc: 0.48
Batch: 20; loss: 1.49; acc: 0.53
Batch: 40; loss: 1.61; acc: 0.48
Batch: 60; loss: 1.86; acc: 0.41
Batch: 80; loss: 1.57; acc: 0.55
Batch: 100; loss: 1.64; acc: 0.48
Batch: 120; loss: 1.71; acc: 0.45
Batch: 140; loss: 1.44; acc: 0.47
Batch: 160; loss: 1.73; acc: 0.45
Batch: 180; loss: 1.38; acc: 0.53
Batch: 200; loss: 1.63; acc: 0.45
Batch: 220; loss: 1.49; acc: 0.52
Batch: 240; loss: 1.51; acc: 0.5
Batch: 260; loss: 1.76; acc: 0.48
Batch: 280; loss: 1.57; acc: 0.47
Batch: 300; loss: 1.54; acc: 0.42
Batch: 320; loss: 1.39; acc: 0.53
Batch: 340; loss: 1.45; acc: 0.53
Batch: 360; loss: 1.45; acc: 0.5
Batch: 380; loss: 1.56; acc: 0.53
Batch: 400; loss: 1.63; acc: 0.53
Batch: 420; loss: 1.38; acc: 0.55
Batch: 440; loss: 1.51; acc: 0.45
Batch: 460; loss: 1.55; acc: 0.45
Batch: 480; loss: 1.49; acc: 0.52
Batch: 500; loss: 1.54; acc: 0.56
Batch: 520; loss: 1.52; acc: 0.45
Batch: 540; loss: 1.49; acc: 0.48
Batch: 560; loss: 1.63; acc: 0.5
Batch: 580; loss: 1.27; acc: 0.52
Batch: 600; loss: 1.05; acc: 0.62
Batch: 620; loss: 1.75; acc: 0.38
Batch: 640; loss: 1.21; acc: 0.7
Batch: 660; loss: 1.5; acc: 0.45
Batch: 680; loss: 1.34; acc: 0.56
Batch: 700; loss: 1.59; acc: 0.45
Batch: 720; loss: 1.33; acc: 0.53
Batch: 740; loss: 1.59; acc: 0.48
Batch: 760; loss: 1.44; acc: 0.55
Batch: 780; loss: 1.53; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.33
Batch: 20; loss: 1.64; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.55
Batch: 120; loss: 1.63; acc: 0.38
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.4636430823878877; val_accuracy: 0.5119426751592356 

The current subspace-distance is: 0.00011190524674020708 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.46; acc: 0.56
Batch: 20; loss: 1.46; acc: 0.52
Batch: 40; loss: 1.59; acc: 0.45
Batch: 60; loss: 1.47; acc: 0.48
Batch: 80; loss: 1.56; acc: 0.47
Batch: 100; loss: 1.46; acc: 0.48
Batch: 120; loss: 1.57; acc: 0.48
Batch: 140; loss: 1.26; acc: 0.64
Batch: 160; loss: 1.35; acc: 0.62
Batch: 180; loss: 1.8; acc: 0.44
Batch: 200; loss: 1.61; acc: 0.52
Batch: 220; loss: 1.53; acc: 0.55
Batch: 240; loss: 1.6; acc: 0.52
Batch: 260; loss: 1.63; acc: 0.53
Batch: 280; loss: 1.79; acc: 0.38
Batch: 300; loss: 1.51; acc: 0.5
Batch: 320; loss: 1.43; acc: 0.53
Batch: 340; loss: 1.45; acc: 0.52
Batch: 360; loss: 1.45; acc: 0.52
Batch: 380; loss: 1.47; acc: 0.45
Batch: 400; loss: 1.42; acc: 0.5
Batch: 420; loss: 1.62; acc: 0.45
Batch: 440; loss: 1.56; acc: 0.55
Batch: 460; loss: 1.58; acc: 0.56
Batch: 480; loss: 1.61; acc: 0.56
Batch: 500; loss: 1.72; acc: 0.38
Batch: 520; loss: 1.68; acc: 0.42
Batch: 540; loss: 1.64; acc: 0.47
Batch: 560; loss: 1.42; acc: 0.5
Batch: 580; loss: 1.5; acc: 0.5
Batch: 600; loss: 1.48; acc: 0.52
Batch: 620; loss: 1.44; acc: 0.5
Batch: 640; loss: 1.51; acc: 0.47
Batch: 660; loss: 1.62; acc: 0.5
Batch: 680; loss: 1.53; acc: 0.48
Batch: 700; loss: 1.38; acc: 0.56
Batch: 720; loss: 1.69; acc: 0.41
Batch: 740; loss: 1.49; acc: 0.47
Batch: 760; loss: 1.38; acc: 0.59
Batch: 780; loss: 1.53; acc: 0.55
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.75; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.44
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.35; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.39
Batch: 140; loss: 1.26; acc: 0.56
Val Epoch over. val_loss: 1.4616984819910328; val_accuracy: 0.5138335987261147 

The current subspace-distance is: 0.00011384129902580753 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.59; acc: 0.47
Batch: 20; loss: 1.51; acc: 0.48
Batch: 40; loss: 1.52; acc: 0.56
Batch: 60; loss: 1.57; acc: 0.45
Batch: 80; loss: 1.54; acc: 0.5
Batch: 100; loss: 1.58; acc: 0.45
Batch: 120; loss: 1.61; acc: 0.47
Batch: 140; loss: 1.33; acc: 0.58
Batch: 160; loss: 1.47; acc: 0.55
Batch: 180; loss: 1.31; acc: 0.56
Batch: 200; loss: 2.03; acc: 0.33
Batch: 220; loss: 1.36; acc: 0.59
Batch: 240; loss: 1.42; acc: 0.5
Batch: 260; loss: 1.44; acc: 0.52
Batch: 280; loss: 1.42; acc: 0.58
Batch: 300; loss: 1.58; acc: 0.56
Batch: 320; loss: 1.64; acc: 0.48
Batch: 340; loss: 1.47; acc: 0.5
Batch: 360; loss: 1.47; acc: 0.56
Batch: 380; loss: 1.53; acc: 0.52
Batch: 400; loss: 1.54; acc: 0.55
Batch: 420; loss: 1.35; acc: 0.56
Batch: 440; loss: 1.49; acc: 0.45
Batch: 460; loss: 1.55; acc: 0.45
Batch: 480; loss: 1.5; acc: 0.45
Batch: 500; loss: 1.5; acc: 0.47
Batch: 520; loss: 1.71; acc: 0.44
Batch: 540; loss: 1.77; acc: 0.41
Batch: 560; loss: 1.45; acc: 0.52
Batch: 580; loss: 1.51; acc: 0.53
Batch: 600; loss: 1.86; acc: 0.44
Batch: 620; loss: 1.63; acc: 0.39
Batch: 640; loss: 1.88; acc: 0.36
Batch: 660; loss: 1.46; acc: 0.53
Batch: 680; loss: 1.68; acc: 0.41
Batch: 700; loss: 1.54; acc: 0.42
Batch: 720; loss: 1.55; acc: 0.5
Batch: 740; loss: 1.68; acc: 0.47
Batch: 760; loss: 1.62; acc: 0.5
Batch: 780; loss: 1.41; acc: 0.66
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.42
Batch: 140; loss: 1.27; acc: 0.5
Val Epoch over. val_loss: 1.4637773454568948; val_accuracy: 0.5133359872611465 

The current subspace-distance is: 0.00011896691285073757 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.49; acc: 0.55
Batch: 20; loss: 1.59; acc: 0.45
Batch: 40; loss: 1.56; acc: 0.52
Batch: 60; loss: 1.66; acc: 0.44
Batch: 80; loss: 1.46; acc: 0.56
Batch: 100; loss: 1.48; acc: 0.47
Batch: 120; loss: 1.52; acc: 0.52
Batch: 140; loss: 1.5; acc: 0.42
Batch: 160; loss: 1.6; acc: 0.47
Batch: 180; loss: 1.53; acc: 0.5
Batch: 200; loss: 1.77; acc: 0.41
Batch: 220; loss: 1.56; acc: 0.52
Batch: 240; loss: 1.6; acc: 0.47
Batch: 260; loss: 1.37; acc: 0.55
Batch: 280; loss: 1.76; acc: 0.48
Batch: 300; loss: 1.31; acc: 0.53
Batch: 320; loss: 1.58; acc: 0.5
Batch: 340; loss: 1.26; acc: 0.67
Batch: 360; loss: 1.46; acc: 0.5
Batch: 380; loss: 1.34; acc: 0.53
Batch: 400; loss: 1.29; acc: 0.59
Batch: 420; loss: 1.46; acc: 0.58
Batch: 440; loss: 1.42; acc: 0.62
Batch: 460; loss: 1.68; acc: 0.52
Batch: 480; loss: 1.68; acc: 0.36
Batch: 500; loss: 1.72; acc: 0.45
Batch: 520; loss: 1.32; acc: 0.56
Batch: 540; loss: 1.72; acc: 0.44
Batch: 560; loss: 1.64; acc: 0.47
Batch: 580; loss: 1.47; acc: 0.53
Batch: 600; loss: 1.56; acc: 0.48
Batch: 620; loss: 1.48; acc: 0.47
Batch: 640; loss: 1.54; acc: 0.45
Batch: 660; loss: 1.3; acc: 0.58
Batch: 680; loss: 1.61; acc: 0.41
Batch: 700; loss: 1.22; acc: 0.59
Batch: 720; loss: 1.6; acc: 0.42
Batch: 740; loss: 1.65; acc: 0.41
Batch: 760; loss: 1.51; acc: 0.55
Batch: 780; loss: 1.5; acc: 0.5
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.63; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.4625484647264906; val_accuracy: 0.5119426751592356 

The current subspace-distance is: 0.0001205882872454822 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.55; acc: 0.52
Batch: 20; loss: 1.24; acc: 0.56
Batch: 40; loss: 1.45; acc: 0.48
Batch: 60; loss: 1.6; acc: 0.42
Batch: 80; loss: 1.54; acc: 0.47
Batch: 100; loss: 1.44; acc: 0.48
Batch: 120; loss: 1.61; acc: 0.45
Batch: 140; loss: 1.59; acc: 0.48
Batch: 160; loss: 1.45; acc: 0.55
Batch: 180; loss: 1.68; acc: 0.53
Batch: 200; loss: 1.61; acc: 0.41
Batch: 220; loss: 1.45; acc: 0.53
Batch: 240; loss: 1.4; acc: 0.55
Batch: 260; loss: 1.6; acc: 0.48
Batch: 280; loss: 1.57; acc: 0.48
Batch: 300; loss: 1.59; acc: 0.45
Batch: 320; loss: 1.39; acc: 0.56
Batch: 340; loss: 1.5; acc: 0.48
Batch: 360; loss: 1.37; acc: 0.5
Batch: 380; loss: 1.72; acc: 0.52
Batch: 400; loss: 1.29; acc: 0.59
Batch: 420; loss: 1.4; acc: 0.56
Batch: 440; loss: 1.5; acc: 0.45
Batch: 460; loss: 1.58; acc: 0.44
Batch: 480; loss: 1.49; acc: 0.56
Batch: 500; loss: 1.4; acc: 0.5
Batch: 520; loss: 1.43; acc: 0.52
Batch: 540; loss: 1.62; acc: 0.47
Batch: 560; loss: 1.57; acc: 0.5
Batch: 580; loss: 1.61; acc: 0.48
Batch: 600; loss: 1.78; acc: 0.41
Batch: 620; loss: 1.75; acc: 0.47
Batch: 640; loss: 1.55; acc: 0.5
Batch: 660; loss: 1.12; acc: 0.66
Batch: 680; loss: 1.66; acc: 0.47
Batch: 700; loss: 1.37; acc: 0.53
Batch: 720; loss: 1.57; acc: 0.48
Batch: 740; loss: 1.77; acc: 0.38
Batch: 760; loss: 1.5; acc: 0.47
Batch: 780; loss: 1.55; acc: 0.55
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.42; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.42; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.26; acc: 0.55
Val Epoch over. val_loss: 1.461989866700142; val_accuracy: 0.513734076433121 

The current subspace-distance is: 0.00012285742559470236 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.6; acc: 0.5
Batch: 20; loss: 1.5; acc: 0.45
Batch: 40; loss: 1.47; acc: 0.53
Batch: 60; loss: 1.65; acc: 0.5
Batch: 80; loss: 1.34; acc: 0.58
Batch: 100; loss: 1.79; acc: 0.41
Batch: 120; loss: 1.55; acc: 0.42
Batch: 140; loss: 1.78; acc: 0.42
Batch: 160; loss: 1.62; acc: 0.47
Batch: 180; loss: 1.66; acc: 0.5
Batch: 200; loss: 1.34; acc: 0.59
Batch: 220; loss: 1.43; acc: 0.52
Batch: 240; loss: 1.58; acc: 0.44
Batch: 260; loss: 1.6; acc: 0.5
Batch: 280; loss: 1.49; acc: 0.48
Batch: 300; loss: 1.72; acc: 0.5
Batch: 320; loss: 1.45; acc: 0.53
Batch: 340; loss: 1.73; acc: 0.36
Batch: 360; loss: 1.74; acc: 0.44
Batch: 380; loss: 1.49; acc: 0.45
Batch: 400; loss: 1.47; acc: 0.5
Batch: 420; loss: 1.56; acc: 0.38
Batch: 440; loss: 1.61; acc: 0.41
Batch: 460; loss: 1.4; acc: 0.5
Batch: 480; loss: 1.89; acc: 0.41
Batch: 500; loss: 1.65; acc: 0.41
Batch: 520; loss: 1.42; acc: 0.56
Batch: 540; loss: 1.85; acc: 0.44
Batch: 560; loss: 1.48; acc: 0.5
Batch: 580; loss: 1.56; acc: 0.55
Batch: 600; loss: 1.6; acc: 0.52
Batch: 620; loss: 1.72; acc: 0.45
Batch: 640; loss: 1.39; acc: 0.58
Batch: 660; loss: 1.64; acc: 0.44
Batch: 680; loss: 1.45; acc: 0.56
Batch: 700; loss: 1.67; acc: 0.42
Batch: 720; loss: 1.51; acc: 0.53
Batch: 740; loss: 1.53; acc: 0.56
Batch: 760; loss: 1.49; acc: 0.44
Batch: 780; loss: 1.42; acc: 0.52
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.26; acc: 0.52
Val Epoch over. val_loss: 1.4620971596165069; val_accuracy: 0.5126393312101911 

The current subspace-distance is: 0.00012269716535229236 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.38; acc: 0.48
Batch: 20; loss: 1.4; acc: 0.53
Batch: 40; loss: 1.61; acc: 0.44
Batch: 60; loss: 1.69; acc: 0.48
Batch: 80; loss: 1.43; acc: 0.52
Batch: 100; loss: 1.62; acc: 0.45
Batch: 120; loss: 1.73; acc: 0.41
Batch: 140; loss: 1.41; acc: 0.53
Batch: 160; loss: 1.52; acc: 0.55
Batch: 180; loss: 1.3; acc: 0.56
Batch: 200; loss: 1.26; acc: 0.62
Batch: 220; loss: 1.62; acc: 0.45
Batch: 240; loss: 1.26; acc: 0.66
Batch: 260; loss: 1.34; acc: 0.61
Batch: 280; loss: 1.43; acc: 0.55
Batch: 300; loss: 1.48; acc: 0.44
Batch: 320; loss: 1.81; acc: 0.5
Batch: 340; loss: 1.55; acc: 0.56
Batch: 360; loss: 1.72; acc: 0.5
Batch: 380; loss: 1.59; acc: 0.41
Batch: 400; loss: 1.53; acc: 0.44
Batch: 420; loss: 1.54; acc: 0.48
Batch: 440; loss: 1.32; acc: 0.56
Batch: 460; loss: 1.45; acc: 0.5
Batch: 480; loss: 1.56; acc: 0.41
Batch: 500; loss: 1.38; acc: 0.59
Batch: 520; loss: 1.46; acc: 0.55
Batch: 540; loss: 1.47; acc: 0.53
Batch: 560; loss: 1.47; acc: 0.5
Batch: 580; loss: 1.59; acc: 0.45
Batch: 600; loss: 1.49; acc: 0.52
Batch: 620; loss: 1.64; acc: 0.52
Batch: 640; loss: 1.63; acc: 0.44
Batch: 660; loss: 1.41; acc: 0.58
Batch: 680; loss: 1.45; acc: 0.62
Batch: 700; loss: 1.42; acc: 0.5
Batch: 720; loss: 1.5; acc: 0.56
Batch: 740; loss: 1.54; acc: 0.53
Batch: 760; loss: 1.32; acc: 0.58
Batch: 780; loss: 1.59; acc: 0.47
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.63; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.4615594247344192; val_accuracy: 0.51453025477707 

The current subspace-distance is: 0.00012733542826026678 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.73; acc: 0.47
Batch: 20; loss: 1.44; acc: 0.55
Batch: 40; loss: 1.58; acc: 0.45
Batch: 60; loss: 1.57; acc: 0.44
Batch: 80; loss: 1.64; acc: 0.45
Batch: 100; loss: 1.42; acc: 0.5
Batch: 120; loss: 1.41; acc: 0.48
Batch: 140; loss: 1.53; acc: 0.48
Batch: 160; loss: 1.16; acc: 0.64
Batch: 180; loss: 1.85; acc: 0.39
Batch: 200; loss: 1.57; acc: 0.45
Batch: 220; loss: 1.51; acc: 0.48
Batch: 240; loss: 1.65; acc: 0.41
Batch: 260; loss: 1.46; acc: 0.5
Batch: 280; loss: 1.48; acc: 0.53
Batch: 300; loss: 1.3; acc: 0.62
Batch: 320; loss: 1.59; acc: 0.45
Batch: 340; loss: 1.81; acc: 0.28
Batch: 360; loss: 1.54; acc: 0.52
Batch: 380; loss: 1.45; acc: 0.56
Batch: 400; loss: 1.47; acc: 0.48
Batch: 420; loss: 1.61; acc: 0.48
Batch: 440; loss: 1.5; acc: 0.52
Batch: 460; loss: 1.39; acc: 0.55
Batch: 480; loss: 1.49; acc: 0.53
Batch: 500; loss: 1.37; acc: 0.52
Batch: 520; loss: 1.36; acc: 0.56
Batch: 540; loss: 1.53; acc: 0.56
Batch: 560; loss: 1.37; acc: 0.58
Batch: 580; loss: 1.59; acc: 0.44
Batch: 600; loss: 1.52; acc: 0.48
Batch: 620; loss: 1.7; acc: 0.41
Batch: 640; loss: 1.55; acc: 0.48
Batch: 660; loss: 1.61; acc: 0.47
Batch: 680; loss: 1.51; acc: 0.48
Batch: 700; loss: 1.72; acc: 0.41
Batch: 720; loss: 1.36; acc: 0.5
Batch: 740; loss: 1.64; acc: 0.44
Batch: 760; loss: 1.6; acc: 0.47
Batch: 780; loss: 1.57; acc: 0.44
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.33
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.56
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.55
Batch: 120; loss: 1.63; acc: 0.42
Batch: 140; loss: 1.26; acc: 0.55
Val Epoch over. val_loss: 1.4622537915114384; val_accuracy: 0.515625 

The current subspace-distance is: 0.00012667180271819234 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.66; acc: 0.47
Batch: 20; loss: 1.42; acc: 0.56
Batch: 40; loss: 1.63; acc: 0.45
Batch: 60; loss: 1.43; acc: 0.52
Batch: 80; loss: 1.3; acc: 0.59
Batch: 100; loss: 1.75; acc: 0.5
Batch: 120; loss: 1.49; acc: 0.47
Batch: 140; loss: 1.52; acc: 0.42
Batch: 160; loss: 1.23; acc: 0.64
Batch: 180; loss: 1.5; acc: 0.48
Batch: 200; loss: 1.38; acc: 0.55
Batch: 220; loss: 1.52; acc: 0.42
Batch: 240; loss: 1.45; acc: 0.56
Batch: 260; loss: 1.65; acc: 0.52
Batch: 280; loss: 1.5; acc: 0.45
Batch: 300; loss: 1.35; acc: 0.55
Batch: 320; loss: 1.45; acc: 0.48
Batch: 340; loss: 1.43; acc: 0.5
Batch: 360; loss: 1.26; acc: 0.58
Batch: 380; loss: 1.33; acc: 0.53
Batch: 400; loss: 1.51; acc: 0.45
Batch: 420; loss: 1.36; acc: 0.59
Batch: 440; loss: 1.45; acc: 0.48
Batch: 460; loss: 1.47; acc: 0.56
Batch: 480; loss: 1.46; acc: 0.47
Batch: 500; loss: 1.61; acc: 0.52
Batch: 520; loss: 1.33; acc: 0.59
Batch: 540; loss: 1.52; acc: 0.53
Batch: 560; loss: 1.46; acc: 0.48
Batch: 580; loss: 1.43; acc: 0.56
Batch: 600; loss: 1.45; acc: 0.5
Batch: 620; loss: 1.5; acc: 0.47
Batch: 640; loss: 1.39; acc: 0.53
Batch: 660; loss: 1.64; acc: 0.44
Batch: 680; loss: 1.46; acc: 0.56
Batch: 700; loss: 1.55; acc: 0.56
Batch: 720; loss: 1.73; acc: 0.45
Batch: 740; loss: 1.73; acc: 0.41
Batch: 760; loss: 1.45; acc: 0.52
Batch: 780; loss: 1.23; acc: 0.56
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.33; acc: 0.56
Batch: 60; loss: 1.42; acc: 0.5
Batch: 80; loss: 1.37; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.55
Batch: 120; loss: 1.63; acc: 0.39
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.461779752354713; val_accuracy: 0.5150278662420382 

The current subspace-distance is: 0.00012990810500923544 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.3; acc: 0.56
Batch: 20; loss: 1.54; acc: 0.56
Batch: 40; loss: 1.61; acc: 0.55
Batch: 60; loss: 1.58; acc: 0.47
Batch: 80; loss: 1.81; acc: 0.5
Batch: 100; loss: 1.64; acc: 0.48
Batch: 120; loss: 1.63; acc: 0.44
Batch: 140; loss: 1.88; acc: 0.44
Batch: 160; loss: 1.49; acc: 0.61
Batch: 180; loss: 1.53; acc: 0.48
Batch: 200; loss: 1.47; acc: 0.48
Batch: 220; loss: 1.38; acc: 0.53
Batch: 240; loss: 1.68; acc: 0.42
Batch: 260; loss: 1.22; acc: 0.62
Batch: 280; loss: 1.61; acc: 0.39
Batch: 300; loss: 1.63; acc: 0.56
Batch: 320; loss: 1.45; acc: 0.5
Batch: 340; loss: 1.56; acc: 0.55
Batch: 360; loss: 1.38; acc: 0.59
Batch: 380; loss: 1.37; acc: 0.62
Batch: 400; loss: 1.68; acc: 0.45
Batch: 420; loss: 1.5; acc: 0.53
Batch: 440; loss: 1.61; acc: 0.5
Batch: 460; loss: 1.56; acc: 0.45
Batch: 480; loss: 1.47; acc: 0.5
Batch: 500; loss: 1.5; acc: 0.53
Batch: 520; loss: 1.6; acc: 0.41
Batch: 540; loss: 1.45; acc: 0.53
Batch: 560; loss: 1.42; acc: 0.56
Batch: 580; loss: 1.41; acc: 0.52
Batch: 600; loss: 1.49; acc: 0.47
Batch: 620; loss: 1.39; acc: 0.48
Batch: 640; loss: 1.45; acc: 0.53
Batch: 660; loss: 1.61; acc: 0.44
Batch: 680; loss: 1.51; acc: 0.45
Batch: 700; loss: 1.51; acc: 0.55
Batch: 720; loss: 1.32; acc: 0.55
Batch: 740; loss: 1.55; acc: 0.5
Batch: 760; loss: 1.51; acc: 0.52
Batch: 780; loss: 1.64; acc: 0.45
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.36
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.59
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.52
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.4617994803531913; val_accuracy: 0.5132364649681529 

The current subspace-distance is: 0.00013464299263432622 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.67; acc: 0.45
Batch: 20; loss: 1.56; acc: 0.39
Batch: 40; loss: 1.43; acc: 0.52
Batch: 60; loss: 1.5; acc: 0.45
Batch: 80; loss: 1.8; acc: 0.44
Batch: 100; loss: 1.31; acc: 0.59
Batch: 120; loss: 1.61; acc: 0.36
Batch: 140; loss: 1.53; acc: 0.45
Batch: 160; loss: 1.52; acc: 0.52
Batch: 180; loss: 1.4; acc: 0.61
Batch: 200; loss: 1.6; acc: 0.48
Batch: 220; loss: 1.55; acc: 0.5
Batch: 240; loss: 1.59; acc: 0.42
Batch: 260; loss: 1.49; acc: 0.5
Batch: 280; loss: 1.61; acc: 0.5
Batch: 300; loss: 1.53; acc: 0.45
Batch: 320; loss: 1.25; acc: 0.56
Batch: 340; loss: 1.58; acc: 0.47
Batch: 360; loss: 1.63; acc: 0.47
Batch: 380; loss: 1.34; acc: 0.64
Batch: 400; loss: 1.38; acc: 0.59
Batch: 420; loss: 1.61; acc: 0.47
Batch: 440; loss: 1.66; acc: 0.39
Batch: 460; loss: 1.61; acc: 0.5
Batch: 480; loss: 1.52; acc: 0.55
Batch: 500; loss: 1.43; acc: 0.5
Batch: 520; loss: 1.34; acc: 0.58
Batch: 540; loss: 1.81; acc: 0.41
Batch: 560; loss: 1.9; acc: 0.41
Batch: 580; loss: 1.44; acc: 0.5
Batch: 600; loss: 1.53; acc: 0.5
Batch: 620; loss: 1.48; acc: 0.55
Batch: 640; loss: 1.6; acc: 0.5
Batch: 660; loss: 1.69; acc: 0.39
Batch: 680; loss: 1.47; acc: 0.52
Batch: 700; loss: 1.52; acc: 0.45
Batch: 720; loss: 1.57; acc: 0.47
Batch: 740; loss: 1.75; acc: 0.45
Batch: 760; loss: 1.52; acc: 0.47
Batch: 780; loss: 1.47; acc: 0.58
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.38
Batch: 20; loss: 1.63; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.4620367030429233; val_accuracy: 0.5131369426751592 

The current subspace-distance is: 0.00013349328946787864 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.75; acc: 0.44
Batch: 20; loss: 1.52; acc: 0.53
Batch: 40; loss: 1.64; acc: 0.5
Batch: 60; loss: 1.55; acc: 0.48
Batch: 80; loss: 1.38; acc: 0.53
Batch: 100; loss: 1.56; acc: 0.5
Batch: 120; loss: 1.54; acc: 0.5
Batch: 140; loss: 1.48; acc: 0.42
Batch: 160; loss: 1.33; acc: 0.58
Batch: 180; loss: 1.62; acc: 0.45
Batch: 200; loss: 1.46; acc: 0.5
Batch: 220; loss: 1.32; acc: 0.56
Batch: 240; loss: 1.62; acc: 0.45
Batch: 260; loss: 1.57; acc: 0.47
Batch: 280; loss: 1.74; acc: 0.42
Batch: 300; loss: 1.42; acc: 0.58
Batch: 320; loss: 1.66; acc: 0.42
Batch: 340; loss: 1.57; acc: 0.44
Batch: 360; loss: 1.54; acc: 0.48
Batch: 380; loss: 1.65; acc: 0.48
Batch: 400; loss: 1.66; acc: 0.44
Batch: 420; loss: 1.4; acc: 0.58
Batch: 440; loss: 1.63; acc: 0.38
Batch: 460; loss: 1.62; acc: 0.42
Batch: 480; loss: 1.5; acc: 0.53
Batch: 500; loss: 1.43; acc: 0.52
Batch: 520; loss: 1.51; acc: 0.55
Batch: 540; loss: 1.59; acc: 0.52
Batch: 560; loss: 1.32; acc: 0.55
Batch: 580; loss: 1.56; acc: 0.36
Batch: 600; loss: 1.64; acc: 0.55
Batch: 620; loss: 1.52; acc: 0.53
Batch: 640; loss: 1.22; acc: 0.62
Batch: 660; loss: 1.76; acc: 0.44
Batch: 680; loss: 1.64; acc: 0.42
Batch: 700; loss: 1.51; acc: 0.58
Batch: 720; loss: 1.74; acc: 0.47
Batch: 740; loss: 1.51; acc: 0.47
Batch: 760; loss: 1.72; acc: 0.5
Batch: 780; loss: 1.59; acc: 0.34
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.39
Batch: 20; loss: 1.63; acc: 0.42
Batch: 40; loss: 1.32; acc: 0.59
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.62
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.26; acc: 0.5
Val Epoch over. val_loss: 1.4620525639527922; val_accuracy: 0.5122412420382165 

The current subspace-distance is: 0.0001305480400333181 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.57; acc: 0.53
Batch: 20; loss: 1.28; acc: 0.62
Batch: 40; loss: 1.4; acc: 0.53
Batch: 60; loss: 1.51; acc: 0.39
Batch: 80; loss: 1.44; acc: 0.52
Batch: 100; loss: 1.46; acc: 0.58
Batch: 120; loss: 1.68; acc: 0.48
Batch: 140; loss: 1.45; acc: 0.59
Batch: 160; loss: 1.54; acc: 0.56
Batch: 180; loss: 1.4; acc: 0.56
Batch: 200; loss: 1.23; acc: 0.62
Batch: 220; loss: 1.64; acc: 0.45
Batch: 240; loss: 1.35; acc: 0.55
Batch: 260; loss: 1.75; acc: 0.38
Batch: 280; loss: 1.56; acc: 0.47
Batch: 300; loss: 1.61; acc: 0.47
Batch: 320; loss: 1.57; acc: 0.53
Batch: 340; loss: 1.39; acc: 0.47
Batch: 360; loss: 1.49; acc: 0.48
Batch: 380; loss: 1.55; acc: 0.45
Batch: 400; loss: 1.48; acc: 0.55
Batch: 420; loss: 1.52; acc: 0.52
Batch: 440; loss: 1.61; acc: 0.47
Batch: 460; loss: 1.48; acc: 0.53
Batch: 480; loss: 1.4; acc: 0.55
Batch: 500; loss: 1.56; acc: 0.5
Batch: 520; loss: 1.58; acc: 0.53
Batch: 540; loss: 1.64; acc: 0.42
Batch: 560; loss: 1.29; acc: 0.67
Batch: 580; loss: 1.57; acc: 0.48
Batch: 600; loss: 1.34; acc: 0.62
Batch: 620; loss: 1.52; acc: 0.48
Batch: 640; loss: 1.44; acc: 0.53
Batch: 660; loss: 1.32; acc: 0.62
Batch: 680; loss: 1.62; acc: 0.45
Batch: 700; loss: 1.48; acc: 0.5
Batch: 720; loss: 1.52; acc: 0.47
Batch: 740; loss: 1.42; acc: 0.53
Batch: 760; loss: 1.72; acc: 0.45
Batch: 780; loss: 1.82; acc: 0.45
Train Epoch over. train_loss: 1.53; train_accuracy: 0.5 

Batch: 0; loss: 1.76; acc: 0.34
Batch: 20; loss: 1.64; acc: 0.41
Batch: 40; loss: 1.32; acc: 0.58
Batch: 60; loss: 1.41; acc: 0.5
Batch: 80; loss: 1.36; acc: 0.61
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.62; acc: 0.41
Batch: 140; loss: 1.27; acc: 0.55
Val Epoch over. val_loss: 1.4620169674514965; val_accuracy: 0.5135350318471338 

The current subspace-distance is: 0.0001348610530840233 

plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_50_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 14272
elements in E: 1977400
fraction nonzero: 0.007217558410033377
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.09
Batch: 180; loss: 2.31; acc: 0.08
Batch: 200; loss: 2.31; acc: 0.11
Batch: 220; loss: 2.31; acc: 0.11
Batch: 240; loss: 2.3; acc: 0.11
Batch: 260; loss: 2.29; acc: 0.14
Batch: 280; loss: 2.31; acc: 0.06
Batch: 300; loss: 2.31; acc: 0.12
Batch: 320; loss: 2.29; acc: 0.03
Batch: 340; loss: 2.32; acc: 0.11
Batch: 360; loss: 2.3; acc: 0.19
Batch: 380; loss: 2.3; acc: 0.27
Batch: 400; loss: 2.28; acc: 0.27
Batch: 420; loss: 2.31; acc: 0.19
Batch: 440; loss: 2.31; acc: 0.17
Batch: 460; loss: 2.29; acc: 0.28
Batch: 480; loss: 2.29; acc: 0.19
Batch: 500; loss: 2.3; acc: 0.19
Batch: 520; loss: 2.31; acc: 0.05
Batch: 540; loss: 2.3; acc: 0.12
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.29; acc: 0.12
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.3; acc: 0.16
Batch: 640; loss: 2.3; acc: 0.2
Batch: 660; loss: 2.28; acc: 0.23
Batch: 680; loss: 2.3; acc: 0.22
Batch: 700; loss: 2.29; acc: 0.23
Batch: 720; loss: 2.28; acc: 0.27
Batch: 740; loss: 2.3; acc: 0.19
Batch: 760; loss: 2.29; acc: 0.22
Batch: 780; loss: 2.27; acc: 0.34
Train Epoch over. train_loss: 2.3; train_accuracy: 0.15 

Batch: 0; loss: 2.3; acc: 0.19
Batch: 20; loss: 2.31; acc: 0.09
Batch: 40; loss: 2.29; acc: 0.27
Batch: 60; loss: 2.3; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.17
Batch: 100; loss: 2.3; acc: 0.19
Batch: 120; loss: 2.31; acc: 0.17
Batch: 140; loss: 2.29; acc: 0.2
Val Epoch over. val_loss: 2.2931394364423814; val_accuracy: 0.1976512738853503 

The current subspace-distance is: 7.96513086243067e-06 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.23
Batch: 20; loss: 2.29; acc: 0.2
Batch: 40; loss: 2.29; acc: 0.27
Batch: 60; loss: 2.28; acc: 0.2
Batch: 80; loss: 2.28; acc: 0.23
Batch: 100; loss: 2.3; acc: 0.16
Batch: 120; loss: 2.3; acc: 0.14
Batch: 140; loss: 2.3; acc: 0.19
Batch: 160; loss: 2.28; acc: 0.25
Batch: 180; loss: 2.28; acc: 0.28
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.28; acc: 0.23
Batch: 240; loss: 2.29; acc: 0.19
Batch: 260; loss: 2.27; acc: 0.27
Batch: 280; loss: 2.28; acc: 0.2
Batch: 300; loss: 2.29; acc: 0.22
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.28; acc: 0.22
Batch: 360; loss: 2.26; acc: 0.3
Batch: 380; loss: 2.3; acc: 0.16
Batch: 400; loss: 2.26; acc: 0.27
Batch: 420; loss: 2.29; acc: 0.22
Batch: 440; loss: 2.27; acc: 0.22
Batch: 460; loss: 2.28; acc: 0.19
Batch: 480; loss: 2.28; acc: 0.16
Batch: 500; loss: 2.28; acc: 0.12
Batch: 520; loss: 2.28; acc: 0.2
Batch: 540; loss: 2.28; acc: 0.14
Batch: 560; loss: 2.3; acc: 0.09
Batch: 580; loss: 2.26; acc: 0.27
Batch: 600; loss: 2.28; acc: 0.17
Batch: 620; loss: 2.28; acc: 0.19
Batch: 640; loss: 2.26; acc: 0.19
Batch: 660; loss: 2.26; acc: 0.19
Batch: 680; loss: 2.25; acc: 0.22
Batch: 700; loss: 2.24; acc: 0.22
Batch: 720; loss: 2.24; acc: 0.2
Batch: 740; loss: 2.24; acc: 0.28
Batch: 760; loss: 2.2; acc: 0.31
Batch: 780; loss: 2.24; acc: 0.23
Train Epoch over. train_loss: 2.28; train_accuracy: 0.21 

Batch: 0; loss: 2.2; acc: 0.28
Batch: 20; loss: 2.23; acc: 0.17
Batch: 40; loss: 2.17; acc: 0.38
Batch: 60; loss: 2.18; acc: 0.31
Batch: 80; loss: 2.2; acc: 0.28
Batch: 100; loss: 2.21; acc: 0.28
Batch: 120; loss: 2.21; acc: 0.33
Batch: 140; loss: 2.21; acc: 0.27
Val Epoch over. val_loss: 2.208672023882532; val_accuracy: 0.26711783439490444 

The current subspace-distance is: 1.1960286428802647e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 2.24; acc: 0.2
Batch: 20; loss: 2.24; acc: 0.2
Batch: 40; loss: 2.16; acc: 0.36
Batch: 60; loss: 2.16; acc: 0.33
Batch: 80; loss: 2.1; acc: 0.33
Batch: 100; loss: 2.07; acc: 0.25
Batch: 120; loss: 2.06; acc: 0.28
Batch: 140; loss: 1.88; acc: 0.42
Batch: 160; loss: 1.97; acc: 0.36
Batch: 180; loss: 1.69; acc: 0.48
Batch: 200; loss: 1.81; acc: 0.42
Batch: 220; loss: 1.69; acc: 0.42
Batch: 240; loss: 1.53; acc: 0.47
Batch: 260; loss: 2.37; acc: 0.3
Batch: 280; loss: 1.58; acc: 0.52
Batch: 300; loss: 1.7; acc: 0.41
Batch: 320; loss: 1.6; acc: 0.41
Batch: 340; loss: 1.73; acc: 0.45
Batch: 360; loss: 1.64; acc: 0.48
Batch: 380; loss: 1.35; acc: 0.56
Batch: 400; loss: 1.95; acc: 0.34
Batch: 420; loss: 1.59; acc: 0.38
Batch: 440; loss: 2.17; acc: 0.25
Batch: 460; loss: 1.46; acc: 0.5
Batch: 480; loss: 1.73; acc: 0.47
Batch: 500; loss: 1.32; acc: 0.59
Batch: 520; loss: 1.52; acc: 0.5
Batch: 540; loss: 1.52; acc: 0.52
Batch: 560; loss: 1.1; acc: 0.69
Batch: 580; loss: 1.81; acc: 0.34
Batch: 600; loss: 1.22; acc: 0.62
Batch: 620; loss: 1.35; acc: 0.5
Batch: 640; loss: 1.99; acc: 0.33
Batch: 660; loss: 1.41; acc: 0.47
Batch: 680; loss: 1.93; acc: 0.39
Batch: 700; loss: 1.44; acc: 0.52
Batch: 720; loss: 1.41; acc: 0.47
Batch: 740; loss: 2.14; acc: 0.27
Batch: 760; loss: 1.43; acc: 0.5
Batch: 780; loss: 1.36; acc: 0.45
Train Epoch over. train_loss: 1.68; train_accuracy: 0.42 

Batch: 0; loss: 1.87; acc: 0.45
Batch: 20; loss: 1.91; acc: 0.38
Batch: 40; loss: 1.41; acc: 0.56
Batch: 60; loss: 1.78; acc: 0.45
Batch: 80; loss: 1.73; acc: 0.47
Batch: 100; loss: 1.49; acc: 0.48
Batch: 120; loss: 1.97; acc: 0.38
Batch: 140; loss: 1.87; acc: 0.47
Val Epoch over. val_loss: 1.9136203884319136; val_accuracy: 0.42147691082802546 

The current subspace-distance is: 2.0282544937799685e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 1.84; acc: 0.5
Batch: 20; loss: 1.52; acc: 0.38
Batch: 40; loss: 1.67; acc: 0.44
Batch: 60; loss: 1.25; acc: 0.56
Batch: 80; loss: 1.4; acc: 0.5
Batch: 100; loss: 1.43; acc: 0.53
Batch: 120; loss: 1.9; acc: 0.34
Batch: 140; loss: 1.44; acc: 0.53
Batch: 160; loss: 1.67; acc: 0.42
Batch: 180; loss: 1.29; acc: 0.5
Batch: 200; loss: 1.32; acc: 0.55
Batch: 220; loss: 1.5; acc: 0.5
Batch: 240; loss: 1.77; acc: 0.5
Batch: 260; loss: 1.55; acc: 0.42
Batch: 280; loss: 1.43; acc: 0.41
Batch: 300; loss: 1.42; acc: 0.55
Batch: 320; loss: 1.32; acc: 0.48
Batch: 340; loss: 1.52; acc: 0.48
Batch: 360; loss: 1.29; acc: 0.56
Batch: 380; loss: 1.37; acc: 0.55
Batch: 400; loss: 1.28; acc: 0.58
Batch: 420; loss: 1.2; acc: 0.62
Batch: 440; loss: 1.38; acc: 0.53
Batch: 460; loss: 1.19; acc: 0.59
Batch: 480; loss: 1.15; acc: 0.62
Batch: 500; loss: 1.3; acc: 0.56
Batch: 520; loss: 1.34; acc: 0.53
Batch: 540; loss: 1.24; acc: 0.59
Batch: 560; loss: 1.7; acc: 0.45
Batch: 580; loss: 1.36; acc: 0.55
Batch: 600; loss: 1.18; acc: 0.58
Batch: 620; loss: 1.27; acc: 0.58
Batch: 640; loss: 1.31; acc: 0.5
Batch: 660; loss: 1.44; acc: 0.48
Batch: 680; loss: 0.81; acc: 0.7
Batch: 700; loss: 1.36; acc: 0.58
Batch: 720; loss: 1.34; acc: 0.52
Batch: 740; loss: 1.48; acc: 0.47
Batch: 760; loss: 1.21; acc: 0.61
Batch: 780; loss: 1.03; acc: 0.7
Train Epoch over. train_loss: 1.4; train_accuracy: 0.52 

Batch: 0; loss: 1.22; acc: 0.58
Batch: 20; loss: 1.42; acc: 0.48
Batch: 40; loss: 1.07; acc: 0.64
Batch: 60; loss: 1.24; acc: 0.58
Batch: 80; loss: 1.16; acc: 0.61
Batch: 100; loss: 1.12; acc: 0.62
Batch: 120; loss: 1.52; acc: 0.5
Batch: 140; loss: 1.1; acc: 0.59
Val Epoch over. val_loss: 1.2297229956669413; val_accuracy: 0.5526472929936306 

The current subspace-distance is: 2.7790110834757797e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.22; acc: 0.56
Batch: 20; loss: 1.69; acc: 0.48
Batch: 40; loss: 1.55; acc: 0.52
Batch: 60; loss: 1.16; acc: 0.64
Batch: 80; loss: 1.16; acc: 0.59
Batch: 100; loss: 1.35; acc: 0.5
Batch: 120; loss: 1.29; acc: 0.59
Batch: 140; loss: 1.35; acc: 0.53
Batch: 160; loss: 1.18; acc: 0.61
Batch: 180; loss: 1.07; acc: 0.66
Batch: 200; loss: 1.18; acc: 0.62
Batch: 220; loss: 1.26; acc: 0.59
Batch: 240; loss: 1.4; acc: 0.55
Batch: 260; loss: 1.27; acc: 0.59
Batch: 280; loss: 1.15; acc: 0.59
Batch: 300; loss: 1.14; acc: 0.59
Batch: 320; loss: 2.19; acc: 0.42
Batch: 340; loss: 1.23; acc: 0.58
Batch: 360; loss: 1.05; acc: 0.64
Batch: 380; loss: 1.42; acc: 0.52
Batch: 400; loss: 1.34; acc: 0.56
Batch: 420; loss: 1.25; acc: 0.53
Batch: 440; loss: 1.33; acc: 0.56
Batch: 460; loss: 1.48; acc: 0.61
Batch: 480; loss: 1.31; acc: 0.58
Batch: 500; loss: 1.31; acc: 0.58
Batch: 520; loss: 1.37; acc: 0.5
Batch: 540; loss: 1.2; acc: 0.56
Batch: 560; loss: 1.41; acc: 0.59
Batch: 580; loss: 1.13; acc: 0.64
Batch: 600; loss: 1.11; acc: 0.67
Batch: 620; loss: 1.51; acc: 0.5
Batch: 640; loss: 0.88; acc: 0.7
Batch: 660; loss: 1.19; acc: 0.56
Batch: 680; loss: 1.42; acc: 0.5
Batch: 700; loss: 1.55; acc: 0.45
Batch: 720; loss: 1.45; acc: 0.53
Batch: 740; loss: 1.26; acc: 0.62
Batch: 760; loss: 1.22; acc: 0.56
Batch: 780; loss: 1.22; acc: 0.62
Train Epoch over. train_loss: 1.28; train_accuracy: 0.57 

Batch: 0; loss: 1.55; acc: 0.47
Batch: 20; loss: 1.62; acc: 0.55
Batch: 40; loss: 1.23; acc: 0.58
Batch: 60; loss: 1.2; acc: 0.67
Batch: 80; loss: 0.98; acc: 0.64
Batch: 100; loss: 1.35; acc: 0.52
Batch: 120; loss: 1.55; acc: 0.47
Batch: 140; loss: 1.04; acc: 0.62
Val Epoch over. val_loss: 1.3579088905055052; val_accuracy: 0.5529458598726115 

The current subspace-distance is: 3.440913496888243e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 1.12; acc: 0.62
Batch: 20; loss: 1.36; acc: 0.55
Batch: 40; loss: 1.06; acc: 0.64
Batch: 60; loss: 1.43; acc: 0.48
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 1.09; acc: 0.59
Batch: 120; loss: 1.7; acc: 0.48
Batch: 140; loss: 1.61; acc: 0.47
Batch: 160; loss: 1.28; acc: 0.59
Batch: 180; loss: 1.15; acc: 0.61
Batch: 200; loss: 1.36; acc: 0.56
Batch: 220; loss: 1.36; acc: 0.52
Batch: 240; loss: 1.32; acc: 0.52
Batch: 260; loss: 1.55; acc: 0.56
Batch: 280; loss: 1.34; acc: 0.53
Batch: 300; loss: 1.42; acc: 0.55
Batch: 320; loss: 1.65; acc: 0.47
Batch: 340; loss: 1.05; acc: 0.64
Batch: 360; loss: 1.29; acc: 0.59
Batch: 380; loss: 1.37; acc: 0.53
Batch: 400; loss: 1.18; acc: 0.58
Batch: 420; loss: 1.23; acc: 0.59
Batch: 440; loss: 1.2; acc: 0.56
Batch: 460; loss: 1.01; acc: 0.73
Batch: 480; loss: 0.99; acc: 0.64
Batch: 500; loss: 2.25; acc: 0.48
Batch: 520; loss: 1.27; acc: 0.58
Batch: 540; loss: 0.84; acc: 0.77
Batch: 560; loss: 0.89; acc: 0.67
Batch: 580; loss: 1.24; acc: 0.55
Batch: 600; loss: 1.21; acc: 0.66
Batch: 620; loss: 1.34; acc: 0.55
Batch: 640; loss: 1.53; acc: 0.47
Batch: 660; loss: 1.2; acc: 0.56
Batch: 680; loss: 1.2; acc: 0.59
Batch: 700; loss: 1.23; acc: 0.62
Batch: 720; loss: 1.62; acc: 0.52
Batch: 740; loss: 0.98; acc: 0.69
Batch: 760; loss: 1.04; acc: 0.62
Batch: 780; loss: 0.99; acc: 0.73
Train Epoch over. train_loss: 1.24; train_accuracy: 0.59 

Batch: 0; loss: 1.72; acc: 0.52
Batch: 20; loss: 2.02; acc: 0.44
Batch: 40; loss: 1.78; acc: 0.53
Batch: 60; loss: 1.78; acc: 0.56
Batch: 80; loss: 1.49; acc: 0.45
Batch: 100; loss: 1.61; acc: 0.41
Batch: 120; loss: 1.91; acc: 0.47
Batch: 140; loss: 1.96; acc: 0.42
Val Epoch over. val_loss: 1.8774720415188249; val_accuracy: 0.4407842356687898 

The current subspace-distance is: 3.849402128253132e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 2.19; acc: 0.39
Batch: 20; loss: 1.07; acc: 0.66
Batch: 40; loss: 1.0; acc: 0.67
Batch: 60; loss: 1.1; acc: 0.66
Batch: 80; loss: 1.09; acc: 0.61
Batch: 100; loss: 1.14; acc: 0.61
Batch: 120; loss: 1.28; acc: 0.5
Batch: 140; loss: 1.5; acc: 0.55
Batch: 160; loss: 1.03; acc: 0.69
Batch: 180; loss: 1.3; acc: 0.61
Batch: 200; loss: 0.95; acc: 0.73
Batch: 220; loss: 1.22; acc: 0.52
Batch: 240; loss: 1.14; acc: 0.69
Batch: 260; loss: 1.02; acc: 0.67
Batch: 280; loss: 1.77; acc: 0.5
Batch: 300; loss: 1.09; acc: 0.61
Batch: 320; loss: 1.34; acc: 0.52
Batch: 340; loss: 1.21; acc: 0.55
Batch: 360; loss: 1.13; acc: 0.62
Batch: 380; loss: 1.19; acc: 0.61
Batch: 400; loss: 1.45; acc: 0.45
Batch: 420; loss: 1.05; acc: 0.62
Batch: 440; loss: 0.91; acc: 0.72
Batch: 460; loss: 1.29; acc: 0.58
Batch: 480; loss: 0.87; acc: 0.72
Batch: 500; loss: 1.28; acc: 0.55
Batch: 520; loss: 1.45; acc: 0.56
Batch: 540; loss: 1.12; acc: 0.66
Batch: 560; loss: 1.04; acc: 0.61
Batch: 580; loss: 0.98; acc: 0.62
Batch: 600; loss: 1.09; acc: 0.64
Batch: 620; loss: 1.06; acc: 0.75
Batch: 640; loss: 1.28; acc: 0.62
Batch: 660; loss: 1.08; acc: 0.61
Batch: 680; loss: 1.32; acc: 0.59
Batch: 700; loss: 1.18; acc: 0.58
Batch: 720; loss: 1.18; acc: 0.62
Batch: 740; loss: 1.26; acc: 0.58
Batch: 760; loss: 0.91; acc: 0.75
Batch: 780; loss: 1.05; acc: 0.58
Train Epoch over. train_loss: 1.23; train_accuracy: 0.6 

Batch: 0; loss: 1.46; acc: 0.5
Batch: 20; loss: 1.82; acc: 0.5
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.47; acc: 0.58
Batch: 80; loss: 1.29; acc: 0.61
Batch: 100; loss: 1.51; acc: 0.56
Batch: 120; loss: 1.76; acc: 0.45
Batch: 140; loss: 1.57; acc: 0.44
Val Epoch over. val_loss: 1.5957683689275366; val_accuracy: 0.48158837579617836 

The current subspace-distance is: 4.504300522967242e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 1.58; acc: 0.47
Batch: 20; loss: 1.33; acc: 0.58
Batch: 40; loss: 1.28; acc: 0.62
Batch: 60; loss: 1.94; acc: 0.47
Batch: 80; loss: 1.05; acc: 0.69
Batch: 100; loss: 1.6; acc: 0.45
Batch: 120; loss: 0.81; acc: 0.73
Batch: 140; loss: 1.08; acc: 0.64
Batch: 160; loss: 1.3; acc: 0.56
Batch: 180; loss: 1.98; acc: 0.5
Batch: 200; loss: 1.27; acc: 0.59
Batch: 220; loss: 1.5; acc: 0.5
Batch: 240; loss: 0.93; acc: 0.7
Batch: 260; loss: 1.02; acc: 0.66
Batch: 280; loss: 1.07; acc: 0.69
Batch: 300; loss: 1.07; acc: 0.62
Batch: 320; loss: 1.09; acc: 0.56
Batch: 340; loss: 1.06; acc: 0.62
Batch: 360; loss: 0.98; acc: 0.7
Batch: 380; loss: 0.9; acc: 0.72
Batch: 400; loss: 1.31; acc: 0.52
Batch: 420; loss: 1.0; acc: 0.67
Batch: 440; loss: 1.14; acc: 0.67
Batch: 460; loss: 1.72; acc: 0.52
Batch: 480; loss: 0.96; acc: 0.61
Batch: 500; loss: 1.05; acc: 0.61
Batch: 520; loss: 1.43; acc: 0.48
Batch: 540; loss: 1.02; acc: 0.61
Batch: 560; loss: 1.44; acc: 0.61
Batch: 580; loss: 0.92; acc: 0.69
Batch: 600; loss: 1.59; acc: 0.45
Batch: 620; loss: 1.32; acc: 0.58
Batch: 640; loss: 1.18; acc: 0.52
Batch: 660; loss: 1.01; acc: 0.66
Batch: 680; loss: 1.41; acc: 0.56
Batch: 700; loss: 1.46; acc: 0.56
Batch: 720; loss: 1.21; acc: 0.67
Batch: 740; loss: 1.01; acc: 0.7
Batch: 760; loss: 1.21; acc: 0.61
Batch: 780; loss: 1.42; acc: 0.52
Train Epoch over. train_loss: 1.21; train_accuracy: 0.6 

Batch: 0; loss: 1.93; acc: 0.48
Batch: 20; loss: 1.74; acc: 0.5
Batch: 40; loss: 1.81; acc: 0.53
Batch: 60; loss: 1.9; acc: 0.44
Batch: 80; loss: 1.84; acc: 0.42
Batch: 100; loss: 1.91; acc: 0.47
Batch: 120; loss: 2.39; acc: 0.42
Batch: 140; loss: 1.78; acc: 0.55
Val Epoch over. val_loss: 1.8574666658024879; val_accuracy: 0.4809912420382166 

The current subspace-distance is: 4.927352711092681e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 2.29; acc: 0.48
Batch: 20; loss: 1.34; acc: 0.52
Batch: 40; loss: 1.06; acc: 0.62
Batch: 60; loss: 0.82; acc: 0.7
Batch: 80; loss: 1.02; acc: 0.66
Batch: 100; loss: 1.17; acc: 0.59
Batch: 120; loss: 1.24; acc: 0.61
Batch: 140; loss: 1.76; acc: 0.44
Batch: 160; loss: 0.88; acc: 0.66
Batch: 180; loss: 1.54; acc: 0.48
Batch: 200; loss: 1.1; acc: 0.62
Batch: 220; loss: 1.03; acc: 0.72
Batch: 240; loss: 1.41; acc: 0.53
Batch: 260; loss: 1.32; acc: 0.55
Batch: 280; loss: 0.93; acc: 0.69
Batch: 300; loss: 1.65; acc: 0.48
Batch: 320; loss: 1.43; acc: 0.5
Batch: 340; loss: 0.79; acc: 0.67
Batch: 360; loss: 1.63; acc: 0.5
Batch: 380; loss: 1.42; acc: 0.52
Batch: 400; loss: 1.3; acc: 0.64
Batch: 420; loss: 0.95; acc: 0.69
Batch: 440; loss: 1.56; acc: 0.52
Batch: 460; loss: 1.13; acc: 0.69
Batch: 480; loss: 1.39; acc: 0.55
Batch: 500; loss: 1.56; acc: 0.55
Batch: 520; loss: 1.65; acc: 0.62
Batch: 540; loss: 0.92; acc: 0.64
Batch: 560; loss: 1.16; acc: 0.64
Batch: 580; loss: 1.92; acc: 0.41
Batch: 600; loss: 1.54; acc: 0.52
Batch: 620; loss: 1.32; acc: 0.53
Batch: 640; loss: 1.7; acc: 0.47
Batch: 660; loss: 1.36; acc: 0.47
Batch: 680; loss: 0.93; acc: 0.69
Batch: 700; loss: 1.27; acc: 0.56
Batch: 720; loss: 1.08; acc: 0.69
Batch: 740; loss: 1.13; acc: 0.61
Batch: 760; loss: 1.22; acc: 0.59
Batch: 780; loss: 1.0; acc: 0.61
Train Epoch over. train_loss: 1.21; train_accuracy: 0.6 

Batch: 0; loss: 1.24; acc: 0.58
Batch: 20; loss: 1.44; acc: 0.53
Batch: 40; loss: 1.09; acc: 0.62
Batch: 60; loss: 1.24; acc: 0.56
Batch: 80; loss: 1.27; acc: 0.59
Batch: 100; loss: 1.38; acc: 0.56
Batch: 120; loss: 1.42; acc: 0.56
Batch: 140; loss: 1.01; acc: 0.69
Val Epoch over. val_loss: 1.2285781973486494; val_accuracy: 0.5705613057324841 

The current subspace-distance is: 5.328451516106725e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 1.28; acc: 0.53
Batch: 20; loss: 1.28; acc: 0.62
Batch: 40; loss: 1.04; acc: 0.67
Batch: 60; loss: 1.07; acc: 0.67
Batch: 80; loss: 1.08; acc: 0.61
Batch: 100; loss: 0.74; acc: 0.8
Batch: 120; loss: 1.13; acc: 0.64
Batch: 140; loss: 1.08; acc: 0.72
Batch: 160; loss: 1.37; acc: 0.58
Batch: 180; loss: 1.23; acc: 0.55
Batch: 200; loss: 0.85; acc: 0.78
Batch: 220; loss: 1.13; acc: 0.67
Batch: 240; loss: 1.28; acc: 0.59
Batch: 260; loss: 1.3; acc: 0.53
Batch: 280; loss: 1.64; acc: 0.45
Batch: 300; loss: 1.18; acc: 0.59
Batch: 320; loss: 1.33; acc: 0.61
Batch: 340; loss: 1.22; acc: 0.53
Batch: 360; loss: 1.2; acc: 0.53
Batch: 380; loss: 1.24; acc: 0.62
Batch: 400; loss: 1.24; acc: 0.52
Batch: 420; loss: 1.55; acc: 0.45
Batch: 440; loss: 4.29; acc: 0.23
Batch: 460; loss: 1.34; acc: 0.55
Batch: 480; loss: 1.43; acc: 0.5
Batch: 500; loss: 1.57; acc: 0.42
Batch: 520; loss: 1.07; acc: 0.64
Batch: 540; loss: 1.02; acc: 0.66
Batch: 560; loss: 1.23; acc: 0.58
Batch: 580; loss: 1.0; acc: 0.67
Batch: 600; loss: 1.27; acc: 0.53
Batch: 620; loss: 0.98; acc: 0.69
Batch: 640; loss: 1.09; acc: 0.66
Batch: 660; loss: 1.34; acc: 0.56
Batch: 680; loss: 1.26; acc: 0.59
Batch: 700; loss: 1.17; acc: 0.59
Batch: 720; loss: 1.52; acc: 0.55
Batch: 740; loss: 1.26; acc: 0.53
Batch: 760; loss: 1.24; acc: 0.55
Batch: 780; loss: 1.17; acc: 0.62
Train Epoch over. train_loss: 1.2; train_accuracy: 0.61 

Batch: 0; loss: 1.31; acc: 0.64
Batch: 20; loss: 1.23; acc: 0.64
Batch: 40; loss: 0.99; acc: 0.66
Batch: 60; loss: 1.24; acc: 0.67
Batch: 80; loss: 1.06; acc: 0.66
Batch: 100; loss: 1.32; acc: 0.64
Batch: 120; loss: 1.6; acc: 0.34
Batch: 140; loss: 1.19; acc: 0.62
Val Epoch over. val_loss: 1.2449184773833888; val_accuracy: 0.5934514331210191 

The current subspace-distance is: 5.6277549447258934e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.11; acc: 0.66
Batch: 20; loss: 0.86; acc: 0.75
Batch: 40; loss: 0.83; acc: 0.75
Batch: 60; loss: 0.88; acc: 0.7
Batch: 80; loss: 0.95; acc: 0.62
Batch: 100; loss: 0.92; acc: 0.69
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.77; acc: 0.75
Batch: 160; loss: 0.86; acc: 0.7
Batch: 180; loss: 1.11; acc: 0.69
Batch: 200; loss: 0.9; acc: 0.77
Batch: 220; loss: 0.71; acc: 0.77
Batch: 240; loss: 1.11; acc: 0.66
Batch: 260; loss: 1.26; acc: 0.67
Batch: 280; loss: 0.82; acc: 0.72
Batch: 300; loss: 0.73; acc: 0.78
Batch: 320; loss: 0.87; acc: 0.69
Batch: 340; loss: 0.75; acc: 0.81
Batch: 360; loss: 0.86; acc: 0.7
Batch: 380; loss: 0.92; acc: 0.73
Batch: 400; loss: 0.84; acc: 0.64
Batch: 420; loss: 1.17; acc: 0.62
Batch: 440; loss: 0.81; acc: 0.78
Batch: 460; loss: 0.98; acc: 0.64
Batch: 480; loss: 0.79; acc: 0.77
Batch: 500; loss: 1.14; acc: 0.7
Batch: 520; loss: 0.91; acc: 0.69
Batch: 540; loss: 1.02; acc: 0.7
Batch: 560; loss: 1.09; acc: 0.66
Batch: 580; loss: 0.89; acc: 0.73
Batch: 600; loss: 0.93; acc: 0.62
Batch: 620; loss: 0.9; acc: 0.75
Batch: 640; loss: 0.84; acc: 0.69
Batch: 660; loss: 1.04; acc: 0.64
Batch: 680; loss: 0.9; acc: 0.73
Batch: 700; loss: 0.7; acc: 0.72
Batch: 720; loss: 0.94; acc: 0.62
Batch: 740; loss: 0.85; acc: 0.78
Batch: 760; loss: 0.92; acc: 0.78
Batch: 780; loss: 1.14; acc: 0.62
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 1.31; acc: 0.59
Batch: 20; loss: 1.38; acc: 0.45
Batch: 40; loss: 1.18; acc: 0.59
Batch: 60; loss: 1.45; acc: 0.52
Batch: 80; loss: 1.38; acc: 0.55
Batch: 100; loss: 1.47; acc: 0.5
Batch: 120; loss: 1.87; acc: 0.52
Batch: 140; loss: 1.23; acc: 0.53
Val Epoch over. val_loss: 1.3678332684905665; val_accuracy: 0.5481687898089171 

The current subspace-distance is: 5.8895460824714974e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 1.62; acc: 0.48
Batch: 20; loss: 0.85; acc: 0.67
Batch: 40; loss: 1.23; acc: 0.61
Batch: 60; loss: 0.79; acc: 0.72
Batch: 80; loss: 0.9; acc: 0.69
Batch: 100; loss: 0.96; acc: 0.66
Batch: 120; loss: 1.02; acc: 0.66
Batch: 140; loss: 0.69; acc: 0.8
Batch: 160; loss: 1.17; acc: 0.66
Batch: 180; loss: 0.89; acc: 0.75
Batch: 200; loss: 0.93; acc: 0.7
Batch: 220; loss: 0.79; acc: 0.78
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.76; acc: 0.75
Batch: 280; loss: 0.85; acc: 0.75
Batch: 300; loss: 1.14; acc: 0.66
Batch: 320; loss: 1.02; acc: 0.66
Batch: 340; loss: 0.57; acc: 0.83
Batch: 360; loss: 0.99; acc: 0.64
Batch: 380; loss: 1.1; acc: 0.66
Batch: 400; loss: 0.9; acc: 0.69
Batch: 420; loss: 1.04; acc: 0.69
Batch: 440; loss: 1.01; acc: 0.7
Batch: 460; loss: 0.84; acc: 0.7
Batch: 480; loss: 0.73; acc: 0.77
Batch: 500; loss: 1.04; acc: 0.61
Batch: 520; loss: 0.91; acc: 0.7
Batch: 540; loss: 0.83; acc: 0.67
Batch: 560; loss: 0.84; acc: 0.72
Batch: 580; loss: 1.0; acc: 0.72
Batch: 600; loss: 0.76; acc: 0.73
Batch: 620; loss: 0.98; acc: 0.64
Batch: 640; loss: 0.93; acc: 0.69
Batch: 660; loss: 1.26; acc: 0.59
Batch: 680; loss: 1.0; acc: 0.69
Batch: 700; loss: 1.02; acc: 0.64
Batch: 720; loss: 0.76; acc: 0.72
Batch: 740; loss: 1.21; acc: 0.59
Batch: 760; loss: 0.93; acc: 0.69
Batch: 780; loss: 0.61; acc: 0.81
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 1.16; acc: 0.58
Batch: 20; loss: 1.26; acc: 0.58
Batch: 40; loss: 0.89; acc: 0.72
Batch: 60; loss: 1.13; acc: 0.62
Batch: 80; loss: 0.89; acc: 0.75
Batch: 100; loss: 1.2; acc: 0.67
Batch: 120; loss: 1.67; acc: 0.47
Batch: 140; loss: 0.95; acc: 0.66
Val Epoch over. val_loss: 1.133249446844599; val_accuracy: 0.6296775477707006 

The current subspace-distance is: 6.253886385820806e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 1.03; acc: 0.62
Batch: 20; loss: 0.95; acc: 0.72
Batch: 40; loss: 1.09; acc: 0.66
Batch: 60; loss: 0.93; acc: 0.66
Batch: 80; loss: 0.82; acc: 0.73
Batch: 100; loss: 0.72; acc: 0.69
Batch: 120; loss: 0.78; acc: 0.75
Batch: 140; loss: 0.75; acc: 0.78
Batch: 160; loss: 0.91; acc: 0.69
Batch: 180; loss: 1.12; acc: 0.58
Batch: 200; loss: 0.84; acc: 0.73
Batch: 220; loss: 1.03; acc: 0.64
Batch: 240; loss: 0.83; acc: 0.64
Batch: 260; loss: 0.68; acc: 0.73
Batch: 280; loss: 0.85; acc: 0.64
Batch: 300; loss: 0.94; acc: 0.73
Batch: 320; loss: 0.86; acc: 0.75
Batch: 340; loss: 0.97; acc: 0.64
Batch: 360; loss: 1.09; acc: 0.69
Batch: 380; loss: 1.17; acc: 0.62
Batch: 400; loss: 1.22; acc: 0.58
Batch: 420; loss: 0.93; acc: 0.69
Batch: 440; loss: 1.01; acc: 0.62
Batch: 460; loss: 0.82; acc: 0.72
Batch: 480; loss: 0.95; acc: 0.73
Batch: 500; loss: 0.92; acc: 0.66
Batch: 520; loss: 1.01; acc: 0.7
Batch: 540; loss: 0.85; acc: 0.67
Batch: 560; loss: 1.04; acc: 0.67
Batch: 580; loss: 0.99; acc: 0.77
Batch: 600; loss: 1.0; acc: 0.7
Batch: 620; loss: 0.99; acc: 0.64
Batch: 640; loss: 0.82; acc: 0.77
Batch: 660; loss: 1.03; acc: 0.61
Batch: 680; loss: 0.93; acc: 0.67
Batch: 700; loss: 1.05; acc: 0.69
Batch: 720; loss: 1.12; acc: 0.67
Batch: 740; loss: 0.81; acc: 0.75
Batch: 760; loss: 1.14; acc: 0.67
Batch: 780; loss: 1.22; acc: 0.59
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 1.13; acc: 0.61
Batch: 20; loss: 1.18; acc: 0.61
Batch: 40; loss: 1.1; acc: 0.64
Batch: 60; loss: 1.27; acc: 0.61
Batch: 80; loss: 1.29; acc: 0.58
Batch: 100; loss: 1.13; acc: 0.59
Batch: 120; loss: 1.56; acc: 0.52
Batch: 140; loss: 0.94; acc: 0.64
Val Epoch over. val_loss: 1.2202834164261058; val_accuracy: 0.5858877388535032 

The current subspace-distance is: 6.758605741197243e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 1.01; acc: 0.69
Batch: 20; loss: 1.19; acc: 0.61
Batch: 40; loss: 0.94; acc: 0.67
Batch: 60; loss: 0.94; acc: 0.69
Batch: 80; loss: 1.14; acc: 0.69
Batch: 100; loss: 0.85; acc: 0.75
Batch: 120; loss: 0.77; acc: 0.78
Batch: 140; loss: 0.81; acc: 0.72
Batch: 160; loss: 0.98; acc: 0.69
Batch: 180; loss: 0.9; acc: 0.67
Batch: 200; loss: 1.09; acc: 0.67
Batch: 220; loss: 0.92; acc: 0.72
Batch: 240; loss: 0.88; acc: 0.72
Batch: 260; loss: 0.94; acc: 0.67
Batch: 280; loss: 0.86; acc: 0.66
Batch: 300; loss: 0.88; acc: 0.7
Batch: 320; loss: 0.84; acc: 0.69
Batch: 340; loss: 0.92; acc: 0.66
Batch: 360; loss: 1.04; acc: 0.64
Batch: 380; loss: 1.28; acc: 0.64
Batch: 400; loss: 0.84; acc: 0.69
Batch: 420; loss: 0.86; acc: 0.73
Batch: 440; loss: 0.99; acc: 0.58
Batch: 460; loss: 0.91; acc: 0.75
Batch: 480; loss: 1.0; acc: 0.67
Batch: 500; loss: 1.1; acc: 0.64
Batch: 520; loss: 0.85; acc: 0.8
Batch: 540; loss: 0.94; acc: 0.7
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.93; acc: 0.7
Batch: 600; loss: 0.89; acc: 0.66
Batch: 620; loss: 0.53; acc: 0.84
Batch: 640; loss: 1.13; acc: 0.59
Batch: 660; loss: 1.24; acc: 0.61
Batch: 680; loss: 0.83; acc: 0.73
Batch: 700; loss: 0.8; acc: 0.69
Batch: 720; loss: 0.86; acc: 0.64
Batch: 740; loss: 0.62; acc: 0.78
Batch: 760; loss: 0.88; acc: 0.72
Batch: 780; loss: 0.66; acc: 0.77
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 1.69; acc: 0.55
Batch: 20; loss: 1.8; acc: 0.45
Batch: 40; loss: 1.37; acc: 0.59
Batch: 60; loss: 1.6; acc: 0.52
Batch: 80; loss: 1.64; acc: 0.56
Batch: 100; loss: 1.24; acc: 0.56
Batch: 120; loss: 1.8; acc: 0.53
Batch: 140; loss: 1.36; acc: 0.53
Val Epoch over. val_loss: 1.5561041516862857; val_accuracy: 0.5458797770700637 

The current subspace-distance is: 7.12870605639182e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 1.31; acc: 0.64
Batch: 20; loss: 0.99; acc: 0.67
Batch: 40; loss: 0.92; acc: 0.69
Batch: 60; loss: 0.87; acc: 0.72
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.84; acc: 0.75
Batch: 120; loss: 1.14; acc: 0.7
Batch: 140; loss: 0.86; acc: 0.73
Batch: 160; loss: 1.16; acc: 0.55
Batch: 180; loss: 0.9; acc: 0.66
Batch: 200; loss: 1.11; acc: 0.61
Batch: 220; loss: 0.99; acc: 0.67
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.92; acc: 0.61
Batch: 280; loss: 0.85; acc: 0.69
Batch: 300; loss: 0.69; acc: 0.83
Batch: 320; loss: 1.1; acc: 0.61
Batch: 340; loss: 1.07; acc: 0.59
Batch: 360; loss: 0.82; acc: 0.7
Batch: 380; loss: 0.83; acc: 0.73
Batch: 400; loss: 0.91; acc: 0.64
Batch: 420; loss: 0.75; acc: 0.72
Batch: 440; loss: 0.87; acc: 0.72
Batch: 460; loss: 0.74; acc: 0.75
Batch: 480; loss: 0.85; acc: 0.7
Batch: 500; loss: 1.28; acc: 0.58
Batch: 520; loss: 0.97; acc: 0.7
Batch: 540; loss: 1.07; acc: 0.59
Batch: 560; loss: 1.04; acc: 0.61
Batch: 580; loss: 0.73; acc: 0.75
Batch: 600; loss: 0.9; acc: 0.7
Batch: 620; loss: 1.05; acc: 0.72
Batch: 640; loss: 1.04; acc: 0.59
Batch: 660; loss: 1.02; acc: 0.69
Batch: 680; loss: 0.83; acc: 0.72
Batch: 700; loss: 0.97; acc: 0.67
Batch: 720; loss: 0.96; acc: 0.7
Batch: 740; loss: 0.96; acc: 0.75
Batch: 760; loss: 0.81; acc: 0.77
Batch: 780; loss: 0.94; acc: 0.66
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.85; acc: 0.67
Batch: 40; loss: 0.77; acc: 0.66
Batch: 60; loss: 0.89; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.87; acc: 0.72
Batch: 120; loss: 1.08; acc: 0.62
Batch: 140; loss: 0.82; acc: 0.7
Val Epoch over. val_loss: 0.9353257448050627; val_accuracy: 0.692078025477707 

The current subspace-distance is: 7.491128781111911e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 0.88; acc: 0.75
Batch: 40; loss: 0.97; acc: 0.7
Batch: 60; loss: 1.0; acc: 0.69
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.91; acc: 0.66
Batch: 120; loss: 0.98; acc: 0.7
Batch: 140; loss: 0.97; acc: 0.69
Batch: 160; loss: 0.92; acc: 0.73
Batch: 180; loss: 0.93; acc: 0.72
Batch: 200; loss: 0.77; acc: 0.78
Batch: 220; loss: 0.93; acc: 0.69
Batch: 240; loss: 0.73; acc: 0.73
Batch: 260; loss: 0.87; acc: 0.75
Batch: 280; loss: 0.97; acc: 0.66
Batch: 300; loss: 0.95; acc: 0.73
Batch: 320; loss: 0.82; acc: 0.73
Batch: 340; loss: 1.21; acc: 0.52
Batch: 360; loss: 0.93; acc: 0.66
Batch: 380; loss: 0.85; acc: 0.72
Batch: 400; loss: 0.96; acc: 0.61
Batch: 420; loss: 0.95; acc: 0.7
Batch: 440; loss: 0.68; acc: 0.73
Batch: 460; loss: 0.78; acc: 0.73
Batch: 480; loss: 0.99; acc: 0.69
Batch: 500; loss: 1.03; acc: 0.62
Batch: 520; loss: 0.8; acc: 0.67
Batch: 540; loss: 0.97; acc: 0.66
Batch: 560; loss: 0.93; acc: 0.73
Batch: 580; loss: 0.98; acc: 0.73
Batch: 600; loss: 0.66; acc: 0.73
Batch: 620; loss: 1.04; acc: 0.66
Batch: 640; loss: 1.07; acc: 0.61
Batch: 660; loss: 0.83; acc: 0.75
Batch: 680; loss: 0.94; acc: 0.67
Batch: 700; loss: 0.78; acc: 0.7
Batch: 720; loss: 0.99; acc: 0.66
Batch: 740; loss: 0.94; acc: 0.7
Batch: 760; loss: 0.74; acc: 0.78
Batch: 780; loss: 1.25; acc: 0.61
Train Epoch over. train_loss: 0.94; train_accuracy: 0.69 

Batch: 0; loss: 0.9; acc: 0.62
Batch: 20; loss: 1.14; acc: 0.66
Batch: 40; loss: 0.69; acc: 0.73
Batch: 60; loss: 0.81; acc: 0.72
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.9; acc: 0.72
Batch: 120; loss: 1.31; acc: 0.61
Batch: 140; loss: 0.83; acc: 0.69
Val Epoch over. val_loss: 0.9108371404325886; val_accuracy: 0.6925756369426752 

The current subspace-distance is: 7.820307655492797e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.96; acc: 0.61
Batch: 20; loss: 0.72; acc: 0.73
Batch: 40; loss: 1.13; acc: 0.64
Batch: 60; loss: 1.11; acc: 0.62
Batch: 80; loss: 1.14; acc: 0.56
Batch: 100; loss: 0.87; acc: 0.72
Batch: 120; loss: 1.0; acc: 0.64
Batch: 140; loss: 0.76; acc: 0.72
Batch: 160; loss: 0.75; acc: 0.77
Batch: 180; loss: 1.09; acc: 0.69
Batch: 200; loss: 0.96; acc: 0.75
Batch: 220; loss: 0.81; acc: 0.77
Batch: 240; loss: 1.22; acc: 0.59
Batch: 260; loss: 1.03; acc: 0.62
Batch: 280; loss: 0.96; acc: 0.69
Batch: 300; loss: 0.76; acc: 0.75
Batch: 320; loss: 1.1; acc: 0.64
Batch: 340; loss: 0.76; acc: 0.77
Batch: 360; loss: 0.85; acc: 0.75
Batch: 380; loss: 1.09; acc: 0.64
Batch: 400; loss: 0.88; acc: 0.73
Batch: 420; loss: 1.26; acc: 0.58
Batch: 440; loss: 0.59; acc: 0.8
Batch: 460; loss: 1.23; acc: 0.62
Batch: 480; loss: 0.83; acc: 0.72
Batch: 500; loss: 0.88; acc: 0.66
Batch: 520; loss: 1.05; acc: 0.64
Batch: 540; loss: 0.94; acc: 0.69
Batch: 560; loss: 0.82; acc: 0.72
Batch: 580; loss: 0.85; acc: 0.72
Batch: 600; loss: 1.1; acc: 0.73
Batch: 620; loss: 0.89; acc: 0.62
Batch: 640; loss: 0.89; acc: 0.66
Batch: 660; loss: 0.9; acc: 0.73
Batch: 680; loss: 0.88; acc: 0.69
Batch: 700; loss: 0.93; acc: 0.72
Batch: 720; loss: 0.98; acc: 0.69
Batch: 740; loss: 1.13; acc: 0.66
Batch: 760; loss: 1.06; acc: 0.69
Batch: 780; loss: 0.98; acc: 0.64
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 0.94; acc: 0.62
Batch: 20; loss: 0.97; acc: 0.66
Batch: 40; loss: 0.74; acc: 0.73
Batch: 60; loss: 0.77; acc: 0.72
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 0.89; acc: 0.73
Batch: 120; loss: 1.19; acc: 0.58
Batch: 140; loss: 1.0; acc: 0.66
Val Epoch over. val_loss: 0.9422110436828273; val_accuracy: 0.6952627388535032 

The current subspace-distance is: 8.069650357356295e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.77; acc: 0.73
Batch: 20; loss: 0.88; acc: 0.7
Batch: 40; loss: 0.88; acc: 0.72
Batch: 60; loss: 0.93; acc: 0.73
Batch: 80; loss: 0.62; acc: 0.78
Batch: 100; loss: 0.95; acc: 0.66
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 1.15; acc: 0.67
Batch: 160; loss: 0.95; acc: 0.66
Batch: 180; loss: 0.97; acc: 0.67
Batch: 200; loss: 1.32; acc: 0.61
Batch: 220; loss: 0.96; acc: 0.67
Batch: 240; loss: 0.76; acc: 0.72
Batch: 260; loss: 0.83; acc: 0.7
Batch: 280; loss: 1.08; acc: 0.64
Batch: 300; loss: 0.85; acc: 0.69
Batch: 320; loss: 0.95; acc: 0.66
Batch: 340; loss: 0.76; acc: 0.77
Batch: 360; loss: 0.9; acc: 0.69
Batch: 380; loss: 0.67; acc: 0.8
Batch: 400; loss: 0.97; acc: 0.72
Batch: 420; loss: 0.87; acc: 0.7
Batch: 440; loss: 1.04; acc: 0.66
Batch: 460; loss: 0.8; acc: 0.72
Batch: 480; loss: 0.78; acc: 0.7
Batch: 500; loss: 1.18; acc: 0.62
Batch: 520; loss: 0.84; acc: 0.69
Batch: 540; loss: 0.85; acc: 0.77
Batch: 560; loss: 0.64; acc: 0.81
Batch: 580; loss: 0.88; acc: 0.75
Batch: 600; loss: 1.08; acc: 0.69
Batch: 620; loss: 0.82; acc: 0.7
Batch: 640; loss: 1.07; acc: 0.59
Batch: 660; loss: 0.89; acc: 0.73
Batch: 680; loss: 0.84; acc: 0.72
Batch: 700; loss: 0.82; acc: 0.7
Batch: 720; loss: 0.67; acc: 0.77
Batch: 740; loss: 0.85; acc: 0.81
Batch: 760; loss: 0.75; acc: 0.7
Batch: 780; loss: 1.09; acc: 0.59
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 0.98; acc: 0.67
Batch: 20; loss: 1.06; acc: 0.64
Batch: 40; loss: 0.89; acc: 0.66
Batch: 60; loss: 1.02; acc: 0.64
Batch: 80; loss: 0.9; acc: 0.72
Batch: 100; loss: 1.08; acc: 0.66
Batch: 120; loss: 1.37; acc: 0.55
Batch: 140; loss: 0.95; acc: 0.61
Val Epoch over. val_loss: 1.0476156932533167; val_accuracy: 0.6492834394904459 

The current subspace-distance is: 8.206101483665407e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 1.07; acc: 0.61
Batch: 20; loss: 1.02; acc: 0.7
Batch: 40; loss: 0.83; acc: 0.72
Batch: 60; loss: 0.92; acc: 0.73
Batch: 80; loss: 1.03; acc: 0.64
Batch: 100; loss: 1.06; acc: 0.73
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.91; acc: 0.69
Batch: 160; loss: 1.03; acc: 0.72
Batch: 180; loss: 1.08; acc: 0.69
Batch: 200; loss: 1.12; acc: 0.66
Batch: 220; loss: 1.48; acc: 0.58
Batch: 240; loss: 0.98; acc: 0.7
Batch: 260; loss: 1.05; acc: 0.67
Batch: 280; loss: 0.93; acc: 0.67
Batch: 300; loss: 0.61; acc: 0.81
Batch: 320; loss: 1.06; acc: 0.67
Batch: 340; loss: 0.95; acc: 0.66
Batch: 360; loss: 0.8; acc: 0.73
Batch: 380; loss: 0.78; acc: 0.67
Batch: 400; loss: 0.86; acc: 0.7
Batch: 420; loss: 0.99; acc: 0.69
Batch: 440; loss: 0.87; acc: 0.73
Batch: 460; loss: 1.02; acc: 0.58
Batch: 480; loss: 1.25; acc: 0.59
Batch: 500; loss: 1.02; acc: 0.69
Batch: 520; loss: 1.26; acc: 0.64
Batch: 540; loss: 0.9; acc: 0.7
Batch: 560; loss: 1.06; acc: 0.72
Batch: 580; loss: 1.12; acc: 0.64
Batch: 600; loss: 0.79; acc: 0.73
Batch: 620; loss: 0.89; acc: 0.69
Batch: 640; loss: 0.65; acc: 0.78
Batch: 660; loss: 0.94; acc: 0.64
Batch: 680; loss: 1.16; acc: 0.66
Batch: 700; loss: 0.93; acc: 0.67
Batch: 720; loss: 0.99; acc: 0.64
Batch: 740; loss: 1.02; acc: 0.67
Batch: 760; loss: 0.7; acc: 0.7
Batch: 780; loss: 0.98; acc: 0.66
Train Epoch over. train_loss: 0.94; train_accuracy: 0.69 

Batch: 0; loss: 1.38; acc: 0.62
Batch: 20; loss: 1.56; acc: 0.58
Batch: 40; loss: 1.13; acc: 0.59
Batch: 60; loss: 1.04; acc: 0.66
Batch: 80; loss: 0.94; acc: 0.67
Batch: 100; loss: 1.38; acc: 0.56
Batch: 120; loss: 1.72; acc: 0.58
Batch: 140; loss: 1.64; acc: 0.47
Val Epoch over. val_loss: 1.4198309388130335; val_accuracy: 0.5936504777070064 

The current subspace-distance is: 8.575523679610342e-05 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 1.25; acc: 0.67
Batch: 20; loss: 1.18; acc: 0.61
Batch: 40; loss: 0.89; acc: 0.66
Batch: 60; loss: 0.72; acc: 0.77
Batch: 80; loss: 1.03; acc: 0.69
Batch: 100; loss: 0.89; acc: 0.64
Batch: 120; loss: 0.91; acc: 0.73
Batch: 140; loss: 0.91; acc: 0.67
Batch: 160; loss: 1.04; acc: 0.61
Batch: 180; loss: 0.92; acc: 0.69
Batch: 200; loss: 0.9; acc: 0.81
Batch: 220; loss: 0.76; acc: 0.69
Batch: 240; loss: 1.05; acc: 0.62
Batch: 260; loss: 0.89; acc: 0.73
Batch: 280; loss: 0.99; acc: 0.62
Batch: 300; loss: 1.26; acc: 0.62
Batch: 320; loss: 1.07; acc: 0.67
Batch: 340; loss: 1.08; acc: 0.7
Batch: 360; loss: 1.13; acc: 0.58
Batch: 380; loss: 1.11; acc: 0.66
Batch: 400; loss: 1.01; acc: 0.67
Batch: 420; loss: 0.88; acc: 0.67
Batch: 440; loss: 0.86; acc: 0.72
Batch: 460; loss: 0.86; acc: 0.75
Batch: 480; loss: 1.05; acc: 0.61
Batch: 500; loss: 0.93; acc: 0.69
Batch: 520; loss: 0.6; acc: 0.81
Batch: 540; loss: 0.75; acc: 0.73
Batch: 560; loss: 0.98; acc: 0.67
Batch: 580; loss: 1.25; acc: 0.61
Batch: 600; loss: 1.12; acc: 0.64
Batch: 620; loss: 0.71; acc: 0.73
Batch: 640; loss: 0.86; acc: 0.7
Batch: 660; loss: 0.89; acc: 0.7
Batch: 680; loss: 1.03; acc: 0.62
Batch: 700; loss: 0.93; acc: 0.62
Batch: 720; loss: 0.94; acc: 0.69
Batch: 740; loss: 1.03; acc: 0.67
Batch: 760; loss: 1.0; acc: 0.69
Batch: 780; loss: 1.16; acc: 0.66
Train Epoch over. train_loss: 0.93; train_accuracy: 0.69 

Batch: 0; loss: 0.89; acc: 0.66
Batch: 20; loss: 0.96; acc: 0.72
Batch: 40; loss: 0.75; acc: 0.75
Batch: 60; loss: 0.84; acc: 0.72
Batch: 80; loss: 0.78; acc: 0.73
Batch: 100; loss: 0.96; acc: 0.7
Batch: 120; loss: 1.18; acc: 0.59
Batch: 140; loss: 0.77; acc: 0.77
Val Epoch over. val_loss: 0.8881637605891866; val_accuracy: 0.7046178343949044 

The current subspace-distance is: 8.78237042343244e-05 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.92; acc: 0.7
Batch: 20; loss: 0.93; acc: 0.7
Batch: 40; loss: 0.88; acc: 0.7
Batch: 60; loss: 0.91; acc: 0.72
Batch: 80; loss: 0.79; acc: 0.73
Batch: 100; loss: 1.03; acc: 0.72
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.85; acc: 0.67
Batch: 160; loss: 0.91; acc: 0.72
Batch: 180; loss: 1.03; acc: 0.62
Batch: 200; loss: 1.03; acc: 0.67
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.9; acc: 0.73
Batch: 280; loss: 0.92; acc: 0.7
Batch: 300; loss: 0.83; acc: 0.69
Batch: 320; loss: 0.97; acc: 0.69
Batch: 340; loss: 0.72; acc: 0.77
Batch: 360; loss: 0.62; acc: 0.84
Batch: 380; loss: 0.78; acc: 0.72
Batch: 400; loss: 0.72; acc: 0.72
Batch: 420; loss: 0.85; acc: 0.72
Batch: 440; loss: 0.83; acc: 0.72
Batch: 460; loss: 0.71; acc: 0.77
Batch: 480; loss: 0.77; acc: 0.67
Batch: 500; loss: 0.86; acc: 0.72
Batch: 520; loss: 0.96; acc: 0.67
Batch: 540; loss: 0.94; acc: 0.75
Batch: 560; loss: 0.93; acc: 0.67
Batch: 580; loss: 0.8; acc: 0.78
Batch: 600; loss: 0.95; acc: 0.73
Batch: 620; loss: 0.84; acc: 0.75
Batch: 640; loss: 1.13; acc: 0.62
Batch: 660; loss: 1.07; acc: 0.66
Batch: 680; loss: 1.03; acc: 0.69
Batch: 700; loss: 1.06; acc: 0.66
Batch: 720; loss: 0.85; acc: 0.81
Batch: 740; loss: 0.89; acc: 0.67
Batch: 760; loss: 0.59; acc: 0.84
Batch: 780; loss: 1.1; acc: 0.64
Train Epoch over. train_loss: 0.87; train_accuracy: 0.72 

Batch: 0; loss: 0.91; acc: 0.69
Batch: 20; loss: 1.05; acc: 0.7
Batch: 40; loss: 0.74; acc: 0.75
Batch: 60; loss: 0.86; acc: 0.7
Batch: 80; loss: 0.83; acc: 0.75
Batch: 100; loss: 0.85; acc: 0.7
Batch: 120; loss: 1.23; acc: 0.59
Batch: 140; loss: 0.7; acc: 0.78
Val Epoch over. val_loss: 0.8808254667907763; val_accuracy: 0.7053144904458599 

The current subspace-distance is: 9.145619696937501e-05 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.14; acc: 0.56
Batch: 20; loss: 0.92; acc: 0.64
Batch: 40; loss: 0.7; acc: 0.72
Batch: 60; loss: 1.01; acc: 0.66
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.98; acc: 0.7
Batch: 120; loss: 0.95; acc: 0.7
Batch: 140; loss: 0.98; acc: 0.69
Batch: 160; loss: 0.97; acc: 0.62
Batch: 180; loss: 0.98; acc: 0.66
Batch: 200; loss: 1.1; acc: 0.66
Batch: 220; loss: 1.06; acc: 0.62
Batch: 240; loss: 0.95; acc: 0.78
Batch: 260; loss: 0.74; acc: 0.78
Batch: 280; loss: 0.86; acc: 0.75
Batch: 300; loss: 0.91; acc: 0.67
Batch: 320; loss: 0.89; acc: 0.72
Batch: 340; loss: 0.96; acc: 0.69
Batch: 360; loss: 0.8; acc: 0.72
Batch: 380; loss: 0.57; acc: 0.83
Batch: 400; loss: 1.07; acc: 0.67
Batch: 420; loss: 0.99; acc: 0.62
Batch: 440; loss: 0.72; acc: 0.77
Batch: 460; loss: 0.78; acc: 0.69
Batch: 480; loss: 0.83; acc: 0.7
Batch: 500; loss: 0.78; acc: 0.73
Batch: 520; loss: 0.64; acc: 0.73
Batch: 540; loss: 0.81; acc: 0.7
Batch: 560; loss: 0.86; acc: 0.69
Batch: 580; loss: 0.76; acc: 0.72
Batch: 600; loss: 0.95; acc: 0.69
Batch: 620; loss: 0.75; acc: 0.83
Batch: 640; loss: 0.81; acc: 0.77
Batch: 660; loss: 0.74; acc: 0.72
Batch: 680; loss: 0.92; acc: 0.77
Batch: 700; loss: 1.14; acc: 0.7
Batch: 720; loss: 0.57; acc: 0.8
Batch: 740; loss: 1.18; acc: 0.61
Batch: 760; loss: 1.1; acc: 0.67
Batch: 780; loss: 0.77; acc: 0.67
Train Epoch over. train_loss: 0.87; train_accuracy: 0.72 

Batch: 0; loss: 0.89; acc: 0.7
Batch: 20; loss: 0.98; acc: 0.72
Batch: 40; loss: 0.74; acc: 0.78
Batch: 60; loss: 0.85; acc: 0.69
Batch: 80; loss: 0.83; acc: 0.7
Batch: 100; loss: 0.86; acc: 0.7
Batch: 120; loss: 1.19; acc: 0.59
Batch: 140; loss: 0.65; acc: 0.84
Val Epoch over. val_loss: 0.8578620169572769; val_accuracy: 0.7112858280254777 

The current subspace-distance is: 9.60829493124038e-05 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.83; acc: 0.66
Batch: 20; loss: 0.6; acc: 0.84
Batch: 40; loss: 0.79; acc: 0.7
Batch: 60; loss: 0.85; acc: 0.77
Batch: 80; loss: 0.81; acc: 0.64
Batch: 100; loss: 0.69; acc: 0.8
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.79; acc: 0.75
Batch: 160; loss: 0.86; acc: 0.77
Batch: 180; loss: 0.65; acc: 0.77
Batch: 200; loss: 0.66; acc: 0.73
Batch: 220; loss: 0.93; acc: 0.75
Batch: 240; loss: 0.73; acc: 0.77
Batch: 260; loss: 1.11; acc: 0.62
Batch: 280; loss: 0.9; acc: 0.7
Batch: 300; loss: 0.78; acc: 0.73
Batch: 320; loss: 0.89; acc: 0.7
Batch: 340; loss: 0.54; acc: 0.86
Batch: 360; loss: 0.81; acc: 0.73
Batch: 380; loss: 0.78; acc: 0.72
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 0.79; acc: 0.7
Batch: 440; loss: 0.85; acc: 0.7
Batch: 460; loss: 0.78; acc: 0.7
Batch: 480; loss: 0.7; acc: 0.75
Batch: 500; loss: 0.63; acc: 0.78
Batch: 520; loss: 1.1; acc: 0.67
Batch: 540; loss: 0.94; acc: 0.69
Batch: 560; loss: 0.92; acc: 0.64
Batch: 580; loss: 1.0; acc: 0.7
Batch: 600; loss: 0.91; acc: 0.72
Batch: 620; loss: 0.6; acc: 0.81
Batch: 640; loss: 1.04; acc: 0.72
Batch: 660; loss: 0.83; acc: 0.7
Batch: 680; loss: 0.85; acc: 0.7
Batch: 700; loss: 0.81; acc: 0.77
Batch: 720; loss: 0.72; acc: 0.67
Batch: 740; loss: 0.81; acc: 0.72
Batch: 760; loss: 0.62; acc: 0.77
Batch: 780; loss: 0.96; acc: 0.67
Train Epoch over. train_loss: 0.87; train_accuracy: 0.71 

Batch: 0; loss: 1.0; acc: 0.64
Batch: 20; loss: 0.98; acc: 0.7
Batch: 40; loss: 0.74; acc: 0.72
Batch: 60; loss: 0.85; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.72
Batch: 100; loss: 0.93; acc: 0.73
Batch: 120; loss: 1.33; acc: 0.53
Batch: 140; loss: 0.91; acc: 0.7
Val Epoch over. val_loss: 0.8986830783497756; val_accuracy: 0.7100915605095541 

The current subspace-distance is: 0.00010037588799605146 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.09; acc: 0.67
Batch: 20; loss: 0.81; acc: 0.75
Batch: 40; loss: 0.94; acc: 0.69
Batch: 60; loss: 0.87; acc: 0.77
Batch: 80; loss: 0.79; acc: 0.77
Batch: 100; loss: 0.83; acc: 0.78
Batch: 120; loss: 0.88; acc: 0.7
Batch: 140; loss: 1.0; acc: 0.7
Batch: 160; loss: 0.91; acc: 0.67
Batch: 180; loss: 0.89; acc: 0.78
Batch: 200; loss: 0.83; acc: 0.64
Batch: 220; loss: 0.72; acc: 0.8
Batch: 240; loss: 0.91; acc: 0.77
Batch: 260; loss: 0.81; acc: 0.75
Batch: 280; loss: 0.77; acc: 0.77
Batch: 300; loss: 0.66; acc: 0.77
Batch: 320; loss: 0.72; acc: 0.73
Batch: 340; loss: 1.01; acc: 0.69
Batch: 360; loss: 0.76; acc: 0.7
Batch: 380; loss: 0.73; acc: 0.77
Batch: 400; loss: 0.72; acc: 0.77
Batch: 420; loss: 0.73; acc: 0.72
Batch: 440; loss: 1.18; acc: 0.58
Batch: 460; loss: 0.87; acc: 0.7
Batch: 480; loss: 0.88; acc: 0.75
Batch: 500; loss: 0.72; acc: 0.73
Batch: 520; loss: 0.86; acc: 0.73
Batch: 540; loss: 0.98; acc: 0.67
Batch: 560; loss: 0.61; acc: 0.8
Batch: 580; loss: 1.12; acc: 0.66
Batch: 600; loss: 0.76; acc: 0.77
Batch: 620; loss: 0.81; acc: 0.78
Batch: 640; loss: 0.75; acc: 0.73
Batch: 660; loss: 0.91; acc: 0.73
Batch: 680; loss: 0.83; acc: 0.73
Batch: 700; loss: 0.88; acc: 0.73
Batch: 720; loss: 0.83; acc: 0.72
Batch: 740; loss: 0.88; acc: 0.72
Batch: 760; loss: 1.04; acc: 0.69
Batch: 780; loss: 1.09; acc: 0.66
Train Epoch over. train_loss: 0.87; train_accuracy: 0.72 

Batch: 0; loss: 1.05; acc: 0.67
Batch: 20; loss: 1.0; acc: 0.7
Batch: 40; loss: 0.89; acc: 0.67
Batch: 60; loss: 1.02; acc: 0.59
Batch: 80; loss: 1.04; acc: 0.61
Batch: 100; loss: 0.94; acc: 0.66
Batch: 120; loss: 1.15; acc: 0.64
Batch: 140; loss: 0.73; acc: 0.8
Val Epoch over. val_loss: 0.9669331437463213; val_accuracy: 0.6664012738853503 

The current subspace-distance is: 0.0001023255244945176 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.99; acc: 0.62
Batch: 20; loss: 0.79; acc: 0.77
Batch: 40; loss: 0.9; acc: 0.7
Batch: 60; loss: 0.88; acc: 0.75
Batch: 80; loss: 0.75; acc: 0.75
Batch: 100; loss: 0.83; acc: 0.78
Batch: 120; loss: 0.78; acc: 0.77
Batch: 140; loss: 0.76; acc: 0.75
Batch: 160; loss: 0.8; acc: 0.78
Batch: 180; loss: 0.6; acc: 0.86
Batch: 200; loss: 1.09; acc: 0.62
Batch: 220; loss: 0.93; acc: 0.64
Batch: 240; loss: 0.74; acc: 0.73
Batch: 260; loss: 0.81; acc: 0.67
Batch: 280; loss: 1.05; acc: 0.7
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.81; acc: 0.72
Batch: 340; loss: 0.77; acc: 0.69
Batch: 360; loss: 0.94; acc: 0.7
Batch: 380; loss: 0.8; acc: 0.69
Batch: 400; loss: 0.97; acc: 0.67
Batch: 420; loss: 0.79; acc: 0.73
Batch: 440; loss: 1.07; acc: 0.64
Batch: 460; loss: 0.82; acc: 0.67
Batch: 480; loss: 0.95; acc: 0.78
Batch: 500; loss: 0.76; acc: 0.77
Batch: 520; loss: 0.73; acc: 0.75
Batch: 540; loss: 0.96; acc: 0.77
Batch: 560; loss: 0.85; acc: 0.69
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 0.71; acc: 0.75
Batch: 620; loss: 0.98; acc: 0.75
Batch: 640; loss: 0.95; acc: 0.7
Batch: 660; loss: 1.03; acc: 0.67
Batch: 680; loss: 0.73; acc: 0.73
Batch: 700; loss: 0.97; acc: 0.66
Batch: 720; loss: 0.99; acc: 0.64
Batch: 740; loss: 0.73; acc: 0.7
Batch: 760; loss: 0.68; acc: 0.75
Batch: 780; loss: 0.84; acc: 0.69
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 1.05; acc: 0.73
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.87; acc: 0.7
Batch: 60; loss: 0.99; acc: 0.61
Batch: 80; loss: 0.96; acc: 0.7
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.2; acc: 0.59
Batch: 140; loss: 0.79; acc: 0.78
Val Epoch over. val_loss: 0.9294127802939931; val_accuracy: 0.6894904458598726 

The current subspace-distance is: 0.0001045086610247381 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.92; acc: 0.69
Batch: 20; loss: 0.83; acc: 0.73
Batch: 40; loss: 0.69; acc: 0.77
Batch: 60; loss: 0.85; acc: 0.72
Batch: 80; loss: 1.04; acc: 0.69
Batch: 100; loss: 0.68; acc: 0.8
Batch: 120; loss: 0.87; acc: 0.77
Batch: 140; loss: 0.84; acc: 0.75
Batch: 160; loss: 0.89; acc: 0.69
Batch: 180; loss: 0.58; acc: 0.83
Batch: 200; loss: 0.72; acc: 0.78
Batch: 220; loss: 0.9; acc: 0.62
Batch: 240; loss: 0.7; acc: 0.73
Batch: 260; loss: 1.01; acc: 0.72
Batch: 280; loss: 1.0; acc: 0.72
Batch: 300; loss: 0.88; acc: 0.66
Batch: 320; loss: 0.77; acc: 0.75
Batch: 340; loss: 0.88; acc: 0.7
Batch: 360; loss: 0.89; acc: 0.69
Batch: 380; loss: 0.74; acc: 0.78
Batch: 400; loss: 0.73; acc: 0.75
Batch: 420; loss: 0.84; acc: 0.75
Batch: 440; loss: 1.22; acc: 0.56
Batch: 460; loss: 0.76; acc: 0.73
Batch: 480; loss: 0.84; acc: 0.72
Batch: 500; loss: 1.03; acc: 0.69
Batch: 520; loss: 0.95; acc: 0.66
Batch: 540; loss: 0.73; acc: 0.72
Batch: 560; loss: 0.65; acc: 0.78
Batch: 580; loss: 0.88; acc: 0.75
Batch: 600; loss: 1.1; acc: 0.66
Batch: 620; loss: 0.98; acc: 0.69
Batch: 640; loss: 1.02; acc: 0.64
Batch: 660; loss: 0.99; acc: 0.66
Batch: 680; loss: 0.84; acc: 0.72
Batch: 700; loss: 0.89; acc: 0.73
Batch: 720; loss: 0.83; acc: 0.8
Batch: 740; loss: 0.93; acc: 0.75
Batch: 760; loss: 1.12; acc: 0.66
Batch: 780; loss: 0.71; acc: 0.75
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 0.91; acc: 0.8
Batch: 20; loss: 0.97; acc: 0.67
Batch: 40; loss: 0.79; acc: 0.73
Batch: 60; loss: 0.89; acc: 0.62
Batch: 80; loss: 0.86; acc: 0.7
Batch: 100; loss: 0.86; acc: 0.7
Batch: 120; loss: 1.17; acc: 0.59
Batch: 140; loss: 0.75; acc: 0.77
Val Epoch over. val_loss: 0.8737712641050861; val_accuracy: 0.7030254777070064 

The current subspace-distance is: 0.00010594453488010913 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.1; acc: 0.61
Batch: 20; loss: 0.75; acc: 0.8
Batch: 40; loss: 1.21; acc: 0.62
Batch: 60; loss: 1.1; acc: 0.61
Batch: 80; loss: 0.72; acc: 0.8
Batch: 100; loss: 0.86; acc: 0.69
Batch: 120; loss: 1.01; acc: 0.69
Batch: 140; loss: 0.77; acc: 0.72
Batch: 160; loss: 0.96; acc: 0.69
Batch: 180; loss: 0.9; acc: 0.7
Batch: 200; loss: 0.87; acc: 0.77
Batch: 220; loss: 0.88; acc: 0.69
Batch: 240; loss: 0.69; acc: 0.73
Batch: 260; loss: 0.73; acc: 0.73
Batch: 280; loss: 0.69; acc: 0.78
Batch: 300; loss: 0.94; acc: 0.66
Batch: 320; loss: 0.89; acc: 0.81
Batch: 340; loss: 0.97; acc: 0.64
Batch: 360; loss: 0.97; acc: 0.66
Batch: 380; loss: 0.94; acc: 0.72
Batch: 400; loss: 0.82; acc: 0.8
Batch: 420; loss: 0.83; acc: 0.69
Batch: 440; loss: 0.66; acc: 0.78
Batch: 460; loss: 0.88; acc: 0.61
Batch: 480; loss: 0.88; acc: 0.7
Batch: 500; loss: 0.89; acc: 0.62
Batch: 520; loss: 0.7; acc: 0.81
Batch: 540; loss: 0.82; acc: 0.77
Batch: 560; loss: 0.97; acc: 0.67
Batch: 580; loss: 0.87; acc: 0.73
Batch: 600; loss: 0.83; acc: 0.75
Batch: 620; loss: 0.89; acc: 0.73
Batch: 640; loss: 0.96; acc: 0.7
Batch: 660; loss: 1.03; acc: 0.69
Batch: 680; loss: 0.88; acc: 0.69
Batch: 700; loss: 0.86; acc: 0.7
Batch: 720; loss: 0.93; acc: 0.69
Batch: 740; loss: 0.88; acc: 0.77
Batch: 760; loss: 0.71; acc: 0.75
Batch: 780; loss: 0.89; acc: 0.73
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 1.0; acc: 0.7
Batch: 20; loss: 0.98; acc: 0.66
Batch: 40; loss: 0.77; acc: 0.75
Batch: 60; loss: 0.85; acc: 0.66
Batch: 80; loss: 0.87; acc: 0.75
Batch: 100; loss: 0.9; acc: 0.69
Batch: 120; loss: 1.24; acc: 0.56
Batch: 140; loss: 0.87; acc: 0.72
Val Epoch over. val_loss: 0.8852457438304926; val_accuracy: 0.7025278662420382 

The current subspace-distance is: 0.00010737418051576242 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.86; acc: 0.73
Batch: 20; loss: 0.61; acc: 0.8
Batch: 40; loss: 0.87; acc: 0.7
Batch: 60; loss: 1.11; acc: 0.7
Batch: 80; loss: 0.92; acc: 0.64
Batch: 100; loss: 0.81; acc: 0.7
Batch: 120; loss: 0.84; acc: 0.75
Batch: 140; loss: 0.67; acc: 0.78
Batch: 160; loss: 0.91; acc: 0.7
Batch: 180; loss: 1.07; acc: 0.64
Batch: 200; loss: 0.79; acc: 0.77
Batch: 220; loss: 1.02; acc: 0.72
Batch: 240; loss: 0.84; acc: 0.73
Batch: 260; loss: 0.9; acc: 0.7
Batch: 280; loss: 0.76; acc: 0.72
Batch: 300; loss: 0.8; acc: 0.72
Batch: 320; loss: 0.83; acc: 0.77
Batch: 340; loss: 0.91; acc: 0.69
Batch: 360; loss: 1.04; acc: 0.61
Batch: 380; loss: 0.94; acc: 0.66
Batch: 400; loss: 0.94; acc: 0.72
Batch: 420; loss: 0.97; acc: 0.73
Batch: 440; loss: 0.84; acc: 0.75
Batch: 460; loss: 0.96; acc: 0.64
Batch: 480; loss: 0.8; acc: 0.69
Batch: 500; loss: 0.65; acc: 0.8
Batch: 520; loss: 0.68; acc: 0.77
Batch: 540; loss: 0.91; acc: 0.7
Batch: 560; loss: 0.92; acc: 0.72
Batch: 580; loss: 1.1; acc: 0.66
Batch: 600; loss: 1.03; acc: 0.7
Batch: 620; loss: 0.79; acc: 0.78
Batch: 640; loss: 0.99; acc: 0.64
Batch: 660; loss: 0.98; acc: 0.64
Batch: 680; loss: 0.86; acc: 0.8
Batch: 700; loss: 0.68; acc: 0.75
Batch: 720; loss: 0.76; acc: 0.72
Batch: 740; loss: 0.75; acc: 0.69
Batch: 760; loss: 0.75; acc: 0.78
Batch: 780; loss: 0.77; acc: 0.78
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 0.93; acc: 0.73
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.86; acc: 0.66
Batch: 80; loss: 0.83; acc: 0.72
Batch: 100; loss: 0.86; acc: 0.72
Batch: 120; loss: 1.15; acc: 0.59
Batch: 140; loss: 0.68; acc: 0.8
Val Epoch over. val_loss: 0.8430623142582596; val_accuracy: 0.7157643312101911 

The current subspace-distance is: 0.00010998993820976466 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.14; acc: 0.62
Batch: 20; loss: 0.5; acc: 0.84
Batch: 40; loss: 0.87; acc: 0.62
Batch: 60; loss: 0.8; acc: 0.73
Batch: 80; loss: 0.8; acc: 0.69
Batch: 100; loss: 0.85; acc: 0.69
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.89; acc: 0.67
Batch: 160; loss: 0.88; acc: 0.73
Batch: 180; loss: 0.8; acc: 0.77
Batch: 200; loss: 0.99; acc: 0.75
Batch: 220; loss: 0.74; acc: 0.72
Batch: 240; loss: 0.86; acc: 0.75
Batch: 260; loss: 0.75; acc: 0.77
Batch: 280; loss: 0.86; acc: 0.7
Batch: 300; loss: 0.71; acc: 0.8
Batch: 320; loss: 0.94; acc: 0.66
Batch: 340; loss: 0.62; acc: 0.81
Batch: 360; loss: 0.92; acc: 0.72
Batch: 380; loss: 0.79; acc: 0.77
Batch: 400; loss: 0.68; acc: 0.78
Batch: 420; loss: 0.91; acc: 0.77
Batch: 440; loss: 1.06; acc: 0.69
Batch: 460; loss: 1.03; acc: 0.7
Batch: 480; loss: 0.81; acc: 0.72
Batch: 500; loss: 0.7; acc: 0.75
Batch: 520; loss: 0.61; acc: 0.77
Batch: 540; loss: 0.77; acc: 0.72
Batch: 560; loss: 0.98; acc: 0.73
Batch: 580; loss: 0.97; acc: 0.69
Batch: 600; loss: 1.0; acc: 0.7
Batch: 620; loss: 1.19; acc: 0.59
Batch: 640; loss: 0.81; acc: 0.73
Batch: 660; loss: 0.75; acc: 0.75
Batch: 680; loss: 0.89; acc: 0.64
Batch: 700; loss: 0.76; acc: 0.73
Batch: 720; loss: 0.89; acc: 0.8
Batch: 740; loss: 0.6; acc: 0.8
Batch: 760; loss: 0.9; acc: 0.72
Batch: 780; loss: 0.67; acc: 0.73
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 0.92; acc: 0.66
Batch: 20; loss: 1.01; acc: 0.67
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 0.84; acc: 0.72
Batch: 80; loss: 0.72; acc: 0.81
Batch: 100; loss: 0.92; acc: 0.72
Batch: 120; loss: 1.25; acc: 0.55
Batch: 140; loss: 0.84; acc: 0.7
Val Epoch over. val_loss: 0.8782763473547188; val_accuracy: 0.7080015923566879 

The current subspace-distance is: 0.0001129585798480548 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 1.27; acc: 0.62
Batch: 20; loss: 1.02; acc: 0.69
Batch: 40; loss: 1.2; acc: 0.61
Batch: 60; loss: 0.74; acc: 0.72
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.82; acc: 0.7
Batch: 120; loss: 1.11; acc: 0.64
Batch: 140; loss: 0.78; acc: 0.73
Batch: 160; loss: 0.86; acc: 0.66
Batch: 180; loss: 0.86; acc: 0.73
Batch: 200; loss: 0.99; acc: 0.69
Batch: 220; loss: 0.86; acc: 0.7
Batch: 240; loss: 0.88; acc: 0.7
Batch: 260; loss: 0.78; acc: 0.77
Batch: 280; loss: 0.73; acc: 0.75
Batch: 300; loss: 0.84; acc: 0.72
Batch: 320; loss: 0.9; acc: 0.73
Batch: 340; loss: 0.89; acc: 0.72
Batch: 360; loss: 0.73; acc: 0.77
Batch: 380; loss: 0.7; acc: 0.73
Batch: 400; loss: 0.88; acc: 0.59
Batch: 420; loss: 0.7; acc: 0.75
Batch: 440; loss: 1.0; acc: 0.72
Batch: 460; loss: 0.77; acc: 0.75
Batch: 480; loss: 0.94; acc: 0.64
Batch: 500; loss: 0.72; acc: 0.73
Batch: 520; loss: 0.65; acc: 0.77
Batch: 540; loss: 0.95; acc: 0.73
Batch: 560; loss: 0.88; acc: 0.7
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.98; acc: 0.69
Batch: 620; loss: 0.88; acc: 0.75
Batch: 640; loss: 0.69; acc: 0.8
Batch: 660; loss: 1.05; acc: 0.69
Batch: 680; loss: 0.99; acc: 0.66
Batch: 700; loss: 0.72; acc: 0.77
Batch: 720; loss: 0.99; acc: 0.64
Batch: 740; loss: 0.91; acc: 0.66
Batch: 760; loss: 0.66; acc: 0.78
Batch: 780; loss: 0.68; acc: 0.77
Train Epoch over. train_loss: 0.86; train_accuracy: 0.72 

Batch: 0; loss: 0.95; acc: 0.66
Batch: 20; loss: 0.91; acc: 0.62
Batch: 40; loss: 0.76; acc: 0.73
Batch: 60; loss: 0.78; acc: 0.72
Batch: 80; loss: 0.74; acc: 0.72
Batch: 100; loss: 0.84; acc: 0.72
Batch: 120; loss: 1.19; acc: 0.58
Batch: 140; loss: 0.89; acc: 0.69
Val Epoch over. val_loss: 0.8585084479325896; val_accuracy: 0.7199442675159236 

The current subspace-distance is: 0.0001156899452325888 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 1.01; acc: 0.64
Batch: 40; loss: 0.82; acc: 0.7
Batch: 60; loss: 1.14; acc: 0.67
Batch: 80; loss: 0.81; acc: 0.67
Batch: 100; loss: 0.81; acc: 0.69
Batch: 120; loss: 0.91; acc: 0.67
Batch: 140; loss: 1.02; acc: 0.67
Batch: 160; loss: 0.75; acc: 0.78
Batch: 180; loss: 0.8; acc: 0.73
Batch: 200; loss: 0.67; acc: 0.8
Batch: 220; loss: 0.72; acc: 0.78
Batch: 240; loss: 0.8; acc: 0.77
Batch: 260; loss: 1.1; acc: 0.66
Batch: 280; loss: 1.11; acc: 0.66
Batch: 300; loss: 0.84; acc: 0.75
Batch: 320; loss: 0.9; acc: 0.73
Batch: 340; loss: 0.67; acc: 0.8
Batch: 360; loss: 1.04; acc: 0.66
Batch: 380; loss: 0.98; acc: 0.72
Batch: 400; loss: 0.95; acc: 0.69
Batch: 420; loss: 0.83; acc: 0.7
Batch: 440; loss: 0.87; acc: 0.72
Batch: 460; loss: 1.04; acc: 0.69
Batch: 480; loss: 1.02; acc: 0.64
Batch: 500; loss: 0.79; acc: 0.77
Batch: 520; loss: 0.82; acc: 0.77
Batch: 540; loss: 0.94; acc: 0.77
Batch: 560; loss: 0.82; acc: 0.66
Batch: 580; loss: 1.18; acc: 0.64
Batch: 600; loss: 0.49; acc: 0.83
Batch: 620; loss: 0.82; acc: 0.75
Batch: 640; loss: 0.93; acc: 0.67
Batch: 660; loss: 0.67; acc: 0.78
Batch: 680; loss: 1.1; acc: 0.67
Batch: 700; loss: 0.72; acc: 0.73
Batch: 720; loss: 0.71; acc: 0.77
Batch: 740; loss: 0.96; acc: 0.72
Batch: 760; loss: 0.92; acc: 0.64
Batch: 780; loss: 0.77; acc: 0.73
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.89; acc: 0.67
Batch: 20; loss: 0.87; acc: 0.7
Batch: 40; loss: 0.71; acc: 0.75
Batch: 60; loss: 0.79; acc: 0.67
Batch: 80; loss: 0.78; acc: 0.73
Batch: 100; loss: 0.82; acc: 0.73
Batch: 120; loss: 1.12; acc: 0.59
Batch: 140; loss: 0.72; acc: 0.78
Val Epoch over. val_loss: 0.8254497670064307; val_accuracy: 0.7329816878980892 

The current subspace-distance is: 0.00011916030780412257 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 1.08; acc: 0.64
Batch: 20; loss: 0.83; acc: 0.69
Batch: 40; loss: 0.92; acc: 0.64
Batch: 60; loss: 1.0; acc: 0.75
Batch: 80; loss: 0.72; acc: 0.72
Batch: 100; loss: 0.84; acc: 0.69
Batch: 120; loss: 0.69; acc: 0.7
Batch: 140; loss: 0.91; acc: 0.7
Batch: 160; loss: 1.23; acc: 0.56
Batch: 180; loss: 0.97; acc: 0.64
Batch: 200; loss: 0.77; acc: 0.75
Batch: 220; loss: 1.02; acc: 0.67
Batch: 240; loss: 0.84; acc: 0.77
Batch: 260; loss: 0.78; acc: 0.72
Batch: 280; loss: 0.96; acc: 0.64
Batch: 300; loss: 0.87; acc: 0.77
Batch: 320; loss: 0.86; acc: 0.7
Batch: 340; loss: 0.84; acc: 0.72
Batch: 360; loss: 0.69; acc: 0.78
Batch: 380; loss: 0.88; acc: 0.75
Batch: 400; loss: 0.82; acc: 0.77
Batch: 420; loss: 0.84; acc: 0.69
Batch: 440; loss: 0.76; acc: 0.72
Batch: 460; loss: 1.01; acc: 0.64
Batch: 480; loss: 0.74; acc: 0.77
Batch: 500; loss: 0.99; acc: 0.67
Batch: 520; loss: 1.02; acc: 0.72
Batch: 540; loss: 0.72; acc: 0.81
Batch: 560; loss: 0.96; acc: 0.7
Batch: 580; loss: 0.79; acc: 0.72
Batch: 600; loss: 0.87; acc: 0.67
Batch: 620; loss: 0.64; acc: 0.83
Batch: 640; loss: 0.95; acc: 0.69
Batch: 660; loss: 0.92; acc: 0.72
Batch: 680; loss: 0.85; acc: 0.73
Batch: 700; loss: 0.98; acc: 0.69
Batch: 720; loss: 0.8; acc: 0.72
Batch: 740; loss: 0.7; acc: 0.78
Batch: 760; loss: 0.91; acc: 0.7
Batch: 780; loss: 0.99; acc: 0.66
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.86; acc: 0.7
Batch: 40; loss: 0.69; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.72
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 0.79; acc: 0.77
Batch: 120; loss: 1.07; acc: 0.61
Batch: 140; loss: 0.77; acc: 0.73
Val Epoch over. val_loss: 0.8137587639176922; val_accuracy: 0.7396496815286624 

The current subspace-distance is: 0.00012134660209994763 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.73; acc: 0.75
Batch: 20; loss: 0.78; acc: 0.77
Batch: 40; loss: 1.3; acc: 0.61
Batch: 60; loss: 0.79; acc: 0.78
Batch: 80; loss: 0.63; acc: 0.78
Batch: 100; loss: 0.82; acc: 0.77
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.76; acc: 0.8
Batch: 160; loss: 0.75; acc: 0.73
Batch: 180; loss: 0.71; acc: 0.75
Batch: 200; loss: 0.91; acc: 0.7
Batch: 220; loss: 1.0; acc: 0.7
Batch: 240; loss: 0.97; acc: 0.64
Batch: 260; loss: 0.74; acc: 0.83
Batch: 280; loss: 0.8; acc: 0.73
Batch: 300; loss: 0.76; acc: 0.73
Batch: 320; loss: 0.77; acc: 0.75
Batch: 340; loss: 0.85; acc: 0.59
Batch: 360; loss: 0.9; acc: 0.73
Batch: 380; loss: 0.81; acc: 0.8
Batch: 400; loss: 1.02; acc: 0.66
Batch: 420; loss: 0.99; acc: 0.7
Batch: 440; loss: 0.77; acc: 0.7
Batch: 460; loss: 0.75; acc: 0.73
Batch: 480; loss: 1.02; acc: 0.67
Batch: 500; loss: 0.7; acc: 0.75
Batch: 520; loss: 1.13; acc: 0.61
Batch: 540; loss: 0.79; acc: 0.81
Batch: 560; loss: 0.6; acc: 0.78
Batch: 580; loss: 0.85; acc: 0.69
Batch: 600; loss: 0.84; acc: 0.75
Batch: 620; loss: 0.95; acc: 0.62
Batch: 640; loss: 0.73; acc: 0.8
Batch: 660; loss: 0.81; acc: 0.78
Batch: 680; loss: 0.91; acc: 0.73
Batch: 700; loss: 0.87; acc: 0.7
Batch: 720; loss: 1.04; acc: 0.69
Batch: 740; loss: 0.77; acc: 0.69
Batch: 760; loss: 0.76; acc: 0.72
Batch: 780; loss: 0.95; acc: 0.66
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.87; acc: 0.69
Batch: 20; loss: 0.87; acc: 0.69
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.72
Batch: 80; loss: 0.72; acc: 0.77
Batch: 100; loss: 0.8; acc: 0.8
Batch: 120; loss: 1.07; acc: 0.61
Batch: 140; loss: 0.73; acc: 0.75
Val Epoch over. val_loss: 0.8133434543184414; val_accuracy: 0.7374601910828026 

The current subspace-distance is: 0.00012459485151339322 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.69; acc: 0.81
Batch: 20; loss: 0.83; acc: 0.77
Batch: 40; loss: 0.61; acc: 0.78
Batch: 60; loss: 0.72; acc: 0.81
Batch: 80; loss: 0.88; acc: 0.72
Batch: 100; loss: 0.69; acc: 0.81
Batch: 120; loss: 0.77; acc: 0.72
Batch: 140; loss: 0.74; acc: 0.77
Batch: 160; loss: 0.78; acc: 0.77
Batch: 180; loss: 0.84; acc: 0.75
Batch: 200; loss: 0.69; acc: 0.77
Batch: 220; loss: 0.67; acc: 0.78
Batch: 240; loss: 0.86; acc: 0.69
Batch: 260; loss: 1.12; acc: 0.72
Batch: 280; loss: 0.93; acc: 0.72
Batch: 300; loss: 0.94; acc: 0.67
Batch: 320; loss: 0.73; acc: 0.8
Batch: 340; loss: 0.91; acc: 0.69
Batch: 360; loss: 0.85; acc: 0.61
Batch: 380; loss: 0.92; acc: 0.75
Batch: 400; loss: 0.61; acc: 0.83
Batch: 420; loss: 0.6; acc: 0.8
Batch: 440; loss: 0.75; acc: 0.69
Batch: 460; loss: 0.74; acc: 0.73
Batch: 480; loss: 0.85; acc: 0.73
Batch: 500; loss: 0.82; acc: 0.73
Batch: 520; loss: 0.88; acc: 0.75
Batch: 540; loss: 0.77; acc: 0.8
Batch: 560; loss: 0.8; acc: 0.72
Batch: 580; loss: 0.8; acc: 0.69
Batch: 600; loss: 1.03; acc: 0.64
Batch: 620; loss: 0.95; acc: 0.7
Batch: 640; loss: 0.74; acc: 0.73
Batch: 660; loss: 0.84; acc: 0.72
Batch: 680; loss: 0.94; acc: 0.66
Batch: 700; loss: 1.05; acc: 0.56
Batch: 720; loss: 0.71; acc: 0.72
Batch: 740; loss: 0.63; acc: 0.83
Batch: 760; loss: 0.75; acc: 0.77
Batch: 780; loss: 0.96; acc: 0.72
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.89; acc: 0.67
Batch: 20; loss: 0.96; acc: 0.69
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.75; acc: 0.73
Batch: 80; loss: 0.7; acc: 0.78
Batch: 100; loss: 0.8; acc: 0.81
Batch: 120; loss: 1.18; acc: 0.64
Batch: 140; loss: 0.77; acc: 0.78
Val Epoch over. val_loss: 0.8371493675906188; val_accuracy: 0.7319864649681529 

The current subspace-distance is: 0.00012629330740310252 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.63; acc: 0.8
Batch: 20; loss: 0.92; acc: 0.69
Batch: 40; loss: 0.69; acc: 0.75
Batch: 60; loss: 1.13; acc: 0.66
Batch: 80; loss: 1.04; acc: 0.62
Batch: 100; loss: 0.74; acc: 0.81
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.59; acc: 0.78
Batch: 160; loss: 0.92; acc: 0.73
Batch: 180; loss: 0.98; acc: 0.66
Batch: 200; loss: 1.12; acc: 0.64
Batch: 220; loss: 0.94; acc: 0.72
Batch: 240; loss: 1.05; acc: 0.75
Batch: 260; loss: 0.82; acc: 0.77
Batch: 280; loss: 0.76; acc: 0.75
Batch: 300; loss: 1.06; acc: 0.64
Batch: 320; loss: 1.07; acc: 0.67
Batch: 340; loss: 0.63; acc: 0.81
Batch: 360; loss: 0.84; acc: 0.8
Batch: 380; loss: 0.6; acc: 0.81
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.95; acc: 0.67
Batch: 440; loss: 0.84; acc: 0.78
Batch: 460; loss: 0.77; acc: 0.78
Batch: 480; loss: 0.71; acc: 0.77
Batch: 500; loss: 0.65; acc: 0.78
Batch: 520; loss: 0.73; acc: 0.77
Batch: 540; loss: 0.85; acc: 0.75
Batch: 560; loss: 0.89; acc: 0.73
Batch: 580; loss: 0.92; acc: 0.75
Batch: 600; loss: 0.94; acc: 0.67
Batch: 620; loss: 0.85; acc: 0.72
Batch: 640; loss: 0.97; acc: 0.61
Batch: 660; loss: 0.87; acc: 0.69
Batch: 680; loss: 1.07; acc: 0.64
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.93; acc: 0.62
Batch: 740; loss: 0.9; acc: 0.73
Batch: 760; loss: 0.8; acc: 0.7
Batch: 780; loss: 0.71; acc: 0.75
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.92; acc: 0.67
Batch: 20; loss: 0.87; acc: 0.7
Batch: 40; loss: 0.67; acc: 0.77
Batch: 60; loss: 0.75; acc: 0.72
Batch: 80; loss: 0.73; acc: 0.72
Batch: 100; loss: 0.8; acc: 0.77
Batch: 120; loss: 1.11; acc: 0.59
Batch: 140; loss: 0.77; acc: 0.77
Val Epoch over. val_loss: 0.8202473456692544; val_accuracy: 0.7385549363057324 

The current subspace-distance is: 0.00012848836195189506 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.97; acc: 0.69
Batch: 20; loss: 0.8; acc: 0.77
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.69; acc: 0.73
Batch: 80; loss: 0.85; acc: 0.72
Batch: 100; loss: 1.01; acc: 0.72
Batch: 120; loss: 0.99; acc: 0.73
Batch: 140; loss: 0.97; acc: 0.67
Batch: 160; loss: 0.69; acc: 0.78
Batch: 180; loss: 0.69; acc: 0.75
Batch: 200; loss: 0.97; acc: 0.7
Batch: 220; loss: 0.74; acc: 0.78
Batch: 240; loss: 0.87; acc: 0.7
Batch: 260; loss: 0.85; acc: 0.73
Batch: 280; loss: 0.9; acc: 0.67
Batch: 300; loss: 1.09; acc: 0.73
Batch: 320; loss: 0.72; acc: 0.75
Batch: 340; loss: 0.83; acc: 0.69
Batch: 360; loss: 0.8; acc: 0.73
Batch: 380; loss: 0.93; acc: 0.72
Batch: 400; loss: 0.93; acc: 0.69
Batch: 420; loss: 0.73; acc: 0.81
Batch: 440; loss: 0.85; acc: 0.75
Batch: 460; loss: 0.73; acc: 0.75
Batch: 480; loss: 0.81; acc: 0.72
Batch: 500; loss: 0.79; acc: 0.69
Batch: 520; loss: 1.23; acc: 0.62
Batch: 540; loss: 0.81; acc: 0.75
Batch: 560; loss: 0.98; acc: 0.69
Batch: 580; loss: 0.76; acc: 0.77
Batch: 600; loss: 1.14; acc: 0.72
Batch: 620; loss: 0.8; acc: 0.72
Batch: 640; loss: 0.86; acc: 0.77
Batch: 660; loss: 0.8; acc: 0.69
Batch: 680; loss: 0.86; acc: 0.69
Batch: 700; loss: 0.88; acc: 0.73
Batch: 720; loss: 0.89; acc: 0.7
Batch: 740; loss: 0.83; acc: 0.72
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.78; acc: 0.77
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.88; acc: 0.69
Batch: 20; loss: 0.91; acc: 0.7
Batch: 40; loss: 0.65; acc: 0.78
Batch: 60; loss: 0.73; acc: 0.7
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.78; acc: 0.8
Batch: 120; loss: 1.1; acc: 0.61
Batch: 140; loss: 0.75; acc: 0.72
Val Epoch over. val_loss: 0.8127212222594364; val_accuracy: 0.7390525477707006 

The current subspace-distance is: 0.0001303230383200571 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 0.64; acc: 0.78
Batch: 40; loss: 0.59; acc: 0.81
Batch: 60; loss: 0.92; acc: 0.72
Batch: 80; loss: 1.01; acc: 0.62
Batch: 100; loss: 1.18; acc: 0.59
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.85; acc: 0.77
Batch: 160; loss: 0.78; acc: 0.75
Batch: 180; loss: 0.59; acc: 0.78
Batch: 200; loss: 0.65; acc: 0.73
Batch: 220; loss: 0.72; acc: 0.77
Batch: 240; loss: 0.93; acc: 0.66
Batch: 260; loss: 0.64; acc: 0.8
Batch: 280; loss: 0.74; acc: 0.73
Batch: 300; loss: 0.79; acc: 0.7
Batch: 320; loss: 0.98; acc: 0.72
Batch: 340; loss: 0.87; acc: 0.69
Batch: 360; loss: 0.59; acc: 0.81
Batch: 380; loss: 0.91; acc: 0.66
Batch: 400; loss: 0.85; acc: 0.72
Batch: 420; loss: 0.87; acc: 0.67
Batch: 440; loss: 0.8; acc: 0.7
Batch: 460; loss: 0.76; acc: 0.77
Batch: 480; loss: 0.83; acc: 0.66
Batch: 500; loss: 0.72; acc: 0.77
Batch: 520; loss: 0.85; acc: 0.72
Batch: 540; loss: 0.99; acc: 0.64
Batch: 560; loss: 1.09; acc: 0.7
Batch: 580; loss: 0.86; acc: 0.75
Batch: 600; loss: 0.87; acc: 0.66
Batch: 620; loss: 0.99; acc: 0.72
Batch: 640; loss: 0.86; acc: 0.7
Batch: 660; loss: 0.96; acc: 0.62
Batch: 680; loss: 0.76; acc: 0.77
Batch: 700; loss: 0.74; acc: 0.83
Batch: 720; loss: 1.12; acc: 0.66
Batch: 740; loss: 1.01; acc: 0.67
Batch: 760; loss: 0.87; acc: 0.75
Batch: 780; loss: 0.78; acc: 0.77
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.72
Batch: 40; loss: 0.66; acc: 0.78
Batch: 60; loss: 0.72; acc: 0.7
Batch: 80; loss: 0.77; acc: 0.75
Batch: 100; loss: 0.77; acc: 0.77
Batch: 120; loss: 1.09; acc: 0.62
Batch: 140; loss: 0.77; acc: 0.77
Val Epoch over. val_loss: 0.8213431309362885; val_accuracy: 0.7347730891719745 

The current subspace-distance is: 0.00013152345491107553 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.83; acc: 0.77
Batch: 40; loss: 0.75; acc: 0.8
Batch: 60; loss: 0.94; acc: 0.67
Batch: 80; loss: 0.88; acc: 0.72
Batch: 100; loss: 0.72; acc: 0.8
Batch: 120; loss: 0.84; acc: 0.66
Batch: 140; loss: 0.77; acc: 0.77
Batch: 160; loss: 0.84; acc: 0.73
Batch: 180; loss: 0.83; acc: 0.73
Batch: 200; loss: 0.88; acc: 0.67
Batch: 220; loss: 0.93; acc: 0.75
Batch: 240; loss: 0.76; acc: 0.75
Batch: 260; loss: 0.9; acc: 0.69
Batch: 280; loss: 0.84; acc: 0.72
Batch: 300; loss: 0.82; acc: 0.73
Batch: 320; loss: 0.75; acc: 0.8
Batch: 340; loss: 0.56; acc: 0.84
Batch: 360; loss: 0.64; acc: 0.81
Batch: 380; loss: 0.81; acc: 0.72
Batch: 400; loss: 0.65; acc: 0.84
Batch: 420; loss: 0.59; acc: 0.81
Batch: 440; loss: 0.85; acc: 0.72
Batch: 460; loss: 0.63; acc: 0.8
Batch: 480; loss: 1.04; acc: 0.66
Batch: 500; loss: 0.92; acc: 0.67
Batch: 520; loss: 1.02; acc: 0.66
Batch: 540; loss: 0.72; acc: 0.78
Batch: 560; loss: 0.69; acc: 0.75
Batch: 580; loss: 0.73; acc: 0.78
Batch: 600; loss: 0.6; acc: 0.77
Batch: 620; loss: 0.99; acc: 0.67
Batch: 640; loss: 0.67; acc: 0.75
Batch: 660; loss: 1.03; acc: 0.59
Batch: 680; loss: 0.83; acc: 0.75
Batch: 700; loss: 1.0; acc: 0.67
Batch: 720; loss: 0.91; acc: 0.67
Batch: 740; loss: 0.76; acc: 0.8
Batch: 760; loss: 0.78; acc: 0.77
Batch: 780; loss: 0.91; acc: 0.7
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.88; acc: 0.66
Batch: 20; loss: 0.89; acc: 0.73
Batch: 40; loss: 0.69; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.72
Batch: 80; loss: 0.74; acc: 0.8
Batch: 100; loss: 0.81; acc: 0.78
Batch: 120; loss: 1.09; acc: 0.62
Batch: 140; loss: 0.77; acc: 0.75
Val Epoch over. val_loss: 0.8302371706932213; val_accuracy: 0.7320859872611465 

The current subspace-distance is: 0.00013395091809798032 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.69
Batch: 20; loss: 0.95; acc: 0.7
Batch: 40; loss: 0.95; acc: 0.64
Batch: 60; loss: 0.8; acc: 0.69
Batch: 80; loss: 0.95; acc: 0.66
Batch: 100; loss: 0.73; acc: 0.7
Batch: 120; loss: 0.79; acc: 0.7
Batch: 140; loss: 0.74; acc: 0.7
Batch: 160; loss: 0.79; acc: 0.72
Batch: 180; loss: 1.03; acc: 0.62
Batch: 200; loss: 0.81; acc: 0.78
Batch: 220; loss: 0.8; acc: 0.7
Batch: 240; loss: 0.56; acc: 0.8
Batch: 260; loss: 0.77; acc: 0.77
Batch: 280; loss: 1.02; acc: 0.7
Batch: 300; loss: 0.83; acc: 0.72
Batch: 320; loss: 0.85; acc: 0.64
Batch: 340; loss: 0.75; acc: 0.77
Batch: 360; loss: 0.73; acc: 0.67
Batch: 380; loss: 0.88; acc: 0.73
Batch: 400; loss: 0.94; acc: 0.69
Batch: 420; loss: 0.73; acc: 0.8
Batch: 440; loss: 0.79; acc: 0.72
Batch: 460; loss: 1.22; acc: 0.64
Batch: 480; loss: 0.7; acc: 0.77
Batch: 500; loss: 1.0; acc: 0.69
Batch: 520; loss: 0.83; acc: 0.67
Batch: 540; loss: 0.84; acc: 0.69
Batch: 560; loss: 1.04; acc: 0.66
Batch: 580; loss: 0.97; acc: 0.67
Batch: 600; loss: 0.87; acc: 0.64
Batch: 620; loss: 0.89; acc: 0.72
Batch: 640; loss: 1.12; acc: 0.67
Batch: 660; loss: 0.75; acc: 0.73
Batch: 680; loss: 1.05; acc: 0.69
Batch: 700; loss: 0.66; acc: 0.78
Batch: 720; loss: 0.98; acc: 0.69
Batch: 740; loss: 0.83; acc: 0.75
Batch: 760; loss: 0.67; acc: 0.75
Batch: 780; loss: 0.71; acc: 0.75
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 0.93; acc: 0.67
Batch: 20; loss: 0.85; acc: 0.72
Batch: 40; loss: 0.71; acc: 0.78
Batch: 60; loss: 0.8; acc: 0.69
Batch: 80; loss: 0.77; acc: 0.73
Batch: 100; loss: 0.82; acc: 0.8
Batch: 120; loss: 1.07; acc: 0.62
Batch: 140; loss: 0.76; acc: 0.7
Val Epoch over. val_loss: 0.8302441983465936; val_accuracy: 0.7323845541401274 

The current subspace-distance is: 0.00013557318015955389 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.76; acc: 0.77
Batch: 20; loss: 0.9; acc: 0.69
Batch: 40; loss: 0.78; acc: 0.8
Batch: 60; loss: 0.94; acc: 0.77
Batch: 80; loss: 0.93; acc: 0.73
Batch: 100; loss: 0.69; acc: 0.77
Batch: 120; loss: 0.94; acc: 0.77
Batch: 140; loss: 0.93; acc: 0.72
Batch: 160; loss: 0.79; acc: 0.8
Batch: 180; loss: 0.8; acc: 0.77
Batch: 200; loss: 0.98; acc: 0.7
Batch: 220; loss: 0.95; acc: 0.66
Batch: 240; loss: 0.83; acc: 0.75
Batch: 260; loss: 0.95; acc: 0.66
Batch: 280; loss: 0.67; acc: 0.77
Batch: 300; loss: 0.72; acc: 0.78
Batch: 320; loss: 0.9; acc: 0.75
Batch: 340; loss: 1.04; acc: 0.61
Batch: 360; loss: 0.73; acc: 0.75
Batch: 380; loss: 0.82; acc: 0.73
Batch: 400; loss: 0.7; acc: 0.75
Batch: 420; loss: 1.0; acc: 0.73
Batch: 440; loss: 0.86; acc: 0.7
Batch: 460; loss: 0.81; acc: 0.75
Batch: 480; loss: 0.64; acc: 0.77
Batch: 500; loss: 0.85; acc: 0.72
Batch: 520; loss: 0.91; acc: 0.75
Batch: 540; loss: 0.85; acc: 0.75
Batch: 560; loss: 0.58; acc: 0.84
Batch: 580; loss: 0.77; acc: 0.75
Batch: 600; loss: 0.82; acc: 0.77
Batch: 620; loss: 0.86; acc: 0.69
Batch: 640; loss: 1.0; acc: 0.61
Batch: 660; loss: 0.69; acc: 0.77
Batch: 680; loss: 0.96; acc: 0.7
Batch: 700; loss: 0.82; acc: 0.75
Batch: 720; loss: 0.65; acc: 0.84
Batch: 740; loss: 0.87; acc: 0.72
Batch: 760; loss: 0.95; acc: 0.78
Batch: 780; loss: 0.86; acc: 0.69
Train Epoch over. train_loss: 0.85; train_accuracy: 0.72 

Batch: 0; loss: 1.0; acc: 0.72
Batch: 20; loss: 0.94; acc: 0.67
Batch: 40; loss: 0.75; acc: 0.75
Batch: 60; loss: 0.86; acc: 0.66
Batch: 80; loss: 0.81; acc: 0.75
Batch: 100; loss: 0.86; acc: 0.75
Batch: 120; loss: 1.23; acc: 0.62
Batch: 140; loss: 0.72; acc: 0.8
Val Epoch over. val_loss: 0.8565737891728711; val_accuracy: 0.7155652866242038 

The current subspace-distance is: 0.00013725180178880692 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.82; acc: 0.73
Batch: 20; loss: 0.95; acc: 0.69
Batch: 40; loss: 1.09; acc: 0.56
Batch: 60; loss: 0.85; acc: 0.77
Batch: 80; loss: 0.68; acc: 0.77
Batch: 100; loss: 0.91; acc: 0.69
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.74; acc: 0.8
Batch: 160; loss: 0.79; acc: 0.66
Batch: 180; loss: 0.51; acc: 0.89
Batch: 200; loss: 0.85; acc: 0.73
Batch: 220; loss: 0.98; acc: 0.7
Batch: 240; loss: 1.0; acc: 0.66
Batch: 260; loss: 0.59; acc: 0.78
Batch: 280; loss: 0.96; acc: 0.73
Batch: 300; loss: 0.84; acc: 0.67
Batch: 320; loss: 1.05; acc: 0.67
Batch: 340; loss: 0.87; acc: 0.72
Batch: 360; loss: 0.7; acc: 0.77
Batch: 380; loss: 0.66; acc: 0.8
Batch: 400; loss: 0.77; acc: 0.73
Batch: 420; loss: 0.96; acc: 0.67
Batch: 440; loss: 0.83; acc: 0.67
Batch: 460; loss: 0.81; acc: 0.69
Batch: 480; loss: 0.77; acc: 0.72
Batch: 500; loss: 0.6; acc: 0.78
Batch: 520; loss: 0.62; acc: 0.78
Batch: 540; loss: 0.87; acc: 0.64
Batch: 560; loss: 0.85; acc: 0.75
Batch: 580; loss: 0.95; acc: 0.7
Batch: 600; loss: 1.25; acc: 0.64
Batch: 620; loss: 0.81; acc: 0.77
Batch: 640; loss: 0.7; acc: 0.78
Batch: 660; loss: 0.82; acc: 0.77
Batch: 680; loss: 0.77; acc: 0.73
Batch: 700; loss: 1.03; acc: 0.66
Batch: 720; loss: 0.9; acc: 0.7
Batch: 740; loss: 1.12; acc: 0.55
Batch: 760; loss: 0.86; acc: 0.77
Batch: 780; loss: 0.82; acc: 0.75
Train Epoch over. train_loss: 0.84; train_accuracy: 0.72 

Batch: 0; loss: 0.87; acc: 0.72
Batch: 20; loss: 0.9; acc: 0.67
Batch: 40; loss: 0.65; acc: 0.78
Batch: 60; loss: 0.72; acc: 0.69
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 0.77; acc: 0.8
Batch: 120; loss: 1.09; acc: 0.64
Batch: 140; loss: 0.73; acc: 0.77
Val Epoch over. val_loss: 0.8080746318883957; val_accuracy: 0.7385549363057324 

The current subspace-distance is: 0.00013799982843920588 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.8; acc: 0.72
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.59; acc: 0.86
Batch: 80; loss: 0.94; acc: 0.62
Batch: 100; loss: 0.73; acc: 0.72
Batch: 120; loss: 0.81; acc: 0.75
Batch: 140; loss: 0.81; acc: 0.73
Batch: 160; loss: 0.67; acc: 0.81
Batch: 180; loss: 0.89; acc: 0.72
Batch: 200; loss: 0.9; acc: 0.72
Batch: 220; loss: 0.82; acc: 0.7
Batch: 240; loss: 0.7; acc: 0.7
Batch: 260; loss: 0.71; acc: 0.78
Batch: 280; loss: 0.95; acc: 0.7
Batch: 300; loss: 0.93; acc: 0.7
Batch: 320; loss: 0.78; acc: 0.72
Batch: 340; loss: 0.9; acc: 0.66
Batch: 360; loss: 0.88; acc: 0.66
Batch: 380; loss: 0.78; acc: 0.7
Batch: 400; loss: 0.63; acc: 0.78
Batch: 420; loss: 0.74; acc: 0.77
Batch: 440; loss: 0.8; acc: 0.77
Batch: 460; loss: 0.91; acc: 0.72
Batch: 480; loss: 0.81; acc: 0.72
Batch: 500; loss: 1.0; acc: 0.7
Batch: 520; loss: 0.88; acc: 0.77
Batch: 540; loss: 0.82; acc: 0.75
Batch: 560; loss: 0.87; acc: 0.73
Batch: 580; loss: 0.92; acc: 0.7
Batch: 600; loss: 1.18; acc: 0.59
Batch: 620; loss: 0.86; acc: 0.72
Batch: 640; loss: 1.05; acc: 0.69
Batch: 660; loss: 0.54; acc: 0.78
Batch: 680; loss: 0.83; acc: 0.78
Batch: 700; loss: 0.8; acc: 0.73
Batch: 720; loss: 0.79; acc: 0.73
Batch: 740; loss: 1.15; acc: 0.64
Batch: 760; loss: 0.98; acc: 0.67
Batch: 780; loss: 0.87; acc: 0.69
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.87; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.67; acc: 0.8
Batch: 60; loss: 0.74; acc: 0.7
Batch: 80; loss: 0.74; acc: 0.78
Batch: 100; loss: 0.77; acc: 0.78
Batch: 120; loss: 1.09; acc: 0.64
Batch: 140; loss: 0.72; acc: 0.77
Val Epoch over. val_loss: 0.8076571795591123; val_accuracy: 0.7373606687898089 

The current subspace-distance is: 0.0001405234943376854 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.92; acc: 0.61
Batch: 20; loss: 1.02; acc: 0.69
Batch: 40; loss: 0.71; acc: 0.77
Batch: 60; loss: 0.98; acc: 0.73
Batch: 80; loss: 0.8; acc: 0.8
Batch: 100; loss: 0.95; acc: 0.7
Batch: 120; loss: 0.94; acc: 0.69
Batch: 140; loss: 0.98; acc: 0.73
Batch: 160; loss: 0.88; acc: 0.7
Batch: 180; loss: 1.03; acc: 0.66
Batch: 200; loss: 0.84; acc: 0.7
Batch: 220; loss: 0.74; acc: 0.75
Batch: 240; loss: 0.96; acc: 0.7
Batch: 260; loss: 0.92; acc: 0.66
Batch: 280; loss: 0.88; acc: 0.69
Batch: 300; loss: 0.89; acc: 0.7
Batch: 320; loss: 0.73; acc: 0.73
Batch: 340; loss: 1.1; acc: 0.64
Batch: 360; loss: 0.96; acc: 0.69
Batch: 380; loss: 0.88; acc: 0.7
Batch: 400; loss: 0.73; acc: 0.75
Batch: 420; loss: 0.85; acc: 0.72
Batch: 440; loss: 1.01; acc: 0.72
Batch: 460; loss: 1.07; acc: 0.69
Batch: 480; loss: 1.16; acc: 0.62
Batch: 500; loss: 0.76; acc: 0.69
Batch: 520; loss: 0.73; acc: 0.73
Batch: 540; loss: 1.11; acc: 0.64
Batch: 560; loss: 0.65; acc: 0.8
Batch: 580; loss: 1.07; acc: 0.69
Batch: 600; loss: 1.22; acc: 0.66
Batch: 620; loss: 0.72; acc: 0.77
Batch: 640; loss: 0.81; acc: 0.77
Batch: 660; loss: 0.87; acc: 0.69
Batch: 680; loss: 0.63; acc: 0.78
Batch: 700; loss: 0.73; acc: 0.8
Batch: 720; loss: 0.76; acc: 0.78
Batch: 740; loss: 0.52; acc: 0.89
Batch: 760; loss: 0.65; acc: 0.75
Batch: 780; loss: 0.75; acc: 0.77
Train Epoch over. train_loss: 0.84; train_accuracy: 0.72 

Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 0.88; acc: 0.67
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 0.73; acc: 0.67
Batch: 80; loss: 0.74; acc: 0.75
Batch: 100; loss: 0.77; acc: 0.8
Batch: 120; loss: 1.08; acc: 0.64
Batch: 140; loss: 0.72; acc: 0.75
Val Epoch over. val_loss: 0.8056243781451207; val_accuracy: 0.7393511146496815 

The current subspace-distance is: 0.00014452848699875176 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.59; acc: 0.8
Batch: 20; loss: 0.81; acc: 0.72
Batch: 40; loss: 0.82; acc: 0.75
Batch: 60; loss: 1.06; acc: 0.64
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.7; acc: 0.78
Batch: 120; loss: 0.94; acc: 0.69
Batch: 140; loss: 0.79; acc: 0.8
Batch: 160; loss: 1.02; acc: 0.66
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.76; acc: 0.78
Batch: 220; loss: 0.96; acc: 0.66
Batch: 240; loss: 0.61; acc: 0.78
Batch: 260; loss: 0.73; acc: 0.77
Batch: 280; loss: 0.47; acc: 0.8
Batch: 300; loss: 0.93; acc: 0.69
Batch: 320; loss: 1.14; acc: 0.67
Batch: 340; loss: 1.14; acc: 0.64
Batch: 360; loss: 0.89; acc: 0.7
Batch: 380; loss: 0.92; acc: 0.67
Batch: 400; loss: 0.84; acc: 0.66
Batch: 420; loss: 0.97; acc: 0.69
Batch: 440; loss: 1.0; acc: 0.62
Batch: 460; loss: 1.06; acc: 0.69
Batch: 480; loss: 0.87; acc: 0.73
Batch: 500; loss: 0.73; acc: 0.75
Batch: 520; loss: 0.83; acc: 0.7
Batch: 540; loss: 0.96; acc: 0.69
Batch: 560; loss: 0.87; acc: 0.66
Batch: 580; loss: 1.0; acc: 0.64
Batch: 600; loss: 0.95; acc: 0.66
Batch: 620; loss: 1.06; acc: 0.58
Batch: 640; loss: 1.14; acc: 0.67
Batch: 660; loss: 0.93; acc: 0.69
Batch: 680; loss: 0.91; acc: 0.67
Batch: 700; loss: 0.87; acc: 0.78
Batch: 720; loss: 0.86; acc: 0.72
Batch: 740; loss: 0.7; acc: 0.77
Batch: 760; loss: 0.66; acc: 0.8
Batch: 780; loss: 0.67; acc: 0.81
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.91; acc: 0.7
Batch: 20; loss: 0.87; acc: 0.66
Batch: 40; loss: 0.67; acc: 0.77
Batch: 60; loss: 0.74; acc: 0.69
Batch: 80; loss: 0.72; acc: 0.77
Batch: 100; loss: 0.79; acc: 0.73
Batch: 120; loss: 1.11; acc: 0.59
Batch: 140; loss: 0.75; acc: 0.75
Val Epoch over. val_loss: 0.8084477245048353; val_accuracy: 0.7374601910828026 

The current subspace-distance is: 0.00014775883755646646 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.07; acc: 0.62
Batch: 20; loss: 0.81; acc: 0.77
Batch: 40; loss: 1.13; acc: 0.69
Batch: 60; loss: 0.74; acc: 0.75
Batch: 80; loss: 0.66; acc: 0.77
Batch: 100; loss: 0.7; acc: 0.72
Batch: 120; loss: 0.89; acc: 0.72
Batch: 140; loss: 0.78; acc: 0.72
Batch: 160; loss: 0.81; acc: 0.69
Batch: 180; loss: 1.22; acc: 0.64
Batch: 200; loss: 0.79; acc: 0.78
Batch: 220; loss: 0.6; acc: 0.75
Batch: 240; loss: 0.98; acc: 0.69
Batch: 260; loss: 0.71; acc: 0.7
Batch: 280; loss: 0.85; acc: 0.72
Batch: 300; loss: 0.74; acc: 0.83
Batch: 320; loss: 0.95; acc: 0.75
Batch: 340; loss: 1.16; acc: 0.61
Batch: 360; loss: 0.77; acc: 0.73
Batch: 380; loss: 0.79; acc: 0.78
Batch: 400; loss: 0.96; acc: 0.67
Batch: 420; loss: 0.75; acc: 0.73
Batch: 440; loss: 1.14; acc: 0.58
Batch: 460; loss: 0.86; acc: 0.75
Batch: 480; loss: 0.79; acc: 0.69
Batch: 500; loss: 1.01; acc: 0.66
Batch: 520; loss: 0.84; acc: 0.75
Batch: 540; loss: 1.01; acc: 0.67
Batch: 560; loss: 0.48; acc: 0.83
Batch: 580; loss: 1.03; acc: 0.72
Batch: 600; loss: 0.9; acc: 0.78
Batch: 620; loss: 0.84; acc: 0.66
Batch: 640; loss: 0.92; acc: 0.72
Batch: 660; loss: 0.93; acc: 0.67
Batch: 680; loss: 0.75; acc: 0.7
Batch: 700; loss: 1.06; acc: 0.64
Batch: 720; loss: 0.73; acc: 0.73
Batch: 740; loss: 0.76; acc: 0.75
Batch: 760; loss: 0.74; acc: 0.8
Batch: 780; loss: 1.09; acc: 0.73
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.9; acc: 0.7
Batch: 20; loss: 0.89; acc: 0.7
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.75; acc: 0.64
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.78; acc: 0.78
Batch: 120; loss: 1.1; acc: 0.62
Batch: 140; loss: 0.7; acc: 0.77
Val Epoch over. val_loss: 0.8068889867348276; val_accuracy: 0.7365644904458599 

The current subspace-distance is: 0.0001495968026574701 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.83; acc: 0.77
Batch: 20; loss: 0.88; acc: 0.69
Batch: 40; loss: 0.68; acc: 0.75
Batch: 60; loss: 0.53; acc: 0.84
Batch: 80; loss: 0.84; acc: 0.7
Batch: 100; loss: 1.02; acc: 0.67
Batch: 120; loss: 0.92; acc: 0.67
Batch: 140; loss: 0.83; acc: 0.73
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.89; acc: 0.7
Batch: 200; loss: 0.69; acc: 0.73
Batch: 220; loss: 0.7; acc: 0.77
Batch: 240; loss: 0.63; acc: 0.78
Batch: 260; loss: 0.8; acc: 0.75
Batch: 280; loss: 0.92; acc: 0.73
Batch: 300; loss: 0.79; acc: 0.77
Batch: 320; loss: 0.9; acc: 0.75
Batch: 340; loss: 0.84; acc: 0.77
Batch: 360; loss: 0.92; acc: 0.73
Batch: 380; loss: 0.65; acc: 0.75
Batch: 400; loss: 0.77; acc: 0.67
Batch: 420; loss: 0.74; acc: 0.8
Batch: 440; loss: 0.8; acc: 0.67
Batch: 460; loss: 0.92; acc: 0.73
Batch: 480; loss: 0.92; acc: 0.75
Batch: 500; loss: 0.85; acc: 0.7
Batch: 520; loss: 0.89; acc: 0.67
Batch: 540; loss: 1.13; acc: 0.62
Batch: 560; loss: 0.89; acc: 0.72
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.87; acc: 0.72
Batch: 620; loss: 0.63; acc: 0.77
Batch: 640; loss: 0.67; acc: 0.75
Batch: 660; loss: 0.93; acc: 0.73
Batch: 680; loss: 0.88; acc: 0.75
Batch: 700; loss: 0.96; acc: 0.66
Batch: 720; loss: 0.87; acc: 0.67
Batch: 740; loss: 0.79; acc: 0.73
Batch: 760; loss: 0.73; acc: 0.8
Batch: 780; loss: 0.78; acc: 0.72
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.91; acc: 0.72
Batch: 20; loss: 0.87; acc: 0.72
Batch: 40; loss: 0.68; acc: 0.77
Batch: 60; loss: 0.76; acc: 0.69
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 1.08; acc: 0.61
Batch: 140; loss: 0.71; acc: 0.77
Val Epoch over. val_loss: 0.8076333471923877; val_accuracy: 0.7377587579617835 

The current subspace-distance is: 0.00015087351494003087 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.67; acc: 0.73
Batch: 20; loss: 1.03; acc: 0.72
Batch: 40; loss: 0.75; acc: 0.72
Batch: 60; loss: 0.78; acc: 0.77
Batch: 80; loss: 1.15; acc: 0.62
Batch: 100; loss: 0.93; acc: 0.7
Batch: 120; loss: 0.83; acc: 0.73
Batch: 140; loss: 0.91; acc: 0.72
Batch: 160; loss: 0.85; acc: 0.7
Batch: 180; loss: 0.93; acc: 0.67
Batch: 200; loss: 0.87; acc: 0.69
Batch: 220; loss: 0.9; acc: 0.8
Batch: 240; loss: 0.8; acc: 0.73
Batch: 260; loss: 0.56; acc: 0.84
Batch: 280; loss: 0.91; acc: 0.69
Batch: 300; loss: 0.86; acc: 0.77
Batch: 320; loss: 0.75; acc: 0.78
Batch: 340; loss: 0.73; acc: 0.72
Batch: 360; loss: 0.88; acc: 0.77
Batch: 380; loss: 0.82; acc: 0.75
Batch: 400; loss: 1.04; acc: 0.61
Batch: 420; loss: 0.97; acc: 0.66
Batch: 440; loss: 0.94; acc: 0.66
Batch: 460; loss: 0.7; acc: 0.75
Batch: 480; loss: 0.67; acc: 0.75
Batch: 500; loss: 0.7; acc: 0.8
Batch: 520; loss: 0.96; acc: 0.75
Batch: 540; loss: 0.89; acc: 0.73
Batch: 560; loss: 0.92; acc: 0.75
Batch: 580; loss: 0.55; acc: 0.81
Batch: 600; loss: 0.95; acc: 0.66
Batch: 620; loss: 0.87; acc: 0.72
Batch: 640; loss: 0.77; acc: 0.7
Batch: 660; loss: 1.12; acc: 0.59
Batch: 680; loss: 0.83; acc: 0.73
Batch: 700; loss: 0.88; acc: 0.75
Batch: 720; loss: 0.74; acc: 0.73
Batch: 740; loss: 0.96; acc: 0.72
Batch: 760; loss: 0.73; acc: 0.75
Batch: 780; loss: 1.02; acc: 0.7
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.88; acc: 0.7
Batch: 20; loss: 0.9; acc: 0.69
Batch: 40; loss: 0.65; acc: 0.77
Batch: 60; loss: 0.73; acc: 0.7
Batch: 80; loss: 0.73; acc: 0.77
Batch: 100; loss: 0.77; acc: 0.78
Batch: 120; loss: 1.1; acc: 0.62
Batch: 140; loss: 0.72; acc: 0.77
Val Epoch over. val_loss: 0.8053499697499974; val_accuracy: 0.7383558917197452 

The current subspace-distance is: 0.00015079065633472055 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 1.02; acc: 0.61
Batch: 20; loss: 0.7; acc: 0.75
Batch: 40; loss: 0.72; acc: 0.69
Batch: 60; loss: 0.97; acc: 0.7
Batch: 80; loss: 0.98; acc: 0.67
Batch: 100; loss: 0.69; acc: 0.72
Batch: 120; loss: 0.87; acc: 0.7
Batch: 140; loss: 0.93; acc: 0.7
Batch: 160; loss: 0.59; acc: 0.78
Batch: 180; loss: 0.86; acc: 0.7
Batch: 200; loss: 0.87; acc: 0.72
Batch: 220; loss: 0.96; acc: 0.64
Batch: 240; loss: 0.76; acc: 0.75
Batch: 260; loss: 0.62; acc: 0.81
Batch: 280; loss: 0.61; acc: 0.77
Batch: 300; loss: 0.69; acc: 0.8
Batch: 320; loss: 0.68; acc: 0.72
Batch: 340; loss: 0.84; acc: 0.75
Batch: 360; loss: 0.64; acc: 0.75
Batch: 380; loss: 0.73; acc: 0.73
Batch: 400; loss: 0.77; acc: 0.78
Batch: 420; loss: 0.89; acc: 0.73
Batch: 440; loss: 0.93; acc: 0.66
Batch: 460; loss: 0.91; acc: 0.67
Batch: 480; loss: 0.8; acc: 0.7
Batch: 500; loss: 0.66; acc: 0.81
Batch: 520; loss: 0.64; acc: 0.75
Batch: 540; loss: 0.9; acc: 0.69
Batch: 560; loss: 0.93; acc: 0.7
Batch: 580; loss: 0.78; acc: 0.75
Batch: 600; loss: 0.87; acc: 0.72
Batch: 620; loss: 0.73; acc: 0.81
Batch: 640; loss: 0.81; acc: 0.7
Batch: 660; loss: 0.99; acc: 0.69
Batch: 680; loss: 0.75; acc: 0.78
Batch: 700; loss: 0.67; acc: 0.8
Batch: 720; loss: 1.2; acc: 0.64
Batch: 740; loss: 1.09; acc: 0.67
Batch: 760; loss: 0.82; acc: 0.72
Batch: 780; loss: 0.77; acc: 0.73
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.91; acc: 0.72
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.76; acc: 0.69
Batch: 80; loss: 0.77; acc: 0.77
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 1.09; acc: 0.64
Batch: 140; loss: 0.7; acc: 0.77
Val Epoch over. val_loss: 0.80907043757712; val_accuracy: 0.7364649681528662 

The current subspace-distance is: 0.00015344696294050664 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.8; acc: 0.78
Batch: 20; loss: 0.88; acc: 0.7
Batch: 40; loss: 0.96; acc: 0.66
Batch: 60; loss: 0.89; acc: 0.7
Batch: 80; loss: 0.92; acc: 0.75
Batch: 100; loss: 1.2; acc: 0.61
Batch: 120; loss: 0.66; acc: 0.75
Batch: 140; loss: 0.82; acc: 0.7
Batch: 160; loss: 0.78; acc: 0.77
Batch: 180; loss: 0.85; acc: 0.77
Batch: 200; loss: 0.83; acc: 0.75
Batch: 220; loss: 0.82; acc: 0.73
Batch: 240; loss: 0.83; acc: 0.72
Batch: 260; loss: 0.58; acc: 0.83
Batch: 280; loss: 0.75; acc: 0.77
Batch: 300; loss: 0.57; acc: 0.8
Batch: 320; loss: 0.79; acc: 0.78
Batch: 340; loss: 1.02; acc: 0.69
Batch: 360; loss: 1.03; acc: 0.66
Batch: 380; loss: 0.75; acc: 0.77
Batch: 400; loss: 0.9; acc: 0.69
Batch: 420; loss: 0.83; acc: 0.72
Batch: 440; loss: 0.93; acc: 0.69
Batch: 460; loss: 0.9; acc: 0.7
Batch: 480; loss: 0.88; acc: 0.67
Batch: 500; loss: 0.91; acc: 0.7
Batch: 520; loss: 0.74; acc: 0.77
Batch: 540; loss: 0.72; acc: 0.78
Batch: 560; loss: 0.73; acc: 0.78
Batch: 580; loss: 0.75; acc: 0.73
Batch: 600; loss: 0.81; acc: 0.7
Batch: 620; loss: 0.86; acc: 0.75
Batch: 640; loss: 0.43; acc: 0.88
Batch: 660; loss: 0.89; acc: 0.7
Batch: 680; loss: 1.09; acc: 0.67
Batch: 700; loss: 0.73; acc: 0.77
Batch: 720; loss: 1.23; acc: 0.64
Batch: 740; loss: 0.84; acc: 0.67
Batch: 760; loss: 0.92; acc: 0.67
Batch: 780; loss: 0.8; acc: 0.72
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.89; acc: 0.72
Batch: 20; loss: 0.89; acc: 0.69
Batch: 40; loss: 0.66; acc: 0.78
Batch: 60; loss: 0.73; acc: 0.67
Batch: 80; loss: 0.75; acc: 0.77
Batch: 100; loss: 0.77; acc: 0.78
Batch: 120; loss: 1.09; acc: 0.61
Batch: 140; loss: 0.74; acc: 0.77
Val Epoch over. val_loss: 0.8068384960958153; val_accuracy: 0.7379578025477707 

The current subspace-distance is: 0.0001538083452032879 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.86; acc: 0.72
Batch: 20; loss: 0.7; acc: 0.77
Batch: 40; loss: 0.98; acc: 0.72
Batch: 60; loss: 0.9; acc: 0.7
Batch: 80; loss: 0.75; acc: 0.73
Batch: 100; loss: 0.78; acc: 0.77
Batch: 120; loss: 0.76; acc: 0.69
Batch: 140; loss: 0.99; acc: 0.72
Batch: 160; loss: 1.07; acc: 0.64
Batch: 180; loss: 0.76; acc: 0.77
Batch: 200; loss: 0.6; acc: 0.78
Batch: 220; loss: 1.15; acc: 0.64
Batch: 240; loss: 0.86; acc: 0.73
Batch: 260; loss: 0.89; acc: 0.69
Batch: 280; loss: 0.88; acc: 0.67
Batch: 300; loss: 0.76; acc: 0.73
Batch: 320; loss: 0.92; acc: 0.7
Batch: 340; loss: 0.96; acc: 0.69
Batch: 360; loss: 0.87; acc: 0.64
Batch: 380; loss: 1.07; acc: 0.62
Batch: 400; loss: 0.82; acc: 0.64
Batch: 420; loss: 0.74; acc: 0.72
Batch: 440; loss: 0.96; acc: 0.67
Batch: 460; loss: 0.81; acc: 0.69
Batch: 480; loss: 1.11; acc: 0.66
Batch: 500; loss: 1.1; acc: 0.62
Batch: 520; loss: 0.64; acc: 0.75
Batch: 540; loss: 0.89; acc: 0.69
Batch: 560; loss: 0.75; acc: 0.67
Batch: 580; loss: 0.91; acc: 0.77
Batch: 600; loss: 0.63; acc: 0.83
Batch: 620; loss: 0.62; acc: 0.81
Batch: 640; loss: 0.94; acc: 0.7
Batch: 660; loss: 0.83; acc: 0.73
Batch: 680; loss: 1.11; acc: 0.69
Batch: 700; loss: 0.93; acc: 0.66
Batch: 720; loss: 0.78; acc: 0.75
Batch: 740; loss: 0.76; acc: 0.77
Batch: 760; loss: 0.78; acc: 0.81
Batch: 780; loss: 1.08; acc: 0.64
Train Epoch over. train_loss: 0.84; train_accuracy: 0.73 

Batch: 0; loss: 0.9; acc: 0.72
Batch: 20; loss: 0.9; acc: 0.72
Batch: 40; loss: 0.67; acc: 0.78
Batch: 60; loss: 0.74; acc: 0.69
Batch: 80; loss: 0.76; acc: 0.77
Batch: 100; loss: 0.76; acc: 0.78
Batch: 120; loss: 1.09; acc: 0.64
Batch: 140; loss: 0.71; acc: 0.77
Val Epoch over. val_loss: 0.8094644058661856; val_accuracy: 0.73546974522293 

The current subspace-distance is: 0.00015506868658121675 

plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_100_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 28264
elements in E: 3954800
fraction nonzero: 0.007146758369576211
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.31; acc: 0.08
Batch: 180; loss: 2.31; acc: 0.08
Batch: 200; loss: 2.3; acc: 0.14
Batch: 220; loss: 2.3; acc: 0.27
Batch: 240; loss: 2.29; acc: 0.12
Batch: 260; loss: 2.29; acc: 0.27
Batch: 280; loss: 2.31; acc: 0.11
Batch: 300; loss: 2.3; acc: 0.19
Batch: 320; loss: 2.29; acc: 0.16
Batch: 340; loss: 2.31; acc: 0.16
Batch: 360; loss: 2.29; acc: 0.09
Batch: 380; loss: 2.3; acc: 0.17
Batch: 400; loss: 2.27; acc: 0.12
Batch: 420; loss: 2.3; acc: 0.14
Batch: 440; loss: 2.3; acc: 0.16
Batch: 460; loss: 2.27; acc: 0.28
Batch: 480; loss: 2.29; acc: 0.12
Batch: 500; loss: 2.29; acc: 0.14
Batch: 520; loss: 2.32; acc: 0.05
Batch: 540; loss: 2.28; acc: 0.11
Batch: 560; loss: 2.29; acc: 0.08
Batch: 580; loss: 2.29; acc: 0.12
Batch: 600; loss: 2.29; acc: 0.08
Batch: 620; loss: 2.28; acc: 0.16
Batch: 640; loss: 2.28; acc: 0.2
Batch: 660; loss: 2.25; acc: 0.23
Batch: 680; loss: 2.25; acc: 0.2
Batch: 700; loss: 2.26; acc: 0.23
Batch: 720; loss: 2.22; acc: 0.3
Batch: 740; loss: 2.26; acc: 0.19
Batch: 760; loss: 2.25; acc: 0.22
Batch: 780; loss: 2.2; acc: 0.36
Train Epoch over. train_loss: 2.29; train_accuracy: 0.15 

Batch: 0; loss: 2.25; acc: 0.2
Batch: 20; loss: 2.28; acc: 0.14
Batch: 40; loss: 2.23; acc: 0.23
Batch: 60; loss: 2.25; acc: 0.22
Batch: 80; loss: 2.23; acc: 0.22
Batch: 100; loss: 2.26; acc: 0.19
Batch: 120; loss: 2.26; acc: 0.19
Batch: 140; loss: 2.25; acc: 0.22
Val Epoch over. val_loss: 2.2507563943316224; val_accuracy: 0.20421974522292993 

The current subspace-distance is: 1.0461092642799485e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 2.24; acc: 0.23
Batch: 20; loss: 2.23; acc: 0.19
Batch: 40; loss: 2.23; acc: 0.27
Batch: 60; loss: 2.23; acc: 0.19
Batch: 80; loss: 2.19; acc: 0.25
Batch: 100; loss: 2.24; acc: 0.17
Batch: 120; loss: 2.18; acc: 0.2
Batch: 140; loss: 2.12; acc: 0.3
Batch: 160; loss: 2.03; acc: 0.3
Batch: 180; loss: 1.89; acc: 0.42
Batch: 200; loss: 1.99; acc: 0.28
Batch: 220; loss: 1.77; acc: 0.38
Batch: 240; loss: 1.88; acc: 0.34
Batch: 260; loss: 1.76; acc: 0.36
Batch: 280; loss: 1.57; acc: 0.5
Batch: 300; loss: 1.8; acc: 0.42
Batch: 320; loss: 1.48; acc: 0.55
Batch: 340; loss: 2.08; acc: 0.36
Batch: 360; loss: 1.07; acc: 0.64
Batch: 380; loss: 1.42; acc: 0.59
Batch: 400; loss: 1.29; acc: 0.62
Batch: 420; loss: 1.29; acc: 0.66
Batch: 440; loss: 1.29; acc: 0.56
Batch: 460; loss: 1.14; acc: 0.61
Batch: 480; loss: 1.35; acc: 0.58
Batch: 500; loss: 1.3; acc: 0.55
Batch: 520; loss: 1.37; acc: 0.59
Batch: 540; loss: 0.99; acc: 0.64
Batch: 560; loss: 1.25; acc: 0.56
Batch: 580; loss: 0.99; acc: 0.66
Batch: 600; loss: 1.4; acc: 0.61
Batch: 620; loss: 1.24; acc: 0.61
Batch: 640; loss: 0.9; acc: 0.7
Batch: 660; loss: 1.26; acc: 0.53
Batch: 680; loss: 0.93; acc: 0.72
Batch: 700; loss: 1.39; acc: 0.55
Batch: 720; loss: 1.22; acc: 0.56
Batch: 740; loss: 1.02; acc: 0.7
Batch: 760; loss: 1.27; acc: 0.61
Batch: 780; loss: 0.8; acc: 0.78
Train Epoch over. train_loss: 1.59; train_accuracy: 0.46 

Batch: 0; loss: 1.03; acc: 0.61
Batch: 20; loss: 1.23; acc: 0.56
Batch: 40; loss: 0.82; acc: 0.72
Batch: 60; loss: 1.07; acc: 0.67
Batch: 80; loss: 0.99; acc: 0.61
Batch: 100; loss: 1.23; acc: 0.56
Batch: 120; loss: 1.35; acc: 0.58
Batch: 140; loss: 0.76; acc: 0.8
Val Epoch over. val_loss: 1.1250745616141398; val_accuracy: 0.6069864649681529 

The current subspace-distance is: 1.908064223243855e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 1.13; acc: 0.61
Batch: 20; loss: 1.13; acc: 0.69
Batch: 40; loss: 0.67; acc: 0.81
Batch: 60; loss: 1.2; acc: 0.56
Batch: 80; loss: 1.09; acc: 0.59
Batch: 100; loss: 0.99; acc: 0.75
Batch: 120; loss: 0.84; acc: 0.72
Batch: 140; loss: 1.13; acc: 0.59
Batch: 160; loss: 1.44; acc: 0.5
Batch: 180; loss: 0.67; acc: 0.8
Batch: 200; loss: 0.86; acc: 0.8
Batch: 220; loss: 1.1; acc: 0.61
Batch: 240; loss: 0.69; acc: 0.69
Batch: 260; loss: 1.29; acc: 0.55
Batch: 280; loss: 1.04; acc: 0.7
Batch: 300; loss: 0.79; acc: 0.69
Batch: 320; loss: 0.78; acc: 0.69
Batch: 340; loss: 2.01; acc: 0.44
Batch: 360; loss: 0.98; acc: 0.72
Batch: 380; loss: 0.83; acc: 0.69
Batch: 400; loss: 0.62; acc: 0.73
Batch: 420; loss: 1.08; acc: 0.59
Batch: 440; loss: 1.07; acc: 0.73
Batch: 460; loss: 0.95; acc: 0.69
Batch: 480; loss: 1.12; acc: 0.7
Batch: 500; loss: 1.09; acc: 0.59
Batch: 520; loss: 0.73; acc: 0.8
Batch: 540; loss: 0.77; acc: 0.75
Batch: 560; loss: 0.57; acc: 0.84
Batch: 580; loss: 1.1; acc: 0.62
Batch: 600; loss: 1.25; acc: 0.62
Batch: 620; loss: 0.87; acc: 0.75
Batch: 640; loss: 0.97; acc: 0.7
Batch: 660; loss: 0.77; acc: 0.78
Batch: 680; loss: 0.74; acc: 0.75
Batch: 700; loss: 0.6; acc: 0.81
Batch: 720; loss: 0.75; acc: 0.73
Batch: 740; loss: 0.71; acc: 0.75
Batch: 760; loss: 0.93; acc: 0.64
Batch: 780; loss: 0.7; acc: 0.75
Train Epoch over. train_loss: 0.92; train_accuracy: 0.71 

Batch: 0; loss: 0.84; acc: 0.78
Batch: 20; loss: 0.97; acc: 0.75
Batch: 40; loss: 0.79; acc: 0.75
Batch: 60; loss: 0.87; acc: 0.72
Batch: 80; loss: 0.51; acc: 0.83
Batch: 100; loss: 0.83; acc: 0.77
Batch: 120; loss: 0.93; acc: 0.66
Batch: 140; loss: 0.64; acc: 0.73
Val Epoch over. val_loss: 0.8289340916712573; val_accuracy: 0.7376592356687898 

The current subspace-distance is: 2.7849760954268277e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.9; acc: 0.69
Batch: 20; loss: 0.98; acc: 0.67
Batch: 40; loss: 0.87; acc: 0.73
Batch: 60; loss: 0.78; acc: 0.77
Batch: 80; loss: 0.73; acc: 0.81
Batch: 100; loss: 0.99; acc: 0.7
Batch: 120; loss: 1.15; acc: 0.66
Batch: 140; loss: 1.7; acc: 0.61
Batch: 160; loss: 0.92; acc: 0.64
Batch: 180; loss: 0.65; acc: 0.8
Batch: 200; loss: 0.8; acc: 0.78
Batch: 220; loss: 0.77; acc: 0.73
Batch: 240; loss: 0.96; acc: 0.7
Batch: 260; loss: 0.56; acc: 0.78
Batch: 280; loss: 0.71; acc: 0.75
Batch: 300; loss: 0.73; acc: 0.8
Batch: 320; loss: 0.86; acc: 0.7
Batch: 340; loss: 1.2; acc: 0.62
Batch: 360; loss: 0.67; acc: 0.77
Batch: 380; loss: 0.61; acc: 0.77
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.87; acc: 0.75
Batch: 440; loss: 0.84; acc: 0.67
Batch: 460; loss: 0.77; acc: 0.73
Batch: 480; loss: 0.49; acc: 0.81
Batch: 500; loss: 0.68; acc: 0.8
Batch: 520; loss: 0.9; acc: 0.7
Batch: 540; loss: 0.76; acc: 0.77
Batch: 560; loss: 0.74; acc: 0.8
Batch: 580; loss: 0.71; acc: 0.73
Batch: 600; loss: 0.62; acc: 0.86
Batch: 620; loss: 1.06; acc: 0.7
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.76; acc: 0.81
Batch: 680; loss: 0.47; acc: 0.83
Batch: 700; loss: 0.77; acc: 0.73
Batch: 720; loss: 0.66; acc: 0.78
Batch: 740; loss: 0.91; acc: 0.77
Batch: 760; loss: 0.84; acc: 0.72
Batch: 780; loss: 0.73; acc: 0.77
Train Epoch over. train_loss: 0.81; train_accuracy: 0.74 

Batch: 0; loss: 0.96; acc: 0.73
Batch: 20; loss: 0.97; acc: 0.66
Batch: 40; loss: 0.89; acc: 0.8
Batch: 60; loss: 1.06; acc: 0.67
Batch: 80; loss: 0.84; acc: 0.7
Batch: 100; loss: 0.91; acc: 0.64
Batch: 120; loss: 1.22; acc: 0.62
Batch: 140; loss: 0.63; acc: 0.72
Val Epoch over. val_loss: 0.8476354310846632; val_accuracy: 0.7237261146496815 

The current subspace-distance is: 3.507892324705608e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.95; acc: 0.7
Batch: 20; loss: 0.78; acc: 0.75
Batch: 40; loss: 0.76; acc: 0.78
Batch: 60; loss: 0.81; acc: 0.7
Batch: 80; loss: 0.68; acc: 0.73
Batch: 100; loss: 1.01; acc: 0.73
Batch: 120; loss: 1.01; acc: 0.66
Batch: 140; loss: 0.99; acc: 0.69
Batch: 160; loss: 0.74; acc: 0.73
Batch: 180; loss: 0.57; acc: 0.8
Batch: 200; loss: 0.69; acc: 0.75
Batch: 220; loss: 0.74; acc: 0.77
Batch: 240; loss: 0.87; acc: 0.7
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.82; acc: 0.77
Batch: 300; loss: 1.07; acc: 0.69
Batch: 320; loss: 0.83; acc: 0.77
Batch: 340; loss: 0.83; acc: 0.72
Batch: 360; loss: 0.63; acc: 0.78
Batch: 380; loss: 1.02; acc: 0.7
Batch: 400; loss: 0.78; acc: 0.73
Batch: 420; loss: 0.82; acc: 0.78
Batch: 440; loss: 1.03; acc: 0.64
Batch: 460; loss: 0.82; acc: 0.78
Batch: 480; loss: 0.75; acc: 0.73
Batch: 500; loss: 0.83; acc: 0.75
Batch: 520; loss: 0.99; acc: 0.69
Batch: 540; loss: 0.82; acc: 0.78
Batch: 560; loss: 0.73; acc: 0.84
Batch: 580; loss: 1.04; acc: 0.69
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.92; acc: 0.73
Batch: 640; loss: 0.71; acc: 0.75
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.99; acc: 0.7
Batch: 700; loss: 0.75; acc: 0.77
Batch: 720; loss: 0.89; acc: 0.75
Batch: 740; loss: 0.67; acc: 0.75
Batch: 760; loss: 0.96; acc: 0.72
Batch: 780; loss: 0.61; acc: 0.77
Train Epoch over. train_loss: 0.76; train_accuracy: 0.76 

Batch: 0; loss: 0.84; acc: 0.7
Batch: 20; loss: 0.86; acc: 0.73
Batch: 40; loss: 0.73; acc: 0.75
Batch: 60; loss: 0.89; acc: 0.72
Batch: 80; loss: 0.51; acc: 0.8
Batch: 100; loss: 0.87; acc: 0.78
Batch: 120; loss: 0.88; acc: 0.69
Batch: 140; loss: 0.39; acc: 0.88
Val Epoch over. val_loss: 0.7686799309056276; val_accuracy: 0.7448248407643312 

The current subspace-distance is: 4.2802294046850875e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.78
Batch: 20; loss: 0.85; acc: 0.75
Batch: 40; loss: 0.47; acc: 0.84
Batch: 60; loss: 1.14; acc: 0.69
Batch: 80; loss: 0.78; acc: 0.77
Batch: 100; loss: 0.83; acc: 0.75
Batch: 120; loss: 1.08; acc: 0.72
Batch: 140; loss: 0.9; acc: 0.7
Batch: 160; loss: 0.71; acc: 0.81
Batch: 180; loss: 0.83; acc: 0.75
Batch: 200; loss: 1.08; acc: 0.67
Batch: 220; loss: 1.02; acc: 0.7
Batch: 240; loss: 0.67; acc: 0.81
Batch: 260; loss: 0.68; acc: 0.77
Batch: 280; loss: 0.8; acc: 0.77
Batch: 300; loss: 0.9; acc: 0.75
Batch: 320; loss: 0.76; acc: 0.73
Batch: 340; loss: 0.43; acc: 0.88
Batch: 360; loss: 0.61; acc: 0.78
Batch: 380; loss: 0.77; acc: 0.73
Batch: 400; loss: 0.6; acc: 0.84
Batch: 420; loss: 0.85; acc: 0.72
Batch: 440; loss: 0.77; acc: 0.77
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.59; acc: 0.78
Batch: 500; loss: 0.7; acc: 0.7
Batch: 520; loss: 0.81; acc: 0.77
Batch: 540; loss: 0.54; acc: 0.81
Batch: 560; loss: 0.49; acc: 0.8
Batch: 580; loss: 0.6; acc: 0.8
Batch: 600; loss: 0.71; acc: 0.78
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.64; acc: 0.77
Batch: 680; loss: 0.57; acc: 0.77
Batch: 700; loss: 0.61; acc: 0.8
Batch: 720; loss: 1.01; acc: 0.69
Batch: 740; loss: 0.68; acc: 0.77
Batch: 760; loss: 0.75; acc: 0.73
Batch: 780; loss: 0.43; acc: 0.84
Train Epoch over. train_loss: 0.71; train_accuracy: 0.78 

Batch: 0; loss: 0.79; acc: 0.72
Batch: 20; loss: 0.88; acc: 0.66
Batch: 40; loss: 0.82; acc: 0.77
Batch: 60; loss: 0.85; acc: 0.7
Batch: 80; loss: 0.72; acc: 0.72
Batch: 100; loss: 0.85; acc: 0.8
Batch: 120; loss: 0.72; acc: 0.81
Batch: 140; loss: 0.58; acc: 0.78
Val Epoch over. val_loss: 0.8764782692216764; val_accuracy: 0.7213375796178344 

The current subspace-distance is: 4.8012298066169024e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 1.05; acc: 0.67
Batch: 20; loss: 0.57; acc: 0.8
Batch: 40; loss: 0.8; acc: 0.8
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.76; acc: 0.73
Batch: 100; loss: 0.49; acc: 0.8
Batch: 120; loss: 0.75; acc: 0.8
Batch: 140; loss: 0.77; acc: 0.8
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.59; acc: 0.8
Batch: 200; loss: 0.94; acc: 0.7
Batch: 220; loss: 0.92; acc: 0.67
Batch: 240; loss: 0.5; acc: 0.81
Batch: 260; loss: 0.44; acc: 0.89
Batch: 280; loss: 0.56; acc: 0.84
Batch: 300; loss: 0.62; acc: 0.81
Batch: 320; loss: 1.13; acc: 0.64
Batch: 340; loss: 0.63; acc: 0.86
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.8; acc: 0.75
Batch: 400; loss: 0.73; acc: 0.72
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.72; acc: 0.78
Batch: 480; loss: 0.65; acc: 0.83
Batch: 500; loss: 0.6; acc: 0.83
Batch: 520; loss: 0.57; acc: 0.81
Batch: 540; loss: 0.69; acc: 0.8
Batch: 560; loss: 0.73; acc: 0.77
Batch: 580; loss: 0.82; acc: 0.78
Batch: 600; loss: 0.51; acc: 0.84
Batch: 620; loss: 0.76; acc: 0.78
Batch: 640; loss: 0.73; acc: 0.78
Batch: 660; loss: 0.78; acc: 0.78
Batch: 680; loss: 0.84; acc: 0.72
Batch: 700; loss: 0.45; acc: 0.86
Batch: 720; loss: 0.51; acc: 0.83
Batch: 740; loss: 0.51; acc: 0.78
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.74; acc: 0.81
Train Epoch over. train_loss: 0.67; train_accuracy: 0.79 

Batch: 0; loss: 0.67; acc: 0.81
Batch: 20; loss: 0.84; acc: 0.69
Batch: 40; loss: 0.62; acc: 0.83
Batch: 60; loss: 0.66; acc: 0.75
Batch: 80; loss: 0.64; acc: 0.75
Batch: 100; loss: 0.67; acc: 0.8
Batch: 120; loss: 0.74; acc: 0.8
Batch: 140; loss: 0.47; acc: 0.83
Val Epoch over. val_loss: 0.7451298453245953; val_accuracy: 0.75109474522293 

The current subspace-distance is: 5.4776854085503146e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.64; acc: 0.78
Batch: 20; loss: 0.85; acc: 0.78
Batch: 40; loss: 0.78; acc: 0.73
Batch: 60; loss: 0.84; acc: 0.73
Batch: 80; loss: 0.64; acc: 0.83
Batch: 100; loss: 0.89; acc: 0.75
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.55; acc: 0.83
Batch: 160; loss: 0.44; acc: 0.8
Batch: 180; loss: 0.88; acc: 0.72
Batch: 200; loss: 0.64; acc: 0.78
Batch: 220; loss: 0.75; acc: 0.77
Batch: 240; loss: 0.65; acc: 0.8
Batch: 260; loss: 0.6; acc: 0.8
Batch: 280; loss: 0.79; acc: 0.7
Batch: 300; loss: 0.69; acc: 0.8
Batch: 320; loss: 0.68; acc: 0.78
Batch: 340; loss: 0.8; acc: 0.78
Batch: 360; loss: 0.71; acc: 0.81
Batch: 380; loss: 0.44; acc: 0.84
Batch: 400; loss: 0.66; acc: 0.73
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.51; acc: 0.83
Batch: 460; loss: 0.83; acc: 0.77
Batch: 480; loss: 0.83; acc: 0.77
Batch: 500; loss: 0.61; acc: 0.86
Batch: 520; loss: 0.64; acc: 0.78
Batch: 540; loss: 0.49; acc: 0.83
Batch: 560; loss: 1.11; acc: 0.64
Batch: 580; loss: 0.36; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.75
Batch: 620; loss: 1.21; acc: 0.55
Batch: 640; loss: 0.5; acc: 0.81
Batch: 660; loss: 0.59; acc: 0.78
Batch: 680; loss: 0.49; acc: 0.91
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.51; acc: 0.89
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.9; acc: 0.77
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

Batch: 0; loss: 1.54; acc: 0.52
Batch: 20; loss: 1.32; acc: 0.56
Batch: 40; loss: 1.29; acc: 0.62
Batch: 60; loss: 1.49; acc: 0.62
Batch: 80; loss: 1.71; acc: 0.55
Batch: 100; loss: 1.63; acc: 0.56
Batch: 120; loss: 1.63; acc: 0.56
Batch: 140; loss: 0.95; acc: 0.72
Val Epoch over. val_loss: 1.4516386059439106; val_accuracy: 0.5729498407643312 

The current subspace-distance is: 6.065931302146055e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 1.08; acc: 0.67
Batch: 20; loss: 0.49; acc: 0.81
Batch: 40; loss: 0.58; acc: 0.81
Batch: 60; loss: 0.56; acc: 0.89
Batch: 80; loss: 0.71; acc: 0.75
Batch: 100; loss: 0.72; acc: 0.72
Batch: 120; loss: 0.67; acc: 0.75
Batch: 140; loss: 1.24; acc: 0.59
Batch: 160; loss: 0.37; acc: 0.84
Batch: 180; loss: 0.69; acc: 0.72
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.73; acc: 0.72
Batch: 240; loss: 0.64; acc: 0.83
Batch: 260; loss: 0.66; acc: 0.78
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.56; acc: 0.83
Batch: 320; loss: 0.72; acc: 0.8
Batch: 340; loss: 0.57; acc: 0.86
Batch: 360; loss: 0.88; acc: 0.72
Batch: 380; loss: 0.8; acc: 0.77
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.43; acc: 0.88
Batch: 440; loss: 0.65; acc: 0.75
Batch: 460; loss: 0.66; acc: 0.77
Batch: 480; loss: 0.93; acc: 0.67
Batch: 500; loss: 0.45; acc: 0.84
Batch: 520; loss: 0.66; acc: 0.8
Batch: 540; loss: 0.6; acc: 0.78
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.5; acc: 0.86
Batch: 600; loss: 0.86; acc: 0.75
Batch: 620; loss: 0.72; acc: 0.75
Batch: 640; loss: 0.87; acc: 0.8
Batch: 660; loss: 0.75; acc: 0.77
Batch: 680; loss: 0.65; acc: 0.75
Batch: 700; loss: 0.68; acc: 0.73
Batch: 720; loss: 0.62; acc: 0.7
Batch: 740; loss: 0.59; acc: 0.8
Batch: 760; loss: 0.76; acc: 0.77
Batch: 780; loss: 0.76; acc: 0.83
Train Epoch over. train_loss: 0.66; train_accuracy: 0.79 

Batch: 0; loss: 0.58; acc: 0.84
Batch: 20; loss: 0.74; acc: 0.8
Batch: 40; loss: 0.37; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.58; acc: 0.83
Batch: 120; loss: 1.04; acc: 0.7
Batch: 140; loss: 0.33; acc: 0.91
Val Epoch over. val_loss: 0.5391622838700653; val_accuracy: 0.8314092356687898 

The current subspace-distance is: 6.499357550637797e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.72; acc: 0.73
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.67; acc: 0.75
Batch: 60; loss: 0.58; acc: 0.78
Batch: 80; loss: 0.65; acc: 0.84
Batch: 100; loss: 0.83; acc: 0.78
Batch: 120; loss: 0.64; acc: 0.77
Batch: 140; loss: 0.49; acc: 0.83
Batch: 160; loss: 0.85; acc: 0.78
Batch: 180; loss: 0.62; acc: 0.78
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.9; acc: 0.75
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.73; acc: 0.78
Batch: 280; loss: 0.75; acc: 0.8
Batch: 300; loss: 0.57; acc: 0.78
Batch: 320; loss: 0.95; acc: 0.77
Batch: 340; loss: 0.93; acc: 0.73
Batch: 360; loss: 0.55; acc: 0.81
Batch: 380; loss: 0.89; acc: 0.78
Batch: 400; loss: 0.72; acc: 0.78
Batch: 420; loss: 0.95; acc: 0.72
Batch: 440; loss: 0.89; acc: 0.72
Batch: 460; loss: 0.73; acc: 0.83
Batch: 480; loss: 0.63; acc: 0.81
Batch: 500; loss: 0.55; acc: 0.81
Batch: 520; loss: 0.47; acc: 0.88
Batch: 540; loss: 0.39; acc: 0.88
Batch: 560; loss: 0.56; acc: 0.81
Batch: 580; loss: 0.51; acc: 0.86
Batch: 600; loss: 0.58; acc: 0.8
Batch: 620; loss: 0.62; acc: 0.86
Batch: 640; loss: 0.49; acc: 0.84
Batch: 660; loss: 0.5; acc: 0.8
Batch: 680; loss: 0.98; acc: 0.72
Batch: 700; loss: 0.93; acc: 0.73
Batch: 720; loss: 0.59; acc: 0.75
Batch: 740; loss: 0.67; acc: 0.78
Batch: 760; loss: 0.75; acc: 0.81
Batch: 780; loss: 0.49; acc: 0.78
Train Epoch over. train_loss: 0.65; train_accuracy: 0.8 

Batch: 0; loss: 1.02; acc: 0.73
Batch: 20; loss: 0.88; acc: 0.69
Batch: 40; loss: 0.75; acc: 0.73
Batch: 60; loss: 1.04; acc: 0.59
Batch: 80; loss: 1.18; acc: 0.59
Batch: 100; loss: 0.81; acc: 0.75
Batch: 120; loss: 1.36; acc: 0.59
Batch: 140; loss: 0.74; acc: 0.73
Val Epoch over. val_loss: 0.9877206933726171; val_accuracy: 0.6731687898089171 

The current subspace-distance is: 6.862723239464685e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.21; acc: 0.62
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.65; acc: 0.81
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.51; acc: 0.89
Batch: 160; loss: 0.56; acc: 0.84
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.45; acc: 0.86
Batch: 220; loss: 0.58; acc: 0.81
Batch: 240; loss: 0.68; acc: 0.81
Batch: 260; loss: 0.4; acc: 0.86
Batch: 280; loss: 0.57; acc: 0.84
Batch: 300; loss: 0.65; acc: 0.8
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.65; acc: 0.84
Batch: 360; loss: 0.42; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.83
Batch: 420; loss: 0.67; acc: 0.84
Batch: 440; loss: 0.43; acc: 0.91
Batch: 460; loss: 0.63; acc: 0.84
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.78; acc: 0.8
Batch: 520; loss: 0.49; acc: 0.89
Batch: 540; loss: 0.39; acc: 0.91
Batch: 560; loss: 0.54; acc: 0.78
Batch: 580; loss: 0.47; acc: 0.81
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.51; acc: 0.88
Batch: 640; loss: 0.33; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.43; acc: 0.89
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.32; acc: 0.89
Batch: 760; loss: 0.73; acc: 0.8
Batch: 780; loss: 0.77; acc: 0.84
Train Epoch over. train_loss: 0.53; train_accuracy: 0.84 

Batch: 0; loss: 0.54; acc: 0.78
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.31; acc: 0.94
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.52; acc: 0.78
Batch: 100; loss: 0.55; acc: 0.88
Batch: 120; loss: 1.12; acc: 0.7
Batch: 140; loss: 0.31; acc: 0.88
Val Epoch over. val_loss: 0.5235890495549341; val_accuracy: 0.8357882165605095 

The current subspace-distance is: 7.397322042379528e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.77; acc: 0.78
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.79; acc: 0.73
Batch: 60; loss: 0.56; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.53; acc: 0.84
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.65; acc: 0.83
Batch: 180; loss: 0.53; acc: 0.86
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.57; acc: 0.8
Batch: 240; loss: 0.44; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.86
Batch: 280; loss: 0.36; acc: 0.86
Batch: 300; loss: 0.52; acc: 0.86
Batch: 320; loss: 0.52; acc: 0.78
Batch: 340; loss: 0.27; acc: 0.95
Batch: 360; loss: 0.43; acc: 0.84
Batch: 380; loss: 0.8; acc: 0.83
Batch: 400; loss: 0.59; acc: 0.8
Batch: 420; loss: 0.48; acc: 0.86
Batch: 440; loss: 0.37; acc: 0.88
Batch: 460; loss: 0.52; acc: 0.84
Batch: 480; loss: 0.45; acc: 0.81
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.47; acc: 0.83
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.55; acc: 0.83
Batch: 580; loss: 0.71; acc: 0.8
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.45; acc: 0.84
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.57; acc: 0.84
Batch: 720; loss: 0.69; acc: 0.83
Batch: 740; loss: 0.76; acc: 0.73
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.65; acc: 0.8
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.48; acc: 0.84
Batch: 20; loss: 0.62; acc: 0.8
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.69; acc: 0.8
Batch: 80; loss: 0.59; acc: 0.89
Batch: 100; loss: 0.68; acc: 0.81
Batch: 120; loss: 1.07; acc: 0.69
Batch: 140; loss: 0.3; acc: 0.92
Val Epoch over. val_loss: 0.5523745710872541; val_accuracy: 0.8289211783439491 

The current subspace-distance is: 7.888857362559065e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.57; acc: 0.8
Batch: 20; loss: 0.52; acc: 0.81
Batch: 40; loss: 0.77; acc: 0.73
Batch: 60; loss: 0.48; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.36; acc: 0.91
Batch: 180; loss: 0.37; acc: 0.88
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.69; acc: 0.81
Batch: 240; loss: 0.43; acc: 0.89
Batch: 260; loss: 0.65; acc: 0.77
Batch: 280; loss: 0.52; acc: 0.83
Batch: 300; loss: 0.64; acc: 0.81
Batch: 320; loss: 0.57; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.88
Batch: 360; loss: 0.6; acc: 0.86
Batch: 380; loss: 0.59; acc: 0.78
Batch: 400; loss: 0.37; acc: 0.89
Batch: 420; loss: 0.44; acc: 0.88
Batch: 440; loss: 0.43; acc: 0.83
Batch: 460; loss: 0.42; acc: 0.83
Batch: 480; loss: 0.35; acc: 0.88
Batch: 500; loss: 0.37; acc: 0.84
Batch: 520; loss: 0.58; acc: 0.8
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.61; acc: 0.83
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.53; acc: 0.84
Batch: 620; loss: 0.8; acc: 0.78
Batch: 640; loss: 0.54; acc: 0.86
Batch: 660; loss: 0.6; acc: 0.78
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.69; acc: 0.84
Batch: 720; loss: 0.51; acc: 0.78
Batch: 740; loss: 0.49; acc: 0.81
Batch: 760; loss: 0.56; acc: 0.84
Batch: 780; loss: 0.6; acc: 0.81
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.5; acc: 0.81
Batch: 20; loss: 0.68; acc: 0.78
Batch: 40; loss: 0.3; acc: 0.92
Batch: 60; loss: 0.68; acc: 0.78
Batch: 80; loss: 0.53; acc: 0.83
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 1.0; acc: 0.7
Batch: 140; loss: 0.27; acc: 0.89
Val Epoch over. val_loss: 0.5225372048699932; val_accuracy: 0.8263335987261147 

The current subspace-distance is: 8.290010737255216e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.6; acc: 0.77
Batch: 20; loss: 0.88; acc: 0.8
Batch: 40; loss: 0.48; acc: 0.83
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.55; acc: 0.8
Batch: 100; loss: 0.54; acc: 0.88
Batch: 120; loss: 0.51; acc: 0.8
Batch: 140; loss: 0.37; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.34; acc: 0.92
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.68; acc: 0.77
Batch: 280; loss: 0.43; acc: 0.83
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.58; acc: 0.81
Batch: 340; loss: 0.58; acc: 0.81
Batch: 360; loss: 0.66; acc: 0.78
Batch: 380; loss: 0.57; acc: 0.86
Batch: 400; loss: 0.57; acc: 0.81
Batch: 420; loss: 0.47; acc: 0.84
Batch: 440; loss: 0.53; acc: 0.84
Batch: 460; loss: 0.53; acc: 0.83
Batch: 480; loss: 0.44; acc: 0.91
Batch: 500; loss: 0.63; acc: 0.83
Batch: 520; loss: 0.51; acc: 0.86
Batch: 540; loss: 0.56; acc: 0.8
Batch: 560; loss: 0.45; acc: 0.84
Batch: 580; loss: 0.65; acc: 0.77
Batch: 600; loss: 0.51; acc: 0.83
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.72; acc: 0.78
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.47; acc: 0.81
Batch: 700; loss: 0.57; acc: 0.81
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.83
Batch: 760; loss: 0.48; acc: 0.81
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.83
Batch: 80; loss: 0.47; acc: 0.86
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.25; acc: 0.89
Val Epoch over. val_loss: 0.48085859977895284; val_accuracy: 0.8462380573248408 

The current subspace-distance is: 8.577563130529597e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.73; acc: 0.77
Batch: 40; loss: 0.65; acc: 0.77
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.4; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.81
Batch: 140; loss: 0.39; acc: 0.89
Batch: 160; loss: 0.65; acc: 0.75
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.44; acc: 0.84
Batch: 220; loss: 0.65; acc: 0.75
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.39; acc: 0.89
Batch: 280; loss: 0.58; acc: 0.8
Batch: 300; loss: 0.43; acc: 0.88
Batch: 320; loss: 0.55; acc: 0.86
Batch: 340; loss: 0.44; acc: 0.86
Batch: 360; loss: 0.33; acc: 0.89
Batch: 380; loss: 0.48; acc: 0.81
Batch: 400; loss: 0.65; acc: 0.8
Batch: 420; loss: 0.45; acc: 0.86
Batch: 440; loss: 0.64; acc: 0.78
Batch: 460; loss: 0.57; acc: 0.8
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.79; acc: 0.78
Batch: 520; loss: 0.58; acc: 0.86
Batch: 540; loss: 0.97; acc: 0.72
Batch: 560; loss: 0.62; acc: 0.86
Batch: 580; loss: 0.45; acc: 0.81
Batch: 600; loss: 0.7; acc: 0.77
Batch: 620; loss: 0.57; acc: 0.81
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.68; acc: 0.83
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.45; acc: 0.84
Batch: 720; loss: 0.59; acc: 0.8
Batch: 740; loss: 0.52; acc: 0.86
Batch: 760; loss: 0.51; acc: 0.81
Batch: 780; loss: 0.47; acc: 0.91
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.5; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.5; acc: 0.83
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.55; acc: 0.8
Batch: 120; loss: 0.63; acc: 0.81
Batch: 140; loss: 0.26; acc: 0.94
Val Epoch over. val_loss: 0.517707941116421; val_accuracy: 0.8303144904458599 

The current subspace-distance is: 8.957456884672865e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.88
Batch: 20; loss: 0.6; acc: 0.81
Batch: 40; loss: 0.66; acc: 0.8
Batch: 60; loss: 0.39; acc: 0.84
Batch: 80; loss: 0.56; acc: 0.86
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.52; acc: 0.84
Batch: 160; loss: 0.62; acc: 0.83
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.51; acc: 0.8
Batch: 220; loss: 0.68; acc: 0.8
Batch: 240; loss: 0.3; acc: 0.88
Batch: 260; loss: 0.6; acc: 0.83
Batch: 280; loss: 0.64; acc: 0.81
Batch: 300; loss: 0.4; acc: 0.89
Batch: 320; loss: 0.47; acc: 0.84
Batch: 340; loss: 0.69; acc: 0.78
Batch: 360; loss: 0.36; acc: 0.88
Batch: 380; loss: 0.39; acc: 0.84
Batch: 400; loss: 0.48; acc: 0.8
Batch: 420; loss: 0.69; acc: 0.75
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.5; acc: 0.84
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.72; acc: 0.72
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.71; acc: 0.8
Batch: 560; loss: 0.54; acc: 0.83
Batch: 580; loss: 0.56; acc: 0.8
Batch: 600; loss: 0.33; acc: 0.88
Batch: 620; loss: 0.77; acc: 0.8
Batch: 640; loss: 0.51; acc: 0.83
Batch: 660; loss: 0.3; acc: 0.92
Batch: 680; loss: 0.38; acc: 0.89
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.84
Batch: 740; loss: 0.59; acc: 0.78
Batch: 760; loss: 0.37; acc: 0.92
Batch: 780; loss: 0.73; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.54; acc: 0.83
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.53; acc: 0.91
Batch: 120; loss: 0.91; acc: 0.77
Batch: 140; loss: 0.29; acc: 0.88
Val Epoch over. val_loss: 0.5219559717899674; val_accuracy: 0.8382762738853503 

The current subspace-distance is: 9.297118231188506e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.42; acc: 0.88
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.83; acc: 0.8
Batch: 100; loss: 0.51; acc: 0.84
Batch: 120; loss: 0.62; acc: 0.81
Batch: 140; loss: 0.53; acc: 0.81
Batch: 160; loss: 0.4; acc: 0.86
Batch: 180; loss: 0.67; acc: 0.83
Batch: 200; loss: 0.45; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.54; acc: 0.83
Batch: 260; loss: 0.33; acc: 0.84
Batch: 280; loss: 0.87; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.58; acc: 0.84
Batch: 340; loss: 0.34; acc: 0.89
Batch: 360; loss: 0.49; acc: 0.78
Batch: 380; loss: 0.57; acc: 0.81
Batch: 400; loss: 0.81; acc: 0.77
Batch: 420; loss: 0.85; acc: 0.8
Batch: 440; loss: 0.44; acc: 0.8
Batch: 460; loss: 0.57; acc: 0.8
Batch: 480; loss: 0.53; acc: 0.83
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.48; acc: 0.88
Batch: 540; loss: 0.48; acc: 0.84
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.45; acc: 0.86
Batch: 600; loss: 0.5; acc: 0.83
Batch: 620; loss: 0.57; acc: 0.83
Batch: 640; loss: 0.43; acc: 0.81
Batch: 660; loss: 0.56; acc: 0.81
Batch: 680; loss: 0.66; acc: 0.83
Batch: 700; loss: 0.58; acc: 0.86
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.6; acc: 0.81
Batch: 760; loss: 0.58; acc: 0.83
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.72; acc: 0.78
Batch: 20; loss: 0.77; acc: 0.75
Batch: 40; loss: 0.52; acc: 0.81
Batch: 60; loss: 0.83; acc: 0.77
Batch: 80; loss: 0.67; acc: 0.77
Batch: 100; loss: 0.72; acc: 0.84
Batch: 120; loss: 0.98; acc: 0.66
Batch: 140; loss: 0.54; acc: 0.8
Val Epoch over. val_loss: 0.686089817031174; val_accuracy: 0.770203025477707 

The current subspace-distance is: 9.586987289367244e-05 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.68; acc: 0.77
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.83
Batch: 80; loss: 0.35; acc: 0.88
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.51; acc: 0.8
Batch: 140; loss: 0.43; acc: 0.86
Batch: 160; loss: 0.48; acc: 0.83
Batch: 180; loss: 0.77; acc: 0.8
Batch: 200; loss: 0.61; acc: 0.8
Batch: 220; loss: 0.83; acc: 0.77
Batch: 240; loss: 0.3; acc: 0.91
Batch: 260; loss: 0.31; acc: 0.92
Batch: 280; loss: 0.45; acc: 0.83
Batch: 300; loss: 0.5; acc: 0.8
Batch: 320; loss: 0.56; acc: 0.8
Batch: 340; loss: 0.48; acc: 0.86
Batch: 360; loss: 0.69; acc: 0.8
Batch: 380; loss: 0.36; acc: 0.92
Batch: 400; loss: 0.71; acc: 0.8
Batch: 420; loss: 0.57; acc: 0.8
Batch: 440; loss: 0.69; acc: 0.8
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.23; acc: 0.92
Batch: 500; loss: 0.87; acc: 0.75
Batch: 520; loss: 0.56; acc: 0.83
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.35; acc: 0.88
Batch: 580; loss: 0.68; acc: 0.75
Batch: 600; loss: 0.71; acc: 0.78
Batch: 620; loss: 0.52; acc: 0.88
Batch: 640; loss: 0.7; acc: 0.83
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.58; acc: 0.75
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.65; acc: 0.83
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.49; acc: 0.86
Batch: 780; loss: 0.52; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.61; acc: 0.8
Batch: 20; loss: 0.58; acc: 0.81
Batch: 40; loss: 0.39; acc: 0.86
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.46; acc: 0.84
Batch: 100; loss: 0.58; acc: 0.81
Batch: 120; loss: 0.82; acc: 0.73
Batch: 140; loss: 0.26; acc: 0.91
Val Epoch over. val_loss: 0.5854863487421327; val_accuracy: 0.8139928343949044 

The current subspace-distance is: 9.901493467623368e-05 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.54; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.91
Batch: 60; loss: 0.55; acc: 0.8
Batch: 80; loss: 0.69; acc: 0.8
Batch: 100; loss: 0.68; acc: 0.75
Batch: 120; loss: 0.66; acc: 0.78
Batch: 140; loss: 0.57; acc: 0.84
Batch: 160; loss: 0.6; acc: 0.84
Batch: 180; loss: 0.43; acc: 0.86
Batch: 200; loss: 0.51; acc: 0.83
Batch: 220; loss: 0.72; acc: 0.84
Batch: 240; loss: 0.47; acc: 0.84
Batch: 260; loss: 0.91; acc: 0.8
Batch: 280; loss: 0.51; acc: 0.86
Batch: 300; loss: 0.29; acc: 0.89
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.56; acc: 0.86
Batch: 360; loss: 0.55; acc: 0.86
Batch: 380; loss: 0.6; acc: 0.83
Batch: 400; loss: 0.47; acc: 0.88
Batch: 420; loss: 0.49; acc: 0.86
Batch: 440; loss: 0.61; acc: 0.81
Batch: 460; loss: 0.67; acc: 0.84
Batch: 480; loss: 0.67; acc: 0.73
Batch: 500; loss: 0.45; acc: 0.83
Batch: 520; loss: 0.69; acc: 0.8
Batch: 540; loss: 0.73; acc: 0.77
Batch: 560; loss: 0.41; acc: 0.88
Batch: 580; loss: 0.72; acc: 0.77
Batch: 600; loss: 0.35; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.47; acc: 0.86
Batch: 660; loss: 0.53; acc: 0.83
Batch: 680; loss: 0.79; acc: 0.81
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.58; acc: 0.81
Batch: 740; loss: 0.53; acc: 0.81
Batch: 760; loss: 0.87; acc: 0.81
Batch: 780; loss: 0.78; acc: 0.78
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.63; acc: 0.78
Batch: 20; loss: 0.87; acc: 0.67
Batch: 40; loss: 0.36; acc: 0.91
Batch: 60; loss: 0.65; acc: 0.8
Batch: 80; loss: 0.55; acc: 0.81
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 1.01; acc: 0.7
Batch: 140; loss: 0.41; acc: 0.88
Val Epoch over. val_loss: 0.6128448796500067; val_accuracy: 0.8019506369426752 

The current subspace-distance is: 0.00010214030771749094 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.86
Batch: 20; loss: 0.71; acc: 0.77
Batch: 40; loss: 0.5; acc: 0.8
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.69; acc: 0.77
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.48; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.86
Batch: 220; loss: 0.42; acc: 0.83
Batch: 240; loss: 0.53; acc: 0.84
Batch: 260; loss: 0.38; acc: 0.84
Batch: 280; loss: 0.56; acc: 0.81
Batch: 300; loss: 0.65; acc: 0.81
Batch: 320; loss: 0.76; acc: 0.8
Batch: 340; loss: 0.55; acc: 0.84
Batch: 360; loss: 0.6; acc: 0.84
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.89
Batch: 420; loss: 0.43; acc: 0.86
Batch: 440; loss: 0.7; acc: 0.81
Batch: 460; loss: 0.42; acc: 0.88
Batch: 480; loss: 0.5; acc: 0.86
Batch: 500; loss: 0.45; acc: 0.91
Batch: 520; loss: 0.44; acc: 0.86
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.52; acc: 0.83
Batch: 580; loss: 0.66; acc: 0.78
Batch: 600; loss: 0.38; acc: 0.89
Batch: 620; loss: 0.55; acc: 0.86
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.59; acc: 0.83
Batch: 680; loss: 0.49; acc: 0.88
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.75; acc: 0.77
Batch: 740; loss: 0.45; acc: 0.81
Batch: 760; loss: 0.48; acc: 0.86
Batch: 780; loss: 0.55; acc: 0.83
Train Epoch over. train_loss: 0.52; train_accuracy: 0.84 

Batch: 0; loss: 0.74; acc: 0.73
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.35; acc: 0.91
Batch: 60; loss: 0.48; acc: 0.89
Batch: 80; loss: 0.45; acc: 0.8
Batch: 100; loss: 0.57; acc: 0.8
Batch: 120; loss: 0.97; acc: 0.75
Batch: 140; loss: 0.26; acc: 0.89
Val Epoch over. val_loss: 0.5739221371662845; val_accuracy: 0.8144904458598726 

The current subspace-distance is: 0.00010514704626984894 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.88
Batch: 20; loss: 0.5; acc: 0.86
Batch: 40; loss: 0.59; acc: 0.8
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.4; acc: 0.86
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.88
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.45; acc: 0.84
Batch: 200; loss: 0.54; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.47; acc: 0.8
Batch: 260; loss: 0.56; acc: 0.83
Batch: 280; loss: 0.62; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.95
Batch: 320; loss: 0.55; acc: 0.86
Batch: 340; loss: 0.47; acc: 0.83
Batch: 360; loss: 0.35; acc: 0.88
Batch: 380; loss: 0.53; acc: 0.83
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.66; acc: 0.8
Batch: 440; loss: 0.63; acc: 0.75
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.33; acc: 0.91
Batch: 500; loss: 0.48; acc: 0.83
Batch: 520; loss: 0.53; acc: 0.88
Batch: 540; loss: 0.6; acc: 0.81
Batch: 560; loss: 0.51; acc: 0.84
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.86; acc: 0.78
Batch: 620; loss: 0.38; acc: 0.89
Batch: 640; loss: 0.61; acc: 0.83
Batch: 660; loss: 0.77; acc: 0.77
Batch: 680; loss: 0.61; acc: 0.86
Batch: 700; loss: 0.57; acc: 0.81
Batch: 720; loss: 0.62; acc: 0.81
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.43; acc: 0.83
Batch: 20; loss: 0.64; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.53; acc: 0.83
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.89; acc: 0.73
Batch: 140; loss: 0.22; acc: 0.91
Val Epoch over. val_loss: 0.4705388055295701; val_accuracy: 0.851015127388535 

The current subspace-distance is: 0.00010787187056848779 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.73; acc: 0.78
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.37; acc: 0.83
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.55; acc: 0.83
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.56; acc: 0.83
Batch: 180; loss: 0.43; acc: 0.89
Batch: 200; loss: 0.53; acc: 0.8
Batch: 220; loss: 0.66; acc: 0.75
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.52; acc: 0.84
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.45; acc: 0.84
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.8; acc: 0.8
Batch: 360; loss: 0.76; acc: 0.81
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.58; acc: 0.84
Batch: 420; loss: 0.43; acc: 0.83
Batch: 440; loss: 0.33; acc: 0.88
Batch: 460; loss: 0.36; acc: 0.86
Batch: 480; loss: 0.62; acc: 0.8
Batch: 500; loss: 0.5; acc: 0.89
Batch: 520; loss: 0.32; acc: 0.89
Batch: 540; loss: 0.66; acc: 0.8
Batch: 560; loss: 0.7; acc: 0.83
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.39; acc: 0.88
Batch: 640; loss: 0.4; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.8
Batch: 680; loss: 0.47; acc: 0.88
Batch: 700; loss: 0.53; acc: 0.83
Batch: 720; loss: 0.43; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.8
Batch: 760; loss: 0.65; acc: 0.8
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.51; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.44; acc: 0.88
Batch: 120; loss: 0.86; acc: 0.77
Batch: 140; loss: 0.21; acc: 0.92
Val Epoch over. val_loss: 0.45294104877171243; val_accuracy: 0.8560907643312102 

The current subspace-distance is: 0.00011040723620681092 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.44; acc: 0.86
Batch: 60; loss: 0.52; acc: 0.8
Batch: 80; loss: 0.44; acc: 0.83
Batch: 100; loss: 0.42; acc: 0.89
Batch: 120; loss: 0.6; acc: 0.86
Batch: 140; loss: 0.67; acc: 0.78
Batch: 160; loss: 0.46; acc: 0.86
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.42; acc: 0.86
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.36; acc: 0.89
Batch: 260; loss: 0.64; acc: 0.83
Batch: 280; loss: 0.36; acc: 0.84
Batch: 300; loss: 0.53; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.89
Batch: 340; loss: 0.26; acc: 0.94
Batch: 360; loss: 0.66; acc: 0.83
Batch: 380; loss: 0.56; acc: 0.78
Batch: 400; loss: 0.48; acc: 0.8
Batch: 420; loss: 0.43; acc: 0.84
Batch: 440; loss: 0.42; acc: 0.84
Batch: 460; loss: 0.59; acc: 0.81
Batch: 480; loss: 0.35; acc: 0.86
Batch: 500; loss: 0.27; acc: 0.94
Batch: 520; loss: 0.52; acc: 0.8
Batch: 540; loss: 0.42; acc: 0.84
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.64; acc: 0.81
Batch: 600; loss: 0.5; acc: 0.84
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.67; acc: 0.83
Batch: 660; loss: 0.43; acc: 0.84
Batch: 680; loss: 0.33; acc: 0.86
Batch: 700; loss: 0.4; acc: 0.83
Batch: 720; loss: 0.46; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.94
Batch: 780; loss: 0.7; acc: 0.86
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.48; acc: 0.81
Batch: 20; loss: 0.59; acc: 0.8
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.45; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.76; acc: 0.75
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.44782565576825173; val_accuracy: 0.8579816878980892 

The current subspace-distance is: 0.00011226264905417338 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.52; acc: 0.81
Batch: 20; loss: 0.33; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.58; acc: 0.78
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.44; acc: 0.89
Batch: 140; loss: 0.51; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.89
Batch: 180; loss: 0.72; acc: 0.8
Batch: 200; loss: 0.59; acc: 0.77
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.42; acc: 0.86
Batch: 260; loss: 0.35; acc: 0.91
Batch: 280; loss: 0.46; acc: 0.89
Batch: 300; loss: 0.46; acc: 0.81
Batch: 320; loss: 0.63; acc: 0.88
Batch: 340; loss: 0.65; acc: 0.88
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.39; acc: 0.91
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.84; acc: 0.72
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.86
Batch: 500; loss: 0.29; acc: 0.94
Batch: 520; loss: 0.67; acc: 0.83
Batch: 540; loss: 0.51; acc: 0.81
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.36; acc: 0.91
Batch: 600; loss: 0.31; acc: 0.88
Batch: 620; loss: 0.49; acc: 0.88
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.91; acc: 0.8
Batch: 680; loss: 0.44; acc: 0.89
Batch: 700; loss: 0.65; acc: 0.81
Batch: 720; loss: 0.61; acc: 0.81
Batch: 740; loss: 0.71; acc: 0.8
Batch: 760; loss: 0.39; acc: 0.89
Batch: 780; loss: 0.59; acc: 0.81
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.88
Batch: 20; loss: 0.65; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.47; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.46; acc: 0.89
Batch: 120; loss: 0.84; acc: 0.73
Batch: 140; loss: 0.24; acc: 0.92
Val Epoch over. val_loss: 0.46151269099135306; val_accuracy: 0.8563893312101911 

The current subspace-distance is: 0.00011466395517345518 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.67; acc: 0.77
Batch: 20; loss: 0.54; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.81
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.36; acc: 0.84
Batch: 100; loss: 0.61; acc: 0.86
Batch: 120; loss: 0.8; acc: 0.78
Batch: 140; loss: 0.34; acc: 0.86
Batch: 160; loss: 0.4; acc: 0.88
Batch: 180; loss: 0.62; acc: 0.88
Batch: 200; loss: 0.49; acc: 0.88
Batch: 220; loss: 0.55; acc: 0.84
Batch: 240; loss: 0.42; acc: 0.89
Batch: 260; loss: 0.39; acc: 0.88
Batch: 280; loss: 0.47; acc: 0.88
Batch: 300; loss: 0.49; acc: 0.84
Batch: 320; loss: 0.34; acc: 0.88
Batch: 340; loss: 0.41; acc: 0.84
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.53; acc: 0.86
Batch: 400; loss: 0.58; acc: 0.81
Batch: 420; loss: 0.3; acc: 0.91
Batch: 440; loss: 0.62; acc: 0.83
Batch: 460; loss: 0.47; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.51; acc: 0.89
Batch: 520; loss: 0.54; acc: 0.81
Batch: 540; loss: 0.61; acc: 0.84
Batch: 560; loss: 0.65; acc: 0.83
Batch: 580; loss: 0.39; acc: 0.91
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.86; acc: 0.8
Batch: 660; loss: 0.55; acc: 0.81
Batch: 680; loss: 0.47; acc: 0.91
Batch: 700; loss: 0.45; acc: 0.81
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.32; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.42; acc: 0.89
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.5; acc: 0.83
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.75
Batch: 140; loss: 0.19; acc: 0.92
Val Epoch over. val_loss: 0.45083462565567844; val_accuracy: 0.8567874203821656 

The current subspace-distance is: 0.00011715803702827543 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.48; acc: 0.81
Batch: 40; loss: 0.31; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.86
Batch: 80; loss: 0.57; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.89
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.54; acc: 0.83
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.44; acc: 0.86
Batch: 280; loss: 0.56; acc: 0.81
Batch: 300; loss: 0.58; acc: 0.81
Batch: 320; loss: 0.38; acc: 0.88
Batch: 340; loss: 0.44; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.91
Batch: 380; loss: 0.6; acc: 0.84
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.78; acc: 0.8
Batch: 460; loss: 0.42; acc: 0.89
Batch: 480; loss: 0.46; acc: 0.81
Batch: 500; loss: 0.36; acc: 0.84
Batch: 520; loss: 0.61; acc: 0.77
Batch: 540; loss: 0.42; acc: 0.91
Batch: 560; loss: 0.44; acc: 0.83
Batch: 580; loss: 0.34; acc: 0.89
Batch: 600; loss: 0.67; acc: 0.75
Batch: 620; loss: 0.65; acc: 0.81
Batch: 640; loss: 0.7; acc: 0.78
Batch: 660; loss: 0.61; acc: 0.83
Batch: 680; loss: 0.37; acc: 0.89
Batch: 700; loss: 0.61; acc: 0.81
Batch: 720; loss: 0.46; acc: 0.8
Batch: 740; loss: 0.72; acc: 0.78
Batch: 760; loss: 0.62; acc: 0.75
Batch: 780; loss: 0.55; acc: 0.84
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.42; acc: 0.89
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.52; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.86
Batch: 100; loss: 0.48; acc: 0.91
Batch: 120; loss: 0.85; acc: 0.72
Batch: 140; loss: 0.21; acc: 0.92
Val Epoch over. val_loss: 0.4582246408625773; val_accuracy: 0.8546974522292994 

The current subspace-distance is: 0.00012053650425514206 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.91
Batch: 20; loss: 0.32; acc: 0.86
Batch: 40; loss: 0.63; acc: 0.83
Batch: 60; loss: 0.7; acc: 0.78
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.76; acc: 0.78
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.57; acc: 0.77
Batch: 160; loss: 0.48; acc: 0.86
Batch: 180; loss: 0.39; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.88
Batch: 220; loss: 0.56; acc: 0.83
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.54; acc: 0.8
Batch: 280; loss: 0.49; acc: 0.89
Batch: 300; loss: 0.54; acc: 0.81
Batch: 320; loss: 0.54; acc: 0.89
Batch: 340; loss: 0.59; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.75; acc: 0.75
Batch: 400; loss: 0.42; acc: 0.86
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.53; acc: 0.88
Batch: 500; loss: 0.59; acc: 0.83
Batch: 520; loss: 0.44; acc: 0.91
Batch: 540; loss: 0.55; acc: 0.84
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.51; acc: 0.84
Batch: 600; loss: 0.47; acc: 0.86
Batch: 620; loss: 0.56; acc: 0.88
Batch: 640; loss: 0.64; acc: 0.77
Batch: 660; loss: 0.52; acc: 0.84
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.24; acc: 0.94
Batch: 720; loss: 0.44; acc: 0.86
Batch: 740; loss: 0.7; acc: 0.8
Batch: 760; loss: 0.52; acc: 0.88
Batch: 780; loss: 0.54; acc: 0.86
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.7; acc: 0.77
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.4; acc: 0.84
Batch: 100; loss: 0.53; acc: 0.89
Batch: 120; loss: 0.97; acc: 0.72
Batch: 140; loss: 0.25; acc: 0.94
Val Epoch over. val_loss: 0.48988939669861153; val_accuracy: 0.8443471337579618 

The current subspace-distance is: 0.00012383365537971258 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.6; acc: 0.83
Batch: 20; loss: 0.59; acc: 0.86
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.75; acc: 0.8
Batch: 80; loss: 0.46; acc: 0.88
Batch: 100; loss: 0.37; acc: 0.84
Batch: 120; loss: 0.58; acc: 0.83
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.48; acc: 0.81
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.46; acc: 0.89
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.45; acc: 0.89
Batch: 260; loss: 0.51; acc: 0.92
Batch: 280; loss: 0.37; acc: 0.88
Batch: 300; loss: 0.4; acc: 0.84
Batch: 320; loss: 0.55; acc: 0.86
Batch: 340; loss: 0.46; acc: 0.86
Batch: 360; loss: 0.63; acc: 0.81
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.65; acc: 0.81
Batch: 420; loss: 0.59; acc: 0.83
Batch: 440; loss: 0.55; acc: 0.81
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.89
Batch: 500; loss: 0.35; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.47; acc: 0.88
Batch: 560; loss: 0.41; acc: 0.89
Batch: 580; loss: 0.49; acc: 0.89
Batch: 600; loss: 0.75; acc: 0.81
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.48; acc: 0.8
Batch: 660; loss: 0.58; acc: 0.83
Batch: 680; loss: 0.59; acc: 0.83
Batch: 700; loss: 0.63; acc: 0.81
Batch: 720; loss: 0.52; acc: 0.88
Batch: 740; loss: 0.62; acc: 0.75
Batch: 760; loss: 0.52; acc: 0.89
Batch: 780; loss: 0.39; acc: 0.88
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.63; acc: 0.8
Batch: 40; loss: 0.3; acc: 0.88
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.35; acc: 0.84
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.73
Batch: 140; loss: 0.23; acc: 0.92
Val Epoch over. val_loss: 0.45522275078258695; val_accuracy: 0.8567874203821656 

The current subspace-distance is: 0.00012539549788925797 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.59; acc: 0.81
Batch: 20; loss: 0.53; acc: 0.86
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.45; acc: 0.88
Batch: 120; loss: 0.43; acc: 0.91
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.62; acc: 0.8
Batch: 200; loss: 0.59; acc: 0.83
Batch: 220; loss: 0.24; acc: 0.95
Batch: 240; loss: 0.71; acc: 0.81
Batch: 260; loss: 0.46; acc: 0.91
Batch: 280; loss: 0.39; acc: 0.83
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.41; acc: 0.81
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.42; acc: 0.92
Batch: 380; loss: 0.42; acc: 0.89
Batch: 400; loss: 0.45; acc: 0.88
Batch: 420; loss: 0.57; acc: 0.8
Batch: 440; loss: 0.63; acc: 0.78
Batch: 460; loss: 0.69; acc: 0.77
Batch: 480; loss: 0.51; acc: 0.84
Batch: 500; loss: 0.36; acc: 0.91
Batch: 520; loss: 0.37; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.89
Batch: 560; loss: 0.54; acc: 0.77
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.43; acc: 0.83
Batch: 620; loss: 0.51; acc: 0.83
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.66; acc: 0.81
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.67; acc: 0.78
Batch: 720; loss: 0.54; acc: 0.84
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.58; acc: 0.81
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.57; acc: 0.83
Batch: 20; loss: 0.56; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.84
Batch: 120; loss: 0.66; acc: 0.83
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.46821658626483503; val_accuracy: 0.8542993630573248 

The current subspace-distance is: 0.00012857424735557288 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.53; acc: 0.86
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.42; acc: 0.86
Batch: 80; loss: 0.62; acc: 0.81
Batch: 100; loss: 0.34; acc: 0.89
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.47; acc: 0.86
Batch: 160; loss: 0.53; acc: 0.84
Batch: 180; loss: 0.58; acc: 0.84
Batch: 200; loss: 0.72; acc: 0.77
Batch: 220; loss: 0.57; acc: 0.86
Batch: 240; loss: 0.73; acc: 0.81
Batch: 260; loss: 0.4; acc: 0.88
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.4; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.89
Batch: 340; loss: 0.4; acc: 0.89
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.61; acc: 0.75
Batch: 400; loss: 0.55; acc: 0.83
Batch: 420; loss: 0.5; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.88
Batch: 460; loss: 0.35; acc: 0.89
Batch: 480; loss: 0.67; acc: 0.78
Batch: 500; loss: 0.42; acc: 0.83
Batch: 520; loss: 0.27; acc: 0.91
Batch: 540; loss: 0.54; acc: 0.86
Batch: 560; loss: 0.49; acc: 0.83
Batch: 580; loss: 0.3; acc: 0.88
Batch: 600; loss: 0.42; acc: 0.89
Batch: 620; loss: 0.56; acc: 0.81
Batch: 640; loss: 0.56; acc: 0.83
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.46; acc: 0.88
Batch: 700; loss: 0.74; acc: 0.83
Batch: 720; loss: 0.7; acc: 0.84
Batch: 740; loss: 0.58; acc: 0.86
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.52; acc: 0.84
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.89
Batch: 20; loss: 0.57; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.75; acc: 0.75
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.43720936836900226; val_accuracy: 0.8630573248407644 

The current subspace-distance is: 0.0001315151312155649 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.98
Batch: 20; loss: 0.44; acc: 0.86
Batch: 40; loss: 0.63; acc: 0.81
Batch: 60; loss: 0.64; acc: 0.8
Batch: 80; loss: 0.71; acc: 0.78
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.58; acc: 0.8
Batch: 140; loss: 0.58; acc: 0.81
Batch: 160; loss: 0.63; acc: 0.83
Batch: 180; loss: 0.29; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.84
Batch: 220; loss: 0.37; acc: 0.91
Batch: 240; loss: 0.66; acc: 0.8
Batch: 260; loss: 0.43; acc: 0.81
Batch: 280; loss: 0.71; acc: 0.77
Batch: 300; loss: 0.87; acc: 0.78
Batch: 320; loss: 0.45; acc: 0.86
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.62; acc: 0.78
Batch: 380; loss: 0.45; acc: 0.84
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.41; acc: 0.91
Batch: 440; loss: 0.66; acc: 0.73
Batch: 460; loss: 0.4; acc: 0.84
Batch: 480; loss: 0.47; acc: 0.81
Batch: 500; loss: 0.35; acc: 0.88
Batch: 520; loss: 0.42; acc: 0.84
Batch: 540; loss: 0.62; acc: 0.8
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.59; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.84
Batch: 640; loss: 0.57; acc: 0.81
Batch: 660; loss: 0.47; acc: 0.88
Batch: 680; loss: 0.56; acc: 0.81
Batch: 700; loss: 0.23; acc: 0.94
Batch: 720; loss: 0.38; acc: 0.89
Batch: 740; loss: 0.41; acc: 0.86
Batch: 760; loss: 0.43; acc: 0.83
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.47; acc: 0.91
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.88
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.72
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.43282090763377534; val_accuracy: 0.8645501592356688 

The current subspace-distance is: 0.00013461832713801414 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.69; acc: 0.84
Batch: 40; loss: 0.73; acc: 0.77
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.47; acc: 0.86
Batch: 140; loss: 0.73; acc: 0.78
Batch: 160; loss: 0.47; acc: 0.81
Batch: 180; loss: 0.61; acc: 0.75
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.51; acc: 0.83
Batch: 240; loss: 0.44; acc: 0.83
Batch: 260; loss: 0.42; acc: 0.91
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.46; acc: 0.86
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.52; acc: 0.84
Batch: 360; loss: 0.37; acc: 0.86
Batch: 380; loss: 0.44; acc: 0.81
Batch: 400; loss: 0.45; acc: 0.84
Batch: 420; loss: 0.4; acc: 0.92
Batch: 440; loss: 0.45; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.67; acc: 0.75
Batch: 520; loss: 0.43; acc: 0.88
Batch: 540; loss: 0.53; acc: 0.86
Batch: 560; loss: 0.31; acc: 0.92
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.59; acc: 0.8
Batch: 620; loss: 0.47; acc: 0.83
Batch: 640; loss: 0.46; acc: 0.86
Batch: 660; loss: 0.67; acc: 0.84
Batch: 680; loss: 0.47; acc: 0.84
Batch: 700; loss: 0.71; acc: 0.83
Batch: 720; loss: 0.53; acc: 0.83
Batch: 740; loss: 0.37; acc: 0.84
Batch: 760; loss: 0.35; acc: 0.94
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.46; acc: 0.89
Batch: 20; loss: 0.56; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4332639493854942; val_accuracy: 0.863953025477707 

The current subspace-distance is: 0.00013686277088709176 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.86
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.62; acc: 0.78
Batch: 60; loss: 0.3; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.83
Batch: 100; loss: 0.62; acc: 0.84
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.64; acc: 0.81
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.41; acc: 0.88
Batch: 220; loss: 0.58; acc: 0.84
Batch: 240; loss: 0.53; acc: 0.84
Batch: 260; loss: 0.45; acc: 0.81
Batch: 280; loss: 0.3; acc: 0.88
Batch: 300; loss: 0.37; acc: 0.84
Batch: 320; loss: 0.55; acc: 0.77
Batch: 340; loss: 0.37; acc: 0.91
Batch: 360; loss: 0.42; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.85; acc: 0.73
Batch: 420; loss: 0.45; acc: 0.83
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.31; acc: 0.89
Batch: 520; loss: 0.79; acc: 0.78
Batch: 540; loss: 0.62; acc: 0.83
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.48; acc: 0.83
Batch: 600; loss: 0.41; acc: 0.91
Batch: 620; loss: 0.57; acc: 0.8
Batch: 640; loss: 0.39; acc: 0.84
Batch: 660; loss: 0.37; acc: 0.88
Batch: 680; loss: 0.63; acc: 0.75
Batch: 700; loss: 0.41; acc: 0.88
Batch: 720; loss: 0.36; acc: 0.88
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.51; acc: 0.83
Batch: 780; loss: 0.64; acc: 0.83
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.3; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.43207749729133715; val_accuracy: 0.8656449044585988 

The current subspace-distance is: 0.00013934400340076536 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.54; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.59; acc: 0.83
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.43; acc: 0.84
Batch: 140; loss: 0.41; acc: 0.89
Batch: 160; loss: 0.4; acc: 0.84
Batch: 180; loss: 0.42; acc: 0.86
Batch: 200; loss: 0.56; acc: 0.81
Batch: 220; loss: 0.4; acc: 0.89
Batch: 240; loss: 0.6; acc: 0.84
Batch: 260; loss: 0.7; acc: 0.83
Batch: 280; loss: 0.34; acc: 0.92
Batch: 300; loss: 0.6; acc: 0.86
Batch: 320; loss: 0.44; acc: 0.83
Batch: 340; loss: 0.75; acc: 0.8
Batch: 360; loss: 0.45; acc: 0.91
Batch: 380; loss: 0.45; acc: 0.88
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.32; acc: 0.88
Batch: 440; loss: 0.58; acc: 0.81
Batch: 460; loss: 0.51; acc: 0.81
Batch: 480; loss: 0.55; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.86
Batch: 520; loss: 0.53; acc: 0.86
Batch: 540; loss: 0.37; acc: 0.89
Batch: 560; loss: 0.26; acc: 0.92
Batch: 580; loss: 0.37; acc: 0.91
Batch: 600; loss: 0.55; acc: 0.84
Batch: 620; loss: 0.44; acc: 0.84
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.42; acc: 0.8
Batch: 680; loss: 0.53; acc: 0.84
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.51; acc: 0.81
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.45; acc: 0.86
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.44; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.44; acc: 0.86
Batch: 120; loss: 0.77; acc: 0.75
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.44049507389023046; val_accuracy: 0.8626592356687898 

The current subspace-distance is: 0.00014263174671214074 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.79; acc: 0.77
Batch: 80; loss: 0.5; acc: 0.86
Batch: 100; loss: 0.53; acc: 0.83
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.52; acc: 0.83
Batch: 160; loss: 0.49; acc: 0.84
Batch: 180; loss: 0.48; acc: 0.83
Batch: 200; loss: 0.54; acc: 0.78
Batch: 220; loss: 0.7; acc: 0.78
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.32; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.65; acc: 0.77
Batch: 320; loss: 0.63; acc: 0.8
Batch: 340; loss: 0.49; acc: 0.89
Batch: 360; loss: 0.65; acc: 0.83
Batch: 380; loss: 0.38; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.94
Batch: 420; loss: 0.68; acc: 0.81
Batch: 440; loss: 0.56; acc: 0.78
Batch: 460; loss: 0.58; acc: 0.8
Batch: 480; loss: 0.58; acc: 0.81
Batch: 500; loss: 0.43; acc: 0.84
Batch: 520; loss: 0.71; acc: 0.84
Batch: 540; loss: 0.51; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.84
Batch: 580; loss: 0.7; acc: 0.78
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.55; acc: 0.84
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.46; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.88
Batch: 700; loss: 0.46; acc: 0.84
Batch: 720; loss: 0.68; acc: 0.81
Batch: 740; loss: 0.52; acc: 0.83
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.51; acc: 0.81
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.61; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.86
Batch: 80; loss: 0.3; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.44019794027516795; val_accuracy: 0.8647492038216561 

The current subspace-distance is: 0.00014579255366697907 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.56; acc: 0.78
Batch: 20; loss: 0.6; acc: 0.77
Batch: 40; loss: 0.36; acc: 0.92
Batch: 60; loss: 0.39; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.69; acc: 0.78
Batch: 120; loss: 0.72; acc: 0.84
Batch: 140; loss: 0.58; acc: 0.84
Batch: 160; loss: 0.49; acc: 0.83
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.62; acc: 0.78
Batch: 220; loss: 0.2; acc: 0.94
Batch: 240; loss: 0.49; acc: 0.88
Batch: 260; loss: 0.45; acc: 0.86
Batch: 280; loss: 0.43; acc: 0.89
Batch: 300; loss: 0.61; acc: 0.84
Batch: 320; loss: 0.43; acc: 0.89
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.45; acc: 0.86
Batch: 400; loss: 0.49; acc: 0.86
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.56; acc: 0.88
Batch: 460; loss: 0.47; acc: 0.81
Batch: 480; loss: 0.47; acc: 0.89
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.8; acc: 0.81
Batch: 540; loss: 0.33; acc: 0.95
Batch: 560; loss: 0.47; acc: 0.83
Batch: 580; loss: 0.63; acc: 0.8
Batch: 600; loss: 0.89; acc: 0.75
Batch: 620; loss: 0.39; acc: 0.91
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.55; acc: 0.77
Batch: 680; loss: 0.49; acc: 0.86
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.68; acc: 0.75
Batch: 740; loss: 0.33; acc: 0.91
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.89
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.48; acc: 0.89
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.88
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.43523832040417726; val_accuracy: 0.8644506369426752 

The current subspace-distance is: 0.00014798787015024573 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.57; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.4; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.4; acc: 0.86
Batch: 160; loss: 0.38; acc: 0.89
Batch: 180; loss: 0.39; acc: 0.84
Batch: 200; loss: 0.5; acc: 0.86
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.59; acc: 0.78
Batch: 280; loss: 0.38; acc: 0.86
Batch: 300; loss: 0.4; acc: 0.88
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.57; acc: 0.83
Batch: 360; loss: 0.6; acc: 0.83
Batch: 380; loss: 0.54; acc: 0.88
Batch: 400; loss: 0.53; acc: 0.86
Batch: 420; loss: 0.62; acc: 0.78
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.47; acc: 0.86
Batch: 480; loss: 0.53; acc: 0.84
Batch: 500; loss: 0.35; acc: 0.91
Batch: 520; loss: 0.55; acc: 0.8
Batch: 540; loss: 0.5; acc: 0.86
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.6; acc: 0.8
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.47; acc: 0.86
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.65; acc: 0.86
Batch: 680; loss: 0.39; acc: 0.84
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.45; acc: 0.86
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.6; acc: 0.84
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.44; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.86
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.97
Val Epoch over. val_loss: 0.43485773914748693; val_accuracy: 0.8632563694267515 

The current subspace-distance is: 0.00015177081513684243 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.45; acc: 0.86
Batch: 20; loss: 0.65; acc: 0.86
Batch: 40; loss: 0.49; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.56; acc: 0.81
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.31; acc: 0.89
Batch: 160; loss: 0.58; acc: 0.86
Batch: 180; loss: 0.28; acc: 0.92
Batch: 200; loss: 0.52; acc: 0.86
Batch: 220; loss: 0.5; acc: 0.88
Batch: 240; loss: 0.46; acc: 0.86
Batch: 260; loss: 0.68; acc: 0.84
Batch: 280; loss: 0.46; acc: 0.84
Batch: 300; loss: 0.79; acc: 0.75
Batch: 320; loss: 0.42; acc: 0.86
Batch: 340; loss: 0.42; acc: 0.88
Batch: 360; loss: 0.38; acc: 0.89
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.92
Batch: 420; loss: 0.37; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.83
Batch: 480; loss: 0.46; acc: 0.84
Batch: 500; loss: 0.6; acc: 0.77
Batch: 520; loss: 0.49; acc: 0.83
Batch: 540; loss: 0.4; acc: 0.89
Batch: 560; loss: 0.5; acc: 0.86
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.39; acc: 0.84
Batch: 620; loss: 0.78; acc: 0.8
Batch: 640; loss: 0.56; acc: 0.88
Batch: 660; loss: 0.66; acc: 0.83
Batch: 680; loss: 0.44; acc: 0.86
Batch: 700; loss: 0.71; acc: 0.84
Batch: 720; loss: 0.59; acc: 0.84
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.58; acc: 0.83
Batch: 780; loss: 0.53; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.91
Batch: 80; loss: 0.29; acc: 0.91
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.68; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4370154315119336; val_accuracy: 0.8640525477707006 

The current subspace-distance is: 0.00015375683142337948 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.49; acc: 0.86
Batch: 20; loss: 0.64; acc: 0.89
Batch: 40; loss: 0.53; acc: 0.8
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.79; acc: 0.78
Batch: 100; loss: 0.46; acc: 0.83
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.42; acc: 0.88
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.45; acc: 0.81
Batch: 200; loss: 0.51; acc: 0.88
Batch: 220; loss: 0.46; acc: 0.88
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.56; acc: 0.86
Batch: 280; loss: 0.66; acc: 0.81
Batch: 300; loss: 0.39; acc: 0.92
Batch: 320; loss: 0.42; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.45; acc: 0.86
Batch: 380; loss: 0.39; acc: 0.88
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.29; acc: 0.89
Batch: 440; loss: 0.47; acc: 0.88
Batch: 460; loss: 0.72; acc: 0.8
Batch: 480; loss: 0.37; acc: 0.89
Batch: 500; loss: 0.63; acc: 0.8
Batch: 520; loss: 0.52; acc: 0.81
Batch: 540; loss: 0.5; acc: 0.88
Batch: 560; loss: 0.49; acc: 0.84
Batch: 580; loss: 0.35; acc: 0.88
Batch: 600; loss: 0.59; acc: 0.83
Batch: 620; loss: 0.4; acc: 0.89
Batch: 640; loss: 0.57; acc: 0.83
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.71; acc: 0.8
Batch: 700; loss: 0.32; acc: 0.91
Batch: 720; loss: 0.71; acc: 0.83
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.25; acc: 0.91
Batch: 780; loss: 0.3; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.45; acc: 0.89
Batch: 120; loss: 0.73; acc: 0.72
Batch: 140; loss: 0.18; acc: 0.94
Val Epoch over. val_loss: 0.43223078862117353; val_accuracy: 0.8637539808917197 

The current subspace-distance is: 0.0001557987416163087 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.34; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.86
Batch: 40; loss: 0.62; acc: 0.84
Batch: 60; loss: 0.57; acc: 0.83
Batch: 80; loss: 0.47; acc: 0.8
Batch: 100; loss: 0.33; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.55; acc: 0.84
Batch: 180; loss: 0.5; acc: 0.81
Batch: 200; loss: 0.7; acc: 0.75
Batch: 220; loss: 0.52; acc: 0.81
Batch: 240; loss: 0.34; acc: 0.88
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.44; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.59; acc: 0.77
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.51; acc: 0.84
Batch: 400; loss: 0.39; acc: 0.89
Batch: 420; loss: 0.7; acc: 0.81
Batch: 440; loss: 0.42; acc: 0.89
Batch: 460; loss: 0.75; acc: 0.78
Batch: 480; loss: 0.37; acc: 0.84
Batch: 500; loss: 0.53; acc: 0.81
Batch: 520; loss: 0.4; acc: 0.89
Batch: 540; loss: 0.52; acc: 0.8
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.88
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.89; acc: 0.73
Batch: 660; loss: 0.4; acc: 0.88
Batch: 680; loss: 0.36; acc: 0.84
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.43; acc: 0.83
Batch: 740; loss: 0.57; acc: 0.84
Batch: 760; loss: 0.52; acc: 0.88
Batch: 780; loss: 0.44; acc: 0.88
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.62; acc: 0.84
Batch: 40; loss: 0.3; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.88
Batch: 80; loss: 0.35; acc: 0.89
Batch: 100; loss: 0.47; acc: 0.88
Batch: 120; loss: 0.8; acc: 0.72
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4451159371691904; val_accuracy: 0.8584792993630573 

The current subspace-distance is: 0.00015823937428649515 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.78
Batch: 20; loss: 0.53; acc: 0.81
Batch: 40; loss: 0.57; acc: 0.8
Batch: 60; loss: 0.52; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.8
Batch: 100; loss: 0.53; acc: 0.81
Batch: 120; loss: 0.34; acc: 0.92
Batch: 140; loss: 0.4; acc: 0.92
Batch: 160; loss: 0.35; acc: 0.84
Batch: 180; loss: 0.49; acc: 0.83
Batch: 200; loss: 0.43; acc: 0.84
Batch: 220; loss: 0.48; acc: 0.83
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.64; acc: 0.8
Batch: 300; loss: 0.48; acc: 0.83
Batch: 320; loss: 0.57; acc: 0.83
Batch: 340; loss: 0.38; acc: 0.86
Batch: 360; loss: 0.38; acc: 0.88
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.39; acc: 0.86
Batch: 460; loss: 0.49; acc: 0.84
Batch: 480; loss: 0.81; acc: 0.75
Batch: 500; loss: 0.52; acc: 0.81
Batch: 520; loss: 0.72; acc: 0.81
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.48; acc: 0.84
Batch: 620; loss: 0.38; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.37; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.52; acc: 0.84
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.71; acc: 0.78
Batch: 780; loss: 0.46; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.48; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.89
Batch: 100; loss: 0.43; acc: 0.89
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.97
Val Epoch over. val_loss: 0.42976109360813336; val_accuracy: 0.865047770700637 

The current subspace-distance is: 0.0001605494471732527 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.49; acc: 0.89
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.44; acc: 0.86
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.63; acc: 0.8
Batch: 160; loss: 0.46; acc: 0.88
Batch: 180; loss: 0.42; acc: 0.89
Batch: 200; loss: 0.51; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.84
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.94
Batch: 280; loss: 0.51; acc: 0.81
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.57; acc: 0.84
Batch: 340; loss: 0.45; acc: 0.8
Batch: 360; loss: 0.33; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.48; acc: 0.81
Batch: 420; loss: 0.42; acc: 0.86
Batch: 440; loss: 0.55; acc: 0.83
Batch: 460; loss: 0.43; acc: 0.88
Batch: 480; loss: 0.69; acc: 0.8
Batch: 500; loss: 0.33; acc: 0.88
Batch: 520; loss: 0.36; acc: 0.91
Batch: 540; loss: 0.41; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.86
Batch: 580; loss: 0.32; acc: 0.88
Batch: 600; loss: 0.54; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.88
Batch: 640; loss: 0.97; acc: 0.8
Batch: 660; loss: 0.46; acc: 0.81
Batch: 680; loss: 0.39; acc: 0.84
Batch: 700; loss: 0.45; acc: 0.88
Batch: 720; loss: 0.37; acc: 0.88
Batch: 740; loss: 0.63; acc: 0.8
Batch: 760; loss: 0.4; acc: 0.91
Batch: 780; loss: 0.41; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.4298907563944531; val_accuracy: 0.8641520700636943 

The current subspace-distance is: 0.00016269154730252922 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.58; acc: 0.86
Batch: 20; loss: 0.68; acc: 0.81
Batch: 40; loss: 0.44; acc: 0.92
Batch: 60; loss: 0.41; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.92
Batch: 100; loss: 0.65; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.84
Batch: 160; loss: 0.39; acc: 0.91
Batch: 180; loss: 0.44; acc: 0.84
Batch: 200; loss: 0.43; acc: 0.91
Batch: 220; loss: 0.51; acc: 0.88
Batch: 240; loss: 0.37; acc: 0.89
Batch: 260; loss: 0.38; acc: 0.86
Batch: 280; loss: 0.53; acc: 0.83
Batch: 300; loss: 0.57; acc: 0.77
Batch: 320; loss: 0.46; acc: 0.92
Batch: 340; loss: 0.61; acc: 0.77
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.47; acc: 0.88
Batch: 400; loss: 0.32; acc: 0.92
Batch: 420; loss: 0.5; acc: 0.86
Batch: 440; loss: 0.45; acc: 0.86
Batch: 460; loss: 0.38; acc: 0.92
Batch: 480; loss: 0.7; acc: 0.83
Batch: 500; loss: 0.5; acc: 0.84
Batch: 520; loss: 0.38; acc: 0.88
Batch: 540; loss: 0.6; acc: 0.73
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.65; acc: 0.78
Batch: 600; loss: 0.75; acc: 0.78
Batch: 620; loss: 0.64; acc: 0.81
Batch: 640; loss: 0.63; acc: 0.73
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.27; acc: 0.89
Batch: 700; loss: 0.55; acc: 0.84
Batch: 720; loss: 0.51; acc: 0.78
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.43; acc: 0.88
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.32; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.4308758448263642; val_accuracy: 0.8629578025477707 

The current subspace-distance is: 0.00016491374117322266 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.25; acc: 0.94
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.47; acc: 0.86
Batch: 60; loss: 0.43; acc: 0.88
Batch: 80; loss: 0.6; acc: 0.8
Batch: 100; loss: 0.4; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.27; acc: 0.91
Batch: 160; loss: 0.54; acc: 0.84
Batch: 180; loss: 0.39; acc: 0.89
Batch: 200; loss: 0.61; acc: 0.86
Batch: 220; loss: 0.86; acc: 0.77
Batch: 240; loss: 0.29; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.8
Batch: 280; loss: 0.29; acc: 0.95
Batch: 300; loss: 0.6; acc: 0.8
Batch: 320; loss: 0.64; acc: 0.8
Batch: 340; loss: 0.74; acc: 0.81
Batch: 360; loss: 0.72; acc: 0.8
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.66; acc: 0.81
Batch: 420; loss: 0.57; acc: 0.83
Batch: 440; loss: 0.55; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.58; acc: 0.81
Batch: 500; loss: 0.33; acc: 0.89
Batch: 520; loss: 0.47; acc: 0.91
Batch: 540; loss: 0.46; acc: 0.86
Batch: 560; loss: 0.64; acc: 0.8
Batch: 580; loss: 0.65; acc: 0.77
Batch: 600; loss: 0.39; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.92
Batch: 640; loss: 0.45; acc: 0.8
Batch: 660; loss: 0.46; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.88
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.58; acc: 0.86
Batch: 740; loss: 0.45; acc: 0.83
Batch: 760; loss: 0.33; acc: 0.88
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.43; acc: 0.89
Batch: 80; loss: 0.31; acc: 0.89
Batch: 100; loss: 0.42; acc: 0.92
Batch: 120; loss: 0.77; acc: 0.73
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.4282458424093617; val_accuracy: 0.865843949044586 

The current subspace-distance is: 0.00016819329175632447 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.59; acc: 0.77
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.59; acc: 0.84
Batch: 60; loss: 0.35; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.86
Batch: 100; loss: 0.45; acc: 0.86
Batch: 120; loss: 0.37; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.86
Batch: 160; loss: 0.56; acc: 0.78
Batch: 180; loss: 0.83; acc: 0.73
Batch: 200; loss: 0.54; acc: 0.84
Batch: 220; loss: 0.37; acc: 0.86
Batch: 240; loss: 0.64; acc: 0.84
Batch: 260; loss: 0.55; acc: 0.86
Batch: 280; loss: 0.45; acc: 0.88
Batch: 300; loss: 0.53; acc: 0.86
Batch: 320; loss: 0.49; acc: 0.81
Batch: 340; loss: 0.71; acc: 0.75
Batch: 360; loss: 0.42; acc: 0.91
Batch: 380; loss: 0.47; acc: 0.84
Batch: 400; loss: 0.46; acc: 0.83
Batch: 420; loss: 0.46; acc: 0.88
Batch: 440; loss: 0.74; acc: 0.78
Batch: 460; loss: 0.49; acc: 0.89
Batch: 480; loss: 0.51; acc: 0.77
Batch: 500; loss: 0.38; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.49; acc: 0.86
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.37; acc: 0.88
Batch: 600; loss: 0.51; acc: 0.86
Batch: 620; loss: 0.49; acc: 0.86
Batch: 640; loss: 0.65; acc: 0.81
Batch: 660; loss: 0.67; acc: 0.83
Batch: 680; loss: 0.33; acc: 0.91
Batch: 700; loss: 0.51; acc: 0.83
Batch: 720; loss: 0.45; acc: 0.81
Batch: 740; loss: 0.58; acc: 0.81
Batch: 760; loss: 0.34; acc: 0.91
Batch: 780; loss: 0.63; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.44; acc: 0.84
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.89
Batch: 80; loss: 0.32; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.73
Batch: 140; loss: 0.18; acc: 0.92
Val Epoch over. val_loss: 0.4347425409752852; val_accuracy: 0.861265923566879 

The current subspace-distance is: 0.00017034527263604105 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.66; acc: 0.81
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.52; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.28; acc: 0.94
Batch: 100; loss: 0.65; acc: 0.8
Batch: 120; loss: 0.65; acc: 0.81
Batch: 140; loss: 0.34; acc: 0.88
Batch: 160; loss: 0.4; acc: 0.89
Batch: 180; loss: 0.53; acc: 0.81
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.92
Batch: 240; loss: 0.33; acc: 0.91
Batch: 260; loss: 0.7; acc: 0.8
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.51; acc: 0.88
Batch: 320; loss: 0.68; acc: 0.77
Batch: 340; loss: 0.49; acc: 0.83
Batch: 360; loss: 0.44; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.83
Batch: 400; loss: 0.68; acc: 0.88
Batch: 420; loss: 0.41; acc: 0.84
Batch: 440; loss: 0.38; acc: 0.88
Batch: 460; loss: 0.41; acc: 0.89
Batch: 480; loss: 0.6; acc: 0.83
Batch: 500; loss: 0.48; acc: 0.91
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.56; acc: 0.78
Batch: 560; loss: 0.59; acc: 0.8
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.52; acc: 0.83
Batch: 620; loss: 0.44; acc: 0.86
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.46; acc: 0.84
Batch: 680; loss: 0.42; acc: 0.83
Batch: 700; loss: 0.43; acc: 0.86
Batch: 720; loss: 0.51; acc: 0.86
Batch: 740; loss: 0.51; acc: 0.89
Batch: 760; loss: 0.54; acc: 0.8
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.74; acc: 0.75
Batch: 140; loss: 0.16; acc: 0.95
Val Epoch over. val_loss: 0.42756146932863126; val_accuracy: 0.865843949044586 

The current subspace-distance is: 0.0001723856112221256 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.37; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.81
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.46; acc: 0.89
Batch: 80; loss: 0.58; acc: 0.84
Batch: 100; loss: 0.53; acc: 0.88
Batch: 120; loss: 0.73; acc: 0.78
Batch: 140; loss: 0.57; acc: 0.81
Batch: 160; loss: 0.66; acc: 0.75
Batch: 180; loss: 0.5; acc: 0.83
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.53; acc: 0.86
Batch: 240; loss: 0.47; acc: 0.81
Batch: 260; loss: 0.54; acc: 0.81
Batch: 280; loss: 0.43; acc: 0.81
Batch: 300; loss: 0.57; acc: 0.83
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.36; acc: 0.89
Batch: 360; loss: 0.44; acc: 0.86
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.74; acc: 0.83
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.66; acc: 0.8
Batch: 460; loss: 0.5; acc: 0.8
Batch: 480; loss: 0.44; acc: 0.88
Batch: 500; loss: 0.51; acc: 0.83
Batch: 520; loss: 0.56; acc: 0.83
Batch: 540; loss: 0.4; acc: 0.84
Batch: 560; loss: 0.53; acc: 0.81
Batch: 580; loss: 0.38; acc: 0.84
Batch: 600; loss: 0.36; acc: 0.89
Batch: 620; loss: 0.46; acc: 0.84
Batch: 640; loss: 0.58; acc: 0.84
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.69; acc: 0.75
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.54; acc: 0.91
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.42; acc: 0.86
Train Epoch over. train_loss: 0.47; train_accuracy: 0.85 

Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.44; acc: 0.92
Batch: 120; loss: 0.74; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42891642432303945; val_accuracy: 0.8675358280254777 

The current subspace-distance is: 0.00017362303333356977 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.7; acc: 0.73
Batch: 20; loss: 0.33; acc: 0.88
Batch: 40; loss: 0.44; acc: 0.91
Batch: 60; loss: 0.62; acc: 0.81
Batch: 80; loss: 0.65; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.38; acc: 0.84
Batch: 160; loss: 0.29; acc: 0.89
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.47; acc: 0.84
Batch: 220; loss: 0.39; acc: 0.88
Batch: 240; loss: 0.44; acc: 0.92
Batch: 260; loss: 0.46; acc: 0.83
Batch: 280; loss: 0.47; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.39; acc: 0.86
Batch: 360; loss: 0.31; acc: 0.88
Batch: 380; loss: 0.46; acc: 0.89
Batch: 400; loss: 0.42; acc: 0.88
Batch: 420; loss: 0.64; acc: 0.77
Batch: 440; loss: 0.49; acc: 0.88
Batch: 460; loss: 0.68; acc: 0.81
Batch: 480; loss: 0.55; acc: 0.77
Batch: 500; loss: 0.52; acc: 0.86
Batch: 520; loss: 0.33; acc: 0.88
Batch: 540; loss: 0.56; acc: 0.81
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.56; acc: 0.86
Batch: 600; loss: 0.47; acc: 0.89
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.61; acc: 0.81
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.42; acc: 0.8
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.56; acc: 0.81
Batch: 780; loss: 0.56; acc: 0.84
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.47; acc: 0.86
Batch: 20; loss: 0.57; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.92
Batch: 100; loss: 0.45; acc: 0.91
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.4294993208756872; val_accuracy: 0.8659434713375797 

The current subspace-distance is: 0.00017548148753121495 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.92
Batch: 20; loss: 0.48; acc: 0.94
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.44; acc: 0.84
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.84; acc: 0.78
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.88
Batch: 160; loss: 0.41; acc: 0.84
Batch: 180; loss: 0.65; acc: 0.78
Batch: 200; loss: 0.53; acc: 0.84
Batch: 220; loss: 0.52; acc: 0.81
Batch: 240; loss: 0.45; acc: 0.83
Batch: 260; loss: 0.37; acc: 0.84
Batch: 280; loss: 0.54; acc: 0.88
Batch: 300; loss: 0.28; acc: 0.88
Batch: 320; loss: 0.54; acc: 0.86
Batch: 340; loss: 0.6; acc: 0.81
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.43; acc: 0.83
Batch: 400; loss: 0.62; acc: 0.78
Batch: 420; loss: 0.63; acc: 0.81
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.47; acc: 0.84
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.51; acc: 0.81
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.45; acc: 0.86
Batch: 560; loss: 0.48; acc: 0.88
Batch: 580; loss: 0.59; acc: 0.8
Batch: 600; loss: 0.61; acc: 0.83
Batch: 620; loss: 0.53; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.95
Batch: 660; loss: 0.61; acc: 0.81
Batch: 680; loss: 0.69; acc: 0.78
Batch: 700; loss: 0.58; acc: 0.81
Batch: 720; loss: 0.6; acc: 0.83
Batch: 740; loss: 0.53; acc: 0.88
Batch: 760; loss: 0.47; acc: 0.86
Batch: 780; loss: 0.59; acc: 0.8
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.59; acc: 0.83
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.43; acc: 0.91
Batch: 120; loss: 0.76; acc: 0.7
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.42853365933439536; val_accuracy: 0.8646496815286624 

The current subspace-distance is: 0.00017777951143216342 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.61; acc: 0.77
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.46; acc: 0.86
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.67; acc: 0.78
Batch: 160; loss: 0.32; acc: 0.91
Batch: 180; loss: 0.42; acc: 0.84
Batch: 200; loss: 0.36; acc: 0.84
Batch: 220; loss: 0.72; acc: 0.83
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.51; acc: 0.83
Batch: 280; loss: 0.6; acc: 0.89
Batch: 300; loss: 0.6; acc: 0.75
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.36; acc: 0.92
Batch: 380; loss: 0.59; acc: 0.83
Batch: 400; loss: 0.38; acc: 0.84
Batch: 420; loss: 0.42; acc: 0.84
Batch: 440; loss: 0.46; acc: 0.86
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.63; acc: 0.77
Batch: 500; loss: 0.66; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.88
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.27; acc: 0.92
Batch: 580; loss: 0.55; acc: 0.83
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.31; acc: 0.84
Batch: 640; loss: 0.88; acc: 0.73
Batch: 660; loss: 0.45; acc: 0.86
Batch: 680; loss: 0.57; acc: 0.81
Batch: 700; loss: 0.44; acc: 0.83
Batch: 720; loss: 0.51; acc: 0.84
Batch: 740; loss: 0.36; acc: 0.89
Batch: 760; loss: 0.48; acc: 0.88
Batch: 780; loss: 0.74; acc: 0.75
Train Epoch over. train_loss: 0.47; train_accuracy: 0.86 

Batch: 0; loss: 0.46; acc: 0.88
Batch: 20; loss: 0.58; acc: 0.84
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.42; acc: 0.91
Batch: 80; loss: 0.3; acc: 0.91
Batch: 100; loss: 0.44; acc: 0.91
Batch: 120; loss: 0.73; acc: 0.73
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.42801195843394396; val_accuracy: 0.866640127388535 

The current subspace-distance is: 0.00017896981444209814 

plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_200_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 41935
elements in E: 5932200
fraction nonzero: 0.007069046896598227
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.29; acc: 0.11
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.31; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.23
Batch: 220; loss: 2.29; acc: 0.27
Batch: 240; loss: 2.3; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.2
Batch: 280; loss: 2.31; acc: 0.09
Batch: 300; loss: 2.29; acc: 0.17
Batch: 320; loss: 2.29; acc: 0.12
Batch: 340; loss: 2.3; acc: 0.11
Batch: 360; loss: 2.29; acc: 0.11
Batch: 380; loss: 2.27; acc: 0.14
Batch: 400; loss: 2.27; acc: 0.11
Batch: 420; loss: 2.28; acc: 0.12
Batch: 440; loss: 2.27; acc: 0.16
Batch: 460; loss: 2.2; acc: 0.23
Batch: 480; loss: 2.28; acc: 0.12
Batch: 500; loss: 2.19; acc: 0.2
Batch: 520; loss: 2.26; acc: 0.12
Batch: 540; loss: 2.06; acc: 0.28
Batch: 560; loss: 1.99; acc: 0.33
Batch: 580; loss: 1.88; acc: 0.27
Batch: 600; loss: 1.96; acc: 0.27
Batch: 620; loss: 1.76; acc: 0.33
Batch: 640; loss: 1.76; acc: 0.31
Batch: 660; loss: 1.82; acc: 0.34
Batch: 680; loss: 1.35; acc: 0.52
Batch: 700; loss: 1.6; acc: 0.48
Batch: 720; loss: 1.55; acc: 0.52
Batch: 740; loss: 2.2; acc: 0.36
Batch: 760; loss: 1.24; acc: 0.62
Batch: 780; loss: 1.28; acc: 0.56
Train Epoch over. train_loss: 2.1; train_accuracy: 0.23 

Batch: 0; loss: 1.52; acc: 0.62
Batch: 20; loss: 1.74; acc: 0.47
Batch: 40; loss: 1.26; acc: 0.66
Batch: 60; loss: 1.52; acc: 0.5
Batch: 80; loss: 1.76; acc: 0.52
Batch: 100; loss: 1.52; acc: 0.53
Batch: 120; loss: 1.57; acc: 0.56
Batch: 140; loss: 1.58; acc: 0.53
Val Epoch over. val_loss: 1.6041413864512353; val_accuracy: 0.4866640127388535 

The current subspace-distance is: 1.2605174561031163e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.62; acc: 0.5
Batch: 20; loss: 1.39; acc: 0.53
Batch: 40; loss: 1.05; acc: 0.67
Batch: 60; loss: 1.61; acc: 0.53
Batch: 80; loss: 1.23; acc: 0.58
Batch: 100; loss: 1.2; acc: 0.55
Batch: 120; loss: 1.62; acc: 0.48
Batch: 140; loss: 0.83; acc: 0.75
Batch: 160; loss: 1.02; acc: 0.66
Batch: 180; loss: 0.61; acc: 0.86
Batch: 200; loss: 0.94; acc: 0.66
Batch: 220; loss: 0.85; acc: 0.7
Batch: 240; loss: 0.95; acc: 0.67
Batch: 260; loss: 1.83; acc: 0.52
Batch: 280; loss: 0.91; acc: 0.72
Batch: 300; loss: 1.51; acc: 0.61
Batch: 320; loss: 0.87; acc: 0.75
Batch: 340; loss: 0.79; acc: 0.73
Batch: 360; loss: 0.55; acc: 0.83
Batch: 380; loss: 0.67; acc: 0.78
Batch: 400; loss: 0.9; acc: 0.69
Batch: 420; loss: 0.72; acc: 0.77
Batch: 440; loss: 0.95; acc: 0.73
Batch: 460; loss: 0.85; acc: 0.7
Batch: 480; loss: 0.78; acc: 0.75
Batch: 500; loss: 0.87; acc: 0.75
Batch: 520; loss: 0.75; acc: 0.77
Batch: 540; loss: 0.49; acc: 0.84
Batch: 560; loss: 0.93; acc: 0.67
Batch: 580; loss: 0.59; acc: 0.81
Batch: 600; loss: 0.89; acc: 0.75
Batch: 620; loss: 0.93; acc: 0.72
Batch: 640; loss: 0.64; acc: 0.84
Batch: 660; loss: 0.78; acc: 0.7
Batch: 680; loss: 0.42; acc: 0.84
Batch: 700; loss: 0.79; acc: 0.77
Batch: 720; loss: 1.31; acc: 0.59
Batch: 740; loss: 0.45; acc: 0.84
Batch: 760; loss: 0.72; acc: 0.78
Batch: 780; loss: 0.49; acc: 0.83
Train Epoch over. train_loss: 0.9; train_accuracy: 0.71 

Batch: 0; loss: 0.6; acc: 0.81
Batch: 20; loss: 0.66; acc: 0.8
Batch: 40; loss: 0.41; acc: 0.89
Batch: 60; loss: 0.65; acc: 0.77
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.98; acc: 0.69
Batch: 140; loss: 0.55; acc: 0.8
Val Epoch over. val_loss: 0.6577040395539278; val_accuracy: 0.7819466560509554 

The current subspace-distance is: 2.3738892195979133e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.66; acc: 0.8
Batch: 20; loss: 0.61; acc: 0.78
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.82; acc: 0.73
Batch: 80; loss: 0.87; acc: 0.75
Batch: 100; loss: 0.54; acc: 0.84
Batch: 120; loss: 0.71; acc: 0.75
Batch: 140; loss: 1.44; acc: 0.61
Batch: 160; loss: 0.49; acc: 0.8
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.62; acc: 0.81
Batch: 220; loss: 0.66; acc: 0.78
Batch: 240; loss: 0.51; acc: 0.88
Batch: 260; loss: 0.7; acc: 0.78
Batch: 280; loss: 0.71; acc: 0.78
Batch: 300; loss: 0.51; acc: 0.86
Batch: 320; loss: 0.5; acc: 0.84
Batch: 340; loss: 0.83; acc: 0.75
Batch: 360; loss: 0.49; acc: 0.88
Batch: 380; loss: 0.52; acc: 0.86
Batch: 400; loss: 0.5; acc: 0.88
Batch: 420; loss: 0.6; acc: 0.78
Batch: 440; loss: 0.55; acc: 0.8
Batch: 460; loss: 0.35; acc: 0.86
Batch: 480; loss: 0.56; acc: 0.84
Batch: 500; loss: 0.45; acc: 0.89
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.69; acc: 0.73
Batch: 560; loss: 0.39; acc: 0.88
Batch: 580; loss: 0.46; acc: 0.84
Batch: 600; loss: 0.62; acc: 0.8
Batch: 620; loss: 0.61; acc: 0.86
Batch: 640; loss: 0.45; acc: 0.86
Batch: 660; loss: 0.53; acc: 0.86
Batch: 680; loss: 0.32; acc: 0.92
Batch: 700; loss: 0.48; acc: 0.84
Batch: 720; loss: 0.53; acc: 0.84
Batch: 740; loss: 0.46; acc: 0.83
Batch: 760; loss: 0.56; acc: 0.83
Batch: 780; loss: 0.37; acc: 0.89
Train Epoch over. train_loss: 0.6; train_accuracy: 0.81 

Batch: 0; loss: 0.81; acc: 0.77
Batch: 20; loss: 0.95; acc: 0.67
Batch: 40; loss: 0.48; acc: 0.84
Batch: 60; loss: 0.54; acc: 0.88
Batch: 80; loss: 0.41; acc: 0.89
Batch: 100; loss: 0.75; acc: 0.78
Batch: 120; loss: 1.09; acc: 0.75
Batch: 140; loss: 0.5; acc: 0.86
Val Epoch over. val_loss: 0.7352559560803091; val_accuracy: 0.7804538216560509 

The current subspace-distance is: 3.2058895158115774e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.78
Batch: 20; loss: 0.67; acc: 0.78
Batch: 40; loss: 0.63; acc: 0.8
Batch: 60; loss: 0.54; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.91
Batch: 100; loss: 0.68; acc: 0.84
Batch: 120; loss: 0.64; acc: 0.84
Batch: 140; loss: 0.83; acc: 0.75
Batch: 160; loss: 0.71; acc: 0.78
Batch: 180; loss: 0.48; acc: 0.84
Batch: 200; loss: 0.38; acc: 0.86
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.68; acc: 0.83
Batch: 260; loss: 0.49; acc: 0.81
Batch: 280; loss: 0.5; acc: 0.84
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.69; acc: 0.83
Batch: 340; loss: 0.31; acc: 0.88
Batch: 360; loss: 0.45; acc: 0.89
Batch: 380; loss: 0.47; acc: 0.8
Batch: 400; loss: 0.36; acc: 0.84
Batch: 420; loss: 0.53; acc: 0.78
Batch: 440; loss: 0.52; acc: 0.81
Batch: 460; loss: 0.38; acc: 0.88
Batch: 480; loss: 0.31; acc: 0.91
Batch: 500; loss: 0.25; acc: 0.88
Batch: 520; loss: 0.49; acc: 0.86
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.59; acc: 0.84
Batch: 580; loss: 0.3; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.84
Batch: 620; loss: 0.71; acc: 0.75
Batch: 640; loss: 0.31; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.88
Batch: 680; loss: 0.54; acc: 0.86
Batch: 700; loss: 0.67; acc: 0.73
Batch: 720; loss: 0.39; acc: 0.88
Batch: 740; loss: 0.73; acc: 0.83
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.91
Train Epoch over. train_loss: 0.48; train_accuracy: 0.85 

Batch: 0; loss: 1.2; acc: 0.62
Batch: 20; loss: 0.8; acc: 0.77
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.94; acc: 0.69
Batch: 80; loss: 0.77; acc: 0.73
Batch: 100; loss: 1.18; acc: 0.66
Batch: 120; loss: 1.92; acc: 0.58
Batch: 140; loss: 0.35; acc: 0.86
Val Epoch over. val_loss: 0.9530738294124603; val_accuracy: 0.7101910828025477 

The current subspace-distance is: 3.969847603002563e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.31; acc: 0.62
Batch: 20; loss: 0.72; acc: 0.72
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.38; acc: 0.89
Batch: 100; loss: 0.76; acc: 0.83
Batch: 120; loss: 0.61; acc: 0.84
Batch: 140; loss: 0.62; acc: 0.8
Batch: 160; loss: 0.39; acc: 0.83
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.51; acc: 0.86
Batch: 220; loss: 0.36; acc: 0.84
Batch: 240; loss: 0.45; acc: 0.86
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.78; acc: 0.78
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.62; acc: 0.84
Batch: 360; loss: 0.3; acc: 0.88
Batch: 380; loss: 0.43; acc: 0.88
Batch: 400; loss: 0.5; acc: 0.88
Batch: 420; loss: 0.57; acc: 0.78
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.29; acc: 0.89
Batch: 480; loss: 0.42; acc: 0.84
Batch: 500; loss: 0.67; acc: 0.73
Batch: 520; loss: 0.45; acc: 0.84
Batch: 540; loss: 0.66; acc: 0.81
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.41; acc: 0.84
Batch: 600; loss: 0.2; acc: 0.94
Batch: 620; loss: 0.46; acc: 0.83
Batch: 640; loss: 0.39; acc: 0.86
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.42; acc: 0.89
Batch: 700; loss: 0.46; acc: 0.86
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.36; acc: 0.86
Batch: 780; loss: 0.22; acc: 0.95
Train Epoch over. train_loss: 0.45; train_accuracy: 0.86 

Batch: 0; loss: 0.64; acc: 0.75
Batch: 20; loss: 0.75; acc: 0.77
Batch: 40; loss: 0.56; acc: 0.81
Batch: 60; loss: 0.6; acc: 0.81
Batch: 80; loss: 0.5; acc: 0.84
Batch: 100; loss: 0.82; acc: 0.78
Batch: 120; loss: 0.85; acc: 0.69
Batch: 140; loss: 0.26; acc: 0.88
Val Epoch over. val_loss: 0.6905872335859166; val_accuracy: 0.7651273885350318 

The current subspace-distance is: 4.6703491534572095e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.53; acc: 0.77
Batch: 20; loss: 0.47; acc: 0.84
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.56; acc: 0.81
Batch: 80; loss: 0.41; acc: 0.88
Batch: 100; loss: 0.55; acc: 0.86
Batch: 120; loss: 0.65; acc: 0.8
Batch: 140; loss: 0.72; acc: 0.77
Batch: 160; loss: 0.38; acc: 0.88
Batch: 180; loss: 0.46; acc: 0.86
Batch: 200; loss: 0.51; acc: 0.88
Batch: 220; loss: 0.55; acc: 0.83
Batch: 240; loss: 0.45; acc: 0.88
Batch: 260; loss: 0.27; acc: 0.88
Batch: 280; loss: 0.56; acc: 0.86
Batch: 300; loss: 0.43; acc: 0.91
Batch: 320; loss: 0.53; acc: 0.88
Batch: 340; loss: 0.23; acc: 0.88
Batch: 360; loss: 0.72; acc: 0.8
Batch: 380; loss: 0.32; acc: 0.89
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.58; acc: 0.78
Batch: 440; loss: 0.68; acc: 0.81
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.35; acc: 0.92
Batch: 500; loss: 0.47; acc: 0.84
Batch: 520; loss: 0.24; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.33; acc: 0.83
Batch: 600; loss: 0.5; acc: 0.88
Batch: 620; loss: 0.34; acc: 0.91
Batch: 640; loss: 0.5; acc: 0.86
Batch: 660; loss: 0.3; acc: 0.94
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.92
Batch: 720; loss: 0.64; acc: 0.8
Batch: 740; loss: 0.49; acc: 0.84
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.4; acc: 0.84
Batch: 20; loss: 0.53; acc: 0.84
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.36; acc: 0.88
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.69; acc: 0.83
Batch: 140; loss: 0.2; acc: 0.95
Val Epoch over. val_loss: 0.4654948573298515; val_accuracy: 0.8549960191082803 

The current subspace-distance is: 5.2964551287004724e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.47; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.51; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.88
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.46; acc: 0.83
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.91
Batch: 200; loss: 0.34; acc: 0.86
Batch: 220; loss: 0.49; acc: 0.88
Batch: 240; loss: 0.39; acc: 0.86
Batch: 260; loss: 0.38; acc: 0.89
Batch: 280; loss: 0.61; acc: 0.8
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.6; acc: 0.81
Batch: 340; loss: 0.31; acc: 0.84
Batch: 360; loss: 0.74; acc: 0.8
Batch: 380; loss: 0.37; acc: 0.86
Batch: 400; loss: 0.41; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.25; acc: 0.89
Batch: 460; loss: 0.57; acc: 0.86
Batch: 480; loss: 0.25; acc: 0.92
Batch: 500; loss: 0.52; acc: 0.81
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.52; acc: 0.84
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.32; acc: 0.94
Batch: 600; loss: 0.55; acc: 0.83
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.52; acc: 0.86
Batch: 660; loss: 0.42; acc: 0.88
Batch: 680; loss: 0.33; acc: 0.92
Batch: 700; loss: 0.38; acc: 0.88
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.4; acc: 0.86
Batch: 760; loss: 0.1; acc: 0.98
Batch: 780; loss: 0.39; acc: 0.86
Train Epoch over. train_loss: 0.42; train_accuracy: 0.87 

Batch: 0; loss: 0.49; acc: 0.81
Batch: 20; loss: 0.59; acc: 0.84
Batch: 40; loss: 0.37; acc: 0.88
Batch: 60; loss: 0.43; acc: 0.84
Batch: 80; loss: 0.31; acc: 0.91
Batch: 100; loss: 0.46; acc: 0.86
Batch: 120; loss: 0.8; acc: 0.84
Batch: 140; loss: 0.17; acc: 0.95
Val Epoch over. val_loss: 0.5447530059298132; val_accuracy: 0.8288216560509554 

The current subspace-distance is: 5.870627501280978e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.62; acc: 0.83
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.6; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.88
Batch: 80; loss: 0.48; acc: 0.84
Batch: 100; loss: 0.38; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.2; acc: 0.95
Batch: 160; loss: 0.43; acc: 0.89
Batch: 180; loss: 0.95; acc: 0.75
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.5; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.57; acc: 0.8
Batch: 300; loss: 0.55; acc: 0.89
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.35; acc: 0.89
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.35; acc: 0.86
Batch: 400; loss: 0.43; acc: 0.84
Batch: 420; loss: 0.3; acc: 0.89
Batch: 440; loss: 0.49; acc: 0.84
Batch: 460; loss: 0.48; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.84
Batch: 500; loss: 0.43; acc: 0.89
Batch: 520; loss: 0.52; acc: 0.84
Batch: 540; loss: 0.44; acc: 0.86
Batch: 560; loss: 0.53; acc: 0.89
Batch: 580; loss: 0.72; acc: 0.78
Batch: 600; loss: 0.52; acc: 0.81
Batch: 620; loss: 0.3; acc: 0.83
Batch: 640; loss: 0.3; acc: 0.92
Batch: 660; loss: 0.49; acc: 0.83
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.54; acc: 0.83
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.42; acc: 0.92
Batch: 760; loss: 0.31; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.89
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.44; acc: 0.88
Batch: 40; loss: 0.24; acc: 0.95
Batch: 60; loss: 0.39; acc: 0.86
Batch: 80; loss: 0.28; acc: 0.88
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.6; acc: 0.81
Batch: 140; loss: 0.14; acc: 0.94
Val Epoch over. val_loss: 0.4092410317841609; val_accuracy: 0.8708200636942676 

The current subspace-distance is: 6.434920214815065e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.59; acc: 0.78
Batch: 40; loss: 0.27; acc: 0.89
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.48; acc: 0.89
Batch: 100; loss: 0.49; acc: 0.81
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.84; acc: 0.67
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.34; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.95
Batch: 240; loss: 0.38; acc: 0.81
Batch: 260; loss: 0.49; acc: 0.84
Batch: 280; loss: 0.42; acc: 0.88
Batch: 300; loss: 0.3; acc: 0.88
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.28; acc: 0.89
Batch: 360; loss: 0.51; acc: 0.88
Batch: 380; loss: 0.48; acc: 0.86
Batch: 400; loss: 0.42; acc: 0.91
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.39; acc: 0.83
Batch: 460; loss: 0.19; acc: 0.95
Batch: 480; loss: 0.57; acc: 0.81
Batch: 500; loss: 0.58; acc: 0.84
Batch: 520; loss: 0.37; acc: 0.84
Batch: 540; loss: 0.42; acc: 0.88
Batch: 560; loss: 0.47; acc: 0.88
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.87; acc: 0.67
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.55; acc: 0.89
Batch: 660; loss: 0.47; acc: 0.83
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.57; acc: 0.88
Batch: 740; loss: 0.21; acc: 0.94
Batch: 760; loss: 0.55; acc: 0.86
Batch: 780; loss: 0.48; acc: 0.81
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 0.54; acc: 0.84
Batch: 20; loss: 0.53; acc: 0.83
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.49; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.21; acc: 0.95
Val Epoch over. val_loss: 0.46184585988521576; val_accuracy: 0.8506170382165605 

The current subspace-distance is: 6.878062413306907e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.57; acc: 0.84
Batch: 20; loss: 0.47; acc: 0.83
Batch: 40; loss: 0.4; acc: 0.86
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.73; acc: 0.84
Batch: 100; loss: 0.5; acc: 0.88
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.81; acc: 0.75
Batch: 180; loss: 0.35; acc: 0.88
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.69; acc: 0.83
Batch: 240; loss: 0.33; acc: 0.89
Batch: 260; loss: 0.35; acc: 0.86
Batch: 280; loss: 0.38; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.86
Batch: 320; loss: 0.56; acc: 0.86
Batch: 340; loss: 0.48; acc: 0.8
Batch: 360; loss: 0.23; acc: 0.91
Batch: 380; loss: 0.4; acc: 0.88
Batch: 400; loss: 0.83; acc: 0.75
Batch: 420; loss: 0.48; acc: 0.91
Batch: 440; loss: 0.59; acc: 0.8
Batch: 460; loss: 0.49; acc: 0.81
Batch: 480; loss: 0.22; acc: 0.92
Batch: 500; loss: 0.32; acc: 0.92
Batch: 520; loss: 0.45; acc: 0.83
Batch: 540; loss: 0.42; acc: 0.89
Batch: 560; loss: 0.37; acc: 0.89
Batch: 580; loss: 0.36; acc: 0.88
Batch: 600; loss: 0.47; acc: 0.83
Batch: 620; loss: 0.45; acc: 0.86
Batch: 640; loss: 0.37; acc: 0.84
Batch: 660; loss: 0.48; acc: 0.86
Batch: 680; loss: 0.28; acc: 0.88
Batch: 700; loss: 0.49; acc: 0.83
Batch: 720; loss: 0.55; acc: 0.8
Batch: 740; loss: 0.43; acc: 0.89
Batch: 760; loss: 0.37; acc: 0.84
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.41; train_accuracy: 0.87 

Batch: 0; loss: 1.03; acc: 0.75
Batch: 20; loss: 1.63; acc: 0.67
Batch: 40; loss: 1.24; acc: 0.78
Batch: 60; loss: 0.97; acc: 0.73
Batch: 80; loss: 1.05; acc: 0.8
Batch: 100; loss: 1.27; acc: 0.75
Batch: 120; loss: 1.56; acc: 0.64
Batch: 140; loss: 1.03; acc: 0.81
Val Epoch over. val_loss: 1.1921724691322655; val_accuracy: 0.7436305732484076 

The current subspace-distance is: 7.362339965766296e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 1.23; acc: 0.73
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.91
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.88
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.29; acc: 0.94
Batch: 240; loss: 0.48; acc: 0.84
Batch: 260; loss: 0.32; acc: 0.89
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.43; acc: 0.88
Batch: 420; loss: 0.35; acc: 0.92
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.56; acc: 0.86
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.92
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.36; acc: 0.94
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.28; acc: 0.88
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.49; acc: 0.89
Train Epoch over. train_loss: 0.31; train_accuracy: 0.9 

Batch: 0; loss: 0.34; acc: 0.84
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.31; acc: 0.86
Batch: 80; loss: 0.22; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.14; acc: 0.95
Val Epoch over. val_loss: 0.332601592964997; val_accuracy: 0.897093949044586 

The current subspace-distance is: 7.864632061682642e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.84
Batch: 20; loss: 0.28; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.34; acc: 0.89
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.56; acc: 0.84
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.43; acc: 0.86
Batch: 380; loss: 0.54; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.4; acc: 0.84
Batch: 440; loss: 0.29; acc: 0.91
Batch: 460; loss: 0.27; acc: 0.91
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.24; acc: 0.91
Batch: 520; loss: 0.31; acc: 0.88
Batch: 540; loss: 0.33; acc: 0.91
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.88
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.37; acc: 0.89
Batch: 680; loss: 0.5; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.89
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.51; acc: 0.84
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.4; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.38; acc: 0.86
Batch: 120; loss: 0.59; acc: 0.89
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.34041950600162435; val_accuracy: 0.8965963375796179 

The current subspace-distance is: 8.306403469759971e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.49; acc: 0.92
Batch: 20; loss: 0.28; acc: 0.95
Batch: 40; loss: 0.38; acc: 0.84
Batch: 60; loss: 0.3; acc: 0.95
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.33; acc: 0.86
Batch: 180; loss: 0.25; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.97
Batch: 220; loss: 0.64; acc: 0.84
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.88
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.94
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.46; acc: 0.91
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.23; acc: 0.94
Batch: 420; loss: 0.31; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.24; acc: 0.89
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.89
Batch: 620; loss: 0.42; acc: 0.86
Batch: 640; loss: 0.18; acc: 0.94
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.28; acc: 0.88
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.46; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.24; acc: 0.91
Batch: 20; loss: 0.33; acc: 0.89
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.46; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.2892733428413701; val_accuracy: 0.9116242038216561 

The current subspace-distance is: 8.754228474572301e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.95
Batch: 20; loss: 0.64; acc: 0.86
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.47; acc: 0.88
Batch: 80; loss: 0.26; acc: 0.89
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.52; acc: 0.88
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.47; acc: 0.84
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.86
Batch: 280; loss: 0.51; acc: 0.84
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.52; acc: 0.84
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.32; acc: 0.89
Batch: 440; loss: 0.33; acc: 0.89
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.42; acc: 0.86
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.16; acc: 0.95
Batch: 580; loss: 0.34; acc: 0.88
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.39; acc: 0.91
Batch: 660; loss: 0.34; acc: 0.91
Batch: 680; loss: 0.34; acc: 0.89
Batch: 700; loss: 0.31; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.41; acc: 0.86
Batch: 780; loss: 0.31; acc: 0.89
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.29; acc: 0.88
Batch: 20; loss: 0.41; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.92
Batch: 60; loss: 0.38; acc: 0.84
Batch: 80; loss: 0.18; acc: 0.92
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.75; acc: 0.86
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.3995566403694973; val_accuracy: 0.8769904458598726 

The current subspace-distance is: 9.019347635330632e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.46; acc: 0.86
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.56; acc: 0.83
Batch: 180; loss: 0.25; acc: 0.88
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.91
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.91
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.98
Batch: 320; loss: 0.36; acc: 0.84
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.15; acc: 0.97
Batch: 380; loss: 0.17; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.37; acc: 0.86
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.61; acc: 0.8
Batch: 520; loss: 0.43; acc: 0.84
Batch: 540; loss: 0.48; acc: 0.89
Batch: 560; loss: 0.45; acc: 0.81
Batch: 580; loss: 0.33; acc: 0.86
Batch: 600; loss: 0.45; acc: 0.88
Batch: 620; loss: 0.17; acc: 0.91
Batch: 640; loss: 0.26; acc: 0.88
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.11; acc: 0.97
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.9 

Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.43; acc: 0.89
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2939409321518081; val_accuracy: 0.9101313694267515 

The current subspace-distance is: 9.417065302841365e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.89
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.33; acc: 0.91
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.41; acc: 0.92
Batch: 160; loss: 0.41; acc: 0.89
Batch: 180; loss: 0.26; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.83
Batch: 240; loss: 0.1; acc: 0.97
Batch: 260; loss: 0.34; acc: 0.84
Batch: 280; loss: 0.44; acc: 0.88
Batch: 300; loss: 0.27; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.98
Batch: 340; loss: 0.28; acc: 0.88
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.35; acc: 0.88
Batch: 420; loss: 0.27; acc: 0.94
Batch: 440; loss: 0.31; acc: 0.92
Batch: 460; loss: 0.26; acc: 0.88
Batch: 480; loss: 0.41; acc: 0.92
Batch: 500; loss: 0.48; acc: 0.8
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.26; acc: 0.95
Batch: 600; loss: 0.27; acc: 0.91
Batch: 620; loss: 0.28; acc: 0.92
Batch: 640; loss: 0.53; acc: 0.86
Batch: 660; loss: 0.13; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.92
Batch: 700; loss: 0.17; acc: 0.94
Batch: 720; loss: 0.47; acc: 0.89
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.17; acc: 0.94
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.29; acc: 0.91
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.27290182335266644; val_accuracy: 0.9170979299363057 

The current subspace-distance is: 9.82304263743572e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.89
Batch: 40; loss: 0.28; acc: 0.92
Batch: 60; loss: 0.17; acc: 0.94
Batch: 80; loss: 0.44; acc: 0.88
Batch: 100; loss: 0.24; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.17; acc: 0.97
Batch: 180; loss: 0.58; acc: 0.84
Batch: 200; loss: 0.21; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.22; acc: 0.95
Batch: 280; loss: 0.81; acc: 0.84
Batch: 300; loss: 0.3; acc: 0.94
Batch: 320; loss: 0.1; acc: 0.98
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.33; acc: 0.86
Batch: 400; loss: 0.36; acc: 0.86
Batch: 420; loss: 0.56; acc: 0.86
Batch: 440; loss: 0.26; acc: 0.92
Batch: 460; loss: 0.37; acc: 0.88
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.1; acc: 0.98
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.21; acc: 0.95
Batch: 580; loss: 0.45; acc: 0.84
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.43; acc: 0.88
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.19; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.43; acc: 0.86
Batch: 760; loss: 0.28; acc: 0.94
Batch: 780; loss: 0.17; acc: 0.94
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.31; acc: 0.88
Batch: 20; loss: 0.65; acc: 0.84
Batch: 40; loss: 0.28; acc: 0.94
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.58; acc: 0.84
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.36091100381817787; val_accuracy: 0.8924164012738853 

The current subspace-distance is: 0.00010135686898138374 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.47; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.91
Batch: 40; loss: 0.25; acc: 0.88
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.27; acc: 0.89
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.4; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.54; acc: 0.88
Batch: 240; loss: 0.19; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.32; acc: 0.92
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.52; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.36; acc: 0.89
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.6; acc: 0.84
Batch: 460; loss: 0.27; acc: 0.94
Batch: 480; loss: 0.28; acc: 0.88
Batch: 500; loss: 0.6; acc: 0.86
Batch: 520; loss: 0.3; acc: 0.94
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.16; acc: 0.97
Batch: 580; loss: 0.57; acc: 0.88
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.54; acc: 0.84
Batch: 640; loss: 0.36; acc: 0.89
Batch: 660; loss: 0.34; acc: 0.94
Batch: 680; loss: 0.35; acc: 0.86
Batch: 700; loss: 0.2; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.89
Batch: 780; loss: 0.33; acc: 0.92
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.39; acc: 0.83
Batch: 20; loss: 0.38; acc: 0.86
Batch: 40; loss: 0.29; acc: 0.94
Batch: 60; loss: 0.43; acc: 0.91
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.49; acc: 0.91
Batch: 120; loss: 0.77; acc: 0.8
Batch: 140; loss: 0.17; acc: 0.94
Val Epoch over. val_loss: 0.41741503068026464; val_accuracy: 0.8692277070063694 

The current subspace-distance is: 0.00010475659655639902 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.81
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.38; acc: 0.88
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.97
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.3; acc: 0.91
Batch: 220; loss: 0.44; acc: 0.88
Batch: 240; loss: 0.35; acc: 0.84
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.33; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.88
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.36; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.86
Batch: 480; loss: 0.45; acc: 0.86
Batch: 500; loss: 0.42; acc: 0.84
Batch: 520; loss: 0.45; acc: 0.86
Batch: 540; loss: 0.35; acc: 0.88
Batch: 560; loss: 0.3; acc: 0.88
Batch: 580; loss: 0.4; acc: 0.83
Batch: 600; loss: 0.23; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.22; acc: 0.94
Batch: 660; loss: 0.37; acc: 0.84
Batch: 680; loss: 0.55; acc: 0.81
Batch: 700; loss: 0.28; acc: 0.92
Batch: 720; loss: 0.47; acc: 0.88
Batch: 740; loss: 0.34; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.88
Batch: 780; loss: 0.64; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.98
Val Epoch over. val_loss: 0.28880323588278645; val_accuracy: 0.9118232484076433 

The current subspace-distance is: 0.0001081779773812741 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.36; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.66; acc: 0.78
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.19; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.08; acc: 1.0
Batch: 240; loss: 0.1; acc: 0.98
Batch: 260; loss: 0.26; acc: 0.89
Batch: 280; loss: 0.34; acc: 0.88
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.54; acc: 0.83
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.88
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.25; acc: 0.89
Batch: 440; loss: 0.47; acc: 0.89
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.36; acc: 0.91
Batch: 500; loss: 0.11; acc: 0.95
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.91
Batch: 560; loss: 0.48; acc: 0.86
Batch: 580; loss: 0.41; acc: 0.84
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.21; acc: 0.91
Batch: 640; loss: 0.18; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.33; acc: 0.91
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.43; acc: 0.86
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.28; acc: 0.86
Batch: 20; loss: 0.29; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.86
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.2738741044500831; val_accuracy: 0.9205812101910829 

The current subspace-distance is: 0.00011127620382467285 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.31; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.36; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.33; acc: 0.95
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.16; acc: 0.94
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.38; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.36; acc: 0.91
Batch: 300; loss: 0.23; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.91
Batch: 340; loss: 0.31; acc: 0.91
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.49; acc: 0.83
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.08; acc: 0.98
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.4; acc: 0.89
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.43; acc: 0.86
Batch: 620; loss: 0.23; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.37; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.91
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.3; acc: 0.89
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.28; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.31; acc: 0.88
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.33; acc: 0.89
Batch: 120; loss: 0.53; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.2685299949708638; val_accuracy: 0.92078025477707 

The current subspace-distance is: 0.00011401991650927812 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.51; acc: 0.88
Batch: 20; loss: 0.34; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.94
Batch: 160; loss: 0.59; acc: 0.81
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.32; acc: 0.92
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.29; acc: 0.89
Batch: 360; loss: 0.57; acc: 0.81
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.27; acc: 0.89
Batch: 440; loss: 0.09; acc: 0.98
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.23; acc: 0.94
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.48; acc: 0.84
Batch: 580; loss: 0.2; acc: 0.92
Batch: 600; loss: 0.4; acc: 0.94
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.47; acc: 0.84
Batch: 720; loss: 0.14; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.5; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.84
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.2565635678352444; val_accuracy: 0.923765923566879 

The current subspace-distance is: 0.00011691750114550814 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.37; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.36; acc: 0.91
Batch: 140; loss: 0.35; acc: 0.89
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.08; acc: 0.97
Batch: 200; loss: 0.18; acc: 0.95
Batch: 220; loss: 0.28; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.94
Batch: 320; loss: 0.16; acc: 0.92
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.97
Batch: 520; loss: 0.22; acc: 0.94
Batch: 540; loss: 0.18; acc: 0.95
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.4; acc: 0.84
Batch: 600; loss: 0.44; acc: 0.89
Batch: 620; loss: 0.15; acc: 0.94
Batch: 640; loss: 0.23; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.27; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.58; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.21; acc: 0.92
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.25006667866258864; val_accuracy: 0.9262539808917197 

The current subspace-distance is: 0.00011944297148147598 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.95
Batch: 100; loss: 0.28; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.52; acc: 0.81
Batch: 200; loss: 0.42; acc: 0.84
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.29; acc: 0.91
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.36; acc: 0.86
Batch: 340; loss: 0.31; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.16; acc: 0.97
Batch: 440; loss: 0.31; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.83
Batch: 480; loss: 0.19; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.25; acc: 0.92
Batch: 540; loss: 0.26; acc: 0.91
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.3; acc: 0.89
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.32; acc: 0.91
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.36; acc: 0.89
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.31; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.31; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.57; acc: 0.84
Batch: 140; loss: 0.09; acc: 0.97
Val Epoch over. val_loss: 0.25611758751759106; val_accuracy: 0.9241640127388535 

The current subspace-distance is: 0.00012239828356541693 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.4; acc: 0.86
Batch: 40; loss: 0.24; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.88
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.95
Batch: 280; loss: 0.19; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.36; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.88
Batch: 480; loss: 0.2; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.28; acc: 0.89
Batch: 560; loss: 0.24; acc: 0.95
Batch: 580; loss: 0.39; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.33; acc: 0.89
Batch: 640; loss: 0.46; acc: 0.91
Batch: 660; loss: 0.41; acc: 0.84
Batch: 680; loss: 0.29; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.95
Batch: 720; loss: 0.34; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.92
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.26225766046032023; val_accuracy: 0.9204816878980892 

The current subspace-distance is: 0.00012532967957668006 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.32; acc: 0.88
Batch: 80; loss: 0.54; acc: 0.88
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.31; acc: 0.86
Batch: 200; loss: 0.22; acc: 0.97
Batch: 220; loss: 0.26; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.19; acc: 0.97
Batch: 300; loss: 0.25; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.43; acc: 0.84
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.54; acc: 0.89
Batch: 460; loss: 0.34; acc: 0.89
Batch: 480; loss: 0.28; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.46; acc: 0.83
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.4; acc: 0.84
Batch: 620; loss: 0.27; acc: 0.91
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.31; acc: 0.89
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.32; acc: 0.89
Batch: 740; loss: 0.24; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.12; acc: 0.94
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.2595330197126812; val_accuracy: 0.9231687898089171 

The current subspace-distance is: 0.00012817364768125117 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.39; acc: 0.91
Batch: 20; loss: 0.15; acc: 0.92
Batch: 40; loss: 0.56; acc: 0.88
Batch: 60; loss: 0.26; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.86
Batch: 120; loss: 0.24; acc: 0.88
Batch: 140; loss: 0.57; acc: 0.83
Batch: 160; loss: 0.32; acc: 0.92
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.28; acc: 0.91
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.29; acc: 0.94
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.26; acc: 0.92
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.08; acc: 0.98
Batch: 480; loss: 0.36; acc: 0.89
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.44; acc: 0.88
Batch: 580; loss: 0.63; acc: 0.81
Batch: 600; loss: 0.34; acc: 0.88
Batch: 620; loss: 0.41; acc: 0.91
Batch: 640; loss: 0.49; acc: 0.86
Batch: 660; loss: 0.5; acc: 0.88
Batch: 680; loss: 0.13; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.98
Batch: 720; loss: 0.32; acc: 0.92
Batch: 740; loss: 0.47; acc: 0.89
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.36; acc: 0.89
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.3; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.32; acc: 0.89
Batch: 120; loss: 0.59; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.2606637594734977; val_accuracy: 0.9224721337579618 

The current subspace-distance is: 0.00013080953794997185 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.49; acc: 0.84
Batch: 20; loss: 0.29; acc: 0.89
Batch: 40; loss: 0.22; acc: 0.89
Batch: 60; loss: 0.31; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.46; acc: 0.89
Batch: 140; loss: 0.19; acc: 0.95
Batch: 160; loss: 0.18; acc: 0.92
Batch: 180; loss: 0.49; acc: 0.88
Batch: 200; loss: 0.22; acc: 0.88
Batch: 220; loss: 0.22; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.91
Batch: 260; loss: 0.39; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.36; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.88
Batch: 340; loss: 0.29; acc: 0.92
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.3; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.86
Batch: 420; loss: 0.49; acc: 0.89
Batch: 440; loss: 0.3; acc: 0.92
Batch: 460; loss: 0.34; acc: 0.86
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.92
Batch: 540; loss: 0.41; acc: 0.91
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.24; acc: 0.95
Batch: 600; loss: 0.39; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.43; acc: 0.89
Batch: 680; loss: 0.41; acc: 0.84
Batch: 700; loss: 0.21; acc: 0.88
Batch: 720; loss: 0.32; acc: 0.94
Batch: 740; loss: 0.4; acc: 0.88
Batch: 760; loss: 0.34; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.92
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.25284230314005335; val_accuracy: 0.9240644904458599 

The current subspace-distance is: 0.0001330996456090361 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.36; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.92
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.88
Batch: 180; loss: 0.36; acc: 0.91
Batch: 200; loss: 0.28; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.31; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.31; acc: 0.89
Batch: 320; loss: 0.46; acc: 0.86
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.23; acc: 0.89
Batch: 380; loss: 0.34; acc: 0.94
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.88
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.37; acc: 0.81
Batch: 480; loss: 0.26; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.21; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.25; acc: 0.88
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.95
Batch: 640; loss: 0.3; acc: 0.94
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.5; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.91
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.21; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.97
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24661487522446046; val_accuracy: 0.9277468152866242 

The current subspace-distance is: 0.00013606097490992397 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.33; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.94
Batch: 80; loss: 0.45; acc: 0.86
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.91
Batch: 220; loss: 0.27; acc: 0.91
Batch: 240; loss: 0.28; acc: 0.89
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.29; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.42; acc: 0.91
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.25; acc: 0.92
Batch: 400; loss: 0.28; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.25; acc: 0.91
Batch: 460; loss: 0.22; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.89
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.95
Batch: 540; loss: 0.34; acc: 0.88
Batch: 560; loss: 0.29; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.98
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.36; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.89
Batch: 660; loss: 0.42; acc: 0.84
Batch: 680; loss: 0.21; acc: 0.94
Batch: 700; loss: 0.45; acc: 0.91
Batch: 720; loss: 0.21; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.29; acc: 0.88
Batch: 780; loss: 0.27; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.24478877113930358; val_accuracy: 0.926453025477707 

The current subspace-distance is: 0.0001382912159897387 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.94
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.41; acc: 0.84
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.44; acc: 0.89
Batch: 160; loss: 0.36; acc: 0.92
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.22; acc: 0.91
Batch: 220; loss: 0.22; acc: 0.95
Batch: 240; loss: 0.42; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.86
Batch: 280; loss: 0.68; acc: 0.84
Batch: 300; loss: 0.39; acc: 0.84
Batch: 320; loss: 0.32; acc: 0.95
Batch: 340; loss: 0.24; acc: 0.94
Batch: 360; loss: 0.42; acc: 0.83
Batch: 380; loss: 0.22; acc: 0.91
Batch: 400; loss: 0.27; acc: 0.91
Batch: 420; loss: 0.19; acc: 0.94
Batch: 440; loss: 0.46; acc: 0.88
Batch: 460; loss: 0.3; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.57; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.16; acc: 0.94
Batch: 620; loss: 0.39; acc: 0.86
Batch: 640; loss: 0.43; acc: 0.89
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.86
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.17; acc: 0.95
Batch: 740; loss: 0.34; acc: 0.92
Batch: 760; loss: 0.19; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.95
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.23997008371030448; val_accuracy: 0.927547770700637 

The current subspace-distance is: 0.00014121114509180188 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.86
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.42; acc: 0.91
Batch: 60; loss: 0.37; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.21; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.5; acc: 0.88
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.39; acc: 0.88
Batch: 200; loss: 0.39; acc: 0.89
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.37; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.36; acc: 0.92
Batch: 360; loss: 0.16; acc: 0.97
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.34; acc: 0.88
Batch: 440; loss: 0.33; acc: 0.91
Batch: 460; loss: 0.41; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.33; acc: 0.91
Batch: 520; loss: 0.42; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.89
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.55; acc: 0.81
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.92
Batch: 680; loss: 0.16; acc: 0.97
Batch: 700; loss: 0.32; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.89
Batch: 740; loss: 0.07; acc: 1.0
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.45; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24099238457715816; val_accuracy: 0.9281449044585988 

The current subspace-distance is: 0.0001435476151527837 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.32; acc: 0.89
Batch: 20; loss: 0.16; acc: 0.91
Batch: 40; loss: 0.42; acc: 0.88
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.34; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.92
Batch: 220; loss: 0.44; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.24; acc: 0.94
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.34; acc: 0.89
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.23; acc: 0.92
Batch: 380; loss: 0.31; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.89
Batch: 420; loss: 0.34; acc: 0.86
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.14; acc: 0.97
Batch: 520; loss: 0.49; acc: 0.88
Batch: 540; loss: 0.25; acc: 0.92
Batch: 560; loss: 0.09; acc: 0.98
Batch: 580; loss: 0.27; acc: 0.88
Batch: 600; loss: 0.33; acc: 0.94
Batch: 620; loss: 0.33; acc: 0.91
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.34; acc: 0.92
Batch: 700; loss: 0.24; acc: 0.89
Batch: 720; loss: 0.53; acc: 0.86
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.3; acc: 0.91
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.23948246030623366; val_accuracy: 0.9297372611464968 

The current subspace-distance is: 0.00014591104991268367 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.95
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.45; acc: 0.89
Batch: 100; loss: 0.33; acc: 0.88
Batch: 120; loss: 0.18; acc: 0.91
Batch: 140; loss: 0.28; acc: 0.92
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.29; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.4; acc: 0.84
Batch: 300; loss: 0.49; acc: 0.91
Batch: 320; loss: 0.2; acc: 0.97
Batch: 340; loss: 0.46; acc: 0.83
Batch: 360; loss: 0.26; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.92
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.21; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.86
Batch: 500; loss: 0.39; acc: 0.84
Batch: 520; loss: 0.33; acc: 0.89
Batch: 540; loss: 0.28; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.92
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.06; acc: 0.98
Batch: 660; loss: 0.28; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.89
Batch: 700; loss: 0.4; acc: 0.86
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.12; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.12; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.51; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.24209252011719024; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 0.00014799737255088985 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.1; acc: 0.98
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.89
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.27; acc: 0.95
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.26; acc: 0.95
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.41; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.89
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.2; acc: 0.91
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.94
Batch: 360; loss: 0.39; acc: 0.89
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.28; acc: 0.89
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.22; acc: 0.94
Batch: 520; loss: 0.41; acc: 0.91
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.24; acc: 0.94
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.17; acc: 0.97
Batch: 620; loss: 0.29; acc: 0.89
Batch: 640; loss: 0.27; acc: 0.86
Batch: 660; loss: 0.24; acc: 0.91
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.32; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.24382994522097384; val_accuracy: 0.9269506369426752 

The current subspace-distance is: 0.00015003851149231195 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.28; acc: 0.88
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.35; acc: 0.86
Batch: 80; loss: 0.37; acc: 0.88
Batch: 100; loss: 0.34; acc: 0.88
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.36; acc: 0.92
Batch: 160; loss: 0.25; acc: 0.94
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.48; acc: 0.89
Batch: 220; loss: 0.16; acc: 0.95
Batch: 240; loss: 0.32; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.44; acc: 0.88
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.41; acc: 0.91
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.34; acc: 0.88
Batch: 400; loss: 0.36; acc: 0.92
Batch: 420; loss: 0.29; acc: 0.88
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.37; acc: 0.89
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.52; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.31; acc: 0.92
Batch: 600; loss: 0.35; acc: 0.88
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.43; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.24468811138705082; val_accuracy: 0.9254578025477707 

The current subspace-distance is: 0.00015178063767962158 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.35; acc: 0.88
Batch: 60; loss: 0.46; acc: 0.88
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.32; acc: 0.94
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.95
Batch: 180; loss: 0.37; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.39; acc: 0.91
Batch: 240; loss: 0.26; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.22; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.98
Batch: 340; loss: 0.3; acc: 0.89
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.29; acc: 0.89
Batch: 400; loss: 0.34; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.23; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.15; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.3; acc: 0.84
Batch: 560; loss: 0.32; acc: 0.89
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.89
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.21; acc: 0.97
Batch: 680; loss: 0.21; acc: 0.97
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.37; acc: 0.86
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.18; acc: 0.98
Batch: 780; loss: 0.32; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.53; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.24453303830069342; val_accuracy: 0.9280453821656051 

The current subspace-distance is: 0.00015352775517385453 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.28; acc: 0.88
Batch: 20; loss: 0.42; acc: 0.92
Batch: 40; loss: 0.44; acc: 0.88
Batch: 60; loss: 0.34; acc: 0.89
Batch: 80; loss: 0.4; acc: 0.88
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.13; acc: 0.94
Batch: 200; loss: 0.2; acc: 0.92
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.92
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.14; acc: 0.95
Batch: 340; loss: 0.37; acc: 0.86
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.41; acc: 0.88
Batch: 440; loss: 0.22; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.25; acc: 0.91
Batch: 500; loss: 0.39; acc: 0.88
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.15; acc: 0.95
Batch: 600; loss: 0.11; acc: 0.97
Batch: 620; loss: 0.47; acc: 0.88
Batch: 640; loss: 0.22; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.88
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.29; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.94
Batch: 740; loss: 0.21; acc: 0.92
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.2; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.49; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2409213663428832; val_accuracy: 0.9270501592356688 

The current subspace-distance is: 0.00015499285655096173 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.19; acc: 0.89
Batch: 20; loss: 0.43; acc: 0.91
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.97
Batch: 120; loss: 0.3; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.35; acc: 0.86
Batch: 200; loss: 0.29; acc: 0.86
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.46; acc: 0.88
Batch: 280; loss: 0.56; acc: 0.88
Batch: 300; loss: 0.33; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.86
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.95
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.92
Batch: 440; loss: 0.41; acc: 0.92
Batch: 460; loss: 0.39; acc: 0.91
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.37; acc: 0.92
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.94
Batch: 640; loss: 0.44; acc: 0.83
Batch: 660; loss: 0.28; acc: 0.94
Batch: 680; loss: 0.37; acc: 0.88
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.98
Batch: 760; loss: 0.12; acc: 0.97
Batch: 780; loss: 0.26; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.24485342363548127; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 0.0001570293097756803 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.91
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.3; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.89
Batch: 180; loss: 0.19; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.18; acc: 0.94
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.86
Batch: 340; loss: 0.34; acc: 0.91
Batch: 360; loss: 0.16; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.27; acc: 0.94
Batch: 460; loss: 0.65; acc: 0.83
Batch: 480; loss: 0.18; acc: 0.94
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.31; acc: 0.92
Batch: 540; loss: 0.36; acc: 0.83
Batch: 560; loss: 0.09; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.91
Batch: 620; loss: 0.07; acc: 1.0
Batch: 640; loss: 0.58; acc: 0.88
Batch: 660; loss: 0.35; acc: 0.86
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.32; acc: 0.88
Batch: 720; loss: 0.16; acc: 0.95
Batch: 740; loss: 0.36; acc: 0.88
Batch: 760; loss: 0.39; acc: 0.92
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.29; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.56; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.24102685231549345; val_accuracy: 0.9284434713375797 

The current subspace-distance is: 0.00015978260489646345 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.44; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.91
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.38; acc: 0.92
Batch: 220; loss: 0.23; acc: 0.91
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.26; acc: 0.94
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.32; acc: 0.88
Batch: 320; loss: 0.32; acc: 0.86
Batch: 340; loss: 0.16; acc: 0.91
Batch: 360; loss: 0.24; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.21; acc: 0.92
Batch: 460; loss: 0.32; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.92
Batch: 500; loss: 0.33; acc: 0.94
Batch: 520; loss: 0.33; acc: 0.94
Batch: 540; loss: 0.59; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.04; acc: 1.0
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.24; acc: 0.91
Batch: 640; loss: 0.17; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.22; acc: 0.89
Batch: 700; loss: 0.27; acc: 0.91
Batch: 720; loss: 0.25; acc: 0.92
Batch: 740; loss: 0.3; acc: 0.91
Batch: 760; loss: 0.3; acc: 0.86
Batch: 780; loss: 0.23; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2390137811066808; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 0.00016155579942278564 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.35; acc: 0.92
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.22; acc: 0.91
Batch: 140; loss: 0.39; acc: 0.86
Batch: 160; loss: 0.24; acc: 0.95
Batch: 180; loss: 0.32; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.91
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.31; acc: 0.94
Batch: 280; loss: 0.33; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.25; acc: 0.91
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.91
Batch: 480; loss: 0.28; acc: 0.89
Batch: 500; loss: 0.18; acc: 0.95
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.42; acc: 0.89
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.34; acc: 0.91
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.18; acc: 0.95
Batch: 780; loss: 0.21; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23879792477199985; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 0.00016437417070847005 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.14; acc: 0.94
Batch: 140; loss: 0.33; acc: 0.88
Batch: 160; loss: 0.15; acc: 0.94
Batch: 180; loss: 0.17; acc: 0.92
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.25; acc: 0.89
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.34; acc: 0.89
Batch: 320; loss: 0.29; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.89
Batch: 360; loss: 0.39; acc: 0.88
Batch: 380; loss: 0.3; acc: 0.88
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.35; acc: 0.92
Batch: 460; loss: 0.46; acc: 0.89
Batch: 480; loss: 0.48; acc: 0.86
Batch: 500; loss: 0.25; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.94
Batch: 540; loss: 0.44; acc: 0.91
Batch: 560; loss: 0.33; acc: 0.95
Batch: 580; loss: 0.46; acc: 0.83
Batch: 600; loss: 0.38; acc: 0.86
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.29; acc: 0.88
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.89
Batch: 760; loss: 0.16; acc: 0.98
Batch: 780; loss: 0.29; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.14; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23845511664203398; val_accuracy: 0.9281449044585988 

The current subspace-distance is: 0.00016715390665922314 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.23; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.35; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.91
Batch: 200; loss: 0.37; acc: 0.92
Batch: 220; loss: 0.26; acc: 0.88
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.35; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.25; acc: 0.92
Batch: 420; loss: 0.42; acc: 0.88
Batch: 440; loss: 0.25; acc: 0.92
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.52; acc: 0.88
Batch: 500; loss: 0.19; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.94
Batch: 540; loss: 0.29; acc: 0.91
Batch: 560; loss: 0.37; acc: 0.91
Batch: 580; loss: 0.27; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.97
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.25; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.94
Batch: 720; loss: 0.27; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23899116552179786; val_accuracy: 0.9272492038216561 

The current subspace-distance is: 0.00016865060024429113 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.25; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.94
Batch: 140; loss: 0.29; acc: 0.88
Batch: 160; loss: 0.33; acc: 0.92
Batch: 180; loss: 0.31; acc: 0.88
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.97
Batch: 240; loss: 0.43; acc: 0.92
Batch: 260; loss: 0.37; acc: 0.92
Batch: 280; loss: 0.46; acc: 0.88
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.4; acc: 0.92
Batch: 340; loss: 0.32; acc: 0.89
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.88
Batch: 400; loss: 0.2; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.53; acc: 0.83
Batch: 460; loss: 0.4; acc: 0.94
Batch: 480; loss: 0.24; acc: 0.89
Batch: 500; loss: 0.32; acc: 0.89
Batch: 520; loss: 0.31; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.94
Batch: 580; loss: 0.34; acc: 0.92
Batch: 600; loss: 0.18; acc: 0.92
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.36; acc: 0.92
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.22; acc: 0.91
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.2; acc: 0.95
Batch: 740; loss: 0.29; acc: 0.91
Batch: 760; loss: 0.27; acc: 0.91
Batch: 780; loss: 0.47; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2383794099400947; val_accuracy: 0.9276472929936306 

The current subspace-distance is: 0.00017095381917897612 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.44; acc: 0.92
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.46; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.94
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.25; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.91
Batch: 200; loss: 0.33; acc: 0.94
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.33; acc: 0.88
Batch: 260; loss: 0.36; acc: 0.92
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.4; acc: 0.91
Batch: 380; loss: 0.06; acc: 1.0
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.28; acc: 0.86
Batch: 440; loss: 0.18; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.28; acc: 0.89
Batch: 540; loss: 0.32; acc: 0.92
Batch: 560; loss: 0.4; acc: 0.91
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.88
Batch: 620; loss: 0.27; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.23; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.33; acc: 0.89
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.89
Batch: 780; loss: 0.08; acc: 0.98
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23842265793851986; val_accuracy: 0.9282444267515924 

The current subspace-distance is: 0.00017274437414016575 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.24; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.28; acc: 0.95
Batch: 160; loss: 0.19; acc: 0.92
Batch: 180; loss: 0.28; acc: 0.89
Batch: 200; loss: 0.26; acc: 0.91
Batch: 220; loss: 0.17; acc: 0.94
Batch: 240; loss: 0.23; acc: 0.91
Batch: 260; loss: 0.23; acc: 0.89
Batch: 280; loss: 0.45; acc: 0.89
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.22; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.95
Batch: 400; loss: 0.18; acc: 0.92
Batch: 420; loss: 0.16; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.91
Batch: 460; loss: 0.31; acc: 0.89
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.46; acc: 0.89
Batch: 580; loss: 0.26; acc: 0.91
Batch: 600; loss: 0.24; acc: 0.92
Batch: 620; loss: 0.2; acc: 0.92
Batch: 640; loss: 0.22; acc: 0.89
Batch: 660; loss: 0.31; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.33; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.16; acc: 0.94
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.27; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.23841878522638302; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 0.00017476890934631228 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.57; acc: 0.86
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.38; acc: 0.88
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.88
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.48; acc: 0.86
Batch: 220; loss: 0.21; acc: 0.91
Batch: 240; loss: 0.41; acc: 0.88
Batch: 260; loss: 0.16; acc: 0.94
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.21; acc: 0.94
Batch: 360; loss: 0.12; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.25; acc: 0.94
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.25; acc: 0.95
Batch: 460; loss: 0.32; acc: 0.88
Batch: 480; loss: 0.29; acc: 0.91
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.17; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.54; acc: 0.88
Batch: 580; loss: 0.27; acc: 0.94
Batch: 600; loss: 0.22; acc: 0.95
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.94
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.23880004420117207; val_accuracy: 0.927547770700637 

The current subspace-distance is: 0.00017667915381025523 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.36; acc: 0.89
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.84
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.24; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.88
Batch: 200; loss: 0.29; acc: 0.92
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.31; acc: 0.91
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.15; acc: 0.98
Batch: 320; loss: 0.42; acc: 0.89
Batch: 340; loss: 0.32; acc: 0.91
Batch: 360; loss: 0.28; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.36; acc: 0.88
Batch: 420; loss: 0.24; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.84
Batch: 460; loss: 0.31; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.91
Batch: 500; loss: 0.36; acc: 0.88
Batch: 520; loss: 0.22; acc: 0.95
Batch: 540; loss: 0.18; acc: 0.94
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.2; acc: 0.91
Batch: 600; loss: 0.35; acc: 0.91
Batch: 620; loss: 0.36; acc: 0.91
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.25; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.94
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.89
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.44; acc: 0.88
Batch: 780; loss: 0.24; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.95
Batch: 20; loss: 0.27; acc: 0.94
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2406539147612965; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 0.00017825736722443253 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.41; acc: 0.86
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.31; acc: 0.86
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.5; acc: 0.86
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.89
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.3; acc: 0.89
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.97
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.26; acc: 0.91
Batch: 460; loss: 0.21; acc: 0.91
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.45; acc: 0.84
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.28; acc: 0.94
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.92
Batch: 640; loss: 0.4; acc: 0.88
Batch: 660; loss: 0.21; acc: 0.94
Batch: 680; loss: 0.3; acc: 0.91
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.23; acc: 0.94
Batch: 780; loss: 0.38; acc: 0.89
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.13; acc: 0.98
Batch: 100; loss: 0.26; acc: 0.92
Batch: 120; loss: 0.52; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.24010556511533487; val_accuracy: 0.9278463375796179 

The current subspace-distance is: 0.00018098426517099142 

plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_300_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 56300
elements in E: 7909600
fraction nonzero: 0.007117932638818651
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.12
Batch: 40; loss: 2.3; acc: 0.17
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.3; acc: 0.09
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.31; acc: 0.16
Batch: 200; loss: 2.29; acc: 0.2
Batch: 220; loss: 2.29; acc: 0.27
Batch: 240; loss: 2.29; acc: 0.16
Batch: 260; loss: 2.28; acc: 0.25
Batch: 280; loss: 2.3; acc: 0.11
Batch: 300; loss: 2.29; acc: 0.2
Batch: 320; loss: 2.29; acc: 0.12
Batch: 340; loss: 2.3; acc: 0.17
Batch: 360; loss: 2.29; acc: 0.16
Batch: 380; loss: 2.25; acc: 0.17
Batch: 400; loss: 2.26; acc: 0.14
Batch: 420; loss: 2.27; acc: 0.14
Batch: 440; loss: 2.24; acc: 0.19
Batch: 460; loss: 2.15; acc: 0.34
Batch: 480; loss: 2.23; acc: 0.11
Batch: 500; loss: 2.03; acc: 0.39
Batch: 520; loss: 2.08; acc: 0.23
Batch: 540; loss: 1.78; acc: 0.41
Batch: 560; loss: 1.63; acc: 0.44
Batch: 580; loss: 1.59; acc: 0.52
Batch: 600; loss: 1.68; acc: 0.38
Batch: 620; loss: 1.51; acc: 0.45
Batch: 640; loss: 1.3; acc: 0.56
Batch: 660; loss: 2.31; acc: 0.38
Batch: 680; loss: 0.97; acc: 0.72
Batch: 700; loss: 1.12; acc: 0.67
Batch: 720; loss: 1.31; acc: 0.64
Batch: 740; loss: 0.86; acc: 0.64
Batch: 760; loss: 1.71; acc: 0.47
Batch: 780; loss: 1.04; acc: 0.69
Train Epoch over. train_loss: 1.98; train_accuracy: 0.29 

Batch: 0; loss: 1.47; acc: 0.42
Batch: 20; loss: 2.33; acc: 0.33
Batch: 40; loss: 1.5; acc: 0.52
Batch: 60; loss: 1.63; acc: 0.48
Batch: 80; loss: 2.19; acc: 0.39
Batch: 100; loss: 1.83; acc: 0.45
Batch: 120; loss: 1.94; acc: 0.44
Batch: 140; loss: 1.99; acc: 0.31
Val Epoch over. val_loss: 1.8661125495934943; val_accuracy: 0.40545382165605093 

The current subspace-distance is: 1.3025126463617198e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 1.85; acc: 0.41
Batch: 20; loss: 1.2; acc: 0.62
Batch: 40; loss: 0.88; acc: 0.78
Batch: 60; loss: 0.83; acc: 0.72
Batch: 80; loss: 0.53; acc: 0.81
Batch: 100; loss: 0.92; acc: 0.7
Batch: 120; loss: 1.44; acc: 0.56
Batch: 140; loss: 0.51; acc: 0.84
Batch: 160; loss: 0.66; acc: 0.77
Batch: 180; loss: 0.64; acc: 0.84
Batch: 200; loss: 0.74; acc: 0.77
Batch: 220; loss: 0.69; acc: 0.8
Batch: 240; loss: 0.66; acc: 0.77
Batch: 260; loss: 1.0; acc: 0.73
Batch: 280; loss: 1.03; acc: 0.78
Batch: 300; loss: 0.89; acc: 0.77
Batch: 320; loss: 1.05; acc: 0.69
Batch: 340; loss: 0.87; acc: 0.72
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.66; acc: 0.8
Batch: 400; loss: 0.74; acc: 0.69
Batch: 420; loss: 0.47; acc: 0.89
Batch: 440; loss: 0.64; acc: 0.78
Batch: 460; loss: 0.95; acc: 0.7
Batch: 480; loss: 0.49; acc: 0.88
Batch: 500; loss: 0.44; acc: 0.81
Batch: 520; loss: 0.4; acc: 0.91
Batch: 540; loss: 0.36; acc: 0.91
Batch: 560; loss: 0.58; acc: 0.81
Batch: 580; loss: 0.4; acc: 0.86
Batch: 600; loss: 0.73; acc: 0.78
Batch: 620; loss: 0.55; acc: 0.78
Batch: 640; loss: 0.46; acc: 0.84
Batch: 660; loss: 0.52; acc: 0.86
Batch: 680; loss: 0.46; acc: 0.84
Batch: 700; loss: 0.68; acc: 0.81
Batch: 720; loss: 0.93; acc: 0.73
Batch: 740; loss: 0.48; acc: 0.86
Batch: 760; loss: 0.58; acc: 0.84
Batch: 780; loss: 0.29; acc: 0.92
Train Epoch over. train_loss: 0.7; train_accuracy: 0.78 

Batch: 0; loss: 0.41; acc: 0.84
Batch: 20; loss: 0.45; acc: 0.83
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.57; acc: 0.8
Batch: 80; loss: 0.42; acc: 0.86
Batch: 100; loss: 0.72; acc: 0.78
Batch: 120; loss: 1.29; acc: 0.73
Batch: 140; loss: 0.28; acc: 0.88
Val Epoch over. val_loss: 0.6337650627087635; val_accuracy: 0.7903065286624203 

The current subspace-distance is: 2.4001883502933197e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.52; acc: 0.83
Batch: 20; loss: 0.72; acc: 0.77
Batch: 40; loss: 0.39; acc: 0.91
Batch: 60; loss: 0.74; acc: 0.72
Batch: 80; loss: 0.54; acc: 0.81
Batch: 100; loss: 0.46; acc: 0.88
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.5; acc: 0.86
Batch: 160; loss: 0.45; acc: 0.86
Batch: 180; loss: 0.31; acc: 0.92
Batch: 200; loss: 0.52; acc: 0.84
Batch: 220; loss: 0.47; acc: 0.84
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.74; acc: 0.81
Batch: 280; loss: 0.63; acc: 0.8
Batch: 300; loss: 0.48; acc: 0.84
Batch: 320; loss: 0.61; acc: 0.8
Batch: 340; loss: 0.51; acc: 0.86
Batch: 360; loss: 0.54; acc: 0.84
Batch: 380; loss: 0.37; acc: 0.89
Batch: 400; loss: 0.41; acc: 0.88
Batch: 420; loss: 0.28; acc: 0.94
Batch: 440; loss: 0.54; acc: 0.84
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.52; acc: 0.83
Batch: 500; loss: 0.48; acc: 0.86
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.92
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.4; acc: 0.92
Batch: 600; loss: 0.54; acc: 0.84
Batch: 620; loss: 0.33; acc: 0.86
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.4; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.48; acc: 0.86
Batch: 740; loss: 0.38; acc: 0.86
Batch: 760; loss: 0.54; acc: 0.83
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.49; train_accuracy: 0.85 

Batch: 0; loss: 0.5; acc: 0.86
Batch: 20; loss: 0.54; acc: 0.83
Batch: 40; loss: 0.49; acc: 0.91
Batch: 60; loss: 0.38; acc: 0.86
Batch: 80; loss: 0.46; acc: 0.91
Batch: 100; loss: 0.59; acc: 0.8
Batch: 120; loss: 1.05; acc: 0.72
Batch: 140; loss: 0.36; acc: 0.92
Val Epoch over. val_loss: 0.632676344103874; val_accuracy: 0.8173765923566879 

The current subspace-distance is: 3.274500704719685e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.4; acc: 0.86
Batch: 20; loss: 0.52; acc: 0.83
Batch: 40; loss: 0.51; acc: 0.84
Batch: 60; loss: 0.4; acc: 0.88
Batch: 80; loss: 0.71; acc: 0.83
Batch: 100; loss: 0.57; acc: 0.83
Batch: 120; loss: 0.61; acc: 0.77
Batch: 140; loss: 1.18; acc: 0.72
Batch: 160; loss: 0.7; acc: 0.77
Batch: 180; loss: 0.33; acc: 0.92
Batch: 200; loss: 0.36; acc: 0.94
Batch: 220; loss: 0.45; acc: 0.84
Batch: 240; loss: 0.66; acc: 0.77
Batch: 260; loss: 0.28; acc: 0.94
Batch: 280; loss: 0.56; acc: 0.8
Batch: 300; loss: 0.45; acc: 0.89
Batch: 320; loss: 0.51; acc: 0.86
Batch: 340; loss: 0.54; acc: 0.84
Batch: 360; loss: 0.34; acc: 0.88
Batch: 380; loss: 0.33; acc: 0.92
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.4; acc: 0.88
Batch: 440; loss: 0.67; acc: 0.77
Batch: 460; loss: 0.55; acc: 0.86
Batch: 480; loss: 0.47; acc: 0.78
Batch: 500; loss: 0.23; acc: 0.95
Batch: 520; loss: 0.45; acc: 0.88
Batch: 540; loss: 0.47; acc: 0.83
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.29; acc: 0.92
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.44; acc: 0.92
Batch: 640; loss: 0.28; acc: 0.94
Batch: 660; loss: 0.45; acc: 0.83
Batch: 680; loss: 0.29; acc: 0.89
Batch: 700; loss: 0.78; acc: 0.83
Batch: 720; loss: 0.25; acc: 0.89
Batch: 740; loss: 0.81; acc: 0.86
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.37; acc: 0.83
Train Epoch over. train_loss: 0.44; train_accuracy: 0.87 

Batch: 0; loss: 0.27; acc: 0.91
Batch: 20; loss: 0.27; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.3; acc: 0.84
Batch: 80; loss: 0.39; acc: 0.89
Batch: 100; loss: 0.35; acc: 0.88
Batch: 120; loss: 0.82; acc: 0.77
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.38814798932356437; val_accuracy: 0.8771894904458599 

The current subspace-distance is: 3.989355536759831e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 0.41; acc: 0.83
Batch: 20; loss: 0.58; acc: 0.78
Batch: 40; loss: 0.46; acc: 0.84
Batch: 60; loss: 0.44; acc: 0.89
Batch: 80; loss: 0.34; acc: 0.91
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.83; acc: 0.8
Batch: 140; loss: 0.4; acc: 0.89
Batch: 160; loss: 0.44; acc: 0.86
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.46; acc: 0.86
Batch: 220; loss: 0.56; acc: 0.8
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.94
Batch: 280; loss: 0.45; acc: 0.83
Batch: 300; loss: 0.95; acc: 0.77
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.57; acc: 0.78
Batch: 360; loss: 0.47; acc: 0.89
Batch: 380; loss: 0.25; acc: 0.95
Batch: 400; loss: 0.39; acc: 0.88
Batch: 420; loss: 0.42; acc: 0.89
Batch: 440; loss: 0.31; acc: 0.88
Batch: 460; loss: 0.48; acc: 0.83
Batch: 480; loss: 0.26; acc: 0.95
Batch: 500; loss: 0.57; acc: 0.84
Batch: 520; loss: 0.42; acc: 0.86
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.54; acc: 0.81
Batch: 580; loss: 0.51; acc: 0.8
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.41; acc: 0.86
Batch: 640; loss: 0.59; acc: 0.81
Batch: 660; loss: 0.32; acc: 0.88
Batch: 680; loss: 0.52; acc: 0.78
Batch: 700; loss: 0.52; acc: 0.86
Batch: 720; loss: 0.35; acc: 0.91
Batch: 740; loss: 0.15; acc: 0.97
Batch: 760; loss: 0.37; acc: 0.86
Batch: 780; loss: 0.9; acc: 0.8
Train Epoch over. train_loss: 0.43; train_accuracy: 0.87 

Batch: 0; loss: 0.87; acc: 0.75
Batch: 20; loss: 0.79; acc: 0.75
Batch: 40; loss: 0.53; acc: 0.91
Batch: 60; loss: 0.66; acc: 0.84
Batch: 80; loss: 0.54; acc: 0.83
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 1.3; acc: 0.64
Batch: 140; loss: 0.44; acc: 0.88
Val Epoch over. val_loss: 0.740854571769192; val_accuracy: 0.7899084394904459 

The current subspace-distance is: 4.665713640861213e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.84; acc: 0.73
Batch: 20; loss: 0.48; acc: 0.83
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.48; acc: 0.84
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.86
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.5; acc: 0.88
Batch: 180; loss: 0.88; acc: 0.7
Batch: 200; loss: 0.36; acc: 0.92
Batch: 220; loss: 0.59; acc: 0.83
Batch: 240; loss: 0.27; acc: 0.88
Batch: 260; loss: 0.21; acc: 0.91
Batch: 280; loss: 0.74; acc: 0.8
Batch: 300; loss: 0.3; acc: 0.89
Batch: 320; loss: 0.51; acc: 0.88
Batch: 340; loss: 0.2; acc: 0.91
Batch: 360; loss: 0.37; acc: 0.89
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.71; acc: 0.81
Batch: 440; loss: 0.42; acc: 0.77
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.71; acc: 0.73
Batch: 520; loss: 0.19; acc: 0.91
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.35; acc: 0.86
Batch: 600; loss: 0.57; acc: 0.88
Batch: 620; loss: 0.42; acc: 0.91
Batch: 640; loss: 0.39; acc: 0.88
Batch: 660; loss: 0.33; acc: 0.86
Batch: 680; loss: 0.41; acc: 0.84
Batch: 700; loss: 0.28; acc: 0.91
Batch: 720; loss: 0.49; acc: 0.84
Batch: 740; loss: 0.52; acc: 0.88
Batch: 760; loss: 0.43; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.88
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.7; acc: 0.81
Batch: 20; loss: 0.82; acc: 0.7
Batch: 40; loss: 0.74; acc: 0.84
Batch: 60; loss: 0.8; acc: 0.75
Batch: 80; loss: 0.45; acc: 0.81
Batch: 100; loss: 0.7; acc: 0.88
Batch: 120; loss: 1.44; acc: 0.72
Batch: 140; loss: 0.42; acc: 0.83
Val Epoch over. val_loss: 0.7712902167610302; val_accuracy: 0.78125 

The current subspace-distance is: 5.2943247283110395e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.91; acc: 0.78
Batch: 20; loss: 0.35; acc: 0.89
Batch: 40; loss: 0.38; acc: 0.81
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.48; acc: 0.88
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.22; acc: 0.92
Batch: 140; loss: 0.44; acc: 0.89
Batch: 160; loss: 0.32; acc: 0.88
Batch: 180; loss: 0.41; acc: 0.86
Batch: 200; loss: 0.35; acc: 0.88
Batch: 220; loss: 0.3; acc: 0.92
Batch: 240; loss: 0.28; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.46; acc: 0.86
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.41; acc: 0.84
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.49; acc: 0.86
Batch: 380; loss: 0.45; acc: 0.86
Batch: 400; loss: 0.48; acc: 0.84
Batch: 420; loss: 0.39; acc: 0.89
Batch: 440; loss: 0.23; acc: 0.91
Batch: 460; loss: 0.51; acc: 0.84
Batch: 480; loss: 0.27; acc: 0.94
Batch: 500; loss: 0.21; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.88
Batch: 540; loss: 0.24; acc: 0.88
Batch: 560; loss: 0.53; acc: 0.83
Batch: 580; loss: 0.31; acc: 0.94
Batch: 600; loss: 0.29; acc: 0.91
Batch: 620; loss: 0.3; acc: 0.92
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.71; acc: 0.83
Batch: 680; loss: 0.45; acc: 0.86
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.26; acc: 0.94
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.41; acc: 0.89
Train Epoch over. train_loss: 0.38; train_accuracy: 0.88 

Batch: 0; loss: 0.23; acc: 0.89
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.26; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.88
Batch: 120; loss: 0.94; acc: 0.7
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.3261247338477973; val_accuracy: 0.8982882165605095 

The current subspace-distance is: 5.817461715196259e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.88
Batch: 20; loss: 0.35; acc: 0.91
Batch: 40; loss: 0.37; acc: 0.89
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.35; acc: 0.91
Batch: 100; loss: 0.37; acc: 0.88
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.38; acc: 0.91
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.63; acc: 0.81
Batch: 200; loss: 0.4; acc: 0.84
Batch: 220; loss: 0.59; acc: 0.84
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.55; acc: 0.81
Batch: 300; loss: 0.47; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.92
Batch: 340; loss: 0.44; acc: 0.84
Batch: 360; loss: 0.25; acc: 0.92
Batch: 380; loss: 0.28; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.32; acc: 0.91
Batch: 440; loss: 0.41; acc: 0.83
Batch: 460; loss: 0.48; acc: 0.88
Batch: 480; loss: 0.45; acc: 0.84
Batch: 500; loss: 0.54; acc: 0.92
Batch: 520; loss: 0.41; acc: 0.88
Batch: 540; loss: 0.3; acc: 0.91
Batch: 560; loss: 0.65; acc: 0.81
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.25; acc: 0.97
Batch: 620; loss: 0.37; acc: 0.91
Batch: 640; loss: 0.33; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.39; acc: 0.89
Batch: 700; loss: 0.44; acc: 0.84
Batch: 720; loss: 0.22; acc: 0.91
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.27; acc: 0.89
Batch: 780; loss: 0.5; acc: 0.86
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 0.8; acc: 0.73
Batch: 20; loss: 0.95; acc: 0.75
Batch: 40; loss: 0.75; acc: 0.75
Batch: 60; loss: 0.61; acc: 0.83
Batch: 80; loss: 0.85; acc: 0.72
Batch: 100; loss: 1.0; acc: 0.69
Batch: 120; loss: 1.6; acc: 0.62
Batch: 140; loss: 0.51; acc: 0.81
Val Epoch over. val_loss: 0.84313359420011; val_accuracy: 0.7516918789808917 

The current subspace-distance is: 6.36865952401422e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.78; acc: 0.75
Batch: 20; loss: 0.48; acc: 0.86
Batch: 40; loss: 0.3; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.56; acc: 0.86
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.48; acc: 0.84
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.3; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.92
Batch: 220; loss: 0.28; acc: 0.92
Batch: 240; loss: 0.65; acc: 0.81
Batch: 260; loss: 0.32; acc: 0.92
Batch: 280; loss: 0.26; acc: 0.91
Batch: 300; loss: 0.25; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.88
Batch: 340; loss: 0.16; acc: 0.95
Batch: 360; loss: 0.57; acc: 0.88
Batch: 380; loss: 0.59; acc: 0.86
Batch: 400; loss: 0.19; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.48; acc: 0.88
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.64; acc: 0.84
Batch: 500; loss: 0.37; acc: 0.88
Batch: 520; loss: 0.37; acc: 0.86
Batch: 540; loss: 0.15; acc: 0.98
Batch: 560; loss: 0.29; acc: 0.95
Batch: 580; loss: 0.42; acc: 0.88
Batch: 600; loss: 0.37; acc: 0.86
Batch: 620; loss: 0.46; acc: 0.91
Batch: 640; loss: 0.47; acc: 0.83
Batch: 660; loss: 0.55; acc: 0.83
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.45; acc: 0.89
Batch: 720; loss: 0.36; acc: 0.86
Batch: 740; loss: 0.24; acc: 0.94
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.39; acc: 0.86
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.89
Batch: 80; loss: 0.16; acc: 0.95
Batch: 100; loss: 0.29; acc: 0.94
Batch: 120; loss: 0.72; acc: 0.8
Batch: 140; loss: 0.08; acc: 0.95
Val Epoch over. val_loss: 0.31761623971211683; val_accuracy: 0.9015724522292994 

The current subspace-distance is: 6.858418055344373e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.35; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.92
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.41; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.46; acc: 0.84
Batch: 180; loss: 0.33; acc: 0.88
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.38; acc: 0.89
Batch: 240; loss: 0.27; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.42; acc: 0.88
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.3; acc: 0.91
Batch: 380; loss: 0.54; acc: 0.83
Batch: 400; loss: 0.44; acc: 0.91
Batch: 420; loss: 0.54; acc: 0.83
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.45; acc: 0.92
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.89
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.55; acc: 0.88
Batch: 620; loss: 0.54; acc: 0.78
Batch: 640; loss: 0.25; acc: 0.91
Batch: 660; loss: 0.14; acc: 0.98
Batch: 680; loss: 0.39; acc: 0.84
Batch: 700; loss: 0.65; acc: 0.81
Batch: 720; loss: 0.47; acc: 0.84
Batch: 740; loss: 0.73; acc: 0.8
Batch: 760; loss: 0.5; acc: 0.84
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.34; train_accuracy: 0.89 

Batch: 0; loss: 0.42; acc: 0.86
Batch: 20; loss: 0.43; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.91
Batch: 60; loss: 0.49; acc: 0.78
Batch: 80; loss: 0.49; acc: 0.78
Batch: 100; loss: 0.45; acc: 0.84
Batch: 120; loss: 0.99; acc: 0.72
Batch: 140; loss: 0.28; acc: 0.88
Val Epoch over. val_loss: 0.49144388374629294; val_accuracy: 0.8352906050955414 

The current subspace-distance is: 7.318357529584318e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.65; acc: 0.8
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.18; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.97
Batch: 80; loss: 0.36; acc: 0.89
Batch: 100; loss: 0.21; acc: 0.91
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.27; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.5; acc: 0.88
Batch: 280; loss: 0.29; acc: 0.89
Batch: 300; loss: 0.39; acc: 0.89
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.25; acc: 0.94
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.26; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.39; acc: 0.89
Batch: 500; loss: 0.34; acc: 0.92
Batch: 520; loss: 0.22; acc: 0.97
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.35; acc: 0.91
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.98
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.24; acc: 0.95
Batch: 740; loss: 0.27; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.95
Batch: 780; loss: 0.51; acc: 0.88
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.95
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.89
Batch: 120; loss: 0.76; acc: 0.8
Batch: 140; loss: 0.16; acc: 0.97
Val Epoch over. val_loss: 0.2787549425462249; val_accuracy: 0.9156050955414012 

The current subspace-distance is: 7.756339618936181e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.42; acc: 0.88
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.42; acc: 0.86
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.98
Batch: 120; loss: 0.36; acc: 0.88
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.28; acc: 0.94
Batch: 200; loss: 0.45; acc: 0.84
Batch: 220; loss: 0.25; acc: 0.94
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.16; acc: 0.94
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.1; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.91
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.91
Batch: 420; loss: 0.36; acc: 0.88
Batch: 440; loss: 0.17; acc: 0.94
Batch: 460; loss: 0.35; acc: 0.88
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.16; acc: 0.92
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.35; acc: 0.89
Batch: 560; loss: 0.25; acc: 0.91
Batch: 580; loss: 0.43; acc: 0.89
Batch: 600; loss: 0.32; acc: 0.89
Batch: 620; loss: 0.37; acc: 0.86
Batch: 640; loss: 0.15; acc: 0.92
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.26; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.47; acc: 0.86
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.3; acc: 0.92
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.86
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.78; acc: 0.81
Batch: 140; loss: 0.13; acc: 0.95
Val Epoch over. val_loss: 0.31067867705206964; val_accuracy: 0.9054538216560509 

The current subspace-distance is: 8.208223152905703e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.22; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.23; acc: 0.92
Batch: 60; loss: 0.13; acc: 0.94
Batch: 80; loss: 0.34; acc: 0.88
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.27; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.92
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.4; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.24; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.94
Batch: 340; loss: 0.34; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.88
Batch: 380; loss: 0.23; acc: 0.91
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.2; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.92
Batch: 460; loss: 0.24; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.89
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.16; acc: 0.94
Batch: 600; loss: 0.36; acc: 0.88
Batch: 620; loss: 0.29; acc: 0.88
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.17; acc: 0.97
Batch: 680; loss: 0.14; acc: 0.94
Batch: 700; loss: 0.36; acc: 0.91
Batch: 720; loss: 0.3; acc: 0.89
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.38; acc: 0.86
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.3; acc: 0.89
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.34; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.27733528205923214; val_accuracy: 0.9130175159235668 

The current subspace-distance is: 8.575072570238262e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.43; acc: 0.89
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.21; acc: 0.91
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.42; acc: 0.88
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.17; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.92
Batch: 200; loss: 0.18; acc: 0.97
Batch: 220; loss: 0.23; acc: 0.92
Batch: 240; loss: 0.34; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.92
Batch: 280; loss: 0.36; acc: 0.89
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.17; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.89
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.92
Batch: 420; loss: 0.33; acc: 0.92
Batch: 440; loss: 0.37; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.91
Batch: 500; loss: 0.3; acc: 0.94
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.33; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.32; acc: 0.89
Batch: 660; loss: 0.32; acc: 0.89
Batch: 680; loss: 0.34; acc: 0.88
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.91
Train Epoch over. train_loss: 0.26; train_accuracy: 0.92 

Batch: 0; loss: 0.11; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.88
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.59; acc: 0.78
Batch: 140; loss: 0.1; acc: 0.97
Val Epoch over. val_loss: 0.24358332508308872; val_accuracy: 0.9232683121019108 

The current subspace-distance is: 8.963432628661394e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.43; acc: 0.88
Batch: 40; loss: 0.36; acc: 0.84
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.45; acc: 0.88
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.27; acc: 0.94
Batch: 220; loss: 0.33; acc: 0.91
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.91
Batch: 280; loss: 0.35; acc: 0.88
Batch: 300; loss: 0.25; acc: 0.89
Batch: 320; loss: 0.26; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.32; acc: 0.94
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.24; acc: 0.95
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.36; acc: 0.88
Batch: 460; loss: 0.31; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.91
Batch: 500; loss: 0.47; acc: 0.83
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.42; acc: 0.86
Batch: 560; loss: 0.3; acc: 0.94
Batch: 580; loss: 0.12; acc: 0.98
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.89
Batch: 640; loss: 0.21; acc: 0.94
Batch: 660; loss: 0.48; acc: 0.88
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.29; acc: 0.92
Batch: 760; loss: 0.34; acc: 0.86
Batch: 780; loss: 0.19; acc: 0.97
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.86
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.38; acc: 0.81
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.2665545974330158; val_accuracy: 0.915406050955414 

The current subspace-distance is: 9.279340883949772e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.42; acc: 0.89
Batch: 40; loss: 0.34; acc: 0.91
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.92
Batch: 140; loss: 0.31; acc: 0.91
Batch: 160; loss: 0.3; acc: 0.89
Batch: 180; loss: 0.23; acc: 0.94
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.31; acc: 0.92
Batch: 240; loss: 0.14; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.23; acc: 0.95
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.3; acc: 0.89
Batch: 380; loss: 0.23; acc: 0.94
Batch: 400; loss: 0.24; acc: 0.92
Batch: 420; loss: 0.31; acc: 0.89
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.92
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.57; acc: 0.88
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.3; acc: 0.89
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.91
Batch: 600; loss: 0.22; acc: 0.92
Batch: 620; loss: 0.31; acc: 0.97
Batch: 640; loss: 0.47; acc: 0.91
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.34; acc: 0.91
Batch: 720; loss: 0.26; acc: 0.91
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.19; acc: 0.95
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.25; acc: 0.89
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.27; acc: 0.91
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.66; acc: 0.81
Batch: 140; loss: 0.12; acc: 0.97
Val Epoch over. val_loss: 0.2524677157924054; val_accuracy: 0.9239649681528662 

The current subspace-distance is: 9.71146218944341e-05 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.28; acc: 0.97
Batch: 200; loss: 0.28; acc: 0.88
Batch: 220; loss: 0.31; acc: 0.89
Batch: 240; loss: 0.32; acc: 0.89
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.5; acc: 0.92
Batch: 300; loss: 0.3; acc: 0.91
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.19; acc: 0.91
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.3; acc: 0.91
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.6; acc: 0.84
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.94
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.41; acc: 0.92
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.24; acc: 0.92
Batch: 580; loss: 0.2; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.24; acc: 0.92
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.34; acc: 0.89
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.94
Batch: 760; loss: 0.32; acc: 0.91
Batch: 780; loss: 0.12; acc: 0.98
Train Epoch over. train_loss: 0.25; train_accuracy: 0.92 

Batch: 0; loss: 0.16; acc: 0.92
Batch: 20; loss: 0.62; acc: 0.83
Batch: 40; loss: 0.18; acc: 0.91
Batch: 60; loss: 0.45; acc: 0.92
Batch: 80; loss: 0.52; acc: 0.84
Batch: 100; loss: 0.41; acc: 0.89
Batch: 120; loss: 0.71; acc: 0.8
Batch: 140; loss: 0.19; acc: 0.95
Val Epoch over. val_loss: 0.32964916074067163; val_accuracy: 0.9000796178343949 

The current subspace-distance is: 0.00010113608732353896 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.19; acc: 0.94
Batch: 160; loss: 0.26; acc: 0.92
Batch: 180; loss: 0.21; acc: 0.91
Batch: 200; loss: 0.27; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.27; acc: 0.94
Batch: 280; loss: 0.37; acc: 0.92
Batch: 300; loss: 0.21; acc: 0.91
Batch: 320; loss: 0.29; acc: 0.91
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.29; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.41; acc: 0.86
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.18; acc: 0.95
Batch: 500; loss: 0.4; acc: 0.89
Batch: 520; loss: 0.34; acc: 0.89
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.05; acc: 1.0
Batch: 580; loss: 0.44; acc: 0.88
Batch: 600; loss: 0.29; acc: 0.94
Batch: 620; loss: 0.5; acc: 0.83
Batch: 640; loss: 0.68; acc: 0.83
Batch: 660; loss: 0.16; acc: 0.92
Batch: 680; loss: 0.31; acc: 0.92
Batch: 700; loss: 0.23; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.91
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.47; acc: 0.83
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.89
Batch: 80; loss: 0.22; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.52; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.22962982981068314; val_accuracy: 0.9303343949044586 

The current subspace-distance is: 0.00010448363900650293 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.4; acc: 0.89
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.43; acc: 0.83
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.92
Batch: 140; loss: 0.3; acc: 0.94
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.91
Batch: 220; loss: 0.29; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.28; acc: 0.92
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.18; acc: 0.97
Batch: 340; loss: 0.21; acc: 0.92
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.88
Batch: 400; loss: 0.19; acc: 0.89
Batch: 420; loss: 0.24; acc: 0.92
Batch: 440; loss: 0.29; acc: 0.95
Batch: 460; loss: 0.27; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.94
Batch: 500; loss: 0.31; acc: 0.95
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.28; acc: 0.91
Batch: 560; loss: 0.15; acc: 0.94
Batch: 580; loss: 0.28; acc: 0.89
Batch: 600; loss: 0.26; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.97
Batch: 640; loss: 0.23; acc: 0.92
Batch: 660; loss: 0.21; acc: 0.92
Batch: 680; loss: 0.56; acc: 0.88
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.32; acc: 0.91
Batch: 740; loss: 0.23; acc: 0.92
Batch: 760; loss: 0.48; acc: 0.84
Batch: 780; loss: 0.59; acc: 0.84
Train Epoch over. train_loss: 0.24; train_accuracy: 0.92 

Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.3; acc: 0.92
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.47; acc: 0.83
Batch: 140; loss: 0.1; acc: 0.95
Val Epoch over. val_loss: 0.23840036841144988; val_accuracy: 0.9294386942675159 

The current subspace-distance is: 0.00010741673031589016 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.21; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.34; acc: 0.86
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.88
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.95
Batch: 240; loss: 0.18; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.91
Batch: 280; loss: 0.25; acc: 0.91
Batch: 300; loss: 0.21; acc: 0.92
Batch: 320; loss: 0.43; acc: 0.91
Batch: 340; loss: 0.34; acc: 0.88
Batch: 360; loss: 0.35; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.5; acc: 0.83
Batch: 460; loss: 0.23; acc: 0.92
Batch: 480; loss: 0.4; acc: 0.91
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.2; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.3; acc: 0.92
Batch: 580; loss: 0.23; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.94
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.29; acc: 0.91
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.37; acc: 0.91
Batch: 740; loss: 0.16; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.84
Train Epoch over. train_loss: 0.24; train_accuracy: 0.93 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.81
Batch: 140; loss: 0.11; acc: 0.97
Val Epoch over. val_loss: 0.2326195119719976; val_accuracy: 0.9279458598726115 

The current subspace-distance is: 0.00011069839092670009 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.92
Batch: 100; loss: 0.26; acc: 0.88
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.09; acc: 0.97
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.34; acc: 0.89
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.24; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.23; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.97
Batch: 520; loss: 0.32; acc: 0.92
Batch: 540; loss: 0.21; acc: 0.89
Batch: 560; loss: 0.18; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.39; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.25; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.46; acc: 0.88
Batch: 720; loss: 0.29; acc: 0.91
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.25; acc: 0.91
Train Epoch over. train_loss: 0.22; train_accuracy: 0.93 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.57; acc: 0.78
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.21851371973752975; val_accuracy: 0.9321257961783439 

The current subspace-distance is: 0.00011380324576748535 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.26; acc: 0.97
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.91
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.25; acc: 0.91
Batch: 120; loss: 0.23; acc: 0.94
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.27; acc: 0.89
Batch: 180; loss: 0.16; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.88
Batch: 240; loss: 0.25; acc: 0.94
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.94
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.92
Batch: 360; loss: 0.34; acc: 0.92
Batch: 380; loss: 0.1; acc: 0.98
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.12; acc: 0.97
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.19; acc: 0.97
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.4; acc: 0.88
Batch: 560; loss: 0.27; acc: 0.88
Batch: 580; loss: 0.17; acc: 0.94
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.09; acc: 0.98
Batch: 640; loss: 0.36; acc: 0.91
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.45; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.92
Batch: 720; loss: 0.11; acc: 0.95
Batch: 740; loss: 0.41; acc: 0.89
Batch: 760; loss: 0.4; acc: 0.89
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.47; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.20908846298030986; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 0.00011640198499662802 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.38; acc: 0.88
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.92
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.94
Batch: 140; loss: 0.26; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.3; acc: 0.89
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.94
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.36; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.21; acc: 0.89
Batch: 400; loss: 0.2; acc: 0.94
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.16; acc: 0.94
Batch: 480; loss: 0.21; acc: 0.91
Batch: 500; loss: 0.14; acc: 0.98
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.89
Batch: 560; loss: 0.14; acc: 0.94
Batch: 580; loss: 0.37; acc: 0.89
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.35; acc: 0.94
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.19; acc: 0.95
Batch: 780; loss: 0.33; acc: 0.88
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.88
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.11; acc: 0.95
Val Epoch over. val_loss: 0.221245163363541; val_accuracy: 0.9324243630573248 

The current subspace-distance is: 0.00011976488895015791 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.12; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.16; acc: 0.94
Batch: 120; loss: 0.25; acc: 0.92
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.89
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.92
Batch: 260; loss: 0.25; acc: 0.91
Batch: 280; loss: 0.21; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.94
Batch: 320; loss: 0.32; acc: 0.91
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.94
Batch: 380; loss: 0.13; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.28; acc: 0.88
Batch: 460; loss: 0.07; acc: 1.0
Batch: 480; loss: 0.43; acc: 0.86
Batch: 500; loss: 0.2; acc: 0.94
Batch: 520; loss: 0.39; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.1; acc: 0.98
Batch: 580; loss: 0.19; acc: 0.95
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.11; acc: 0.95
Batch: 700; loss: 0.3; acc: 0.92
Batch: 720; loss: 0.18; acc: 0.92
Batch: 740; loss: 0.28; acc: 0.91
Batch: 760; loss: 0.33; acc: 0.91
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.57; acc: 0.81
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.20908534283613323; val_accuracy: 0.9370023885350318 

The current subspace-distance is: 0.0001224305888172239 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.89
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.37; acc: 0.91
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.43; acc: 0.86
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.27; acc: 0.92
Batch: 220; loss: 0.18; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.94
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.98
Batch: 360; loss: 0.22; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.91
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.4; acc: 0.89
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.11; acc: 0.95
Batch: 500; loss: 0.22; acc: 0.92
Batch: 520; loss: 0.08; acc: 0.95
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.31; acc: 0.88
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.86
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.94
Batch: 660; loss: 0.46; acc: 0.83
Batch: 680; loss: 0.14; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.20421256431064028; val_accuracy: 0.9394904458598726 

The current subspace-distance is: 0.00012565594806801528 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.91
Batch: 20; loss: 0.17; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.25; acc: 0.91
Batch: 80; loss: 0.36; acc: 0.86
Batch: 100; loss: 0.07; acc: 0.97
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.09; acc: 0.98
Batch: 220; loss: 0.21; acc: 0.89
Batch: 240; loss: 0.28; acc: 0.91
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.94
Batch: 320; loss: 0.39; acc: 0.88
Batch: 340; loss: 0.24; acc: 0.92
Batch: 360; loss: 0.12; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.04; acc: 0.98
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.41; acc: 0.86
Batch: 460; loss: 0.14; acc: 0.95
Batch: 480; loss: 0.26; acc: 0.91
Batch: 500; loss: 0.13; acc: 0.95
Batch: 520; loss: 0.36; acc: 0.86
Batch: 540; loss: 0.25; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.26; acc: 0.88
Batch: 600; loss: 0.34; acc: 0.89
Batch: 620; loss: 0.28; acc: 0.89
Batch: 640; loss: 0.19; acc: 0.97
Batch: 660; loss: 0.25; acc: 0.92
Batch: 680; loss: 0.22; acc: 0.94
Batch: 700; loss: 0.23; acc: 0.92
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.22; acc: 0.92
Batch: 780; loss: 0.16; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.94
Batch: 80; loss: 0.22; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.98
Batch: 120; loss: 0.46; acc: 0.88
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.20145257574262893; val_accuracy: 0.9389928343949044 

The current subspace-distance is: 0.00012796252849511802 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.34; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.89
Batch: 100; loss: 0.38; acc: 0.94
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.24; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.92
Batch: 200; loss: 0.33; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.27; acc: 0.95
Batch: 260; loss: 0.33; acc: 0.89
Batch: 280; loss: 0.07; acc: 1.0
Batch: 300; loss: 0.29; acc: 0.94
Batch: 320; loss: 0.23; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.91
Batch: 360; loss: 0.27; acc: 0.89
Batch: 380; loss: 0.32; acc: 0.91
Batch: 400; loss: 0.24; acc: 0.94
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.09; acc: 0.95
Batch: 520; loss: 0.44; acc: 0.91
Batch: 540; loss: 0.21; acc: 0.92
Batch: 560; loss: 0.29; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.86
Batch: 600; loss: 0.37; acc: 0.88
Batch: 620; loss: 0.28; acc: 0.94
Batch: 640; loss: 0.24; acc: 0.91
Batch: 660; loss: 0.36; acc: 0.92
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.22; acc: 0.94
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.94
Batch: 780; loss: 0.29; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.24; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.53; acc: 0.83
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.20734589322689612; val_accuracy: 0.9358081210191083 

The current subspace-distance is: 0.0001304716570302844 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.94
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.23; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.25; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.25; acc: 0.91
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.09; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.16; acc: 0.97
Batch: 360; loss: 0.35; acc: 0.89
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.95
Batch: 420; loss: 0.33; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.94
Batch: 560; loss: 0.32; acc: 0.92
Batch: 580; loss: 0.18; acc: 0.95
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.21; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.88
Batch: 700; loss: 0.14; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.37; acc: 0.89
Batch: 760; loss: 0.34; acc: 0.89
Batch: 780; loss: 0.24; acc: 0.91
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.09; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.92
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.5; acc: 0.83
Batch: 140; loss: 0.08; acc: 0.98
Val Epoch over. val_loss: 0.21258846743945864; val_accuracy: 0.9365047770700637 

The current subspace-distance is: 0.0001339825103059411 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.3; acc: 0.94
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.21; acc: 0.94
Batch: 60; loss: 0.3; acc: 0.97
Batch: 80; loss: 0.11; acc: 0.94
Batch: 100; loss: 0.24; acc: 0.97
Batch: 120; loss: 0.26; acc: 0.88
Batch: 140; loss: 0.1; acc: 0.98
Batch: 160; loss: 0.05; acc: 0.98
Batch: 180; loss: 0.48; acc: 0.91
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.16; acc: 0.97
Batch: 320; loss: 0.34; acc: 0.92
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.17; acc: 0.91
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.91
Batch: 440; loss: 0.34; acc: 0.89
Batch: 460; loss: 0.29; acc: 0.91
Batch: 480; loss: 0.27; acc: 0.92
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.14; acc: 0.98
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.26; acc: 0.88
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.29; acc: 0.91
Batch: 680; loss: 0.11; acc: 0.97
Batch: 700; loss: 0.17; acc: 0.92
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.2; acc: 0.95
Batch: 760; loss: 0.24; acc: 0.92
Batch: 780; loss: 0.18; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.08; acc: 0.97
Batch: 20; loss: 0.26; acc: 0.91
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.27; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.91
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.21597878493748274; val_accuracy: 0.9346138535031847 

The current subspace-distance is: 0.00013640862016472965 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.44; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.45; acc: 0.83
Batch: 60; loss: 0.36; acc: 0.91
Batch: 80; loss: 0.28; acc: 0.92
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.23; acc: 0.91
Batch: 140; loss: 0.16; acc: 0.89
Batch: 160; loss: 0.21; acc: 0.94
Batch: 180; loss: 0.28; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.89
Batch: 220; loss: 0.43; acc: 0.89
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.2; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.32; acc: 0.91
Batch: 420; loss: 0.09; acc: 0.98
Batch: 440; loss: 0.12; acc: 0.95
Batch: 460; loss: 0.36; acc: 0.91
Batch: 480; loss: 0.4; acc: 0.89
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.24; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.26; acc: 0.92
Batch: 640; loss: 0.17; acc: 0.95
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.17; acc: 0.94
Batch: 700; loss: 0.17; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.19; acc: 0.92
Train Epoch over. train_loss: 0.21; train_accuracy: 0.93 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19949441469588858; val_accuracy: 0.9378980891719745 

The current subspace-distance is: 0.00013940311328042299 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.24; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.94
Batch: 80; loss: 0.23; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.89
Batch: 120; loss: 0.21; acc: 0.92
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.3; acc: 0.92
Batch: 180; loss: 0.22; acc: 0.92
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.32; acc: 0.91
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.27; acc: 0.89
Batch: 300; loss: 0.41; acc: 0.86
Batch: 320; loss: 0.24; acc: 0.94
Batch: 340; loss: 0.2; acc: 0.97
Batch: 360; loss: 0.28; acc: 0.88
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.35; acc: 0.89
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.34; acc: 0.91
Batch: 460; loss: 0.17; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.15; acc: 0.95
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.45; acc: 0.88
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.2; acc: 0.92
Batch: 660; loss: 0.23; acc: 0.91
Batch: 680; loss: 0.21; acc: 0.92
Batch: 700; loss: 0.1; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.25; acc: 0.92
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.17; acc: 0.94
Batch: 120; loss: 0.44; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.19654663365073266; val_accuracy: 0.9391918789808917 

The current subspace-distance is: 0.000141885073389858 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.91
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.23; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.45; acc: 0.88
Batch: 160; loss: 0.22; acc: 0.92
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.39; acc: 0.91
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.21; acc: 0.94
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.92
Batch: 320; loss: 0.23; acc: 0.95
Batch: 340; loss: 0.27; acc: 0.88
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.91
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.15; acc: 0.95
Batch: 440; loss: 0.4; acc: 0.91
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.95
Batch: 500; loss: 0.2; acc: 0.92
Batch: 520; loss: 0.31; acc: 0.95
Batch: 540; loss: 0.2; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.94
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.28; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.11; acc: 0.97
Batch: 660; loss: 0.26; acc: 0.91
Batch: 680; loss: 0.18; acc: 0.92
Batch: 700; loss: 0.28; acc: 0.95
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.12; acc: 0.98
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.35; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.19366045853799316; val_accuracy: 0.9404856687898089 

The current subspace-distance is: 0.00014506507432088256 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.08; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.92
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.38; acc: 0.92
Batch: 240; loss: 0.27; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.12; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.97
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.13; acc: 0.98
Batch: 360; loss: 0.24; acc: 0.94
Batch: 380; loss: 0.12; acc: 0.95
Batch: 400; loss: 0.25; acc: 0.88
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.12; acc: 0.94
Batch: 480; loss: 0.31; acc: 0.88
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.42; acc: 0.81
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.05; acc: 0.98
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.3; acc: 0.94
Batch: 620; loss: 0.27; acc: 0.94
Batch: 640; loss: 0.27; acc: 0.91
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.32; acc: 0.91
Batch: 700; loss: 0.12; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.46; acc: 0.91
Batch: 780; loss: 0.26; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.19563972051878264; val_accuracy: 0.9395899681528662 

The current subspace-distance is: 0.0001476135803386569 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.27; acc: 0.92
Batch: 40; loss: 0.07; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.91
Batch: 100; loss: 0.23; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.2; acc: 0.94
Batch: 180; loss: 0.19; acc: 0.94
Batch: 200; loss: 0.11; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.37; acc: 0.92
Batch: 260; loss: 0.27; acc: 0.91
Batch: 280; loss: 0.1; acc: 0.95
Batch: 300; loss: 0.23; acc: 0.95
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.33; acc: 0.91
Batch: 400; loss: 0.15; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.95
Batch: 460; loss: 0.15; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.91
Batch: 560; loss: 0.17; acc: 0.95
Batch: 580; loss: 0.12; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.11; acc: 0.95
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.15; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.91
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.06; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.25; acc: 0.89
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.48; acc: 0.81
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.1959239297730338; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 0.0001506581174908206 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.09; acc: 0.95
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.33; acc: 0.91
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.24; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.94
Batch: 160; loss: 0.17; acc: 0.94
Batch: 180; loss: 0.18; acc: 0.91
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.26; acc: 0.89
Batch: 240; loss: 0.35; acc: 0.91
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.11; acc: 0.97
Batch: 300; loss: 0.31; acc: 0.88
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.17; acc: 0.98
Batch: 360; loss: 0.39; acc: 0.92
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.08; acc: 0.98
Batch: 420; loss: 0.26; acc: 0.89
Batch: 440; loss: 0.22; acc: 0.92
Batch: 460; loss: 0.22; acc: 0.94
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.11; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.95
Batch: 540; loss: 0.41; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.95
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.12; acc: 0.98
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.97
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.44; acc: 0.86
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.97
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19566259445373418; val_accuracy: 0.9392914012738853 

The current subspace-distance is: 0.00015249867283273488 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.33; acc: 0.88
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.98
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.49; acc: 0.88
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.19; acc: 0.95
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.97
Batch: 300; loss: 0.43; acc: 0.89
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.15; acc: 0.94
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.23; acc: 0.92
Batch: 460; loss: 0.19; acc: 0.94
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.34; acc: 0.91
Batch: 540; loss: 0.19; acc: 0.95
Batch: 560; loss: 0.21; acc: 0.92
Batch: 580; loss: 0.3; acc: 0.94
Batch: 600; loss: 0.33; acc: 0.91
Batch: 620; loss: 0.19; acc: 0.94
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.27; acc: 0.94
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.94
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.19838791706000164; val_accuracy: 0.9392914012738853 

The current subspace-distance is: 0.00015527271898463368 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.92
Batch: 40; loss: 0.4; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.91
Batch: 80; loss: 0.23; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.97
Batch: 160; loss: 0.31; acc: 0.91
Batch: 180; loss: 0.22; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.29; acc: 0.88
Batch: 300; loss: 0.2; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.97
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.28; acc: 0.92
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.26; acc: 0.94
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.14; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.33; acc: 0.91
Batch: 580; loss: 0.14; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.95
Batch: 640; loss: 0.2; acc: 0.94
Batch: 660; loss: 0.13; acc: 0.92
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.07; acc: 1.0
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.35; acc: 0.92
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.84
Batch: 140; loss: 0.07; acc: 0.97
Val Epoch over. val_loss: 0.19465186814688573; val_accuracy: 0.9396894904458599 

The current subspace-distance is: 0.00015771850303281099 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.27; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.89
Batch: 40; loss: 0.25; acc: 0.91
Batch: 60; loss: 0.24; acc: 0.88
Batch: 80; loss: 0.31; acc: 0.88
Batch: 100; loss: 0.06; acc: 0.98
Batch: 120; loss: 0.09; acc: 0.98
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.27; acc: 0.94
Batch: 200; loss: 0.21; acc: 0.94
Batch: 220; loss: 0.32; acc: 0.94
Batch: 240; loss: 0.21; acc: 0.89
Batch: 260; loss: 0.3; acc: 0.91
Batch: 280; loss: 0.33; acc: 0.86
Batch: 300; loss: 0.32; acc: 0.92
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.09; acc: 0.97
Batch: 400; loss: 0.33; acc: 0.91
Batch: 420; loss: 0.33; acc: 0.89
Batch: 440; loss: 0.1; acc: 0.98
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.3; acc: 0.92
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.12; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.97
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.05; acc: 1.0
Batch: 660; loss: 0.18; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.3; acc: 0.94
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.1; acc: 0.95
Batch: 760; loss: 0.27; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.44; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19729901660399832; val_accuracy: 0.9394904458598726 

The current subspace-distance is: 0.00015999573224689811 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.09; acc: 0.98
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.94
Batch: 160; loss: 0.1; acc: 0.97
Batch: 180; loss: 0.38; acc: 0.89
Batch: 200; loss: 0.4; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.92
Batch: 260; loss: 0.23; acc: 0.88
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.22; acc: 0.95
Batch: 320; loss: 0.37; acc: 0.89
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.13; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.26; acc: 0.92
Batch: 420; loss: 0.12; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.33; acc: 0.88
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.25; acc: 0.91
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.15; acc: 0.92
Batch: 580; loss: 0.13; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.91
Batch: 640; loss: 0.37; acc: 0.89
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.89
Batch: 700; loss: 0.19; acc: 0.94
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.07; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.19804315878802045; val_accuracy: 0.9377985668789809 

The current subspace-distance is: 0.00016239458636846393 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.11; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.18; acc: 0.92
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.13; acc: 0.95
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.25; acc: 0.89
Batch: 240; loss: 0.15; acc: 0.97
Batch: 260; loss: 0.16; acc: 0.97
Batch: 280; loss: 0.21; acc: 0.97
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.92
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.97
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.52; acc: 0.83
Batch: 480; loss: 0.24; acc: 0.94
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.35; acc: 0.89
Batch: 540; loss: 0.1; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.16; acc: 0.95
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.31; acc: 0.91
Batch: 660; loss: 0.22; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.94
Batch: 700; loss: 0.15; acc: 0.92
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.22; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.91
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.05; acc: 1.0
Batch: 20; loss: 0.2; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1920766375579272; val_accuracy: 0.939390923566879 

The current subspace-distance is: 0.00016434573626611382 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.21; acc: 0.91
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.43; acc: 0.89
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.92
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.33; acc: 0.92
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.3; acc: 0.94
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.15; acc: 0.97
Batch: 400; loss: 0.21; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.13; acc: 0.94
Batch: 460; loss: 0.22; acc: 0.92
Batch: 480; loss: 0.2; acc: 0.91
Batch: 500; loss: 0.29; acc: 0.91
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.94
Batch: 560; loss: 0.21; acc: 0.88
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.26; acc: 0.89
Batch: 620; loss: 0.23; acc: 0.92
Batch: 640; loss: 0.09; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.98
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.91
Batch: 720; loss: 0.31; acc: 0.91
Batch: 740; loss: 0.2; acc: 0.94
Batch: 760; loss: 0.24; acc: 0.95
Batch: 780; loss: 0.09; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.97
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19199948106554282; val_accuracy: 0.939390923566879 

The current subspace-distance is: 0.00016695988597348332 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.22; acc: 0.92
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.22; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.26; acc: 0.89
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.14; acc: 0.97
Batch: 180; loss: 0.16; acc: 0.97
Batch: 200; loss: 0.35; acc: 0.89
Batch: 220; loss: 0.12; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.28; acc: 0.95
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.14; acc: 0.98
Batch: 320; loss: 0.25; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.27; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.95
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.23; acc: 0.89
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.5; acc: 0.88
Batch: 500; loss: 0.25; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.27; acc: 0.88
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.97
Batch: 600; loss: 0.27; acc: 0.89
Batch: 620; loss: 0.18; acc: 0.94
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.06; acc: 1.0
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.22; acc: 0.92
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.35; acc: 0.89
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19246807154623946; val_accuracy: 0.9396894904458599 

The current subspace-distance is: 0.00016853569832164794 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.08; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.2; acc: 0.94
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.19; acc: 0.92
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.19; acc: 0.91
Batch: 220; loss: 0.33; acc: 0.88
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.33; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.95
Batch: 300; loss: 0.12; acc: 0.94
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.23; acc: 0.94
Batch: 360; loss: 0.19; acc: 0.94
Batch: 380; loss: 0.24; acc: 0.94
Batch: 400; loss: 0.2; acc: 0.97
Batch: 420; loss: 0.26; acc: 0.94
Batch: 440; loss: 0.16; acc: 0.97
Batch: 460; loss: 0.27; acc: 0.92
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.26; acc: 0.92
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.28; acc: 0.92
Batch: 600; loss: 0.25; acc: 0.94
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.2; acc: 0.92
Batch: 680; loss: 0.09; acc: 0.97
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.14; acc: 0.98
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.22; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.21; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19364242464493794; val_accuracy: 0.9390923566878981 

The current subspace-distance is: 0.00017085949366446584 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.36; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.97
Batch: 60; loss: 0.2; acc: 0.89
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.15; acc: 0.97
Batch: 120; loss: 0.24; acc: 0.91
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.28; acc: 0.89
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.25; acc: 0.98
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.51; acc: 0.91
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.14; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.38; acc: 0.86
Batch: 440; loss: 0.23; acc: 0.94
Batch: 460; loss: 0.15; acc: 0.95
Batch: 480; loss: 0.29; acc: 0.92
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.37; acc: 0.89
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.46; acc: 0.89
Batch: 600; loss: 0.14; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.94
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.2; acc: 0.92
Batch: 740; loss: 0.27; acc: 0.94
Batch: 760; loss: 0.06; acc: 1.0
Batch: 780; loss: 0.15; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19485619492164463; val_accuracy: 0.9404856687898089 

The current subspace-distance is: 0.00017333250434603542 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.38; acc: 0.91
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.05; acc: 0.98
Batch: 100; loss: 0.22; acc: 0.91
Batch: 120; loss: 0.12; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.92
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.34; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.94
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.35; acc: 0.88
Batch: 280; loss: 0.35; acc: 0.91
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.26; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.92
Batch: 380; loss: 0.17; acc: 0.95
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.43; acc: 0.88
Batch: 460; loss: 0.21; acc: 0.94
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.16; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.92
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.32; acc: 0.91
Batch: 600; loss: 0.06; acc: 0.97
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.29; acc: 0.97
Batch: 660; loss: 0.14; acc: 0.92
Batch: 680; loss: 0.1; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.15; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.12; acc: 0.95
Batch: 780; loss: 0.37; acc: 0.88
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19191829551746892; val_accuracy: 0.9400875796178344 

The current subspace-distance is: 0.00017568380280863494 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.09; acc: 0.97
Batch: 40; loss: 0.27; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.23; acc: 0.92
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.2; acc: 0.95
Batch: 140; loss: 0.21; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.94
Batch: 180; loss: 0.31; acc: 0.89
Batch: 200; loss: 0.31; acc: 0.95
Batch: 220; loss: 0.12; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.27; acc: 0.92
Batch: 340; loss: 0.24; acc: 0.91
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.09; acc: 0.95
Batch: 400; loss: 0.07; acc: 0.97
Batch: 420; loss: 0.22; acc: 0.95
Batch: 440; loss: 0.16; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.91
Batch: 480; loss: 0.16; acc: 0.97
Batch: 500; loss: 0.21; acc: 0.94
Batch: 520; loss: 0.15; acc: 0.94
Batch: 540; loss: 0.33; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.17; acc: 0.91
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.17; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.95
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.19; acc: 0.92
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.08; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.19; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1924450390373066; val_accuracy: 0.9399880573248408 

The current subspace-distance is: 0.000177338850335218 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.21; acc: 0.97
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.27; acc: 0.91
Batch: 80; loss: 0.2; acc: 0.95
Batch: 100; loss: 0.22; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.89
Batch: 140; loss: 0.28; acc: 0.91
Batch: 160; loss: 0.21; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.19; acc: 0.94
Batch: 220; loss: 0.19; acc: 0.94
Batch: 240; loss: 0.3; acc: 0.92
Batch: 260; loss: 0.18; acc: 0.92
Batch: 280; loss: 0.3; acc: 0.91
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.12; acc: 0.97
Batch: 340; loss: 0.06; acc: 0.98
Batch: 360; loss: 0.15; acc: 0.94
Batch: 380; loss: 0.21; acc: 0.94
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.09; acc: 0.97
Batch: 440; loss: 0.21; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.08; acc: 0.97
Batch: 500; loss: 0.16; acc: 0.95
Batch: 520; loss: 0.32; acc: 0.91
Batch: 540; loss: 0.22; acc: 0.91
Batch: 560; loss: 0.43; acc: 0.91
Batch: 580; loss: 0.19; acc: 0.92
Batch: 600; loss: 0.08; acc: 0.97
Batch: 620; loss: 0.19; acc: 0.92
Batch: 640; loss: 0.24; acc: 0.92
Batch: 660; loss: 0.34; acc: 0.86
Batch: 680; loss: 0.25; acc: 0.91
Batch: 700; loss: 0.1; acc: 0.97
Batch: 720; loss: 0.26; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.95
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.18; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.21; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1919171941128506; val_accuracy: 0.9398885350318471 

The current subspace-distance is: 0.0001795468560885638 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.89
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.23; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.92
Batch: 80; loss: 0.25; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.97
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.13; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.35; acc: 0.92
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.97
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.14; acc: 0.97
Batch: 380; loss: 0.16; acc: 0.95
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.22; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.97
Batch: 460; loss: 0.4; acc: 0.89
Batch: 480; loss: 0.24; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.95
Batch: 540; loss: 0.24; acc: 0.92
Batch: 560; loss: 0.3; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.21; acc: 0.91
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.17; acc: 0.95
Batch: 720; loss: 0.21; acc: 0.92
Batch: 740; loss: 0.22; acc: 0.94
Batch: 760; loss: 0.27; acc: 0.92
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.2; acc: 0.97
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.42; acc: 0.86
Batch: 140; loss: 0.05; acc: 0.97
Val Epoch over. val_loss: 0.19244407743785033; val_accuracy: 0.9399880573248408 

The current subspace-distance is: 0.0001823554775910452 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.11; acc: 0.95
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.29; acc: 0.89
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.14; acc: 0.92
Batch: 140; loss: 0.22; acc: 0.91
Batch: 160; loss: 0.26; acc: 0.91
Batch: 180; loss: 0.35; acc: 0.89
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.16; acc: 0.94
Batch: 240; loss: 0.22; acc: 0.88
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.94
Batch: 300; loss: 0.05; acc: 1.0
Batch: 320; loss: 0.25; acc: 0.92
Batch: 340; loss: 0.2; acc: 0.92
Batch: 360; loss: 0.28; acc: 0.91
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.37; acc: 0.86
Batch: 420; loss: 0.34; acc: 0.89
Batch: 440; loss: 0.19; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.13; acc: 0.94
Batch: 600; loss: 0.27; acc: 0.92
Batch: 620; loss: 0.1; acc: 0.97
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.19; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.94
Batch: 700; loss: 0.31; acc: 0.95
Batch: 720; loss: 0.22; acc: 0.92
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.18; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.21; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.95
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.45; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.19283782750083384; val_accuracy: 0.940187101910828 

The current subspace-distance is: 0.00018469341739546508 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.29; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.08; acc: 0.98
Batch: 140; loss: 0.14; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.94
Batch: 180; loss: 0.12; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.35; acc: 0.88
Batch: 240; loss: 0.13; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.18; acc: 0.92
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.18; acc: 0.95
Batch: 340; loss: 0.1; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.19; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.2; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.92
Batch: 480; loss: 0.42; acc: 0.89
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.24; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.95
Batch: 560; loss: 0.11; acc: 0.97
Batch: 580; loss: 0.38; acc: 0.88
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.15; acc: 0.98
Batch: 640; loss: 0.34; acc: 0.92
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.97
Batch: 720; loss: 0.19; acc: 0.92
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.43; acc: 0.91
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.24; acc: 0.94
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.22; acc: 0.94
Batch: 80; loss: 0.19; acc: 0.97
Batch: 100; loss: 0.18; acc: 0.95
Batch: 120; loss: 0.43; acc: 0.88
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1945298415175669; val_accuracy: 0.9398885350318471 

The current subspace-distance is: 0.00018654139421414584 

plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_400_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
nonzero elements in E: 69957
elements in E: 9887000
fraction nonzero: 0.007075654900374229
Epoch 1 start
The current lr is: 1.0
Batch: 0; loss: 2.3; acc: 0.16
Batch: 20; loss: 2.3; acc: 0.16
Batch: 40; loss: 2.3; acc: 0.16
Batch: 60; loss: 2.3; acc: 0.12
Batch: 80; loss: 2.3; acc: 0.12
Batch: 100; loss: 2.3; acc: 0.08
Batch: 120; loss: 2.31; acc: 0.05
Batch: 140; loss: 2.29; acc: 0.2
Batch: 160; loss: 2.3; acc: 0.12
Batch: 180; loss: 2.3; acc: 0.11
Batch: 200; loss: 2.28; acc: 0.2
Batch: 220; loss: 2.28; acc: 0.2
Batch: 240; loss: 2.29; acc: 0.14
Batch: 260; loss: 2.27; acc: 0.14
Batch: 280; loss: 2.29; acc: 0.06
Batch: 300; loss: 2.27; acc: 0.12
Batch: 320; loss: 2.26; acc: 0.12
Batch: 340; loss: 2.26; acc: 0.12
Batch: 360; loss: 2.23; acc: 0.16
Batch: 380; loss: 2.11; acc: 0.23
Batch: 400; loss: 2.07; acc: 0.25
Batch: 420; loss: 2.08; acc: 0.12
Batch: 440; loss: 1.9; acc: 0.33
Batch: 460; loss: 1.63; acc: 0.47
Batch: 480; loss: 1.84; acc: 0.3
Batch: 500; loss: 1.53; acc: 0.42
Batch: 520; loss: 1.66; acc: 0.38
Batch: 540; loss: 1.52; acc: 0.53
Batch: 560; loss: 1.49; acc: 0.44
Batch: 580; loss: 1.11; acc: 0.72
Batch: 600; loss: 1.19; acc: 0.58
Batch: 620; loss: 0.74; acc: 0.73
Batch: 640; loss: 0.81; acc: 0.75
Batch: 660; loss: 1.15; acc: 0.66
Batch: 680; loss: 0.55; acc: 0.89
Batch: 700; loss: 0.68; acc: 0.83
Batch: 720; loss: 1.15; acc: 0.66
Batch: 740; loss: 0.97; acc: 0.59
Batch: 760; loss: 0.75; acc: 0.8
Batch: 780; loss: 0.84; acc: 0.78
Train Epoch over. train_loss: 1.79; train_accuracy: 0.35 

Batch: 0; loss: 0.82; acc: 0.73
Batch: 20; loss: 0.99; acc: 0.69
Batch: 40; loss: 0.56; acc: 0.86
Batch: 60; loss: 0.71; acc: 0.75
Batch: 80; loss: 0.71; acc: 0.77
Batch: 100; loss: 0.73; acc: 0.75
Batch: 120; loss: 0.95; acc: 0.69
Batch: 140; loss: 0.61; acc: 0.83
Val Epoch over. val_loss: 0.7407239740061912; val_accuracy: 0.7623407643312102 

The current subspace-distance is: 1.4718206330144312e-05 

Epoch 2 start
The current lr is: 1.0
Batch: 0; loss: 0.63; acc: 0.84
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.6; acc: 0.81
Batch: 60; loss: 0.66; acc: 0.77
Batch: 80; loss: 0.7; acc: 0.77
Batch: 100; loss: 0.65; acc: 0.78
Batch: 120; loss: 1.11; acc: 0.67
Batch: 140; loss: 0.56; acc: 0.83
Batch: 160; loss: 0.48; acc: 0.84
Batch: 180; loss: 0.47; acc: 0.88
Batch: 200; loss: 0.47; acc: 0.8
Batch: 220; loss: 0.58; acc: 0.83
Batch: 240; loss: 0.44; acc: 0.86
Batch: 260; loss: 0.89; acc: 0.77
Batch: 280; loss: 0.65; acc: 0.78
Batch: 300; loss: 0.87; acc: 0.8
Batch: 320; loss: 0.97; acc: 0.69
Batch: 340; loss: 0.83; acc: 0.72
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.89
Batch: 400; loss: 0.52; acc: 0.84
Batch: 420; loss: 0.44; acc: 0.86
Batch: 440; loss: 0.49; acc: 0.86
Batch: 460; loss: 0.49; acc: 0.83
Batch: 480; loss: 0.5; acc: 0.81
Batch: 500; loss: 0.41; acc: 0.81
Batch: 520; loss: 0.35; acc: 0.91
Batch: 540; loss: 0.31; acc: 0.91
Batch: 560; loss: 0.42; acc: 0.86
Batch: 580; loss: 0.38; acc: 0.84
Batch: 600; loss: 0.49; acc: 0.86
Batch: 620; loss: 0.58; acc: 0.81
Batch: 640; loss: 0.41; acc: 0.91
Batch: 660; loss: 0.43; acc: 0.81
Batch: 680; loss: 0.39; acc: 0.91
Batch: 700; loss: 0.44; acc: 0.86
Batch: 720; loss: 0.75; acc: 0.73
Batch: 740; loss: 0.53; acc: 0.83
Batch: 760; loss: 0.35; acc: 0.92
Batch: 780; loss: 0.5; acc: 0.8
Train Epoch over. train_loss: 0.54; train_accuracy: 0.83 

Batch: 0; loss: 0.45; acc: 0.88
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.27; acc: 0.94
Batch: 60; loss: 0.56; acc: 0.86
Batch: 80; loss: 0.43; acc: 0.88
Batch: 100; loss: 0.62; acc: 0.81
Batch: 120; loss: 0.89; acc: 0.73
Batch: 140; loss: 0.19; acc: 0.94
Val Epoch over. val_loss: 0.4736169854736632; val_accuracy: 0.8550955414012739 

The current subspace-distance is: 2.614349614304956e-05 

Epoch 3 start
The current lr is: 1.0
Batch: 0; loss: 0.48; acc: 0.83
Batch: 20; loss: 0.46; acc: 0.84
Batch: 40; loss: 0.4; acc: 0.88
Batch: 60; loss: 0.41; acc: 0.88
Batch: 80; loss: 0.52; acc: 0.88
Batch: 100; loss: 0.47; acc: 0.84
Batch: 120; loss: 0.42; acc: 0.88
Batch: 140; loss: 0.41; acc: 0.86
Batch: 160; loss: 0.6; acc: 0.86
Batch: 180; loss: 0.33; acc: 0.91
Batch: 200; loss: 0.29; acc: 0.91
Batch: 220; loss: 0.41; acc: 0.83
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.6; acc: 0.77
Batch: 280; loss: 0.41; acc: 0.88
Batch: 300; loss: 0.23; acc: 0.92
Batch: 320; loss: 0.71; acc: 0.73
Batch: 340; loss: 0.36; acc: 0.91
Batch: 360; loss: 0.51; acc: 0.88
Batch: 380; loss: 0.22; acc: 0.92
Batch: 400; loss: 0.33; acc: 0.88
Batch: 420; loss: 0.26; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.34; acc: 0.92
Batch: 500; loss: 0.31; acc: 0.92
Batch: 520; loss: 0.38; acc: 0.89
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.25; acc: 0.92
Batch: 600; loss: 0.3; acc: 0.92
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.34; acc: 0.88
Batch: 660; loss: 0.6; acc: 0.86
Batch: 680; loss: 0.17; acc: 0.97
Batch: 700; loss: 0.27; acc: 0.92
Batch: 720; loss: 0.35; acc: 0.86
Batch: 740; loss: 0.32; acc: 0.88
Batch: 760; loss: 0.49; acc: 0.86
Batch: 780; loss: 0.35; acc: 0.91
Train Epoch over. train_loss: 0.4; train_accuracy: 0.88 

Batch: 0; loss: 0.63; acc: 0.86
Batch: 20; loss: 0.62; acc: 0.81
Batch: 40; loss: 0.48; acc: 0.89
Batch: 60; loss: 0.72; acc: 0.86
Batch: 80; loss: 0.59; acc: 0.81
Batch: 100; loss: 0.78; acc: 0.8
Batch: 120; loss: 1.2; acc: 0.73
Batch: 140; loss: 0.4; acc: 0.83
Val Epoch over. val_loss: 0.6743528596155203; val_accuracy: 0.8053343949044586 

The current subspace-distance is: 3.5217919503338635e-05 

Epoch 4 start
The current lr is: 1.0
Batch: 0; loss: 0.56; acc: 0.83
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.26; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.61; acc: 0.84
Batch: 100; loss: 0.63; acc: 0.83
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.45; acc: 0.91
Batch: 160; loss: 0.55; acc: 0.81
Batch: 180; loss: 0.34; acc: 0.91
Batch: 200; loss: 0.43; acc: 0.91
Batch: 220; loss: 0.4; acc: 0.91
Batch: 240; loss: 0.39; acc: 0.88
Batch: 260; loss: 0.28; acc: 0.89
Batch: 280; loss: 0.42; acc: 0.84
Batch: 300; loss: 0.34; acc: 0.94
Batch: 320; loss: 0.38; acc: 0.89
Batch: 340; loss: 0.25; acc: 0.92
Batch: 360; loss: 0.31; acc: 0.91
Batch: 380; loss: 0.25; acc: 0.94
Batch: 400; loss: 0.23; acc: 0.95
Batch: 420; loss: 0.25; acc: 0.92
Batch: 440; loss: 0.44; acc: 0.86
Batch: 460; loss: 0.3; acc: 0.89
Batch: 480; loss: 0.44; acc: 0.83
Batch: 500; loss: 0.34; acc: 0.91
Batch: 520; loss: 0.39; acc: 0.86
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.43; acc: 0.88
Batch: 580; loss: 0.24; acc: 0.92
Batch: 600; loss: 0.19; acc: 0.92
Batch: 620; loss: 0.59; acc: 0.88
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.84
Batch: 680; loss: 0.23; acc: 0.97
Batch: 700; loss: 0.53; acc: 0.86
Batch: 720; loss: 0.38; acc: 0.84
Batch: 740; loss: 0.63; acc: 0.86
Batch: 760; loss: 0.26; acc: 0.91
Batch: 780; loss: 0.32; acc: 0.88
Train Epoch over. train_loss: 0.36; train_accuracy: 0.89 

Batch: 0; loss: 1.54; acc: 0.52
Batch: 20; loss: 1.91; acc: 0.48
Batch: 40; loss: 1.33; acc: 0.62
Batch: 60; loss: 1.84; acc: 0.55
Batch: 80; loss: 1.56; acc: 0.62
Batch: 100; loss: 1.71; acc: 0.47
Batch: 120; loss: 2.44; acc: 0.44
Batch: 140; loss: 0.93; acc: 0.66
Val Epoch over. val_loss: 1.5461362011873039; val_accuracy: 0.5642914012738853 

The current subspace-distance is: 4.2683921492425725e-05 

Epoch 5 start
The current lr is: 1.0
Batch: 0; loss: 1.71; acc: 0.53
Batch: 20; loss: 0.37; acc: 0.88
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.25; acc: 0.94
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.4; acc: 0.88
Batch: 120; loss: 0.59; acc: 0.8
Batch: 140; loss: 0.29; acc: 0.91
Batch: 160; loss: 0.28; acc: 0.91
Batch: 180; loss: 0.23; acc: 0.92
Batch: 200; loss: 0.4; acc: 0.88
Batch: 220; loss: 0.24; acc: 0.92
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.91
Batch: 280; loss: 0.31; acc: 0.92
Batch: 300; loss: 0.37; acc: 0.94
Batch: 320; loss: 0.44; acc: 0.89
Batch: 340; loss: 0.97; acc: 0.75
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.22; acc: 0.94
Batch: 400; loss: 0.34; acc: 0.89
Batch: 420; loss: 0.45; acc: 0.89
Batch: 440; loss: 0.34; acc: 0.86
Batch: 460; loss: 0.55; acc: 0.84
Batch: 480; loss: 0.22; acc: 0.89
Batch: 500; loss: 0.36; acc: 0.84
Batch: 520; loss: 0.46; acc: 0.84
Batch: 540; loss: 0.29; acc: 0.94
Batch: 560; loss: 0.38; acc: 0.88
Batch: 580; loss: 0.28; acc: 0.88
Batch: 600; loss: 0.31; acc: 0.89
Batch: 620; loss: 0.55; acc: 0.81
Batch: 640; loss: 0.29; acc: 0.89
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.35; acc: 0.91
Batch: 700; loss: 0.4; acc: 0.83
Batch: 720; loss: 0.35; acc: 0.88
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.32; acc: 0.92
Batch: 780; loss: 0.32; acc: 0.89
Train Epoch over. train_loss: 0.35; train_accuracy: 0.89 

Batch: 0; loss: 0.62; acc: 0.78
Batch: 20; loss: 0.45; acc: 0.86
Batch: 40; loss: 0.57; acc: 0.81
Batch: 60; loss: 0.65; acc: 0.81
Batch: 80; loss: 0.54; acc: 0.86
Batch: 100; loss: 0.58; acc: 0.8
Batch: 120; loss: 0.69; acc: 0.8
Batch: 140; loss: 0.1; acc: 0.98
Val Epoch over. val_loss: 0.5212415100852396; val_accuracy: 0.82703025477707 

The current subspace-distance is: 4.93392362841405e-05 

Epoch 6 start
The current lr is: 1.0
Batch: 0; loss: 0.45; acc: 0.84
Batch: 20; loss: 0.46; acc: 0.88
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.28; acc: 0.92
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.48; acc: 0.86
Batch: 140; loss: 0.61; acc: 0.83
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.41; acc: 0.89
Batch: 200; loss: 0.56; acc: 0.88
Batch: 220; loss: 0.48; acc: 0.86
Batch: 240; loss: 0.24; acc: 0.94
Batch: 260; loss: 0.22; acc: 0.92
Batch: 280; loss: 0.62; acc: 0.83
Batch: 300; loss: 0.39; acc: 0.88
Batch: 320; loss: 0.3; acc: 0.91
Batch: 340; loss: 0.22; acc: 0.92
Batch: 360; loss: 0.59; acc: 0.89
Batch: 380; loss: 0.26; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.98
Batch: 420; loss: 0.52; acc: 0.84
Batch: 440; loss: 0.41; acc: 0.88
Batch: 460; loss: 0.29; acc: 0.92
Batch: 480; loss: 0.39; acc: 0.86
Batch: 500; loss: 0.49; acc: 0.84
Batch: 520; loss: 0.18; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.33; acc: 0.88
Batch: 600; loss: 0.46; acc: 0.88
Batch: 620; loss: 0.13; acc: 0.95
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.21; acc: 0.91
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.85; acc: 0.72
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.92
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.32; train_accuracy: 0.9 

Batch: 0; loss: 0.22; acc: 0.97
Batch: 20; loss: 0.41; acc: 0.83
Batch: 40; loss: 0.35; acc: 0.92
Batch: 60; loss: 0.37; acc: 0.89
Batch: 80; loss: 0.37; acc: 0.84
Batch: 100; loss: 0.26; acc: 0.94
Batch: 120; loss: 0.67; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.97
Val Epoch over. val_loss: 0.3864390103110842; val_accuracy: 0.8781847133757962 

The current subspace-distance is: 5.5495223932666704e-05 

Epoch 7 start
The current lr is: 1.0
Batch: 0; loss: 0.47; acc: 0.88
Batch: 20; loss: 0.25; acc: 0.91
Batch: 40; loss: 0.5; acc: 0.86
Batch: 60; loss: 0.22; acc: 0.92
Batch: 80; loss: 0.37; acc: 0.89
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.24; acc: 0.92
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.23; acc: 0.89
Batch: 180; loss: 0.24; acc: 0.92
Batch: 200; loss: 0.22; acc: 0.92
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.26; acc: 0.92
Batch: 280; loss: 0.42; acc: 0.89
Batch: 300; loss: 0.37; acc: 0.89
Batch: 320; loss: 0.27; acc: 0.94
Batch: 340; loss: 0.23; acc: 0.92
Batch: 360; loss: 0.36; acc: 0.89
Batch: 380; loss: 0.42; acc: 0.88
Batch: 400; loss: 0.21; acc: 0.97
Batch: 420; loss: 0.23; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.45; acc: 0.88
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.31; acc: 0.91
Batch: 520; loss: 0.14; acc: 0.97
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.32; acc: 0.94
Batch: 580; loss: 0.43; acc: 0.88
Batch: 600; loss: 0.25; acc: 0.91
Batch: 620; loss: 0.44; acc: 0.89
Batch: 640; loss: 0.42; acc: 0.86
Batch: 660; loss: 0.33; acc: 0.88
Batch: 680; loss: 0.28; acc: 0.92
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.4; acc: 0.83
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.28; acc: 0.91
Train Epoch over. train_loss: 0.3; train_accuracy: 0.91 

Batch: 0; loss: 0.42; acc: 0.84
Batch: 20; loss: 0.41; acc: 0.84
Batch: 40; loss: 0.38; acc: 0.89
Batch: 60; loss: 0.74; acc: 0.84
Batch: 80; loss: 0.52; acc: 0.83
Batch: 100; loss: 0.52; acc: 0.88
Batch: 120; loss: 0.81; acc: 0.72
Batch: 140; loss: 0.06; acc: 0.97
Val Epoch over. val_loss: 0.4053860391211358; val_accuracy: 0.8761942675159236 

The current subspace-distance is: 6.131973350420594e-05 

Epoch 8 start
The current lr is: 1.0
Batch: 0; loss: 0.18; acc: 0.92
Batch: 20; loss: 0.39; acc: 0.92
Batch: 40; loss: 0.31; acc: 0.89
Batch: 60; loss: 0.3; acc: 0.91
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.92
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.55; acc: 0.83
Batch: 200; loss: 0.26; acc: 0.89
Batch: 220; loss: 0.26; acc: 0.88
Batch: 240; loss: 0.23; acc: 0.88
Batch: 260; loss: 0.12; acc: 0.95
Batch: 280; loss: 0.33; acc: 0.88
Batch: 300; loss: 0.29; acc: 0.91
Batch: 320; loss: 0.23; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.28; acc: 0.91
Batch: 400; loss: 0.18; acc: 0.94
Batch: 420; loss: 0.14; acc: 0.95
Batch: 440; loss: 0.3; acc: 0.89
Batch: 460; loss: 0.4; acc: 0.91
Batch: 480; loss: 0.19; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.92
Batch: 520; loss: 0.37; acc: 0.83
Batch: 540; loss: 0.19; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.89
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.13; acc: 0.94
Batch: 620; loss: 0.3; acc: 0.89
Batch: 640; loss: 0.34; acc: 0.89
Batch: 660; loss: 0.33; acc: 0.89
Batch: 680; loss: 0.36; acc: 0.89
Batch: 700; loss: 0.39; acc: 0.89
Batch: 720; loss: 0.44; acc: 0.88
Batch: 740; loss: 0.13; acc: 0.97
Batch: 760; loss: 0.09; acc: 0.98
Batch: 780; loss: 0.39; acc: 0.89
Train Epoch over. train_loss: 0.28; train_accuracy: 0.91 

Batch: 0; loss: 0.26; acc: 0.91
Batch: 20; loss: 0.7; acc: 0.75
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.32; acc: 0.89
Batch: 80; loss: 0.54; acc: 0.84
Batch: 100; loss: 0.6; acc: 0.81
Batch: 120; loss: 0.9; acc: 0.67
Batch: 140; loss: 0.27; acc: 0.94
Val Epoch over. val_loss: 0.5216270605469965; val_accuracy: 0.836484872611465 

The current subspace-distance is: 6.648217095062137e-05 

Epoch 9 start
The current lr is: 1.0
Batch: 0; loss: 0.55; acc: 0.84
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.29; acc: 0.89
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.31; acc: 0.92
Batch: 100; loss: 0.5; acc: 0.91
Batch: 120; loss: 0.39; acc: 0.91
Batch: 140; loss: 0.49; acc: 0.84
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.21; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.14; acc: 0.95
Batch: 240; loss: 0.46; acc: 0.89
Batch: 260; loss: 0.17; acc: 0.92
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.42; acc: 0.84
Batch: 320; loss: 0.45; acc: 0.91
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.27; acc: 0.92
Batch: 380; loss: 0.32; acc: 0.86
Batch: 400; loss: 0.21; acc: 0.91
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.17; acc: 0.95
Batch: 460; loss: 0.26; acc: 0.89
Batch: 480; loss: 0.41; acc: 0.86
Batch: 500; loss: 0.19; acc: 0.91
Batch: 520; loss: 0.26; acc: 0.91
Batch: 540; loss: 0.07; acc: 1.0
Batch: 560; loss: 0.26; acc: 0.91
Batch: 580; loss: 0.31; acc: 0.89
Batch: 600; loss: 0.21; acc: 0.92
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.44; acc: 0.89
Batch: 660; loss: 0.36; acc: 0.86
Batch: 680; loss: 0.27; acc: 0.92
Batch: 700; loss: 0.37; acc: 0.88
Batch: 720; loss: 0.63; acc: 0.83
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.37; acc: 0.88
Batch: 780; loss: 0.31; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.91 

Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.46; acc: 0.86
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.29; acc: 0.88
Batch: 80; loss: 0.24; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.89
Batch: 120; loss: 0.54; acc: 0.83
Batch: 140; loss: 0.07; acc: 0.98
Val Epoch over. val_loss: 0.23550771620527955; val_accuracy: 0.9267515923566879 

The current subspace-distance is: 7.236257079057395e-05 

Epoch 10 start
The current lr is: 1.0
Batch: 0; loss: 0.23; acc: 0.94
Batch: 20; loss: 0.19; acc: 0.95
Batch: 40; loss: 0.27; acc: 0.91
Batch: 60; loss: 0.23; acc: 0.94
Batch: 80; loss: 0.33; acc: 0.89
Batch: 100; loss: 0.25; acc: 0.89
Batch: 120; loss: 0.28; acc: 0.92
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.48; acc: 0.88
Batch: 180; loss: 0.24; acc: 0.89
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.41; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.22; acc: 0.97
Batch: 280; loss: 0.29; acc: 0.91
Batch: 300; loss: 0.1; acc: 0.97
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.4; acc: 0.86
Batch: 360; loss: 0.41; acc: 0.86
Batch: 380; loss: 0.35; acc: 0.91
Batch: 400; loss: 0.44; acc: 0.86
Batch: 420; loss: 0.28; acc: 0.95
Batch: 440; loss: 0.32; acc: 0.89
Batch: 460; loss: 0.5; acc: 0.88
Batch: 480; loss: 0.16; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.27; acc: 0.91
Batch: 580; loss: 0.22; acc: 0.95
Batch: 600; loss: 0.15; acc: 0.95
Batch: 620; loss: 0.2; acc: 0.95
Batch: 640; loss: 0.16; acc: 0.95
Batch: 660; loss: 0.27; acc: 0.89
Batch: 680; loss: 0.4; acc: 0.86
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.16; acc: 0.92
Batch: 740; loss: 0.42; acc: 0.88
Batch: 760; loss: 0.24; acc: 0.91
Batch: 780; loss: 0.22; acc: 0.91
Train Epoch over. train_loss: 0.27; train_accuracy: 0.92 

Batch: 0; loss: 0.12; acc: 0.98
Batch: 20; loss: 0.33; acc: 0.94
Batch: 40; loss: 0.17; acc: 0.95
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.14; acc: 0.94
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.21425587039701877; val_accuracy: 0.9327229299363057 

The current subspace-distance is: 7.715241372352466e-05 

Epoch 11 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.38; acc: 0.91
Batch: 40; loss: 0.15; acc: 0.97
Batch: 60; loss: 0.32; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.97
Batch: 100; loss: 0.2; acc: 0.91
Batch: 120; loss: 0.27; acc: 0.91
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.46; acc: 0.91
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.23; acc: 0.92
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.35; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.25; acc: 0.95
Batch: 360; loss: 0.19; acc: 0.97
Batch: 380; loss: 0.24; acc: 0.92
Batch: 400; loss: 0.19; acc: 0.91
Batch: 420; loss: 0.53; acc: 0.86
Batch: 440; loss: 0.11; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.15; acc: 0.97
Batch: 500; loss: 0.48; acc: 0.89
Batch: 520; loss: 0.16; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.19; acc: 0.94
Batch: 600; loss: 0.2; acc: 0.91
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.21; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.16; acc: 0.95
Batch: 720; loss: 0.42; acc: 0.88
Batch: 740; loss: 0.12; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.89
Batch: 780; loss: 0.28; acc: 0.94
Train Epoch over. train_loss: 0.21; train_accuracy: 0.94 

Batch: 0; loss: 0.08; acc: 0.98
Batch: 20; loss: 0.37; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.94
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.18; acc: 0.94
Batch: 100; loss: 0.29; acc: 0.89
Batch: 120; loss: 0.45; acc: 0.83
Batch: 140; loss: 0.06; acc: 0.98
Val Epoch over. val_loss: 0.2139518297852794; val_accuracy: 0.9346138535031847 

The current subspace-distance is: 8.218756556743756e-05 

Epoch 12 start
The current lr is: 0.4
Batch: 0; loss: 0.39; acc: 0.86
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.33; acc: 0.91
Batch: 60; loss: 0.28; acc: 0.91
Batch: 80; loss: 0.1; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.91
Batch: 120; loss: 0.26; acc: 0.92
Batch: 140; loss: 0.32; acc: 0.92
Batch: 160; loss: 0.28; acc: 0.94
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.92
Batch: 220; loss: 0.08; acc: 0.98
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.94
Batch: 300; loss: 0.22; acc: 0.91
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.29; acc: 0.92
Batch: 400; loss: 0.21; acc: 0.95
Batch: 420; loss: 0.17; acc: 0.92
Batch: 440; loss: 0.07; acc: 0.98
Batch: 460; loss: 0.25; acc: 0.97
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.12; acc: 0.98
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.26; acc: 0.94
Batch: 580; loss: 0.45; acc: 0.88
Batch: 600; loss: 0.15; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.86
Batch: 640; loss: 0.15; acc: 0.92
Batch: 660; loss: 0.1; acc: 0.95
Batch: 680; loss: 0.3; acc: 0.92
Batch: 700; loss: 0.26; acc: 0.92
Batch: 720; loss: 0.13; acc: 0.97
Batch: 740; loss: 0.47; acc: 0.88
Batch: 760; loss: 0.18; acc: 0.92
Batch: 780; loss: 0.2; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.25; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.91
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.4; acc: 0.88
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.1970865501885771; val_accuracy: 0.9388933121019108 

The current subspace-distance is: 8.657342550577596e-05 

Epoch 13 start
The current lr is: 0.4
Batch: 0; loss: 0.07; acc: 1.0
Batch: 20; loss: 0.21; acc: 0.92
Batch: 40; loss: 0.23; acc: 0.94
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.12; acc: 0.94
Batch: 100; loss: 0.2; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.22; acc: 0.91
Batch: 180; loss: 0.14; acc: 0.97
Batch: 200; loss: 0.04; acc: 1.0
Batch: 220; loss: 0.3; acc: 0.91
Batch: 240; loss: 0.18; acc: 0.91
Batch: 260; loss: 0.16; acc: 0.95
Batch: 280; loss: 0.31; acc: 0.89
Batch: 300; loss: 0.26; acc: 0.91
Batch: 320; loss: 0.26; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.95
Batch: 360; loss: 0.44; acc: 0.94
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.11; acc: 0.94
Batch: 420; loss: 0.23; acc: 0.92
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.19; acc: 0.95
Batch: 520; loss: 0.41; acc: 0.89
Batch: 540; loss: 0.08; acc: 0.97
Batch: 560; loss: 0.11; acc: 0.95
Batch: 580; loss: 0.06; acc: 0.98
Batch: 600; loss: 0.33; acc: 0.94
Batch: 620; loss: 0.35; acc: 0.92
Batch: 640; loss: 0.26; acc: 0.91
Batch: 660; loss: 0.23; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.16; acc: 0.92
Batch: 720; loss: 0.28; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.24; acc: 0.97
Batch: 780; loss: 0.41; acc: 0.88
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.43; acc: 0.86
Batch: 40; loss: 0.25; acc: 0.92
Batch: 60; loss: 0.33; acc: 0.89
Batch: 80; loss: 0.15; acc: 0.97
Batch: 100; loss: 0.47; acc: 0.89
Batch: 120; loss: 0.72; acc: 0.77
Batch: 140; loss: 0.13; acc: 0.94
Val Epoch over. val_loss: 0.317998314050922; val_accuracy: 0.9009753184713376 

The current subspace-distance is: 9.126713848672807e-05 

Epoch 14 start
The current lr is: 0.4
Batch: 0; loss: 0.18; acc: 0.95
Batch: 20; loss: 0.28; acc: 0.92
Batch: 40; loss: 0.22; acc: 0.94
Batch: 60; loss: 0.15; acc: 0.95
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.3; acc: 0.89
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.12; acc: 0.94
Batch: 160; loss: 0.19; acc: 0.94
Batch: 180; loss: 0.29; acc: 0.89
Batch: 200; loss: 0.2; acc: 0.91
Batch: 220; loss: 0.23; acc: 0.94
Batch: 240; loss: 0.11; acc: 0.98
Batch: 260; loss: 0.21; acc: 0.92
Batch: 280; loss: 0.17; acc: 0.95
Batch: 300; loss: 0.19; acc: 0.94
Batch: 320; loss: 0.25; acc: 0.88
Batch: 340; loss: 0.13; acc: 0.95
Batch: 360; loss: 0.08; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.92
Batch: 400; loss: 0.3; acc: 0.94
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.21; acc: 0.94
Batch: 460; loss: 0.33; acc: 0.91
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.18; acc: 0.95
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.19; acc: 0.95
Batch: 580; loss: 0.48; acc: 0.88
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.28; acc: 0.92
Batch: 660; loss: 0.3; acc: 0.89
Batch: 680; loss: 0.22; acc: 0.95
Batch: 700; loss: 0.29; acc: 0.89
Batch: 720; loss: 0.21; acc: 0.91
Batch: 740; loss: 0.12; acc: 0.95
Batch: 760; loss: 0.23; acc: 0.92
Batch: 780; loss: 0.13; acc: 0.95
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.29; acc: 0.91
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.28; acc: 0.89
Batch: 80; loss: 0.17; acc: 0.92
Batch: 100; loss: 0.39; acc: 0.91
Batch: 120; loss: 0.61; acc: 0.81
Batch: 140; loss: 0.03; acc: 0.98
Val Epoch over. val_loss: 0.2090544733604428; val_accuracy: 0.93640525477707 

The current subspace-distance is: 9.574754221830517e-05 

Epoch 15 start
The current lr is: 0.4
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.34; acc: 0.88
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.14; acc: 0.97
Batch: 80; loss: 0.25; acc: 0.94
Batch: 100; loss: 0.12; acc: 0.95
Batch: 120; loss: 0.21; acc: 0.94
Batch: 140; loss: 0.15; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.09; acc: 0.97
Batch: 200; loss: 0.31; acc: 0.91
Batch: 220; loss: 0.24; acc: 0.91
Batch: 240; loss: 0.09; acc: 0.97
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.2; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.39; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.16; acc: 0.95
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.94
Batch: 420; loss: 0.28; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.95
Batch: 460; loss: 0.2; acc: 0.94
Batch: 480; loss: 0.13; acc: 0.98
Batch: 500; loss: 0.49; acc: 0.89
Batch: 520; loss: 0.23; acc: 0.89
Batch: 540; loss: 0.25; acc: 0.88
Batch: 560; loss: 0.24; acc: 0.91
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.37; acc: 0.91
Batch: 620; loss: 0.24; acc: 0.94
Batch: 640; loss: 0.2; acc: 0.95
Batch: 660; loss: 0.31; acc: 0.92
Batch: 680; loss: 0.06; acc: 0.98
Batch: 700; loss: 0.16; acc: 0.98
Batch: 720; loss: 0.23; acc: 0.89
Batch: 740; loss: 0.25; acc: 0.94
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.5; acc: 0.91
Train Epoch over. train_loss: 0.2; train_accuracy: 0.94 

Batch: 0; loss: 0.13; acc: 0.95
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.26; acc: 0.92
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.91
Batch: 120; loss: 0.38; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.18168419883082246; val_accuracy: 0.9425756369426752 

The current subspace-distance is: 9.913732355926186e-05 

Epoch 16 start
The current lr is: 0.4
Batch: 0; loss: 0.27; acc: 0.92
Batch: 20; loss: 0.33; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.92
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.12; acc: 0.97
Batch: 120; loss: 0.31; acc: 0.91
Batch: 140; loss: 0.33; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.92
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.15; acc: 0.97
Batch: 220; loss: 0.27; acc: 0.95
Batch: 240; loss: 0.09; acc: 0.98
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.09; acc: 0.97
Batch: 300; loss: 0.18; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.24; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.31; acc: 0.89
Batch: 420; loss: 0.18; acc: 0.94
Batch: 440; loss: 0.29; acc: 0.94
Batch: 460; loss: 0.11; acc: 0.98
Batch: 480; loss: 0.06; acc: 0.98
Batch: 500; loss: 0.42; acc: 0.89
Batch: 520; loss: 0.05; acc: 0.98
Batch: 540; loss: 0.27; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.15; acc: 0.91
Batch: 600; loss: 0.05; acc: 1.0
Batch: 620; loss: 0.15; acc: 0.95
Batch: 640; loss: 0.39; acc: 0.89
Batch: 660; loss: 0.08; acc: 0.98
Batch: 680; loss: 0.21; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.95
Batch: 720; loss: 0.27; acc: 0.88
Batch: 740; loss: 0.19; acc: 0.97
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.27; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.18; acc: 0.94
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.36; acc: 0.92
Batch: 120; loss: 0.54; acc: 0.84
Batch: 140; loss: 0.05; acc: 0.98
Val Epoch over. val_loss: 0.1978688659798947; val_accuracy: 0.9402866242038217 

The current subspace-distance is: 0.00010291396756656468 

Epoch 17 start
The current lr is: 0.4
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.24; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.98
Batch: 80; loss: 0.42; acc: 0.89
Batch: 100; loss: 0.15; acc: 0.92
Batch: 120; loss: 0.25; acc: 0.95
Batch: 140; loss: 0.31; acc: 0.94
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.17; acc: 0.94
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.25; acc: 0.92
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.39; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.91
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.32; acc: 0.94
Batch: 360; loss: 0.23; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.13; acc: 0.95
Batch: 420; loss: 0.35; acc: 0.91
Batch: 440; loss: 0.18; acc: 0.95
Batch: 460; loss: 0.28; acc: 0.88
Batch: 480; loss: 0.17; acc: 0.94
Batch: 500; loss: 0.06; acc: 1.0
Batch: 520; loss: 0.28; acc: 0.92
Batch: 540; loss: 0.11; acc: 0.95
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.36; acc: 0.89
Batch: 600; loss: 0.36; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.94
Batch: 640; loss: 0.08; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.26; acc: 0.89
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.89
Batch: 760; loss: 0.13; acc: 0.95
Batch: 780; loss: 0.2; acc: 0.97
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.14; acc: 0.95
Batch: 20; loss: 0.24; acc: 0.91
Batch: 40; loss: 0.14; acc: 0.95
Batch: 60; loss: 0.19; acc: 0.92
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.39; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.18121277988194281; val_accuracy: 0.9443670382165605 

The current subspace-distance is: 0.00010662015847628936 

Epoch 18 start
The current lr is: 0.4
Batch: 0; loss: 0.16; acc: 0.94
Batch: 20; loss: 0.17; acc: 0.92
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.19; acc: 0.95
Batch: 80; loss: 0.11; acc: 0.98
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.07; acc: 0.98
Batch: 140; loss: 0.17; acc: 0.94
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.89
Batch: 200; loss: 0.35; acc: 0.91
Batch: 220; loss: 0.34; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.17; acc: 0.95
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.16; acc: 0.92
Batch: 320; loss: 0.2; acc: 0.94
Batch: 340; loss: 0.14; acc: 0.95
Batch: 360; loss: 0.47; acc: 0.88
Batch: 380; loss: 0.16; acc: 0.94
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.24; acc: 0.95
Batch: 440; loss: 0.47; acc: 0.89
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.95
Batch: 500; loss: 0.34; acc: 0.88
Batch: 520; loss: 0.27; acc: 0.95
Batch: 540; loss: 0.12; acc: 0.95
Batch: 560; loss: 0.07; acc: 0.97
Batch: 580; loss: 0.38; acc: 0.91
Batch: 600; loss: 0.1; acc: 1.0
Batch: 620; loss: 0.2; acc: 0.94
Batch: 640; loss: 0.37; acc: 0.88
Batch: 660; loss: 0.19; acc: 0.94
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.13; acc: 0.98
Batch: 720; loss: 0.17; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.36; acc: 0.91
Batch: 780; loss: 0.36; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.32; acc: 0.91
Batch: 40; loss: 0.19; acc: 0.95
Batch: 60; loss: 0.21; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.92
Batch: 120; loss: 0.5; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.21491104952848641; val_accuracy: 0.9350119426751592 

The current subspace-distance is: 0.00011028576409444213 

Epoch 19 start
The current lr is: 0.4
Batch: 0; loss: 0.26; acc: 0.92
Batch: 20; loss: 0.31; acc: 0.91
Batch: 40; loss: 0.17; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.26; acc: 0.92
Batch: 100; loss: 0.38; acc: 0.91
Batch: 120; loss: 0.29; acc: 0.91
Batch: 140; loss: 0.13; acc: 0.95
Batch: 160; loss: 0.2; acc: 0.97
Batch: 180; loss: 0.17; acc: 0.97
Batch: 200; loss: 0.16; acc: 0.97
Batch: 220; loss: 0.28; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.94
Batch: 260; loss: 0.29; acc: 0.88
Batch: 280; loss: 0.22; acc: 0.95
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.11; acc: 0.97
Batch: 360; loss: 0.25; acc: 0.97
Batch: 380; loss: 0.2; acc: 0.92
Batch: 400; loss: 0.29; acc: 0.94
Batch: 420; loss: 0.29; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.22; acc: 0.95
Batch: 500; loss: 0.26; acc: 0.95
Batch: 520; loss: 0.27; acc: 0.94
Batch: 540; loss: 0.16; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.94
Batch: 580; loss: 0.2; acc: 0.94
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.16; acc: 0.94
Batch: 660; loss: 0.22; acc: 0.97
Batch: 680; loss: 0.49; acc: 0.89
Batch: 700; loss: 0.1; acc: 0.94
Batch: 720; loss: 0.24; acc: 0.89
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.2; acc: 0.92
Batch: 780; loss: 0.33; acc: 0.94
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.26; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.28; acc: 0.92
Batch: 120; loss: 0.42; acc: 0.89
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.2091420884867003; val_accuracy: 0.9365047770700637 

The current subspace-distance is: 0.00011354582966305315 

Epoch 20 start
The current lr is: 0.4
Batch: 0; loss: 0.17; acc: 0.94
Batch: 20; loss: 0.32; acc: 0.88
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.19; acc: 0.97
Batch: 80; loss: 0.33; acc: 0.92
Batch: 100; loss: 0.22; acc: 0.92
Batch: 120; loss: 0.17; acc: 0.94
Batch: 140; loss: 0.14; acc: 0.95
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.04; acc: 0.98
Batch: 200; loss: 0.08; acc: 0.95
Batch: 220; loss: 0.2; acc: 0.92
Batch: 240; loss: 0.11; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.98
Batch: 280; loss: 0.31; acc: 0.91
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.19; acc: 0.91
Batch: 340; loss: 0.27; acc: 0.92
Batch: 360; loss: 0.26; acc: 0.92
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.21; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.19; acc: 0.94
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.25; acc: 0.92
Batch: 580; loss: 0.27; acc: 0.92
Batch: 600; loss: 0.16; acc: 0.95
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.11; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.21; acc: 0.97
Batch: 720; loss: 0.27; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.91
Batch: 760; loss: 0.13; acc: 0.97
Batch: 780; loss: 0.28; acc: 0.88
Train Epoch over. train_loss: 0.19; train_accuracy: 0.94 

Batch: 0; loss: 0.1; acc: 0.95
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.91
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.36; acc: 0.89
Batch: 120; loss: 0.55; acc: 0.81
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.19831105925522413; val_accuracy: 0.940187101910828 

The current subspace-distance is: 0.00011797747720265761 

Epoch 21 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.23; acc: 0.95
Batch: 100; loss: 0.17; acc: 0.95
Batch: 120; loss: 0.13; acc: 0.97
Batch: 140; loss: 0.08; acc: 0.97
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.21; acc: 0.94
Batch: 280; loss: 0.25; acc: 0.92
Batch: 300; loss: 0.16; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.91
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.13; acc: 0.95
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.05; acc: 0.98
Batch: 420; loss: 0.26; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.13; acc: 0.97
Batch: 480; loss: 0.09; acc: 0.95
Batch: 500; loss: 0.24; acc: 0.89
Batch: 520; loss: 0.15; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.29; acc: 0.94
Batch: 580; loss: 0.05; acc: 1.0
Batch: 600; loss: 0.32; acc: 0.91
Batch: 620; loss: 0.14; acc: 0.95
Batch: 640; loss: 0.14; acc: 0.95
Batch: 660; loss: 0.4; acc: 0.91
Batch: 680; loss: 0.28; acc: 0.91
Batch: 700; loss: 0.35; acc: 0.91
Batch: 720; loss: 0.18; acc: 0.94
Batch: 740; loss: 0.09; acc: 0.95
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.94
Batch: 60; loss: 0.2; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.92
Batch: 120; loss: 0.37; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16830145290038387; val_accuracy: 0.9483479299363057 

The current subspace-distance is: 0.00012114112905692309 

Epoch 22 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.28; acc: 0.94
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.06; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.25; acc: 0.95
Batch: 120; loss: 0.28; acc: 0.89
Batch: 140; loss: 0.3; acc: 0.91
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.29; acc: 0.88
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.13; acc: 0.95
Batch: 280; loss: 0.02; acc: 1.0
Batch: 300; loss: 0.09; acc: 0.97
Batch: 320; loss: 0.09; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.97
Batch: 360; loss: 0.2; acc: 0.92
Batch: 380; loss: 0.19; acc: 0.94
Batch: 400; loss: 0.38; acc: 0.88
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.98
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.21; acc: 0.95
Batch: 500; loss: 0.13; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.94
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.22; acc: 0.92
Batch: 580; loss: 0.21; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.92
Batch: 640; loss: 0.19; acc: 0.92
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.24; acc: 0.94
Batch: 700; loss: 0.32; acc: 0.94
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.23; acc: 0.95
Batch: 760; loss: 0.26; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.1; acc: 0.97
Batch: 20; loss: 0.2; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.28; acc: 0.91
Batch: 120; loss: 0.41; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17013624612431807; val_accuracy: 0.948546974522293 

The current subspace-distance is: 0.0001242395956069231 

Epoch 23 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.12; acc: 0.95
Batch: 20; loss: 0.23; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.92
Batch: 60; loss: 0.2; acc: 0.92
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.11; acc: 0.98
Batch: 120; loss: 0.23; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.97
Batch: 180; loss: 0.1; acc: 0.97
Batch: 200; loss: 0.1; acc: 0.95
Batch: 220; loss: 0.25; acc: 0.92
Batch: 240; loss: 0.04; acc: 1.0
Batch: 260; loss: 0.12; acc: 0.97
Batch: 280; loss: 0.15; acc: 0.95
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.03; acc: 1.0
Batch: 360; loss: 0.1; acc: 0.97
Batch: 380; loss: 0.15; acc: 0.94
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.3; acc: 0.92
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.17; acc: 0.92
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.22; acc: 0.92
Batch: 540; loss: 0.15; acc: 0.95
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.45; acc: 0.89
Batch: 620; loss: 0.06; acc: 1.0
Batch: 640; loss: 0.32; acc: 0.91
Batch: 660; loss: 0.09; acc: 0.95
Batch: 680; loss: 0.15; acc: 0.94
Batch: 700; loss: 0.19; acc: 0.95
Batch: 720; loss: 0.14; acc: 0.95
Batch: 740; loss: 0.05; acc: 1.0
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.46; acc: 0.88
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.04; acc: 0.98
Batch: 100; loss: 0.27; acc: 0.94
Batch: 120; loss: 0.37; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.177560239164218; val_accuracy: 0.9459593949044586 

The current subspace-distance is: 0.0001271931832889095 

Epoch 24 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.2; acc: 0.92
Batch: 60; loss: 0.12; acc: 0.97
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.27; acc: 0.94
Batch: 140; loss: 0.21; acc: 0.97
Batch: 160; loss: 0.08; acc: 0.97
Batch: 180; loss: 0.38; acc: 0.88
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.26; acc: 0.91
Batch: 280; loss: 0.13; acc: 0.95
Batch: 300; loss: 0.07; acc: 0.98
Batch: 320; loss: 0.27; acc: 0.89
Batch: 340; loss: 0.12; acc: 0.95
Batch: 360; loss: 0.21; acc: 0.94
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.97
Batch: 420; loss: 0.06; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.97
Batch: 480; loss: 0.29; acc: 0.89
Batch: 500; loss: 0.17; acc: 0.94
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.14; acc: 0.94
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.95
Batch: 600; loss: 0.07; acc: 0.98
Batch: 620; loss: 0.08; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.95
Batch: 660; loss: 0.18; acc: 0.94
Batch: 680; loss: 0.08; acc: 0.97
Batch: 700; loss: 0.25; acc: 0.94
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.94
Batch: 760; loss: 0.26; acc: 0.94
Batch: 780; loss: 0.15; acc: 0.95
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.13; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.91
Batch: 120; loss: 0.45; acc: 0.84
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17149683209076808; val_accuracy: 0.9486464968152867 

The current subspace-distance is: 0.00013064169615972787 

Epoch 25 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.2; acc: 0.94
Batch: 20; loss: 0.15; acc: 0.91
Batch: 40; loss: 0.13; acc: 0.95
Batch: 60; loss: 0.09; acc: 0.95
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.08; acc: 0.97
Batch: 120; loss: 0.2; acc: 0.89
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.16; acc: 0.97
Batch: 240; loss: 0.08; acc: 0.95
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.13; acc: 0.94
Batch: 300; loss: 0.12; acc: 0.95
Batch: 320; loss: 0.09; acc: 0.98
Batch: 340; loss: 0.09; acc: 0.98
Batch: 360; loss: 0.16; acc: 0.94
Batch: 380; loss: 0.06; acc: 0.98
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.05; acc: 0.98
Batch: 440; loss: 0.25; acc: 0.94
Batch: 460; loss: 0.34; acc: 0.91
Batch: 480; loss: 0.12; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.1; acc: 0.97
Batch: 540; loss: 0.36; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.92
Batch: 580; loss: 0.25; acc: 0.89
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.22; acc: 0.92
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.28; acc: 0.92
Batch: 680; loss: 0.15; acc: 0.97
Batch: 700; loss: 0.11; acc: 0.98
Batch: 720; loss: 0.3; acc: 0.92
Batch: 740; loss: 0.11; acc: 0.97
Batch: 760; loss: 0.05; acc: 1.0
Batch: 780; loss: 0.13; acc: 0.98
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.94
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.29; acc: 0.92
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16684108895433555; val_accuracy: 0.9494426751592356 

The current subspace-distance is: 0.00013325846521183848 

Epoch 26 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.32; acc: 0.92
Batch: 20; loss: 0.1; acc: 0.95
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.92
Batch: 80; loss: 0.15; acc: 0.92
Batch: 100; loss: 0.07; acc: 0.98
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.04; acc: 1.0
Batch: 160; loss: 0.16; acc: 0.95
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.16; acc: 0.94
Batch: 260; loss: 0.12; acc: 0.98
Batch: 280; loss: 0.14; acc: 0.98
Batch: 300; loss: 0.23; acc: 0.94
Batch: 320; loss: 0.24; acc: 0.91
Batch: 340; loss: 0.13; acc: 0.97
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.22; acc: 0.95
Batch: 400; loss: 0.02; acc: 1.0
Batch: 420; loss: 0.07; acc: 1.0
Batch: 440; loss: 0.38; acc: 0.91
Batch: 460; loss: 0.1; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.23; acc: 0.92
Batch: 520; loss: 0.21; acc: 0.92
Batch: 540; loss: 0.14; acc: 0.97
Batch: 560; loss: 0.03; acc: 1.0
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.17; acc: 0.94
Batch: 620; loss: 0.14; acc: 0.94
Batch: 640; loss: 0.13; acc: 0.95
Batch: 660; loss: 0.25; acc: 0.94
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.23; acc: 0.95
Batch: 720; loss: 0.07; acc: 0.98
Batch: 740; loss: 0.26; acc: 0.91
Batch: 760; loss: 0.37; acc: 0.89
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.94
Batch: 40; loss: 0.14; acc: 0.94
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.4; acc: 0.86
Batch: 140; loss: 0.02; acc: 1.0
Val Epoch over. val_loss: 0.17452271426820262; val_accuracy: 0.946656050955414 

The current subspace-distance is: 0.00013630796456709504 

Epoch 27 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.17; acc: 0.92
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.34; acc: 0.89
Batch: 60; loss: 0.14; acc: 0.98
Batch: 80; loss: 0.17; acc: 0.95
Batch: 100; loss: 0.13; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.95
Batch: 160; loss: 0.24; acc: 0.94
Batch: 180; loss: 0.26; acc: 0.94
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.95
Batch: 240; loss: 0.26; acc: 0.97
Batch: 260; loss: 0.3; acc: 0.89
Batch: 280; loss: 0.08; acc: 0.98
Batch: 300; loss: 0.2; acc: 0.95
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.18; acc: 0.92
Batch: 380; loss: 0.18; acc: 0.94
Batch: 400; loss: 0.25; acc: 0.95
Batch: 420; loss: 0.15; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.26; acc: 0.94
Batch: 540; loss: 0.26; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.43; acc: 0.86
Batch: 600; loss: 0.15; acc: 0.97
Batch: 620; loss: 0.18; acc: 0.97
Batch: 640; loss: 0.4; acc: 0.91
Batch: 660; loss: 0.35; acc: 0.89
Batch: 680; loss: 0.14; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.1; acc: 0.94
Batch: 740; loss: 0.17; acc: 0.94
Batch: 760; loss: 0.14; acc: 0.98
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.17; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.94
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.17029354904013075; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 0.0001393809070577845 

Epoch 28 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.26; acc: 0.89
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.24; acc: 0.91
Batch: 80; loss: 0.12; acc: 0.95
Batch: 100; loss: 0.16; acc: 0.95
Batch: 120; loss: 0.14; acc: 0.95
Batch: 140; loss: 0.13; acc: 0.97
Batch: 160; loss: 0.16; acc: 0.98
Batch: 180; loss: 0.11; acc: 0.97
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.07; acc: 0.98
Batch: 260; loss: 0.15; acc: 0.97
Batch: 280; loss: 0.17; acc: 0.97
Batch: 300; loss: 0.2; acc: 0.94
Batch: 320; loss: 0.07; acc: 0.98
Batch: 340; loss: 0.05; acc: 1.0
Batch: 360; loss: 0.21; acc: 0.92
Batch: 380; loss: 0.27; acc: 0.92
Batch: 400; loss: 0.34; acc: 0.88
Batch: 420; loss: 0.29; acc: 0.92
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.18; acc: 0.94
Batch: 480; loss: 0.05; acc: 0.98
Batch: 500; loss: 0.11; acc: 0.97
Batch: 520; loss: 0.04; acc: 0.98
Batch: 540; loss: 0.19; acc: 0.92
Batch: 560; loss: 0.2; acc: 0.94
Batch: 580; loss: 0.08; acc: 0.97
Batch: 600; loss: 0.34; acc: 0.92
Batch: 620; loss: 0.29; acc: 0.92
Batch: 640; loss: 0.16; acc: 0.92
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.17; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.94
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.35; acc: 0.88
Batch: 760; loss: 0.25; acc: 0.94
Batch: 780; loss: 0.24; acc: 0.94
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.18; acc: 0.92
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16992669020465034; val_accuracy: 0.9489450636942676 

The current subspace-distance is: 0.00014194681716617197 

Epoch 29 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.29; acc: 0.91
Batch: 20; loss: 0.29; acc: 0.94
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.97
Batch: 80; loss: 0.15; acc: 0.94
Batch: 100; loss: 0.21; acc: 0.94
Batch: 120; loss: 0.24; acc: 0.89
Batch: 140; loss: 0.07; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.95
Batch: 180; loss: 0.19; acc: 0.95
Batch: 200; loss: 0.28; acc: 0.92
Batch: 220; loss: 0.04; acc: 1.0
Batch: 240; loss: 0.22; acc: 0.91
Batch: 260; loss: 0.19; acc: 0.95
Batch: 280; loss: 0.24; acc: 0.92
Batch: 300; loss: 0.18; acc: 0.92
Batch: 320; loss: 0.31; acc: 0.92
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.2; acc: 0.94
Batch: 400; loss: 0.22; acc: 0.95
Batch: 420; loss: 0.11; acc: 0.97
Batch: 440; loss: 0.24; acc: 0.92
Batch: 460; loss: 0.45; acc: 0.86
Batch: 480; loss: 0.3; acc: 0.89
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.14; acc: 0.92
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.98
Batch: 640; loss: 0.14; acc: 0.94
Batch: 660; loss: 0.28; acc: 0.89
Batch: 680; loss: 0.04; acc: 1.0
Batch: 700; loss: 0.18; acc: 0.92
Batch: 720; loss: 0.14; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.14; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.98
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.35; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1699472654100721; val_accuracy: 0.9480493630573248 

The current subspace-distance is: 0.00014525180449709296 

Epoch 30 start
The current lr is: 0.16000000000000003
Batch: 0; loss: 0.18; acc: 0.94
Batch: 20; loss: 0.23; acc: 0.92
Batch: 40; loss: 0.16; acc: 0.94
Batch: 60; loss: 0.34; acc: 0.94
Batch: 80; loss: 0.26; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.16; acc: 0.95
Batch: 140; loss: 0.07; acc: 0.98
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.14; acc: 0.94
Batch: 200; loss: 0.15; acc: 0.95
Batch: 220; loss: 0.35; acc: 0.92
Batch: 240; loss: 0.18; acc: 0.95
Batch: 260; loss: 0.2; acc: 0.92
Batch: 280; loss: 0.21; acc: 0.95
Batch: 300; loss: 0.06; acc: 0.98
Batch: 320; loss: 0.11; acc: 0.97
Batch: 340; loss: 0.35; acc: 0.88
Batch: 360; loss: 0.18; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.95
Batch: 400; loss: 0.2; acc: 0.92
Batch: 420; loss: 0.19; acc: 0.95
Batch: 440; loss: 0.15; acc: 0.97
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.38; acc: 0.89
Batch: 500; loss: 0.22; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.98
Batch: 540; loss: 0.13; acc: 0.92
Batch: 560; loss: 0.17; acc: 0.92
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.18; acc: 0.91
Batch: 640; loss: 0.06; acc: 1.0
Batch: 660; loss: 0.1; acc: 0.97
Batch: 680; loss: 0.09; acc: 0.95
Batch: 700; loss: 0.18; acc: 0.95
Batch: 720; loss: 0.08; acc: 0.98
Batch: 740; loss: 0.14; acc: 0.97
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.16; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.92
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.38; acc: 0.92
Batch: 120; loss: 0.3; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1640421625191144; val_accuracy: 0.9487460191082803 

The current subspace-distance is: 0.0001483030937379226 

Epoch 31 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.16; acc: 0.91
Batch: 20; loss: 0.05; acc: 0.98
Batch: 40; loss: 0.21; acc: 0.92
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.15; acc: 0.95
Batch: 100; loss: 0.35; acc: 0.91
Batch: 120; loss: 0.1; acc: 0.94
Batch: 140; loss: 0.16; acc: 0.97
Batch: 160; loss: 0.29; acc: 0.91
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.13; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.97
Batch: 240; loss: 0.34; acc: 0.89
Batch: 260; loss: 0.15; acc: 0.94
Batch: 280; loss: 0.21; acc: 0.94
Batch: 300; loss: 0.32; acc: 0.91
Batch: 320; loss: 0.17; acc: 0.94
Batch: 340; loss: 0.06; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.94
Batch: 380; loss: 0.19; acc: 0.92
Batch: 400; loss: 0.32; acc: 0.94
Batch: 420; loss: 0.07; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.1; acc: 0.95
Batch: 500; loss: 0.1; acc: 0.95
Batch: 520; loss: 0.26; acc: 0.92
Batch: 540; loss: 0.32; acc: 0.91
Batch: 560; loss: 0.13; acc: 0.95
Batch: 580; loss: 0.21; acc: 0.92
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.15; acc: 0.97
Batch: 640; loss: 0.15; acc: 0.94
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.16; acc: 0.94
Batch: 700; loss: 0.03; acc: 1.0
Batch: 720; loss: 0.1; acc: 0.97
Batch: 740; loss: 0.17; acc: 0.95
Batch: 760; loss: 0.14; acc: 0.94
Batch: 780; loss: 0.06; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1615356059899186; val_accuracy: 0.9505374203821656 

The current subspace-distance is: 0.0001508721907157451 

Epoch 32 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.3; acc: 0.89
Batch: 20; loss: 0.19; acc: 0.92
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.94
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.23; acc: 0.92
Batch: 120; loss: 0.12; acc: 0.95
Batch: 140; loss: 0.2; acc: 0.92
Batch: 160; loss: 0.12; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.94
Batch: 200; loss: 0.49; acc: 0.88
Batch: 220; loss: 0.09; acc: 0.98
Batch: 240; loss: 0.08; acc: 0.94
Batch: 260; loss: 0.06; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.92
Batch: 300; loss: 0.09; acc: 0.98
Batch: 320; loss: 0.08; acc: 0.95
Batch: 340; loss: 0.18; acc: 0.92
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.05; acc: 1.0
Batch: 400; loss: 0.08; acc: 0.97
Batch: 420; loss: 0.07; acc: 0.98
Batch: 440; loss: 0.24; acc: 0.91
Batch: 460; loss: 0.26; acc: 0.91
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.15; acc: 0.94
Batch: 520; loss: 0.25; acc: 0.94
Batch: 540; loss: 0.17; acc: 0.97
Batch: 560; loss: 0.2; acc: 0.97
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.2; acc: 0.92
Batch: 620; loss: 0.09; acc: 0.97
Batch: 640; loss: 0.12; acc: 0.97
Batch: 660; loss: 0.32; acc: 0.92
Batch: 680; loss: 0.23; acc: 0.89
Batch: 700; loss: 0.38; acc: 0.86
Batch: 720; loss: 0.09; acc: 0.95
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.11; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.98
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16510348008340522; val_accuracy: 0.9501393312101911 

The current subspace-distance is: 0.00015278796490747482 

Epoch 33 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.15; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.92
Batch: 40; loss: 0.13; acc: 0.97
Batch: 60; loss: 0.11; acc: 0.98
Batch: 80; loss: 0.11; acc: 0.97
Batch: 100; loss: 0.15; acc: 0.95
Batch: 120; loss: 0.19; acc: 0.95
Batch: 140; loss: 0.22; acc: 0.92
Batch: 160; loss: 0.33; acc: 0.94
Batch: 180; loss: 0.03; acc: 1.0
Batch: 200; loss: 0.21; acc: 0.97
Batch: 220; loss: 0.14; acc: 0.94
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.14; acc: 0.94
Batch: 280; loss: 0.05; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.95
Batch: 320; loss: 0.27; acc: 0.95
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.98
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.16; acc: 0.94
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.1; acc: 0.97
Batch: 460; loss: 0.08; acc: 0.97
Batch: 480; loss: 0.13; acc: 0.95
Batch: 500; loss: 0.09; acc: 0.98
Batch: 520; loss: 0.1; acc: 0.98
Batch: 540; loss: 0.15; acc: 0.92
Batch: 560; loss: 0.08; acc: 0.97
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.46; acc: 0.94
Batch: 620; loss: 0.17; acc: 0.95
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.15; acc: 0.95
Batch: 720; loss: 0.16; acc: 0.94
Batch: 740; loss: 0.08; acc: 0.98
Batch: 760; loss: 0.38; acc: 0.91
Batch: 780; loss: 0.24; acc: 0.89
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.11; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16154015281943568; val_accuracy: 0.951234076433121 

The current subspace-distance is: 0.0001549980224808678 

Epoch 34 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.25; acc: 0.91
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.05; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.97
Batch: 80; loss: 0.19; acc: 0.94
Batch: 100; loss: 0.08; acc: 0.98
Batch: 120; loss: 0.03; acc: 1.0
Batch: 140; loss: 0.05; acc: 0.98
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.17; acc: 0.95
Batch: 200; loss: 0.11; acc: 0.97
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.29; acc: 0.92
Batch: 280; loss: 0.24; acc: 0.94
Batch: 300; loss: 0.29; acc: 0.92
Batch: 320; loss: 0.13; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.14; acc: 0.98
Batch: 380; loss: 0.31; acc: 0.91
Batch: 400; loss: 0.09; acc: 0.97
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.11; acc: 0.95
Batch: 460; loss: 0.08; acc: 0.95
Batch: 480; loss: 0.09; acc: 0.97
Batch: 500; loss: 0.34; acc: 0.89
Batch: 520; loss: 0.21; acc: 0.88
Batch: 540; loss: 0.14; acc: 0.95
Batch: 560; loss: 0.04; acc: 1.0
Batch: 580; loss: 0.11; acc: 0.94
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.05; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.94
Batch: 660; loss: 0.05; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.2; acc: 0.97
Batch: 720; loss: 0.08; acc: 0.97
Batch: 740; loss: 0.04; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.98
Batch: 780; loss: 0.09; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.07; acc: 0.97
Batch: 100; loss: 0.3; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.86
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.159353468531541; val_accuracy: 0.9515326433121019 

The current subspace-distance is: 0.0001574843772687018 

Epoch 35 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.05; acc: 0.98
Batch: 20; loss: 0.05; acc: 0.97
Batch: 40; loss: 0.1; acc: 0.98
Batch: 60; loss: 0.22; acc: 0.95
Batch: 80; loss: 0.2; acc: 0.89
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.04; acc: 1.0
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.24; acc: 0.91
Batch: 180; loss: 0.08; acc: 0.98
Batch: 200; loss: 0.19; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.95
Batch: 240; loss: 0.13; acc: 0.97
Batch: 260; loss: 0.14; acc: 0.95
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.15; acc: 0.95
Batch: 320; loss: 0.17; acc: 0.92
Batch: 340; loss: 0.19; acc: 0.92
Batch: 360; loss: 0.29; acc: 0.94
Batch: 380; loss: 0.08; acc: 0.95
Batch: 400; loss: 0.06; acc: 0.97
Batch: 420; loss: 0.16; acc: 0.94
Batch: 440; loss: 0.27; acc: 0.92
Batch: 460; loss: 0.13; acc: 0.95
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.16; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.95
Batch: 560; loss: 0.22; acc: 0.95
Batch: 580; loss: 0.1; acc: 0.97
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.25; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.97
Batch: 660; loss: 0.15; acc: 0.94
Batch: 680; loss: 0.05; acc: 1.0
Batch: 700; loss: 0.12; acc: 0.95
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.14; acc: 0.94
Batch: 760; loss: 0.2; acc: 0.94
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.92
Batch: 40; loss: 0.11; acc: 0.95
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16163247021710037; val_accuracy: 0.9508359872611465 

The current subspace-distance is: 0.00016006572695914656 

Epoch 36 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.06; acc: 1.0
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.18; acc: 0.95
Batch: 80; loss: 0.21; acc: 0.94
Batch: 100; loss: 0.23; acc: 0.91
Batch: 120; loss: 0.15; acc: 0.97
Batch: 140; loss: 0.32; acc: 0.94
Batch: 160; loss: 0.14; acc: 0.95
Batch: 180; loss: 0.27; acc: 0.89
Batch: 200; loss: 0.17; acc: 0.95
Batch: 220; loss: 0.04; acc: 0.98
Batch: 240; loss: 0.15; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.1; acc: 0.97
Batch: 300; loss: 0.34; acc: 0.92
Batch: 320; loss: 0.19; acc: 0.95
Batch: 340; loss: 0.11; acc: 0.95
Batch: 360; loss: 0.04; acc: 1.0
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.29; acc: 0.95
Batch: 420; loss: 0.21; acc: 0.95
Batch: 440; loss: 0.28; acc: 0.92
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.97
Batch: 500; loss: 0.08; acc: 0.97
Batch: 520; loss: 0.33; acc: 0.92
Batch: 540; loss: 0.13; acc: 0.97
Batch: 560; loss: 0.19; acc: 0.92
Batch: 580; loss: 0.26; acc: 0.92
Batch: 600; loss: 0.21; acc: 0.94
Batch: 620; loss: 0.07; acc: 0.97
Batch: 640; loss: 0.2; acc: 0.98
Batch: 660; loss: 0.26; acc: 0.94
Batch: 680; loss: 0.26; acc: 0.91
Batch: 700; loss: 0.08; acc: 0.97
Batch: 720; loss: 0.22; acc: 0.94
Batch: 740; loss: 0.15; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.98
Batch: 780; loss: 0.22; acc: 0.92
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.17; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.11; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16604559978315975; val_accuracy: 0.9500398089171974 

The current subspace-distance is: 0.00016207208682317287 

Epoch 37 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.06; acc: 0.97
Batch: 20; loss: 0.07; acc: 0.98
Batch: 40; loss: 0.19; acc: 0.97
Batch: 60; loss: 0.15; acc: 0.94
Batch: 80; loss: 0.18; acc: 0.95
Batch: 100; loss: 0.3; acc: 0.94
Batch: 120; loss: 0.11; acc: 0.95
Batch: 140; loss: 0.09; acc: 0.97
Batch: 160; loss: 0.15; acc: 0.91
Batch: 180; loss: 0.07; acc: 0.98
Batch: 200; loss: 0.03; acc: 1.0
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.17; acc: 0.95
Batch: 260; loss: 0.06; acc: 0.98
Batch: 280; loss: 0.17; acc: 0.92
Batch: 300; loss: 0.05; acc: 0.98
Batch: 320; loss: 0.12; acc: 0.95
Batch: 340; loss: 0.19; acc: 0.94
Batch: 360; loss: 0.22; acc: 0.95
Batch: 380; loss: 0.13; acc: 0.95
Batch: 400; loss: 0.08; acc: 1.0
Batch: 420; loss: 0.17; acc: 0.95
Batch: 440; loss: 0.18; acc: 0.97
Batch: 460; loss: 0.31; acc: 0.92
Batch: 480; loss: 0.18; acc: 0.92
Batch: 500; loss: 0.19; acc: 0.94
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.21; acc: 0.91
Batch: 560; loss: 0.18; acc: 0.97
Batch: 580; loss: 0.21; acc: 0.95
Batch: 600; loss: 0.1; acc: 0.95
Batch: 620; loss: 0.16; acc: 0.95
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.09; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.95
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.95
Batch: 740; loss: 0.09; acc: 0.97
Batch: 760; loss: 0.15; acc: 0.97
Batch: 780; loss: 0.21; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.98
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.159975643720549; val_accuracy: 0.9518312101910829 

The current subspace-distance is: 0.00016397070430684835 

Epoch 38 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.17; acc: 0.92
Batch: 60; loss: 0.18; acc: 0.92
Batch: 80; loss: 0.27; acc: 0.94
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.1; acc: 0.98
Batch: 140; loss: 0.12; acc: 0.97
Batch: 160; loss: 0.14; acc: 0.92
Batch: 180; loss: 0.14; acc: 0.95
Batch: 200; loss: 0.2; acc: 0.94
Batch: 220; loss: 0.22; acc: 0.94
Batch: 240; loss: 0.17; acc: 0.92
Batch: 260; loss: 0.24; acc: 0.91
Batch: 280; loss: 0.16; acc: 0.95
Batch: 300; loss: 0.14; acc: 0.97
Batch: 320; loss: 0.06; acc: 0.98
Batch: 340; loss: 0.12; acc: 0.94
Batch: 360; loss: 0.07; acc: 0.97
Batch: 380; loss: 0.1; acc: 0.97
Batch: 400; loss: 0.14; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.97
Batch: 440; loss: 0.05; acc: 0.98
Batch: 460; loss: 0.07; acc: 0.97
Batch: 480; loss: 0.12; acc: 0.97
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.16; acc: 0.95
Batch: 540; loss: 0.1; acc: 0.95
Batch: 560; loss: 0.12; acc: 0.92
Batch: 580; loss: 0.07; acc: 0.97
Batch: 600; loss: 0.12; acc: 0.95
Batch: 620; loss: 0.3; acc: 0.94
Batch: 640; loss: 0.07; acc: 0.98
Batch: 660; loss: 0.14; acc: 0.95
Batch: 680; loss: 0.11; acc: 0.94
Batch: 700; loss: 0.14; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.07; acc: 0.97
Batch: 760; loss: 0.26; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.16; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.06; acc: 0.97
Batch: 100; loss: 0.31; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15879036525299975; val_accuracy: 0.9526273885350318 

The current subspace-distance is: 0.00016660423716530204 

Epoch 39 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.07; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.31; acc: 0.91
Batch: 60; loss: 0.1; acc: 0.98
Batch: 80; loss: 0.14; acc: 0.95
Batch: 100; loss: 0.24; acc: 0.94
Batch: 120; loss: 0.16; acc: 0.97
Batch: 140; loss: 0.16; acc: 0.94
Batch: 160; loss: 0.22; acc: 0.95
Batch: 180; loss: 0.22; acc: 0.95
Batch: 200; loss: 0.31; acc: 0.94
Batch: 220; loss: 0.13; acc: 0.95
Batch: 240; loss: 0.19; acc: 0.95
Batch: 260; loss: 0.27; acc: 0.97
Batch: 280; loss: 0.4; acc: 0.91
Batch: 300; loss: 0.27; acc: 0.92
Batch: 320; loss: 0.22; acc: 0.95
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.1; acc: 0.95
Batch: 380; loss: 0.28; acc: 0.94
Batch: 400; loss: 0.09; acc: 0.95
Batch: 420; loss: 0.12; acc: 0.97
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.06; acc: 0.97
Batch: 500; loss: 0.26; acc: 0.89
Batch: 520; loss: 0.1; acc: 0.95
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.06; acc: 0.98
Batch: 580; loss: 0.05; acc: 0.98
Batch: 600; loss: 0.23; acc: 0.92
Batch: 620; loss: 0.11; acc: 0.97
Batch: 640; loss: 0.26; acc: 0.89
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.19; acc: 0.92
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.2; acc: 0.97
Batch: 740; loss: 0.07; acc: 0.98
Batch: 760; loss: 0.06; acc: 0.97
Batch: 780; loss: 0.22; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.14; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.29; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16088745813626962; val_accuracy: 0.9505374203821656 

The current subspace-distance is: 0.00016929229605011642 

Epoch 40 start
The current lr is: 0.06400000000000002
Batch: 0; loss: 0.03; acc: 1.0
Batch: 20; loss: 0.24; acc: 0.95
Batch: 40; loss: 0.08; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.98
Batch: 80; loss: 0.13; acc: 0.95
Batch: 100; loss: 0.06; acc: 1.0
Batch: 120; loss: 0.13; acc: 0.95
Batch: 140; loss: 0.23; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.95
Batch: 220; loss: 0.07; acc: 1.0
Batch: 240; loss: 0.14; acc: 0.97
Batch: 260; loss: 0.13; acc: 0.97
Batch: 280; loss: 0.27; acc: 0.91
Batch: 300; loss: 0.33; acc: 0.91
Batch: 320; loss: 0.28; acc: 0.94
Batch: 340; loss: 0.09; acc: 0.97
Batch: 360; loss: 0.06; acc: 0.98
Batch: 380; loss: 0.16; acc: 0.97
Batch: 400; loss: 0.15; acc: 0.95
Batch: 420; loss: 0.13; acc: 0.95
Batch: 440; loss: 0.07; acc: 0.95
Batch: 460; loss: 0.44; acc: 0.88
Batch: 480; loss: 0.14; acc: 0.94
Batch: 500; loss: 0.05; acc: 0.98
Batch: 520; loss: 0.17; acc: 0.94
Batch: 540; loss: 0.05; acc: 0.98
Batch: 560; loss: 0.02; acc: 1.0
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.13; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.36; acc: 0.86
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.25; acc: 0.92
Batch: 700; loss: 0.07; acc: 1.0
Batch: 720; loss: 0.12; acc: 0.97
Batch: 740; loss: 0.18; acc: 0.92
Batch: 760; loss: 0.21; acc: 0.94
Batch: 780; loss: 0.16; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.37; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.16151487077497373; val_accuracy: 0.95203025477707 

The current subspace-distance is: 0.00017129594925791025 

Epoch 41 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.15; acc: 0.97
Batch: 20; loss: 0.19; acc: 0.94
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.16; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.98
Batch: 100; loss: 0.14; acc: 0.95
Batch: 120; loss: 0.06; acc: 0.98
Batch: 140; loss: 0.11; acc: 0.95
Batch: 160; loss: 0.03; acc: 1.0
Batch: 180; loss: 0.05; acc: 1.0
Batch: 200; loss: 0.15; acc: 0.92
Batch: 220; loss: 0.11; acc: 0.97
Batch: 240; loss: 0.02; acc: 1.0
Batch: 260; loss: 0.18; acc: 0.95
Batch: 280; loss: 0.22; acc: 0.91
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.2; acc: 0.92
Batch: 340; loss: 0.05; acc: 0.98
Batch: 360; loss: 0.07; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.98
Batch: 400; loss: 0.13; acc: 0.98
Batch: 420; loss: 0.15; acc: 0.94
Batch: 440; loss: 0.05; acc: 1.0
Batch: 460; loss: 0.06; acc: 0.98
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.94
Batch: 520; loss: 0.23; acc: 0.94
Batch: 540; loss: 0.23; acc: 0.94
Batch: 560; loss: 0.19; acc: 0.94
Batch: 580; loss: 0.06; acc: 0.97
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.22; acc: 0.97
Batch: 640; loss: 0.1; acc: 0.97
Batch: 660; loss: 0.05; acc: 0.98
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.18; acc: 0.94
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.09; acc: 0.97
Batch: 780; loss: 0.05; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.94
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1578766433106866; val_accuracy: 0.9519307324840764 

The current subspace-distance is: 0.000171829538885504 

Epoch 42 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.06; acc: 0.98
Batch: 20; loss: 0.13; acc: 0.97
Batch: 40; loss: 0.2; acc: 0.91
Batch: 60; loss: 0.09; acc: 0.97
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.12; acc: 0.98
Batch: 140; loss: 0.23; acc: 0.94
Batch: 160; loss: 0.18; acc: 0.95
Batch: 180; loss: 0.1; acc: 0.98
Batch: 200; loss: 0.23; acc: 0.91
Batch: 220; loss: 0.07; acc: 0.98
Batch: 240; loss: 0.04; acc: 0.97
Batch: 260; loss: 0.11; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.97
Batch: 320; loss: 0.13; acc: 0.94
Batch: 340; loss: 0.17; acc: 0.95
Batch: 360; loss: 0.05; acc: 0.98
Batch: 380; loss: 0.07; acc: 0.97
Batch: 400; loss: 0.1; acc: 0.97
Batch: 420; loss: 0.2; acc: 0.94
Batch: 440; loss: 0.14; acc: 0.95
Batch: 460; loss: 0.17; acc: 0.94
Batch: 480; loss: 0.12; acc: 0.92
Batch: 500; loss: 0.14; acc: 0.94
Batch: 520; loss: 0.11; acc: 0.97
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.18; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.97
Batch: 600; loss: 0.24; acc: 0.94
Batch: 620; loss: 0.13; acc: 0.94
Batch: 640; loss: 0.3; acc: 0.89
Batch: 660; loss: 0.08; acc: 0.97
Batch: 680; loss: 0.18; acc: 0.95
Batch: 700; loss: 0.13; acc: 0.97
Batch: 720; loss: 0.21; acc: 0.94
Batch: 740; loss: 0.33; acc: 0.89
Batch: 760; loss: 0.12; acc: 0.92
Batch: 780; loss: 0.11; acc: 0.97
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.13; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.92
Batch: 120; loss: 0.31; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1581977658733061; val_accuracy: 0.9524283439490446 

The current subspace-distance is: 0.00017365813255310059 

Epoch 43 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.09; acc: 0.97
Batch: 20; loss: 0.09; acc: 0.98
Batch: 40; loss: 0.06; acc: 0.98
Batch: 60; loss: 0.25; acc: 0.92
Batch: 80; loss: 0.08; acc: 0.98
Batch: 100; loss: 0.12; acc: 0.94
Batch: 120; loss: 0.17; acc: 0.95
Batch: 140; loss: 0.18; acc: 0.91
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.97
Batch: 240; loss: 0.11; acc: 0.97
Batch: 260; loss: 0.15; acc: 0.95
Batch: 280; loss: 0.28; acc: 0.91
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.22; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.92
Batch: 360; loss: 0.22; acc: 0.94
Batch: 380; loss: 0.18; acc: 0.95
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.27; acc: 0.91
Batch: 440; loss: 0.13; acc: 0.97
Batch: 460; loss: 0.18; acc: 0.91
Batch: 480; loss: 0.32; acc: 0.91
Batch: 500; loss: 0.07; acc: 0.98
Batch: 520; loss: 0.04; acc: 1.0
Batch: 540; loss: 0.47; acc: 0.92
Batch: 560; loss: 0.13; acc: 0.97
Batch: 580; loss: 0.22; acc: 0.91
Batch: 600; loss: 0.2; acc: 0.95
Batch: 620; loss: 0.13; acc: 0.98
Batch: 640; loss: 0.25; acc: 0.94
Batch: 660; loss: 0.16; acc: 0.95
Batch: 680; loss: 0.05; acc: 0.98
Batch: 700; loss: 0.15; acc: 0.97
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.19; acc: 0.94
Batch: 760; loss: 0.04; acc: 1.0
Batch: 780; loss: 0.14; acc: 0.94
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.11; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.09; acc: 0.95
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.08; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1564948980216008; val_accuracy: 0.9526273885350318 

The current subspace-distance is: 0.00017608996131457388 

Epoch 44 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.97
Batch: 20; loss: 0.16; acc: 0.95
Batch: 40; loss: 0.12; acc: 0.98
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.28; acc: 0.91
Batch: 100; loss: 0.11; acc: 0.97
Batch: 120; loss: 0.29; acc: 0.89
Batch: 140; loss: 0.09; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.95
Batch: 180; loss: 0.18; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.95
Batch: 220; loss: 0.18; acc: 0.92
Batch: 240; loss: 0.13; acc: 0.94
Batch: 260; loss: 0.1; acc: 0.97
Batch: 280; loss: 0.12; acc: 0.94
Batch: 300; loss: 0.21; acc: 0.95
Batch: 320; loss: 0.24; acc: 0.88
Batch: 340; loss: 0.08; acc: 0.97
Batch: 360; loss: 0.34; acc: 0.91
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.94
Batch: 420; loss: 0.35; acc: 0.94
Batch: 440; loss: 0.2; acc: 0.91
Batch: 460; loss: 0.12; acc: 0.95
Batch: 480; loss: 0.17; acc: 0.89
Batch: 500; loss: 0.09; acc: 0.97
Batch: 520; loss: 0.06; acc: 0.98
Batch: 540; loss: 0.2; acc: 0.94
Batch: 560; loss: 0.23; acc: 0.94
Batch: 580; loss: 0.33; acc: 0.89
Batch: 600; loss: 0.09; acc: 0.97
Batch: 620; loss: 0.16; acc: 0.94
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.07; acc: 0.97
Batch: 680; loss: 0.2; acc: 0.92
Batch: 700; loss: 0.21; acc: 0.94
Batch: 720; loss: 0.13; acc: 0.94
Batch: 740; loss: 0.16; acc: 0.95
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.94
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.91
Batch: 120; loss: 0.33; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15791115792361415; val_accuracy: 0.9524283439490446 

The current subspace-distance is: 0.00017822501831687987 

Epoch 45 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.92
Batch: 20; loss: 0.19; acc: 0.97
Batch: 40; loss: 0.16; acc: 0.95
Batch: 60; loss: 0.06; acc: 0.98
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.19; acc: 0.94
Batch: 120; loss: 0.1; acc: 0.97
Batch: 140; loss: 0.18; acc: 0.94
Batch: 160; loss: 0.15; acc: 0.97
Batch: 180; loss: 0.24; acc: 0.94
Batch: 200; loss: 0.1; acc: 0.97
Batch: 220; loss: 0.1; acc: 0.98
Batch: 240; loss: 0.12; acc: 0.95
Batch: 260; loss: 0.24; acc: 0.89
Batch: 280; loss: 0.25; acc: 0.94
Batch: 300; loss: 0.08; acc: 0.97
Batch: 320; loss: 0.1; acc: 0.97
Batch: 340; loss: 0.18; acc: 0.91
Batch: 360; loss: 0.17; acc: 0.97
Batch: 380; loss: 0.28; acc: 0.92
Batch: 400; loss: 0.11; acc: 0.97
Batch: 420; loss: 0.17; acc: 0.94
Batch: 440; loss: 0.38; acc: 0.86
Batch: 460; loss: 0.16; acc: 0.95
Batch: 480; loss: 0.06; acc: 1.0
Batch: 500; loss: 0.12; acc: 0.95
Batch: 520; loss: 0.13; acc: 0.97
Batch: 540; loss: 0.09; acc: 0.98
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.25; acc: 0.94
Batch: 600; loss: 0.14; acc: 0.95
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.19; acc: 0.95
Batch: 660; loss: 0.2; acc: 0.95
Batch: 680; loss: 0.08; acc: 0.95
Batch: 700; loss: 0.33; acc: 0.92
Batch: 720; loss: 0.09; acc: 0.97
Batch: 740; loss: 0.26; acc: 0.92
Batch: 760; loss: 0.05; acc: 0.98
Batch: 780; loss: 0.17; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15790755568653536; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 0.00017988146282732487 

Epoch 46 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.19; acc: 0.94
Batch: 20; loss: 0.03; acc: 1.0
Batch: 40; loss: 0.14; acc: 0.97
Batch: 60; loss: 0.17; acc: 0.95
Batch: 80; loss: 0.16; acc: 0.97
Batch: 100; loss: 0.13; acc: 0.97
Batch: 120; loss: 0.15; acc: 0.95
Batch: 140; loss: 0.15; acc: 0.95
Batch: 160; loss: 0.08; acc: 0.98
Batch: 180; loss: 0.13; acc: 0.97
Batch: 200; loss: 0.13; acc: 0.97
Batch: 220; loss: 0.07; acc: 0.97
Batch: 240; loss: 0.06; acc: 0.98
Batch: 260; loss: 0.23; acc: 0.91
Batch: 280; loss: 0.09; acc: 0.95
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.21; acc: 0.92
Batch: 340; loss: 0.07; acc: 0.97
Batch: 360; loss: 0.11; acc: 0.97
Batch: 380; loss: 0.08; acc: 0.97
Batch: 400; loss: 0.11; acc: 0.95
Batch: 420; loss: 0.04; acc: 0.98
Batch: 440; loss: 0.08; acc: 0.97
Batch: 460; loss: 0.2; acc: 0.92
Batch: 480; loss: 0.15; acc: 0.94
Batch: 500; loss: 0.24; acc: 0.95
Batch: 520; loss: 0.09; acc: 0.97
Batch: 540; loss: 0.17; acc: 0.94
Batch: 560; loss: 0.15; acc: 0.95
Batch: 580; loss: 0.11; acc: 0.95
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.19; acc: 0.95
Batch: 640; loss: 0.04; acc: 1.0
Batch: 660; loss: 0.11; acc: 0.95
Batch: 680; loss: 0.12; acc: 0.97
Batch: 700; loss: 0.06; acc: 1.0
Batch: 720; loss: 0.11; acc: 0.98
Batch: 740; loss: 0.21; acc: 0.95
Batch: 760; loss: 0.16; acc: 0.97
Batch: 780; loss: 0.08; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.15; acc: 0.94
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1577283774745787; val_accuracy: 0.9528264331210191 

The current subspace-distance is: 0.0001816846342990175 

Epoch 47 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.17; acc: 0.95
Batch: 20; loss: 0.14; acc: 0.97
Batch: 40; loss: 0.12; acc: 0.97
Batch: 60; loss: 0.26; acc: 0.94
Batch: 80; loss: 0.1; acc: 0.97
Batch: 100; loss: 0.1; acc: 0.97
Batch: 120; loss: 0.19; acc: 0.91
Batch: 140; loss: 0.17; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.98
Batch: 180; loss: 0.22; acc: 0.91
Batch: 200; loss: 0.1; acc: 0.98
Batch: 220; loss: 0.15; acc: 0.94
Batch: 240; loss: 0.2; acc: 0.91
Batch: 260; loss: 0.11; acc: 0.94
Batch: 280; loss: 0.46; acc: 0.91
Batch: 300; loss: 0.17; acc: 0.95
Batch: 320; loss: 0.19; acc: 0.94
Batch: 340; loss: 0.15; acc: 0.97
Batch: 360; loss: 0.08; acc: 0.97
Batch: 380; loss: 0.12; acc: 0.97
Batch: 400; loss: 0.22; acc: 0.92
Batch: 420; loss: 0.25; acc: 0.94
Batch: 440; loss: 0.15; acc: 0.94
Batch: 460; loss: 0.07; acc: 0.98
Batch: 480; loss: 0.11; acc: 0.97
Batch: 500; loss: 0.06; acc: 0.98
Batch: 520; loss: 0.31; acc: 0.91
Batch: 540; loss: 0.15; acc: 0.94
Batch: 560; loss: 0.2; acc: 0.95
Batch: 580; loss: 0.09; acc: 0.97
Batch: 600; loss: 0.03; acc: 1.0
Batch: 620; loss: 0.06; acc: 0.98
Batch: 640; loss: 0.09; acc: 0.95
Batch: 660; loss: 0.3; acc: 0.95
Batch: 680; loss: 0.24; acc: 0.91
Batch: 700; loss: 0.11; acc: 0.95
Batch: 720; loss: 0.19; acc: 0.94
Batch: 740; loss: 0.13; acc: 0.95
Batch: 760; loss: 0.08; acc: 0.95
Batch: 780; loss: 0.12; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.31; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1571543535727794; val_accuracy: 0.9519307324840764 

The current subspace-distance is: 0.00018376829393673688 

Epoch 48 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.24; acc: 0.95
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.15; acc: 0.95
Batch: 60; loss: 0.23; acc: 0.92
Batch: 80; loss: 0.17; acc: 0.94
Batch: 100; loss: 0.18; acc: 0.92
Batch: 120; loss: 0.2; acc: 0.94
Batch: 140; loss: 0.11; acc: 0.98
Batch: 160; loss: 0.13; acc: 0.97
Batch: 180; loss: 0.05; acc: 0.98
Batch: 200; loss: 0.14; acc: 0.97
Batch: 220; loss: 0.17; acc: 0.95
Batch: 240; loss: 0.29; acc: 0.91
Batch: 260; loss: 0.09; acc: 0.97
Batch: 280; loss: 0.07; acc: 0.98
Batch: 300; loss: 0.08; acc: 0.98
Batch: 320; loss: 0.16; acc: 0.95
Batch: 340; loss: 0.08; acc: 0.98
Batch: 360; loss: 0.02; acc: 1.0
Batch: 380; loss: 0.11; acc: 0.97
Batch: 400; loss: 0.12; acc: 0.97
Batch: 420; loss: 0.31; acc: 0.91
Batch: 440; loss: 0.24; acc: 0.95
Batch: 460; loss: 0.24; acc: 0.94
Batch: 480; loss: 0.19; acc: 0.92
Batch: 500; loss: 0.18; acc: 0.92
Batch: 520; loss: 0.2; acc: 0.95
Batch: 540; loss: 0.16; acc: 0.94
Batch: 560; loss: 0.31; acc: 0.91
Batch: 580; loss: 0.17; acc: 0.97
Batch: 600; loss: 0.23; acc: 0.89
Batch: 620; loss: 0.07; acc: 0.98
Batch: 640; loss: 0.18; acc: 0.95
Batch: 660; loss: 0.14; acc: 0.94
Batch: 680; loss: 0.07; acc: 1.0
Batch: 700; loss: 0.09; acc: 0.97
Batch: 720; loss: 0.23; acc: 0.92
Batch: 740; loss: 0.18; acc: 0.94
Batch: 760; loss: 0.28; acc: 0.92
Batch: 780; loss: 0.07; acc: 0.98
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.13; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.95
Batch: 60; loss: 0.12; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.34; acc: 0.92
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15819989946807267; val_accuracy: 0.9521297770700637 

The current subspace-distance is: 0.00018612740677781403 

Epoch 49 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.14; acc: 0.92
Batch: 20; loss: 0.15; acc: 0.97
Batch: 40; loss: 0.11; acc: 0.98
Batch: 60; loss: 0.08; acc: 0.97
Batch: 80; loss: 0.12; acc: 0.92
Batch: 100; loss: 0.19; acc: 0.92
Batch: 120; loss: 0.05; acc: 0.98
Batch: 140; loss: 0.05; acc: 1.0
Batch: 160; loss: 0.06; acc: 0.97
Batch: 180; loss: 0.15; acc: 0.97
Batch: 200; loss: 0.17; acc: 0.94
Batch: 220; loss: 0.15; acc: 0.95
Batch: 240; loss: 0.34; acc: 0.92
Batch: 260; loss: 0.08; acc: 0.97
Batch: 280; loss: 0.08; acc: 0.97
Batch: 300; loss: 0.13; acc: 0.95
Batch: 320; loss: 0.22; acc: 0.92
Batch: 340; loss: 0.1; acc: 0.95
Batch: 360; loss: 0.17; acc: 0.94
Batch: 380; loss: 0.11; acc: 0.95
Batch: 400; loss: 0.27; acc: 0.89
Batch: 420; loss: 0.28; acc: 0.92
Batch: 440; loss: 0.16; acc: 0.94
Batch: 460; loss: 0.16; acc: 0.97
Batch: 480; loss: 0.03; acc: 1.0
Batch: 500; loss: 0.16; acc: 0.94
Batch: 520; loss: 0.08; acc: 0.97
Batch: 540; loss: 0.23; acc: 0.95
Batch: 560; loss: 0.14; acc: 0.95
Batch: 580; loss: 0.18; acc: 0.89
Batch: 600; loss: 0.18; acc: 0.94
Batch: 620; loss: 0.1; acc: 0.95
Batch: 640; loss: 0.04; acc: 0.98
Batch: 660; loss: 0.08; acc: 0.95
Batch: 680; loss: 0.18; acc: 0.91
Batch: 700; loss: 0.18; acc: 0.97
Batch: 720; loss: 0.16; acc: 0.97
Batch: 740; loss: 0.23; acc: 0.91
Batch: 760; loss: 0.14; acc: 0.95
Batch: 780; loss: 0.16; acc: 0.95
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.14; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.97
Batch: 60; loss: 0.14; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.32; acc: 0.92
Batch: 120; loss: 0.34; acc: 0.88
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.15816308817215216; val_accuracy: 0.9526273885350318 

The current subspace-distance is: 0.00018847384490072727 

Epoch 50 start
The current lr is: 0.025600000000000005
Batch: 0; loss: 0.11; acc: 0.95
Batch: 20; loss: 0.04; acc: 1.0
Batch: 40; loss: 0.09; acc: 0.97
Batch: 60; loss: 0.07; acc: 0.97
Batch: 80; loss: 0.24; acc: 0.94
Batch: 100; loss: 0.02; acc: 1.0
Batch: 120; loss: 0.11; acc: 0.97
Batch: 140; loss: 0.21; acc: 0.95
Batch: 160; loss: 0.1; acc: 0.95
Batch: 180; loss: 0.2; acc: 0.95
Batch: 200; loss: 0.08; acc: 0.97
Batch: 220; loss: 0.32; acc: 0.91
Batch: 240; loss: 0.15; acc: 0.94
Batch: 260; loss: 0.11; acc: 0.98
Batch: 280; loss: 0.11; acc: 0.98
Batch: 300; loss: 0.14; acc: 0.94
Batch: 320; loss: 0.15; acc: 0.94
Batch: 340; loss: 0.04; acc: 1.0
Batch: 360; loss: 0.3; acc: 0.95
Batch: 380; loss: 0.14; acc: 0.94
Batch: 400; loss: 0.17; acc: 0.95
Batch: 420; loss: 0.1; acc: 0.95
Batch: 440; loss: 0.19; acc: 0.94
Batch: 460; loss: 0.1; acc: 0.95
Batch: 480; loss: 0.22; acc: 0.94
Batch: 500; loss: 0.23; acc: 0.94
Batch: 520; loss: 0.06; acc: 0.97
Batch: 540; loss: 0.22; acc: 0.92
Batch: 560; loss: 0.07; acc: 0.95
Batch: 580; loss: 0.29; acc: 0.88
Batch: 600; loss: 0.1; acc: 0.97
Batch: 620; loss: 0.12; acc: 0.97
Batch: 640; loss: 0.35; acc: 0.89
Batch: 660; loss: 0.14; acc: 0.97
Batch: 680; loss: 0.49; acc: 0.95
Batch: 700; loss: 0.07; acc: 0.98
Batch: 720; loss: 0.08; acc: 1.0
Batch: 740; loss: 0.06; acc: 0.98
Batch: 760; loss: 0.17; acc: 0.95
Batch: 780; loss: 0.23; acc: 0.92
Train Epoch over. train_loss: 0.15; train_accuracy: 0.95 

Batch: 0; loss: 0.12; acc: 0.97
Batch: 20; loss: 0.12; acc: 0.95
Batch: 40; loss: 0.1; acc: 0.94
Batch: 60; loss: 0.13; acc: 0.95
Batch: 80; loss: 0.09; acc: 0.97
Batch: 100; loss: 0.33; acc: 0.91
Batch: 120; loss: 0.32; acc: 0.89
Batch: 140; loss: 0.01; acc: 1.0
Val Epoch over. val_loss: 0.1572101463023929; val_accuracy: 0.9522292993630573 

The current subspace-distance is: 0.00019043203792534769 

plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_500_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
plots/subspace_training/reg_lenet_2/2020-01-22 14:39:50/d_dim_XXXXX_lr_1.0_gamma_0.4_sched_freq_10_seed_1_epochs_50_batchsize_64
